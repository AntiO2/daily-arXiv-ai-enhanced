<div id=toc></div>

# Table of Contents

- [cs.SE](#cs.SE) [Total: 19]
- [cs.DC](#cs.DC) [Total: 6]
- [cs.DB](#cs.DB) [Total: 4]


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [1] [VibeTensor: System Software for Deep Learning, Fully Generated by AI Agents](https://arxiv.org/abs/2601.16238)
*Bing Xu,Terry Chen,Fengzhe Zhou,Tianqi Chen,Yangqing Jia,Vinod Grover,Haicheng Wu,Wei Liu,Craig Wittenbrink,Wen-mei Hwu,Roger Bringmann,Ming-Yu Liu,Luis Ceze,Michael Lightstone,Humphrey Shi*

Main category: cs.SE

TL;DR: VIBETENSOR是一个由LLM驱动的编码代理在高层人类指导下生成的开源深度学习系统软件栈，实现了类似PyTorch的eager tensor库，包含C++20核心、Python绑定和实验性TypeScript接口，展示了AI辅助软件工程的里程碑。


<details>
  <summary>Details</summary>
Motivation: 展示AI编码代理能够生成一个从语言绑定到CUDA内存管理的完整深度学习运行时系统，验证AI辅助软件工程的可行性，探索LLM在系统软件开发中的应用潜力。

Method: 使用LLM驱动的编码代理在高层人类指导下生成代码，实现完整的tensor库系统：包括C++20核心、Python绑定、TypeScript接口、tensor存储系统、调度器、自动微分、CUDA运行时、内存分配器，以及稳定的C ABI插件接口。

Result: 成功生成了功能完整的深度学习运行时系统，通过了构建和测试验证，在微基准测试中与PyTorch SDPA/FlashAttention对比，并在三个小型工作负载（序列反转、ViT、miniGPT）上进行了端到端训练验证，支持H100和Blackwell GPU。

Conclusion: VIBETENSOR代表了AI辅助软件工程的重要里程碑，证明了编码代理能够生成复杂的系统软件，但也揭示了"弗兰肯斯坦"组合效应等挑战，即局部正确的子系统组合可能导致全局性能次优。

Abstract: VIBETENSOR is an open-source research system software stack for deep learning, generated by LLM-powered coding agents under high-level human guidance. In this paper, "fully generated" refers to code provenance: implementation changes were produced and applied as agent-proposed diffs; validation relied on agent-run builds, tests, and differential checks, without per-change manual diff review. It implements a PyTorch-style eager tensor library with a C++20 core (CPU+CUDA), a torch-like Python overlay via nanobind, and an experimental Node.js/TypeScript interface. Unlike thin bindings, VIBETENSOR includes its own tensor/storage system, schema-lite dispatcher, reverse-mode autograd, CUDA runtime (streams/events/graphs), a stream-ordered caching allocator with diagnostics, and a stable C ABI for dynamically loaded operator plugins. We view this release as a milestone for AI-assisted software engineering: it shows coding agents can generate a coherent deep learning runtime spanning language bindings down to CUDA memory management, validated primarily by builds and tests. We describe the architecture, summarize the workflow used to produce and validate the system, and evaluate the artifact. We report repository scale and test-suite composition, and summarize reproducible microbenchmarks from an accompanying AI-generated kernel suite, including fused attention versus PyTorch SDPA/FlashAttention. We also report end-to-end training sanity checks on 3 small workloads (sequence reversal, ViT, miniGPT) on NVIDIA H100 (Hopper, SM90) and Blackwell-class GPUs; multi-GPU results are Blackwell-only and use an optional CUTLASS-based ring-allreduce plugin gated on CUDA 13+ and sm103a toolchain support. Finally, we discuss failure modes in generated system software, including a "Frankenstein" composition effect where locally correct subsystems interact to yield globally suboptimal performance.

</details>


### [2] [Combining Tests and Proofs for Better Software Verification](https://arxiv.org/abs/2601.16239)
*Li Huang,Bertrand Meyer,Manuel Oriol*

Main category: cs.SE

TL;DR: 论文提出测试与证明互补的新视角，利用契约式设计和SMT反例生成技术，实现自动测试生成、回归测试套件构建和程序修复。


<details>
  <summary>Details</summary>
Motivation: 传统上将软件验证的测试和证明视为对立方法，本文旨在探索两者互补的可能性，以应对程序测试、软件维护和自动程序修复的挑战。

Method: 基于Eiffel语言的契约式设计，利用基于"可满足性模理论"的程序证明工具的反例生成功能。通过向正确程序中引入故障，将反例转化为自动生成的回归测试套件，并利用这些机制帮助生成有正确性保证的程序修复。

Result: 开发了三种应用：1) 将反例生成用于错误程序的自动测试生成；2) 通过向正确程序引入故障，将反例转化为具有完全覆盖的自动回归测试套件；3) 利用这些机制帮助生成有正确性保证的程序修复。

Conclusion: 测试和证明不是对立而是互补的技术，通过契约式设计和SMT反例生成，可以显著提升软件验证、维护和修复的效率与质量。

Abstract: Test or prove? These two approaches to software verification have long been presented as opposites. One is dynamic, the other static: a test executes the program, a proof only analyzes the program text. A different perspective is emerging, in which testing and proving are complementary rather than competing techniques for producing software of verified quality.
  Work performed over the past few years and reviewed here develops this complementarity by taking advantage of Design by Contract, as available in Eiffel, and exploiting a feature of modern program-proving tools based on ``Satisfiability Modulo Theories'' (SMT): counterexample generation. A counterexample is an input combination that makes the program fail. If we are trying to prove a program correct, we hope not to find any. One can, however, apply counterexample generation to incorrect programs, as a tool for automatic test generation. We can also introduce faults into a correct program and turn the counterexamples into an automatically generated regression test suite with full coverage. Additionally, we can use these mechanisms to help produce program fixes for incorrect programs, with a guarantee that the fixes are correct. All three applications, leveraging on the mechanisms of Eiffel and Design by Contract, hold significant promise to address some of the challenges of program testing, software maintenance and Automatic Program Repair.

</details>


### [3] [Identifying Concurrency Bug Reports via Linguistic Patterns](https://arxiv.org/abs/2601.16338)
*Shuai Shao,Lu Xiao,Tingting Yu*

Main category: cs.SE

TL;DR: 提出基于语言模式的框架，自动识别并发错误报告，通过微调预训练语言模型达到91-93%的精确度


<details>
  <summary>Details</summary>
Motivation: 随着多核架构普及，并发系统问题（如数据竞争、死锁）日益复杂，但标记并发错误报告仍是一项劳动密集且易出错的任务，需要自动化解决方案

Method: 从730个手动标记的并发错误报告中提取58种语言模式，分为四个层次：词汇级、短语级、句子级和报告级。评估四种互补方法：匹配、学习、提示和微调，涵盖传统机器学习、大语言模型和预训练语言模型

Result: 在12个大型开源项目（10,920个GitHub和Jira问题报告）上的评估显示，使用语言模式增强输入的预训练语言模型微调方法表现最佳，GitHub上精确度达91%，Jira上达93%，在截止后数据上保持91%的精确度

Conclusion: 该工作提供了并发错误的全面语言模式分类法、将领域特定语言知识集成到预训练语言模型的新微调策略，以及支持可重复研究的标记数据集，为提高并发错误分类的自动化、精确度和可解释性奠定了基础

Abstract: With the growing ubiquity of multi-core architectures, concurrent systems have become essential but increasingly prone to complex issues such as data races and deadlocks. While modern issue-tracking systems facilitate the reporting of such problems, labeling concurrency-related bug reports remains a labor-intensive and error-prone task. This paper presents a linguistic-pattern-based framework for automatically identifying concurrency bug reports. We derive 58 distinct linguistic patterns from 730 manually labeled concurrency bug reports, organized across four levels: word-level (keywords), phrase-level (n-grams), sentence-level (semantic), and bug report-level (contextual). To assess their effectiveness, we evaluate four complementary approaches-matching, learning, prompt-based, and fine-tuning-spanning traditional machine learning, large language models (LLMs), and pre-trained language models (PLMs). Our comprehensive evaluation on 12 large-scale open-source projects (10,920 issue reports from GitHub and Jira) demonstrates that fine-tuning PLMs with linguistic-pattern-enriched inputs achieves the best performance, reaching a precision of 91% on GitHub and 93% on Jira, and maintaining strong precision on post cut-off data (91%). The contributions of this work include: (1) a comprehensive taxonomy of linguistic patterns for concurrency bugs, (2) a novel fine-tuning strategy that integrates domain-specific linguistic knowledge into PLMs, and (3) a curated, labeled dataset to support reproducible research. Together, these advances provide a foundation for improving the automation, precision, and interpretability of concurrency bug classification.

</details>


### [4] [SE Research is a Complex Ecosystem: Isolated Fixes Keep Failing -- and Systems Thinking Shows Why](https://arxiv.org/abs/2601.16363)
*Mary Shaw,Mary Lou Maher,Keith Webster*

Main category: cs.SE

TL;DR: 该论文提出软件工程研究社区面临系统性挑战，需要从生态系统角度进行整体改革，而非孤立解决问题


<details>
  <summary>Details</summary>
Motivation: 软件工程研究社区面临评审过程过载、指标驱动激励、扭曲的发表实践以及AI、规模和欺诈带来的压力等系统性挑战，这些问题分散了研究对社会更大作用的关注

Method: 采用复杂系统、生态系统和变革理论的框架，从整体系统层面分析SE研究生态系统，识别非线性反馈循环和改革杠杆点

Result: 通过生态系统视角揭示了维持当前功能障碍的非线性反馈循环，并识别出需要跨SE生态系统协调实施的改革杠杆点

Conclusion: 软件工程研究的挑战需要从生态系统层面进行整体改革，探索跨系统的协调解决方案，而非孤立的修复措施

Abstract: The software engineering research community is productive, yet it faces a constellation of challenges: swamped review processes, metric-driven incentives, distorted publication practices, and increasing pressures from AI, scale, and outright scams. These issues are often treated in isolation, yet they arise from deep structural dynamics within the research ecosystem itself and distract us from the larger role of research in society. Meaningful progress requires a holistic system-level view. We sketch such a framework drawing on ideas from complex systems, ecosystems, and theory of change. Reframing SE's challenges through this lens reveals non-linear feedback loops that sustain current dysfunctions, and it helps to identify leverage points for reform. These are less a matter of isolated fixes and more a matter of exploring coordinated sets of fixes that operate across the SE ecosystem

</details>


### [5] [Toward Agentic Software Project Management: A Vision and Roadmap](https://arxiv.org/abs/2601.16392)
*Lakshana Iruni Assalaarachchi,Zainab Masood,Rashina Hoda,John Grundy*

Main category: cs.SE

TL;DR: 论文提出"代理化项目管理"愿景，将AI代理作为"初级项目经理"与软件团队协作，引入四种工作模式解决伦理和责任问题，并探讨人类项目经理角色向战略领导和教练的转变。


<details>
  <summary>Details</summary>
Motivation: 随着代理化AI的发展，软件工程进入3.0时代，项目管理需要相应变革以提升项目成功率，同时保持以人为中心。现有项目管理方法需要适应AI代理的协作环境。

Method: 提出"代理化项目经理"作为多代理系统，设计四种不同自主级别的工作模式，根据项目管理任务选择合适模式，解决伦理、责任和信任问题。

Result: 建立了代理化项目管理的研究基础，提出了人类项目经理角色演变为"战略领导者"和"教练"的新技能要求，并为更广泛的研究社区制定了研究议程。

Conclusion: 代理化项目经理作为"初级项目经理"或"实习项目经理"与软件团队协作，通过灵活的工作模式平衡自主性与人类监督，推动软件项目管理进入3.0时代，同时保持人类在项目管理中的核心地位。

Abstract: With the advent of agentic AI, Software Engineering is transforming to a new era dubbed Software Engineering 3.0. Software project management (SPM) must also evolve with such transformations to boost successful project completion, while keeping humans at the heart of it. Building on our preliminary ideas of "agentic SPM", and supporting literature, we present our vision of an "Agentic Project Manager (PM)" as a multi-agent system for SPM 3.0. They will work like a "junior project manager", or an "intern project manager" collaboratively with software teams. We introduce four working modes, with varying autonomy levels to choose from, based on the SPM task. This addresses concerns with ethics, accountability, and trust related to agentic PMs. We also share insights on human PM role evolution and new skill requirements as a "strategic leader" and a "coach" for humans and agents. While creating the foundation for agentic SPM research, we present a research agenda for the wider research community.

</details>


### [6] [RubberDuckBench: A Benchmark for AI Coding Assistants](https://arxiv.org/abs/2601.16456)
*Ferida Mohammad,Fatma Ayad,Petros Maniatis,Satish Chandra,Elizabeth Dinella*

Main category: cs.SE

TL;DR: RubberDuckBench是一个多语言代码问题基准，评估了20个LLM在回答真实世界代码问题上的表现，发现即使最先进的模型也难以给出一致正确的回答，且存在严重幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 随着程序员越来越多地使用AI编程助手回答代码问题，需要可靠的基准来评估这些系统的性能并理解其能力边界。

Method: 从GitHub拉取请求评论中收集真实世界的上下文化问题，创建多语言代码问题基准RubberDuckBench，并制定详细的评估标准。评估了20个LLM（包括专有和开源模型）在这些问题上的表现。

Result: 最佳模型Grok 4（69.29%）、Claude Opus 4（68.5%）和GPT-5（67.8%）表现最好，但与后续9个模型没有显著差异。大多数模型通过部分得分获得分数，最佳模型在所有试验中最多只完全正确回答2个问题。平均58.3%的回答存在幻觉问题，且成本与性能无相关性。

Conclusion: 当前最先进的AI编程助手在回答真实世界代码问题时仍存在严重缺陷，需要进一步研究来开发可信且正确的AI编程助手，该基准为此提供了评估目标。

Abstract: Programmers are turning to AI coding assistants to answer questions about their code. Benchmarks are needed to soundly evaluate these systems and understand their performance. To enable such a study, we curate a benchmark of real-world contextualized questions derived from Github pull request comments. Out of this work, we present RubberDuckBench: a multilingual benchmark of questions about code, along with detailed rubrics for evaluating answers. We evaluate a diverse set of 20 LLMs (proprietary & open-source) on answering these questions. We find that even state of the art models fail to give consistent, correct responses across the benchmark. Grok 4 (69.29%), Claude Opus 4 (68.5%), and GPT-5 (67.8%) perform best overall, but do not exhibit pairwise significant superiority over the next 9 best performing models. Most models obtain points through partial credit, with the best performing models only answering at most 2 questions completely correctly across all trials. Furthermore, models often hallucinate with lies in 58.3\% of responses on average. Cost analysis reveals no correlation between expense (API pricing or parameter count) and performance. We intend this benchmark to be a target for future research in trustworthy and correct AI coding assistants.

</details>


### [7] [Bridging Expert Reasoning and LLM Detection: A Knowledge-Driven Framework for Malicious Packages](https://arxiv.org/abs/2601.16458)
*Wenbo Guo,Shiwen Song,Jiaxun Guo,Zhengzi Xu,Chengwei Liu,Haoran Ou,Mengmeng Ge,Yang Liu*

Main category: cs.SE

TL;DR: IntelGuard是一个基于检索增强生成(RAG)的恶意软件包检测框架，通过构建威胁情报知识库，结合专家推理实现高精度检测。


<details>
  <summary>Details</summary>
Motivation: 开源生态系统如NPM和PyPI面临日益严重的供应链攻击，现有检测方法要么依赖脆弱的手工规则，要么使用无法捕捉攻击语义演变的数据驱动特征。

Method: 构建包含8000+威胁情报报告的结构化知识库，将恶意代码片段与行为描述和专家推理关联。分析新包时，检索语义相似的恶意示例，应用LLM引导的推理来评估代码行为是否与预期功能一致。

Result: 在4027个真实软件包上测试，达到99%准确率和0.50%误报率，对混淆代码保持96.5%准确率。在PyPI.org部署中发现54个先前未报告的恶意包。

Conclusion: IntelGuard通过集成专家分析推理到自动化恶意包检测中，实现了可解释且鲁棒的检测，展示了基于专家知识的检测框架的有效性。

Abstract: Open-source ecosystems such as NPM and PyPI are increasingly targeted by supply chain attacks, yet existing detection methods either depend on fragile handcrafted rules or data-driven features that fail to capture evolving attack semantics. We present IntelGuard, a retrieval-augmented generation (RAG) based framework that integrates expert analytical reasoning into automated malicious package detection. IntelGuard constructs a structured knowledge base from over 8,000 threat intelligence reports, linking malicious code snippets with behavioral descriptions and expert reasoning. When analyzing new packages, it retrieves semantically similar malicious examples and applies LLM-guided reasoning to assess whether code behaviors align with intended functionality. Experiments on 4,027 real-world packages show that IntelGuard achieves 99% accuracy and a 0.50% false positive rate, while maintaining 96.5% accuracy on obfuscated code. Deployed on PyPI.org, it discovered 54 previously unreported malicious packages, demonstrating interpretable and robust detection guided by expert knowledge.

</details>


### [8] [EvoConfig: Self-Evolving Multi-Agent Systems for Efficient Autonomous Environment Configuration](https://arxiv.org/abs/2601.16489)
*Xinshuai Guo,Jiayi Kuang,Linyue Pan,Yinghui Li,Yangning Li,Hai-Tao Zheng,Ying Shen,Di Yin,Xing Sun*

Main category: cs.SE

TL;DR: EvoConfig是一个高效的环境配置框架，通过多智能体协作和细粒度执行后分析，优化运行时环境构建，在复杂任务上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 可靠的执行环境是确保大语言模型解决软件工程任务的基础。现有方法构建过程复杂繁琐，大规模配置效率低下，且缺乏对智能体执行动作的细粒度分析，难以处理复杂错误导致配置失败。

Method: 提出EvoConfig框架，采用多智能体协作构建正确的运行时环境。框架包含专家诊断模块进行细粒度执行后分析，以及自演进机制让专家智能体自我反馈并实时动态调整错误修复优先级。

Result: 在Repo2Run的420个仓库上达到与先前最佳方法Repo2Run相当的性能，在更具挑战性的Envbench上达到78.1%的成功率，比Repo2Run高出7.1%。在错误识别准确性和修复建议有效性方面也优于现有方法。

Conclusion: EvoConfig通过细粒度分析和自演进机制，显著提升了环境配置的成功率，特别是在复杂场景下表现出更强的调试能力，为软件工程任务提供了更可靠的环境配置解决方案。

Abstract: A reliable executable environment is the foundation for ensuring that large language models solve software engineering tasks. Due to the complex and tedious construction process, large-scale configuration is relatively inefficient. However, most methods always overlook fine-grained analysis of the actions performed by the agent, making it difficult to handle complex errors and resulting in configuration failures. To address this bottleneck, we propose EvoConfig, an efficient environment configuration framework that optimizes multi-agent collaboration to build correct runtime environments. EvoConfig features an expert diagnosis module for fine-grained post-execution analysis, and a self-evolving mechanism that lets expert agents self-feedback and dynamically adjust error-fixing priorities in real time. Empirically, EvoConfig matches the previous state-of-the-art Repo2Run on Repo2Run's 420 repositories, while delivering clear gains on harder cases: on the more challenging Envbench, EvoConfig achieves a 78.1% success rate, outperforming Repo2Run by 7.1%. Beyond end-to-end success, EvoConfig also demonstrates stronger debugging competence, achieving higher accuracy in error identification and producing more effective repair recommendations than existing methods.

</details>


### [9] [REprompt: Prompt Generation for Intelligent Software Development Guided by Requirements Engineering](https://arxiv.org/abs/2601.16507)
*Junjie Shi,Weisong Sun,Zhenpeng Chen,Zhujun Wu,Xiaohong Chen,Zhi Jin,Yang Liu*

Main category: cs.SE

TL;DR: REprompt：基于需求工程指导的多智能体提示优化框架，用于改进编码代理中的系统提示和用户提示设计


<details>
  <summary>Details</summary>
Motivation: 当前LLM在编码代理中作为基础模型使用时，提示设计至关重要但具有挑战性，需要同时掌握提示工程和需求工程的专业知识。现有自动化提示工程方法大多忽视了需求工程的方法论原则，难以生成符合正式需求规范的提示。

Method: 提出REprompt框架，这是一个基于需求工程指导的多智能体提示优化框架。该框架将需求工程原则融入提示生成过程，能够同时优化系统提示和用户提示。

Result: 实验结果表明，REprompt能够有效优化系统提示和用户提示，通过将提示生成建立在需求工程原则基础上，提升了提示的质量和适用性。

Conclusion: REprompt通过结合需求工程原则，解决了现有自动化提示工程方法的局限性，为智能软件开发中的提示设计提供了更有效的方法。

Abstract: The rapid development of large language models is transforming software development. Beyond serving as code auto-completion tools in integrated development environments, large language models increasingly function as foundation models within coding agents in vibe-coding scenarios. In such settings, prompts play a central role in agent-based intelligent software development, as they not only guide the behavior of large language models but also serve as carriers of user requirements. Under the dominant conversational paradigm, prompts are typically divided into system prompts and user prompts. System prompts provide high-level instructions to steer model behavior and establish conversational context, while user prompts represent inputs and requirements provided by human users. Despite their importance, designing effective prompts remains challenging, as it requires expertise in both prompt engineering and software engineering, particularly requirements engineering. To reduce the burden of manual prompt construction, numerous automated prompt engineering methods have been proposed. However, most existing approaches neglect the methodological principles of requirements engineering, limiting their ability to generate artifacts that conform to formal requirement specifications in realistic software development scenarios. To address this gap, we propose REprompt, a multi-agent prompt optimization framework guided by requirements engineering. Experiment results demonstrate that REprompt effectively optimizes both system and user prompts by grounding prompt generation in requirements engineering principles.

</details>


### [10] [Revisiting the Role of Natural Language Code Comments in Code Translation](https://arxiv.org/abs/2601.16661)
*Monika Gupta,Ajay Meena,Anamitra Roy Choudhury,Vijay Arya,Srikanta Bedathur*

Main category: cs.SE

TL;DR: 研究表明代码注释能显著提升LLM的代码翻译质量，特别是描述整体目的的注释效果最好，基于此提出的COMMENTRA方法可使翻译性能翻倍。


<details>
  <summary>Details</summary>
Motivation: 由于大多数代码专用LLM是在带有注释的代码上预训练的，自然语言注释可能有助于提高代码翻译质量，但现有基准测试中注释缺失，其影响未被充分研究。

Method: 进行了大规模实证研究，涉及超过80,000次翻译，对比有/无注释的情况，涵盖C、C++、Go、Java、Python五种语言的1100+代码样本，并基于发现提出了COMMENTRA代码翻译方法。

Result: 代码注释（特别是描述代码整体目的的注释）能显著提高翻译准确性，COMMENTRA方法可使基于LLM的代码翻译性能翻倍。

Conclusion: 这是首个在全面性、规模和语言覆盖度上研究如何利用代码注释提高代码翻译准确性的研究，证明了注释对代码翻译的重要价值。

Abstract: The advent of large language models (LLMs) has ushered in a new era in automated code translation across programming languages. Since most code-specific LLMs are pretrained on well-commented code from large repositories like GitHub, it is reasonable to hypothesize that natural language code comments could aid in improving translation quality. Despite their potential relevance, comments are largely absent from existing code translation benchmarks, rendering their impact on translation quality inadequately characterised. In this paper, we present a large-scale empirical study evaluating the impact of comments on translation performance. Our analysis involves more than $80,000$ translations, with and without comments, of $1100+$ code samples from two distinct benchmarks covering pairwise translations between five different programming languages: C, C++, Go, Java, and Python. Our results provide strong evidence that code comments, particularly those that describe the overall purpose of the code rather than line-by-line functionality, significantly enhance translation accuracy. Based on these findings, we propose COMMENTRA, a code translation approach, and demonstrate that it can potentially double the performance of LLM-based code translation. To the best of our knowledge, our study is the first in terms of its comprehensiveness, scale, and language coverage on how to improve code translation accuracy using code comments.

</details>


### [11] [The Green Side of the Lua](https://arxiv.org/abs/2601.16670)
*André Brandão,Diogo Matos,Miguel Guimarães,Simão Cunha,João Saraiva*

Main category: cs.SE

TL;DR: 该论文通过实证研究发现，LuaJIT编译器相比标准Lua解释器能显著提升性能和能效，能耗降低约7倍，速度提升约7倍，且接近C语言的效率水平。


<details>
  <summary>Details</summary>
Motivation: 联合国2030年可持续发展议程强调节能软件的重要性。编程语言和执行模型对软件能耗有重要影响，解释型语言通常比编译型语言效率低。Lua作为流行语言，其能效不如C等更环保快速的语言，因此需要研究如何提升其性能与能效。

Method: 对25个官方Lua解释器版本和即时编译(JIT)编译器进行实证研究，使用全面的基准测试套件测量执行时间和能耗，分析Lua的演进、JIT编译的影响以及与其他语言的比较。

Result: 所有LuaJIT编译器都显著优于标准Lua解释器。最高效的LuaJIT能耗比最佳Lua解释器低约7倍，运行速度快约7倍。LuaJIT接近C语言的效率，能耗约为C的6倍，运行速度约为C的8倍。

Conclusion: JIT编译对提升解释型语言的性能和能效有显著益处，LuaJIT能大幅改善Lua的能源效率，使其接近编译型语言的性能水平，这对实现可持续软件开发具有重要意义。

Abstract: The United Nations' 2030 Agenda for Sustainable Development highlights the importance of energy-efficient software to reduce the global carbon footprint. Programming languages and execution models strongly influence software energy consumption, with interpreted languages generally being less efficient than compiled ones. Lua illustrates this trade-off: despite its popularity, it is less energy-efficient than greener and faster languages such as C.
  This paper presents an empirical study of Lua's runtime performance and energy efficiency across 25 official interpreter versions and just-in-time (JIT) compilers. Using a comprehensive benchmark suite, we measure execution time and energy consumption to analyze Lua's evolution, the impact of JIT compilation, and comparisons with other languages. Results show that all LuaJIT compilers significantly outperform standard Lua interpreters. The most efficient LuaJIT consumes about seven times less energy and runs seven times faster than the best Lua interpreter. Moreover, LuaJIT approaches C's efficiency, using roughly six times more energy and running about eight times slower, demonstrating the substantial benefits of JIT compilation for improving both performance and energy efficiency in interpreted languages.

</details>


### [12] [Supporting Stakeholder Requirements Expression with LLM Revisions: An Empirical Evaluation](https://arxiv.org/abs/2601.16699)
*Michael Mircea,Emre Gevrek,Elisa Schmid,Kurt Schneider*

Main category: cs.SE

TL;DR: LLMs能有效辅助需求表达，特别是帮助领域知识有限的利益相关者更清晰、完整地表达需求，提升需求的质量和意图对齐度。


<details>
  <summary>Details</summary>
Motivation: 利益相关者常因领域知识有限或认知限制而难以准确表达需求，导致表达的需求与真实意图不一致。传统需求获取方法耗时且可能在迭代过程中扭曲原始意图。LLMs具有从上下文推断用户意图的能力，可能帮助利益相关者更好地表达需求。

Method: 研究采用利益相关者为中心的方法，让26名参与者产生130个需求陈述。参与者先无辅助地表达需求，然后评估LLM根据其上下文生成的修订版本。通过定量评分（意图对齐度、可读性、推理性、明确性）和定性反馈进行评估。

Result: 参与者对LLM修订版本的评分在所有维度上都显著高于原始陈述。定性反馈显示LLM修订经常能揭示利益相关者认为重要但未明确表达的细节，并帮助他们更好地理解自己的需求。

Conclusion: LLM辅助的需求重构能提高需求的感知完整性、清晰度和意图对齐度。通过将利益相关者保持在验证循环中，这种方法促进了AI在需求工程中的负责任和可信赖使用。

Abstract: Stakeholders often struggle to accurately express their requirements due to articulation barriers arising from limited domain knowledge or from cognitive constraints. This can cause misalignment between expressed and intended requirements, complicating elicitation and validation. Traditional elicitation techniques, such as interviews and follow-up sessions, are time-consuming and risk distorting stakeholders' original intent across iterations. Large Language Models (LLMs) can infer user intentions from context, suggesting potential for assisting stakeholders in expressing their needs. This raises the questions of (i) how effectively LLMs can support requirement expression and (ii) whether such support benefits stakeholders with limited domain expertise. We conducted a study with 26 participants who produced 130 requirement statements. Each participant first expressed requirements unaided, then evaluated LLM-generated revisions tailored to their context. Participants rated LLM revisions significantly higher than their original statements across all dimensions-alignment with intent, readability, reasoning, and unambiguity. Qualitative feedback further showed that LLM revisions often surfaced tacit details stakeholders considered important and helped them better understand their own requirements. We present and evaluate a stakeholder-centered approach that leverages LLMs as articulation aids in requirements elicitation and validation. Our results show that LLM-assisted reformulation improves perceived completeness, clarity, and alignment of requirements. By keeping stakeholders in the validation loop, this approach promotes responsible and trustworthy use of AI in Requirements Engineering.

</details>


### [13] [Adoption of Generative Artificial Intelligence in the German Software Engineering Industry: An Empirical Study](https://arxiv.org/abs/2601.16700)
*Ludwig Felder,Tobias Eisenreich,Mahsa Fischer,Stefan Wagner,Chunyang Chen*

Main category: cs.SE

TL;DR: 德国软件工程师中生成式AI工具的采用研究：经验水平调节感知收益，组织规模影响工具选择与使用强度，项目上下文认知不足是主要障碍。


<details>
  <summary>Details</summary>
Motivation: 尽管生成式AI工具在软件开发者中快速普及，但影响其有效使用的因素（如交互深度、组织约束、经验考量）尚未充分研究。在德国等有严格监管要求的环境中，开发者需平衡GDPR、欧盟AI法案与生产力提升、知识产权保护，但目前缺乏德国背景下GenAI采用动态的实证研究。

Method: 采用混合方法研究：首先进行18次探索性访谈，随后开展包含109名参与者的开发者调查。分析工具采用模式、提示策略以及影响有效性的组织因素。

Result: 经验水平调节GenAI工具的感知收益，生产力提升在开发者中分布不均；组织规模影响工具选择和使用强度；项目上下文认知有限被确定为最主要障碍。

Conclusion: 总结了针对开发者、组织和工具供应商的行动建议，以推进AI辅助软件开发。研究填补了德国背景下GenAI采用动态的实证研究空白，为在监管严格环境中有效采用AI工具提供了实践指导。

Abstract: Generative artificial intelligence (GenAI) tools have seen rapid adoption among software developers. While adoption rates in the industry are rising, the underlying factors influencing the effective use of these tools, including the depth of interaction, organizational constraints, and experience-related considerations, have not been thoroughly investigated. This issue is particularly relevant in environments with stringent regulatory requirements, such as Germany, where practitioners must address the GDPR and the EU AI Act while balancing productivity gains with intellectual property considerations. Despite the significant impact of GenAI on software engineering, to the best of our knowledge, no empirical study has systematically examined the adoption dynamics of GenAI tools within the German context. To address this gap, we present a comprehensive mixed-methods study on GenAI adoption among German software engineers. Specifically, we conducted 18 exploratory interviews with practitioners, followed by a developer survey with 109 participants. We analyze patterns of tool adoption, prompting strategies, and organizational factors that influence effectiveness. Our results indicate that experience level moderates the perceived benefits of GenAI tools, and productivity gains are not evenly distributed among developers. Further, organizational size affects both tool selection and the intensity of tool use. Limited awareness of the project context is identified as the most significant barrier. We summarize a set of actionable implications for developers, organizations, and tool vendors seeking to advance artificial intelligence (AI) assisted software development.

</details>


### [14] [Developer Perspectives on REST API Usability: A Study of REST API Guidelines](https://arxiv.org/abs/2601.16705)
*Sven Peldszus,Jan Rutenkolk,Marcel Heide,Jan Sollmann,Benjamin Klatt,Frank Köhne,Thorsten Berger*

Main category: cs.SE

TL;DR: 该研究通过访谈16位REST API行业专家，探讨了REST API设计指南的有效性、采用挑战及最佳实践，识别出影响API可用性的八个因素，其中遵循惯例最为重要。


<details>
  <summary>Details</summary>
Motivation: REST API已成为核心业务资产，但设计质量参差不齐。虽然存在各种设计指南，但开发者仍难以设计有效的REST API。现有指南常被认为过于庞大且不适用，公司自行制定指南又面临挑战。需要实证研究来理解REST API指南的采用、使用和创建过程。

Method: 采用访谈研究方法，对16位来自工业界的REST API专家进行访谈，分析API可用性概念、指南有效性因素、采用和设计指南的挑战以及最佳实践。

Result: 识别出影响REST API可用性的八个因素，其中遵循惯例是最重要的因素。研究发现指南确实能有效提高API可用性，但开发者对严格指南存在显著抵触。指南规模和组织适配性是重要考虑因素，指南需要随组织发展而演进，所有利益相关者都应参与其开发和维护。自动化lint工具不仅能嵌入合规执行，还能通过教育性解释为指南规则提供依据。

Conclusion: REST API指南是提高API可用性的有效手段，但需要平衡严格性与灵活性，考虑组织适配性，并采用自动化工具支持。指南应作为动态文档，随组织发展而演进，并确保利益相关者的广泛参与。

Abstract: REST is today's most widely used architectural style for providing web-based services. In the age of service-orientation (a.k.a. Software as a Service (SaaS)) APIs have become core business assets and can easily expose hundreds of operations. While well-designed APIs contribute to the commercial success of a service, poorly designed APIs can threaten entire organizations. Recognizing their relevance and value, many guidelines have been proposed for designing usable APIs, similar to design patterns and coding standards. For example, Zalando and Microsoft provide popular REST API guidelines. However, they are often considered as too large and inapplicable, so many companies create and maintain their own guidelines, which is a challenge in itself. In practice, however, developers still struggle to design effective REST APIs. To improve the situation, we need to improve our empirical understanding of adopting, using, and creating REST API guidelines.
  We present an interview study with 16 REST API experts from industry. We determine the notion of API usability, guideline effectiveness factors, challenges of adopting and designing guidelines, and best practices. We identified eight factors influencing REST API usability, among which the adherence to conventions is the most important one. While guidelines can in fact be an effective means to improve API usability, there is significant resistance from developers against strict guidelines. Guideline size and how it fits with organizational needs are two important factors to consider. REST guidelines also have to grow with the organization, while all stakeholders need to be involved in their development and maintenance. Automated linting provides an opportunity to not only embed compliance enforcement into processes, but also to justify guideline rules with educational explanations.

</details>


### [15] [SWE-Pruner: Self-Adaptive Context Pruning for Coding Agents](https://arxiv.org/abs/2601.16746)
*Yuhang Wang,Yuling Shi,Mo Yang,Rongrui Zhang,Shilin He,Heng Lian,Yuting Chen,Siyu Ye,Kai Cai,Xiaodong Gu*

Main category: cs.SE

TL;DR: SWE-Pruner是一个针对编码代理的自适应上下文剪枝框架，通过任务感知的代码行选择来压缩长上下文，减少API成本和延迟。


<details>
  <summary>Details</summary>
Motivation: LLM代理在软件开发中表现出色，但长交互上下文导致高API成本和延迟。现有上下文压缩方法（如LongLLMLingua）使用固定指标（如PPL），忽略了代码理解的任务特定性，经常破坏语法逻辑结构并丢失关键实现细节。

Method: 受人类程序员"选择性浏览"代码的启发，SWE-Pruner执行任务感知的自适应剪枝：1）代理根据当前任务制定明确目标（如"关注错误处理"）作为提示；2）训练轻量级神经筛选器（0.6B参数）根据目标动态选择相关代码行。

Result: 在四个基准测试和多个模型上的评估验证了SWE-Pruner的有效性：在SWE-Bench Verified等代理任务上实现23-54%的token减少，在LongCodeQA等单轮任务上实现高达14.84倍的压缩，性能影响最小。

Conclusion: SWE-Pruner通过任务感知的自适应上下文剪枝，有效解决了编码代理的长上下文问题，显著减少了token使用和延迟，同时保持了代码理解的质量。

Abstract: LLM agents have demonstrated remarkable capabilities in software development, but their performance is hampered by long interaction contexts, which incur high API costs and latency. While various context compression approaches such as LongLLMLingua have emerged to tackle this challenge, they typically rely on fixed metrics such as PPL, ignoring the task-specific nature of code understanding. As a result, they frequently disrupt syntactic and logical structure and fail to retain critical implementation details. In this paper, we propose SWE-Pruner, a self-adaptive context pruning framework tailored for coding agents. Drawing inspiration from how human programmers "selectively skim" source code during development and debugging, SWE-Pruner performs task-aware adaptive pruning for long contexts. Given the current task, the agent formulates an explicit goal (e.g., "focus on error handling") as a hint to guide the pruning targets. A lightweight neural skimmer (0.6B parameters) is trained to dynamically select relevant lines from the surrounding context given the goal. Evaluations across four benchmarks and multiple models validate SWE-Pruner's effectiveness in various scenarios, achieving 23-54% token reduction on agent tasks like SWE-Bench Verified and up to 14.84x compression on single-turn tasks like LongCodeQA with minimal performance impact.

</details>


### [16] [Variability-Aware Detection and Repair of Compilation Errors Using Foundation Models in Configurable Systems](https://arxiv.org/abs/2601.16755)
*Rohit Gheyi,Lucas Albuquerque,Márcio Ribeiro,Eduardo Almeida,Danyllo Albuquerque,Mirko Perkusich*

Main category: cs.SE

TL;DR: 该研究评估了基础模型（GPT-OSS-20B和GEMINI 3 PRO）在检测和修复可配置C系统中由特性可变性引起的编译错误方面的效果，发现其性能优于传统工具TYPECHEF，并能有效修复70%以上的编译错误。


<details>
  <summary>Details</summary>
Motivation: 可配置软件系统中，特定特性组合可能引发编译错误，这些错误在开发和测试中难以发现。传统编译器一次只能分析单个配置，而现有的可变性感知工具设置复杂且分析成本高，需要更实用的解决方案。

Method: 使用基础模型（GPT-OSS-20B和GEMINI 3 PRO）检测和修复由特性可变性引起的编译错误，并与最先进的可变性感知解析器TYPECHEF进行比较。评估包括：1）5000个小型可配置系统（包含有/无编译错误的系统）；2）14个真实GitHub提交；3）42个变异测试场景。

Result: 基础模型能有效识别可变性引起的编译错误：GPT-OSS-20B在小型系统上达到精度0.97、召回率0.90、准确率0.94，检测覆盖率显著高于TYPECHEF。在修复方面，GPT-OSS-20B在70%以上的情况下能生成可编译的修复方案。在真实提交分析中，CHATGPT-5.2检测出除2个案例外的所有注入故障，并在一个超过1000行修改的Linux提交中识别出潜在的真实编译错误。

Conclusion: 当前最先进的基础模型为传统可变性感知分析提供了实用且低成本的补充方案，能够有效检测和修复可配置系统中的编译错误，具有实际应用价值。

Abstract: Modern software systems often rely on conditional compilation to support optional features and multiple deployment scenarios. In configurable systems, compilation errors may arise only under specific combinations of features, remaining hidden during development and testing. Such variability-induced errors are difficult to detect in practice, as traditional compilers analyze only a single configuration at a time, while existing variability-aware tools typically require complex setup and incur high analysis costs. In this article, we present an empirical study on the use of foundation models to detect and fix compilation errors caused by feature variability in configurable C systems. We evaluate GPT-OSS-20B and GEMINI 3 PRO, and compare them with TYPECHEF, a state-of-the-art variability-aware parser. Our evaluation considers two complementary settings: 5,000 small configurable systems designed to systematically exercise variability-induced compilation behavior, comprising both systems with and without compilation errors, and 14 real-world GitHub commits, as well as an additional set of mutation testing scenarios (42). Our results show that foundation models can effectively identify variability-induced compilation errors. On small configurable systems, GPT-OSS-20B achieved a precision of 0.97, recall of 0.90, and accuracy of 0.94, substantially increasing detection coverage compared to TYPECHEF, and exhibiting performance comparable to GEMINI 3. For compilation error repair, GPT-OSS-20B produced compilable fixes in over 70% of the cases. In the analysis of real commits, CHATGPT-5.2 detected all injected faults except for two cases and identified a potential real compilation bug in a Linux commit with more than 1,000 modified lines. Our findings indicate that current state-of-the-art foundation models provide a practical and low-effort complement to traditional variability-aware analyses.

</details>


### [17] [Will It Survive? Deciphering the Fate of AI-Generated Code in Open Source](https://arxiv.org/abs/2601.16809)
*Musfiqur Rahman,Emad Shihab*

Main category: cs.SE

TL;DR: AI代理生成的代码比人类代码存活时间更长，修改率更低，反驳了"一次性代码"假设


<details>
  <summary>Details</summary>
Motivation: 研究AI代理生成的代码是否如软件工程社区普遍认为的那样是"一次性"的，即快速合并但很快被丢弃，以评估组织是否面临从生成到部署后维护的负担转移风险

Method: 通过对201个开源项目进行生存分析，追踪超过20万个由AI代理与人类编写的代码单元，比较修改率、修改风险、修正性修改与适应性修改的比例

Result: 与一次性代码假设相反，AI代理编写的代码存活时间显著更长：行级修改率低15.8个百分点，修改风险低16%。AI代码修正性修改率略高（26.3% vs 23.0%），但人类代码适应性修改率更高。文本特征可识别易修改代码（AUC-ROC = 0.671），但预测修改时间仍具挑战性（Macro F1 = 0.285）

Conclusion: AI生成代码的主要瓶颈可能不是生成质量，而是管理其长期演化的组织实践。代理代码的修改模式与人类不同，但代理间差异大于人机差异，表明组织实践对代码长期维护至关重要

Abstract: The integration of AI agents as coding assistants into software development has raised questions about the long-term viability of AI agent-generated code. A prevailing hypothesis within the software engineering community suggests this code is "disposable", meaning it is merged quickly but discarded shortly thereafter. If true, organizations risk shifting maintenance burden from generation to post-deployment remediation. We investigate this hypothesis through survival analysis of 201 open-source projects, tracking over 200,000 code units authored by AI agents versus humans. Contrary to the disposable code narrative, agent-authored code survives significantly longer: at the line level, it exhibits a 15.8 percentage-point lower modification rate and 16% lower hazard of modification (HR = 0.842, p < 0.001). However, modification profiles differ. Agent-authored code shows modestly elevated corrective rates (26.3% vs. 23.0%), while human code shows higher adaptive rates. However, the effect sizes are small (Cramér's V = 0.116), and per-agent variation exceeds the agent-human gap. Turning to prediction, textual features can identify modification-prone code (AUC-ROC = 0.671), but predicting when modifications occur remains challenging (Macro F1 = 0.285), suggesting timing depends on external organizational dynamics. The bottleneck for agent-generated code may not be generation quality, but the organizational practices that govern its long-term evolution.

</details>


### [18] [AI builds, We Analyze: An Empirical Study of AI-Generated Build Code Quality](https://arxiv.org/abs/2601.16839)
*Anwar Ghammam,Mohamed Almukhtar*

Main category: cs.SE

TL;DR: AI编码代理在构建系统中既引入代码异味又消除异味，61%以上的AI生成PR被接受合并，需要AI感知的构建代码质量评估。


<details>
  <summary>Details</summary>
Motivation: AI编码代理在软件开发中广泛应用，但其对构建系统（软件生命周期关键但研究不足的组件）的影响尚未充分探索。需要研究AI生成的构建代码质量及其对开发实践的影响。

Method: 使用AIDev数据集（首个大规模、公开可用的AI代理编写PR数据集），通过数据挖掘方法分析：1）AI编码代理是否生成有质量问题的构建代码；2）AI代理能在多大程度上消除构建代码异味；3）AI生成的PR被开发者接受的程度。

Result: 识别出364个可维护性和安全性相关的构建代码异味，表明AI生成的构建代码会引入质量问题（如缺乏错误处理、硬编码路径/URL），但也能通过重构（如Pull Up Module和Externalize Properties）消除现有异味。超过61%的AI生成PR被批准合并，人工干预最少。

Conclusion: AI编码代理对构建代码质量具有双重影响：既引入质量问题又消除异味。需要未来研究开发AI感知的构建代码质量评估方法，以系统评估、指导和治理AI生成的构建系统代码。

Abstract: The rapid adoption of AI coding agents for software development has raised important questions about the quality and maintainability of the code they produce. While prior studies have examined AI-generated source code, the impact of AI coding agents on build systems-a critical yet understudied component of the software lifecycle-remains largely unexplored. This data mining challenge focuses on AIDev, the first large-scale, openly available dataset capturing agent-authored pull requests (Agentic-PRs) from real-world GitHub repositories. Our paper leverages this dataset to investigate (RQ1) whether AI coding agents generate build code with quality issues (e.g., code smells), (RQ2) to what extent AI agents can eliminate code smells from build code, and (RQ3) to what extent Agentic-PRs are accepted by developers. We identified 364 maintainability and security-related build smells across varying severity levels, indicating that AI-generated build code can introduce quality issues-such as lack of error handling, and hardcoded paths or URLs-while also, in some cases, removing existing smells through refactorings (e.g., Pull Up Module and Externalize Properties). Notably, more than 61\% of Agentic-PRs are approved and merged with minimal human intervention. This dual impact underscores the need for future research on AI-aware build code quality assessment to systematically evaluate, guide, and govern AI-generated build systems code.

</details>


### [19] [Assessing the Feasibility of Selective Instrumentation for Runtime Code Coverage in Large C++ Game Engines](https://arxiv.org/abs/2601.16881)
*Ian Gauk,Doriane Olewicki,Joshua Romoff,Cor-Paul Bezemer*

Main category: cs.SE

TL;DR: 针对大型C++游戏引擎的选择性代码覆盖率检测方法，在保持相关覆盖率数据的同时显著降低性能开销，避免自动化测试不稳定


<details>
  <summary>Details</summary>
Motivation: 在AAA游戏中，传统的代码覆盖率检测工具会产生显著的性能开销，这与严格的性能要求相冲突，并且可能破坏自动化测试的稳定性。游戏引擎通常使用C++编写且规模庞大，需要一种更轻量级的覆盖率检测方法。

Method: 提出了一种针对大型C++游戏引擎的选择性检测方法，通过缩小检测范围来减少开销，同时保留与开发者提交相关的覆盖率数据。该框架集成到工业游戏测试流程中，使开发者能够立即获得针对其变更的测试覆盖率反馈。

Result: 编译开销极小，在检测超过2000次提交后才会使构建时间翻倍。性能评估显示，即使在最坏情况下，帧率也能保持在非检测基线的50%以上。在两个生产测试套件中，该框架未导致任何自动化测试失败，避免了全检测下的不稳定性问题。

Conclusion: 研究表明，通过选择性检测方法，可以在大型C++游戏引擎中实现提交级或构建级的代码覆盖率检测，同时保持最小开销且不损害测试稳定性，为游戏开发中的覆盖率指导测试提供了实用解决方案。

Abstract: Code coverage is a valuable guide for testing, but in AAA games the overhead of instrumentation conflicts with strict performance requirements and can destabilize automated tests. We propose and assess a selective instrumentation approach tailored to large game engines written in \texttt{C++}, which reduces the scope of instrumentation while preserving relevant coverage data to developer commits. Our framework integrates into an industrial game testing pipeline, enabling developers to receive immediate coverage feedback on tests run against their changes. The compilation overhead of our approach is minimal, allowing instrumentation of over 2,000 commits before doubling build time. In performance evaluations, even the worst-case scenario maintains frame rates above 50\% of the non-instrumented baseline. Across two production test suites maintained by our industry partner, our framework caused no automated test failures, avoiding the instability observed under full instrumentation. Our work shows that commit-level or build-level coverage of large \texttt{C++} game engines can be achieved with minimal overhead and without compromising test stability.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [20] [Space Filling Curves is All You Need: Communication-Avoiding Matrix Multiplication Made Simple](https://arxiv.org/abs/2601.16294)
*Evangelos Georganas,Alexander Heinecke,Pradeep Dubey*

Main category: cs.DC

TL;DR: 使用空间填充曲线（SFC）实现平台无关和形状无关的矩阵乘法优化，避免繁琐调参，通过通信避免算法减少数据移动，在多个CPU平台上性能超越厂商库达2倍。


<details>
  <summary>Details</summary>
Motivation: 现代CPU平台上的矩阵乘法加速器具有高FLOP/Byte比，使得实现最优矩阵乘法具有挑战性。厂商库需要针对不同平台和矩阵形状进行复杂的参数调优（张量布局、并行化方案、缓存分块），这在实际中导致性能"玻璃下巴"问题，即某些配置下性能急剧下降。

Method: 采用空间填充曲线（SFC）将多维计算空间（如2D）转换为1D顺序，保持高维空间中邻近点在1D顺序中的接近性。使用广义希尔伯特曲线对矩阵乘法计算空间进行分区，获得平台无关和形状无关的矩阵乘法方案。进一步扩展SFC工作分区实现通信避免算法，复制输入张量并在关键路径上最小化通信/数据移动。

Result: 该方法在多个CPU平台上实现了最先进的结果，对于一系列GEMM形状，几何平均加速比达到厂商库的2倍。代码紧凑（约30行代码），通信避免算法的集成无缝。

Conclusion: 空间填充曲线提供了一种优雅的解决方案，避免了传统矩阵乘法优化中繁琐的平台和形状特定调优，通过固有的高数据局部性和通信避免算法，实现了高性能且平台无关的矩阵乘法实现。

Abstract: General Matrix Multiplication (GEMM) is the cornerstone of Deep Learning and HPC workloads; accordingly, academia and industry have heavily optimized this kernel. Modern platforms with matrix multiplication accelerators exhibit high FLOP/Byte machine balance, which makes implementing optimal matrix multiplication challenging. On modern CPU platforms with matrix engines, state-of-the-art vendor libraries tune input tensor layouts, parallelization schemes, and cache blocking to minimize data movement across the memory hierarchy and maximize throughput. However, the best settings for these parameters depend strongly on the target platform (number of cores, memory hierarchy, cache sizes) and on the shapes of the matrices, making exhaustive tuning infeasible; in practice this leads to performance "glass jaws". In this work we revisit space filling curves (SFC) to alleviate the problem of this cumbersome tuning. SFC convert multi-dimensional coordinates (e.g. 2D) into a single dimension (1D), keeping nearby points in the high-dimensional space close in the 1D order. We partition the Matrix Multiplication computation space using recent advancements in generalized SFC (Generalized Hilbert Curves), and we obtain platform-oblivious and shape-oblivious matrix-multiplication schemes that exhibit inherently high degree of data locality. Furthermore, we extend the SFC-based work partitioning to implement Communication-Avoiding (CA) algorithms that replicate the input tensors and provably minimize communication/data-movement on the critical path. The integration of CA-algorithms is seamless and yields compact code (~30 LOC), yet it achieves state-of-the-art results on multiple CPU platforms, outperforming vendor libraries by up to 2x(geometric-mean speedup) for a range of GEMM shapes.

</details>


### [21] [Consensus In Asynchrony](https://arxiv.org/abs/2601.16460)
*Ivan Klianev*

Main category: cs.DC

TL;DR: 该论文证明了事件同步对于解决异步确定性容错共识是充分的，提出了一个算法在满足安全、活性和容错一个崩溃的条件下实现向量一致性，并重新审视了FLP不可能性定理的隐含假设。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探索在异步系统中实现确定性容错共识的可能性，挑战FLP不可能性定理的传统理解，寻找在异步环境下实现共识的新途径。

Method: 提出基于事件同步的算法，实现向量一致性协议，区分数据无关和数据相关两种一致性类型，分析FLP定理的三个隐含假设。

Result: 算法在异步环境中实现了确定性容错共识，能容忍一个崩溃故障，实验结果表明FLP定理的第三个隐含假设缺乏证据支持。

Conclusion: 事件同步足以实现异步确定性容错共识，FLP不可能性定理依赖于特定隐含假设，其中第三个假设缺乏实证支持，为异步共识提供了新的理论框架。

Abstract: We demonstrate sufficiency of events-based synchronisation for solving deterministic fault-tolerant consensus in asynchrony. Main result is an algorithm that terminates with valid vector agreement, hence operates with safety, liveness, and tolerance to one crash. Reconciling with the FLP impossibility result, we identified: i) existence of two types of agreements: data-independent and data-dependent; and ii) dependence of FLP theorem correctness on three implicit assumptions. Consensus impossibility with data-dependent agreement is contingent on two of them. The theorem-stated impossibility with every agreement type hinges entirely on the third. We provide experimental results showing that the third assumption has no evidence in support.

</details>


### [22] [W4A16 Mixed-Precision Matrix Multiplication on Decoupled Architecture: Kernel Design and Memory Bottleneck Analysis for Ascend NPUs](https://arxiv.org/abs/2601.16536)
*Yuanhong He,Peiyu Niu,Jun Chen,Chenchen Zhang,Chao Yang*

Main category: cs.DC

TL;DR: 本文提出了首个针对华为昇腾910 NPU的W4A16矩阵乘法内核，通过向量核心进行INT4到FP16的即时反量化，立方核心进行GEMM计算，以及Split-K并行化来优化内存延迟，在LLM解码场景下实现1.01-1.74倍加速。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型规模扩大，仅权重量化(W4A16)对减少内存占用至关重要，但在华为昇腾910 NPU上高效部署面临挑战，因为该加速器缺乏原生混合精度支持且采用解耦计算架构。

Method: 设计针对昇腾910 NPU的W4A16矩阵乘法内核，利用向量核心进行INT4到FP16的即时反量化，立方核心进行高吞吐GEMM计算，采用Split-K并行化策略缓解内存延迟。

Result: 在不同矩阵形状和批量大小下评估，当K >> N（LLM解码典型场景）时，方法优于数据并行方法，实现1.01-1.74倍加速。分析显示主要瓶颈不是反量化计算本身，而是权重的额外全局内存传输，W4A16相比原生FP16最大加速1.48倍。

Conclusion: 该方法为在各种领域特定加速器上高效部署量化大语言模型奠定了坚实基础，并提供了有价值的见解。

Abstract: As Large Language Models (LLMs) scale, weight-only quantization (W4A16: 4-bit weights, 16-bit activations) becomes critical for reducing memory footprint with minimal accuracy loss. However, its efficient deployment on Huawei's Ascend 910 Neural Processing Unit (NPU) is challenging due to limited native mixed-precision support and the accelerator's decoupled compute architecture. To enable quantization on such architecture, we present the first practical W4A16 matrix multiplication kernel tailored for the Ascend 910 NPU. Our design leverages vector cores for on-the-fly INT4-to-FP16 dequantization, cube cores for high-throughput GEMM, and Split-K parallelization to mitigate memory latency. Performance evaluations across diverse matrix shapes and batch sizes show our method outperforms data-parallel approaches when K >> N, a typical scenario in LLM decoding. Specially, our method can achieve a speedup ranging from 1.01x to 1.74x. In addition, our profile reveals the primary bottleneck is not dequantization compution itself, but extra global memory transfer for the weight, making W4A16 only reaching a maximum speedup of 1.48x over native FP16xFP16 matrix multiplication in PyTorch. In the long run, our method lays a solid foundation and provides insightful views for the efficient deployment of quantized large language models on various domain-specific accelerators.

</details>


### [23] [Artifact for Service-Level Energy Modeling and Experimentation for Cloud-Native Microservices](https://arxiv.org/abs/2601.16635)
*Julian Legler*

Main category: cs.DC

TL;DR: GOXN是一个用于Kubernetes微服务的能耗实验引擎，能够在服务级别量化计算、网络和存储能耗，避免分布式环境中能耗低估问题。


<details>
  <summary>Details</summary>
Motivation: 虽然云原生环境已能进行细粒度能耗测量（如容器或进程级别），但微服务应用的服务级别能耗测量仍未被充分探索。现有测量往往忽略网络和存储能耗，导致分布式设置中能耗被低估。

Method: 开发GOXN（Green Observability eXperiment eNginE）引擎，用于Kubernetes微服务环境。通过Kepler和cAdvisor收集指标，使用加性能耗模型从容器级数据推导服务级能耗。在OpenTelemetry Demo上测试不同配置（监控、追踪、服务网格）和稳态合成负载。

Result: 结果显示：1）排除网络和存储能耗会导致辅助服务能耗被低估高达63%；2）高追踪负载会使能耗主导从计算转向网络和存储。

Conclusion: 微服务能耗测量必须包含计算、网络和存储三个维度才能获得准确结果。GOXN引擎为服务级别能耗分析提供了有效工具，揭示了分布式系统中能耗分布的重要特征。

Abstract: Recent advancements enable fine-grained energy measurements in cloud-native environments (e.g., at container or process level) beyond traditional coarse-grained scopes. However, service-level energy measurement for microservice-based applications remains underexplored. Such measurements must include compute, network, and storage energy to avoid underestimating consumption in distributed setups. We present GOXN (Green Observability eXperiment eNginE), an energy experimentation engine for Kubernetes-based microservices that quantifies compute, network, and storage energy at the service level. Using GOXN, we evaluated the OpenTelemetry Demo under varying configurations (monitoring, tracing, service mesh) and steady synthetic load, collecting metrics from Kepler and cAdvisor. Our additive energy model derives service-level energy from container-level data. Results show that excluding network and storage can underestimate auxiliary-service energy by up to 63%, and that high tracing loads shift energy dominance toward network and storage.

</details>


### [24] [GPU-Accelerated Selected Basis Diagonalization with Thrust for SQD-based Algorithms](https://arxiv.org/abs/2601.16637)
*Jun Doi,Tomonori Shirakawa,Yukio Kawashima,Seiji Yunoki,Hiroshi Horii*

Main category: cs.DC

TL;DR: GPU加速的Selected Basis Diagonalization实现，使用Thrust库实现40倍加速，提升量子-经典工作流性能


<details>
  <summary>Details</summary>
Motivation: SBD在基于采样的量子对角化(SQD)中起核心作用，其迭代对角化过程是主要经典计算负载，需要GPU加速来提升性能

Method: 使用Thrust库实现GPU加速的SBD，重构配置处理、激发生成和矩阵向量操作等关键组件，采用细粒度数据并行原语和扁平化GPU友好数据布局

Result: Thrust-based SBD相比CPU执行实现高达40倍加速，显著减少SQD迭代的总运行时间

Conclusion: GPU原生并行原语为加速SQD量子-经典工作流提供了简单、可移植且高性能的基础

Abstract: Selected Basis Diagonalization (SBD) plays a central role in Sample-based Quantum Diagonalization (SQD), where iterative diagonalization of the Hamiltonian in selected configuration subspaces forms the dominant classical workload. We present a GPU-accelerated implementation of SBD using the Thrust library. By restructuring key components -- including configuration processing, excitation generation, and matrix-vector operations -- around fine-grained data-parallel primitives and flattened GPU-friendly data layouts, the proposed approach efficiently exploits modern GPU architectures. In our experiments, the Thrust-based SBD achieves up to $\sim$40$\times$ speedup over CPU execution and substantially reduces the total runtime of SQD iterations. These results demonstrate that GPU-native parallel primitives provide a simple, portable, and high-performance foundation for accelerating SQD-based quantum-classical workflows.

</details>


### [25] [DataStates-LLM: Scalable Checkpointing for Transformer Models Using Composable State Providers](https://arxiv.org/abs/2601.16956)
*Avinash Maurya,M. Mustafa Rafique,Franck Cappello,Bogdan Nicolae*

Main category: cs.DC

TL;DR: DataStates-LLM：针对大规模Transformer模型训练的新型检查点架构，通过状态提供者解耦状态抽象与数据移动，利用参数不变性实现异步懒快照，显著提升检查点吞吐量并减少训练时间。


<details>
  <summary>Details</summary>
Motivation: 随着LLM参数规模达到万亿级别，需要在数千GPU上使用复杂混合并行策略进行训练。现有检查点方案将模型状态视为不透明的二进制数据块，忽略了数据结构的"3D异质性"（内存位置、分片数量、数据类型、序列化需求），导致运行时开销大、设备到主机传输阻塞、数据无关序列化和存储I/O争用等问题。

Method: 提出DataStates-LLM架构，引入状态提供者（State Providers）解耦状态抽象与数据移动。利用前向和反向传播期间模型参数的不变性，执行"懒"非阻塞异步快照。通过状态提供者高效合并碎片化的异构分片，并将元数据序列化与批量张量I/O重叠执行。

Result: 在256个A100-40GB GPU上对高达700亿参数的模型进行评估。结果显示，DataStates-LLM相比最先进解决方案实现了高达4倍的检查点吞吐量提升，并将端到端训练时间减少了高达2.2倍，有效缓解了极端规模LLM训练中的序列化和异质性瓶颈。

Conclusion: DataStates-LLM通过创新的状态提供者架构和异步懒快照机制，解决了大规模分布式LLM训练中检查点的关键性能瓶颈，显著提升了训练效率和系统可靠性。

Abstract: The rapid growth of Large Transformer-based models, specifically Large Language Models (LLMs), now scaling to trillions of parameters, has necessitated training across thousands of GPUs using complex hybrid parallelism strategies (e.g., data, tensor, and pipeline parallelism). Checkpointing this massive, distributed state is critical for a wide range of use cases, such as resilience, suspend-resume, investigating undesirable training trajectories, and explaining model evolution. However, existing checkpointing solutions typically treat model state as opaque binary blobs, ignoring the ``3D heterogeneity'' of the underlying data structures--varying by memory location (GPU vs. Host), number of ``logical'' objects sharded and split across multiple files, data types (tensors vs. Python objects), and their serialization requirements. This results in significant runtime overheads due to blocking device-to-host transfers, data-oblivious serialization, and storage I/O contention. In this paper, we introduce DataStates-LLM, a novel checkpointing architecture that leverages State Providers to decouple state abstraction from data movement. DataStates-LLM exploits the immutability of model parameters during the forward and backward passes to perform ``lazy'', non-blocking asynchronous snapshots. By introducing State Providers, we efficiently coalesce fragmented, heterogeneous shards and overlap the serialization of metadata with bulk tensor I/O. We evaluate DataStates-LLM on models up to 70B parameters on 256 A100-40GB GPUs. Our results demonstrate that DataStates-LLM achieves up to 4$\times$ higher checkpointing throughput and reduces end-to-end training time by up to 2.2$\times$ compared to state-of-the-art solutions, effectively mitigating the serialization and heterogeneity bottlenecks in extreme-scale LLM training.

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [26] [Gen-DBA: Generative Database Agents (Towards a Move 37 for Databases)](https://arxiv.org/abs/2601.16409)
*Yeasir Rayhan,Walid G. Aref*

Main category: cs.DB

TL;DR: 该论文探讨了AI4DB（数据库系统人工智能）研究的现状，提出了构建生成式数据库代理（Gen-DBA）作为实现数据库系统"Move 37"突破的路径。


<details>
  <summary>Details</summary>
Motivation: 受AlphaGo的"Move 37"突破启发，作者认为数据库系统研究需要类似的创新突破。当前NLP、CV、机器人领域已通过大模型取得显著进展，但数据库系统的AI研究尚未达到类似里程碑。

Method: 提出构建生成式数据库代理（Gen-DBA）的框架，包括Transformer骨干网络、硬件基础的分词机制、两阶段目标导向的下一个令牌预测训练范式，以及生成式推理过程。

Result: 提出了实现数据库系统"Move 37"时刻的愿景和具体技术路线，将生成式推理和创造性引入数据库学习任务。

Conclusion: Gen-DBA是实现数据库系统AI突破的关键路径，能够为数据库系统带来生成式推理和创造性能力，推动AI4DB领域向前发展。

Abstract: Move\,37 marks one of the major breakthroughs in AI in terms of its ability to surpass human expertise and discover novel strategies beyond the traditional game play in the strategic two-player board game of Go. The domains of Natural Language Processing, Computer Vision, and Robotics have also undergone a similar phenomenon through the advent of large foundational models in the form of Large Language Models (LLMs), Vision Language Models (VLMs) and Vision Language Action models (VLAs), respectively. In this paper, we investigate the current state of Artificial Intelligence for Database Systems research (AI4DB), and assess how far AI4DB systems are from achieving their own Move\,37 moment. We envision a Generative Database Agent (Gen-DBA, for short) as the pathway to achieving Move\,37 for database systems that will bring generative reasoning and creativity into the realm of database learning tasks. This vision paper explores this direction by presenting the recipe for building Gen-DBA that encompasses but is not limited to a Transformer backbone, a hardware-grounded tokenization mechanism, a two-stage Goal-Directed Next Token Prediction training paradigm, and a generative inference process.

</details>


### [27] [iPDB -- Optimizing SQL Queries with ML and LLM Predicates](https://arxiv.org/abs/2601.16432)
*Udesh Kumarasinghe,Tyler Liu,Chunwei Liu,Walid G. Aref*

Main category: cs.DB

TL;DR: iPDB是一个支持在数据库内进行机器学习和LLM推理的关系系统，通过扩展SQL语法实现语义查询，避免数据迁移的复杂工程


<details>
  <summary>Details</summary>
Motivation: 传统SQL和关系数据库系统在处理需要利用学习模型的工作负载时存在不兼容或效率低下的问题，导致复杂的工程和数据迁移操作

Method: 开发iPDB关系系统，支持在数据库内进行ML和LLM推理，使用扩展SQL语法，引入新的关系预测算子和语义查询优化

Result: iPDB能够高效执行语义SQL查询，性能优于现有技术，LLM和ML调用可以作为语义投影、谓词执行语义选择和连接，或用于语义分组

Conclusion: iPDB通过支持在数据库内进行ML和LLM推理，解决了传统SQL在处理学习模型工作负载时的局限性，简化了应用开发

Abstract: Structured Query Language (SQL) has remained the standard query language for databases. SQL is highly optimized for processing structured data laid out in relations. Meanwhile, in the present application development landscape, it is highly desirable to utilize the power of learned models to perform complex tasks. Large language models (LLMs) have been shown to understand and extract information from unstructured textual data. However, SQL as a query language and accompanying relational database systems are either incompatible or inefficient for workloads that require leveraging learned models. This results in complex engineering and multiple data migration operations that move data between the data sources and the model inference platform. In this paper, we present iPDB, a relational system that supports in-database machine learning (ML) and large language model (LLM) inferencing using extended SQL syntax. In iPDB, LLMs and ML calls can function as semantic projects, as predicates to perform semantic selects and semantic joins, or for semantic grouping in group-by clauses. iPDB has a novel relational predict operator and semantic query optimizations that enable users to write and efficiently execute semantic SQL queries, outperforming the state-of-the-art.

</details>


### [28] [A Scalable Transaction Management Framework for Consistent Document-Oriented NoSQL Databases](https://arxiv.org/abs/2601.16490)
*Adam A. E. Alflahi,Mohammed A. Y. Mohammed,Abdallah Alsammani*

Main category: cs.DB

TL;DR: 提出一个四阶段事务管理框架，用于文档型NoSQL数据库，结合事务生命周期管理、操作分类、冲突检测和自适应锁策略，在保证冲突可串行化的同时提升性能。


<details>
  <summary>Details</summary>
Motivation: NoSQL数据库虽然具有可扩展性和模式灵活性，但通常依赖最终一致性模型，限制了可靠的事务处理能力。需要一种既能保证数据完整性又不损害可扩展性的事务管理方案。

Method: 提出四阶段事务管理框架：1) 事务生命周期管理；2) 操作分类；3) 预执行冲突检测；4) 自适应锁策略（含超时死锁预防）。以MongoDB为参考平台，进行形式化正确性分析。

Result: 实验使用YCSB工作负载A、B、F，在1-100客户端并发下：事务中止率从8.3%降至4.7%；消除死锁；延迟方差降低34.2%；高并发下吞吐量提升6.3%-18.4%。分布式9节点集群吞吐量提高15.2%，中止率降低53%。

Conclusion: 精心设计的一致性机制可以显著提升NoSQL系统的数据完整性而不损害可扩展性。该框架在一致性保证和性能开销之间取得了良好平衡，最佳参数包括100ms锁超时、10ms初始退避和500ms最大退避。

Abstract: NoSQL databases are widely used in modern applications due to their scalability and schema flexibility, yet they often rely on eventual consistency models that limit reliable transaction processing. This study proposes a four-stage transaction management framework for document-oriented NoSQL databases, with MongoDB as the reference platform. The framework combines transaction lifecycle management, operation classification, pre-execution conflict detection, and an adaptive locking strategy with timeout-based deadlock prevention. Formal correctness analysis shows that the proposed approach guarantees conflict serializability under defined conditions. An experimental evaluation using the Yahoo Cloud Serving Benchmark (YCSB) workloads A, B, and F, with concurrency levels ranging from 1 to 100 clients, demonstrates a reduction in transaction abort rates from 8.3% to 4.7%, the elimination of observed deadlocks, and a 34.2% decrease in latency variance. Throughput improvements ranging from 6.3% to 18.4% are observed under high concurrency, particularly for read-modify-write workloads. Distributed experiments on clusters of up to 9 nodes confirm scalability, achieving 15.2% higher throughput and 53% lower abort rates than baseline systems. Comparisons with MongoDB's native transactions, CockroachDB, and TiDB indicate that the proposed framework strikes a good balance between consistency guarantees and performance overhead. Sensitivity analysis identifies optimal parameter settings, including a lock timeout of 100 ms, an initial backoff of 10 ms, and a maximum backoff of 500 ms. These results show that carefully designed consistency mechanisms can significantly improve data integrity in NoSQL systems without undermining scalability.

</details>


### [29] [A Categorical Approach to Semantic Interoperability across Building Lifecycle](https://arxiv.org/abs/2601.16663)
*Zoltan Nagy,Ryan Wisnesky,Kevin Carlson,Eswaran Subrahmanian,Gioele Zardini*

Main category: cs.DB

TL;DR: 该论文提出使用范畴论作为建筑数据集成的基础数学框架，解决现有40多种元数据模式碎片化问题，将复杂度从O(n²)降低到O(n)，并通过CQL实现原型验证。


<details>
  <summary>Details</summary>
Motivation: 建筑生命周期产生异构数据，但数据集成仍是未解决的挑战。尽管有30年标准化努力，但出现了40多种元数据模式，碎片化加剧而非解决。现有方法要么需要点对点映射（复杂度O(n²)），要么创建笨重的通用本体，缺乏跨异构建筑数据的结构保持转换的数学基础。

Method: 使用范畴论作为数学基础，将建筑本体形式化为一级理论。在范畴查询语言(CQL)中实现两个概念验证：1)从IFC设计数据生成BRICK模型；2)IFC、BRICK和RealEstateCore的三向集成，仅需两个显式映射即可通过范畴组合自动获得第三个映射。

Result: 成功展示了范畴方法在建筑数据集成中的可行性，实现了O(n)规范复杂度（而非O(n²)），支持正确构造的属性集作为一级模式实体，提供自动双向迁移，并支持跨本体查询。

Conclusion: 范畴论为建筑数据集成提供了必要的数学基础，使系统化数据集成成为可能。该方法为建筑应用生态系统铺平了道路，类似于智能手机平台，数学基础可实现可靠的组件集成。

Abstract: Buildings generate heterogeneous data across their lifecycle, yet integrating these data remains a critical unsolved challenge. Despite three decades of standardization efforts, over 40 metadata schemas now span the building lifecycle, with fragmentation accelerating rather than resolving. Current approaches rely on point-to-point mappings that scale quadratically with the number of schemas, or universal ontologies that become unwieldy monoliths. The fundamental gap is the absence of mathematical foundations for structure-preserving transformations across heterogeneous building data. Here we show that category theory provides these foundations, enabling systematic data integration with $O(n)$ specification complexity for $n$ ontologies. We formalize building ontologies as first-order theories and demonstrate two proof-of-concept implementations in Categorical Query Language (CQL): 1) generating BRICK models from IFC design data at commissioning, and 2) three-way integration of IFC, BRICK, and RealEstateCore where only two explicit mappings yield the third automatically through categorical composition. Our correct-by-construction approach treats property sets as first-class schema entities and provides automated bidirectional migrations, and enables cross-ontology queries. These results establish feasibility of categorical methods for building data integration and suggest a path toward an app ecosystem for buildings, where mathematical foundations enable reliable component integration analogous to smartphone platforms.

</details>
