{"id": "2601.14737", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2601.14737", "abs": "https://arxiv.org/abs/2601.14737", "authors": ["Dildar Ali", "Suman Banerjee", "Rajibul Islam"], "title": "Trajectory-Driven Multi-Product Influence Maximization in Billboard Advertising", "comment": "31 Pages. arXiv admin note: text overlap with arXiv:2510.09050", "summary": "Billboard Advertising has emerged as an effective out-of-home advertising technique, where the goal is to select a limited number of slots and play advertisement content there, with the hope that it will be observed by many people and, effectively, a significant number of them will be influenced towards the brand. Given a trajectory and a billboard database and a positive integer $k$, how can we select $k$ highly influential slots to maximize influence? In this paper, we study a variant of this problem where a commercial house wants to make a promotion of multiple products, and there is an influence demand for each product. We have studied two variants of the problem. In the first variant, our goal is to select $k$ slots such that the respective influence demand of each product is satisfied. In the other variant of the problem, we are given with $\\ell$ integers $k_1,k_2, \\ldots, k_{\\ell}$, the goal here is to search for $\\ell$ many set of slots $S_1, S_2, \\ldots, S_{\\ell}$ such that for all $i \\in [\\ell]$, $|S_{i}| \\leq k_i$ and for all $i \\neq j$, $S_i \\cap S_j=\\emptyset$ and the influence demand of each of the products gets satisfied. We model the first variant of the problem as a multi-submodular cover problem and the second variant as its generalization. To solve the common-slot variant, we formulate the problem as a multi-submodular cover problem and design a bi-criteria approximation algorithm based on the continuous greedy framework and randomized rounding. For the disjoint-slot variant, we proposed a sampling-based approximation approach along with an efficient primal-dual greedy algorithm that enforces disjointness naturally. Extensive experiments with real-world trajectory and billboard datasets highlight the effectiveness and efficiency of the proposed solution approaches.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u591a\u4ea7\u54c1\u5e7f\u544a\u724c\u6295\u653e\u95ee\u9898\uff0c\u63d0\u51fa\u4e24\u79cd\u53d8\u4f53\uff1a\u5171\u540c\u69fd\u4f4d\u9009\u62e9\u548c\u4e92\u65a5\u69fd\u4f4d\u9009\u62e9\uff0c\u5206\u522b\u5efa\u6a21\u4e3a\u591a\u5b50\u6a21\u8986\u76d6\u95ee\u9898\u53ca\u5176\u63a8\u5e7f\uff0c\u5e76\u8bbe\u8ba1\u76f8\u5e94\u7684\u8fd1\u4f3c\u7b97\u6cd5\u3002", "motivation": "\u4f20\u7edf\u5e7f\u544a\u724c\u5e7f\u544a\u5173\u6ce8\u5355\u4e2a\u4ea7\u54c1\u7684\u5f71\u54cd\u529b\u6700\u5927\u5316\uff0c\u4f46\u5546\u4e1a\u516c\u53f8\u901a\u5e38\u9700\u8981\u540c\u65f6\u63a8\u5e7f\u591a\u4e2a\u4ea7\u54c1\uff0c\u6bcf\u4e2a\u4ea7\u54c1\u6709\u7279\u5b9a\u7684\u5f71\u54cd\u529b\u9700\u6c42\u3002\u73b0\u6709\u7814\u7a76\u7f3a\u4e4f\u8003\u8651\u591a\u4ea7\u54c1\u63a8\u5e7f\u573a\u666f\u4e0b\u7684\u5e7f\u544a\u724c\u9009\u62e9\u95ee\u9898\u3002", "method": "1. \u5171\u540c\u69fd\u4f4d\u53d8\u4f53\uff1a\u5efa\u6a21\u4e3a\u591a\u5b50\u6a21\u8986\u76d6\u95ee\u9898\uff0c\u8bbe\u8ba1\u57fa\u4e8e\u8fde\u7eed\u8d2a\u5fc3\u6846\u67b6\u548c\u968f\u673a\u820d\u5165\u7684\u53cc\u51c6\u5219\u8fd1\u4f3c\u7b97\u6cd5\n2. \u4e92\u65a5\u69fd\u4f4d\u53d8\u4f53\uff1a\u5efa\u6a21\u4e3a\u591a\u5b50\u6a21\u8986\u76d6\u95ee\u9898\u7684\u63a8\u5e7f\uff0c\u63d0\u51fa\u57fa\u4e8e\u91c7\u6837\u7684\u8fd1\u4f3c\u65b9\u6cd5\u548c\u9ad8\u6548\u7684\u539f\u5bf9\u5076\u8d2a\u5fc3\u7b97\u6cd5\uff0c\u786e\u4fdd\u69fd\u4f4d\u4e92\u65a5\u6027", "result": "\u5728\u771f\u5b9e\u8f68\u8ff9\u548c\u5e7f\u544a\u724c\u6570\u636e\u96c6\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u89e3\u51b3\u65b9\u6848\u5728\u6548\u679c\u548c\u6548\u7387\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u80fd\u591f\u6709\u6548\u6ee1\u8db3\u591a\u4ea7\u54c1\u63a8\u5e7f\u7684\u9700\u6c42\u3002", "conclusion": "\u8be5\u7814\u7a76\u586b\u8865\u4e86\u591a\u4ea7\u54c1\u5e7f\u544a\u724c\u6295\u653e\u95ee\u9898\u7684\u7a7a\u767d\uff0c\u63d0\u51fa\u7684\u7b97\u6cd5\u6846\u67b6\u80fd\u591f\u6709\u6548\u89e3\u51b3\u5171\u540c\u69fd\u4f4d\u548c\u4e92\u65a5\u69fd\u4f4d\u4e24\u79cd\u53d8\u4f53\uff0c\u4e3a\u5b9e\u9645\u5e7f\u544a\u6295\u653e\u63d0\u4f9b\u4e86\u7406\u8bba\u652f\u6301\u548c\u5b9e\u7528\u5de5\u5177\u3002"}}
{"id": "2601.14434", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.14434", "abs": "https://arxiv.org/abs/2601.14434", "authors": ["Chia-Yi Su", "Collin McMillan"], "title": "CMind: An AI Agent for Localizing C Memory Bugs", "comment": "4 pages, 2 figures. To be published in 34th IEEE/ACM International Conference on Program Comprehension (ICPC 2026)", "summary": "This demonstration paper presents CMind, an artificial intelligence agent for localizing C memory bugs. The novel aspect to CMind is that it follows steps that we observed human programmers perform during empirical study of those programmers finding memory bugs in C programs. The input to the tool is a C program's source code and a bug report describing the problem. The output is the tool's hypothesis about the reason for the bug and its location. CMind reads the bug report to find potential entry points to the program, then navigates the program's source code, analyzes that source code, and generates a hypothesis location and rationale that fit a template. The tool combines large language model reasoning with guided decision making we encoded to mimic human behavior. The video demonstration is available at https://youtu.be/_vVd0LRvVHI.", "AI": {"tldr": "CMind\u662f\u4e00\u4e2a\u57fa\u4e8e\u4eba\u7c7b\u7a0b\u5e8f\u5458\u884c\u4e3a\u6a21\u5f0f\u7684AI\u4ee3\u7406\uff0c\u7528\u4e8e\u5b9a\u4f4dC\u8bed\u8a00\u5185\u5b58\u9519\u8bef\uff0c\u7ed3\u5408LLM\u63a8\u7406\u548c\u7f16\u7801\u7684\u51b3\u7b56\u6307\u5bfc\u6765\u6a21\u62df\u4eba\u7c7b\u8c03\u8bd5\u8fc7\u7a0b\u3002", "motivation": "\u73b0\u6709\u5de5\u5177\u5728\u5b9a\u4f4dC\u5185\u5b58\u9519\u8bef\u65f6\u5f80\u5f80\u7f3a\u4e4f\u4eba\u7c7b\u7a0b\u5e8f\u5458\u7684\u7cfb\u7edf\u6027\u601d\u7ef4\u8fc7\u7a0b\u3002\u901a\u8fc7\u5b9e\u8bc1\u7814\u7a76\u89c2\u5bdf\u4eba\u7c7b\u7a0b\u5e8f\u5458\u5982\u4f55\u67e5\u627e\u5185\u5b58\u9519\u8bef\uff0c\u4f5c\u8005\u5e0c\u671b\u6784\u5efa\u4e00\u4e2a\u80fd\u6a21\u62df\u8fd9\u79cd\u4eba\u7c7b\u884c\u4e3a\u7684AI\u4ee3\u7406\uff0c\u63d0\u9ad8\u5185\u5b58\u9519\u8bef\u5b9a\u4f4d\u7684\u6548\u7387\u548c\u51c6\u786e\u6027\u3002", "method": "CMind\u901a\u8fc7\u8bfb\u53d6bug\u62a5\u544a\u627e\u5230\u7a0b\u5e8f\u5165\u53e3\u70b9\uff0c\u7136\u540e\u5bfc\u822a\u6e90\u4ee3\u7801\u8fdb\u884c\u5206\u6790\uff0c\u751f\u6210\u7b26\u5408\u6a21\u677f\u7684\u5047\u8bbe\u4f4d\u7f6e\u548c\u7406\u7531\u3002\u5de5\u5177\u7ed3\u5408\u5927\u578b\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u4e0e\u7f16\u7801\u7684\u51b3\u7b56\u6307\u5bfc\uff0c\u6a21\u62df\u4eba\u7c7b\u7a0b\u5e8f\u5458\u5728\u67e5\u627e\u5185\u5b58\u9519\u8bef\u65f6\u7684\u884c\u4e3a\u6a21\u5f0f\u3002", "result": "CMind\u80fd\u591f\u63a5\u6536C\u7a0b\u5e8f\u6e90\u4ee3\u7801\u548cbug\u62a5\u544a\u4f5c\u4e3a\u8f93\u5165\uff0c\u8f93\u51fa\u5173\u4e8ebug\u539f\u56e0\u548c\u4f4d\u7f6e\u7684\u5047\u8bbe\u3002\u5de5\u5177\u5c55\u793a\u4e86\u7ed3\u5408LLM\u63a8\u7406\u4e0e\u4eba\u7c7b\u884c\u4e3a\u6a21\u62df\u7684\u65b9\u6cd5\u5728\u5185\u5b58\u9519\u8bef\u5b9a\u4f4d\u4efb\u52a1\u4e0a\u7684\u53ef\u884c\u6027\u3002", "conclusion": "\u901a\u8fc7\u6a21\u62df\u4eba\u7c7b\u7a0b\u5e8f\u5458\u67e5\u627e\u5185\u5b58\u9519\u8bef\u7684\u884c\u4e3a\u6a21\u5f0f\uff0cCMind\u5c55\u793a\u4e86AI\u4ee3\u7406\u5728\u8f6f\u4ef6\u8c03\u8bd5\u4efb\u52a1\u4e2d\u7684\u6f5c\u529b\uff0c\u4e3a\u7ed3\u5408\u4eba\u7c7b\u4e13\u4e1a\u77e5\u8bc6\u4e0eAI\u63a8\u7406\u7684\u8c03\u8bd5\u5de5\u5177\u5f00\u53d1\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2601.14466", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2601.14466", "abs": "https://arxiv.org/abs/2601.14466", "authors": ["Roeland Wiersema"], "title": "JAXMg: A multi-GPU linear solver in JAX", "comment": null, "summary": "Solving large dense linear systems and eigenvalue problems is a core requirement in many areas of scientific computing, but scaling these operations beyond a single GPU remains challenging within modern programming frameworks. While highly optimized multi-GPU solver libraries exist, they are typically difficult to integrate into composable, just-in-time (JIT) compiled Python workflows. JAXMg provides multi-GPU dense linear algebra for JAX, enabling Cholesky-based linear solves and symmetric eigendecompositions for matrices that exceed single-GPU memory limits. By interfacing JAX with NVIDIA's cuSOLVERMg through an XLA Foreign Function Interface, JAXMg exposes distributed GPU solvers as JIT-compatible JAX primitives. This design allows scalable linear algebra to be embedded directly within JAX programs, preserving composability with JAX transformations and enabling multi-GPU execution in end-to-end scientific workflows.", "AI": {"tldr": "JAXMg\u4e3aJAX\u63d0\u4f9b\u591aGPU\u7a20\u5bc6\u7ebf\u6027\u4ee3\u6570\u529f\u80fd\uff0c\u901a\u8fc7\u96c6\u6210NVIDIA cuSOLVERMg\u5b9e\u73b0\u8de8GPU\u5185\u5b58\u9650\u5236\u7684Cholesky\u7ebf\u6027\u6c42\u89e3\u548c\u5bf9\u79f0\u7279\u5f81\u5206\u89e3\u3002", "motivation": "\u73b0\u4ee3\u79d1\u5b66\u8ba1\u7b97\u4e2d\u9700\u8981\u5904\u7406\u5927\u89c4\u6a21\u7a20\u5bc6\u7ebf\u6027\u7cfb\u7edf\u548c\u7279\u5f81\u503c\u95ee\u9898\uff0c\u4f46\u73b0\u6709\u7f16\u7a0b\u6846\u67b6\u96be\u4ee5\u5728\u5355GPU\u4e4b\u5916\u6269\u5c55\u3002\u867d\u7136\u6709\u591aGPU\u6c42\u89e3\u5668\u5e93\uff0c\u4f46\u96be\u4ee5\u96c6\u6210\u5230\u53ef\u7ec4\u5408\u7684JIT\u7f16\u8bd1Python\u5de5\u4f5c\u6d41\u4e2d\u3002", "method": "\u901a\u8fc7XLA\u5916\u90e8\u51fd\u6570\u63a5\u53e3\u5c06JAX\u4e0eNVIDIA cuSOLVERMg\u8fde\u63a5\uff0c\u5c06\u5206\u5e03\u5f0fGPU\u6c42\u89e3\u5668\u66b4\u9732\u4e3aJIT\u517c\u5bb9\u7684JAX\u539f\u8bed\uff0c\u4f7f\u53ef\u6269\u5c55\u7ebf\u6027\u4ee3\u6570\u80fd\u76f4\u63a5\u5d4c\u5165JAX\u7a0b\u5e8f\u4e2d\u3002", "result": "\u5b9e\u73b0\u4e86\u591aGPU\u7a20\u5bc6\u7ebf\u6027\u4ee3\u6570\u529f\u80fd\uff0c\u652f\u6301\u8d85\u8fc7\u5355GPU\u5185\u5b58\u9650\u5236\u7684\u77e9\u9635\u7684Cholesky\u7ebf\u6027\u6c42\u89e3\u548c\u5bf9\u79f0\u7279\u5f81\u5206\u89e3\uff0c\u4fdd\u6301\u4e0eJAX\u53d8\u6362\u7684\u53ef\u7ec4\u5408\u6027\u3002", "conclusion": "JAXMg\u6210\u529f\u5c06\u5206\u5e03\u5f0fGPU\u6c42\u89e3\u5668\u96c6\u6210\u5230JAX\u751f\u6001\u7cfb\u7edf\u4e2d\uff0c\u4f7f\u53ef\u6269\u5c55\u7ebf\u6027\u4ee3\u6570\u80fd\u5728\u7aef\u5230\u7aef\u79d1\u5b66\u5de5\u4f5c\u6d41\u4e2d\u5b9e\u73b0\u591aGPU\u6267\u884c\uff0c\u89e3\u51b3\u4e86\u5927\u89c4\u6a21\u7a20\u5bc6\u7ebf\u6027\u4ee3\u6570\u5728JIT\u7f16\u8bd1\u5de5\u4f5c\u6d41\u4e2d\u7684\u6269\u5c55\u6311\u6218\u3002"}}
{"id": "2601.14455", "categories": ["cs.SE", "cs.CR"], "pdf": "https://arxiv.org/pdf/2601.14455", "abs": "https://arxiv.org/abs/2601.14455", "authors": ["Madjda Fares", "Yogya Gamage", "Benoit Baudry"], "title": "Unpacking Security Scanners for GitHub Actions Workflows", "comment": "20 pages, 3 figures, 5 tables, First version", "summary": "GitHub Actions is a widely used platform that allows developers to automate the build and deployment of their projects through configurable workflows. As the platform's popularity continues to grow, it has become a target of choice for recent software supply chain attacks. These attacks exploit excessive permissions, ambiguous versions, or the absence of artifact integrity checks to compromise workflows. In response to these attacks, several security scanners have emerged to help developers harden their workflows.\n  In this paper, we perform the first systematic comparison of 9 GitHub Actions workflow security scanners. We compare them in terms of scope (which security weaknesses they target), detection capabilities (how many weaknesses they detect), and usability (how long they take to scan a workflow). To compare scanners on a common ground, we first establish a taxonomy of 10 security weaknesses that can occur in GitHub Actions workflows. Then, we run the scanners against a curated set of 596 workflows.\n  Our study reveals that the landscape of GitHub Actions workflow security scanners is diverse, with both broad-scope tools and very focused ones. More importantly, we show that scanners interpret security weaknesses differently, leading to significant differences in the type and number of reported weaknesses. Based on this empirical evidence, we make actionable recommendations for developers to harden their GitHub Actions workflows.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u7cfb\u7edf\u6bd4\u8f83\u4e869\u6b3eGitHub Actions\u5de5\u4f5c\u6d41\u5b89\u5168\u626b\u63cf\u5668\uff0c\u5efa\u7acb\u4e8610\u7c7b\u5b89\u5168\u5f31\u70b9\u7684\u5206\u7c7b\u6cd5\uff0c\u5e76\u5728596\u4e2a\u5de5\u4f5c\u6d41\u4e0a\u6d4b\u8bd5\u4e86\u8fd9\u4e9b\u5de5\u5177\u7684\u8303\u56f4\u3001\u68c0\u6d4b\u80fd\u529b\u548c\u53ef\u7528\u6027\u3002", "motivation": "GitHub Actions\u4f5c\u4e3a\u5e7f\u6cdb\u4f7f\u7528\u7684\u81ea\u52a8\u5316\u5e73\u53f0\uff0c\u5df2\u6210\u4e3a\u8f6f\u4ef6\u4f9b\u5e94\u94fe\u653b\u51fb\u7684\u4e3b\u8981\u76ee\u6807\u3002\u653b\u51fb\u8005\u5229\u7528\u6743\u9650\u8fc7\u9ad8\u3001\u7248\u672c\u6a21\u7cca\u6216\u7f3a\u4e4f\u5b8c\u6574\u6027\u68c0\u67e5\u7b49\u5f31\u70b9\u6765\u7834\u574f\u5de5\u4f5c\u6d41\u3002\u867d\u7136\u51fa\u73b0\u4e86\u591a\u79cd\u5b89\u5168\u626b\u63cf\u5668\u6765\u5e2e\u52a9\u5f00\u53d1\u8005\u52a0\u56fa\u5de5\u4f5c\u6d41\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u8fd9\u4e9b\u5de5\u5177\u7684\u7cfb\u7edf\u6027\u6bd4\u8f83\u3002", "method": "1. \u5efa\u7acb\u5305\u542b10\u7c7b\u5b89\u5168\u5f31\u70b9\u7684GitHub Actions\u5de5\u4f5c\u6d41\u5b89\u5168\u5f31\u70b9\u5206\u7c7b\u6cd5\uff1b2. \u6536\u96c69\u6b3e\u5b89\u5168\u626b\u63cf\u5668\uff1b3. \u4f7f\u7528596\u4e2a\u7cbe\u9009\u7684\u5de5\u4f5c\u6d41\u4f5c\u4e3a\u6d4b\u8bd5\u96c6\uff1b4. \u4ece\u4e09\u4e2a\u7ef4\u5ea6\u6bd4\u8f83\u626b\u63cf\u5668\uff1a\u8303\u56f4\uff08\u9488\u5bf9\u54ea\u4e9b\u5b89\u5168\u5f31\u70b9\uff09\u3001\u68c0\u6d4b\u80fd\u529b\uff08\u68c0\u6d4b\u591a\u5c11\u5f31\u70b9\uff09\u3001\u53ef\u7528\u6027\uff08\u626b\u63cf\u65f6\u95f4\uff09\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff1a1. GitHub Actions\u5de5\u4f5c\u6d41\u5b89\u5168\u626b\u63cf\u5668\u751f\u6001\u591a\u6837\uff0c\u65e2\u6709\u8303\u56f4\u5e7f\u6cdb\u7684\u5de5\u5177\uff0c\u4e5f\u6709\u975e\u5e38\u4e13\u6ce8\u7684\u5de5\u5177\uff1b2. \u4e0d\u540c\u626b\u63cf\u5668\u5bf9\u5b89\u5168\u5f31\u70b9\u7684\u89e3\u91ca\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff0c\u5bfc\u81f4\u62a5\u544a\u5f31\u70b9\u7684\u7c7b\u578b\u548c\u6570\u91cf\u6709\u5f88\u5927\u4e0d\u540c\uff1b3. \u57fa\u4e8e\u5b9e\u8bc1\u8bc1\u636e\uff0c\u4e3a\u5f00\u53d1\u8005\u63d0\u4f9b\u4e86\u53ef\u64cd\u4f5c\u7684\u5efa\u8bae\u6765\u52a0\u56fa\u4ed6\u4eec\u7684GitHub Actions\u5de5\u4f5c\u6d41\u3002", "conclusion": "\u8fd9\u662f\u5bf9GitHub Actions\u5de5\u4f5c\u6d41\u5b89\u5168\u626b\u63cf\u5668\u7684\u9996\u6b21\u7cfb\u7edf\u6027\u6bd4\u8f83\u7814\u7a76\uff0c\u63ed\u793a\u4e86\u5f53\u524d\u5de5\u5177\u751f\u6001\u7684\u591a\u6837\u6027\u548c\u4e0d\u4e00\u81f4\u6027\u3002\u7814\u7a76\u7ed3\u679c\u4e3a\u5f00\u53d1\u8005\u9009\u62e9\u548c\u4f7f\u7528\u5b89\u5168\u626b\u63cf\u5668\u63d0\u4f9b\u4e86\u91cd\u8981\u53c2\u8003\uff0c\u5e76\u63d0\u51fa\u4e86\u52a0\u56fa\u5de5\u4f5c\u6d41\u7684\u5177\u4f53\u5efa\u8bae\u3002"}}
{"id": "2601.14608", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2601.14608", "abs": "https://arxiv.org/abs/2601.14608", "authors": ["Torben R. Lahnor", "Mia Reitz", "Jonas Posner", "Patrick Diehl"], "title": "Exploring Performance-Productivity Trade-offs in AMT Runtimes: A Task Bench Study of Itoyori, ItoyoriFBC, HPX, and MPI", "comment": null, "summary": "Asynchronous Many-Task (AMT) runtimes offer a productive alternative to the Message Passing Interface (MPI). However, the diverse AMT landscape makes fair comparisons challenging. Task Bench, proposed by Slaughter et al., addresses this challenge through a parameterized framework for evaluating parallel programming systems. This work integrates two recent cluster AMTs, Itoyori and ItoyoriFBC, into Task Bench for comprehensive evaluation against MPI and HPX. Itoyori employs a Partitioned Global Address Space (PGAS) model with RDMA-based work stealing, while ItoyoriFBC extends it with futurebased synchronization.\n  We evaluate these systems in terms of both performance and programmer productivity. Performance is assessed across various configurations, including compute-bound kernels, weak scaling, and both imbalanced and communication-intensive patterns. Performance is quantified using application efficiency, i.e., the percentage of maximum performance achieved, and the Minimum Effective Task Granularity (METG), i.e., the smallest task duration before runtime overheads dominate. Programmer productivity is quantified using Lines of Code (LOC) and the Number of Library Constructs (NLC).\n  Our results reveal distinct trade-offs. MPI achieves the highest efficiency for regular, communication-light workloads but requires verbose, lowlevel code. HPX maintains stable efficiency under load imbalance across varying node counts, yet ranks last in productivity metrics, demonstrating that AMTs do not inherently guarantee improved productivity over MPI. Itoyori achieves the highest efficiency in communication-intensive configurations while leading in programmer productivity. ItoyoriFBC exhibits slightly lower efficiency than Itoyori, though its future-based synchronization offers potential for expressing irregular workloads.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5c06Itoyori\u548cItoyoriFBC\u4e24\u79cd\u5f02\u6b65\u591a\u4efb\u52a1\u8fd0\u884c\u65f6\u96c6\u6210\u5230Task Bench\u6846\u67b6\u4e2d\uff0c\u4e0eMPI\u548cHPX\u8fdb\u884c\u7efc\u5408\u6027\u80fd\u4e0e\u751f\u4ea7\u529b\u5bf9\u6bd4\u8bc4\u4f30\u3002", "motivation": "\u5f02\u6b65\u591a\u4efb\u52a1\u8fd0\u884c\u65f6\u4f5c\u4e3aMPI\u7684\u66ff\u4ee3\u65b9\u6848\u5177\u6709\u4f18\u52bf\uff0c\u4f46\u591a\u6837\u5316\u7684AMT\u751f\u6001\u7cfb\u7edf\u4f7f\u5f97\u516c\u5e73\u6bd4\u8f83\u53d8\u5f97\u56f0\u96be\u3002\u9700\u8981\u7cfb\u7edf\u6027\u5730\u8bc4\u4f30\u4e0d\u540c\u5e76\u884c\u7f16\u7a0b\u7cfb\u7edf\u7684\u6027\u80fd\u4e0e\u7a0b\u5e8f\u5458\u751f\u4ea7\u529b\u3002", "method": "\u4f7f\u7528Task Bench\u53c2\u6570\u5316\u6846\u67b6\uff0c\u96c6\u6210Itoyori\uff08\u57fa\u4e8ePGAS\u548cRDMA\u5de5\u4f5c\u7a83\u53d6\uff09\u548cItoyoriFBC\uff08\u6269\u5c55\u4e86\u57fa\u4e8efuture\u7684\u540c\u6b65\uff09\u4e24\u79cdAMT\u8fd0\u884c\u65f6\u3002\u901a\u8fc7\u5e94\u7528\u6548\u7387\u3001\u6700\u5c0f\u6709\u6548\u4efb\u52a1\u7c92\u5ea6\u8bc4\u4f30\u6027\u80fd\uff0c\u901a\u8fc7\u4ee3\u7801\u884c\u6570\u548c\u5e93\u6784\u9020\u6570\u91cf\u8bc4\u4f30\u7a0b\u5e8f\u5458\u751f\u4ea7\u529b\u3002", "result": "MPI\u5728\u89c4\u5219\u3001\u901a\u4fe1\u8f7b\u91cf\u7ea7\u5de5\u4f5c\u8d1f\u8f7d\u4e2d\u6548\u7387\u6700\u9ad8\u4f46\u4ee3\u7801\u5197\u957f\uff1bHPX\u5728\u8d1f\u8f7d\u4e0d\u5747\u8861\u65f6\u4fdd\u6301\u7a33\u5b9a\u6548\u7387\u4f46\u751f\u4ea7\u529b\u6307\u6807\u6700\u5dee\uff1bItoyori\u5728\u901a\u4fe1\u5bc6\u96c6\u578b\u914d\u7f6e\u4e2d\u6548\u7387\u6700\u9ad8\u4e14\u751f\u4ea7\u529b\u6700\u4f73\uff1bItoyoriFBC\u6548\u7387\u7565\u4f4e\u4e8eItoyori\u4f46\u4e3a\u4e0d\u89c4\u5219\u5de5\u4f5c\u8d1f\u8f7d\u63d0\u4f9b\u8868\u8fbe\u6f5c\u529b\u3002", "conclusion": "\u4e0d\u540c\u7cfb\u7edf\u5b58\u5728\u660e\u663e\u7684\u6743\u8861\u53d6\u820d\uff1aAMT\u8fd0\u884c\u65f6\u5e76\u4e0d\u5929\u7136\u4fdd\u8bc1\u6bd4MPI\u66f4\u9ad8\u7684\u751f\u4ea7\u529b\uff0cItoyori\u5728\u901a\u4fe1\u5bc6\u96c6\u578b\u573a\u666f\u4e2d\u8868\u73b0\u6700\u4f73\uff0c\u800cfuture-based\u540c\u6b65\u4e3a\u4e0d\u89c4\u5219\u5de5\u4f5c\u8d1f\u8f7d\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u6269\u5c55\u80fd\u529b\u3002"}}
{"id": "2601.14470", "categories": ["cs.SE", "cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2601.14470", "abs": "https://arxiv.org/abs/2601.14470", "authors": ["Mohamad Salim", "Jasmine Latendresse", "SayedHassan Khatoonabadi", "Emad Shihab"], "title": "Tokenomics: Quantifying Where Tokens Are Used in Agentic Software Engineering", "comment": null, "summary": "LLM-based Multi-Agent (LLM-MA) systems are increasingly applied to automate complex software engineering tasks such as requirements engineering, code generation, and testing. However, their operational efficiency and resource consumption remain poorly understood, hindering practical adoption due to unpredictable costs and environmental impact. To address this, we conduct an analysis of token consumption patterns in an LLM-MA system within the Software Development Life Cycle (SDLC), aiming to understand where tokens are consumed across distinct software engineering activities. We analyze execution traces from 30 software development tasks performed by the ChatDev framework using a GPT-5 reasoning model, mapping its internal phases to distinct development stages (Design, Coding, Code Completion, Code Review, Testing, and Documentation) to create a standardized evaluation framework. We then quantify and compare token distribution (input, output, reasoning) across these stages.\n  Our preliminary findings show that the iterative Code Review stage accounts for the majority of token consumption for an average of 59.4% of tokens. Furthermore, we observe that input tokens consistently constitute the largest share of consumption for an average of 53.9%, providing empirical evidence for potentially significant inefficiencies in agentic collaboration. Our results suggest that the primary cost of agentic software engineering lies not in initial code generation but in automated refinement and verification. Our novel methodology can help practitioners predict expenses and optimize workflows, and it directs future research toward developing more token-efficient agent collaboration protocols.", "AI": {"tldr": "\u5206\u6790LLM\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5728\u8f6f\u4ef6\u5f00\u53d1\u751f\u547d\u5468\u671f\u4e2d\u7684token\u6d88\u8017\u6a21\u5f0f\uff0c\u53d1\u73b0\u4ee3\u7801\u5ba1\u67e5\u9636\u6bb5\u6d88\u8017\u6700\u591atoken\uff08\u5e73\u574759.4%\uff09\uff0c\u8f93\u5165token\u5360\u6bd4\u6700\u5927\uff08\u5e73\u574753.9%\uff09\uff0c\u8868\u660e\u81ea\u52a8\u5316\u7cbe\u70bc\u548c\u9a8c\u8bc1\u662f\u4e3b\u8981\u6210\u672c\u6765\u6e90\u3002", "motivation": "LLM\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\u65e5\u76ca\u5e7f\u6cdb\uff0c\u4f46\u5176\u8fd0\u884c\u6548\u7387\u548c\u8d44\u6e90\u6d88\u8017\u60c5\u51b5\u5c1a\u4e0d\u660e\u786e\uff0c\u8fd9\u963b\u788d\u4e86\u5b9e\u9645\u5e94\u7528\uff0c\u56e0\u4e3a\u4e0d\u53ef\u9884\u6d4b\u7684\u6210\u672c\u548c\u73af\u5883\u5f71\u54cd\u6210\u4e3a\u4e3b\u8981\u969c\u788d\u3002", "method": "\u4f7f\u7528ChatDev\u6846\u67b6\u548cGPT-5\u63a8\u7406\u6a21\u578b\uff0c\u5206\u679030\u4e2a\u8f6f\u4ef6\u5f00\u53d1\u4efb\u52a1\u7684\u6267\u884c\u8f68\u8ff9\uff0c\u5c06\u5185\u90e8\u9636\u6bb5\u6620\u5c04\u5230\u6807\u51c6\u5f00\u53d1\u9636\u6bb5\uff08\u8bbe\u8ba1\u3001\u7f16\u7801\u3001\u4ee3\u7801\u5b8c\u6210\u3001\u4ee3\u7801\u5ba1\u67e5\u3001\u6d4b\u8bd5\u3001\u6587\u6863\uff09\uff0c\u521b\u5efa\u6807\u51c6\u5316\u8bc4\u4f30\u6846\u67b6\uff0c\u91cf\u5316\u6bd4\u8f83\u5404\u9636\u6bb5\u7684token\u5206\u5e03\uff08\u8f93\u5165\u3001\u8f93\u51fa\u3001\u63a8\u7406\uff09\u3002", "result": "\u4ee3\u7801\u5ba1\u67e5\u9636\u6bb5\u6d88\u8017\u4e86\u5927\u90e8\u5206token\uff08\u5e73\u574759.4%\uff09\uff0c\u8f93\u5165token\u59cb\u7ec8\u662f\u6700\u5927\u7684\u6d88\u8017\u90e8\u5206\uff08\u5e73\u574753.9%\uff09\uff0c\u8868\u660e\u667a\u80fd\u4f53\u534f\u4f5c\u5b58\u5728\u663e\u8457\u4f4e\u6548\u6027\uff0c\u4e3b\u8981\u6210\u672c\u6765\u81ea\u81ea\u52a8\u5316\u7cbe\u70bc\u548c\u9a8c\u8bc1\u800c\u975e\u521d\u59cb\u4ee3\u7801\u751f\u6210\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u9884\u6d4bLLM\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u6210\u672c\u548c\u4f18\u5316\u5de5\u4f5c\u6d41\u7a0b\u63d0\u4f9b\u4e86\u65b9\u6cd5\u8bba\uff0c\u6307\u5bfc\u672a\u6765\u7814\u7a76\u5f00\u53d1\u66f4token\u9ad8\u6548\u7684\u667a\u80fd\u4f53\u534f\u4f5c\u534f\u8bae\uff0c\u91cd\u70b9\u5173\u6ce8\u51cf\u5c11\u4ee3\u7801\u5ba1\u67e5\u9636\u6bb5\u7684token\u6d88\u8017\u3002"}}
{"id": "2601.14612", "categories": ["cs.DC", "cs.NI", "cs.PF", "math.OC"], "pdf": "https://arxiv.org/pdf/2601.14612", "abs": "https://arxiv.org/abs/2601.14612", "authors": ["Neelkamal Bhuyan", "Randeep Bhatia", "Murali Kodialam", "TV Lakshman"], "title": "Exploiting Spot Instances for Time-Critical Cloud Workloads Using Optimal Randomized Strategies", "comment": "Accepted for publication in the 45th IEEE International Conference on Computer Communications (INFOCOM 2026). Copyright 2026 IEEE", "summary": "This paper addresses the challenge of deadline-aware online scheduling for jobs in hybrid cloud environments, where jobs may run on either cost-effective but unreliable spot instances or more expensive on-demand instances, under hard deadlines. We first establish a fundamental limit for existing (predominantly-) deterministic policies, proving a worst-case competitive ratio of $\u03a9(K)$, where $K$ is the cost ratio between on-demand and spot instances. We then present a novel randomized scheduling algorithm, ROSS, that achieves a provably optimal competitive ratio of $\\sqrt{K}$ under reasonable deadlines, significantly improving upon existing approaches. Extensive evaluations on real-world trace data from Azure and AWS demonstrate that ROSS effectively balances cost optimization and deadline guarantees, consistently outperforming the state-of-the-art by up to $30\\%$ in cost savings, across diverse spot market conditions.", "AI": {"tldr": "\u63d0\u51fa\u968f\u673a\u8c03\u5ea6\u7b97\u6cd5ROSS\uff0c\u5728\u6df7\u5408\u4e91\u73af\u5883\u4e2d\u5b9e\u73b0\u6700\u4f18\u7ade\u4e89\u6bd4\u221aK\uff0c\u663e\u8457\u6539\u8fdb\u73b0\u6709\u65b9\u6cd5\uff0c\u5b9e\u9645\u8bc4\u4f30\u663e\u793a\u6210\u672c\u8282\u7701\u63d0\u534730%", "motivation": "\u89e3\u51b3\u6df7\u5408\u4e91\u73af\u5883\u4e2d\u5177\u6709\u786c\u622a\u6b62\u65f6\u95f4\u7684\u4f5c\u4e1a\u8c03\u5ea6\u6311\u6218\uff0c\u73b0\u6709\u786e\u5b9a\u6027\u7b56\u7565\u5b58\u5728\u03a9(K)\u7684\u6700\u574f\u60c5\u51b5\u7ade\u4e89\u6bd4\u9650\u5236\uff0c\u9700\u8981\u66f4\u4f18\u7684\u8c03\u5ea6\u7b97\u6cd5\u6765\u5e73\u8861\u6210\u672c\u4f18\u5316\u548c\u622a\u6b62\u65f6\u95f4\u4fdd\u8bc1", "method": "\u63d0\u51fa\u968f\u673a\u8c03\u5ea6\u7b97\u6cd5ROSS\uff0c\u9488\u5bf9\u6df7\u5408\u4e91\u73af\u5883\u4e2d\u7684\u4f5c\u4e1a\u8c03\u5ea6\u95ee\u9898\uff0c\u5728\u5408\u7406\u7684\u622a\u6b62\u65f6\u95f4\u7ea6\u675f\u4e0b\uff0c\u901a\u8fc7\u968f\u673a\u5316\u7b56\u7565\u5b9e\u73b0\u6700\u4f18\u8c03\u5ea6\u6027\u80fd", "result": "\u7406\u8bba\u8bc1\u660eROSS\u7b97\u6cd5\u8fbe\u5230\u6700\u4f18\u7ade\u4e89\u6bd4\u221aK\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u7684\u03a9(K)\u4e0b\u754c\uff1b\u5728Azure\u548cAWS\u771f\u5b9e\u8ffd\u8e2a\u6570\u636e\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\uff0cROSS\u6bd4\u73b0\u6709\u6700\u4f18\u65b9\u6cd5\u8282\u7701\u9ad8\u8fbe30%\u7684\u6210\u672c", "conclusion": "ROSS\u7b97\u6cd5\u5728\u6df7\u5408\u4e91\u8c03\u5ea6\u4e2d\u5b9e\u73b0\u4e86\u7406\u8bba\u6700\u4f18\u6027\u80fd\uff0c\u6709\u6548\u5e73\u8861\u4e86\u6210\u672c\u4f18\u5316\u548c\u622a\u6b62\u65f6\u95f4\u4fdd\u8bc1\uff0c\u5728\u4e0d\u540c\u73b0\u8d27\u5e02\u573a\u6761\u4ef6\u4e0b\u5747\u8868\u73b0\u4f18\u5f02"}}
{"id": "2601.14501", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.14501", "abs": "https://arxiv.org/abs/2601.14501", "authors": ["Lodovica Marchesi", "Amal Nasharti", "Michele Marchesi"], "title": "AQUA: an Agile Process to Develop Quantum Annealing Applications", "comment": null, "summary": "Quadratic unconstrained binary optimization (QUBO) is a field of operations research that is attracting growing interest due to the recent availability of quantum hardware targeted at solving QUBO problems. However, practical adoption is hindered by mathematical intricacy, hardware constraints, and a lack of sound software engineering processes for QUBO development. This work presents AQUA (Agile QUantum Annealing), an agile lifecycle for QUBO/QA development created through an industry-academia partnership between NetService S.p.A and the University of Cagliari. Using the Design Science Research (DSR) approach, AQUA customizes Scrum to the needs of QUBO/QA development, structuring work into four stages: initial assessment with formal modeling, prototype-driven algorithm selection, agile implementation, and deployment with ongoing maintenance, each gated by milestones. Validated on a real credit-scoring case, AQUA shows feasibility and offers an explicit, systematic QA engineering framework. Key contributions of our work are: a dedicated QUBO/QA software process, its creation and design using DSR approach, and its empirical validation on a simple yet real case study.", "AI": {"tldr": "AQUA\u662f\u4e00\u4e2a\u4e3aQUBO/\u91cf\u5b50\u9000\u706b\u5f00\u53d1\u5b9a\u5236\u7684\u654f\u6377\u751f\u547d\u5468\u671f\u6846\u67b6\uff0c\u901a\u8fc7\u884c\u4e1a-\u5b66\u672f\u5408\u4f5c\u521b\u5efa\uff0c\u91c7\u7528\u8bbe\u8ba1\u79d1\u5b66\u7814\u7a76\u65b9\u6cd5\uff0c\u5c06\u5de5\u4f5c\u5206\u4e3a\u56db\u4e2a\u9636\u6bb5\uff0c\u5e76\u5728\u771f\u5b9e\u4fe1\u7528\u8bc4\u5206\u6848\u4f8b\u4e2d\u9a8c\u8bc1\u4e86\u53ef\u884c\u6027\u3002", "motivation": "QUBO\u9886\u57df\u867d\u7136\u56e0\u91cf\u5b50\u786c\u4ef6\u7684\u53d1\u5c55\u800c\u53d7\u5230\u5173\u6ce8\uff0c\u4f46\u5b9e\u9645\u5e94\u7528\u53d7\u5230\u6570\u5b66\u590d\u6742\u6027\u3001\u786c\u4ef6\u9650\u5236\u4ee5\u53ca\u7f3a\u4e4f\u5065\u5168\u7684QUBO\u5f00\u53d1\u8f6f\u4ef6\u5de5\u7a0b\u6d41\u7a0b\u7684\u963b\u788d\u3002\u9700\u8981\u7cfb\u7edf\u5316\u7684\u5f00\u53d1\u6846\u67b6\u6765\u4fc3\u8fdb\u5b9e\u9645\u5e94\u7528\u3002", "method": "\u91c7\u7528\u8bbe\u8ba1\u79d1\u5b66\u7814\u7a76\u65b9\u6cd5\uff0c\u901a\u8fc7\u884c\u4e1a-\u5b66\u672f\u5408\u4f5c\uff0c\u5c06Scrum\u5b9a\u5236\u4e3a\u9002\u5408QUBO/\u91cf\u5b50\u9000\u706b\u5f00\u53d1\u7684AQUA\u6846\u67b6\u3002\u5de5\u4f5c\u5206\u4e3a\u56db\u4e2a\u9636\u6bb5\uff1a\u521d\u59cb\u8bc4\u4f30\u4e0e\u5f62\u5f0f\u5efa\u6a21\u3001\u539f\u578b\u9a71\u52a8\u7684\u7b97\u6cd5\u9009\u62e9\u3001\u654f\u6377\u5b9e\u73b0\u3001\u90e8\u7f72\u4e0e\u6301\u7eed\u7ef4\u62a4\uff0c\u6bcf\u4e2a\u9636\u6bb5\u90fd\u6709\u91cc\u7a0b\u7891\u63a7\u5236\u3002", "result": "\u5728\u771f\u5b9e\u7684\u4fe1\u7528\u8bc4\u5206\u6848\u4f8b\u4e2d\u9a8c\u8bc1\u4e86AQUA\u7684\u53ef\u884c\u6027\uff0c\u63d0\u4f9b\u4e86\u4e00\u4e2a\u660e\u786e\u3001\u7cfb\u7edf\u7684\u91cf\u5b50\u9000\u706b\u5de5\u7a0b\u6846\u67b6\uff0c\u5c55\u793a\u4e86\u8be5\u6846\u67b6\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u6709\u6548\u6027\u3002", "conclusion": "AQUA\u4e3aQUBO/\u91cf\u5b50\u9000\u706b\u5f00\u53d1\u63d0\u4f9b\u4e86\u4e13\u95e8\u7684\u8f6f\u4ef6\u6d41\u7a0b\uff0c\u901a\u8fc7\u8bbe\u8ba1\u79d1\u5b66\u7814\u7a76\u65b9\u6cd5\u521b\u5efa\u548c\u8bbe\u8ba1\uff0c\u5e76\u5728\u771f\u5b9e\u6848\u4f8b\u4e2d\u8fdb\u884c\u4e86\u5b9e\u8bc1\u9a8c\u8bc1\uff0c\u6709\u52a9\u4e8e\u4fc3\u8fdb\u91cf\u5b50\u8ba1\u7b97\u5728\u5b9e\u9645\u95ee\u9898\u4e2d\u7684\u5e94\u7528\u3002"}}
{"id": "2601.14642", "categories": ["cs.DC", "cs.LO", "eess.SY"], "pdf": "https://arxiv.org/pdf/2601.14642", "abs": "https://arxiv.org/abs/2601.14642", "authors": ["Guillaume Ambal", "Max Stupple", "Brijesh Dongol", "Azalea Raad"], "title": "Specifying and Verifying RDMA Synchronisation (Extended Version)", "comment": "95 pages, extended version of ESOP 2026 paper", "summary": "Remote direct memory access (RDMA) allows a machine to directly read from and write to the memory of remote machine, enabling high-throughput, low-latency data transfer. Ensuring correctness of RDMA programs has only recently become possible with the formalisation of $\\text{RDMA}^\\text{TSO}$ semantics (describing the behaviour of RDMA networking over a TSO CPU). However, this semantics currently lacks a formalisation of remote synchronisation, meaning that the implementations of common abstractions such as locks cannot be verified. In this paper, we close this gap by presenting $\\text{RDMA}^{\\text{TSO}}_{\\text{RMW}}$, the first semantics for remote `read-modify-write' (RMW) instructions over TSO. It turns out that remote RMW operations are weak and only ensure atomicity against other remote RMWs. We therefore build a set of composable synchronisation abstractions starting with the $\\text{RDMA}^{\\text{WAIT}}_{\\text{RMW}}$ library. Underpinned by $\\text{RDMA}^{\\text{WAIT}}_{\\text{RMW}}$, we then specify, implement and verify three classes of remote locks that are suitable for different scenarios. Additionally, we develop the notion of a strong RDMA model, $\\text{RDMA}^{\\text{SC}}_{\\text{RMW}}$, which is akin to sequential consistency in shared memory architectures. Our libraries are built to be compatible with an existing set of high-performance libraries called LOCO, which ensures compositionality and verifiability.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86RDMA\u207d\u1d1b\u02e2\u1d0f\u207e\u1d3f\u1d39\u1d42\u8bed\u4e49\uff0c\u9996\u6b21\u5f62\u5f0f\u5316\u8fdc\u7a0bRMW\u6307\u4ee4\uff0c\u89e3\u51b3\u4e86RDMA\u7a0b\u5e8f\u9a8c\u8bc1\u4e2d\u8fdc\u7a0b\u540c\u6b65\u7f3a\u5931\u7684\u95ee\u9898\uff0c\u5e76\u6784\u5efa\u4e86\u53ef\u7ec4\u5408\u7684\u540c\u6b65\u62bd\u8c61\u5e93\u548c\u4e09\u7c7b\u8fdc\u7a0b\u9501\u3002", "motivation": "\u73b0\u6709RDMA\u207d\u1d1b\u02e2\u1d0f\u207e\u8bed\u4e49\u7f3a\u4e4f\u8fdc\u7a0b\u540c\u6b65\u7684\u5f62\u5f0f\u5316\u63cf\u8ff0\uff0c\u5bfc\u81f4\u65e0\u6cd5\u9a8c\u8bc1\u9501\u7b49\u5e38\u89c1\u62bd\u8c61\u7684\u5b9e\u73b0\u6b63\u786e\u6027\u3002\u9700\u8981\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u4e3aRDMA\u7a0b\u5e8f\u63d0\u4f9b\u5b8c\u6574\u7684\u9a8c\u8bc1\u57fa\u7840\u3002", "method": "1. \u63d0\u51faRDMA\u207d\u1d1b\u02e2\u1d0f\u207e\u1d3f\u1d39\u1d42\u8bed\u4e49\uff0c\u5f62\u5f0f\u5316\u8fdc\u7a0bRMW\u6307\u4ee4\uff1b2. \u6784\u5efaRDMA\u207d\u1d21\u1d00\u026a\u1d1b\u207e\u1d3f\u1d39\u1d42\u5e93\u4f5c\u4e3a\u53ef\u7ec4\u5408\u540c\u6b65\u62bd\u8c61\u57fa\u7840\uff1b3. \u57fa\u4e8e\u6b64\u5e93\u8bbe\u8ba1\u3001\u5b9e\u73b0\u5e76\u9a8c\u8bc1\u4e09\u7c7b\u9002\u7528\u4e8e\u4e0d\u540c\u573a\u666f\u7684\u8fdc\u7a0b\u9501\uff1b4. \u63d0\u51fa\u7c7b\u4f3c\u987a\u5e8f\u4e00\u81f4\u6027\u7684\u5f3aRDMA\u6a21\u578bRDMA\u207d\u02e2\u1d9c\u207e\u1d3f\u1d39\u1d42\u3002", "result": "1. \u53d1\u73b0\u8fdc\u7a0bRMW\u64cd\u4f5c\u8f83\u5f31\uff0c\u4ec5\u4fdd\u8bc1\u5bf9\u5176\u4ed6\u8fdc\u7a0bRMW\u7684\u539f\u5b50\u6027\uff1b2. \u6210\u529f\u6784\u5efa\u4e86\u53ef\u7ec4\u5408\u7684\u540c\u6b65\u62bd\u8c61\u5e93\uff1b3. \u9a8c\u8bc1\u4e86\u4e09\u7c7b\u8fdc\u7a0b\u9501\u7684\u6b63\u786e\u6027\uff1b4. \u63d0\u51fa\u7684\u5e93\u4e0e\u73b0\u6709\u9ad8\u6027\u80fdLOCO\u5e93\u517c\u5bb9\uff0c\u786e\u4fdd\u53ef\u7ec4\u5408\u6027\u548c\u53ef\u9a8c\u8bc1\u6027\u3002", "conclusion": "\u672c\u6587\u586b\u8865\u4e86RDMA\u8bed\u4e49\u4e2d\u8fdc\u7a0b\u540c\u6b65\u7684\u7a7a\u767d\uff0c\u4e3aRDMA\u7a0b\u5e8f\u9a8c\u8bc1\u63d0\u4f9b\u4e86\u5b8c\u6574\u57fa\u7840\uff0c\u4f7f\u9501\u7b49\u540c\u6b65\u539f\u8bed\u7684\u5b9e\u73b0\u9a8c\u8bc1\u6210\u4e3a\u53ef\u80fd\uff0c\u63a8\u52a8\u4e86RDMA\u7f16\u7a0b\u6a21\u578b\u7684\u5f62\u5f0f\u5316\u53d1\u5c55\u3002"}}
{"id": "2601.14598", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.14598", "abs": "https://arxiv.org/abs/2601.14598", "authors": ["Yonatan Gizachew Achamyeleh", "Harsh Thomare", "Mohammad Abdullah Al Faruque"], "title": "HELIOS: Hierarchical Graph Abstraction for Structure-Aware LLM Decompilation", "comment": null, "summary": "Large language models (LLMs) have recently been applied to binary decompilation, yet they still treat code as plain text and ignore the graphs that govern program control flow. This limitation often yields syntactically fragile and logically inconsistent output, especially for optimized binaries. This paper presents \\textsc{HELIOS}, a framework that reframes LLM-based decompilation as a structured reasoning task. \\textsc{HELIOS} summarizes a binary's control flow and function calls into a hierarchical text representation that spells out basic blocks, their successors, and high-level patterns such as loops and conditionals. This representation is supplied to a general-purpose LLM, along with raw decompiler output, optionally combined with a compiler-in-the-loop that returns error messages when the generated code fails to build.\n  On HumanEval-Decompile for \\texttt{x86\\_64}, \\textsc{HELIOS} raises average object file compilability from 45.0\\% to 85.2\\% for Gemini~2.0 and from 71.4\\% to 89.6\\% for GPT-4.1~Mini. With compiler feedback, compilability exceeds 94\\% and functional correctness improves by up to 5.6 percentage points over text-only prompting. Across six architectures drawn from x86, ARM, and MIPS, \\textsc{HELIOS} reduces the spread in functional correctness while keeping syntactic correctness consistently high, all without fine-tuning. These properties make \\textsc{HELIOS} a practical building block for reverse engineering workflows in security settings where analysts need recompilable, semantically faithful code across diverse hardware targets.", "AI": {"tldr": "HELIOS\u6846\u67b6\u5c06LLM\u53cd\u7f16\u8bd1\u91cd\u6784\u4e3a\u7ed3\u6784\u5316\u63a8\u7406\u4efb\u52a1\uff0c\u901a\u8fc7\u63a7\u5236\u6d41\u5c42\u6b21\u5316\u6587\u672c\u8868\u793a\u548c\u7f16\u8bd1\u5668\u53cd\u9988\uff0c\u663e\u8457\u63d0\u5347\u53cd\u7f16\u8bd1\u4ee3\u7801\u7684\u53ef\u7f16\u8bd1\u6027\u548c\u529f\u80fd\u6b63\u786e\u6027\u3002", "motivation": "\u73b0\u6709LLM\u53cd\u7f16\u8bd1\u65b9\u6cd5\u5c06\u4ee3\u7801\u89c6\u4e3a\u7eaf\u6587\u672c\uff0c\u5ffd\u7565\u4e86\u7a0b\u5e8f\u63a7\u5236\u6d41\u56fe\uff0c\u5bfc\u81f4\u8f93\u51fa\u5728\u8bed\u6cd5\u4e0a\u8106\u5f31\u4e14\u903b\u8f91\u4e0d\u4e00\u81f4\uff0c\u7279\u522b\u662f\u5728\u4f18\u5316\u4e8c\u8fdb\u5236\u6587\u4ef6\u7684\u60c5\u51b5\u4e0b\u3002", "method": "HELIOS\u5c06\u4e8c\u8fdb\u5236\u6587\u4ef6\u63a7\u5236\u6d41\u548c\u51fd\u6570\u8c03\u7528\u603b\u7ed3\u4e3a\u5c42\u6b21\u5316\u6587\u672c\u8868\u793a\uff0c\u5305\u542b\u57fa\u672c\u5757\u3001\u540e\u7ee7\u5757\u4ee5\u53ca\u5faa\u73af\u548c\u6761\u4ef6\u7b49\u9ad8\u7ea7\u6a21\u5f0f\uff0c\u5c06\u6b64\u8868\u793a\u4e0e\u539f\u59cb\u53cd\u7f16\u8bd1\u5668\u8f93\u51fa\u4e00\u8d77\u63d0\u4f9b\u7ed9\u901a\u7528LLM\uff0c\u5e76\u53ef\u9009\u62e9\u7ed3\u5408\u7f16\u8bd1\u5668\u53cd\u9988\u5faa\u73af\u3002", "result": "\u5728x86_64\u4e0a\uff0cHELIOS\u5c06\u5e73\u5747\u76ee\u6807\u6587\u4ef6\u53ef\u7f16\u8bd1\u6027\u4ece45.0%\u63d0\u5347\u81f385.2%\uff08Gemini 2.0\uff09\u548c\u4ece71.4%\u63d0\u5347\u81f389.6%\uff08GPT-4.1 Mini\uff09\u3002\u4f7f\u7528\u7f16\u8bd1\u5668\u53cd\u9988\u540e\uff0c\u53ef\u7f16\u8bd1\u6027\u8d85\u8fc794%\uff0c\u529f\u80fd\u6b63\u786e\u6027\u6bd4\u7eaf\u6587\u672c\u63d0\u793a\u63d0\u5347\u9ad8\u8fbe5.6\u4e2a\u767e\u5206\u70b9\u3002", "conclusion": "HELIOS\u65e0\u9700\u5fae\u8c03\u5373\u53ef\u5728\u4e0d\u540c\u786c\u4ef6\u67b6\u6784\u4e0a\u4fdd\u6301\u9ad8\u8bed\u6cd5\u6b63\u786e\u6027\u5e76\u51cf\u5c11\u529f\u80fd\u6b63\u786e\u6027\u5dee\u5f02\uff0c\u6210\u4e3a\u5b89\u5168\u9006\u5411\u5de5\u7a0b\u5de5\u4f5c\u6d41\u7a0b\u4e2d\u5b9e\u7528\u7684\u6784\u5efa\u6a21\u5757\uff0c\u80fd\u591f\u751f\u6210\u53ef\u91cd\u65b0\u7f16\u8bd1\u4e14\u8bed\u4e49\u5fe0\u5b9e\u7684\u4ee3\u7801\u3002"}}
{"id": "2601.14735", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2601.14735", "abs": "https://arxiv.org/abs/2601.14735", "authors": ["Varad Kulkarni", "Vaibhav Jha", "Nikhil Reddy", "Yogesh Simmhan"], "title": "Optimizing FaaS Platforms for MCP-enabled Agentic Workflows", "comment": null, "summary": "Agentic workflows that use autonomous AI Agents powered by Large Language Models (LLMs) and Model Context Protocol (MCP) servers is rapidly rising. This introduces challenges in scalable cloud deployment and state management. Traditional hosting on Virtual Machines (VMs) is resource-intensive and lacks elasticity. Functions-as-a-Service (FaaS) platforms offer modularity, autoscaling and cost efficiency but are inherently stateless. In this paper, we present the FAME, a FaaS-based architecture for orchestrating MCP-enabled agentic workflows. FAME decomposes agentic patterns such as ReAct into composable agents: Planner, Actor and Evaluator, that are each a FaaS function built using LangGraph and are orchestrated as a FaaS workflow. This enables modular composition as AWS Step Functions and avoids function timeouts seen for monolithic agentic workflows. To address context persistence across user requests in a conversation, FAME automates agent memory persistence and injection using DynamoDB. It also optimizes MCP server deployment through AWS Lambda wrappers, caches tool outputs in S3 and proposes function fusion strategies. We evaluate FAME on two representative applications, on research paper summarization and log analytics, under diverse memory and caching configurations. Results show up to 13x latency reduction, 88% fewer input tokens and 66% in cost savings, along with improved workflow completion rates. This demonstrates the viability of serverless platforms for hosting complex, multi-agent AI workflows at scale.", "AI": {"tldr": "FAME\u662f\u4e00\u4e2a\u57fa\u4e8eFaaS\u7684\u67b6\u6784\uff0c\u7528\u4e8e\u7f16\u6392\u652f\u6301MCP\u7684\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\uff0c\u901a\u8fc7\u5c06\u667a\u80fd\u4f53\u6a21\u5f0f\u5206\u89e3\u4e3a\u53ef\u7ec4\u5408\u7684FaaS\u51fd\u6570\uff0c\u89e3\u51b3\u670d\u52a1\u5668\u90e8\u7f72\u548c\u72b6\u6001\u7ba1\u7406\u95ee\u9898\uff0c\u663e\u8457\u964d\u4f4e\u5ef6\u8fdf\u548c\u6210\u672c\u3002", "motivation": "\u57fa\u4e8eLLM\u548cMCP\u7684\u81ea\u4e3bAI\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\u5feb\u901f\u589e\u957f\uff0c\u4f46\u9762\u4e34\u53ef\u6269\u5c55\u4e91\u90e8\u7f72\u548c\u72b6\u6001\u7ba1\u7406\u7684\u6311\u6218\u3002\u4f20\u7edfVM\u6258\u7ba1\u8d44\u6e90\u5bc6\u96c6\u4e14\u7f3a\u4e4f\u5f39\u6027\uff0c\u800cFaaS\u5e73\u53f0\u867d\u7136\u6a21\u5757\u5316\u3001\u53ef\u81ea\u52a8\u6269\u5c55\u4e14\u6210\u672c\u6548\u76ca\u9ad8\uff0c\u4f46\u672c\u8d28\u4e0a\u662f\u65e0\u72b6\u6001\u7684\u3002", "method": "FAME\u5c06\u667a\u80fd\u4f53\u6a21\u5f0f\uff08\u5982ReAct\uff09\u5206\u89e3\u4e3a\u53ef\u7ec4\u5408\u7684\u667a\u80fd\u4f53\uff1a\u89c4\u5212\u5668\u3001\u6267\u884c\u5668\u548c\u8bc4\u4f30\u5668\uff0c\u6bcf\u4e2a\u90fd\u662f\u4f7f\u7528LangGraph\u6784\u5efa\u7684FaaS\u51fd\u6570\uff0c\u5e76\u7f16\u6392\u4e3aFaaS\u5de5\u4f5c\u6d41\u3002\u4f7f\u7528DynamoDB\u5b9e\u73b0\u8de8\u7528\u6237\u8bf7\u6c42\u7684\u4e0a\u4e0b\u6587\u6301\u4e45\u5316\uff0c\u901a\u8fc7AWS Lambda\u5305\u88c5\u5668\u4f18\u5316MCP\u670d\u52a1\u5668\u90e8\u7f72\uff0c\u5728S3\u4e2d\u7f13\u5b58\u5de5\u5177\u8f93\u51fa\uff0c\u5e76\u63d0\u51fa\u51fd\u6570\u878d\u5408\u7b56\u7565\u3002", "result": "\u5728\u4e24\u4e2a\u4ee3\u8868\u6027\u5e94\u7528\uff08\u7814\u7a76\u8bba\u6587\u6458\u8981\u548c\u65e5\u5fd7\u5206\u6790\uff09\u4e0a\u8bc4\u4f30\uff0c\u7ed3\u679c\u663e\u793a\u5ef6\u8fdf\u964d\u4f4e\u9ad8\u8fbe13\u500d\uff0c\u8f93\u5165\u4ee4\u724c\u51cf\u5c1188%\uff0c\u6210\u672c\u8282\u770166%\uff0c\u5de5\u4f5c\u6d41\u5b8c\u6210\u7387\u63d0\u9ad8\u3002", "conclusion": "FAME\u8bc1\u660e\u4e86\u65e0\u670d\u52a1\u5668\u5e73\u53f0\u5728\u89c4\u6a21\u5316\u6258\u7ba1\u590d\u6742\u591a\u667a\u80fd\u4f53AI\u5de5\u4f5c\u6d41\u65b9\u9762\u7684\u53ef\u884c\u6027\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u90e8\u7f72\u65b9\u6cd5\u7684\u8d44\u6e90\u5bc6\u96c6\u6027\u548c\u72b6\u6001\u7ba1\u7406\u95ee\u9898\u3002"}}
{"id": "2601.14731", "categories": ["cs.SE", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.14731", "abs": "https://arxiv.org/abs/2601.14731", "authors": ["Shuning Ge", "Fangyun Qin", "Xiaohui Wan", "Yang Liu", "Qian Dai", "Zheng Zheng"], "title": "ARFT-Transformer: Modeling Metric Dependencies for Cross-Project Aging-Related Bug Prediction", "comment": "Accepted by The Journal of Systems & Software (JSS), 2026", "summary": "Software systems that run for long periods often suffer from software aging, which is typically caused by Aging-Related Bugs (ARBs). To mitigate the risk of ARBs early in the development phase, ARB prediction has been introduced into software aging research. However, due to the difficulty of collecting ARBs, within-project ARB prediction faces the challenge of data scarcity, leading to the proposal of cross-project ARB prediction. This task faces two major challenges: 1) domain adaptation issue caused by distribution difference between source and target projects; and 2) severe class imbalance between ARB-prone and ARB-free samples. Although various methods have been proposed for cross-project ARB prediction, existing approaches treat the input metrics independently and often neglect the rich inter-metric dependencies, which can lead to overlapping information and misjudgment of metric importance, potentially affecting the model's performance. Moreover, they typically use cross-entropy as the loss function during training, which cannot distinguish the difficulty of sample classification. To overcome these limitations, we propose ARFT-Transformer, a transformer-based cross-project ARB prediction framework that introduces a metric-level multi-head attention mechanism to capture metric interactions and incorporates Focal Loss function to effectively handle class imbalance. Experiments conducted on three large-scale open-source projects demonstrate that ARFT-Transformer on average outperforms state-of-the-art cross-project ARB prediction methods in both single-source and multi-source cases, achieving up to a 29.54% and 19.92% improvement in Balance metric.", "AI": {"tldr": "\u63d0\u51faARFT-Transformer\u6846\u67b6\uff0c\u4f7f\u7528Transformer\u7684\u6ce8\u610f\u529b\u673a\u5236\u6355\u6349\u5ea6\u91cf\u6307\u6807\u95f4\u7684\u4f9d\u8d56\u5173\u7cfb\uff0c\u5e76\u7ed3\u5408Focal Loss\u5904\u7406\u7c7b\u522b\u4e0d\u5e73\u8861\uff0c\u663e\u8457\u63d0\u5347\u8de8\u9879\u76eeARB\u9884\u6d4b\u6027\u80fd\u3002", "motivation": "\u8f6f\u4ef6\u8001\u5316\u76f8\u5173\u7f3a\u9677(ARB)\u9884\u6d4b\u9762\u4e34\u6570\u636e\u7a00\u7f3a\u95ee\u9898\uff0c\u8de8\u9879\u76ee\u9884\u6d4b\u5b58\u5728\u4e24\u5927\u6311\u6218\uff1a1)\u6e90\u9879\u76ee\u4e0e\u76ee\u6807\u9879\u76ee\u95f4\u7684\u5206\u5e03\u5dee\u5f02\u5bfc\u81f4\u7684\u9886\u57df\u9002\u5e94\u95ee\u9898\uff1b2)ARB\u6613\u53d1\u6837\u672c\u4e0e\u65e0ARB\u6837\u672c\u95f4\u7684\u4e25\u91cd\u7c7b\u522b\u4e0d\u5e73\u8861\u3002\u73b0\u6709\u65b9\u6cd5\u5c06\u8f93\u5165\u5ea6\u91cf\u6307\u6807\u72ec\u7acb\u5904\u7406\uff0c\u5ffd\u7565\u4e86\u4e30\u5bcc\u7684\u6307\u6807\u95f4\u4f9d\u8d56\u5173\u7cfb\uff0c\u4e14\u4f7f\u7528\u4ea4\u53c9\u71b5\u635f\u5931\u65e0\u6cd5\u533a\u5206\u6837\u672c\u5206\u7c7b\u96be\u5ea6\u3002", "method": "\u63d0\u51faARFT-Transformer\u6846\u67b6\uff0c\u57fa\u4e8eTransformer\u67b6\u6784\u5f15\u5165\u5ea6\u91cf\u7ea7\u591a\u5934\u6ce8\u610f\u529b\u673a\u5236\u6765\u6355\u6349\u5ea6\u91cf\u6307\u6807\u95f4\u7684\u4ea4\u4e92\u5173\u7cfb\uff0c\u5e76\u91c7\u7528Focal Loss\u51fd\u6570\u6709\u6548\u5904\u7406\u7c7b\u522b\u4e0d\u5e73\u8861\u95ee\u9898\u3002", "result": "\u5728\u4e09\u4e2a\u5927\u578b\u5f00\u6e90\u9879\u76ee\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cARFT-Transformer\u5728\u5355\u6e90\u548c\u591a\u6e90\u60c5\u51b5\u4e0b\u5747\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u7684\u8de8\u9879\u76eeARB\u9884\u6d4b\u65b9\u6cd5\uff0cBalance\u6307\u6807\u5e73\u5747\u63d0\u5347\u6700\u9ad8\u8fbe29.54%\u548c19.92%\u3002", "conclusion": "ARFT-Transformer\u901a\u8fc7\u6355\u6349\u5ea6\u91cf\u6307\u6807\u95f4\u4f9d\u8d56\u5173\u7cfb\u548c\u6709\u6548\u5904\u7406\u7c7b\u522b\u4e0d\u5e73\u8861\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8de8\u9879\u76eeARB\u9884\u6d4b\u6027\u80fd\uff0c\u4e3a\u89e3\u51b3\u8f6f\u4ef6\u8001\u5316\u76f8\u5173\u7f3a\u9677\u9884\u6d4b\u4e2d\u7684\u6570\u636e\u7a00\u7f3a\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6848\u3002"}}
{"id": "2601.14912", "categories": ["cs.DC", "cs.SE"], "pdf": "https://arxiv.org/pdf/2601.14912", "abs": "https://arxiv.org/abs/2601.14912", "authors": ["Guangba Yu", "Genting Mai", "Rui Wang", "Ruipeng Li", "Pengfei Chen", "Long Pan", "Ruijie Xu"], "title": "AlertGuardian: Intelligent Alert Life-Cycle Management for Large-scale Cloud Systems", "comment": "Accepted by ASE 2025", "summary": "Alerts are critical for detecting anomalies in large-scale cloud systems, ensuring reliability and user experience. However, current systems generate overwhelming volumes of alerts, degrading operational efficiency due to ineffective alert life-cycle management. This paper details the efforts of Company-X to optimize alert life-cycle management, addressing alert fatigue in cloud systems. We propose AlertGuardian, a framework collaborating large language models (LLMs) and lightweight graph models to optimize the alert life-cycle through three phases: Alert Denoise uses graph learning model with virtual noise to filter noise, Alert Summary employs Retrieval Augmented Generation (RAG) with LLMs to create actionable summary, and Alert Rule Refinement leverages multi-agent iterative feedbacks to improve alert rule quality. Evaluated on four real-world datasets from Company-X's services, AlertGuardian significantly mitigates alert fatigue (94.8\\% alert reduction ratios) and accelerates fault diagnosis (90.5\\% diagnosis accuracy). Moreover, AlertGuardian improves 1,174 alert rules, with 375 accepted by SREs (32% acceptance rate). Finally, we share success stories and lessons learned about alert life-cycle management after the deployment of AlertGuardian in Company-X.", "AI": {"tldr": "AlertGuardian\u6846\u67b6\u5229\u7528LLM\u548c\u56fe\u6a21\u578b\u4f18\u5316\u4e91\u7cfb\u7edf\u544a\u8b66\u751f\u547d\u5468\u671f\u7ba1\u7406\uff0c\u901a\u8fc7\u964d\u566a\u3001\u6458\u8981\u548c\u89c4\u5219\u4f18\u5316\u4e09\u9636\u6bb5\u663e\u8457\u51cf\u5c11\u544a\u8b66\u75b2\u52b3\u5e76\u63d0\u5347\u8bca\u65ad\u6548\u7387\u3002", "motivation": "\u5927\u89c4\u6a21\u4e91\u7cfb\u7edf\u4e2d\u544a\u8b66\u6570\u91cf\u8fc7\u591a\u5bfc\u81f4\u544a\u8b66\u75b2\u52b3\uff0c\u964d\u4f4e\u8fd0\u7ef4\u6548\u7387\uff0c\u9700\u8981\u4f18\u5316\u544a\u8b66\u751f\u547d\u5468\u671f\u7ba1\u7406\u6765\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u63d0\u51faAlertGuardian\u6846\u67b6\uff0c\u7ed3\u5408\u5927\u8bed\u8a00\u6a21\u578b\u548c\u8f7b\u91cf\u7ea7\u56fe\u6a21\u578b\uff0c\u5305\u542b\u4e09\u4e2a\u9636\u6bb5\uff1a\u544a\u8b66\u964d\u566a\uff08\u4f7f\u7528\u5e26\u865a\u62df\u566a\u58f0\u7684\u56fe\u5b66\u4e60\u6a21\u578b\uff09\u3001\u544a\u8b66\u6458\u8981\uff08\u57fa\u4e8eRAG\u7684LLM\u751f\u6210\u53ef\u64cd\u4f5c\u6458\u8981\uff09\u3001\u544a\u8b66\u89c4\u5219\u4f18\u5316\uff08\u591a\u667a\u80fd\u4f53\u8fed\u4ee3\u53cd\u9988\u6539\u8fdb\u89c4\u5219\u8d28\u91cf\uff09\u3002", "result": "\u5728\u56db\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0c\u663e\u8457\u7f13\u89e3\u544a\u8b66\u75b2\u52b3\uff0894.8%\u544a\u8b66\u51cf\u5c11\u7387\uff09\uff0c\u52a0\u901f\u6545\u969c\u8bca\u65ad\uff0890.5%\u8bca\u65ad\u51c6\u786e\u7387\uff09\uff0c\u6539\u8fdb1174\u6761\u544a\u8b66\u89c4\u5219\uff0c\u5176\u4e2d375\u6761\u88abSRE\u63a5\u53d7\uff0832%\u63a5\u53d7\u7387\uff09\u3002", "conclusion": "AlertGuardian\u6210\u529f\u4f18\u5316\u4e86\u4e91\u7cfb\u7edf\u544a\u8b66\u751f\u547d\u5468\u671f\u7ba1\u7406\uff0c\u5206\u4eab\u4e86\u90e8\u7f72\u540e\u7684\u6210\u529f\u7ecf\u9a8c\u548c\u6559\u8bad\uff0c\u4e3a\u7c7b\u4f3c\u7cfb\u7edf\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.14743", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.14743", "abs": "https://arxiv.org/abs/2601.14743", "authors": ["Konstantin Poddubnyy", "Igor Vozniak", "Nils Lipp", "Ivan Burmistrov", "Davit Hovhannisyan", "Christian Mueller", "Philipp Slusallek"], "title": "ARISE - Adaptive Refinement and Iterative Scenario Engineering", "comment": "Accepted for publication at the IEEE Intelligent Vehicles Symposium (IV), 2026", "summary": "The effectiveness of collision-free trajectory planners depends on the quality and diversity of training data, especially for rare scenarios. A widely used approach to improve dataset diversity involves generating realistic synthetic traffic scenarios. However, producing such scenarios remains difficult due to the precision required when scripting them manually or generating them in a single pass. Natural language offers a flexible way to describe scenarios, but existing text-to-simulation pipelines often rely on static snippet retrieval, limited grammar, single-pass decoding, or lack robust executability checks. Moreover, they depend heavily on constrained LLM prompting with minimal post-processing. To address these limitations, we introduce ARISE - Adaptive Refinement and Iterative Scenario Engineering, a multi-stage tool that converts natural language prompts into executable Scenic scripts through iterative LLM-guided refinement. After each generation, ARISE tests script executability in simulation software, feeding structured diagnostics back to the LLM until both syntactic and functional requirements are met. This process significantly reduces the need for manual intervention. Through extensive evaluation, ARISE outperforms the baseline in generating semantically accurate and executable traffic scenarios with greater reliability and robustness.", "AI": {"tldr": "ARISE\u662f\u4e00\u4e2a\u591a\u9636\u6bb5\u5de5\u5177\uff0c\u901a\u8fc7\u8fed\u4ee3\u5f0fLLM\u5f15\u5bfc\u7684\u4f18\u5316\uff0c\u5c06\u81ea\u7136\u8bed\u8a00\u63d0\u793a\u8f6c\u6362\u4e3a\u53ef\u6267\u884c\u7684Scenic\u811a\u672c\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u624b\u52a8\u5e72\u9884\u9700\u6c42\uff0c\u5728\u751f\u6210\u8bed\u4e49\u51c6\u786e\u4e14\u53ef\u6267\u884c\u7684\u4ea4\u901a\u573a\u666f\u65b9\u9762\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u5f53\u524d\u78b0\u649e\u81ea\u7531\u8f68\u8ff9\u89c4\u5212\u5668\u7684\u6709\u6548\u6027\u4f9d\u8d56\u4e8e\u8bad\u7ec3\u6570\u636e\u7684\u8d28\u91cf\u548c\u591a\u6837\u6027\uff0c\u7279\u522b\u662f\u5bf9\u4e8e\u7f55\u89c1\u573a\u666f\u3002\u867d\u7136\u751f\u6210\u5408\u6210\u4ea4\u901a\u573a\u666f\u662f\u5e38\u7528\u65b9\u6cd5\uff0c\u4f46\u624b\u52a8\u811a\u672c\u7f16\u5199\u6216\u5355\u6b21\u751f\u6210\u9700\u8981\u9ad8\u7cbe\u5ea6\uff0c\u800c\u73b0\u6709\u7684\u6587\u672c\u5230\u6a21\u62df\u7ba1\u9053\u5b58\u5728\u9759\u6001\u7247\u6bb5\u68c0\u7d22\u3001\u6709\u9650\u8bed\u6cd5\u3001\u5355\u6b21\u89e3\u7801\u6216\u7f3a\u4e4f\u9c81\u68d2\u53ef\u6267\u884c\u6027\u68c0\u67e5\u7b49\u9650\u5236\u3002", "method": "ARISE\u91c7\u7528\u81ea\u9002\u5e94\u4f18\u5316\u548c\u8fed\u4ee3\u573a\u666f\u5de5\u7a0b\u7684\u591a\u9636\u6bb5\u65b9\u6cd5\uff0c\u901a\u8fc7\u8fed\u4ee3\u5f0fLLM\u5f15\u5bfc\u7684\u4f18\u5316\u5c06\u81ea\u7136\u8bed\u8a00\u63d0\u793a\u8f6c\u6362\u4e3a\u53ef\u6267\u884c\u7684Scenic\u811a\u672c\u3002\u6bcf\u6b21\u751f\u6210\u540e\uff0cARISE\u5728\u6a21\u62df\u8f6f\u4ef6\u4e2d\u6d4b\u8bd5\u811a\u672c\u53ef\u6267\u884c\u6027\uff0c\u5e76\u5c06\u7ed3\u6784\u5316\u8bca\u65ad\u53cd\u9988\u7ed9LLM\uff0c\u76f4\u5230\u6ee1\u8db3\u8bed\u6cd5\u548c\u529f\u80fd\u8981\u6c42\u3002", "result": "\u901a\u8fc7\u5e7f\u6cdb\u8bc4\u4f30\uff0cARISE\u5728\u751f\u6210\u8bed\u4e49\u51c6\u786e\u4e14\u53ef\u6267\u884c\u7684\u4ea4\u901a\u573a\u666f\u65b9\u9762\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5177\u6709\u66f4\u9ad8\u7684\u53ef\u9760\u6027\u548c\u9c81\u68d2\u6027\u3002", "conclusion": "ARISE\u901a\u8fc7\u8fed\u4ee3\u5f0fLLM\u5f15\u5bfc\u7684\u4f18\u5316\u548c\u53ef\u6267\u884c\u6027\u68c0\u67e5\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u751f\u6210\u5408\u6210\u4ea4\u901a\u573a\u666f\u65f6\u7684\u624b\u52a8\u5e72\u9884\u9700\u6c42\uff0c\u4e3a\u8f68\u8ff9\u89c4\u5212\u63d0\u4f9b\u4e86\u66f4\u9ad8\u8d28\u91cf\u548c\u591a\u6837\u6027\u7684\u8bad\u7ec3\u6570\u636e\u3002"}}
{"id": "2601.14923", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2601.14923", "abs": "https://arxiv.org/abs/2601.14923", "authors": ["Kaddour Sidi", "Daniel Balouek", "Baptiste Jonglez"], "title": "Application-level observability for adaptive Edge to Cloud continuum systems", "comment": "UCC 2025 - IEEE/ACM 18th International Conference on Utility and Cloud Computing, Dec 2025, NANTES, France", "summary": "Modern Edge-to-Cloud (E2C) systems require fine-grained observability to ensure adaptive behavior and compliance with performance objectives across heterogeneous and dynamic environments. This work introduces an application-level observability framework that integrates developer-driven instrumentation and SLO-aware feedback for autonomous adaptation. By combining OpenTelemetry, Prometheus, K3s, and Chaos Mesh, the framework enables real-time monitoring and adaptive control across the continuum. A video processing use case demonstrates how application-level metrics guide automatic adjustments to maintain target frame rate, latency, and detection accuracy under variable workloads and injected faults. Preliminary results highlight improved scalability, fault tolerance, and responsiveness, providing a practical foundation for adaptive, SLO-compliant E2C applications.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u5e94\u7528\u7ea7\u53ef\u89c2\u6d4b\u6027\u6846\u67b6\uff0c\u7528\u4e8e\u73b0\u4ee3\u8fb9\u7f18\u5230\u4e91\u7cfb\u7edf\uff0c\u901a\u8fc7\u5f00\u53d1\u8005\u9a71\u52a8\u7684\u4eea\u5668\u5316\u548cSLO\u611f\u77e5\u53cd\u9988\u5b9e\u73b0\u81ea\u4e3b\u9002\u5e94\uff0c\u5728\u89c6\u9891\u5904\u7406\u7528\u4f8b\u4e2d\u5c55\u793a\u4e86\u81ea\u52a8\u8c03\u6574\u4ee5\u7ef4\u6301\u6027\u80fd\u76ee\u6807\u7684\u80fd\u529b\u3002", "motivation": "\u73b0\u4ee3\u8fb9\u7f18\u5230\u4e91\u7cfb\u7edf\u9700\u8981\u7ec6\u7c92\u5ea6\u7684\u53ef\u89c2\u6d4b\u6027\uff0c\u4ee5\u786e\u4fdd\u5728\u5f02\u6784\u548c\u52a8\u6001\u73af\u5883\u4e2d\u5b9e\u73b0\u81ea\u9002\u5e94\u884c\u4e3a\u5e76\u6ee1\u8db3\u6027\u80fd\u76ee\u6807\u3002\u73b0\u6709\u7cfb\u7edf\u7f3a\u4e4f\u6709\u6548\u7684\u5e94\u7528\u7ea7\u76d1\u63a7\u548c\u81ea\u9002\u5e94\u63a7\u5236\u673a\u5236\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u5e94\u7528\u7ea7\u53ef\u89c2\u6d4b\u6027\u6846\u67b6\uff0c\u96c6\u6210\u4e86OpenTelemetry\u3001Prometheus\u3001K3s\u548cChaos Mesh\u7b49\u6280\u672f\u3002\u8be5\u6846\u67b6\u7ed3\u5408\u5f00\u53d1\u8005\u9a71\u52a8\u7684\u4eea\u5668\u5316\u548cSLO\u611f\u77e5\u53cd\u9988\uff0c\u5b9e\u73b0\u5b9e\u65f6\u76d1\u63a7\u548c\u81ea\u9002\u5e94\u63a7\u5236\u3002", "result": "\u901a\u8fc7\u89c6\u9891\u5904\u7406\u7528\u4f8b\u9a8c\u8bc1\uff0c\u5e94\u7528\u7ea7\u6307\u6807\u80fd\u591f\u6307\u5bfc\u81ea\u52a8\u8c03\u6574\uff0c\u5728\u53ef\u53d8\u5de5\u4f5c\u8d1f\u8f7d\u548c\u6ce8\u5165\u6545\u969c\u7684\u60c5\u51b5\u4e0b\u7ef4\u6301\u76ee\u6807\u5e27\u7387\u3001\u5ef6\u8fdf\u548c\u68c0\u6d4b\u7cbe\u5ea6\u3002\u521d\u6b65\u7ed3\u679c\u663e\u793a\u63d0\u9ad8\u4e86\u53ef\u6269\u5c55\u6027\u3001\u5bb9\u9519\u6027\u548c\u54cd\u5e94\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u81ea\u9002\u5e94\u3001\u7b26\u5408SLO\u7684\u8fb9\u7f18\u5230\u4e91\u5e94\u7528\u63d0\u4f9b\u4e86\u5b9e\u7528\u57fa\u7840\uff0c\u901a\u8fc7\u5e94\u7528\u7ea7\u53ef\u89c2\u6d4b\u6027\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u7cfb\u7edf\u9002\u5e94\u6027\u548c\u6027\u80fd\u4fdd\u8bc1\u3002"}}
{"id": "2601.14800", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.14800", "abs": "https://arxiv.org/abs/2601.14800", "authors": ["Yuzhen Tan", "Jian Wang", "Shuaiyu Xie", "Bing Li", "Yunqing Yong", "Neng Zhang", "Shaolin Tan"], "title": "FastFI: Enhancing API Call-Site Robustness in Microservice-Based Systems with Fault Injection", "comment": null, "summary": "Fault injection is a key technique for assessing software reliability, enabling proactive detection of system defects before they manifest in production. However, the increasing complexity of microservice architectures leads to exponential growth in the fault-injection space, rendering traditional random injection inefficient. Recent lineage-driven approaches mitigate this problem through heuristic pruning, but they face two limitations. First, combinatorial-fault discovery remains bottlenecked by general-purpose SAT solvers, which fail to exploit the monotone and low-overlap structure of derived CNF formulas and typically rely on a static upper bound on fault size. Second, existing techniques provide limited post-injection guidance beyond reporting detected faults. To address these challenges, we propose FastFI, a fault-injection-guided framework to enhance the robustness of API call sites in microservice-based systems. FastFI features a DFS-based solver with dynamic fault injection to discover all valid combinatorial faults, and it leverages fault-injection results to identify critical APIs whose call sites should be hardened for robustness. Experiments on four representative microservice benchmarks show that FastFI reduces end-to-end fault-injection time by an average of 76.12\\% compared to state-of-the-art baselines while maintaining acceptable resource overhead. Moreover, FastFI accurately identifies high-impact APIs and provides actionable guidance for call-site hardening.", "AI": {"tldr": "FastFI\u662f\u4e00\u4e2a\u6545\u969c\u6ce8\u5165\u5f15\u5bfc\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u589e\u5f3a\u5fae\u670d\u52a1\u7cfb\u7edf\u4e2dAPI\u8c03\u7528\u7ad9\u70b9\u7684\u9c81\u68d2\u6027\uff0c\u901a\u8fc7\u52a8\u6001\u6545\u969c\u6ce8\u5165\u548cDFS\u6c42\u89e3\u5668\u9ad8\u6548\u53d1\u73b0\u7ec4\u5408\u6545\u969c\uff0c\u5e76\u63d0\u4f9b\u53ef\u64cd\u4f5c\u7684API\u52a0\u56fa\u6307\u5bfc\u3002", "motivation": "\u5fae\u670d\u52a1\u67b6\u6784\u7684\u590d\u6742\u6027\u5bfc\u81f4\u6545\u969c\u6ce8\u5165\u7a7a\u95f4\u5448\u6307\u6570\u589e\u957f\uff0c\u4f20\u7edf\u968f\u673a\u6ce8\u5165\u6548\u7387\u4f4e\u4e0b\u3002\u73b0\u6709\u57fa\u4e8e\u8c31\u7cfb\u9a71\u52a8\u7684\u65b9\u6cd5\u5b58\u5728\u4e24\u4e2a\u4e3b\u8981\u9650\u5236\uff1a1) \u7ec4\u5408\u6545\u969c\u53d1\u73b0\u53d7\u9650\u4e8e\u901a\u7528SAT\u6c42\u89e3\u5668\uff0c\u65e0\u6cd5\u5229\u7528CNF\u516c\u5f0f\u7684\u5355\u8c03\u4f4e\u91cd\u53e0\u7ed3\u6784\uff1b2) \u73b0\u6709\u6280\u672f\u63d0\u4f9b\u7684\u6ce8\u5165\u540e\u6307\u5bfc\u6709\u9650\u3002", "method": "FastFI\u91c7\u7528DFS-based\u6c42\u89e3\u5668\u914d\u5408\u52a8\u6001\u6545\u969c\u6ce8\u5165\u6765\u53d1\u73b0\u6240\u6709\u6709\u6548\u7684\u7ec4\u5408\u6545\u969c\uff0c\u5e76\u5229\u7528\u6545\u969c\u6ce8\u5165\u7ed3\u679c\u8bc6\u522b\u9700\u8981\u52a0\u56fa\u7684\u5173\u952eAPI\u8c03\u7528\u7ad9\u70b9\u3002", "result": "\u5728\u56db\u4e2a\u4ee3\u8868\u6027\u5fae\u670d\u52a1\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cFastFI\u76f8\u6bd4\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\u5e73\u5747\u51cf\u5c11\u4e8676.12%\u7684\u7aef\u5230\u7aef\u6545\u969c\u6ce8\u5165\u65f6\u95f4\uff0c\u540c\u65f6\u4fdd\u6301\u53ef\u63a5\u53d7\u7684\u8d44\u6e90\u5f00\u9500\u3002\u80fd\u591f\u51c6\u786e\u8bc6\u522b\u9ad8\u5f71\u54cdAPI\u5e76\u63d0\u4f9b\u53ef\u64cd\u4f5c\u7684\u8c03\u7528\u7ad9\u70b9\u52a0\u56fa\u6307\u5bfc\u3002", "conclusion": "FastFI\u901a\u8fc7\u9ad8\u6548\u7684\u7ec4\u5408\u6545\u969c\u53d1\u73b0\u548c\u5b9e\u7528\u7684API\u52a0\u56fa\u6307\u5bfc\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u5fae\u670d\u52a1\u7cfb\u7edf\u4e2d\u6545\u969c\u6ce8\u5165\u7684\u6548\u7387\u548c\u5b9e\u7528\u6027\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8f6f\u4ef6\u53ef\u9760\u6027\u8bc4\u4f30\u7684\u6548\u679c\u3002"}}
{"id": "2601.14980", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2601.14980", "abs": "https://arxiv.org/abs/2601.14980", "authors": ["Mengchun Xia", "Zhicheng Dong", "Donghong Cai", "Fang Fang", "Lisheng Fan", "Pingzhi Fan"], "title": "Parallel Collaborative ADMM Privacy Computing and Adaptive GPU Acceleration for Distributed Edge Networks", "comment": null, "summary": "Distributed computing has been widely applied in distributed edge networks for reducing the processing burden of high-dimensional data centralization, where a high-dimensional computational task is decomposed into multiple low-dimensional collaborative processing tasks or multiple edge nodes use distributed data to train a global model. However, the computing power of a single-edge node is limited, and collaborative computing will cause information leakage and excessive communication overhead. In this paper, we design a parallel collaborative distributed alternating direction method of multipliers (ADMM) and propose a three-phase parallel collaborative ADMM privacy computing (3P-ADMM-PC2) algorithm for distributed computing in edge networks, where the Paillier homomorphic encryption is utilized to protect data privacy during interactions. Especially, a quantization method is introduced, which maps the real numbers to a positive integer interval without affecting the homomorphic operations. To address the architectural mismatch between large-integer and Graphics Processing Unit (GPU) computing, we transform high-bitwidth computations into low-bitwidth matrix and vector operations. Thus the GPU can be utilized to implement parallel encryption and decryption computations with long keys. Finally, a GPU-accelerated 3P-ADMM-PC2 is proposed to optimize the collaborative computing tasks. Meanwhile, large-scale computational tasks are conducted in network topologies with varying numbers of edge nodes. Experimental results demonstrate that the proposed 3P-ADMM-PC2 has excellent mean square error performance, which is close to that of distributed ADMM without privacy-preserving. Compared to centralized ADMM and distributed ADMM implemented with Central Processing Unit (CPU) computation, the proposed scheme demonstrates a significant speedup ratio.", "AI": {"tldr": "\u63d0\u51fa3P-ADMM-PC2\u7b97\u6cd5\uff0c\u7ed3\u5408\u5e76\u884cADMM\u3001Paillier\u540c\u6001\u52a0\u5bc6\u548cGPU\u52a0\u901f\uff0c\u7528\u4e8e\u8fb9\u7f18\u7f51\u7edc\u5206\u5e03\u5f0f\u8ba1\u7b97\u4e2d\u7684\u9690\u79c1\u4fdd\u62a4", "motivation": "\u8fb9\u7f18\u7f51\u7edc\u5206\u5e03\u5f0f\u8ba1\u7b97\u9762\u4e34\u5355\u8282\u70b9\u8ba1\u7b97\u80fd\u529b\u6709\u9650\u3001\u534f\u4f5c\u8ba1\u7b97\u5bfc\u81f4\u4fe1\u606f\u6cc4\u9732\u548c\u901a\u4fe1\u5f00\u9500\u8fc7\u5927\u7684\u95ee\u9898\uff0c\u9700\u8981\u9690\u79c1\u4fdd\u62a4\u7684\u9ad8\u6548\u5206\u5e03\u5f0f\u8ba1\u7b97\u65b9\u6848", "method": "\u8bbe\u8ba1\u5e76\u884c\u534f\u4f5c\u5206\u5e03\u5f0fADMM\uff0c\u7ed3\u5408Paillier\u540c\u6001\u52a0\u5bc6\u4fdd\u62a4\u4ea4\u4e92\u6570\u636e\u9690\u79c1\uff0c\u5f15\u5165\u91cf\u5316\u65b9\u6cd5\u5c06\u5b9e\u6570\u6620\u5c04\u5230\u6b63\u6574\u6570\u533a\u95f4\uff0c\u5229\u7528GPU\u52a0\u901f\u5b9e\u73b0\u5e76\u884c\u52a0\u5bc6\u89e3\u5bc6\u8ba1\u7b97", "result": "3P-ADMM-PC2\u5177\u6709\u4f18\u5f02\u7684\u5747\u65b9\u8bef\u5dee\u6027\u80fd\uff0c\u63a5\u8fd1\u65e0\u9690\u79c1\u4fdd\u62a4\u7684\u5206\u5e03\u5f0fADMM\uff0c\u76f8\u6bd4CPU\u5b9e\u73b0\u7684\u96c6\u4e2d\u5f0f\u548c\u5206\u5e03\u5f0fADMM\u6709\u663e\u8457\u52a0\u901f\u6bd4", "conclusion": "\u63d0\u51fa\u7684GPU\u52a0\u901f3P-ADMM-PC2\u7b97\u6cd5\u80fd\u6709\u6548\u89e3\u51b3\u8fb9\u7f18\u7f51\u7edc\u5206\u5e03\u5f0f\u8ba1\u7b97\u4e2d\u7684\u9690\u79c1\u4fdd\u62a4\u548c\u8ba1\u7b97\u6548\u7387\u95ee\u9898"}}
{"id": "2601.14861", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.14861", "abs": "https://arxiv.org/abs/2601.14861", "authors": ["Tanja E. J. Vos", "Tijs van der Storm", "Alexander Serebrenik", "Lionel Briand", "Roberto Di Cosmo", "J. -M Bruel", "Beno\u00eet Combemale"], "title": "Reclaiming Software Engineering as the Enabling Technology for the Digital Age", "comment": null, "summary": "Software engineering is the invisible infrastructure of the digital age. Every breakthrough in artificial intelligence, quantum computing, photonics, and cybersecurity relies on advances in software engineering, yet the field is too often treated as a supportive digital component rather than as a strategic, enabling discipline. In policy frameworks, including major European programmes, software appears primarily as a building block within other technologies, while the scientific discipline of software engineering remains largely absent. This position paper argues that the long-term sustainability, dependability, and sovereignty of digital technologies depend on investment in software engineering research. It is a call to reclaim the identity of software engineering.", "AI": {"tldr": "\u672c\u6587\u4e3b\u5f20\u8f6f\u4ef6\u5de5\u7a0b\u5e94\u88ab\u89c6\u4e3a\u6218\u7565\u6027\u5b66\u79d1\u800c\u975e\u8f85\u52a9\u6027\u6280\u672f\uff0c\u547c\u5401\u6295\u8d44\u8f6f\u4ef6\u5de5\u7a0b\u7814\u7a76\u4ee5\u786e\u4fdd\u6570\u5b57\u6280\u672f\u7684\u53ef\u6301\u7eed\u6027\u3001\u53ef\u9760\u6027\u548c\u81ea\u4e3b\u6027\u3002", "motivation": "\u8f6f\u4ef6\u5de5\u7a0b\u5728\u4eba\u5de5\u667a\u80fd\u3001\u91cf\u5b50\u8ba1\u7b97\u3001\u5149\u5b50\u5b66\u548c\u7f51\u7edc\u5b89\u5168\u7b49\u6570\u5b57\u6280\u672f\u7a81\u7834\u4e2d\u53d1\u6325\u7740\u5173\u952e\u4f5c\u7528\uff0c\u4f46\u5728\u653f\u7b56\u6846\u67b6\u4e2d\u5e38\u88ab\u89c6\u4e3a\u8f85\u52a9\u6027\u6280\u672f\u800c\u975e\u6218\u7565\u6027\u5b66\u79d1\u3002\u6b27\u6d32\u4e3b\u8981\u9879\u76ee\u4e2d\u5c06\u8f6f\u4ef6\u4f5c\u4e3a\u5176\u4ed6\u6280\u672f\u7684\u7ec4\u6210\u90e8\u5206\uff0c\u800c\u8f6f\u4ef6\u5de5\u7a0b\u4f5c\u4e3a\u79d1\u5b66\u5b66\u79d1\u7684\u5730\u4f4d\u88ab\u5ffd\u89c6\u3002", "method": "\u672c\u6587\u91c7\u7528\u7acb\u573a\u8bba\u6587\u7684\u5f62\u5f0f\uff0c\u901a\u8fc7\u8bba\u8bc1\u8f6f\u4ef6\u5de5\u7a0b\u5728\u6570\u5b57\u57fa\u7840\u8bbe\u65bd\u4e2d\u7684\u6838\u5fc3\u5730\u4f4d\uff0c\u547c\u5401\u653f\u7b56\u5236\u5b9a\u8005\u548c\u7814\u7a76\u673a\u6784\u91cd\u65b0\u8ba4\u8bc6\u8f6f\u4ef6\u5de5\u7a0b\u7684\u6218\u7565\u4ef7\u503c\u3002", "result": "\u63d0\u51fa\u8f6f\u4ef6\u5de5\u7a0b\u5e94\u88ab\u89c6\u4e3a\u6218\u7565\u6027\u3001\u8d4b\u80fd\u6027\u5b66\u79d1\uff0c\u800c\u975e\u4ec5\u4ec5\u662f\u652f\u6301\u6027\u6570\u5b57\u7ec4\u4ef6\u3002\u5f3a\u8c03\u6570\u5b57\u6280\u672f\u7684\u957f\u671f\u53ef\u6301\u7eed\u6027\u3001\u53ef\u9760\u6027\u548c\u4e3b\u6743\u4f9d\u8d56\u4e8e\u5bf9\u8f6f\u4ef6\u5de5\u7a0b\u7814\u7a76\u7684\u6295\u8d44\u3002", "conclusion": "\u8f6f\u4ef6\u5de5\u7a0b\u9700\u8981\u91cd\u65b0\u786e\u7acb\u5176\u5b66\u79d1\u8eab\u4efd\uff0c\u6210\u4e3a\u653f\u7b56\u6846\u67b6\u4e2d\u7684\u6218\u7565\u6027\u6295\u8d44\u9886\u57df\uff0c\u4ee5\u786e\u4fdd\u6b27\u6d32\u5728\u6570\u5b57\u6280\u672f\u9886\u57df\u7684\u53ef\u6301\u7eed\u53d1\u5c55\u548c\u6280\u672f\u4e3b\u6743\u3002"}}
{"id": "2601.14865", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.14865", "abs": "https://arxiv.org/abs/2601.14865", "authors": ["Martin Obaidi", "Kushtrim Qengaj", "Hannah Deters", "Jakob Droste", "Marc Herrmann", "Kurt Schneider", "Jil Kl\u00fcnder"], "title": "Understanding Usefulness in Developer Explanations on Stack Overflow", "comment": "This paper has been accepted at the research track of the 32nd International Working Conference on Requirements Engineering: Foundation for Software Quality (REFSQ 2026)", "summary": "Explanations are essential in software engineering (SE) and requirements communication, helping stakeholders clarify ambiguities, justify design choices, and build shared understanding. Online Q&A forums such as Stack Overflow provide large-scale settings where such explanations are produced and evaluated, offering valuable insights into what makes them effective. While prior work has explored answer acceptance and voting behavior, little is known about which specific features make explanations genuinely useful. The relative influence of structural, contextual, and linguistic factors, such as content richness, timing, and sentiment, remains unclear. We analyzed 3,323 questions and 59,398 answers from Stack Overflow, combining text analysis and statistical modeling to examine how explanation attributes relate to perceived usefulness (normalized upvotes). Structural and contextual factors, especially explanation length, code inclusion, timing, and author reputation, show small to moderate positive effects. Sentiment polarity has negligible influence, suggesting that clarity and substance outweigh tone in technical communication. This study provides an empirical account of what drives perceived usefulness in developer explanations. It contributes methodological transparency through open data and replication materials, and conceptual insight by relating observed communication patterns to principles of requirements communication. The findings offer evidence-based implications for how developers and RE practitioners can craft clearer and more effective explanations, potentially supporting fairer communication in both open and organizational contexts. From an RE perspective, these determinants can be interpreted as practical signals for ambiguity reduction and rationale articulation in day-to-day requirements communication.", "AI": {"tldr": "\u7814\u7a76\u901a\u8fc7\u5206\u6790Stack Overflow\u4e0a\u768459,398\u4e2a\u56de\u7b54\uff0c\u53d1\u73b0\u89e3\u91ca\u957f\u5ea6\u3001\u4ee3\u7801\u5305\u542b\u3001\u65f6\u673a\u548c\u4f5c\u8005\u58f0\u8a89\u5bf9\u89e3\u91ca\u7684\u6709\u7528\u6027\u6709\u6b63\u5411\u5f71\u54cd\uff0c\u800c\u60c5\u611f\u6781\u6027\u5f71\u54cd\u751a\u5fae\uff0c\u8868\u660e\u6280\u672f\u4ea4\u6d41\u4e2d\u6e05\u6670\u5ea6\u548c\u5b9e\u8d28\u5185\u5bb9\u6bd4\u8bed\u6c14\u66f4\u91cd\u8981\u3002", "motivation": "\u5728\u7ebf\u95ee\u7b54\u8bba\u575b\u5982Stack Overflow\u63d0\u4f9b\u4e86\u5927\u89c4\u6a21\u7684\u89e3\u91ca\u4ea7\u751f\u548c\u8bc4\u4f30\u573a\u666f\uff0c\u4f46\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u7b54\u6848\u63a5\u53d7\u548c\u6295\u7968\u884c\u4e3a\uff0c\u5bf9\u4e8e\u54ea\u4e9b\u5177\u4f53\u7279\u5f81\u4f7f\u89e3\u91ca\u771f\u6b63\u6709\u7528\u77e5\u4e4b\u751a\u5c11\u3002\u7ed3\u6784\u3001\u4e0a\u4e0b\u6587\u548c\u8bed\u8a00\u56e0\u7d20\uff08\u5982\u5185\u5bb9\u4e30\u5bcc\u5ea6\u3001\u65f6\u673a\u548c\u60c5\u611f\uff09\u7684\u76f8\u5bf9\u5f71\u54cd\u5c1a\u4e0d\u6e05\u695a\u3002", "method": "\u5206\u6790\u4e86Stack Overflow\u4e0a\u76843,323\u4e2a\u95ee\u9898\u548c59,398\u4e2a\u7b54\u6848\uff0c\u7ed3\u5408\u6587\u672c\u5206\u6790\u548c\u7edf\u8ba1\u5efa\u6a21\uff0c\u7814\u7a76\u89e3\u91ca\u5c5e\u6027\u5982\u4f55\u4e0e\u611f\u77e5\u6709\u7528\u6027\uff08\u6807\u51c6\u5316\u70b9\u8d5e\u6570\uff09\u76f8\u5173\u3002", "result": "\u7ed3\u6784\u548c\u4e0a\u4e0b\u6587\u56e0\u7d20\uff0c\u7279\u522b\u662f\u89e3\u91ca\u957f\u5ea6\u3001\u4ee3\u7801\u5305\u542b\u3001\u65f6\u673a\u548c\u4f5c\u8005\u58f0\u8a89\uff0c\u663e\u793a\u51fa\u5c0f\u5230\u4e2d\u5ea6\u7684\u6b63\u5411\u5f71\u54cd\u3002\u60c5\u611f\u6781\u6027\u5f71\u54cd\u53ef\u5ffd\u7565\u4e0d\u8ba1\uff0c\u8868\u660e\u5728\u6280\u672f\u4ea4\u6d41\u4e2d\u6e05\u6670\u5ea6\u548c\u5b9e\u8d28\u5185\u5bb9\u6bd4\u8bed\u6c14\u66f4\u91cd\u8981\u3002", "conclusion": "\u7814\u7a76\u63d0\u4f9b\u4e86\u5173\u4e8e\u5f00\u53d1\u8005\u89e3\u91ca\u4e2d\u611f\u77e5\u6709\u7528\u6027\u9a71\u52a8\u56e0\u7d20\u7684\u5b9e\u8bc1\u5206\u6790\uff0c\u901a\u8fc7\u5f00\u653e\u6570\u636e\u548c\u590d\u5236\u6750\u6599\u63d0\u4f9b\u65b9\u6cd5\u900f\u660e\u5ea6\uff0c\u5e76\u5c06\u89c2\u5bdf\u5230\u7684\u6c9f\u901a\u6a21\u5f0f\u4e0e\u9700\u6c42\u6c9f\u901a\u539f\u5219\u8054\u7cfb\u8d77\u6765\u3002\u7814\u7a76\u7ed3\u679c\u4e3a\u5f00\u53d1\u8005\u548c\u9700\u6c42\u5de5\u7a0b\u4ece\u4e1a\u8005\u5982\u4f55\u6784\u5efa\u66f4\u6e05\u6670\u6709\u6548\u7684\u89e3\u91ca\u63d0\u4f9b\u4e86\u57fa\u4e8e\u8bc1\u636e\u7684\u542f\u793a\u3002"}}
{"id": "2601.14936", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.14936", "abs": "https://arxiv.org/abs/2601.14936", "authors": ["Chansong You", "Hyun Deok Choi", "Jingun Hong"], "title": "LLM-Based Repair of C++ Implicit Data Loss Compiler Warnings: An Industrial Case Study", "comment": null, "summary": "This paper presents a method to automatically fix implicit data loss warnings in large C++ projects using Large Language Models (LLMs). Our approach uses the Language Server Protocol (LSP) to gather context, Tree-sitter to extract relevant code, and LLMs to make decisions and generate fixes. The method evaluates the necessity of range checks concerning performance implications and generates appropriate fixes. We tested this method in a large C++ project, resulting in a 92.73% acceptance rate of the fixes by human developers during the code review. Our LLM-generated fixes reduced the number of warning fix changes that introduced additional instructions due to range checks and exception handling by 39.09% compared to a baseline fix strategy. This result was 13.56% behind the optimal solutions created by human developers. These findings demonstrate that our LLM-based approach can reduce the manual effort to address compiler warnings while maintaining code quality and performance in a real-world scenario. Our automated approach shows promise for integration into existing development workflows, potentially improving code maintenance practices in complex C++ software projects.", "AI": {"tldr": "\u4f7f\u7528LLM\u81ea\u52a8\u4fee\u590dC++\u9879\u76ee\u4e2d\u9690\u5f0f\u6570\u636e\u4e22\u5931\u8b66\u544a\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7LSP\u6536\u96c6\u4e0a\u4e0b\u6587\u3001Tree-sitter\u63d0\u53d6\u4ee3\u7801\u3001LLM\u51b3\u7b56\u751f\u6210\u4fee\u590d\uff0c\u5728\u5927\u578bC++\u9879\u76ee\u4e2d\u8fbe\u523092.73%\u7684\u4ee3\u7801\u5ba1\u67e5\u63a5\u53d7\u7387\u3002", "motivation": "\u51cf\u5c11\u624b\u52a8\u4fee\u590d\u7f16\u8bd1\u5668\u8b66\u544a\u7684\u5de5\u4f5c\u91cf\uff0c\u540c\u65f6\u4fdd\u6301\u4ee3\u7801\u8d28\u91cf\u548c\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728\u5927\u578bC++\u9879\u76ee\u4e2d\u5904\u7406\u9690\u5f0f\u6570\u636e\u4e22\u5931\u8b66\u544a\u7684\u6311\u6218\u3002", "method": "\u7ed3\u5408\u8bed\u8a00\u670d\u52a1\u5668\u534f\u8bae(LSP)\u6536\u96c6\u4e0a\u4e0b\u6587\u4fe1\u606f\uff0c\u4f7f\u7528Tree-sitter\u63d0\u53d6\u76f8\u5173\u4ee3\u7801\uff0c\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLM)\u8fdb\u884c\u51b3\u7b56\u5e76\u751f\u6210\u4fee\u590d\u65b9\u6848\uff0c\u8bc4\u4f30\u8303\u56f4\u68c0\u67e5\u7684\u6027\u80fd\u5f71\u54cd\u3002", "result": "\u5728\u5927\u578bC++\u9879\u76ee\u4e2d\u6d4b\u8bd5\uff0c\u4fee\u590d\u65b9\u6848\u5728\u4ee3\u7801\u5ba1\u67e5\u4e2d\u83b7\u5f9792.73%\u7684\u63a5\u53d7\u7387\uff1b\u76f8\u6bd4\u57fa\u51c6\u4fee\u590d\u7b56\u7565\uff0cLLM\u751f\u6210\u7684\u4fee\u590d\u51cf\u5c11\u4e8639.09%\u56e0\u8303\u56f4\u68c0\u67e5\u548c\u5f02\u5e38\u5904\u7406\u5f15\u5165\u7684\u989d\u5916\u6307\u4ee4\uff1b\u6bd4\u4eba\u5de5\u5f00\u53d1\u8005\u6700\u4f18\u65b9\u6848\u4f4e13.56%\u3002", "conclusion": "LLM\u65b9\u6cd5\u80fd\u6709\u6548\u51cf\u5c11\u4fee\u590d\u7f16\u8bd1\u5668\u8b66\u544a\u7684\u624b\u52a8\u5de5\u4f5c\u91cf\uff0c\u540c\u65f6\u4fdd\u6301\u4ee3\u7801\u8d28\u91cf\u548c\u6027\u80fd\uff0c\u6709\u671b\u96c6\u6210\u5230\u73b0\u6709\u5f00\u53d1\u6d41\u7a0b\u4e2d\uff0c\u6539\u5584\u590d\u6742C++\u8f6f\u4ef6\u9879\u76ee\u7684\u4ee3\u7801\u7ef4\u62a4\u5b9e\u8df5\u3002"}}
{"id": "2601.15074", "categories": ["cs.SE", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.15074", "abs": "https://arxiv.org/abs/2601.15074", "authors": ["Srinath Srinivasan", "Tim Menzies", "Marcelo D'Amorim"], "title": "SmartOracle - An Agentic Approach to Mitigate Noise in Differential Oracles", "comment": null, "summary": "Differential fuzzers detect bugs by executing identical inputs across distinct implementations of the same specification, such as JavaScript interpreters. Validating the outputs requires an oracle and for differential testing of JavaScript, these are constructed manually, making them expensive, time-consuming, and prone to false positives. Worse, when the specification evolves, this manual effort must be repeated.\n  Inspired by the success of agentic systems in other SE domains, this paper introduces SmartOracle. SmartOracle decomposes the manual triage workflow into specialized Large Language Model (LLM) sub-agents. These agents synthesize independently gathered evidence from terminal runs and targeted specification queries to reach a final verdict.\n  For historical benchmarks, SmartOracle achieves 0.84 recall with an 18% false positive rate. Compared to a sequential Gemini 2.5 Pro baseline, it improves triage accuracy while reducing analysis time by 4$\\times$ and API costs by 10$\\times$. In active fuzzing campaigns, SmartOracle successfully identified and reported previously unknown specification-level issues across major engines, including bugs in V8, JavaScriptCore, and GraalJS.\n  The success of SmartOracle's agentic architecture on Javascript suggests it might be useful other software systems- a research direction we will explore in future work.", "AI": {"tldr": "SmartOracle\u4f7f\u7528LLM\u4ee3\u7406\u67b6\u6784\u81ea\u52a8\u5316JavaScript\u5f15\u64ce\u5dee\u5206\u6a21\u7cca\u6d4b\u8bd5\u7684\u9a8c\u8bc1\u8fc7\u7a0b\uff0c\u5c06\u624b\u52a8\u5de5\u4f5c\u6d41\u7a0b\u5206\u89e3\u4e3a\u4e13\u95e8\u5b50\u4ee3\u7406\uff0c\u663e\u8457\u63d0\u9ad8\u6548\u7387\u548c\u51c6\u786e\u6027\u3002", "motivation": "\u5dee\u5206\u6a21\u7cca\u6d4b\u8bd5\u9700\u8981\u624b\u52a8\u6784\u5efa\u9a8c\u8bc1\u9884\u8a00\u673a\uff0c\u6210\u672c\u9ad8\u3001\u8017\u65f6\u957f\u3001\u6613\u4ea7\u751f\u8bef\u62a5\uff0c\u4e14\u89c4\u8303\u53d8\u5316\u65f6\u9700\u8981\u91cd\u590d\u5de5\u4f5c\u3002\u9700\u8981\u81ea\u52a8\u5316\u89e3\u51b3\u65b9\u6848\u6765\u6539\u8fdb\u8fd9\u4e00\u8fc7\u7a0b\u3002", "method": "\u5c06\u624b\u52a8\u5206\u7c7b\u5de5\u4f5c\u6d41\u7a0b\u5206\u89e3\u4e3a\u4e13\u95e8\u7684LLM\u5b50\u4ee3\u7406\uff0c\u8fd9\u4e9b\u4ee3\u7406\u7efc\u5408\u4ece\u7ec8\u7aef\u8fd0\u884c\u548c\u9488\u5bf9\u6027\u89c4\u8303\u67e5\u8be2\u4e2d\u72ec\u7acb\u6536\u96c6\u7684\u8bc1\u636e\uff0c\u505a\u51fa\u6700\u7ec8\u5224\u65ad\u3002", "result": "\u5728\u5386\u53f2\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u52300.84\u53ec\u56de\u7387\u548c18%\u8bef\u62a5\u7387\uff1b\u76f8\u6bd4Gemini 2.5 Pro\u57fa\u7ebf\uff0c\u63d0\u9ad8\u5206\u7c7b\u51c6\u786e\u6027\uff0c\u5206\u6790\u65f6\u95f4\u51cf\u5c114\u500d\uff0cAPI\u6210\u672c\u964d\u4f4e10\u500d\uff1b\u5728\u4e3b\u52a8\u6a21\u7cca\u6d4b\u8bd5\u6d3b\u52a8\u4e2d\u6210\u529f\u8bc6\u522b\u5e76\u62a5\u544a\u4e86V8\u3001JavaScriptCore\u548cGraalJS\u7b49\u4e3b\u8981\u5f15\u64ce\u4e2d\u5148\u524d\u672a\u77e5\u7684\u89c4\u8303\u7ea7\u95ee\u9898\u3002", "conclusion": "SmartOracle\u7684\u4ee3\u7406\u67b6\u6784\u5728JavaScript\u5dee\u5206\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u6210\u529f\uff0c\u8868\u660e\u8be5\u65b9\u6cd5\u53ef\u80fd\u9002\u7528\u4e8e\u5176\u4ed6\u8f6f\u4ef6\u7cfb\u7edf\uff0c\u8fd9\u662f\u672a\u6765\u7814\u7a76\u7684\u65b9\u5411\u3002"}}
{"id": "2601.15084", "categories": ["cs.SE", "cs.OS"], "pdf": "https://arxiv.org/pdf/2601.15084", "abs": "https://arxiv.org/abs/2601.15084", "authors": ["Siyu Yu", "Yifan Wu", "Junjielong Xu", "Ying Fu", "Ning Wang", "Maoyin Liu", "Pancheng Jiang", "Xiang Zhang", "Tong Jia", "Pinjia He", "Ying Li"], "title": "DeLog: An Efficient Log Compression Framework with Pattern Signature Synthesis", "comment": "23 pages, 11 figures", "summary": "Parser-based log compression, which separates static tem- plates from dynamic variables, is a promising approach to exploit the unique structure of log data. However, its perfor- mance on complex production logs is often unsatisfactory. This performance gap coincides with a known degradation in the accuracy of its core log parsing component on such data, motivating our investigation into a foundational yet unverified question: does higher parsing accuracy necessarily lead to better compression ratio?\n  To answer this, we conduct the first empirical study quanti- fying this relationship and find that a higher parsing accuracy does not guarantee a better compression ratio. Instead, our findings reveal that compression ratio is dictated by achiev- ing effective pattern-based grouping and encoding, i.e., the partitioning of tokens into low entropy, highly compressible groups.\n  Guided by this insight, we design DeLog, a novel log com- pressor that implements a Pattern Signature Synthesis mecha- nism to achieve efficient pattern-based grouping. On 16 public and 10 production datasets, DeLog achieves state-of-the-art compression ratio and speed.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u53d1\u73b0\u65e5\u5fd7\u89e3\u6790\u7cbe\u5ea6\u4e0e\u538b\u7f29\u7387\u65e0\u5fc5\u7136\u6b63\u76f8\u5173\uff0c\u63d0\u51fa\u57fa\u4e8e\u6a21\u5f0f\u7b7e\u540d\u5408\u6210\u7684DeLog\u538b\u7f29\u5668\uff0c\u5728\u538b\u7f29\u7387\u548c\u901f\u5ea6\u4e0a\u8fbe\u5230SOTA\u3002", "motivation": "\u57fa\u4e8e\u89e3\u6790\u5668\u7684\u65e5\u5fd7\u538b\u7f29\u65b9\u6cd5\u5728\u751f\u4ea7\u73af\u5883\u590d\u6742\u65e5\u5fd7\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0c\u8fd9\u4e0e\u65e5\u5fd7\u89e3\u6790\u7ec4\u4ef6\u7cbe\u5ea6\u4e0b\u964d\u6709\u5173\u3002\u4f5c\u8005\u7814\u7a76\u4e00\u4e2a\u57fa\u7840\u4f46\u672a\u9a8c\u8bc1\u7684\u95ee\u9898\uff1a\u66f4\u9ad8\u7684\u89e3\u6790\u7cbe\u5ea6\u662f\u5426\u5fc5\u7136\u5e26\u6765\u66f4\u597d\u7684\u538b\u7f29\u7387\uff1f", "method": "\u9996\u5148\u8fdb\u884c\u5b9e\u8bc1\u7814\u7a76\u91cf\u5316\u89e3\u6790\u7cbe\u5ea6\u4e0e\u538b\u7f29\u7387\u7684\u5173\u7cfb\uff0c\u53d1\u73b0\u4e24\u8005\u65e0\u5fc5\u7136\u8054\u7cfb\u3002\u57fa\u4e8e\u6b64\u8bbe\u8ba1DeLog\u538b\u7f29\u5668\uff0c\u91c7\u7528\u6a21\u5f0f\u7b7e\u540d\u5408\u6210\u673a\u5236\u5b9e\u73b0\u9ad8\u6548\u7684\u6a21\u5f0f\u5206\u7ec4\u3002", "result": "\u572816\u4e2a\u516c\u5f00\u6570\u636e\u96c6\u548c10\u4e2a\u751f\u4ea7\u6570\u636e\u96c6\u4e0a\uff0cDeLog\u5728\u538b\u7f29\u7387\u548c\u901f\u5ea6\u65b9\u9762\u90fd\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "conclusion": "\u538b\u7f29\u7387\u7684\u5173\u952e\u5728\u4e8e\u5b9e\u73b0\u6709\u6548\u7684\u57fa\u4e8e\u6a21\u5f0f\u7684\u5206\u7ec4\u548c\u7f16\u7801\uff0c\u800c\u975e\u5355\u7eaf\u63d0\u9ad8\u89e3\u6790\u7cbe\u5ea6\u3002DeLog\u901a\u8fc7\u6a21\u5f0f\u7b7e\u540d\u5408\u6210\u673a\u5236\u5b9e\u73b0\u4e86\u8fd9\u4e00\u76ee\u6807\u3002"}}
{"id": "2601.15094", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.15094", "abs": "https://arxiv.org/abs/2601.15094", "authors": ["Md Zahidul Haque", "Saima Afrin", "Antonio Mastropaolo"], "title": "Parameter-Efficient Multi-Task Fine-Tuning in Code-Related Tasks", "comment": null, "summary": "Large Language Models (LLMs) have proven highly effective in automating software engineering tasks, bridging natural language and code semantics to achieve notable results in code generation and summarization. However, their scale incurs substantial computational costs, making full fine-tuning impractical. Parameter-Efficient Fine-Tuning (PEFT) methods like QLoRA enable efficient specialization with lower resource demands. Recent studies show QLoRA-optimized Large Code Models (LCMs) perform strongly across diverse tasks, yet it remains unclear whether this effectiveness persists when a single model is QLoRA fine-tuned for multiple code-related tasks. The interaction between Multi-task fine-tuning and QLoRA optimization, and how transfer learning affects correctness and quality of generated artifacts, remains largely unexplored. We investigate Multi-task QLoRA fine-tuning across three representative tasks: code generation, translation, and summarization. We evaluate functional correctness through execution-based and similarity-based metrics, complemented by comprehensive code quality analysis--an aspect largely overlooked in prior work. Our findings show that Multi-task QLoRA effectively leverages transfer learning, achieving competitive or superior performance relative to both Single-task QLoRA and Multi-task full fine-tuning. Larger models demonstrate more consistent balance between correctness and quality, whereas smaller models preserve functionality but exhibit a higher incidence of quality-related issues.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u5728\u591a\u4efb\u52a1\u573a\u666f\u4e0b\u4f7f\u7528QLoRA\u5bf9\u5927\u578b\u4ee3\u7801\u6a21\u578b\u8fdb\u884c\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u7684\u6548\u679c\uff0c\u53d1\u73b0\u591a\u4efb\u52a1QLoRA\u80fd\u591f\u6709\u6548\u5229\u7528\u8fc1\u79fb\u5b66\u4e60\uff0c\u5728\u4ee3\u7801\u751f\u6210\u3001\u7ffb\u8bd1\u548c\u603b\u7ed3\u4e09\u4e2a\u4efb\u52a1\u4e0a\u53d6\u5f97\u4e0e\u5355\u4efb\u52a1QLoRA\u548c\u591a\u4efb\u52a1\u5168\u5fae\u8c03\u76f8\u5f53\u6216\u66f4\u597d\u7684\u6027\u80fd\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5168\u5fae\u8c03\u8ba1\u7b97\u6210\u672c\u9ad8\u6602\u3002\u867d\u7136QLoRA\u7b49\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u65b9\u6cd5\u80fd\u5728\u5355\u4efb\u52a1\u4e0a\u53d6\u5f97\u826f\u597d\u6548\u679c\uff0c\u4f46\u591a\u4efb\u52a1QLoRA\u5fae\u8c03\u7684\u6548\u679c\u4ee5\u53ca\u8fc1\u79fb\u5b66\u4e60\u5bf9\u751f\u6210\u4ee3\u7801\u6b63\u786e\u6027\u548c\u8d28\u91cf\u7684\u5f71\u54cd\u5c1a\u672a\u5f97\u5230\u5145\u5206\u7814\u7a76\u3002", "method": "\u91c7\u7528\u591a\u4efb\u52a1QLoRA\u5fae\u8c03\u65b9\u6cd5\uff0c\u5728\u4ee3\u7801\u751f\u6210\u3001\u4ee3\u7801\u7ffb\u8bd1\u548c\u4ee3\u7801\u603b\u7ed3\u4e09\u4e2a\u4ee3\u8868\u6027\u4efb\u52a1\u4e0a\u8fdb\u884c\u5b9e\u9a8c\u3002\u901a\u8fc7\u6267\u884c\u6b63\u786e\u6027\u548c\u76f8\u4f3c\u6027\u6307\u6807\u8bc4\u4f30\u529f\u80fd\u6b63\u786e\u6027\uff0c\u5e76\u8fdb\u884c\u5168\u9762\u7684\u4ee3\u7801\u8d28\u91cf\u5206\u6790\u3002", "result": "\u591a\u4efb\u52a1QLoRA\u80fd\u591f\u6709\u6548\u5229\u7528\u8fc1\u79fb\u5b66\u4e60\uff0c\u5728\u6b63\u786e\u6027\u548c\u8d28\u91cf\u65b9\u9762\u8fbe\u5230\u6216\u8d85\u8fc7\u5355\u4efb\u52a1QLoRA\u548c\u591a\u4efb\u52a1\u5168\u5fae\u8c03\u7684\u6027\u80fd\u3002\u8f83\u5927\u6a21\u578b\u5728\u6b63\u786e\u6027\u548c\u8d28\u91cf\u4e4b\u95f4\u4fdd\u6301\u66f4\u4e00\u81f4\u7684\u5e73\u8861\uff0c\u800c\u8f83\u5c0f\u6a21\u578b\u867d\u7136\u80fd\u4fdd\u6301\u529f\u80fd\u6b63\u786e\u6027\uff0c\u4f46\u51fa\u73b0\u8d28\u91cf\u76f8\u5173\u95ee\u9898\u7684\u9891\u7387\u66f4\u9ad8\u3002", "conclusion": "\u591a\u4efb\u52a1QLoRA\u5fae\u8c03\u662f\u4e00\u79cd\u6709\u6548\u7684\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u7b56\u7565\uff0c\u80fd\u591f\u5728\u591a\u4e2a\u4ee3\u7801\u76f8\u5173\u4efb\u52a1\u4e0a\u5b9e\u73b0\u7ade\u4e89\u6027\u6027\u80fd\uff0c\u540c\u65f6\u5927\u5e45\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u3002\u6a21\u578b\u89c4\u6a21\u5bf9\u6b63\u786e\u6027\u548c\u8d28\u91cf\u4e4b\u95f4\u7684\u5e73\u8861\u6709\u91cd\u8981\u5f71\u54cd\u3002"}}
{"id": "2601.15139", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.15139", "abs": "https://arxiv.org/abs/2601.15139", "authors": ["Alexandros Tsakpinis", "Nicolas Raube", "Alexander Pretschner"], "title": "Why Authors and Maintainers Link (or Don't Link) Their PyPI Libraries to Code Repositories and Donation Platforms", "comment": "12 pages, 5 tables, 1 figure", "summary": "Metadata of libraries on the Python Package Index (PyPI)-including links to source code repositories and donation platforms-plays a critical role in supporting the transparency, trust, and sustainability of open-source libraries. Yet, many packages lack such metadata, and little is known about the underlying reasons. This paper presents a large-scale empirical study combining two targeted surveys sent to 50,000 PyPI authors and maintainers. We analyze more than 1,400 responses using large language model (LLM)-based topic modeling to uncover key motivations and barriers related to linking repositories and donation platforms. While repository URLs are often linked to foster collaboration, increase transparency, and enable issue tracking, some maintainers omit them due to oversight, laziness, or the perceived irrelevance to their project. Donation platform links are reported to support open source work or receive financial contributions, but are hindered by skepticism, technical friction, and organizational constraints. Cross-cutting challenges-such as outdated links, lack of awareness, and unclear guidance-affect both types of metadata. We further assess the robustness of our topic modeling pipeline across 30 runs (84% lexical and 89% semantic similarity) and validate topic quality with 23 expert raters (Randolph's kappa = 0.55). The study contributes empirical insights into PyPI's metadata practices and provides recommendations for improving them, while also demonstrating the effectiveness of our topic modeling approach for analyzing short-text survey responses.", "AI": {"tldr": "\u5bf9PyPI\u5e93\u5143\u6570\u636e\uff08\u6e90\u7801\u4ed3\u5e93\u94fe\u63a5\u548c\u6350\u8d60\u5e73\u53f0\u94fe\u63a5\uff09\u7f3a\u5931\u539f\u56e0\u7684\u5927\u89c4\u6a21\u5b9e\u8bc1\u7814\u7a76\uff0c\u901a\u8fc75\u4e07\u5f00\u53d1\u8005\u8c03\u67e5\u548cLLM\u4e3b\u9898\u5efa\u6a21\u5206\u6790\uff0c\u63ed\u793a\u4e86\u94fe\u63a5\u52a8\u673a\u3001\u969c\u788d\u53ca\u6539\u8fdb\u5efa\u8bae\u3002", "motivation": "PyPI\u5e93\u7684\u5143\u6570\u636e\uff08\u6e90\u7801\u4ed3\u5e93\u94fe\u63a5\u548c\u6350\u8d60\u5e73\u53f0\u94fe\u63a5\uff09\u5bf9\u5f00\u6e90\u5e93\u7684\u900f\u660e\u5ea6\u3001\u4fe1\u4efb\u548c\u53ef\u6301\u7eed\u6027\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u8bb8\u591a\u5305\u7f3a\u4e4f\u6b64\u7c7b\u5143\u6570\u636e\uff0c\u4e14\u7f3a\u4e4f\u5bf9\u5176\u80cc\u540e\u539f\u56e0\u7684\u4e86\u89e3\u3002", "method": "\u5927\u89c4\u6a21\u5b9e\u8bc1\u7814\u7a76\uff0c\u54115\u4e07\u540dPyPI\u4f5c\u8005\u548c\u7ef4\u62a4\u8005\u53d1\u9001\u9488\u5bf9\u6027\u8c03\u67e5\uff0c\u6536\u96c61400\u591a\u4efd\u56de\u590d\uff0c\u4f7f\u7528\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4e3b\u9898\u5efa\u6a21\u5206\u6790\u5173\u952e\u52a8\u673a\u548c\u969c\u788d\u3002", "result": "\u6e90\u7801\u4ed3\u5e93\u94fe\u63a5\u4e3b\u8981\u7528\u4e8e\u4fc3\u8fdb\u534f\u4f5c\u3001\u589e\u52a0\u900f\u660e\u5ea6\u548c\u95ee\u9898\u8ffd\u8e2a\uff0c\u7f3a\u5931\u539f\u56e0\u5305\u62ec\u758f\u5ffd\u3001\u61d2\u60f0\u6216\u8ba4\u4e3a\u4e0e\u9879\u76ee\u65e0\u5173\uff1b\u6350\u8d60\u94fe\u63a5\u7528\u4e8e\u652f\u6301\u5f00\u6e90\u5de5\u4f5c\u6216\u83b7\u5f97\u8d22\u52a1\u8d21\u732e\uff0c\u4f46\u53d7\u5230\u6000\u7591\u3001\u6280\u672f\u6469\u64e6\u548c\u7ec4\u7ec7\u7ea6\u675f\u7684\u963b\u788d\uff1b\u5171\u540c\u6311\u6218\u5305\u62ec\u94fe\u63a5\u8fc7\u65f6\u3001\u7f3a\u4e4f\u610f\u8bc6\u548c\u6307\u5bfc\u4e0d\u6e05\u6670\u3002\u4e3b\u9898\u5efa\u6a21\u7ba1\u9053\u572830\u6b21\u8fd0\u884c\u4e2d\u8868\u73b0\u51fa84%\u8bcd\u6c47\u548c89%\u8bed\u4e49\u76f8\u4f3c\u5ea6\u7684\u7a33\u5065\u6027\u3002", "conclusion": "\u7814\u7a76\u63d0\u4f9b\u4e86PyPI\u5143\u6570\u636e\u5b9e\u8df5\u7684\u5b9e\u8bc1\u89c1\u89e3\uff0c\u63d0\u51fa\u4e86\u6539\u8fdb\u5efa\u8bae\uff0c\u540c\u65f6\u8bc1\u660e\u4e86\u57fa\u4e8eLLM\u7684\u4e3b\u9898\u5efa\u6a21\u65b9\u6cd5\u5728\u5206\u6790\u77ed\u6587\u672c\u8c03\u67e5\u56de\u590d\u4e2d\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2601.15154", "categories": ["cs.SE", "cs.CR"], "pdf": "https://arxiv.org/pdf/2601.15154", "abs": "https://arxiv.org/abs/2601.15154", "authors": ["Yoann Marquer", "Domenico Bianculli", "Lionel C. Briand"], "title": "SAGA: Detecting Security Vulnerabilities Using Static Aspect Analysis", "comment": "50 pages, 3-page appendix, 23 Figures, 11 Tables", "summary": "Python is one of the most popular programming languages; as such, projects written in Python involve an increasing number of diverse security vulnerabilities. However, existing state-of-the-art analysis tools for Python only support a few vulnerability types. Hence, there is a need to detect a large variety of vulnerabilities in Python projects.\n  In this paper, we propose the SAGA approach to detect and locate vulnerabilities in Python source code in a versatile way. SAGA includes a source code parser able to extract control- and data-flow information and to represent it as a symbolic control-flow graph, as well as a domain-specific language defining static aspects of the source code and their evolution during graph traversals. We have leveraged this language to define a library of static aspects for integrity, confidentiality, and other security-related properties.\n  We have evaluated SAGA on a dataset of 108 vulnerabilities, obtaining 100% sensitivity and 99.15% specificity, with only one false positive, while outperforming four common security analysis tools. This analysis was performed in less than 31 seconds, i.e., between 2.5 and 512.1 times faster than the baseline tools.", "AI": {"tldr": "SAGA\u662f\u4e00\u79cd\u7528\u4e8e\u68c0\u6d4bPython\u6e90\u4ee3\u7801\u6f0f\u6d1e\u7684\u9759\u6001\u5206\u6790\u65b9\u6cd5\uff0c\u901a\u8fc7\u7b26\u53f7\u63a7\u5236\u6d41\u56fe\u548c\u9886\u57df\u7279\u5b9a\u8bed\u8a00\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u68c0\u6d4b\uff0c\u5728108\u4e2a\u6f0f\u6d1e\u6570\u636e\u96c6\u4e0a\u8fbe\u5230100%\u654f\u611f\u5ea6\u548c99.15%\u7279\u5f02\u5ea6\u3002", "motivation": "Python\u4f5c\u4e3a\u6d41\u884c\u7f16\u7a0b\u8bed\u8a00\uff0c\u5176\u9879\u76ee\u5305\u542b\u8d8a\u6765\u8d8a\u591a\u7684\u5b89\u5168\u6f0f\u6d1e\uff0c\u4f46\u73b0\u6709\u5206\u6790\u5de5\u5177\u4ec5\u652f\u6301\u5c11\u6570\u6f0f\u6d1e\u7c7b\u578b\uff0c\u9700\u8981\u80fd\u591f\u68c0\u6d4b\u591a\u79cdPython\u6f0f\u6d1e\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51faSAGA\u65b9\u6cd5\uff0c\u5305\u62ec\uff1a1\uff09\u6e90\u4ee3\u7801\u89e3\u6790\u5668\u63d0\u53d6\u63a7\u5236\u6d41\u548c\u6570\u636e\u6d41\u4fe1\u606f\uff0c\u8868\u793a\u4e3a\u7b26\u53f7\u63a7\u5236\u6d41\u56fe\uff1b2\uff09\u9886\u57df\u7279\u5b9a\u8bed\u8a00\u5b9a\u4e49\u9759\u6001\u5c5e\u6027\u53ca\u5176\u5728\u56fe\u904d\u5386\u4e2d\u7684\u6f14\u5316\uff1b3\uff09\u57fa\u4e8e\u8be5\u8bed\u8a00\u6784\u5efa\u5b8c\u6574\u6027\u3001\u673a\u5bc6\u6027\u7b49\u5b89\u5168\u5c5e\u6027\u7684\u9759\u6001\u5c5e\u6027\u5e93\u3002", "result": "\u5728108\u4e2a\u6f0f\u6d1e\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0c\u83b7\u5f97100%\u654f\u611f\u5ea6\u548c99.15%\u7279\u5f02\u5ea6\uff0c\u4ec5\u4ea7\u751f1\u4e2a\u8bef\u62a5\uff0c\u4f18\u4e8e4\u4e2a\u5e38\u7528\u5b89\u5168\u5206\u6790\u5de5\u5177\u3002\u5206\u6790\u65f6\u95f4\u5c11\u4e8e31\u79d2\uff0c\u6bd4\u57fa\u7ebf\u5de5\u5177\u5feb2.5-512.1\u500d\u3002", "conclusion": "SAGA\u80fd\u591f\u4ee5\u9ad8\u7cbe\u5ea6\u548c\u9ad8\u6548\u7684\u65b9\u5f0f\u68c0\u6d4bPython\u6e90\u4ee3\u7801\u4e2d\u7684\u591a\u79cd\u5b89\u5168\u6f0f\u6d1e\uff0c\u586b\u8865\u4e86\u73b0\u6709\u5de5\u5177\u4ec5\u652f\u6301\u6709\u9650\u6f0f\u6d1e\u7c7b\u578b\u7684\u7a7a\u767d\u3002"}}
{"id": "2601.15188", "categories": ["cs.SE", "cs.AI", "cs.PL"], "pdf": "https://arxiv.org/pdf/2601.15188", "abs": "https://arxiv.org/abs/2601.15188", "authors": ["Stephan Wallraven", "Tim K\u00f6hne", "Hartmut Westenberger", "Andreas Moser"], "title": "Benchmarking Large Language Models for ABAP Code Generation: An Empirical Study on Iterative Improvement by Compiler Feedback", "comment": "20 pages, 10 figures, Author: Hartmut Westenberger (ORCID: 0009-0009-9063-8318)", "summary": "This work investigates the performance of Large Language Models (LLMs) in generating ABAP code. Despite successful applications of generative AI in many programming languages, there are hardly any systematic analyses of ABAP code generation to date. The aim of the study is to empirically analyze to what extent various LLMs can generate syntactically correct and functional ABAP code, how effectively they use compiler feedback for iterative improvement, and which task types pose special challenges. For this purpose, a benchmark with 180 tasks is conducted, consisting of adapted HumanEval tasks and practical SAP scenarios. The results show significant performance differences between the models: more powerful LLMs achieve success rates of around 75% after several iterations and benefit greatly from compiler feedback, while smaller models perform significantly weaker. Overall, the study highlights the high potential of powerful LLMs for ABAP development processes, especially in iterative error correction.", "AI": {"tldr": "LLMs\u5728\u751f\u6210ABAP\u4ee3\u7801\u65b9\u9762\u8868\u73b0\u51fa\u663e\u8457\u6027\u80fd\u5dee\u5f02\uff0c\u5f3a\u5927\u6a21\u578b\u901a\u8fc7\u8fed\u4ee3\u7f16\u8bd1\u53cd\u9988\u53ef\u8fbe75%\u6210\u529f\u7387\uff0c\u800c\u5c0f\u6a21\u578b\u8868\u73b0\u8f83\u5dee", "motivation": "\u5c3d\u7ba1\u751f\u6210\u5f0fAI\u5728\u8bb8\u591a\u7f16\u7a0b\u8bed\u8a00\u4e2d\u5e94\u7528\u6210\u529f\uff0c\u4f46ABAP\u4ee3\u7801\u751f\u6210\u7684\u7cfb\u7edf\u6027\u5206\u6790\u51e0\u4e4e\u7a7a\u767d\uff0c\u9700\u8981\u5b9e\u8bc1\u7814\u7a76LLM\u751f\u6210ABAP\u4ee3\u7801\u7684\u80fd\u529b", "method": "\u4f7f\u7528\u5305\u542b180\u4e2a\u4efb\u52a1\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u62ec\u6539\u7f16\u7684HumanEval\u4efb\u52a1\u548c\u5b9e\u9645SAP\u573a\u666f\uff0c\u8bc4\u4f30LLM\u751f\u6210\u8bed\u6cd5\u6b63\u786e\u548c\u529f\u80fd\u6027ABAP\u4ee3\u7801\u7684\u80fd\u529b\uff0c\u5e76\u6d4b\u8bd5\u5b83\u4eec\u5229\u7528\u7f16\u8bd1\u5668\u53cd\u9988\u8fdb\u884c\u8fed\u4ee3\u6539\u8fdb\u7684\u6548\u679c", "result": "\u6a21\u578b\u95f4\u5b58\u5728\u663e\u8457\u6027\u80fd\u5dee\u5f02\uff1a\u5f3a\u5927LLM\u7ecf\u8fc7\u591a\u6b21\u8fed\u4ee3\u540e\u6210\u529f\u7387\u7ea675%\uff0c\u5e76\u80fd\u4ece\u7f16\u8bd1\u5668\u53cd\u9988\u4e2d\u5927\u5e45\u53d7\u76ca\uff1b\u800c\u8f83\u5c0f\u6a21\u578b\u8868\u73b0\u660e\u663e\u8f83\u5f31", "conclusion": "\u7814\u7a76\u8868\u660e\u5f3a\u5927LLM\u5728ABAP\u5f00\u53d1\u6d41\u7a0b\u4e2d\u5177\u6709\u9ad8\u6f5c\u529b\uff0c\u7279\u522b\u662f\u5728\u8fed\u4ee3\u9519\u8bef\u4fee\u6b63\u65b9\u9762\uff0c\u4e3aABAP\u4ee3\u7801\u751f\u6210\u63d0\u4f9b\u4e86\u5b9e\u8bc1\u57fa\u7840"}}
{"id": "2601.15195", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.15195", "abs": "https://arxiv.org/abs/2601.15195", "authors": ["Ramtin Ehsani", "Sakshi Pathak", "Shriya Rawal", "Abdullah Al Mujahid", "Mia Mohammad Imran", "Preetha Chatterjee"], "title": "Where Do AI Coding Agents Fail? An Empirical Study of Failed Agentic Pull Requests in GitHub", "comment": "Accepted at International Mining Software Repositories Conference (MSR 2026)", "summary": "AI coding agents are now submitting pull requests (PRs) to software projects, acting not just as assistants but as autonomous contributors. As these agentic contributions are rapidly increasing across real repositories, little is known about how they behave in practice and why many of them fail to be merged. In this paper, we conduct a large-scale study of 33k agent-authored PRs made by five coding agents across GitHub. (RQ1) We first quantitatively characterize merged and not-merged PRs along four broad dimensions: 1) merge outcomes across task types, 2) code changes, 3) CI build results, and 4) review dynamics. We observe that tasks related to documentation, CI, and build update achieve the highest merge success, whereas performance and bug-fix tasks perform the worst. Not-merged PRs tend to involve larger code changes, touch more files, and often do not pass the project's CI/CD pipeline validation. (RQ2) To further investigate why some agentic PRs are not merged, we qualitatively analyze 600 PRs to derive a hierarchical taxonomy of rejection patterns. This analysis complements the quantitative findings in RQ1 by uncovering rejection reasons not captured by quantitative metrics, including lack of meaningful reviewer engagement, duplicate PRs, unwanted feature implementations, and agent misalignment. Together, our findings highlight key socio-technical and human-AI collaboration factors that are critical to improving the success of future agentic workflows.", "AI": {"tldr": "\u5bf9GitHub\u4e0a33k\u4e2aAI\u7f16\u7801\u4ee3\u7406\u63d0\u4ea4\u7684PR\u8fdb\u884c\u5927\u89c4\u6a21\u7814\u7a76\uff0c\u5206\u6790\u5408\u5e76\u4e0e\u672a\u5408\u5e76PR\u7684\u7279\u5f81\uff0c\u5e76\u6784\u5efa\u62d2\u7edd\u6a21\u5f0f\u7684\u5206\u7c7b\u4f53\u7cfb\u3002", "motivation": "\u968f\u7740AI\u7f16\u7801\u4ee3\u7406\u5728\u771f\u5b9e\u8f6f\u4ef6\u9879\u76ee\u4e2d\u4f5c\u4e3a\u81ea\u4e3b\u8d21\u732e\u8005\u63d0\u4ea4PR\u7684\u6570\u91cf\u5feb\u901f\u589e\u957f\uff0c\u4f46\u5bf9\u5176\u5b9e\u9645\u884c\u4e3a\u4ee5\u53ca\u4e3a\u4f55\u8bb8\u591aPR\u672a\u80fd\u5408\u5e76\u7684\u539f\u56e0\u4e86\u89e3\u751a\u5c11\u3002", "method": "1) \u5bf933k\u4e2a\u7531\u4e94\u4e2a\u7f16\u7801\u4ee3\u7406\u63d0\u4ea4\u7684PR\u8fdb\u884c\u5b9a\u91cf\u5206\u6790\uff0c\u4ece\u56db\u4e2a\u7ef4\u5ea6\u6bd4\u8f83\u5408\u5e76\u4e0e\u672a\u5408\u5e76PR\uff1a\u4efb\u52a1\u7c7b\u578b\u3001\u4ee3\u7801\u53d8\u66f4\u3001CI\u6784\u5efa\u7ed3\u679c\u3001\u8bc4\u5ba1\u52a8\u6001\uff1b2) \u5bf9600\u4e2aPR\u8fdb\u884c\u5b9a\u6027\u5206\u6790\uff0c\u6784\u5efa\u62d2\u7edd\u6a21\u5f0f\u7684\u5c42\u6b21\u5206\u7c7b\u4f53\u7cfb\u3002", "result": "\u6587\u6863\u3001CI\u548c\u6784\u5efa\u66f4\u65b0\u76f8\u5173\u4efb\u52a1\u5408\u5e76\u6210\u529f\u7387\u6700\u9ad8\uff0c\u6027\u80fd\u548cbug\u4fee\u590d\u4efb\u52a1\u8868\u73b0\u6700\u5dee\uff1b\u672a\u5408\u5e76PR\u901a\u5e38\u6d89\u53ca\u66f4\u5927\u7684\u4ee3\u7801\u53d8\u66f4\u3001\u4fee\u6539\u66f4\u591a\u6587\u4ef6\uff0c\u4e14\u7ecf\u5e38\u65e0\u6cd5\u901a\u8fc7CI/CD\u6d41\u6c34\u7ebf\u9a8c\u8bc1\uff1b\u5b9a\u6027\u5206\u6790\u63ed\u793a\u4e86\u7f3a\u4e4f\u6709\u610f\u4e49\u7684\u8bc4\u5ba1\u53c2\u4e0e\u3001\u91cd\u590dPR\u3001\u4e0d\u9700\u8981\u7684\u529f\u80fd\u5b9e\u73b0\u548c\u4ee3\u7406\u9519\u4f4d\u7b49\u62d2\u7edd\u539f\u56e0\u3002", "conclusion": "\u7814\u7a76\u5f3a\u8c03\u4e86\u6539\u8fdb\u672a\u6765\u4ee3\u7406\u5de5\u4f5c\u6d41\u6210\u529f\u7684\u5173\u952e\u793e\u4f1a\u6280\u672f\u548c\u4eba\u673a\u534f\u4f5c\u56e0\u7d20\uff0c\u8fd9\u4e9b\u56e0\u7d20\u5bf9\u4e8e\u63d0\u9ad8AI\u7f16\u7801\u4ee3\u7406\u7684\u8d21\u732e\u8d28\u91cf\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2601.15232", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.15232", "abs": "https://arxiv.org/abs/2601.15232", "authors": ["Niful Islam", "Ragib Shahriar Ayon", "Deepak George Thomas", "Shibbir Ahmed", "Mohammad Wardat"], "title": "When Agents Fail: A Comprehensive Study of Bugs in LLM Agents with Automated Labeling", "comment": "A version of this paper has been submitted to ACM Transactions on Software Engineering and Methodology", "summary": "Large Language Models (LLMs) have revolutionized intelligent application development. While standalone LLMs cannot perform any actions, LLM agents address the limitation by integrating tools. However, debugging LLM agents is difficult and costly as the field is still in it's early stage and the community is underdeveloped. To understand the bugs encountered during agent development, we present the first comprehensive study of bug types, root causes, and effects in LLM agent-based software. We collected and analyzed 1,187 bug-related posts and code snippets from Stack Overflow, GitHub, and Hugging Face forums, focused on LLM agents built with seven widely used LLM frameworks as well as custom implementations. For a deeper analysis, we have also studied the component where the bug occurred, along with the programming language and framework. This study also investigates the feasibility of automating bug identification. For that, we have built a ReAct agent named BugReAct, equipped with adequate external tools to determine whether it can detect and annotate the bugs in our dataset. According to our study, we found that BugReAct equipped with Gemini 2.5 Flash achieved a remarkable performance in annotating bug characteristics with an average cost of 0.01 USD per post/code snippet.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u5168\u9762\u7814\u7a76LLM\u667a\u80fd\u4f53\u5f00\u53d1\u4e2d\u7684bug\u7c7b\u578b\u3001\u6839\u672c\u539f\u56e0\u548c\u5f71\u54cd\uff0c\u5206\u6790\u4e861187\u4e2abug\u76f8\u5173\u5e16\u5b50\uff0c\u5e76\u6784\u5efaBugReAct\u667a\u80fd\u4f53\u5b9e\u73b0\u81ea\u52a8\u5316bug\u8bc6\u522b\u3002", "motivation": "LLM\u667a\u80fd\u4f53\u901a\u8fc7\u96c6\u6210\u5de5\u5177\u6269\u5c55\u4e86LLM\u80fd\u529b\uff0c\u4f46\u8c03\u8bd5\u56f0\u96be\u4e14\u6210\u672c\u9ad8\uff0c\u8be5\u9886\u57df\u4ecd\u5904\u4e8e\u65e9\u671f\u9636\u6bb5\uff0c\u793e\u533a\u53d1\u5c55\u4e0d\u6210\u719f\uff0c\u9700\u8981\u7cfb\u7edf\u7814\u7a76\u5f00\u53d1\u4e2d\u9047\u5230\u7684bug\u95ee\u9898\u3002", "method": "\u4eceStack Overflow\u3001GitHub\u548cHugging Face\u8bba\u575b\u6536\u96c61187\u4e2abug\u76f8\u5173\u5e16\u5b50\u548c\u4ee3\u7801\u7247\u6bb5\uff0c\u5206\u67907\u4e2a\u4e3b\u6d41LLM\u6846\u67b6\u53ca\u81ea\u5b9a\u4e49\u5b9e\u73b0\u7684bug\uff1b\u6784\u5efaBugReAct\u667a\u80fd\u4f53\uff08\u57fa\u4e8eReAct\u67b6\u6784\uff0c\u914d\u5907\u5916\u90e8\u5de5\u5177\uff09\u6d4b\u8bd5\u81ea\u52a8\u5316bug\u8bc6\u522b\u7684\u53ef\u884c\u6027\u3002", "result": "\u7814\u7a76\u53d1\u73b0BugReAct\u667a\u80fd\u4f53\uff08\u4f7f\u7528Gemini 2.5 Flash\uff09\u5728\u6807\u6ce8bug\u7279\u5f81\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u5e73\u5747\u6bcf\u4e2a\u5e16\u5b50/\u4ee3\u7801\u7247\u6bb5\u7684\u6210\u672c\u4ec5\u4e3a0.01\u7f8e\u5143\u3002", "conclusion": "\u8fd9\u662f\u9996\u4e2a\u5168\u9762\u7814\u7a76LLM\u667a\u80fd\u4f53bug\u7684\u5de5\u4f5c\uff0c\u4e3a\u5f00\u53d1\u8005\u63d0\u4f9b\u4e86bug\u5206\u7c7b\u548c\u6839\u672c\u539f\u56e0\u7684\u6df1\u5165\u7406\u89e3\uff0c\u5e76\u5c55\u793a\u4e86\u81ea\u52a8\u5316bug\u8bc6\u522b\u7684\u53ef\u884c\u6027\uff0c\u6709\u52a9\u4e8e\u964d\u4f4eLLM\u667a\u80fd\u4f53\u5f00\u53d1\u8c03\u8bd5\u6210\u672c\u3002"}}
