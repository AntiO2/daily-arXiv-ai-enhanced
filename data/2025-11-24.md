<div id=toc></div>

# Table of Contents

- [cs.SE](#cs.SE) [Total: 12]
- [cs.DC](#cs.DC) [Total: 2]
- [cs.DB](#cs.DB) [Total: 3]


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [1] [Large language models for automated PRISMA 2020 adherence checking](https://arxiv.org/abs/2511.16707)
*Yuki Kataoka,Ryuhei So,Masahiro Banno,Yasushi Tsujimoto,Tomohiro Takayama,Yosuke Yamagishi,Takahiro Tsuge,Norio Yamamoto,Chiaki Suda,Toshi A. Furukawa*

Main category: cs.SE

TL;DR: 构建了一个包含108篇CC许可系统评价的基准数据集，评估了10个LLM在5种输入格式下对PRISMA 2020指南的依从性评估能力。提供结构化检查表显著提高了准确性，最佳模型Qwen3-Max在完整数据集上达到95.1%的敏感性和49.3%的特异性。


<details>
  <summary>Details</summary>
Motivation: 解决同行评审过程中PRISMA 2020指南依从性评估缺乏可共享基准的问题，为自动化评估提供可靠工具。

Method: 构建版权感知基准数据集，评估10个LLM在5种输入格式下的表现，包括开发队列和独立验证队列的对比分析。

Result: 结构化检查表输入（Markdown、JSON、XML、纯文本）准确率达78.7-79.7%，显著高于仅使用手稿的45.21%。不同模型准确率在70.6-82.8%之间，Qwen3-Max在完整数据集上表现最佳。

Conclusion: 提供结构化检查表可显著改善基于LLM的PRISMA评估，但在编辑决策前仍需人类专家验证。

Abstract: Evaluating adherence to PRISMA 2020 guideline remains a burden in the peer review process. To address the lack of shareable benchmarks, we constructed a copyright-aware benchmark of 108 Creative Commons-licensed systematic reviews and evaluated ten large language models (LLMs) across five input formats. In a development cohort, supplying structured PRISMA 2020 checklists (Markdown, JSON, XML, or plain text) yielded 78.7-79.7% accuracy versus 45.21% for manuscript-only input (p less than 0.0001), with no differences between structured formats (p>0.9). Across models, accuracy ranged from 70.6-82.8% with distinct sensitivity-specificity trade-offs, replicated in an independent validation cohort. We then selected Qwen3-Max (a high-sensitivity open-weight model) and extended evaluation to the full dataset (n=120), achieving 95.1% sensitivity and 49.3% specificity. Structured checklist provision substantially improves LLM-based PRISMA assessment, though human expert verification remains essential before editorial decisions.

</details>


### [2] [Multi-Agent Code Verification with Compound Vulnerability Detection](https://arxiv.org/abs/2511.16708)
*Shreshth Rajan*

Main category: cs.SE

TL;DR: CodeX-Verify是一个多代理系统，专门检测LLM生成的代码中的bug，能捕获76.1%的bug，比单代理系统准确率提高39.7个百分点，运行速度快，无需测试执行。


<details>
  <summary>Details</summary>
Motivation: 现有工具只能捕获65%的bug且假阳性率达35%，而LLM生成的代码中bug率很高（SWE-bench中29.6%的补丁失败，BaxBench中62%的解决方案有漏洞）。

Method: 使用四个专门代理检测不同类型bug的多代理系统，数学证明不同检测模式的代理组合能发现更多bug，代理间相关性p=0.05-0.25。

Result: 在99个带验证标签的代码样本上测试，系统捕获76.1%的bug，匹配最佳现有方法但运行更快；多代理比单代理准确率提高39.7个百分点（从32.8%到72.4%）；最佳双代理组合达到79.3%准确率；在300个真实补丁上测试，每个样本运行时间<200ms。

Conclusion: 多代理系统能有效检测LLM生成的代码bug，准确率高且实用，同时发现同一代码中的多个漏洞会带来指数级风险增加（如SQL注入加凭证泄露风险增加15倍）。

Abstract: LLMs generate buggy code: 29.6% of SWE-bench "solved" patches fail, 62% of BaxBench solutions have vulnerabilities, and existing tools only catch 65% of bugs with 35% false positives. We built CodeX-Verify, a multi-agent system that uses four specialized agents to detect different types of bugs. We prove mathematically that combining agents with different detection patterns finds more bugs than any single agent when the agents look for different problems, confirmed by measuring agent correlation of p = 0.05--0.25. We also show that multiple vulnerabilities in the same code create exponentially more risk than previously thought--SQL injection plus exposed credentials creates 15x more danger (risk 300 vs. 20) than traditional models predict. Testing on 99 code samples with verified labels shows our system catches 76.1% of bugs, matching the best existing method while running faster and without test execution. We tested 15 different agent combinations and found that using multiple agents improves accuracy by 39.7 percentage points (from 32.8% to 72.4%) compared to single agents, with gains of +14.9pp, +13.5pp, and +11.2pp for agents 2, 3, and 4. The best two-agent combination reaches 79.3% accuracy. Testing on 300 real patches from Claude Sonnet 4.5 runs in under 200ms per sample, making this practical for production use.

</details>


### [3] [Is the Cure Still Worse Than the Disease? Test Overfitting by LLMs in Automated Program Repair](https://arxiv.org/abs/2511.16858)
*Toufique Ahmed,Jatin Ganhotra,Avraham Shinnar,Martin Hirzel*

Main category: cs.SE

TL;DR: 研究探讨了在大型语言模型时代，程序自动修复中的测试过拟合问题是否仍然存在，使用SWE-bench仓库级任务进行实验分析。


<details>
  <summary>Details</summary>
Motivation: 程序自动修复技术存在测试过拟合问题，即修复后的代码在可见测试上通过但在隐藏测试集上失败。虽然这个问题在大型语言模型兴起前已被研究，但需要验证在当前技术背景下是否仍然显著。

Method: 使用SWE-bench仓库级任务进行实验研究，分析程序修复中的测试过拟合现象。

Result: 实验结果表明测试过拟合问题在当今基于大型语言模型的程序修复中仍然存在。

Conclusion: 即使在大型语言模型时代，程序自动修复中的测试过拟合问题仍需关注和解决。

Abstract: Automated program repair has been shown to be susceptible to generating repaired code that passes on seen tests but fails on a hold-out set of hidden tests. This problem, dubbed test overfitting, has been identified and studied before the rise of large language models. We experimentally study how much test overfitting is still a problem today, using repository-level SWE-bench tasks.

</details>


### [4] [MOOT: a Repository of Many Multi-Objective Optimization Tasks](https://arxiv.org/abs/2511.16882)
*Tim Menzies,Tao Chen,Yulong Ye,Kishan Kumar Ganguly,Amirali Rayegan,Srinath Srinivasan,Andre Lustosa*

Main category: cs.SE

TL;DR: MOOT是一个多目标优化任务库，包含120+个来自软件工程研究论文的任务，涵盖软件配置、云调优、项目健康等多个领域，旨在促进软件工程中多目标权衡的研究。


<details>
  <summary>Details</summary>
Motivation: 软件工程师需要在竞争性目标之间做出权衡决策（如速度vs成本、安全vs可用性等），但现有研究工具不足，导致研究人员难以探索这些权衡，工业实践者也无法优化产品。

Method: 构建MOOT知识库，收集来自近期软件工程研究论文的120多个多目标优化任务，涵盖软件配置、云调优、项目健康、过程建模、超参数优化等领域，并在GitHub上开源。

Result: MOOT提供了120多个多目标优化任务，这些数据能够支持数十个新的研究问题，为软件工程权衡研究提供了丰富的数据基础。

Conclusion: MOOT知识库填补了软件工程多目标优化研究的数据空白，为研究者和实践者提供了探索竞争性目标权衡的工具，有望推动该领域的研究进展。

Abstract: Software engineers must make decisions that trade off competing goals (faster vs. cheaper, secure vs. usable, accurate vs. interpretable, etc.). Despite MSR's proven techniques for exploring such goals, researchers still struggle with these trade-offs. Similarly, industrial practitioners deliver sub-optimal products since they lack the tools needed to explore these trade-offs.
  To enable more research in this important area, we introduce MOOT, a repository of multi-objective optimization tasks taken from recent SE research papers. MOOT's tasks cover software configuration, cloud tuning, project health, process modeling, hyperparameter optimization, and more. Located at github.com/timm/moot, MOOT's current 120+ tasks are freely available under an MIT license (and we invite community contributions). As shown here, this data enables dozens of novel research questions.

</details>


### [5] [ReVul-CoT: Towards Effective Software Vulnerability Assessment with Retrieval-Augmented Generation and Chain-of-Thought Prompting](https://arxiv.org/abs/2511.17027)
*Zhijie Chen,Xiang Chen,Ziming Li,Jiacheng Xue,Chaoyang Gao*

Main category: cs.SE

TL;DR: ReVul-CoT框架结合检索增强生成(RAG)和思维链(COT)提示，通过动态检索漏洞知识库和逐步推理，显著提升了基于大语言模型的软件漏洞评估性能。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在软件漏洞评估中存在两个主要局限：缺乏领域专业知识，以及依赖浅层模式匹配而非深度上下文推理，难以充分理解复杂代码语义及其安全影响。

Method: 提出ReVul-CoT框架，集成RAG模块从构建的本地知识库（包含NVD、CWE等权威漏洞数据）动态检索相关信息，并基于DeepSeek-V3.1使用COT提示引导模型对可利用性、影响范围等进行逐步推理。

Result: 在12,070个漏洞数据集上的实验表明，ReVul-CoT在MCC指标上比最先进基线提升16.50%-42.26%，在准确率、F1分数和MCC上分别比最佳基线提升10.43%、15.86%和16.50%。消融研究验证了动态检索、知识集成和COT推理的贡献。

Conclusion: 结合RAG与COT提示能显著增强基于LLM的软件漏洞评估，为未来研究指明了有前景的方向。

Abstract: Context: Software Vulnerability Assessment (SVA) plays a vital role in evaluating and ranking vulnerabilities in software systems to ensure their security and reliability. Objective: Although Large Language Models (LLMs) have recently shown remarkable potential in SVA, they still face two major limitations. First, most LLMs are trained on general-purpose corpora and thus lack domain-specific knowledge essential for effective SVA. Second, they tend to rely on shallow pattern matching instead of deep contextual reasoning, making it challenging to fully comprehend complex code semantics and their security implications. Method: To alleviate these limitations, we propose a novel framework ReVul-CoT that integrates Retrieval-Augmented Generation (RAG) with Chain-of-Thought (COT) prompting. In ReVul-CoT, the RAG module dynamically retrieves contextually relevant information from a constructed local knowledge base that consolidates vulnerability data from authoritative sources (such as NVD and CWE), along with corresponding code snippets and descriptive information. Building on DeepSeek-V3.1, CoT prompting guides the LLM to perform step-by-step reasoning over exploitability, impact scope, and related factors Results: We evaluate ReVul-CoT on a dataset of 12,070 vulnerabilities. Experimental results show that ReVul-CoT outperforms state-of-the-art SVA baselines by 16.50%-42.26% in terms of MCC, and outperforms the best baseline by 10.43%, 15.86%, and 16.50% in Accuracy, F1-score, and MCC, respectively. Our ablation studies further validate the contributions of considering dynamic retrieval, knowledge integration, and CoT-based reasoning. Conclusion: Our results demonstrate that combining RAG with CoT prompting significantly enhances LLM-based SVA and points out promising directions for future research.

</details>


### [6] [UI-CUBE: Enterprise-Grade Computer Use Agent Benchmarking Beyond Task Accuracy to Operational Reliability](https://arxiv.org/abs/2511.17131)
*Horia Cristescu,Charles Park,Trong Canh Nguyen,Sergiu Talmacel,Alexandru-Gabriel Ilie,Stefan Adam*

Main category: cs.SE

TL;DR: UI-CUBE是一个系统性的计算机使用代理基准测试，包含226个任务，旨在揭示当前CUAs在企业部署准备度方面的基本架构限制。评估显示CUAs在简单UI交互上表现尚可(67-85%)，但在复杂工作流中性能急剧下降至9-19%，表明存在根本性的架构问题。


<details>
  <summary>Details</summary>
Motivation: 当前CUA基准测试主要衡量任务完成度，但对企业部署准备度评估有限，过于强调功能正确性而忽视了生产系统所需的操作可靠性。需要开发能暴露CUAs基本架构限制的系统性基准。

Method: UI-CUBE包含226个任务，分为两个难度层级：简单UI交互(136个任务)和复杂工作流(90个任务，包括50个复制粘贴任务和40个企业应用场景)。采用系统界面变化覆盖、多分辨率测试和通过应用状态自动验证任务成功的方法。

Result: 评估五个最先进模型显示能力悬崖而非渐进性能下降：简单UI交互成功率67-85%(人类97.9%)，复杂工作流急剧下降至9-19%。人类评估者在复杂任务上仅达61.2%，为CUAs设定了现实性能上限。

Conclusion: 当前CUAs可以操作单个界面元素，但还不能作为可靠的工作流自动化工具。这种不连续性能模式表明存在内存管理、分层规划和状态协调方面的基本架构限制，而非可通过更好训练或提示解决的增量能力差距。

Abstract: While current Computer Use Agent (CUA) benchmarks measure task completion effectively, they provide limited assessment of enterprise deployment readiness, emphasizing functional correctness over the operational reliability required for production systems. We present UI-CUBE (UiPath Computer Use BEnchmark), a systematic benchmark comprising 226 tasks across two difficulty tiers designed to expose fundamental architectural limitations in current CUAs. Our evaluation covers simple UI interactions (136 tasks) and complex workflows including copy-paste tasks (50 tasks) and enterprise application scenarios (40 tasks), with systematic interface variation coverage, multi-resolution testing and automated validation of task success through the application state. Evaluation of five state-of-the-art models reveals a sharp capability cliff rather than gradual performance degradation. Simple UI interactions achieve 67-85% success rates (compared to 97.9% human performance), but complex workflows drop precipitously to 9-19%. Human evaluators with no prior application experience achieve only 61.2% on complex tasks despite near-perfect performance on simple tasks, establishing realistic performance ceilings. This discontinuous performance pattern -- where agents achieve 68-87% of human performance on simple tasks but only 15-32% on complex workflows -- indicates fundamental architectural limitations in memory management, hierarchical planning, and state coordination rather than incremental capability gaps addressable through better training or prompting. UI-CUBE functions as an enterprise-readiness diagnostic, revealing that while current CUAs can manipulate individual interface elements, they cannot yet function as reliable workflow automation tools. These findings provide architectural insights essential for developing production-ready CUAs capable of managing complex, multi-step enterprise processes.

</details>


### [7] [SlsReuse: LLM-Powered Serverless Function Reuse](https://arxiv.org/abs/2511.17262)
*Jinfeng Wen,Yuehan Sun*

Main category: cs.SE

TL;DR: SlsReuse是首个基于大语言模型的服务器less函数重用框架，通过构建可重用函数库、学习统一语义增强表示，并结合意图感知发现和多级剪枝策略，显著提升了函数推荐的准确性。


<details>
  <summary>Details</summary>
Motivation: 服务器less计算虽然降低了运维开销，但新手开发者需要适应平台特定的编程风格，从头开发函数耗时且易错。函数重用是解决这些挑战的有效方法，但现有技术由于任务描述与异构函数实现之间的语义鸿沟而不足。

Method: SlsReuse首先构建可重用函数库作为知识基础，然后通过有效的提示工程和少样本提示学习异构函数的统一语义增强表示，捕获代码意图、目标平台、编程语言和云服务。最后，给定自然语言任务查询，执行意图感知发现结合多级剪枝策略和相似性匹配。

Result: 在110个任务查询的精选数据集上评估，基于ChatGPT-4o的SlsReuse在Recall@10指标上达到91.20%，比最先进的基线方法提高了24.53个百分点。

Conclusion: SlsReuse通过利用大语言模型成功弥合了开发者需求与函数语义之间的差距，为服务器less函数重用提供了有效的解决方案。

Abstract: Serverless computing has rapidly emerged as a popular cloud computing paradigm. It enables developers to implement function-level tasks, i.e., serverless functions, without managing infrastructure. While reducing operational overhead, it poses challenges, especially for novice developers. Developing functions from scratch requires adapting to heterogeneous, platform-specific programming styles, making the process time-consuming and error-prone. Function reuse offers a promising solution to address these challenges. However, research on serverless computing lacks a dedicated approach for function recommendation. Existing techniques from traditional contexts remain insufficient due to the semantic gap between task descriptions and heterogeneous function implementations. Advances in large language models (LLMs), pre-trained on large-scale corpora, create opportunities to bridge this gap by aligning developer requirements with function semantics.
  This paper presents SlsReuse, the first LLM-powered framework for serverless function reuse. Specifically, SlsReuse first constructs a reusable function repository serving as a foundational knowledge base. Then, it learns unified semantic-enhanced representations of heterogeneous functions through effective prompt engineering with few-shot prompting, capturing implicit code intent, target platforms, programming languages, and cloud services. Finally, given a natural language task query, SlsReuse performs intent-aware discovery combined with a multi-level pruning strategy and similarity matching. We evaluate SlsReuse on a curated dataset of 110 task queries. Built on ChatGPT-4o, one of the most representative LLMs, SlsReuse achieves Recall@10 of 91.20%, exceeding the state-of-the-art baseline by 24.53 percentage points.

</details>


### [8] [Detecting Performance-Relevant Changes in Configurable Software Systems](https://arxiv.org/abs/2511.17271)
*Sebastian Böhm,Florian Sattler,Norbert Siegmund,Sven Apel*

Main category: cs.SE

TL;DR: ConfFLARE通过识别与性能相关代码的数据流交互来检测性能回归，并基于相关特征选择配置子集进行性能分析，显著减少了测试配置数量。


<details>
  <summary>Details</summary>
Motivation: 软件系统的性能是易变的，需要频繁的性能分析来保持对系统性能行为的了解。在存在可配置性的情况下，对所有配置进行性能测量成本高昂，而配置抽样方法无法保证完整性，可能会遗漏仅影响少数配置的性能回归。

Method: ConfFLARE通过识别与性能相关代码的数据流交互来估计变更是否可能影响性能，并提取参与此类交互的软件特征。基于这些特征，可以选择相关配置子集来集中性能分析工作。

Result: 在合成和真实世界软件系统的研究中，ConfFLARE在几乎所有情况下都能正确检测性能回归，并在除两个案例外的所有情况下识别出相关特征，平均减少79%（合成）和70%（真实世界）的测试配置数量，节省了数小时的性能测试时间。

Conclusion: ConfFLARE提供了一种有效的替代方法来解决性能测试成本问题，通过智能选择相关配置子集，在保证检测性能回归的同时显著降低了测试工作量。

Abstract: Performance is a volatile property of a software system and frequent performance profiling is required to keep the knowledge about a software system's performance behavior up to date. Repeating all performance measurements after every revision is a cost-intensive task, especially in the presence of configurability, where one has to measure multiple configurations to obtain a comprehensive picture. Configuration sampling is a common approach to control the measurement cost. However, it cannot guarantee completeness and might miss performance regressions, especially if they only affect few configurations. As an alternative to solve the cost reduction problem, we present ConfFLARE: ConfFLARE estimates whether a change potentially impacts performance by identifying data-flow interactions with performance-relevant code and extracts which software features participate in such interactions. Based on these features, we can select a subset of relevant configurations to focus performance profiling efforts on. In a study conducted on both, synthetic and real-world software systems, ConfFLARE correctly detects performance regressions in almost all cases and identifies relevant features in all but two cases, reducing the number of configurations to be tested on average by $79\%$ for synthetic and by $70\%$ for real-world regression scenarios saving hours of performance testing time.

</details>


### [9] [Framework Matters: Energy Efficiency of UI Automation Testing Frameworks](https://arxiv.org/abs/2511.17303)
*Timmie M. R. Lagermann,Kristina Sophia Carter,Su Mei Gwen Ho,Luís Cruz,Kerstin Eder,Maja H. Kirkeby*

Main category: cs.SE

TL;DR: 研究比较了四种Web UI自动化测试框架的能耗表现，发现不同框架执行相同UI操作的能耗差异可达6倍，Puppeteer在多数操作中最节能，Nightwatch最耗能。


<details>
  <summary>Details</summary>
Motivation: 研究旨在确定UI自动化测试框架的能耗特性，为开发者在测试特定UI操作时提供能耗透明的决策依据。

Method: 在受控的客户端-服务器环境中使用外部功率测量，对每种UI操作（刷新、点击变体、复选框、拖放、文本输入、滚动）重复执行35次。

Result: 不同框架和操作的能耗差异显著：Puppeteer在左击、右击、双击、复选框和文本输入操作中最节能；Selenium在刷新和滚动操作中最节能；Nightwatch通常能耗最高。相同操作在不同框架间的能耗差异可达6倍。

Conclusion: 为UI自动化测试框架提供能耗透明度，使开发者能够针对特定UI操作做出明智的节能测试决策。

Abstract: We examine per action energy consumption across four web user interface (UI) automation testing frameworks to determine whether consistent tendencies can guide energy-aware test design. Using a controlled client-server setup with external power metering, we repeat each UI action (refresh, click variants, checkbox, drag&drop, input-text, scroll) 35 times. Across each of the actions, energy costs vary by both framework and action. Puppeteer is the most efficient for left-click, right-click, double-click, checkbox, and input-text; Selenium is the most efficient for refresh and scroll; Nightwatch is generally the least energy efficient. The energy cost of performing the same action varied by up to a factor of six depending on the framework. This indicates that providing transparency of energy consumption for UI automation testing frameworks allows developers to make informed, energy-aware decisions when testing a specific UI action.

</details>


### [10] [Agentic Program Verification](https://arxiv.org/abs/2511.17330)
*Haoxin Tu,Huan Zhao,Yahui Song,Mehtab Zafar,Ruijie Meng,Abhik Roychoudhury*

Main category: cs.SE

TL;DR: AutoRocq是首个用于程序验证的LLM智能体，通过迭代精化循环与Rocq定理证明器协作，实现自主的程序验证，无需大量训练数据。


<details>
  <summary>Details</summary>
Motivation: 随着AI生成代码的普及，需要AI智能体来验证大量生成的代码。程序验证比一般数学推理更具结构性和上下文丰富性，因此开发能够自主进行程序验证的AI智能体具有重要意义。

Method: 采用LLM智能体与Rocq定理证明器协作的方法，通过迭代精化循环学习并改进证明。智能体从定理证明器获取上下文和反馈，自主构建证明树结构。

Result: 在SV-COMP基准测试和Linux内核模块上的实验评估显示，该方法在实现自动化程序验证方面具有良好效果。

Conclusion: AutoRocq验证智能体可以与AI代码生成智能体集成，实现生成-验证循环，推动可信自动编程愿景的实现。

Abstract: Automatically generated code is gaining traction recently, owing to the prevalence of Large Language Models (LLMs). Further, the AlphaProof initiative has demonstrated the possibility of using AI for general mathematical reasoning. Reasoning about computer programs (software) can be accomplished via general mathematical reasoning; however, it tends to be more structured and richer in contexts. This forms an attractive proposition, since then AI agents can be used to reason about voluminous code that gets generated by AI.
  In this work, we present a first LLM agent, AutoRocq, for conducting program verification. Unlike past works, which rely on extensive training of LLMs on proof examples, our agent learns on-the-fly and improves the proof via an iterative refinement loop. The iterative improvement of the proof is achieved by the proof agent communicating with the Rocq (formerly Coq) theorem prover to get additional context and feedback. The final result of the iteration is a proof derivation checked by the Rocq theorem prover. In this way, our proof construction involves autonomous collaboration between the proof agent and the theorem prover. This autonomy facilitates the search for proofs and decision-making in deciding on the structure of the proof tree.
  Experimental evaluation on SV-COMP benchmarks and on Linux kernel modules shows promising efficacy in achieving automated program verification. As automation in code generation becomes more widespread, we posit that our proof agent can be potentially integrated with AI coding agents to achieve a generate and validate loop, thus moving closer to the vision of trusted automatic programming.

</details>


### [11] [Exploring Scientific Debt: Harnessing AI for SATD Identification in Scientific Software](https://arxiv.org/abs/2511.17368)
*Eric L. Melin,Ahmed Musa Awon,Nasir U. Eisty,Neil A. Ernst,Shurui Zhou*

Main category: cs.SE

TL;DR: 本研究探索了科学软件中的自认技术债务，发现科学软件比通用软件包含9.25倍的科学债务和4.93倍的SATD，并评估了基于transformer的SATD识别模型。


<details>
  <summary>Details</summary>
Motivation: 科学软件中的技术债务对研究结果的准确性和可重复性构成威胁，但SATD与科学软件之间的关系尚未得到充分探索。

Method: 分析了27个科学和通用软件仓库，在67,066个标注代码注释上微调比较了10个基于transformer的模型（参数范围1亿-70亿）。

Result: 科学软件包含显著更多的科学债务和SATD，最佳模型性能优于现有方法。

Conclusion: 研究揭示了科学软件中SATD的特殊性及其对质量和科学有效性的影响，为开发者和研究人员提供了管理技术债务的策略。

Abstract: Developers often leave behind clues in their code, admitting where it falls short, known as Self-Admitted Technical Debt (SATD). In the world of Scientific Software (SSW), where innovation moves fast and collaboration is key, such debt is not just common but deeply impactful. As research relies on accurate and reproducible results, accumulating SATD can threaten the very foundations of scientific discovery. Yet, despite its significance, the relationship between SATD and SSW remains largely unexplored, leaving a crucial gap in understanding how to manage SATD in this critical domain. This study explores SATD in SSW repositories, comparing SATD in scientific versus general-purpose open-source software and evaluating transformer-based models for SATD identification. We analyzed SATD in 27 scientific and general-purpose repositories across multiple domains and languages. We fine-tuned and compared 10 transformer-based models (100M-7B parameters) on 67,066 labeled code comments. SSW contains 9.25x more Scientific Debt and 4.93x more SATD than general-purpose software due to complex computations, domain constraints, and evolving research needs. Furthermore, our best model outperforms existing ones. This study uncovers how SATD in SSW differs from general software, revealing its impact on quality and scientific validity. By recognizing these challenges, developers and researchers can adopt smarter strategies to manage debt and safeguard the integrity of scientific discovery.

</details>


### [12] [CREST: Improving Interpretability and Effectiveness of Troubleshooting at Ericsson through Criterion-Specific Trouble Report Retrieval](https://arxiv.org/abs/2511.17417)
*Soroush Javdan,Pragash Krishnamoorthy,Olga Baysal*

Main category: cs.SE

TL;DR: CREST是一个基于多标准集成学习的故障报告检索系统，通过为不同故障标准训练专门模型并集成输出，显著提升了检索准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 电信行业快速发展需要高效的故障排除流程，但Ericsson生产系统中的故障报告数据复杂且量大，包含反映故障不同方面的多种标准，给检索系统带来挑战。

Method: 提出CREST方法，为不同的故障报告标准训练专门模型，然后集成这些专门模型的输出来捕获多样化和互补的信号，从而提高检索效果和可解释性。

Result: 在Ericsson内部故障报告子集上的实验表明，基于标准专门化的模型在关键评估指标上显著优于单一模型方法。

Conclusion: 所有目标标准对于优化检索系统性能都很重要，CREST方法通过提供每个标准的相关性分数，帮助用户理解特定故障报告被检索的原因，支持更快的故障解决和软件维护。

Abstract: The rapid evolution of the telecommunication industry necessitates efficient troubleshooting processes to maintain network reliability, software maintainability, and service quality. Trouble Reports (TRs), which document issues in Ericsson's production system, play a critical role in facilitating the timely resolution of software faults. However, the complexity and volume of TR data, along with the presence of diverse criteria that reflect different aspects of each fault, present challenges for retrieval systems. Building on prior work at Ericsson, which utilized a two-stage workflow, comprising Initial Retrieval (IR) and Re-Ranking (RR) stages, this study investigates different TR observation criteria and their impact on the performance of retrieval models. We propose \textbf{CREST} (\textbf{C}riteria-specific \textbf{R}etrieval via \textbf{E}nsemble of \textbf{S}pecialized \textbf{T}R models), a criterion-driven retrieval approach that leverages specialized models for different TR fields to improve both effectiveness and interpretability, thereby enabling quicker fault resolution and supporting software maintenance. CREST utilizes specialized models trained on specific TR criteria and aggregates their outputs to capture diverse and complementary signals. This approach leads to enhanced retrieval accuracy, better calibration of predicted scores, and improved interpretability by providing relevance scores for each criterion, helping users understand why specific TRs were retrieved. Using a subset of Ericsson's internal TRs, this research demonstrates that criterion-specific models significantly outperform a single model approach across key evaluation metrics. This highlights the importance of all targeted criteria used in this study for optimizing the performance of retrieval systems.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [13] [MicroMoE: Fine-Grained Load Balancing for Mixture-of-Experts with Token Scheduling](https://arxiv.org/abs/2511.16947)
*Chenqi Zhao,Wenfei Wu,Linhai Song,Yuchen Xu*

Main category: cs.DC

TL;DR: MicroEP是一种新颖的并行化策略，通过跨GPU的高效token调度实现MoE系统中细粒度的负载均衡。MicroMoE系统基于此策略，相比最先进系统可将端到端训练吞吐量提升高达47.6%。


<details>
  <summary>Details</summary>
Motivation: MoE方法在扩展深度学习模型方面很有前景，但其动态特性导致专家间负载不均衡，严重影响训练效率。现有解决方案要么牺牲模型精度，要么引入额外系统开销，无法实现细粒度负载均衡。

Method: 提出MicroEP并行化策略，通过跨GPU的高效token调度在每个微批次中实现最优负载均衡。基于此构建了MicroMoE分布式MoE训练系统。

Result: 实验结果表明，MicroMoE相比最先进系统可将端到端训练吞吐量提升高达47.6%，并且几乎始终在GPU间实现最优负载均衡。

Conclusion: MicroEP策略和MicroMoE系统有效解决了MoE训练中的负载不均衡问题，显著提升了训练效率，同时保持了模型精度。

Abstract: Mixture-of-Experts (MoE) has emerged as a promising approach to scale up deep learning models due to its significant reduction in computational resources. However, the dynamic nature of MoE leads to load imbalance among experts, severely impacting training efficiency. While previous research has attempted to address the load balancing challenge, existing solutions either compromise model accuracy or introduce additional system overhead. As a result, they fail to achieve fine-grained load balancing, which is crucial to optimizing training efficiency.
  We propose MicroEP, a novel parallelization strategy to achieve fine-grained load balancing in MoE systems. MicroEP is capable of achieving optimal load balancing in every micro-batch through efficient token scheduling across GPUs. Furthermore, we propose MicroMoE, an efficient distributed MoE training system with MicroEP's load balancing capabilities. Our experimental results demonstrate that MicroMoE improves the end-to-end training throughput by up to 47.6% compared with the state-of-the-art system, and almost consistently achieves optimal load balance among GPUs.

</details>


### [14] [Modeling Anomaly Detection in Cloud Services: Analysis of the Properties that Impact Latency and Resource Consumption](https://arxiv.org/abs/2511.17119)
*Gabriel Job Antunes Grabher,Fumio Machida,Thomas Ropars*

Main category: cs.DC

TL;DR: 研究性能异常检测器的特性如何优化云服务中性能与成本的权衡，发现高精度和高召回率并非总是必要，检测频率会影响哪个特性更重要。


<details>
  <summary>Details</summary>
Motivation: 云服务中性能异常检测对于维持性能目标至关重要，但检测器会犯错，需要研究哪些检测特性对优化性能与成本权衡最重要。

Method: 使用随机奖励网络建模由性能异常检测器监控的云服务，分析检测器精度、召回率和检查频率对平均延迟和资源消耗的影响。

Result: 结果显示：如果检测频繁运行，高精度足以获得良好的性能-成本权衡；如果检测运行不频繁，召回率变得最重要。高精度和高召回率并非总是必要。

Conclusion: 性能异常检测器的优化策略应根据检测频率调整：高频检测时侧重精度，低频检测时侧重召回率，以实现最佳性能-成本权衡。

Abstract: Detecting and resolving performance anomalies in Cloud services is crucial for maintaining desired performance objectives. Scaling actions triggered by an anomaly detector help achieve target latency at the cost of extra resource consumption. However, performance anomaly detectors make mistakes. This paper studies which characteristics of performance anomaly detection are important to optimize the trade-off between performance and cost. Using Stochastic Reward Nets, we model a Cloud service monitored by a performance anomaly detector. Using our model, we study the impact of detector characteristics, namely precision, recall and inspection frequency, on the average latency and resource consumption of the monitored service. Our results show that achieving a high precision and a high recall is not always necessary. If detection can be run frequently, a high precision is enough to obtain a good performance-to-cost trade-off, but if the detector is run infrequently, recall becomes the most important.

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [15] [RAG-Driven Data Quality Governance for Enterprise ERP Systems](https://arxiv.org/abs/2511.16700)
*Sedat Bin Vedat,Enes Kutay Yarkan,Meftun Akarsu,Recep Kaan Karaman,Arda Sar,Çağrı Çelikbilek,Savaş Saygılı*

Main category: cs.DB

TL;DR: 提出一个端到端的企业ERP数据质量解决方案，结合自动化数据清理和LLM驱动的SQL查询生成，在管理24万员工记录的生产系统中部署6个月，显著提升查询效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 企业ERP系统面临多语言环境下人力资源部门分散手动录入导致的数据质量问题，需要解决数据清理和自然语言查询的挑战。

Method: 采用两阶段集成方法：多阶段清理管道（翻译标准化、拼写纠正、实体去重）和基于GPT-4o的检索增强生成框架，支持土耳其语、俄语和英语的自然语言转SQL查询。

Result: 在2847个生产查询中达到92.5%查询有效性、95.1%模式合规性和90.7%语义准确性，查询周转时间从2.3天缩短至5秒内，GPT-4o相比GPT-3.5延迟降低46%、成本减少68%。

Conclusion: 该模块化架构为企业AI原生数据治理提供了可复现框架，在企业规模下展现实际可行性，用户满意度达4.3/5.0。

Abstract: Enterprise ERP systems managing hundreds of thousands of employee records face critical data quality challenges when human resources departments perform decentralized manual entry across multiple languages. We present an end-to-end pipeline combining automated data cleaning with LLM-driven SQL query generation, deployed on a production system managing 240,000 employee records over six months.
  The system operates in two integrated stages: a multi-stage cleaning pipeline that performs translation normalization, spelling correction, and entity deduplication during periodic synchronization from Microsoft SQL Server to PostgreSQL; and a retrieval-augmented generation framework powered by GPT-4o that translates natural-language questions in Turkish, Russian, and English into validated SQL queries. The query engine employs LangChain orchestration, FAISS vector similarity search, and few-shot learning with 500+ validated examples.
  Our evaluation demonstrates 92.5% query validity, 95.1% schema compliance, and 90.7\% semantic accuracy on 2,847 production queries. The system reduces query turnaround time from 2.3 days to under 5 seconds while maintaining 99.2% uptime, with GPT-4o achieving 46% lower latency and 68% cost reduction versus GPT-3.5. This modular architecture provides a reproducible framework for AI-native enterprise data governance, demonstrating real-world viability at enterprise scale with 4.3/5.0 user satisfaction.

</details>


### [16] [LinkML: An Open Data Modeling Framework](https://arxiv.org/abs/2511.16935)
*Sierra A. T. Moxon,Harold Solbrig,Nomi L. Harris,Patrick Kalita,Mark A. Miller,Sujay Patil,Kevin Schaper,Chris Bizon,J. Harry Caufield,Silvano Cirujano Cuesta,Corey Cox,Frank Dekervel,Damion M. Dooley,William D. Duncan,Tim Fliss,Sarah Gehrke,Adam S. L. Graefe,Harshad Hegde,AJ Ireland,Julius O. B. Jacobsen,Madan Krishnamurthy,Carlo Kroll,David Linke,Ryan Ly,Nicolas Matentzoglu,James A. Overton,Jonny L. Saunders,Deepak R. Unni,Gaurav Vaidya,Wouter-Michiel A. M. Vierdag,LinkML Community Contributors,Oliver Ruebel,Christopher G. Chute,Matthew H. Brush,Melissa A. Haendel,Christopher J. Mungall*

Main category: cs.DB

TL;DR: LinkML是一个开放框架，用于简化数据的创建、验证和共享过程，通过提供标准化的数据建模语言来解决科学数据缺乏结构化的问题。


<details>
  <summary>Details</summary>
Motivation: 科学数据通常存储在非结构化格式中，如自由文本实验室笔记本、非标准化电子表格等，这导致数据互操作性差，难以集成、验证和重用。

Method: LinkML提供了一种可访问的语法来描述模式、类和关系，支持从简单列表到复杂相互关联模型的多种数据结构，并可与现有框架无缝集成。

Result: LinkML已在生物学、化学、生物医学、金融等多个领域得到应用，帮助减少数据异构性和复杂性，同时支持FAIR数据标准合规。

Conclusion: LinkML使隐式模型变得显式可计算，允许在数据源头进行标准化，为跨学科合作提供了可靠的数据语义定义和共享平台。

Abstract: Scientific research relies on well-structured, standardized data; however, much of it is stored in formats such as free-text lab notebooks, non-standardized spreadsheets, or data repositories. This lack of structure challenges interoperability, making data integration, validation, and reuse difficult. LinkML (Linked Data Modeling Language) is an open framework that simplifies the process of authoring, validating, and sharing data. LinkML can describe a range of data structures, from flat, list-based models to complex, interrelated, and normalized models that utilize polymorphism and compound inheritance. It offers an approachable syntax that is not tied to any one technical architecture and can be integrated seamlessly with many existing frameworks. The LinkML syntax provides a standard way to describe schemas, classes, and relationships, allowing modelers to build well-defined, stable, and optionally ontology-aligned data structures. Once defined, LinkML schemas may be imported into other LinkML schemas. These key features make LinkML an accessible platform for interdisciplinary collaboration and a reliable way to define and share data semantics.
  LinkML helps reduce heterogeneity, complexity, and the proliferation of single-use data models while simultaneously enabling compliance with FAIR data standards. LinkML has seen increasing adoption in various fields, including biology, chemistry, biomedicine, microbiome research, finance, electrical engineering, transportation, and commercial software development. In short, LinkML makes implicit models explicitly computable and allows data to be standardized at its origin. LinkML documentation and code are available at linkml.io.

</details>


### [17] [Anomaly Pattern-guided Transaction Bug Testing in Relational Databases](https://arxiv.org/abs/2511.17377)
*Huicong Xu,Shuang Liu,Xianyu Zhu,Qiyu Zhuang,Wei Lu,Xiaoyong Du*

Main category: cs.DB

TL;DR: 提出了APTrans工具，通过异常模式引导的测试方法来发现RDBMS中的事务bug，在MySQL、MariaDB和OceanBase中发现了13个未知事务相关bug。


<details>
  <summary>Details</summary>
Motivation: 测试不同隔离级别下的事务行为具有挑战性：自动生成能暴露事务处理逻辑bug的测试事务困难，且检测事务结果中的逻辑异常也困难。

Method: 采用异常模式引导的测试方法，包括基于预定义异常模式的测试用例生成技术，以及包含显式和隐式错误检测的两阶段检测过程。

Result: 在三个主流RDBMS（MySQL、MariaDB、OceanBase）中成功识别了13个之前未知的事务相关bug，其中11个已被相应开发团队确认。

Conclusion: APTrans方法有效解决了事务测试中的挑战，能够可靠地发现RDBMS中的事务处理bug。

Abstract: Concurrent transaction processing is a fundamental capability of Relational Database Management Systems (RDBMSs), widely utilized in applications requiring high levels of parallel user interaction, such as banking systems, e-commerce platforms, and telecommunications infrastructure. Isolation levels offer a configurable mechanism to manage the interaction between concurrent transactions, enabling varying degrees of consistency and performance trade-offs. These isolation guarantees are supported by all major RDBMSs. However, testing transaction behavior under different isolation levels remains a significant challenge due to two primary reasons. First, automatically generating test transactions that can effectively expose bugs in transaction handling logic is non-trivial, as such bugs are typically triggered under specific transactional constraints. Second, detecting logic anomalies in transaction outcomes is difficult because the correct execution results are often unknown for randomly generated transactions. To address these challenges, we propose an anomaly pattern-guided testing approach for uncovering transaction bugs in RDBMSs. Our solution tackles the first challenge by introducing a test case generation technique guided by predefined anomaly patterns, which increases the likelihood of exposing transactional bugs. For the second challenge, we present a two-phase detection process, involving explicit error detection and implicit error detection, to identify bugs in transaction execution. We have implemented our approach in a tool, APTrans, and evaluated it on three widely-used RDBMSs: MySQL, MariaDB, and OceanBase. APTrans successfully identified 13 previously unknown transaction-related bugs, 11 of which have been confirmed by the respective development teams.

</details>
