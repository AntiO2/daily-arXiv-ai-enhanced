{"id": "2602.10387", "categories": ["cs.DB", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.10387", "abs": "https://arxiv.org/abs/2602.10387", "authors": ["Mehmet Hamza Erol", "Xiangpeng Hao", "Federico Bianchi", "Ciro Greco", "Jacopo Tagliabue", "James Zou"], "title": "Making Databases Faster with LLM Evolutionary Sampling", "comment": null, "summary": "Traditional query optimization relies on cost-based optimizers that estimate execution cost (e.g., runtime, memory, and I/O) using predefined heuristics and statistical models. Improving these heuristics requires substantial engineering effort, and even when implemented, these heuristics often cannot take into account semantic correlations in queries and schemas that could enable better physical plans. Using our DBPlanBench harness for the DataFusion engine, we expose the physical plan through a compact serialized representation and let the LLM propose localized edits that can be applied and executed. We then apply an evolutionary search over these edits to refine candidates across iterations. Our key insight is that LLMs can leverage semantic knowledge to identify and apply non-obvious optimizations, such as join orderings that minimize intermediate cardinalities. We obtain up to 4.78$\\times$ speedups on some queries and we demonstrate a small-to-large workflow in which optimizations found on small databases transfer effectively to larger databases.", "AI": {"tldr": "\u4f7f\u7528LLM\u8fdb\u884c\u67e5\u8be2\u4f18\u5316\uff0c\u901a\u8fc7\u8fdb\u5316\u641c\u7d22\u6539\u8fdb\u7269\u7406\u6267\u884c\u8ba1\u5212\uff0c\u5728DataFusion\u5f15\u64ce\u4e0a\u5b9e\u73b0\u6700\u9ad84.78\u500d\u52a0\u901f", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u6210\u672c\u7684\u67e5\u8be2\u4f18\u5316\u5668\u4f9d\u8d56\u9884\u5b9a\u4e49\u542f\u53d1\u5f0f\u548c\u7edf\u8ba1\u6a21\u578b\uff0c\u6539\u8fdb\u8fd9\u4e9b\u542f\u53d1\u5f0f\u9700\u8981\u5927\u91cf\u5de5\u7a0b\u5de5\u4f5c\uff0c\u4e14\u65e0\u6cd5\u8003\u8651\u67e5\u8be2\u548c\u6a21\u5f0f\u4e2d\u7684\u8bed\u4e49\u76f8\u5173\u6027\uff0c\u53ef\u80fd\u9519\u8fc7\u66f4\u597d\u7684\u7269\u7406\u6267\u884c\u8ba1\u5212", "method": "\u4f7f\u7528DBPlanBench\u6846\u67b6\u66b4\u9732DataFusion\u5f15\u64ce\u7684\u7269\u7406\u6267\u884c\u8ba1\u5212\uff0c\u901a\u8fc7\u7d27\u51d1\u5e8f\u5217\u5316\u8868\u793a\u8ba9LLM\u63d0\u51fa\u5c40\u90e8\u7f16\u8f91\u5efa\u8bae\uff0c\u7136\u540e\u5e94\u7528\u8fdb\u5316\u641c\u7d22\u8fed\u4ee3\u6539\u8fdb\u5019\u9009\u65b9\u6848", "result": "\u5728\u67d0\u4e9b\u67e5\u8be2\u4e0a\u83b7\u5f97\u6700\u9ad84.78\u500d\u52a0\u901f\uff0c\u5e76\u5c55\u793a\u4e86\u4ece\u5c0f\u6570\u636e\u5e93\u5230\u5927\u6570\u636e\u5e93\u7684\u4f18\u5316\u8fc1\u79fb\u5de5\u4f5c\u6d41\uff0c\u8bc1\u660e\u5728\u5c0f\u6570\u636e\u5e93\u4e0a\u53d1\u73b0\u7684\u4f18\u5316\u80fd\u6709\u6548\u8fc1\u79fb\u5230\u66f4\u5927\u6570\u636e\u5e93", "conclusion": "LLM\u80fd\u591f\u5229\u7528\u8bed\u4e49\u77e5\u8bc6\u8bc6\u522b\u548c\u5e94\u7528\u975e\u663e\u800c\u6613\u89c1\u7684\u4f18\u5316\uff08\u5982\u6700\u5c0f\u5316\u4e2d\u95f4\u57fa\u6570\u7684\u8fde\u63a5\u987a\u5e8f\uff09\uff0c\u4e3a\u67e5\u8be2\u4f18\u5316\u63d0\u4f9b\u4e86\u65b0\u7684\u6709\u6548\u65b9\u6cd5"}}
{"id": "2602.10748", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2602.10748", "abs": "https://arxiv.org/abs/2602.10748", "authors": ["Farzad Shami", "Stefano Marchesin", "Gianmaria Silvello"], "title": "Benchmarking Large Language Models for Knowledge Graph Validation", "comment": "Accepted paper by the 29th International Conference on Extending Database Technology (EDBT'26)", "summary": "Knowledge Graphs (KGs) store structured factual knowledge by linking entities through relationships, crucial for many applications. These applications depend on the KG's factual accuracy, so verifying facts is essential, yet challenging. Expert manual verification is ideal but impractical on a large scale. Automated methods show promise but are not ready for real-world KGs. Large Language Models (LLMs) offer potential with their semantic understanding and knowledge access, yet their suitability and effectiveness for KG fact validation remain largely unexplored.\n  In this paper, we introduce FactCheck, a benchmark designed to evaluate LLMs for KG fact validation across three key dimensions: (1) LLMs internal knowledge; (2) external evidence via Retrieval-Augmented Generation (RAG); and (3) aggregated knowledge employing a multi-model consensus strategy. We evaluated open-source and commercial LLMs on three diverse real-world KGs. FactCheck also includes a RAG dataset with 2+ million documents tailored for KG fact validation. Additionally, we offer an interactive exploration platform for analyzing verification decisions.\n  The experimental analyses demonstrate that while LLMs yield promising results, they are still not sufficiently stable and reliable to be used in real-world KG validation scenarios. Integrating external evidence through RAG methods yields fluctuating performance, providing inconsistent improvements over more streamlined approaches -- at higher computational costs. Similarly, strategies based on multi-model consensus do not consistently outperform individual models, underscoring the lack of a one-fits-all solution. These findings further emphasize the need for a benchmark like FactCheck to systematically evaluate and drive progress on this difficult yet crucial task.", "AI": {"tldr": "FactCheck\u662f\u4e00\u4e2a\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5728\u77e5\u8bc6\u56fe\u8c31\u4e8b\u5b9e\u9a8c\u8bc1\u4efb\u52a1\u4e0a\u6027\u80fd\u7684\u57fa\u51c6\uff0c\u6db5\u76d6\u5185\u90e8\u77e5\u8bc6\u3001RAG\u5916\u90e8\u8bc1\u636e\u548c\u591a\u6a21\u578b\u5171\u8bc6\u4e09\u4e2a\u7ef4\u5ea6\uff0c\u53d1\u73b0LLMs\u5728\u771f\u5b9e\u573a\u666f\u4e2d\u4ecd\u4e0d\u591f\u7a33\u5b9a\u53ef\u9760\u3002", "motivation": "\u77e5\u8bc6\u56fe\u8c31\u7684\u4e8b\u5b9e\u51c6\u786e\u6027\u5bf9\u8bb8\u591a\u5e94\u7528\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5927\u89c4\u6a21\u624b\u52a8\u9a8c\u8bc1\u4e0d\u73b0\u5b9e\uff0c\u73b0\u6709\u81ea\u52a8\u5316\u65b9\u6cd5\u4e5f\u4e0d\u6210\u719f\u3002\u5927\u8bed\u8a00\u6a21\u578b\u5177\u6709\u8bed\u4e49\u7406\u89e3\u548c\u77e5\u8bc6\u8bbf\u95ee\u80fd\u529b\uff0c\u4f46\u5176\u5728KG\u4e8b\u5b9e\u9a8c\u8bc1\u4e2d\u7684\u9002\u7528\u6027\u548c\u6709\u6548\u6027\u5c1a\u672a\u5145\u5206\u63a2\u7d22\uff0c\u9700\u8981\u7cfb\u7edf\u8bc4\u4f30\u3002", "method": "\u63d0\u51faFactCheck\u57fa\u51c6\uff0c\u4ece\u4e09\u4e2a\u7ef4\u5ea6\u8bc4\u4f30LLMs\uff1a1) \u6a21\u578b\u5185\u90e8\u77e5\u8bc6\uff1b2) \u901a\u8fc7\u68c0\u7d22\u589e\u5f3a\u751f\u6210(RAG)\u7684\u5916\u90e8\u8bc1\u636e\uff1b3) \u591a\u6a21\u578b\u5171\u8bc6\u7b56\u7565\u7684\u805a\u5408\u77e5\u8bc6\u3002\u5728\u4e09\u4e2a\u771f\u5b9eKG\u4e0a\u8bc4\u4f30\u5f00\u6e90\u548c\u5546\u4e1aLLMs\uff0c\u5e76\u63d0\u4f9b\u5305\u542b200\u4e07+\u6587\u6863\u7684RAG\u6570\u636e\u96c6\u548c\u4ea4\u4e92\u5f0f\u5206\u6790\u5e73\u53f0\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff1a1) LLMs\u867d\u6709\u6f5c\u529b\u4f46\u4e0d\u591f\u7a33\u5b9a\u53ef\u9760\uff0c\u4e0d\u9002\u5408\u771f\u5b9eKG\u9a8c\u8bc1\u573a\u666f\uff1b2) RAG\u65b9\u6cd5\u6027\u80fd\u6ce2\u52a8\uff0c\u6539\u8fdb\u4e0d\u4e00\u81f4\u4e14\u8ba1\u7b97\u6210\u672c\u9ad8\uff1b3) \u591a\u6a21\u578b\u5171\u8bc6\u7b56\u7565\u4e0d\u603b\u662f\u4f18\u4e8e\u5355\u4e2a\u6a21\u578b\uff0c\u6ca1\u6709\u901a\u7528\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "LLMs\u5728KG\u4e8b\u5b9e\u9a8c\u8bc1\u4e2d\u4ecd\u6709\u5c40\u9650\u6027\uff0c\u9700\u8981FactCheck\u8fd9\u6837\u7684\u57fa\u51c6\u6765\u7cfb\u7edf\u8bc4\u4f30\u548c\u63a8\u52a8\u8be5\u5173\u952e\u4efb\u52a1\u7684\u53d1\u5c55\u3002\u5f53\u524d\u65b9\u6cd5\u5c1a\u672a\u627e\u5230\u7a33\u5b9a\u53ef\u9760\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5f3a\u8c03\u4e86\u8fdb\u4e00\u6b65\u7814\u7a76\u7684\u5fc5\u8981\u6027\u3002"}}
{"id": "2602.11052", "categories": ["cs.DB", "cs.AI", "cs.CL", "cs.HC", "cs.IR"], "pdf": "https://arxiv.org/pdf/2602.11052", "abs": "https://arxiv.org/abs/2602.11052", "authors": ["Maciej Besta", "\u0141ukasz Jarmocik", "Orest Hrycyna", "Shachar Klaiman", "Konrad M\u0105czka", "Robert Gerstenberger", "J\u00fcrgen M\u00fcller", "Piotr Nyczyk", "Hubert Niewiadomski", "Torsten Hoefler"], "title": "GraphSeek: Next-Generation Graph Analytics with LLMs", "comment": null, "summary": "Graphs are foundational across domains but remain hard to use without deep expertise. LLMs promise accessible natural language (NL) graph analytics, yet they fail to process industry-scale property graphs effectively and efficiently: such datasets are large, highly heterogeneous, structurally complex, and evolve dynamically. To address this, we devise a novel abstraction for complex multi-query analytics over such graphs. Its key idea is to replace brittle generation of graph queries directly from NL with planning over a Semantic Catalog that describes both the graph schema and the graph operations. Concretely, this induces a clean separation between a Semantic Plane for LLM planning and broader reasoning, and an Execution Plane for deterministic, database-grade query execution over the full dataset and tool implementations. This design yields substantial gains in both token efficiency and task effectiveness even with small-context LLMs. We use this abstraction as the basis of the first LLM-enhanced graph analytics framework called GraphSeek. GraphSeek achieves substantially higher success rates (e.g., 86% over enhanced LangChain) and points toward the next generation of affordable and accessible graph analytics that unify LLM reasoning with database-grade execution over large and complex property graphs.", "AI": {"tldr": "GraphSeek\uff1a\u9996\u4e2aLLM\u589e\u5f3a\u7684\u56fe\u5206\u6790\u6846\u67b6\uff0c\u901a\u8fc7\u8bed\u4e49\u76ee\u5f55\u89c4\u5212\u5b9e\u73b0\u81ea\u7136\u8bed\u8a00\u5230\u590d\u6742\u5c5e\u6027\u56fe\u67e5\u8be2\u7684\u9ad8\u6548\u8f6c\u6362\uff0c\u663e\u8457\u63d0\u5347\u4efb\u52a1\u6210\u529f\u7387\u548c\u4ee4\u724c\u6548\u7387", "motivation": "\u56fe\u6570\u636e\u5728\u5404\u9886\u57df\u5e94\u7528\u5e7f\u6cdb\u4f46\u4f7f\u7528\u95e8\u69db\u9ad8\uff0c\u73b0\u6709LLM\u65e0\u6cd5\u6709\u6548\u5904\u7406\u5de5\u4e1a\u7ea7\u89c4\u6a21\u3001\u9ad8\u5ea6\u5f02\u6784\u3001\u7ed3\u6784\u590d\u6742\u4e14\u52a8\u6001\u6f14\u5316\u7684\u5c5e\u6027\u56fe\uff0c\u9700\u8981\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u6765\u964d\u4f4e\u56fe\u5206\u6790\u7684\u4f7f\u7528\u95e8\u69db", "method": "\u63d0\u51fa\u65b0\u9896\u7684\u62bd\u8c61\u5c42\uff0c\u901a\u8fc7\u8bed\u4e49\u76ee\u5f55\u63cf\u8ff0\u56fe\u6a21\u5f0f\u548c\u64cd\u4f5c\uff0c\u5c06LLM\u89c4\u5212\uff08\u8bed\u4e49\u5e73\u9762\uff09\u4e0e\u786e\u5b9a\u6027\u67e5\u8be2\u6267\u884c\uff08\u6267\u884c\u5e73\u9762\uff09\u5206\u79bb\uff0c\u907f\u514d\u76f4\u63a5\u4ece\u81ea\u7136\u8bed\u8a00\u751f\u6210\u6613\u9519\u7684\u56fe\u67e5\u8be2", "result": "GraphSeek\u6846\u67b6\u76f8\u6bd4\u589e\u5f3a\u7248LangChain\u5b9e\u73b0\u663e\u8457\u66f4\u9ad8\u7684\u6210\u529f\u7387\uff0886%\uff09\uff0c\u5728\u5c0f\u4e0a\u4e0b\u6587LLM\u4e0b\u4e5f\u80fd\u83b7\u5f97\u4ee4\u724c\u6548\u7387\u548c\u4efb\u52a1\u6548\u679c\u7684\u53cc\u91cd\u63d0\u5347", "conclusion": "GraphSeek\u4e3a\u4e0b\u4e00\u4ee3\u53ef\u8d1f\u62c5\u3001\u6613\u8bbf\u95ee\u7684\u56fe\u5206\u6790\u6307\u660e\u4e86\u65b9\u5411\uff0c\u901a\u8fc7\u7edf\u4e00LLM\u63a8\u7406\u4e0e\u6570\u636e\u5e93\u7ea7\u6267\u884c\uff0c\u6709\u6548\u5904\u7406\u5927\u89c4\u6a21\u590d\u6742\u5c5e\u6027\u56fe"}}
{"id": "2602.10246", "categories": ["cs.DC", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.10246", "abs": "https://arxiv.org/abs/2602.10246", "authors": ["Mayur Akewar", "Sandeep Madireddy", "Dongsheng Luo", "Janki Bhimani"], "title": "KORAL: Knowledge Graph Guided LLM Reasoning for SSD Operational Analysis", "comment": null, "summary": "Solid State Drives (SSDs) are critical to datacenters, consumer platforms, and mission-critical systems. Yet diagnosing their performance and reliability is difficult because data are fragmented and time-disjoint, and existing methods demand large datasets and expert input while offering only limited insights. Degradation arises not only from shifting workloads and evolving architectures but also from environmental factors such as temperature, humidity, and vibration. We present KORAL, a knowledge driven reasoning framework that integrates Large Language Models (LLMs) with a structured Knowledge Graph (KG) to generate insights into SSD operations. Unlike traditional approaches that require extensive expert input and large datasets, KORAL generates a Data KG from fragmented telemetry and integrates a Literature KG that already organizes knowledge from literature, reports, and traces. This turns unstructured sources into a queryable graph and telemetry into structured knowledge, and both the Graphs guide the LLM to deliver evidence-based, explainable analysis aligned with the domain vocabulary and constraints. Evaluation using real production traces shows that the KORAL delivers expert-level diagnosis and recommendations, supported by grounded explanations that improve reasoning transparency, guide operator decisions, reduce manual effort, and provide actionable insights to improve service quality. To our knowledge, this is the first end-to-end system that combines LLMs and KGs for full-spectrum SSD reasoning including Descriptive, Predictive, Prescriptive, and What-if analysis. We release the generated SSD-specific KG to advance reproducible research in knowledge-based storage system analysis. GitHub Repository: https://github.com/Damrl-lab/KORAL", "AI": {"tldr": "KORAL\u662f\u4e00\u4e2a\u7ed3\u5408\u5927\u578b\u8bed\u8a00\u6a21\u578b\u548c\u77e5\u8bc6\u56fe\u8c31\u7684\u63a8\u7406\u6846\u67b6\uff0c\u7528\u4e8e\u5206\u6790\u56fa\u6001\u786c\u76d8\u7684\u6027\u80fd\u548c\u53ef\u9760\u6027\u95ee\u9898\uff0c\u80fd\u591f\u4ece\u788e\u7247\u5316\u9065\u6d4b\u6570\u636e\u751f\u6210\u53ef\u67e5\u8be2\u7684\u77e5\u8bc6\u56fe\u8c31\uff0c\u63d0\u4f9b\u4e13\u5bb6\u7ea7\u8bca\u65ad\u548c\u5efa\u8bae\u3002", "motivation": "\u56fa\u6001\u786c\u76d8\u7684\u6027\u80fd\u548c\u53ef\u9760\u6027\u8bca\u65ad\u56f0\u96be\uff0c\u56e0\u4e3a\u6570\u636e\u788e\u7247\u5316\u4e14\u65f6\u95f4\u4e0d\u8fde\u7eed\uff0c\u73b0\u6709\u65b9\u6cd5\u9700\u8981\u5927\u91cf\u6570\u636e\u96c6\u548c\u4e13\u5bb6\u8f93\u5165\uff0c\u4f46\u53ea\u80fd\u63d0\u4f9b\u6709\u9650\u89c1\u89e3\u3002\u6027\u80fd\u4e0b\u964d\u4e0d\u4ec5\u6765\u81ea\u5de5\u4f5c\u8d1f\u8f7d\u53d8\u5316\u548c\u67b6\u6784\u6f14\u8fdb\uff0c\u8fd8\u53d7\u6e29\u5ea6\u3001\u6e7f\u5ea6\u3001\u632f\u52a8\u7b49\u73af\u5883\u56e0\u7d20\u5f71\u54cd\u3002", "method": "\u63d0\u51faKORAL\u6846\u67b6\uff0c\u5c06\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e0e\u7ed3\u6784\u5316\u77e5\u8bc6\u56fe\u8c31\u7ed3\u5408\uff1a1\uff09\u4ece\u788e\u7247\u5316\u9065\u6d4b\u6570\u636e\u751f\u6210\u6570\u636e\u77e5\u8bc6\u56fe\u8c31\uff1b2\uff09\u6574\u5408\u6587\u732e\u77e5\u8bc6\u56fe\u8c31\uff08\u5305\u542b\u6587\u732e\u3001\u62a5\u544a\u548c\u8ddf\u8e2a\u8bb0\u5f55\u4e2d\u7684\u77e5\u8bc6\uff09\uff1b3\uff09\u4e24\u4e2a\u56fe\u8c31\u5171\u540c\u6307\u5bfcLLM\u751f\u6210\u57fa\u4e8e\u8bc1\u636e\u3001\u53ef\u89e3\u91ca\u7684\u5206\u6790\u3002", "result": "\u4f7f\u7528\u771f\u5b9e\u751f\u4ea7\u8ddf\u8e2a\u6570\u636e\u8bc4\u4f30\u663e\u793a\uff0cKORAL\u80fd\u591f\u63d0\u4f9b\u4e13\u5bb6\u7ea7\u8bca\u65ad\u548c\u63a8\u8350\uff0c\u652f\u6301\u57fa\u4e8e\u8bc1\u636e\u7684\u89e3\u91ca\uff0c\u63d0\u9ad8\u63a8\u7406\u900f\u660e\u5ea6\uff0c\u6307\u5bfc\u64cd\u4f5c\u5458\u51b3\u7b56\uff0c\u51cf\u5c11\u4eba\u5de5\u5de5\u4f5c\u91cf\uff0c\u5e76\u63d0\u4f9b\u53ef\u64cd\u4f5c\u7684\u89c1\u89e3\u6765\u6539\u5584\u670d\u52a1\u8d28\u91cf\u3002", "conclusion": "KORAL\u662f\u9996\u4e2a\u7ed3\u5408LLM\u548cKG\u8fdb\u884c\u5168\u8c31SSD\u63a8\u7406\uff08\u5305\u62ec\u63cf\u8ff0\u6027\u3001\u9884\u6d4b\u6027\u3001\u89c4\u8303\u6027\u5206\u6790\u548c\u5047\u8bbe\u5206\u6790\uff09\u7684\u7aef\u5230\u7aef\u7cfb\u7edf\u3002\u53d1\u5e03\u4e86SSD\u7279\u5b9a\u77e5\u8bc6\u56fe\u8c31\u4ee5\u63a8\u8fdb\u57fa\u4e8e\u77e5\u8bc6\u7684\u5b58\u50a8\u7cfb\u7edf\u5206\u6790\u7684\u53ef\u91cd\u590d\u7814\u7a76\u3002"}}
{"id": "2602.10262", "categories": ["cs.DC", "cs.AR"], "pdf": "https://arxiv.org/pdf/2602.10262", "abs": "https://arxiv.org/abs/2602.10262", "authors": ["Aaron Jarmusch", "Connor Vitz", "Sunita Chandrasekaran"], "title": "Execution-Centric Characterization of FP8 Matrix Cores, Asynchronous Execution, and Structured Sparsity on AMD MI300A", "comment": null, "summary": "The AMD MI300A APU integrates CDNA3 GPUs with high-bandwidth memory and advanced accelerator features: FP8 matrix cores, asynchronous compute engines (ACE), and 2:4 structured sparsity. These capabilities are increasingly relied upon by modern HPC and HPC-AI workloads, yet their execution characteristics and system-level implications remain insufficiently understood. In this paper, we present an execution-centric characterization of FP8 matrix execution, ACE concurrency, and structured sparsity on MI300A using targeted microbenchmarks. We quantify occupancy thresholds, fairness, throughput trade-offs under concurrent execution, and context-dependent sparsity benefits. We evaluate representative case studies - transformer-style, concurrent, and mixed-precision kernels - to show how these effects translate into application-level performance and predictability. Our results provide practical guidance for occupancy-aware scheduling, concurrency decisions, and sparsity enablement on MI300A-class unified nodes.", "AI": {"tldr": "\u5bf9AMD MI300A APU\u4e2dFP8\u77e9\u9635\u8fd0\u7b97\u3001\u5f02\u6b65\u8ba1\u7b97\u5f15\u64ce\u5e76\u53d1\u548c\u7ed3\u6784\u5316\u7a00\u758f\u6027\u7684\u6267\u884c\u7279\u6027\u8fdb\u884c\u5fae\u57fa\u51c6\u6d4b\u8bd5\u5206\u6790\uff0c\u4e3a\u7edf\u4e00\u8282\u70b9\u4e0a\u7684\u8c03\u5ea6\u51b3\u7b56\u63d0\u4f9b\u5b9e\u7528\u6307\u5bfc", "motivation": "AMD MI300A APU\u96c6\u6210\u4e86CDNA3 GPU\u3001\u9ad8\u5e26\u5bbd\u5185\u5b58\u548c\u5148\u8fdb\u52a0\u901f\u5668\u7279\u6027\uff08FP8\u77e9\u9635\u6838\u5fc3\u3001\u5f02\u6b65\u8ba1\u7b97\u5f15\u64ce\u30012:4\u7ed3\u6784\u5316\u7a00\u758f\u6027\uff09\uff0c\u8fd9\u4e9b\u7279\u6027\u88ab\u73b0\u4ee3HPC\u548cHPC-AI\u5de5\u4f5c\u8d1f\u8f7d\u65e5\u76ca\u4f9d\u8d56\uff0c\u4f46\u5176\u6267\u884c\u7279\u6027\u548c\u7cfb\u7edf\u7ea7\u5f71\u54cd\u5c1a\u672a\u88ab\u5145\u5206\u7406\u89e3", "method": "\u4f7f\u7528\u9488\u5bf9\u6027\u5fae\u57fa\u51c6\u6d4b\u8bd5\u5bf9MI300A\u8fdb\u884c\u6267\u884c\u4e2d\u5fc3\u5316\u8868\u5f81\uff0c\u91cf\u5316\u5360\u7528\u7387\u9608\u503c\u3001\u516c\u5e73\u6027\u3001\u5e76\u53d1\u6267\u884c\u4e0b\u7684\u541e\u5410\u91cf\u6743\u8861\u4ee5\u53ca\u4e0a\u4e0b\u6587\u76f8\u5173\u7684\u7a00\u758f\u6027\u4f18\u52bf\uff0c\u5e76\u8bc4\u4f30\u4ee3\u8868\u6027\u6848\u4f8b\u7814\u7a76\uff08transformer\u98ce\u683c\u3001\u5e76\u53d1\u548c\u6df7\u5408\u7cbe\u5ea6\u5185\u6838\uff09", "result": "\u63d0\u4f9b\u4e86FP8\u77e9\u9635\u6267\u884c\u3001ACE\u5e76\u53d1\u548c\u7ed3\u6784\u5316\u7a00\u758f\u6027\u7684\u8be6\u7ec6\u6267\u884c\u7279\u6027\u5206\u6790\uff0c\u5c55\u793a\u4e86\u8fd9\u4e9b\u6548\u5e94\u5982\u4f55\u8f6c\u5316\u4e3a\u5e94\u7528\u7ea7\u6027\u80fd\u548c\u53ef\u9884\u6d4b\u6027", "conclusion": "\u7814\u7a76\u7ed3\u679c\u4e3aMI300A\u7c7b\u7edf\u4e00\u8282\u70b9\u4e0a\u7684\u5360\u7528\u7387\u611f\u77e5\u8c03\u5ea6\u3001\u5e76\u53d1\u51b3\u7b56\u548c\u7a00\u758f\u6027\u542f\u7528\u63d0\u4f9b\u4e86\u5b9e\u7528\u6307\u5bfc"}}
{"id": "2602.10378", "categories": ["cs.DC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.10378", "abs": "https://arxiv.org/abs/2602.10378", "authors": ["Elliot L. Epstein", "Rajat Vadiraj Dwaraknath", "John Winnicki"], "title": "Flash-SD-KDE: Accelerating SD-KDE with Tensor Cores", "comment": "11 pages", "summary": "Score-debiased kernel density estimation (SD-KDE) achieves improved asymptotic convergence rates over classical KDE, but its use of an empirical score has made it significantly slower in practice. We show that by re-ordering the SD-KDE computation to expose matrix-multiplication structure, Tensor Cores can be used to accelerate the GPU implementation. On a 32k-sample 16-dimensional problem, our approach runs up to $47\\times$ faster than a strong SD-KDE GPU baseline and $3{,}300\\times$ faster than scikit-learn's KDE. On a larger 1M-sample 16-dimensional task evaluated on 131k queries, Flash-SD-KDE completes in $2.3$ s on a single GPU, making score-debiased density estimation practical at previously infeasible scales.", "AI": {"tldr": "Flash-SD-KDE\u901a\u8fc7\u91cd\u65b0\u7ec4\u7ec7\u8ba1\u7b97\u7ed3\u6784\u5229\u7528Tensor Cores\u52a0\u901fGPU\u5b9e\u73b0\uff0c\u4f7f\u57fa\u4e8e\u5f97\u5206\u7684\u53bb\u504f\u6838\u5bc6\u5ea6\u4f30\u8ba1\u5728\u4e4b\u524d\u4e0d\u53ef\u884c\u7684\u89c4\u6a21\u4e0a\u53d8\u5f97\u5b9e\u7528", "motivation": "SD-KDE\u867d\u7136\u6bd4\u7ecf\u5178KDE\u6709\u66f4\u597d\u7684\u6e10\u8fd1\u6536\u655b\u901f\u5ea6\uff0c\u4f46\u7531\u4e8e\u4f7f\u7528\u7ecf\u9a8c\u5f97\u5206\u51fd\u6570\uff0c\u5b9e\u9645\u8ba1\u7b97\u901f\u5ea6\u663e\u8457\u8f83\u6162\uff0c\u9650\u5236\u4e86\u5176\u5728\u5927\u89c4\u6a21\u5e94\u7528\u4e2d\u7684\u5b9e\u7528\u6027", "method": "\u91cd\u65b0\u7ec4\u7ec7SD-KDE\u8ba1\u7b97\u4ee5\u66b4\u9732\u77e9\u9635\u4e58\u6cd5\u7ed3\u6784\uff0c\u4ece\u800c\u5229\u7528GPU\u7684Tensor Cores\u8fdb\u884c\u52a0\u901f\uff0c\u5b9e\u73b0Flash-SD-KDE\u7b97\u6cd5", "result": "\u572832k\u6837\u672c16\u7ef4\u95ee\u9898\u4e0a\uff0c\u6bd4\u5f3aSD-KDE GPU\u57fa\u7ebf\u5feb47\u500d\uff0c\u6bd4scikit-learn\u7684KDE\u5feb3300\u500d\uff1b\u57281M\u6837\u672c16\u7ef4\u4efb\u52a1\u4e0a\uff0c131k\u4e2a\u67e5\u8be2\u4ec5\u97002.3\u79d2", "conclusion": "\u901a\u8fc7GPU\u52a0\u901f\u7684Flash-SD-KDE\u4f7f\u57fa\u4e8e\u5f97\u5206\u7684\u53bb\u504f\u5bc6\u5ea6\u4f30\u8ba1\u5728\u4e4b\u524d\u4e0d\u53ef\u884c\u7684\u89c4\u6a21\u4e0a\u53d8\u5f97\u5b9e\u7528\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8ba1\u7b97\u6548\u7387"}}
{"id": "2602.10486", "categories": ["cs.DC", "cs.DS"], "pdf": "https://arxiv.org/pdf/2602.10486", "abs": "https://arxiv.org/abs/2602.10486", "authors": ["Vijay K. Garg", "Rohan Garg"], "title": "Computing Least Fixed Points with Overwrite Semantics in Parallel and Distributed Systems", "comment": null, "summary": "We present methods to compute least fixed points of multiple monotone inflationary functions in parallel and distributed settings. While the classic Knaster-Tarski theorem addresses a single function with sequential iteration, modern computing systems require parallel execution with overwrite semantics, non-atomic updates, and stale reads. We prove three convergence theorems under progressively relaxed synchronization: (1) Interleaving semantics with fair scheduling, (2) Parallel execution with update-only-on-change semantics (processes write only on those coordinates whose values change), and (3) Distributed execution with bounded staleness (updates propagate within $T$ rounds) and $i$-locality (each process modifies only its own component).\n  Our approach differs from prior work in fundamental ways: Cousot-Cousot's chaotic iteration uses join-based merges that preserve information. Instead, we use coordinate-wise overwriting. Bertsekas's asynchronous methods assume contractions. We use coordinate-wise overwriting with structural constraints (locality, bounded staleness) instead. Applications include parallel and distributed algorithms for the transitive closure, stable marriage, shortest paths, and fair division with subsidy problems. Our results provide the first exact least-fixed-point convergence guarantees for overwrite-based parallel updates without join operations or contraction assumptions.", "AI": {"tldr": "\u63d0\u51fa\u5e76\u884c\u548c\u5206\u5e03\u5f0f\u8ba1\u7b97\u4e2d\u591a\u5355\u8c03\u81a8\u80c0\u51fd\u6570\u6700\u5c0f\u4e0d\u52a8\u70b9\u7684\u8ba1\u7b97\u65b9\u6cd5\uff0c\u8bc1\u660e\u4e09\u79cd\u540c\u6b65\u6761\u4ef6\u4e0b\u7684\u6536\u655b\u5b9a\u7406\uff0c\u9002\u7528\u4e8e\u8986\u76d6\u8bed\u4e49\u800c\u975e\u8fde\u63a5\u64cd\u4f5c", "motivation": "\u7ecf\u5178Knaster-Tarski\u5b9a\u7406\u5904\u7406\u5355\u51fd\u6570\u987a\u5e8f\u8fed\u4ee3\uff0c\u4f46\u73b0\u4ee3\u8ba1\u7b97\u7cfb\u7edf\u9700\u8981\u5e76\u884c\u6267\u884c\u3001\u8986\u76d6\u8bed\u4e49\u3001\u975e\u539f\u5b50\u66f4\u65b0\u548c\u8fc7\u65f6\u8bfb\u53d6\uff0c\u9700\u8981\u65b0\u7684\u7406\u8bba\u6846\u67b6", "method": "\u4f7f\u7528\u5750\u6807\u8986\u76d6\u800c\u975e\u8fde\u63a5\u5408\u5e76\uff0c\u5728\u4e09\u79cd\u6e10\u8fdb\u653e\u677e\u7684\u540c\u6b65\u6761\u4ef6\u4e0b\u8bc1\u660e\u6536\u655b\uff1a(1)\u516c\u5e73\u8c03\u5ea6\u7684\u4ea4\u9519\u8bed\u4e49\uff0c(2)\u4ec5\u5f53\u503c\u53d8\u5316\u65f6\u66f4\u65b0\u7684\u5e76\u884c\u6267\u884c\uff0c(3)\u6709\u754c\u8fc7\u65f6\u548ci-\u5c40\u90e8\u6027\u7684\u5206\u5e03\u5f0f\u6267\u884c", "result": "\u9996\u6b21\u4e3a\u57fa\u4e8e\u8986\u76d6\u7684\u5e76\u884c\u66f4\u65b0\u63d0\u4f9b\u7cbe\u786e\u7684\u6700\u5c0f\u4e0d\u52a8\u70b9\u6536\u655b\u4fdd\u8bc1\uff0c\u65e0\u9700\u8fde\u63a5\u64cd\u4f5c\u6216\u6536\u7f29\u5047\u8bbe\uff0c\u9002\u7528\u4e8e\u4f20\u9012\u95ed\u5305\u3001\u7a33\u5b9a\u5a5a\u59fb\u3001\u6700\u77ed\u8def\u5f84\u548c\u516c\u5e73\u5206\u914d\u7b49\u5e94\u7528", "conclusion": "\u5efa\u7acb\u4e86\u8986\u76d6\u8bed\u4e49\u4e0b\u5e76\u884c\u548c\u5206\u5e03\u5f0f\u4e0d\u52a8\u70b9\u8ba1\u7b97\u7684\u7406\u8bba\u57fa\u7840\uff0c\u4e3a\u73b0\u4ee3\u8ba1\u7b97\u7cfb\u7edf\u63d0\u4f9b\u4e86\u65b0\u7684\u6536\u655b\u4fdd\u8bc1\u6846\u67b6\uff0c\u533a\u522b\u4e8e\u4f20\u7edf\u7684\u8fde\u63a5\u5408\u5e76\u548c\u6536\u7f29\u65b9\u6cd5"}}
{"id": "2602.10729", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2602.10729", "abs": "https://arxiv.org/abs/2602.10729", "authors": ["Youhe Jiang", "Fangcheng Fu", "Eiko Yoneki"], "title": "BOute: Cost-Efficient LLM Serving with Heterogeneous LLMs and GPUs via Multi-Objective Bayesian Optimization", "comment": "MLSys 2026", "summary": "The rapid growth of large language model (LLM) deployments has made cost-efficient serving systems essential. Recent efforts to enhance system cost-efficiency adopt two main perspectives: (i) An algorithmic perspective that exploits heterogeneous model capabilities to route simpler queries to lower-cost models and complex queries to higher-cost models (i.e., heterogeneous query routing); and (ii) a systems perspective that utilizes heterogeneous GPU resources as cost-effective alternatives to homogeneous high-end GPUs (i.e., heterogeneous model deployment). However, algorithm-system co-design for cost-efficient LLM serving necessitates sophisticated management: (i) Determining optimal query routing strategies under latency and quality requirements, (ii) configuring model deployment across heterogeneous GPUs with appropriate resource allocation and parallelism strategies, and (iii) co-optimizing routing and deployment decisions to maximize overall system performance. To address these challenges, we present BOute, a quality-aware scheduling system that jointly exploits heterogeneous model and GPU capabilities for cost-efficient LLM serving. BOute employs a multi-objective Bayesian optimization (MOBO) framework to co-optimize the routing strategy and model deployment, thereby maximizing the cost-efficiency of the serving system while guaranteeing response quality. Evaluation results demonstrate that BOute outperforms state-of-the-art LLM serving systems by up to 157% and 59% on average under identical cost budgets and quality requirements, or reducing serving costs by 15%-61% (38% on average) while maintaining the same performance targets, validating its effectiveness in achieving cost-efficient LLM serving.", "AI": {"tldr": "BOute\u662f\u4e00\u4e2a\u8d28\u91cf\u611f\u77e5\u8c03\u5ea6\u7cfb\u7edf\uff0c\u901a\u8fc7\u8054\u5408\u4f18\u5316\u5f02\u6784\u6a21\u578b\u8def\u7531\u548cGPU\u90e8\u7f72\u7b56\u7565\uff0c\u5b9e\u73b0\u6210\u672c\u9ad8\u6548\u7684LLM\u670d\u52a1\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u90e8\u7f72\u5feb\u901f\u589e\u957f\uff0c\u9700\u8981\u6210\u672c\u9ad8\u6548\u7684\u670d\u52a1\u7cfb\u7edf\u3002\u73b0\u6709\u65b9\u6cd5\u5206\u522b\u4ece\u7b97\u6cd5\u89d2\u5ea6\uff08\u5f02\u6784\u67e5\u8be2\u8def\u7531\uff09\u548c\u7cfb\u7edf\u89d2\u5ea6\uff08\u5f02\u6784GPU\u90e8\u7f72\uff09\u4f18\u5316\uff0c\u4f46\u7f3a\u4e4f\u7b97\u6cd5-\u7cfb\u7edf\u534f\u540c\u8bbe\u8ba1\u6765\u6700\u5927\u5316\u6574\u4f53\u6027\u80fd\u3002", "method": "\u91c7\u7528\u591a\u76ee\u6807\u8d1d\u53f6\u65af\u4f18\u5316\u6846\u67b6\uff0c\u8054\u5408\u4f18\u5316\u8def\u7531\u7b56\u7565\u548c\u6a21\u578b\u90e8\u7f72\u914d\u7f6e\uff0c\u5728\u4fdd\u8bc1\u54cd\u5e94\u8d28\u91cf\u7684\u524d\u63d0\u4e0b\u6700\u5927\u5316\u7cfb\u7edf\u6210\u672c\u6548\u7387\u3002", "result": "\u5728\u76f8\u540c\u6210\u672c\u9884\u7b97\u548c\u8d28\u91cf\u8981\u6c42\u4e0b\uff0cBOute\u6bd4\u73b0\u6709\u6700\u4f18LLM\u670d\u52a1\u7cfb\u7edf\u6027\u80fd\u63d0\u5347\u6700\u9ad8157%\uff0c\u5e73\u574759%\uff1b\u6216\u5728\u4fdd\u6301\u76f8\u540c\u6027\u80fd\u76ee\u6807\u4e0b\u964d\u4f4e\u670d\u52a1\u6210\u672c15%-61%\uff08\u5e73\u574738%\uff09\u3002", "conclusion": "BOute\u901a\u8fc7\u7b97\u6cd5-\u7cfb\u7edf\u534f\u540c\u8bbe\u8ba1\u6709\u6548\u89e3\u51b3\u4e86\u6210\u672c\u9ad8\u6548LLM\u670d\u52a1\u4e2d\u7684\u590d\u6742\u7ba1\u7406\u95ee\u9898\uff0c\u9a8c\u8bc1\u4e86\u8054\u5408\u4f18\u5316\u5f02\u6784\u6a21\u578b\u548cGPU\u80fd\u529b\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2602.11000", "categories": ["cs.DC", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.11000", "abs": "https://arxiv.org/abs/2602.11000", "authors": ["Ali Tehrani", "Yahya Emara", "Essam Wissam", "Wojciech Paluch", "Waleed Atallah", "\u0141ukasz Dudziak", "Mohamed S. Abdelfattah"], "title": "Fine-Tuning GPT-5 for GPU Kernel Generation", "comment": null, "summary": "Developing efficient GPU kernels is essential for scaling modern AI systems, yet it remains a complex task due to intricate hardware architectures and the need for specialized optimization expertise. Although Large Language Models (LLMs) demonstrate strong capabilities in general sequential code generation, they face significant challenges in GPU code generation because of the scarcity of high-quality labeled training data, compiler biases when generating synthetic solutions, and limited generalization across hardware generations. This precludes supervised fine-tuning (SFT) as a scalable methodology for improving current LLMs. In contrast, reinforcement learning (RL) offers a data-efficient and adaptive alternative but requires access to relevant tools, careful selection of training problems, and a robust evaluation environment. We present Makora's environment and tools for reinforcement learning finetuning of frontier models and report our results from fine-tuning GPT-5 for Triton code generation. In the single-attempt setting, our fine-tuned model improves kernel correctness from 43.7% to 77.0% (+33.3 percentage points) and increases the fraction of problems outperforming TorchInductor from 14.8% to 21.8% (+7 percentage points) compared to baseline GPT-5, while exceeding prior state-of-the-art models on KernelBench. When integrated into a full coding agent, it is able to solve up to 97.4% of problems in an expanded KernelBench suite, outperforming the PyTorch TorchInductor compiler on 72.9% of problems with a geometric mean speedup of 2.12x. Our work demonstrates that targeted post-training with reinforcement learning can unlock LLM capabilities in highly specialized technical domains where traditional supervised learning is limited by data availability, opening new pathways for AI-assisted accelerator programming.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faMakora\u73af\u5883\u4e0e\u5de5\u5177\uff0c\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u5fae\u8c03\u524d\u6cbf\u6a21\u578bGPT-5\u7528\u4e8eTriton GPU\u4ee3\u7801\u751f\u6210\uff0c\u663e\u8457\u63d0\u5347\u5185\u6838\u6b63\u786e\u6027\u548c\u6027\u80fd\uff0c\u8d85\u8d8a\u4f20\u7edf\u76d1\u7763\u5b66\u4e60\u65b9\u6cd5\u3002", "motivation": "GPU\u5185\u6838\u5f00\u53d1\u5bf9AI\u7cfb\u7edf\u6269\u5c55\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u9762\u4e34\u786c\u4ef6\u67b6\u6784\u590d\u6742\u548c\u4f18\u5316\u4e13\u4e1a\u77e5\u8bc6\u9700\u6c42\u9ad8\u7684\u6311\u6218\u3002\u867d\u7136LLM\u5728\u901a\u7528\u4ee3\u7801\u751f\u6210\u65b9\u9762\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728GPU\u4ee3\u7801\u751f\u6210\u4e2d\u9762\u4e34\u9ad8\u8d28\u91cf\u6807\u6ce8\u6570\u636e\u7a00\u7f3a\u3001\u7f16\u8bd1\u5668\u504f\u89c1\u548c\u786c\u4ef6\u4ee3\u9645\u6cdb\u5316\u6709\u9650\u7b49\u95ee\u9898\uff0c\u4f7f\u5f97\u76d1\u7763\u5fae\u8c03\u65b9\u6cd5\u4e0d\u53ef\u6269\u5c55\u3002", "method": "\u63d0\u51faMakora\u73af\u5883\u548c\u5de5\u5177\u96c6\uff0c\u91c7\u7528\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u5fae\u8c03\u524d\u6cbf\u6a21\u578bGPT-5\uff0c\u4e13\u6ce8\u4e8eTriton GPU\u4ee3\u7801\u751f\u6210\u3002\u8be5\u65b9\u6cd5\u907f\u514d\u4e86\u76d1\u7763\u5b66\u4e60\u5bf9\u5927\u91cf\u6807\u6ce8\u6570\u636e\u7684\u4f9d\u8d56\uff0c\u901a\u8fc7\u7cbe\u5fc3\u9009\u62e9\u8bad\u7ec3\u95ee\u9898\u548c\u6784\u5efa\u9c81\u68d2\u8bc4\u4f30\u73af\u5883\u6765\u4f18\u5316\u6a21\u578b\u3002", "result": "\u5355\u6b21\u5c1d\u8bd5\u8bbe\u7f6e\u4e2d\uff0c\u5fae\u8c03\u6a21\u578b\u5c06\u5185\u6838\u6b63\u786e\u7387\u4ece43.7%\u63d0\u5347\u81f377.0%\uff08+33.3\u4e2a\u767e\u5206\u70b9\uff09\uff0c\u8d85\u8d8aTorchInductor\u7684\u95ee\u9898\u6bd4\u4f8b\u4ece14.8%\u63d0\u5347\u81f321.8%\uff08+7\u4e2a\u767e\u5206\u70b9\uff09\u3002\u5728\u5b8c\u6574\u7f16\u7801\u4ee3\u7406\u4e2d\uff0c\u80fd\u89e3\u51b3\u6269\u5c55KernelBench\u5957\u4ef6\u4e2d97.4%\u7684\u95ee\u9898\uff0c\u572872.9%\u7684\u95ee\u9898\u4e0a\u8d85\u8d8aPyTorch TorchInductor\u7f16\u8bd1\u5668\uff0c\u51e0\u4f55\u5e73\u5747\u52a0\u901f\u6bd4\u8fbe2.12\u500d\u3002", "conclusion": "\u9488\u5bf9\u6027\u7684\u5f3a\u5316\u5b66\u4e60\u540e\u8bad\u7ec3\u80fd\u591f\u89e3\u9501LLM\u5728\u9ad8\u5ea6\u4e13\u4e1a\u5316\u6280\u672f\u9886\u57df\u7684\u80fd\u529b\uff0c\u4e3a\u4f20\u7edf\u76d1\u7763\u5b66\u4e60\u53d7\u6570\u636e\u53ef\u7528\u6027\u9650\u5236\u7684\u573a\u666f\u5f00\u8f9f\u4e86\u65b0\u9014\u5f84\uff0c\u63a8\u52a8\u4e86AI\u8f85\u52a9\u52a0\u901f\u5668\u7f16\u7a0b\u7684\u53d1\u5c55\u3002"}}
{"id": "2602.10479", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.10479", "abs": "https://arxiv.org/abs/2602.10479", "authors": ["Mamdouh Alenezi"], "title": "From Prompt-Response to Goal-Directed Systems: The Evolution of Agentic AI Software Architecture", "comment": null, "summary": "Agentic AI denotes an architectural transition from stateless, prompt-driven generative models toward goal-directed systems capable of autonomous perception, planning, action, and adaptation through iterative control loops. This paper examines this transition by connecting foundational intelligent agent theories, including reactive, deliberative, and Belief-Desire-Intention models, with contemporary LLM-centric approaches such as tool invocation, memory-augmented reasoning, and multi-agent coordination. The paper presents three primary contributions: (i) a reference architecture for production-grade LLM agents that separates cognitive reasoning from execution using typed tool interfaces; (ii) a taxonomy of multi-agent topologies, together with their associated failure modes and mitigation approaches; and (iii) an enterprise hardening checklist that incorporates governance, observability, and reproducibility considerations. Through an analysis of emerging industry platforms, including Kore.ai, Salesforce Agentforce, TrueFoundry, ZenML, and LangChain, the study identifies a convergence toward standardized agent loops, registries, and auditable control mechanisms. It is argued that the subsequent phase of agentic AI development will parallel the maturation of web services, relying on shared protocols, typed contracts, and layered governance structures to support scalable and composable autonomy. The persistent challenges related to verifiability, interoperability, and safe autonomy remain key areas for future research and practical deployment.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63a2\u8ba8\u4e86Agentic AI\u4ece\u9759\u6001\u751f\u6210\u6a21\u578b\u5411\u81ea\u4e3b\u76ee\u6807\u5bfc\u5411\u7cfb\u7edf\u7684\u67b6\u6784\u8f6c\u53d8\uff0c\u63d0\u51fa\u4e86LLM\u667a\u80fd\u4f53\u7684\u53c2\u8003\u67b6\u6784\u3001\u591a\u667a\u80fd\u4f53\u62d3\u6251\u5206\u7c7b\u548c\u4f01\u4e1a\u7ea7\u90e8\u7f72\u6e05\u5355\uff0c\u5206\u6790\u4e86\u884c\u4e1a\u5e73\u53f0\u53d1\u5c55\u8d8b\u52bf\u3002", "motivation": "\u7814\u7a76Agentic AI\u4ece\u63d0\u793a\u9a71\u52a8\u7684\u751f\u6210\u6a21\u578b\u5411\u5177\u6709\u81ea\u4e3b\u611f\u77e5\u3001\u89c4\u5212\u3001\u884c\u52a8\u548c\u9002\u5e94\u80fd\u529b\u7684\u667a\u80fd\u7cfb\u7edf\u7684\u67b6\u6784\u8f6c\u53d8\uff0c\u8fde\u63a5\u4f20\u7edf\u667a\u80fd\u4f53\u7406\u8bba\u4e0e\u73b0\u4ee3LLM\u65b9\u6cd5\uff0c\u4e3a\u751f\u4ea7\u7ea7\u90e8\u7f72\u63d0\u4f9b\u6846\u67b6\u3002", "method": "\u901a\u8fc7\u5206\u6790\u884c\u4e1a\u5e73\u53f0\uff08Kore.ai\u3001Salesforce Agentforce\u3001TrueFoundry\u3001ZenML\u3001LangChain\uff09\uff0c\u63d0\u51fa\u4e09\u65b9\u9762\u8d21\u732e\uff1a1\uff09\u57fa\u4e8e\u7c7b\u578b\u5316\u5de5\u5177\u63a5\u53e3\u5206\u79bb\u8ba4\u77e5\u4e0e\u6267\u884c\u7684\u53c2\u8003\u67b6\u6784\uff1b2\uff09\u591a\u667a\u80fd\u4f53\u62d3\u6251\u5206\u7c7b\u53ca\u6545\u969c\u6a21\u5f0f\u7f13\u89e3\u65b9\u6cd5\uff1b3\uff09\u5305\u542b\u6cbb\u7406\u3001\u53ef\u89c2\u6d4b\u6027\u548c\u53ef\u590d\u73b0\u6027\u7684\u4f01\u4e1a\u7ea7\u68c0\u67e5\u6e05\u5355\u3002", "result": "\u8bc6\u522b\u51fa\u884c\u4e1a\u5411\u6807\u51c6\u5316\u667a\u80fd\u4f53\u5faa\u73af\u3001\u6ce8\u518c\u8868\u548c\u53ef\u5ba1\u8ba1\u63a7\u5236\u673a\u5236\u7684\u8d8b\u540c\u8d8b\u52bf\uff0c\u8ba4\u4e3aAgentic AI\u53d1\u5c55\u5c06\u7c7b\u4f3cWeb\u670d\u52a1\u7684\u6210\u719f\u8fc7\u7a0b\uff0c\u9700\u8981\u5171\u4eab\u534f\u8bae\u3001\u7c7b\u578b\u5316\u5951\u7ea6\u548c\u5206\u5c42\u6cbb\u7406\u7ed3\u6784\u3002", "conclusion": "Agentic AI\u6b63\u5904\u4e8e\u5411\u53ef\u6269\u5c55\u3001\u53ef\u7ec4\u5408\u81ea\u4e3b\u7cfb\u7edf\u53d1\u5c55\u7684\u5173\u952e\u9636\u6bb5\uff0c\u4f46\u53ef\u9a8c\u8bc1\u6027\u3001\u4e92\u64cd\u4f5c\u6027\u548c\u5b89\u5168\u81ea\u4e3b\u6027\u7b49\u6311\u6218\u4ecd\u9700\u672a\u6765\u7814\u7a76\u548c\u5b9e\u9645\u90e8\u7f72\u4e2d\u89e3\u51b3\u3002"}}
{"id": "2602.11125", "categories": ["cs.DC", "cs.RO"], "pdf": "https://arxiv.org/pdf/2602.11125", "abs": "https://arxiv.org/abs/2602.11125", "authors": ["Animesh Maiti", "Abhinav Chakraborty", "Bibhuti Das", "Subhash Bhagat", "Krishnendu Mukhopadhyaya"], "title": "Min-Sum Uniform Coverage Problem by Autonomous Mobile Robots", "comment": null, "summary": "We study the \\textit{min-sum uniform coverage} problem for a swarm of $n$ mobile robots on a given finite line segment and on a circle having finite positive radius, where the circle is given as an input. The robots must coordinate their movements to reach a uniformly spaced configuration that minimizes the total distance traveled by all robots. The robots are autonomous, anonymous, identical, and homogeneous, and operate under the \\textit{Look-Compute-Move} (LCM) model with \\textit{non-rigid} motion controlled by a fair asynchronous scheduler. They are oblivious and silent, possessing neither persistent memory nor a means of explicit communication. In the \\textbf{line-segment setting}, the \\textit{min-sum uniform coverage} problem requires placing the robots at uniformly spaced points along the segment so as to minimize the total distance traveled by all robots. In the \\textbf{circle setting} for this problem, the robots have to arrange themselves uniformly around the given circle to form a regular $n$-gon. There is no fixed orientation or designated starting vertex, and the goal is to minimize the total distance traveled by all the robots. We present a deterministic distributed algorithm that achieves uniform coverage in the line-segment setting with minimum total movement cost. For the circle setting, we characterize all initial configurations for which the \\textit{min-sum uniform coverage} problem is deterministically unsolvable under the considered robot model. For all the other remaining configurations, we provide a deterministic distributed algorithm that achieves uniform coverage while minimizing the total distance traveled. These results characterize the deterministic solvability of min-sum coverage for oblivious robots and achieve optimal cost whenever solvable.", "AI": {"tldr": "\u7814\u7a76\u79fb\u52a8\u673a\u5668\u4eba\u5728\u7ebf\u6bb5\u548c\u5706\u4e0a\u7684\u6700\u5c0f\u603b\u79fb\u52a8\u8ddd\u79bb\u5747\u5300\u8986\u76d6\u95ee\u9898\uff0c\u63d0\u51fa\u786e\u5b9a\u6027\u5206\u5e03\u5f0f\u7b97\u6cd5\u5b9e\u73b0\u6700\u4f18\u6210\u672c\u8986\u76d6", "motivation": "\u7814\u7a76\u5728\u6709\u9650\u7ebf\u6bb5\u548c\u5706\u4e0a\uff0c\u4e00\u7fa4\u79fb\u52a8\u673a\u5668\u4eba\u5982\u4f55\u534f\u8c03\u8fd0\u52a8\u4ee5\u8fbe\u5230\u5747\u5300\u95f4\u9694\u914d\u7f6e\uff0c\u540c\u65f6\u6700\u5c0f\u5316\u6240\u6709\u673a\u5668\u4eba\u79fb\u52a8\u7684\u603b\u8ddd\u79bb\u3002\u673a\u5668\u4eba\u5177\u6709\u81ea\u4e3b\u6027\u3001\u533f\u540d\u6027\u3001\u76f8\u540c\u6027\u3001\u540c\u8d28\u6027\uff0c\u5728\u975e\u521a\u6027\u8fd0\u52a8\u63a7\u5236\u7684\u516c\u5e73\u5f02\u6b65\u8c03\u5ea6\u5668\u4e0b\u8fd0\u884c\uff0c\u4e14\u65e0\u6301\u4e45\u8bb0\u5fc6\u548c\u663e\u5f0f\u901a\u4fe1\u80fd\u529b\u3002", "method": "\u5728\u7ebf\u6bb5\u8bbe\u7f6e\u4e2d\uff0c\u63d0\u51fa\u786e\u5b9a\u6027\u5206\u5e03\u5f0f\u7b97\u6cd5\u5b9e\u73b0\u5747\u5300\u8986\u76d6\u5e76\u6700\u5c0f\u5316\u603b\u79fb\u52a8\u8ddd\u79bb\u3002\u5728\u5706\u8bbe\u7f6e\u4e2d\uff0c\u9996\u5148\u523b\u753b\u6240\u6709\u786e\u5b9a\u6027\u4e0d\u53ef\u89e3\u521d\u59cb\u914d\u7f6e\uff0c\u7136\u540e\u4e3a\u5176\u4f59\u914d\u7f6e\u63d0\u4f9b\u786e\u5b9a\u6027\u5206\u5e03\u5f0f\u7b97\u6cd5\u5b9e\u73b0\u5747\u5300\u8986\u76d6\u5e76\u6700\u5c0f\u5316\u603b\u79fb\u52a8\u8ddd\u79bb\u3002", "result": "\u5728\u7ebf\u6bb5\u8bbe\u7f6e\u4e2d\uff0c\u7b97\u6cd5\u5b9e\u73b0\u4e86\u6700\u5c0f\u603b\u79fb\u52a8\u6210\u672c\u7684\u5747\u5300\u8986\u76d6\u3002\u5728\u5706\u8bbe\u7f6e\u4e2d\uff0c\u523b\u753b\u4e86\u786e\u5b9a\u6027\u4e0d\u53ef\u89e3\u914d\u7f6e\uff0c\u5e76\u4e3a\u53ef\u89e3\u914d\u7f6e\u63d0\u4f9b\u4e86\u5b9e\u73b0\u6700\u5c0f\u603b\u79fb\u52a8\u8ddd\u79bb\u7684\u7b97\u6cd5\u3002", "conclusion": "\u8fd9\u4e9b\u7ed3\u679c\u523b\u753b\u4e86\u65e0\u8bb0\u5fc6\u673a\u5668\u4eba\u6700\u5c0f\u548c\u8986\u76d6\u95ee\u9898\u7684\u786e\u5b9a\u6027\u53ef\u89e3\u6027\uff0c\u5e76\u5728\u53ef\u89e3\u65f6\u5b9e\u73b0\u4e86\u6700\u4f18\u6210\u672c\uff0c\u4e3a\u79fb\u52a8\u673a\u5668\u4eba\u7684\u5747\u5300\u8986\u76d6\u95ee\u9898\u63d0\u4f9b\u4e86\u5b8c\u6574\u7684\u7406\u8bba\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.10522", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.10522", "abs": "https://arxiv.org/abs/2602.10522", "authors": ["Hamed Taherkhani", "Alireza DaghighFarsoodeh", "Mohammad Chowdhury", "Hung Viet Pham", "Hadi Hemmati"], "title": "Consistency Meets Verification: Enhancing Test Generation Quality in Large Language Models Without Ground-Truth Solutions", "comment": null, "summary": "Large Language Models (LLMs) have significantly advanced automated test generation, yet existing methods often rely on ground-truth code for verification, risking bug propagation and limiting applicability in test-driven development. We present ConVerTest, a novel two-stage pipeline for synthesizing reliable tests without requiring prior code implementations. ConVerTest integrates three core strategies: (i) Self-Consistency(SC) to generate convergent test cases via majority voting; (ii) Chain-of-Verification (CoVe) for iterative, reasoning-guided code refinement; and (iii) a Dual Execution Agreement to crossvalidate code and tests through consensus. Experiments on BIGCODEBENCH and LESS BASIC PYTHON PROBLEMS (LBPP) benchmarks demonstrate that ConVerTest improves test validity, line coverage, and mutation scores by up to 39%, 28%, and 18% respectively over baselines. Our findings highlight ConVerTest as a robust solution for mitigating hallucinations and enhancing the reliability of autonomous software testing agents.", "AI": {"tldr": "ConVerTest\uff1a\u65e0\u9700\u771f\u5b9e\u4ee3\u7801\u5373\u53ef\u751f\u6210\u53ef\u9760\u6d4b\u8bd5\u7684\u4e24\u9636\u6bb5\u7ba1\u9053\uff0c\u901a\u8fc7\u81ea\u4e00\u81f4\u6027\u3001\u9a8c\u8bc1\u94fe\u548c\u53cc\u91cd\u6267\u884c\u534f\u8bae\u63d0\u5347\u6d4b\u8bd5\u6709\u6548\u6027\u3001\u8986\u76d6\u7387\u548c\u53d8\u5f02\u5206\u6570", "motivation": "\u73b0\u6709LLM\u6d4b\u8bd5\u751f\u6210\u65b9\u6cd5\u4f9d\u8d56\u771f\u5b9e\u4ee3\u7801\u8fdb\u884c\u9a8c\u8bc1\uff0c\u5b58\u5728bug\u4f20\u64ad\u98ce\u9669\uff0c\u4e14\u5728\u6d4b\u8bd5\u9a71\u52a8\u5f00\u53d1\u4e2d\u9002\u7528\u6027\u6709\u9650\uff0c\u9700\u8981\u65e0\u9700\u5148\u9a8c\u4ee3\u7801\u5b9e\u73b0\u5373\u53ef\u751f\u6210\u53ef\u9760\u6d4b\u8bd5\u7684\u65b9\u6cd5", "method": "\u4e24\u9636\u6bb5\u7ba1\u9053\uff1a1\uff09\u81ea\u4e00\u81f4\u6027\u901a\u8fc7\u591a\u6570\u6295\u7968\u751f\u6210\u6536\u655b\u6d4b\u8bd5\u7528\u4f8b\uff1b2\uff09\u9a8c\u8bc1\u94fe\u8fdb\u884c\u8fed\u4ee3\u3001\u63a8\u7406\u5f15\u5bfc\u7684\u4ee3\u7801\u7cbe\u70bc\uff1b3\uff09\u53cc\u91cd\u6267\u884c\u534f\u8bae\u901a\u8fc7\u5171\u8bc6\u4ea4\u53c9\u9a8c\u8bc1\u4ee3\u7801\u548c\u6d4b\u8bd5", "result": "\u5728BIGCODEBENCH\u548cLBPP\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cConVerTest\u5c06\u6d4b\u8bd5\u6709\u6548\u6027\u3001\u884c\u8986\u76d6\u7387\u548c\u53d8\u5f02\u5206\u6570\u5206\u522b\u63d0\u5347\u9ad8\u8fbe39%\u300128%\u548c18%\uff0c\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5", "conclusion": "ConVerTest\u662f\u7f13\u89e3\u5e7b\u89c9\u3001\u589e\u5f3a\u81ea\u4e3b\u8f6f\u4ef6\u6d4b\u8bd5\u4ee3\u7406\u53ef\u9760\u6027\u7684\u7a33\u5065\u89e3\u51b3\u65b9\u6848\uff0c\u4e3a\u65e0\u9700\u5148\u9a8c\u4ee3\u7801\u5b9e\u73b0\u7684\u53ef\u9760\u6d4b\u8bd5\u751f\u6210\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6cd5"}}
{"id": "2602.10540", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.10540", "abs": "https://arxiv.org/abs/2602.10540", "authors": ["Arty Starr", "Margaret-Anne Storey"], "title": "Theory of Troubleshooting: The Developer's Cognitive Experience of Overcoming Confusion", "comment": "42 pages + 16 pages of appendix, 13 figures, 2 tables", "summary": "This paper introduces a Theory of Troubleshooting that is rooted in cognitive science. This theory helps software developers explain the challenges they face and the project risks that emerge as troubleshooting becomes difficult. We define troubleshooting as the cognitive problem-solving process of identifying, understanding, and constructing a mental model of the cause of an unexpected system behavior, and consider the cognitive process of troubleshooting to be an integral part of the activity of debugging. Troubleshooting is a particularly intense and draining aspect of software work, placing sustained demands on attention, working memory, and mental modeling. By surfacing and naming the confusion experience inherent in troubleshooting in terms of neurological and attentional dynamics, our theory explains how prolonged troubleshooting can deplete cognitive resources and lead to cognitive fatigue. In the study presented in this paper, we interview 27 professional developers about their troubleshooting experiences, and follow a Constructivist Grounded Theory approach to construct a theory grounded in empirical data. Our theory contributes to research on Developer Experience by providing a cognitive foundation for understanding troubleshooting difficulty, fatigue, and sustainability risk--and offers practical implications for both research and industry.", "AI": {"tldr": "\u672c\u6587\u57fa\u4e8e\u8ba4\u77e5\u79d1\u5b66\u63d0\u51fa\u4e86\u4e00\u4e2a\u6545\u969c\u6392\u9664\u7406\u8bba\uff0c\u89e3\u91ca\u8f6f\u4ef6\u5f00\u53d1\u8005\u5728\u6392\u67e5\u95ee\u9898\u65f6\u7684\u8ba4\u77e5\u6311\u6218\u548c\u9879\u76ee\u98ce\u9669\uff0c\u901a\u8fc7\u8bbf\u8c0827\u4f4d\u4e13\u4e1a\u5f00\u53d1\u8005\u6784\u5efa\u4e86\u8be5\u7406\u8bba\u3002", "motivation": "\u6545\u969c\u6392\u9664\u662f\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u7279\u522b\u8017\u8d39\u7cbe\u529b\u7684\u90e8\u5206\uff0c\u5bf9\u6ce8\u610f\u529b\u3001\u5de5\u4f5c\u8bb0\u5fc6\u548c\u5fc3\u7406\u5efa\u6a21\u6709\u6301\u7eed\u9700\u6c42\uff0c\u4f46\u7f3a\u4e4f\u4ece\u8ba4\u77e5\u79d1\u5b66\u89d2\u5ea6\u7cfb\u7edf\u7406\u89e3\u8fd9\u4e00\u8fc7\u7a0b\u7684\u7406\u8bba\u6846\u67b6\u3002", "method": "\u91c7\u7528\u5efa\u6784\u4e3b\u4e49\u624e\u6839\u7406\u8bba\u65b9\u6cd5\uff0c\u8bbf\u8c0827\u4f4d\u4e13\u4e1a\u5f00\u53d1\u8005\u5173\u4e8e\u4ed6\u4eec\u7684\u6545\u969c\u6392\u9664\u7ecf\u9a8c\uff0c\u57fa\u4e8e\u5b9e\u8bc1\u6570\u636e\u6784\u5efa\u7406\u8bba\u6846\u67b6\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u8ba4\u77e5\u79d1\u5b66\u7684\u6545\u969c\u6392\u9664\u7406\u8bba\uff0c\u89e3\u91ca\u4e86\u6545\u969c\u6392\u9664\u5982\u4f55\u6d88\u8017\u8ba4\u77e5\u8d44\u6e90\u5e76\u5bfc\u81f4\u8ba4\u77e5\u75b2\u52b3\uff0c\u63ed\u793a\u4e86\u56f0\u60d1\u4f53\u9a8c\u7684\u795e\u7ecf\u548c\u6ce8\u610f\u529b\u52a8\u6001\u673a\u5236\u3002", "conclusion": "\u8be5\u7406\u8bba\u4e3a\u7406\u89e3\u6545\u969c\u6392\u9664\u7684\u56f0\u96be\u3001\u75b2\u52b3\u548c\u53ef\u6301\u7eed\u6027\u98ce\u9669\u63d0\u4f9b\u4e86\u8ba4\u77e5\u57fa\u7840\uff0c\u5bf9\u5f00\u53d1\u8005\u4f53\u9a8c\u7814\u7a76\u548c\u5de5\u4e1a\u5b9e\u8df5\u90fd\u6709\u5b9e\u9645\u610f\u4e49\u3002"}}
{"id": "2602.10620", "categories": ["cs.SE", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.10620", "abs": "https://arxiv.org/abs/2602.10620", "authors": ["YoungHoon Jeon", "Suwan Kim", "Haein Son", "Sookbun Lee", "Yeil Jeong", "Unggi Lee"], "title": "ISD-Agent-Bench: A Comprehensive Benchmark for Evaluating LLM-based Instructional Design Agents", "comment": null, "summary": "Large Language Model (LLM) agents have shown promising potential in automating Instructional Systems Design (ISD), a systematic approach to developing educational programs. However, evaluating these agents remains challenging due to the lack of standardized benchmarks and the risk of LLM-as-judge bias. We present ISD-Agent-Bench, a comprehensive benchmark comprising 25,795 scenarios generated via a Context Matrix framework that combines 51 contextual variables across 5 categories with 33 ISD sub-steps derived from the ADDIE model. To ensure evaluation reliability, we employ a multi-judge protocol using diverse LLMs from different providers, achieving high inter-judge reliability. We compare existing ISD agents with novel agents grounded in classical ISD theories such as ADDIE, Dick \\& Carey, and Rapid Prototyping ISD. Experiments on 1,017 test scenarios demonstrate that integrating classical ISD frameworks with modern ReAct-style reasoning achieves the highest performance, outperforming both pure theory-based agents and technique-only approaches. Further analysis reveals that theoretical quality strongly correlates with benchmark performance, with theory-based agents showing significant advantages in problem-centered design and objective-assessment alignment. Our work provides a foundation for systematic LLM-based ISD research.", "AI": {"tldr": "ISD-Agent-Bench\uff1a\u4e00\u4e2a\u5305\u542b25,795\u4e2a\u573a\u666f\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u4e8e\u8bc4\u4f30LLM\u5728\u6559\u5b66\u8bbe\u8ba1\u4e2d\u7684\u81ea\u52a8\u5316\u80fd\u529b\uff0c\u7ed3\u5408\u7ecf\u5178ISD\u7406\u8bba\u4e0e\u73b0\u4ee3\u63a8\u7406\u65b9\u6cd5\u8868\u73b0\u6700\u4f73", "motivation": "\u5f53\u524dLLM\u4ee3\u7406\u5728\u81ea\u52a8\u5316\u6559\u5b66\u8bbe\u8ba1\u65b9\u9762\u6709\u6f5c\u529b\uff0c\u4f46\u7f3a\u4e4f\u6807\u51c6\u5316\u57fa\u51c6\u8bc4\u4f30\uff0c\u4e14\u5b58\u5728LLM\u4f5c\u4e3a\u8bc4\u5224\u8005\u7684\u504f\u89c1\u98ce\u9669", "method": "\u901a\u8fc7\u4e0a\u4e0b\u6587\u77e9\u9635\u6846\u67b6\u751f\u621025,795\u4e2a\u573a\u666f\uff0c\u7ed3\u540851\u4e2a\u4e0a\u4e0b\u6587\u53d8\u91cf\u548c33\u4e2aADDIE\u5b50\u6b65\u9aa4\uff1b\u91c7\u7528\u591a\u8bc4\u5224\u534f\u8bae\u4f7f\u7528\u4e0d\u540c\u63d0\u4f9b\u5546\u7684LLM\u786e\u4fdd\u53ef\u9760\u6027\uff1b\u6bd4\u8f83\u57fa\u4e8e\u7ecf\u5178ISD\u7406\u8bba\uff08ADDIE\u3001Dick & Carey\u3001\u5feb\u901f\u539f\u578b\uff09\u7684\u4ee3\u7406\u4e0e\u73b0\u6709\u65b9\u6cd5", "result": "\u57281,017\u4e2a\u6d4b\u8bd5\u573a\u666f\u4e2d\uff0c\u7ed3\u5408\u7ecf\u5178ISD\u6846\u67b6\u4e0e\u73b0\u4ee3ReAct\u63a8\u7406\u7684\u4ee3\u7406\u8868\u73b0\u6700\u4f73\uff0c\u8d85\u8d8a\u7eaf\u7406\u8bba\u4ee3\u7406\u548c\u7eaf\u6280\u672f\u65b9\u6cd5\uff1b\u7406\u8bba\u8d28\u91cf\u4e0e\u57fa\u51c6\u8868\u73b0\u5f3a\u76f8\u5173\uff0c\u7406\u8bba\u4ee3\u7406\u5728\u95ee\u9898\u4e2d\u5fc3\u8bbe\u8ba1\u548c\u76ee\u6807\u8bc4\u4f30\u5bf9\u9f50\u65b9\u9762\u4f18\u52bf\u663e\u8457", "conclusion": "\u7ecf\u5178ISD\u7406\u8bba\u4e0e\u73b0\u4ee3LLM\u63a8\u7406\u7684\u7ed3\u5408\u4e3a\u81ea\u52a8\u5316\u6559\u5b66\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u6700\u4f73\u65b9\u6848\uff0cISD-Agent-Bench\u4e3a\u7cfb\u7edf\u5316LLM-based ISD\u7814\u7a76\u5960\u5b9a\u4e86\u57fa\u7840"}}
{"id": "2602.10655", "categories": ["cs.SE", "cs.RO"], "pdf": "https://arxiv.org/pdf/2602.10655", "abs": "https://arxiv.org/abs/2602.10655", "authors": ["Muhammad Yousaf", "Aitor Arrieta", "Shaukat Ali", "Paolo Arcaini", "Shuai Wang"], "title": "Assessing Vision-Language Models for Perception in Autonomous Underwater Robotic Software", "comment": "10 pages, 5 figures, submitted to ICST 2026", "summary": "Autonomous Underwater Robots (AURs) operate in challenging underwater environments, including low visibility and harsh water conditions. Such conditions present challenges for software engineers developing perception modules for the AUR software. To successfully carry out these tasks, deep learning has been incorporated into the AUR software to support its operations. However, the unique challenges of underwater environments pose difficulties for deep learning models, which often rely on labeled data that is scarce and noisy. This may undermine the trustworthiness of AUR software that relies on perception modules. Vision-Language Models (VLMs) offer promising solutions for AUR software as they generalize to unseen objects and remain robust in noisy conditions by inferring information from contextual cues. Despite this potential, their performance and uncertainty in underwater environments remain understudied from a software engineering perspective. Motivated by the needs of an industrial partner in assurance and risk management for maritime systems to assess the potential use of VLMs in this context, we present an empirical evaluation of VLM-based perception modules within the AUR software. We assess their ability to detect underwater trash by computing performance, uncertainty, and their relationship, to enable software engineers to select appropriate VLMs for their AUR software.", "AI": {"tldr": "\u672c\u6587\u5bf9\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u6c34\u4e0b\u673a\u5668\u4eba\u8f6f\u4ef6\u4e2d\u7684\u611f\u77e5\u6a21\u5757\u8fdb\u884c\u5b9e\u8bc1\u8bc4\u4f30\uff0c\u5206\u6790\u5176\u5728\u68c0\u6d4b\u6c34\u4e0b\u5783\u573e\u65f6\u7684\u6027\u80fd\u3001\u4e0d\u786e\u5b9a\u6027\u53ca\u5176\u5173\u7cfb\uff0c\u4e3a\u8f6f\u4ef6\u5de5\u7a0b\u5e08\u9009\u62e9\u5408\u9002\u6a21\u578b\u63d0\u4f9b\u4f9d\u636e\u3002", "motivation": "\u6c34\u4e0b\u673a\u5668\u4eba\u9762\u4e34\u4f4e\u80fd\u89c1\u5ea6\u548c\u6076\u52a3\u73af\u5883\u6761\u4ef6\uff0c\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u4f9d\u8d56\u7a00\u7f3a\u4e14\u6709\u566a\u58f0\u7684\u6807\u6ce8\u6570\u636e\uff0c\u53ef\u80fd\u5f71\u54cd\u611f\u77e5\u6a21\u5757\u7684\u53ef\u4fe1\u5ea6\u3002\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5177\u6709\u6cdb\u5316\u5230\u672a\u89c1\u5bf9\u8c61\u548c\u5728\u566a\u58f0\u6761\u4ef6\u4e0b\u4fdd\u6301\u9c81\u68d2\u6027\u7684\u6f5c\u529b\uff0c\u4f46\u5176\u5728\u6c34\u4e0b\u73af\u5883\u4e2d\u7684\u6027\u80fd\u548c\u4e0d\u786e\u5b9a\u6027\u5c1a\u672a\u4ece\u8f6f\u4ef6\u5de5\u7a0b\u89d2\u5ea6\u5f97\u5230\u5145\u5206\u7814\u7a76\u3002", "method": "\u5bf9\u57fa\u4e8e\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u611f\u77e5\u6a21\u5757\u8fdb\u884c\u5b9e\u8bc1\u8bc4\u4f30\uff0c\u901a\u8fc7\u8ba1\u7b97\u6027\u80fd\u3001\u4e0d\u786e\u5b9a\u6027\u4ee5\u53ca\u5b83\u4eec\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u8bc4\u4f30\u5176\u68c0\u6d4b\u6c34\u4e0b\u5783\u573e\u7684\u80fd\u529b\u3002", "result": "\u7814\u7a76\u63d0\u4f9b\u4e86\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u6c34\u4e0b\u73af\u5883\u4e2d\u7684\u6027\u80fd\u3001\u4e0d\u786e\u5b9a\u6027\u53ca\u5176\u5173\u7cfb\u7684\u8bc4\u4f30\u7ed3\u679c\uff0c\u4f46\u5177\u4f53\u6570\u636e\u672a\u5728\u6458\u8981\u4e2d\u7ed9\u51fa\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u8f6f\u4ef6\u5de5\u7a0b\u5e08\u9009\u62e9\u9002\u5408\u6c34\u4e0b\u673a\u5668\u4eba\u8f6f\u4ef6\u7684\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u4e86\u5b9e\u8bc1\u4f9d\u636e\uff0c\u6709\u52a9\u4e8e\u8bc4\u4f30\u611f\u77e5\u6a21\u5757\u5728\u5177\u6709\u6311\u6218\u6027\u7684\u6c34\u4e0b\u73af\u5883\u4e2d\u7684\u53ef\u4fe1\u5ea6\u3002"}}
{"id": "2602.10758", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.10758", "abs": "https://arxiv.org/abs/2602.10758", "authors": ["Bo Wang", "Yueyang Chen", "Jieke Shi", "Minghui Li", "Yunbo Lyu", "Yinan Wu", "Youfang Lin", "Zhou Yang"], "title": "Hidden Licensing Risks in the LLMware Ecosystem", "comment": null, "summary": "Large Language Models (LLMs) are increasingly integrated into software systems, giving rise to a new class of systems referred to as LLMware. Beyond traditional source-code components, LLMware embeds or interacts with LLMs that depend on other models and datasets, forming complex supply chains across open-source software (OSS), models, and datasets. However, licensing issues emerging from these intertwined dependencies remain largely unexplored. Leveraging GitHub and Hugging Face, we curate a large-scale dataset capturing LLMware supply chains, including 12,180 OSS repositories, 3,988 LLMs, and 708 datasets. Our analysis reveals that license distributions in LLMware differ substantially from traditional OSS ecosystems. We further examine license-related discussions and find that license selection and maintenance are the dominant concerns, accounting for 84% of cases. To understand incompatibility risks, we analyze license conflicts along supply chains and evaluate state-of-the-art detection approaches, which achieve only 58% and 76% F1 scores in this setting. Motivated by these limitations, we propose LiAgent, an LLM-based agent framework for ecosystem-level license compatibility analysis. LiAgent achieves an F1 score of 87%, improving performance by 14 percentage points over prior methods. We reported 60 incompatibility issues detected by LiAgent, 11 of which have been confirmed by developers. Notably, two conflicted LLMs have over 107 million and 5 million downloads on Hugging Face, respectively, indicating potentially widespread downstream impact. We conclude with implications and recommendations to support the sustainable growth of the LLMware ecosystem.", "AI": {"tldr": "\u7814\u7a76\u5206\u6790\u4e86LLMware\uff08\u96c6\u6210LLM\u7684\u8f6f\u4ef6\u7cfb\u7edf\uff09\u4e2d\u7684\u8bb8\u53ef\u8bc1\u95ee\u9898\uff0c\u6784\u5efa\u4e86\u5927\u89c4\u6a21\u6570\u636e\u96c6\uff0c\u53d1\u73b0\u8bb8\u53ef\u8bc1\u5206\u5e03\u4e0e\u4f20\u7edfOSS\u4e0d\u540c\uff0c\u73b0\u6709\u68c0\u6d4b\u65b9\u6cd5\u6548\u679c\u6709\u9650\uff0c\u63d0\u51fa\u4e86\u57fa\u4e8eLLM\u7684\u4ee3\u7406\u6846\u67b6LiAgent\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8bb8\u53ef\u8bc1\u517c\u5bb9\u6027\u68c0\u6d4b\u6027\u80fd\u3002", "motivation": "LLMware\uff08\u96c6\u6210\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8f6f\u4ef6\u7cfb\u7edf\uff09\u5f62\u6210\u4e86\u8de8\u8d8a\u5f00\u6e90\u8f6f\u4ef6\u3001\u6a21\u578b\u548c\u6570\u636e\u96c6\u7684\u590d\u6742\u4f9b\u5e94\u94fe\uff0c\u4f46\u8fd9\u4e9b\u4ea4\u7ec7\u4f9d\u8d56\u5173\u7cfb\u4e2d\u7684\u8bb8\u53ef\u8bc1\u95ee\u9898\u5c1a\u672a\u5f97\u5230\u5145\u5206\u7814\u7a76\uff0c\u9700\u8981\u7cfb\u7edf\u6027\u5206\u6790\u5176\u98ce\u9669\u3002", "method": "1. \u4eceGitHub\u548cHugging Face\u6536\u96c6\u5927\u89c4\u6a21LLMware\u4f9b\u5e94\u94fe\u6570\u636e\u96c6\uff0812,180\u4e2aOSS\u4ed3\u5e93\u30013,988\u4e2aLLM\u3001708\u4e2a\u6570\u636e\u96c6\uff09\uff1b2. \u5206\u6790\u8bb8\u53ef\u8bc1\u5206\u5e03\u7279\u5f81\uff1b3. \u7814\u7a76\u8bb8\u53ef\u8bc1\u76f8\u5173\u8ba8\u8bba\uff1b4. \u8bc4\u4f30\u73b0\u6709\u68c0\u6d4b\u65b9\u6cd5\uff1b5. \u63d0\u51fa\u57fa\u4e8eLLM\u7684\u4ee3\u7406\u6846\u67b6LiAgent\u8fdb\u884c\u751f\u6001\u7cfb\u7edf\u7ea7\u8bb8\u53ef\u8bc1\u517c\u5bb9\u6027\u5206\u6790\u3002", "result": "1. LLMware\u8bb8\u53ef\u8bc1\u5206\u5e03\u4e0e\u4f20\u7edfOSS\u751f\u6001\u7cfb\u7edf\u663e\u8457\u4e0d\u540c\uff1b2. \u8bb8\u53ef\u8bc1\u9009\u62e9\u548c\u7ef4\u62a4\u662f\u4e3b\u8981\u5173\u6ce8\u70b9\uff08\u536084%\uff09\uff1b3. \u73b0\u6709\u68c0\u6d4b\u65b9\u6cd5F1\u5206\u6570\u4ec558%\u548c76%\uff1b4. LiAgent\u6846\u67b6\u8fbe\u523087%\u7684F1\u5206\u6570\uff0c\u63d0\u534714\u4e2a\u767e\u5206\u70b9\uff1b5. \u68c0\u6d4b\u523060\u4e2a\u4e0d\u517c\u5bb9\u95ee\u9898\uff0c11\u4e2a\u88ab\u5f00\u53d1\u8005\u786e\u8ba4\uff0c\u5176\u4e2d\u4e24\u4e2a\u51b2\u7a81\u6a21\u578b\u4e0b\u8f7d\u91cf\u5206\u522b\u8d85\u8fc71.07\u4ebf\u548c500\u4e07\u6b21\u3002", "conclusion": "LLMware\u751f\u6001\u7cfb\u7edf\u9762\u4e34\u72ec\u7279\u7684\u8bb8\u53ef\u8bc1\u6311\u6218\uff0c\u73b0\u6709\u68c0\u6d4b\u65b9\u6cd5\u4e0d\u8db3\uff0c\u63d0\u51fa\u7684LiAgent\u6846\u67b6\u80fd\u6709\u6548\u8bc6\u522b\u8bb8\u53ef\u8bc1\u51b2\u7a81\uff0c\u6709\u52a9\u4e8e\u652f\u6301LLMware\u751f\u6001\u7cfb\u7edf\u7684\u53ef\u6301\u7eed\u53d1\u5c55\uff0c\u9700\u8981\u5236\u5b9a\u76f8\u5e94\u5efa\u8bae\u548c\u89c4\u8303\u3002"}}
{"id": "2602.10787", "categories": ["cs.SE", "cs.AI", "cs.CR", "cs.IR"], "pdf": "https://arxiv.org/pdf/2602.10787", "abs": "https://arxiv.org/abs/2602.10787", "authors": ["Samal Mukhtar", "Yinghua Yao", "Zhu Sun", "Mustafa Mustafa", "Yew Soon Ong", "Youcheng Sun"], "title": "VulReaD: Knowledge-Graph-guided Software Vulnerability Reasoning and Detection", "comment": "22 pages, 3 figures", "summary": "Software vulnerability detection (SVD) is a critical challenge in modern systems. Large language models (LLMs) offer natural-language explanations alongside predictions, but most work focuses on binary evaluation, and explanations often lack semantic consistency with Common Weakness Enumeration (CWE) categories. We propose VulReaD, a knowledge-graph-guided approach for vulnerability reasoning and detection that moves beyond binary classification toward CWE-level reasoning. VulReaD leverages a security knowledge graph (KG) as a semantic backbone and uses a strong teacher LLM to generate CWE-consistent contrastive reasoning supervision, enabling student model training without manual annotations. Students are fine-tuned with Odds Ratio Preference Optimization (ORPO) to encourage taxonomy-aligned reasoning while suppressing unsupported explanations. Across three real-world datasets, VulReaD improves binary F1 by 8-10% and multi-class classification by 30% Macro-F1 and 18% Micro-F1 compared to state-of-the-art baselines. Results show that LLMs outperform deep learning baselines in binary detection and that KG-guided reasoning enhances CWE coverage and interpretability.", "AI": {"tldr": "VulReaD\uff1a\u57fa\u4e8e\u77e5\u8bc6\u56fe\u8c31\u6307\u5bfc\u7684\u6f0f\u6d1e\u63a8\u7406\u4e0e\u68c0\u6d4b\u65b9\u6cd5\uff0c\u901a\u8fc7\u5b89\u5168\u77e5\u8bc6\u56fe\u8c31\u548c\u6559\u5e08LLM\u751f\u6210CWE\u4e00\u81f4\u7684\u5bf9\u6bd4\u63a8\u7406\u76d1\u7763\uff0c\u63d0\u5347\u6f0f\u6d1e\u68c0\u6d4b\u7684\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u5f53\u524d\u8f6f\u4ef6\u6f0f\u6d1e\u68c0\u6d4b\u4e3b\u8981\u5173\u6ce8\u4e8c\u5143\u5206\u7c7b\uff0c\u7f3a\u4e4f\u4e0eCWE\u7c7b\u522b\u7684\u8bed\u4e49\u4e00\u81f4\u6027\u89e3\u91ca\u3002\u9700\u8981\u8d85\u8d8a\u4e8c\u5143\u5206\u7c7b\uff0c\u5b9e\u73b0CWE\u7ea7\u522b\u7684\u63a8\u7406\u548c\u68c0\u6d4b\u3002", "method": "1. \u4f7f\u7528\u5b89\u5168\u77e5\u8bc6\u56fe\u8c31\u4f5c\u4e3a\u8bed\u4e49\u9aa8\u5e72\uff1b2. \u5229\u7528\u5f3a\u5927\u7684\u6559\u5e08LLM\u751f\u6210CWE\u4e00\u81f4\u7684\u5bf9\u6bd4\u63a8\u7406\u76d1\u7763\uff1b3. \u901a\u8fc7ORPO\u4f18\u5316\u5b66\u751f\u6a21\u578b\uff0c\u9f13\u52b1\u7b26\u5408\u5206\u7c7b\u5b66\u7684\u63a8\u7406\uff0c\u6291\u5236\u65e0\u652f\u6301\u7684\u8bf4\u660e\u3002", "result": "\u5728\u4e09\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\uff0cVulReaD\u76f8\u6bd4\u6700\u5148\u8fdb\u57fa\u7ebf\uff1a\u4e8c\u5143F1\u63d0\u53478-10%\uff0c\u591a\u7c7b\u5206\u7c7b\u63d0\u534730%\u5b8fF1\u548c18%\u5faeF1\u3002LLM\u5728\u4e8c\u5143\u68c0\u6d4b\u4e2d\u4f18\u4e8e\u6df1\u5ea6\u5b66\u4e60\u57fa\u7ebf\uff0cKG\u6307\u5bfc\u7684\u63a8\u7406\u589e\u5f3a\u4e86CWE\u8986\u76d6\u548c\u53ef\u89e3\u91ca\u6027\u3002", "conclusion": "VulReaD\u901a\u8fc7\u77e5\u8bc6\u56fe\u8c31\u5f15\u5bfc\u7684\u63a8\u7406\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6f0f\u6d1e\u68c0\u6d4b\u7684\u51c6\u786e\u6027\u548cCWE\u7ea7\u522b\u7684\u89e3\u91ca\u80fd\u529b\uff0c\u4e3a\u8f6f\u4ef6\u6f0f\u6d1e\u68c0\u6d4b\u63d0\u4f9b\u4e86\u66f4\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.10808", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.10808", "abs": "https://arxiv.org/abs/2602.10808", "authors": ["Rasmus Krebs", "Somnath Mazumdar"], "title": "PELLI: Framework to effectively integrate LLMs for quality software generation", "comment": "15 pages", "summary": "Recent studies have revealed that when LLMs are appropriately prompted and configured, they demonstrate mixed results. Such results often meet or exceed the baseline performance. However, these comparisons have two primary issues. First, they mostly considered only reliability as a comparison metric and selected a few LLMs (such as Codex and ChatGPT) for comparision. This paper proposes a comprehensive code quality assessment framework called Programmatic Excellence via LLM Iteration (PELLI). PELLI is an iterative analysis-based process that upholds high-quality code changes. We extended the state-of-the-art by performing a comprehensive evaluation that generates quantitative metrics for analyzing three primary nonfunctional requirements (such as maintainability, performance, and reliability) while selecting five popular LLMs. For PELLI's applicability, we selected three application domains while following Python coding standards. Following this framework, practitioners can ensure harmonious integration between LLMs and human developers, ensuring that their potential is fully realized. PELLI can serve as a practical guide for developers aiming to leverage LLMs while adhering to recognized quality standards. This study's outcomes are crucial for advancing LLM technologies in real-world applications, providing stakeholders with a clear understanding of where these LLMs excel and where they require further refinement. Overall, based on three nonfunctional requirements, we have found that GPT-4T and Gemini performed slightly better. We also found that prompt design can influence the overall code quality. In addition, each application domain demonstrated high and low scores across various metrics, and even within the same metrics across different prompts.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faPELLI\u6846\u67b6\uff0c\u901a\u8fc7\u8fed\u4ee3\u5206\u6790\u8bc4\u4f30LLM\u751f\u6210\u7684\u4ee3\u7801\u8d28\u91cf\uff0c\u91cd\u70b9\u5173\u6ce8\u53ef\u7ef4\u62a4\u6027\u3001\u6027\u80fd\u548c\u53ef\u9760\u6027\u4e09\u4e2a\u975e\u529f\u80fd\u6027\u9700\u6c42\uff0c\u53d1\u73b0GPT-4T\u548cGemini\u8868\u73b0\u7565\u4f18\uff0c\u63d0\u793a\u8bbe\u8ba1\u5f71\u54cd\u4ee3\u7801\u8d28\u91cf\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u53ef\u9760\u6027\u6307\u6807\u4e14\u4ec5\u6bd4\u8f83\u5c11\u6570LLM\uff08\u5982Codex\u548cChatGPT\uff09\uff0c\u7f3a\u4e4f\u5bf9\u4ee3\u7801\u8d28\u91cf\u7684\u5168\u9762\u8bc4\u4f30\u3002\u9700\u8981\u5efa\u7acb\u7cfb\u7edf\u6846\u67b6\u6765\u8bc4\u4f30LLM\u751f\u6210\u7684\u4ee3\u7801\u8d28\u91cf\uff0c\u4fc3\u8fdbLLM\u4e0e\u4eba\u7c7b\u5f00\u53d1\u8005\u7684\u6709\u6548\u534f\u4f5c\u3002", "method": "\u63d0\u51faPELLI\uff08Programmatic Excellence via LLM Iteration\uff09\u6846\u67b6\uff0c\u57fa\u4e8e\u8fed\u4ee3\u5206\u6790\u8fc7\u7a0b\u786e\u4fdd\u9ad8\u8d28\u91cf\u4ee3\u7801\u53d8\u66f4\u3002\u5bf95\u4e2a\u6d41\u884cLLM\u8fdb\u884c\u7efc\u5408\u8bc4\u4f30\uff0c\u751f\u6210\u4e09\u4e2a\u975e\u529f\u80fd\u6027\u9700\u6c42\uff08\u53ef\u7ef4\u62a4\u6027\u3001\u6027\u80fd\u3001\u53ef\u9760\u6027\uff09\u7684\u91cf\u5316\u6307\u6807\uff0c\u5728\u4e09\u4e2a\u5e94\u7528\u9886\u57df\u9075\u5faaPython\u7f16\u7801\u6807\u51c6\u8fdb\u884c\u6d4b\u8bd5\u3002", "result": "GPT-4T\u548cGemini\u5728\u4e09\u4e2a\u975e\u529f\u80fd\u6027\u9700\u6c42\u4e0a\u8868\u73b0\u7565\u4f18\uff1b\u63d0\u793a\u8bbe\u8ba1\u663e\u8457\u5f71\u54cd\u6574\u4f53\u4ee3\u7801\u8d28\u91cf\uff1b\u4e0d\u540c\u5e94\u7528\u9886\u57df\u5728\u4e0d\u540c\u6307\u6807\u4e0a\u8868\u73b0\u6709\u9ad8\u6709\u4f4e\uff0c\u540c\u4e00\u6307\u6807\u5728\u4e0d\u540c\u63d0\u793a\u4e0b\u4e5f\u6709\u5dee\u5f02\u3002", "conclusion": "PELLI\u6846\u67b6\u53ef\u4f5c\u4e3a\u5f00\u53d1\u8005\u5728\u9075\u5faa\u8d28\u91cf\u6807\u51c6\u7684\u540c\u65f6\u5229\u7528LLM\u7684\u5b9e\u7528\u6307\u5357\uff0c\u4fc3\u8fdbLLM\u6280\u672f\u5728\u73b0\u5b9e\u5e94\u7528\u4e2d\u7684\u53d1\u5c55\uff0c\u5e2e\u52a9\u5229\u76ca\u76f8\u5173\u8005\u4e86\u89e3LLM\u7684\u4f18\u52bf\u548c\u6539\u8fdb\u65b9\u5411\u3002"}}
{"id": "2602.10972", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.10972", "abs": "https://arxiv.org/abs/2602.10972", "authors": ["Hina Saeeda", "Mijin Kim", "Eric Knauss", "Jesper Thyssen", "Jesper \u00d8rting", "Jesper Lysemose Korsgaard", "Niels J\u00f8rgen Str\u00f8m"], "title": "Deriving and Validating Requirements Engineering Principles for Large-Scale Agile Development: An Industrial Longitudinal Study", "comment": null, "summary": "In large scale agile systems development, the lack of a unified requirements engineering (RE) process is a major challenge, exacerbated by the absence of high level guiding principles for effective requirements management. To address this challenge, we conducted a five year longitudinal case study with Grundfos AB, in collaboration with the Software Centre in Sweden. RE principles were first derived through qualitative data collection spanning more than 25 sprints, approximately 320 weekly synchronisation meetings, and seven cross-company, company-specific workshops between 2019 and 2024. These activities engaged practitioners from diverse roles, representing several hundred developers across domains. In late 2024, five in depth focus groups with senior leaders at Grundfos provided retrospective validation of the principles and assessed their strategic impact. We aim to (1) empirically examine RE principles in large scale agile system development, (2) explore their benefits in practice within the case company, and (3) identify a set of transferable RE principles for large scale contexts. Using thematic analysis, six key RE principles architectural context, stakeholder-driven validation and alignment, requirements practices in large-scale agile organisations. evolution with lightweight documentation, delegated requirements management, organisational roles and responsibilities, and a shared understanding of requirements are derived. The study was further validated through crosscompany expert evaluation with three additional multinational organisations (Bosch, Ericsson, and Volvo Cars), which are directly responsible for largescale requirements management. Together, these efforts provide a scalable and adaptable foundation for improving requirements practices in largescale agile organisations.", "AI": {"tldr": "\u901a\u8fc75\u5e74\u7eb5\u5411\u6848\u4f8b\u7814\u7a76\uff0c\u4e3a\u5927\u89c4\u6a21\u654f\u6377\u7ec4\u7ec7\u63d0\u51fa6\u4e2a\u53ef\u8f6c\u79fb\u7684\u9700\u6c42\u5de5\u7a0b\u539f\u5219\uff0c\u5305\u62ec\u67b6\u6784\u4e0a\u4e0b\u6587\u3001\u5229\u76ca\u76f8\u5173\u8005\u9a71\u52a8\u9a8c\u8bc1\u3001\u8f7b\u91cf\u7ea7\u6587\u6863\u6f14\u5316\u7b49\u3002", "motivation": "\u5927\u89c4\u6a21\u654f\u6377\u7cfb\u7edf\u5f00\u53d1\u4e2d\u7f3a\u4e4f\u7edf\u4e00\u7684\u9700\u6c42\u5de5\u7a0b\u6d41\u7a0b\u548c\u9ad8\u7ea7\u6307\u5bfc\u539f\u5219\uff0c\u5bfc\u81f4\u9700\u6c42\u7ba1\u7406\u56f0\u96be\uff0c\u9700\u8981\u5efa\u7acb\u53ef\u6269\u5c55\u7684\u5b9e\u8df5\u57fa\u7840\u3002", "method": "\u91c7\u75285\u5e74\u7eb5\u5411\u6848\u4f8b\u7814\u7a76\uff0c\u6536\u96c6\u8d85\u8fc725\u4e2a\u51b2\u523a\u3001320\u6b21\u5468\u4f1a\u30017\u4e2a\u8de8\u516c\u53f8\u7814\u8ba8\u4f1a\u7684\u5b9a\u6027\u6570\u636e\uff0c\u901a\u8fc7\u4e3b\u9898\u5206\u6790\u5f97\u51fa\u539f\u5219\uff0c\u5e76\u75313\u5bb6\u8de8\u56fd\u516c\u53f8\u4e13\u5bb6\u9a8c\u8bc1\u3002", "result": "\u8bc6\u522b\u51fa6\u4e2a\u5173\u952e\u9700\u6c42\u5de5\u7a0b\u539f\u5219\uff1a\u67b6\u6784\u4e0a\u4e0b\u6587\u3001\u5229\u76ca\u76f8\u5173\u8005\u9a71\u52a8\u9a8c\u8bc1\u4e0e\u5bf9\u9f50\u3001\u8f7b\u91cf\u7ea7\u6587\u6863\u6f14\u5316\u3001\u59d4\u6258\u9700\u6c42\u7ba1\u7406\u3001\u7ec4\u7ec7\u89d2\u8272\u804c\u8d23\u3001\u9700\u6c42\u5171\u4eab\u7406\u89e3\u3002", "conclusion": "\u7814\u7a76\u4e3a\u5927\u89c4\u6a21\u654f\u6377\u7ec4\u7ec7\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u3001\u53ef\u9002\u5e94\u7684\u9700\u6c42\u5b9e\u8df5\u57fa\u7840\uff0c\u7ecf\u8fc7\u591a\u516c\u53f8\u9a8c\u8bc1\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2602.10975", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.10975", "abs": "https://arxiv.org/abs/2602.10975", "authors": ["Qixing Zhou", "Jiacheng Zhang", "Haiyang Wang", "Rui Hao", "Jiahe Wang", "Minghao Han", "Yuxue Yang", "Shuzhe Wu", "Feiyang Pan", "Lue Fan", "Dandan Tu", "Zhaoxiang Zhang"], "title": "FeatureBench: Benchmarking Agentic Coding for Complex Feature Development", "comment": "Accepted by ICLR 2026", "summary": "Agents powered by large language models (LLMs) are increasingly adopted in the software industry, contributing code as collaborators or even autonomous developers. As their presence grows, it becomes important to assess the current boundaries of their coding abilities. Existing agentic coding benchmarks, however, cover a limited task scope, e.g., bug fixing within a single pull request (PR), and often rely on non-executable evaluations or lack an automated approach for continually updating the evaluation coverage. To address such issues, we propose FeatureBench, a benchmark designed to evaluate agentic coding performance in end-to-end, feature-oriented software development. FeatureBench incorporates an execution-based evaluation protocol and a scalable test-driven method that automatically derives tasks from code repositories with minimal human effort. By tracing from unit tests along a dependency graph, our approach can identify feature-level coding tasks spanning multiple commits and PRs scattered across the development timeline, while ensuring the proper functioning of other features after the separation. Using this framework, we curated 200 challenging evaluation tasks and 3825 executable environments from 24 open-source repositories in the first version of our benchmark. Empirical evaluation reveals that the state-of-the-art agentic model, such as Claude 4.5 Opus, which achieves a 74.4% resolved rate on SWE-bench, succeeds on only 11.0% of tasks, opening new opportunities for advancing agentic coding. Moreover, benefiting from our automated task collection toolkit, FeatureBench can be easily scaled and updated over time to mitigate data leakage. The inherent verifiability of constructed environments also makes our method potentially valuable for agent training.", "AI": {"tldr": "FeatureBench\u662f\u4e00\u4e2a\u8bc4\u4f30LLM\u4ee3\u7406\u5728\u7aef\u5230\u7aef\u3001\u9762\u5411\u529f\u80fd\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u7f16\u7801\u80fd\u529b\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u901a\u8fc7\u81ea\u52a8\u5316\u65b9\u6cd5\u4ece\u4ee3\u7801\u4ed3\u5e93\u63d0\u53d6\u4efb\u52a1\uff0c\u5e76\u91c7\u7528\u57fa\u4e8e\u6267\u884c\u7684\u8bc4\u4f30\u534f\u8bae\u3002", "motivation": "\u73b0\u6709\u4ee3\u7406\u7f16\u7801\u57fa\u51c6\u6d4b\u8bd5\u4efb\u52a1\u8303\u56f4\u6709\u9650\uff08\u5982\u5355\u4e2aPR\u5185\u7684bug\u4fee\u590d\uff09\uff0c\u4f9d\u8d56\u975e\u6267\u884c\u6027\u8bc4\u4f30\uff0c\u4e14\u7f3a\u4e4f\u81ea\u52a8\u66f4\u65b0\u8bc4\u4f30\u8986\u76d6\u7684\u65b9\u6cd5\u3002\u9700\u8981\u8bc4\u4f30LLM\u4ee3\u7406\u5728\u771f\u5b9e\u8f6f\u4ef6\u5f00\u53d1\u573a\u666f\u4e2d\u7684\u80fd\u529b\u8fb9\u754c\u3002", "method": "\u63d0\u51fa\u53ef\u6269\u5c55\u7684\u6d4b\u8bd5\u9a71\u52a8\u65b9\u6cd5\uff0c\u901a\u8fc7\u4f9d\u8d56\u56fe\u4ece\u5355\u5143\u6d4b\u8bd5\u81ea\u52a8\u8bc6\u522b\u529f\u80fd\u7ea7\u7f16\u7801\u4efb\u52a1\uff08\u8de8\u591a\u4e2a\u63d0\u4ea4\u548cPR\uff09\uff0c\u6784\u5efa\u53ef\u6267\u884c\u73af\u5883\uff0c\u786e\u4fdd\u529f\u80fd\u5206\u79bb\u540e\u5176\u4ed6\u529f\u80fd\u6b63\u5e38\u8fd0\u884c\u3002", "result": "\u4ece24\u4e2a\u5f00\u6e90\u4ed3\u5e93\u6536\u96c6\u4e86200\u4e2a\u6311\u6218\u6027\u8bc4\u4f30\u4efb\u52a1\u548c3825\u4e2a\u53ef\u6267\u884c\u73af\u5883\u3002Claude 4.5 Opus\u5728SWE-bench\u4e0a\u8fbe\u523074.4%\u89e3\u51b3\u7387\uff0c\u4f46\u5728FeatureBench\u4e0a\u4ec5\u6210\u529f11.0%\uff0c\u663e\u793a\u65b0\u6311\u6218\u3002", "conclusion": "FeatureBench\u586b\u8865\u4e86\u4ee3\u7406\u7f16\u7801\u8bc4\u4f30\u7684\u7a7a\u767d\uff0c\u63d0\u4f9b\u81ea\u52a8\u6269\u5c55\u548c\u66f4\u65b0\u7684\u80fd\u529b\uff0c\u5176\u6784\u5efa\u73af\u5883\u7684\u53ef\u9a8c\u8bc1\u6027\u5bf9\u4ee3\u7406\u8bad\u7ec3\u4e5f\u6709\u4ef7\u503c\uff0c\u4e3a\u63a8\u8fdb\u4ee3\u7406\u7f16\u7801\u80fd\u529b\u63d0\u4f9b\u4e86\u65b0\u673a\u4f1a\u3002"}}
