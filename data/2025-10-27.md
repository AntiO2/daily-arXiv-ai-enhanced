<div id=toc></div>

# Table of Contents

- [cs.DC](#cs.DC) [Total: 10]
- [cs.DB](#cs.DB) [Total: 2]
- [cs.SE](#cs.SE) [Total: 12]


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [1] [Lincoln AI Computing Survey (LAICS) and Trends](https://arxiv.org/abs/2510.20931)
*Albert Reuther,Peter Michaleas,Michael Jones,Vijay Gadepally,Jeremy Kepner*

Main category: cs.DC

TL;DR: 本文是林肯AI计算调查(LAICS)的年度更新，收集并总结了当前公开宣布的商业AI加速器性能数据，通过散点图分析趋势，并新增了计算架构分类。


<details>
  <summary>Details</summary>
Motivation: 生成式AI模型在过去一年受到极大关注，增加了对GenAI训练和推理计算系统的关注度，因此需要更新这项已持续七年的AI加速器调查。

Method: 收集公开宣布的商业AI加速器的峰值性能和功耗数据，绘制散点图分析趋势，按市场细分展示，并新增计算架构分类。

Result: 提供了当前AI加速器的性能功耗散点图，展示了不同市场细分中的趋势，并对新增加速器进行了简要描述。

Conclusion: 这项年度更新调查继续追踪AI加速器的发展趋势，通过系统化的数据收集和分析为AI计算系统研究提供参考。

Abstract: In the past year, generative AI (GenAI) models have received a tremendous
amount of attention, which in turn has increased attention to computing systems
for training and inference for GenAI. Hence, an update to this survey is due.
This paper is an update of the survey of AI accelerators and processors from
past seven years, which is called the Lincoln AI Computing Survey -- LAICS
(pronounced "lace"). This multi-year survey collects and summarizes the current
commercial accelerators that have been publicly announced with peak performance
and peak power consumption numbers. In the same tradition of past papers of
this survey, the performance and power values are plotted on a scatter graph,
and a number of dimensions and observations from the trends on this plot are
again discussed and analyzed. Market segments are highlighted on the scatter
plot, and zoomed plots of each segment are also included. A brief description
of each of the new accelerators that have been added in the survey this year is
included, and this update features a new categorization of computing
architectures that implement each of the accelerators.

</details>


### [2] [Towards Straggler-Resilient Split Federated Learning: An Unbalanced Update Approach](https://arxiv.org/abs/2510.21155)
*Dandan Liang,Jianing Zhang,Evan Chen,Zhe Li,Rui Li,Haibo Yang*

Main category: cs.DC

TL;DR: 提出MU-SplitFed算法解决Split Federated Learning中的straggler问题，通过非平衡更新机制实现线性加速


<details>
  <summary>Details</summary>
Motivation: Split Federated Learning结合了联邦学习的并行性和分割学习的计算卸载优势，但受到straggler问题的严重影响，特别是服务器端模型更新依赖客户端激活的同步要求导致显著延迟

Method: 使用零阶优化的straggler弹性SFL算法，通过非平衡更新机制解耦训练进度与straggler延迟，使服务器每轮客户端执行τ次本地更新

Result: 在非凸目标上实现O(√(d/(τT)))的收敛率，通信轮次实现τ的线性加速，实验显示在存在straggler时持续优于基线方法

Conclusion: MU-SplitFed通过自适应调整τ有效缓解straggler影响，提高系统可扩展性和效率

Abstract: Split Federated Learning (SFL) enables scalable training on edge devices by
combining the parallelism of Federated Learning (FL) with the computational
offloading of Split Learning (SL). Despite its great success, SFL suffers
significantly from the well-known straggler issue in distributed learning
systems. This problem is exacerbated by the dependency between Split Server and
clients: the Split Server side model update relies on receiving activations
from clients. Such synchronization requirement introduces significant time
latency, making straggler a critical bottleneck to the scalability and
efficiency of the system. To mitigate this problem, we propose MU-SplitFed, a
straggler-resilient SFL algorithm in zeroth-order optimization that decouples
training progress from straggler delays via a simple yet effective unbalanced
update mechanism.
  By enabling the server to perform $\tau$ local updates per client round,
MU-SplitFed achieves a convergence rate of $O(\sqrt{d/(\tau T)})$ for
non-convex objectives, demonstrating a linear speedup of $\tau$ in
communication rounds. Experiments demonstrate that MU-SplitFed consistently
outperforms baseline methods with the presence of stragglers and effectively
mitigates their impact through adaptive tuning of $\tau$. The code for this
project is available at https://github.com/Johnny-Zip/MU-SplitFed.

</details>


### [3] [From SLA to vendor-neutral metrics: An intelligent knowledge-based approach for multi-cloud SLA-based broker](https://arxiv.org/abs/2510.21173)
*Víctor Rampérez,Javier Soriano,David Lizcano,Shadi Aljawarneh,Juan A. Lara*

Main category: cs.DC

TL;DR: 提出了一种自动将SLA转换为跨云供应商可测量指标的解决方案，包括智能知识系统和供应商中立指标，支持多云环境部署。


<details>
  <summary>Details</summary>
Motivation: 解决云消费者缺乏专业知识来实施SLA合规机制的问题，以及不同云供应商使用不同底层指标导致的供应商锁定问题。

Method: 1. 智能知识系统自动将高层SLA转换为供应商中立指标条件；2. 定义供应商中立指标集并说明如何在不同云供应商中测量；3. 通过IaaS和PaaS用例在多云环境中验证。

Result: 验证表明两种解决方案的互补性使云消费者能够自动透明地利用多云环境，得到云专家认可。

Conclusion: 该方案成功解决了SLA自动转换和跨云供应商指标测量问题，支持多云环境的应用部署。

Abstract: Cloud computing has been consolidated as a support for the vast majority of
current and emerging technologies. However, there are some barriers that
prevent the exploitation of the full potential of this technology. First, the
major cloud providers currently put the onus of implementing the mechanisms
that ensure compliance with the desired service levels on cloud consumers.
However, consumers do not have the required expertise. Since each cloud
provider exports a different set of low-level metrics, the strategies defined
to ensure compliance with the established service-level agreement (SLA) are
bound to a particular cloud provider. This fosters provider lock-in and
prevents consumers from benefiting from the advantages of multi-cloud
environments. This paper presents a solution to the problem of automatically
translating SLAs into objectives expressed as metrics that can be measured
across multiple cloud providers. First, we propose an intelligent
knowledge-based system capable of automatically translating high-level SLAs
defined by cloud consumers into a set of conditions expressed as vendor-neutral
metrics, providing feedback to cloud consumers (intelligent tutoring system).
Secondly, we present the set of vendor-neutral metrics and explain how they can
be measured for the different cloud providers. Finally, we report a validation
based on two use cases (IaaS and PaaS) in a multi-cloud environment formed by
leading cloud providers. This evaluation has demonstrated that, thanks to the
complementarity of the two solutions, cloud consumers can automatically and
transparently exploit the multi-cloud in many application domains, as endorsed
by the cloud experts consulted in the course of this study.

</details>


### [4] [Generative Federated Learning for Smart Prediction and Recommendation Applications](https://arxiv.org/abs/2510.21183)
*Anwesha Mukherjee,Rajkumar Buyya*

Main category: cs.DC

TL;DR: 提出了一种结合生成对抗网络和联邦学习的模型（GFL），用于解决智能预测和推荐应用中的高响应时间、数据隐私泄露和数据稀缺问题，并以心脏健康监测应用为案例验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 解决智能预测和推荐应用中存在的高响应时间、数据隐私泄露和数据稀缺等挑战，特别是在医疗健康监测领域需要保护用户隐私的同时提高预测准确性。

Method: 结合生成对抗网络（GAN）和联邦学习（FL），提出生成联邦学习（GFL）框架。使用GAN生成合成数据集解决数据稀缺和类别不平衡问题，在边缘计算环境中实现集中式和去中心化联邦学习方法。

Result: 与现有方法相比，预测准确率提高了12%，响应时间比纯云系统减少了73%。生成的数据集改善了数据多样性、质量和数据增强效果。

Conclusion: 提出的GFL框架在心脏健康监测应用中表现出色，有效解决了数据隐私、响应时间和数据稀缺问题，为智能医疗应用提供了可行的解决方案。

Abstract: This paper proposes a generative adversarial network and federated
learning-based model to address various challenges of the smart prediction and
recommendation applications, such as high response time, compromised data
privacy, and data scarcity. The integration of the generative adversarial
network and federated learning is referred to as Generative Federated Learning
(GFL). As a case study of the proposed model, a heart health monitoring
application is considered. The realistic synthetic datasets are generated using
the generated adversarial network-based proposed algorithm for improving data
diversity, data quality, and data augmentation, and remove the data scarcity
and class imbalance issues. In this paper, we implement the centralized and
decentralized federated learning approaches in an edge computing paradigm. In
centralized federated learning, the edge nodes communicate with the central
server to build the global and personalized local models in a collaborative
manner. In the decentralized federated learning approach, the edge nodes
communicate among themselves to exchange model updates for collaborative
training. The comparative study shows that the proposed framework outperforms
the existing heart health monitoring applications. The results show that using
the proposed framework (i) the prediction accuracy is improved by 12% than the
conventional framework, and (ii) the response time is reduced by 73% than the
conventional cloud-only system.

</details>


### [5] [Arbitration-Free Consistency is Available (and Vice Versa)](https://arxiv.org/abs/2510.21304)
*Hagit Attiya,Constantin Enea,Enrique Román-Calvo*

Main category: cs.DC

TL;DR: 该论文提出了仲裁自由一致性(AFC)定理，揭示了仲裁自由性是区分无需协调的一致性模型与需要同步行为的基本属性。


<details>
  <summary>Details</summary>
Motivation: 分布式存储系统中可用性与一致性之间存在根本矛盾，现有理论只覆盖了简单读写接口的极端情况，缺乏对对象语义和一致性模型组合的精确解释。

Method: 开发了一个通用的语义框架，将操作语义和一致性模型结合到存储规范中，涵盖多种对象类型和一致性模型。

Result: 证明了仲裁自由一致性定理：当且仅当对象规范是仲裁自由时，才能在一致性模型中实现可用实现。

Conclusion: AFC定理统一并推广了先前结果，揭示了仲裁自由性是协调自由一致性与固有同步行为之间的根本分界线。

Abstract: The fundamental tension between \emph{availability} and \emph{consistency}
shapes the design of distributed storage systems. Classical results capture
extreme points of this trade-off: the CAP theorem shows that strong models like
linearizability preclude availability under partitions, while weak models like
causal consistency remain implementable without coordination. These theorems
apply to simple read-write interfaces, leaving open a precise explanation of
the combinations of object semantics and consistency models that admit
available implementations.
  This paper develops a general semantic framework in which storage
specifications combine operation semantics and consistency models. The
framework encompasses a broad range of objects (key-value stores, counters,
sets, CRDTs, and transactional databases) and consistency models (from causal
consistency and sequential consistency to snapshot isolation and transactional
and non-transactional SQL).
  Within this framework, we prove the \emph{Arbitration-Free Consistency} (AFC)
theorem, showing that an object specification within a consistency model admits
an available implementation if and only if it is \emph{arbitration-free}, that
is, it does not require a total arbitration order to resolve visibility or read
dependencies.
  The AFC theorem unifies and generalizes previous results, revealing
arbitration-freedom as the fundamental property that delineates
coordination-free consistency from inherently synchronized behavior.

</details>


### [6] [Parsley's Group Size Study](https://arxiv.org/abs/2510.21348)
*João A. Silva,Hervé Paulino,João M. Lourenço*

Main category: cs.DC

TL;DR: Parsley是一种基于组的分布式哈希表，通过预对等重定位技术和动态数据分片机制提高鲁棒性和负载均衡。它引入了软限制来维持稳定的组大小，防止硬限制被违反，从而在节点变动下提升系统稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有系统通常未合理解释组大小限制的选择依据，缺乏对参数如何影响性能和可扩展性的系统分析。

Method: 进行系统化的覆盖网络特性研究，分析拓扑操作、大组行为以及整体权衡，为参数配置提供依据。

Result: 通过软限制的引入，系统能够在节点变动时主动采取措施，避免违反硬限制，提高了系统稳定性。

Conclusion: 该研究为组大小限制参数的选择提供了理论基础，通过系统分析解释了配置值的合理性，有助于提升分布式哈希表的性能与可扩展性。

Abstract: Parsley is a resilient group-based Distributed Hash Table that incorporates a
preemptive peer relocation technique and a dynamic data sharding mechanism to
enhance robustness and balance. In addition to the hard limits on group size,
defined by minimum and maximum thresholds, Parsley introduces two soft limits
that define a target interval for maintaining stable group sizes. These soft
boundaries allow the overlay to take proactive measures to prevent violations
of the hard limits, improving system stability under churn. This work provides
an in-depth analysis of the rationale behind the parameter values adopted for
Parsley's evaluation. Unlike related systems, which specify group size limits
without justification, we conduct a systematic overlay characterization study
to understand the effects of these parameters on performance and scalability.
The study examines topology operations, the behavior of large groups, and the
overall trade-offs observed, offering a grounded explanation for the chosen
configuration values.

</details>


### [7] [LIDC: A Location Independent Multi-Cluster Computing Framework for Data Intensive Science](https://arxiv.org/abs/2510.21373)
*Sankalpa Timilsina,Susmit Shannigrahi*

Main category: cs.DC

TL;DR: 提出了一种使用语义名称的分布式控制平面，用于在地理分散的计算集群上进行计算放置，替代传统的集中式控制器方法。


<details>
  <summary>Details</summary>
Motivation: 当前基于Kubernetes等集中式控制器的计算放置方法不适用于多组织协作环境，且工作流通常需要针对单一平台的手动配置，无法适应基础设施的动态变化。

Method: 使用语义名称将计算与命名的Kubernetes服务端点进行匹配，实现去中心化的控制平面。

Result: 该方法使计算作业的放置与位置无关，允许任何具有足够资源的集群执行计算，并支持动态计算放置而无需预先了解集群位置或预定义配置。

Conclusion: 基于语义名称的分布式控制平面能够有效解决多组织协作环境中的计算放置问题，提供位置无关性和动态适应性。

Abstract: Scientific communities are increasingly using geographically distributed
computing platforms. The current methods of compute placement predominantly use
logically centralized controllers such as Kubernetes (K8s) to match tasks to
available resources. However, this centralized approach is unsuitable in
multi-organizational collaborations. Furthermore, workflows often need to use
manual configurations tailored for a single platform and cannot adapt to
dynamic changes across infrastructure. Our work introduces a decentralized
control plane for placing computations on geographically dispersed compute
clusters using semantic names. We assign semantic names to computations to
match requests with named Kubernetes (K8s) service endpoints. We show that this
approach provides multiple benefits. First, it allows placement of
computational jobs to be independent of location, enabling any cluster with
sufficient resources to execute the computation. Second, it facilitates dynamic
compute placement without requiring prior knowledge of cluster locations or
predefined configurations.

</details>


### [8] [Learning to Schedule: A Supervised Learning Framework for Network-Aware Scheduling of Data-Intensive Workloads](https://arxiv.org/abs/2510.21419)
*Sankalpa Timilsina,Susmit Shannigrahi*

Main category: cs.DC

TL;DR: 提出基于监督学习的网络感知作业调度器，通过预测作业完成时间来优化节点选择，相比Kubernetes默认调度器提升34-54%的节点选择准确率。


<details>
  <summary>Details</summary>
Motivation: 分布式云环境中网络拥塞、带宽不对称和节点间数据混洗等因素导致应用性能下降，传统基于CPU/内存的主机级指标无法捕捉这些网络状况，导致调度决策不佳。

Method: 使用监督学习预测候选作业完成时间，通过预测-排序机制收集所有节点的实时遥测数据，使用训练好的监督模型估计每个节点的作业持续时间，并排序选择最佳放置位置。

Result: 在FABRIC测试平台上部署的地理分布式Kubernetes集群上评估，运行网络密集型Spark工作负载，相比仅基于当前资源可用性的默认Kubernetes调度器，监督调度器在作业放置节点选择上实现了34-54%的准确率提升。

Conclusion: 本工作的新颖性在于展示了监督学习在多站点集群上实现实时网络感知作业调度的可行性。

Abstract: Distributed cloud environments hosting data-intensive applications often
experience slowdowns due to network congestion, asymmetric bandwidth, and
inter-node data shuffling. These factors are typically not captured by
traditional host-level metrics like CPU or memory. Scheduling without
accounting for these conditions can lead to poor placement decisions, longer
data transfers, and suboptimal job performance. We present a network-aware job
scheduler that uses supervised learning to predict the completion time of
candidate jobs. Our system introduces a prediction-and-ranking mechanism that
collects real-time telemetry from all nodes, uses a trained supervised model to
estimate job duration per node, and ranks them to select the best placement. We
evaluate the scheduler on a geo-distributed Kubernetes cluster deployed on the
FABRIC testbed by running network-intensive Spark workloads. Compared to the
default Kubernetes scheduler, which makes placement decisions based on current
resource availability alone, our proposed supervised scheduler achieved 34-54%
higher accuracy in selecting optimal nodes for job placement. The novelty of
our work lies in the demonstration of supervised learning for real-time,
network-aware job scheduling on a multi-site cluster.

</details>


### [9] [On Reduction and Synthesis of Petri's Cycloids](https://arxiv.org/abs/2510.21493)
*Rüdiger Valk,Daniel Moldt*

Main category: cs.DC

TL;DR: 该论文研究循环体（cycloids）这种特殊Petri网的结构特性，定义了基于重写系统的约简方法，并提出了从Petri网结构合成循环体参数的高效决策算法。


<details>
  <summary>Details</summary>
Motivation: 循环体作为Petri一般系统理论的基础，用于建模动作和事件过程，但对其结构特性的深入研究仍显不足，需要开发有效的分析方法。

Method: 定义了类似重写系统的循环体约简系统，证明不可约循环体的性质，并从Petri网结构推导循环体参数的合成方法。

Result: 开发了循环体同构的高效决策程序，能够从网络结构确定循环体参数，为循环体分析提供了实用工具。

Conclusion: 通过约简系统和参数合成方法，建立了循环体结构分析的完整框架，显著提升了循环体同构判定的效率。

Abstract: Cycloids are particular Petri nets for modelling processes of actions and
events, belonging to the fundaments of Petri's general systems theory. Defined
by four parameters they provide an algebraic formalism to describe strongly
synchronized sequential processes. To further investigate their structure,
reduction systems of cycloids are defined in the style of rewriting systems and
properties of irreducible cycloids are proved. In particular the synthesis of
cycloid parameters from their Petri net structure is derived, leading to an
efficient method for a decision procedure for cycloid isomorphism.

</details>


### [10] [Distributed $(Δ+1)$-Coloring in Graphs of Bounded Neighborhood Independence](https://arxiv.org/abs/2510.21549)
*Marc Fuchs,Fabian Kuhn*

Main category: cs.DC

TL;DR: 本文显著改进了在邻域独立度为θ的图中(Δ+1)着色的确定性分布式算法复杂度，从2^O(√logΔ)提升到(θ·logΔ)^O(loglogΔ/logloglogΔ)轮，当θ为polylog(Δ)时达到准多项式时间。


<details>
  <summary>Details</summary>
Motivation: 分布式着色是分布式图算法中的核心问题，但(Δ+1)着色的确定性复杂度仍是重要开放问题。本文旨在在邻域独立度θ=O(1)的特殊图族中改进算法复杂度，这类图已有显著更快的算法。

Method: 针对邻域独立度为θ的图，开发新的确定性分布式算法，利用图的结构特性来加速(Δ+1)着色过程。

Result: 在邻域独立度为θ的图中，(Δ+1)着色可在(θ·logΔ)^O(loglogΔ/logloglogΔ)+O(log* n)轮内完成，当θ≤polylog(Δ)时达到准多项式时间。

Conclusion: 本文显著改进了邻域独立度有界图中(Δ+1)着色的确定性分布式算法复杂度，并指出已知的(2Δ-1)边着色方法无法推广到超图边着色。

Abstract: The distributed coloring problem is arguably one of the key problems studied
in the area of distributed graph algorithms. The most standard variant of the
problem asks for a proper vertex coloring of a graph with $\Delta+1$ colors,
where $\Delta$ is the maximum degree of the graph. Despite an immense amount of
work on distributed coloring problems in the distributed setting, determining
the deterministic complexity of $(\Delta+1)$-coloring in the standard message
passing model remains one of the most important open questions of the area. In
this paper, we aim to improve our understanding of the deterministic complexity
of $(\Delta+1)$-coloring as a function of $\Delta$ in a special family of
graphs for which significantly faster algorithms are already known. The
neighborhood independence $\theta$ of a graph is the maximum number of pairwise
non-adjacent neighbors of some node of the graph. In general, in graphs of
neighborhood independence $\theta=O(1)$ (e.g., line graphs), it is known that
$(\Delta+1)$-coloring can be solved in $2^{O(\sqrt{\log\Delta})}+O(\log^* n)$
rounds. In the present paper, we significantly improve this result, and we show
that in graphs of neighborhood independence $\theta$, a $(\Delta+1)$-coloring
can be computed in $(\theta\cdot\log\Delta)^{O(\log\log\Delta /
\log\log\log\Delta)}+O(\log^* n)$ rounds and thus in quasipolylogarithmic time
in $\Delta$ as long as $\theta$ is at most polylogarithmic in $\Delta$. We also
show that the known approach that leads to a polylogarithmic in $\Delta$
algorithm for $(2\Delta-1)$-edge coloring already fails for edge colorings of
hypergraphs of rank at least $3$.

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [11] [World-POI: Global Point-of-Interest Data Enriched from Foursquare and OpenStreetMap as Tabular and Graph Data](https://arxiv.org/abs/2510.21342)
*Hossein Amiri,Mohammad Hashemi,Andreas Züfle*

Main category: cs.DB

TL;DR: 提出了一种整合Foursquare和OpenStreetMap POI数据的方法，通过名称相似度和空间距离匹配来创建增强的商业POI数据集，提供可下载的过滤版本。


<details>
  <summary>Details</summary>
Motivation: Foursquare的POI数据集虽然规模庞大但缺乏完整元数据，而OSM提供丰富的元数据但未验证商业真实性，需要结合两者的优势。

Method: 通过计算Foursquare和OSM POI之间的名称相似度得分和空间距离来进行记录链接，保留高置信度匹配，并构建基于图的POI表示。

Result: 创建了约1TB的整合数据集，提供631GB的可复现构建版本和过滤后的实用版本，支持高级空间分析和下游应用。

Conclusion: 该方法成功整合了两个数据源的优势，为商业POI分析提供了更完整和可靠的数据基础。

Abstract: Recently, Foursquare released a global dataset with more than 100 million
points of interest (POIs), each representing a real-world business on its
platform. However, many entries lack complete metadata such as addresses or
categories, and some correspond to non-existent or fictional locations. In
contrast, OpenStreetMap (OSM) offers a rich, user-contributed POI dataset with
detailed and frequently updated metadata, though it does not formally verify
whether a POI represents an actual business. In this data paper, we present a
methodology that integrates the strengths of both datasets: Foursquare as a
comprehensive baseline of commercial POIs and OSM as a source of enriched
metadata. The combined dataset totals approximately 1 TB. While this full
version is not publicly released, we provide filtered releases with adjustable
thresholds that reduce storage needs and make the data practical to download
and use across domains. We also provide step-by-step instructions to reproduce
the full 631 GB build. Record linkage is achieved by computing name similarity
scores and spatial distances between Foursquare and OSM POIs. These measures
identify and retain high-confidence matches that correspond to real businesses
in Foursquare, have representations in OSM, and show strong name similarity.
Finally, we use this filtered dataset to construct a graph-based representation
of POIs enriched with attributes from both sources, enabling advanced spatial
analyses and a range of downstream applications.

</details>


### [12] [SurVigilance: An Application for Accessing Global Pharmacovigilance Data](https://arxiv.org/abs/2510.21572)
*Raktim Mukhopadhyay,Marianthi Markatou*

Main category: cs.DB

TL;DR: SurVigilance是一个开源工具，简化了从七个主要药物警戒数据库检索安全数据的过程，提供图形界面和编程访问功能。


<details>
  <summary>Details</summary>
Motivation: 现有药物警戒数据库数据提取技术难度大，且现有工具通常只针对单一数据库，需要更便捷的多数据库访问工具。

Method: 采用模块化架构访问异构数据源，提供图形用户界面和程序化访问函数，可集成到现有研究流程中。

Result: 开发了能够访问七个主要药物警戒数据库的统一工具，降低了技术门槛。

Conclusion: SurVigilance通过降低访问安全数据的技术障碍，旨在促进药物警戒研究。

Abstract: Even though several publicly accessible pharmacovigilance databases are
available, extracting data from them is a technically challenging process.
Existing tools typically focus on a single database. We present SurVigilance,
an open-source tool that streamlines the process of retrieving safety data from
seven major pharmacovigilance databases. SurVigilance provides a graphical user
interface as well as functions for programmatic access, thus enabling
integration into existing research workflows. SurVigilance utilizes a modular
architecture to provide access to the heterogeneous sources. By reducing the
technical barriers to accessing safety data, SurVigilance aims to facilitate
pharmacovigilance research.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [13] [AgentArcEval: An Architecture Evaluation Method for Foundation Model based Agents](https://arxiv.org/abs/2510.21031)
*Qinghua Lu,Dehai Zhao,Yue Liu,Hao Zhang,Liming Zhu,Xiwei Xu,Angela Shi,Tristan Tan,Rick Kazman*

Main category: cs.SE

TL;DR: 提出了AgentArcEval方法，专门用于评估基于基础模型的智能体架构，并提供了智能体特定通用场景目录来指导架构设计和评估。


<details>
  <summary>Details</summary>
Motivation: 传统方法无法满足智能体架构评估需求，因为智能体具有复合架构、自主非确定性行为和持续演化等独特特性。

Method: 开发了AgentArcEval评估方法，创建了智能体特定通用场景目录，并通过名为Luna的税务副驾驶真实案例研究进行验证。

Result: 成功展示了AgentArcEval方法和场景目录在评估真实世界智能体架构方面的实用性。

Conclusion: AgentArcEval为基于基础模型的智能体架构评估提供了专门解决方案，能够有效应对智能体的复杂特性。

Abstract: The emergence of foundation models (FMs) has enabled the development of
highly capable and autonomous agents, unlocking new application opportunities
across a wide range of domains. Evaluating the architecture of agents is
particularly important as the architectural decisions significantly impact the
quality attributes of agents given their unique characteristics, including
compound architecture, autonomous and non-deterministic behaviour, and
continuous evolution. However, these traditional methods fall short in
addressing the evaluation needs of agent architecture due to the unique
characteristics of these agents. Therefore, in this paper, we present
AgentArcEval, a novel agent architecture evaluation method designed specially
to address the complexities of FM-based agent architecture and its evaluation.
Moreover, we present a catalogue of agent-specific general scenarios, which
serves as a guide for generating concrete scenarios to design and evaluate the
agent architecture. We demonstrate the usefulness of AgentArcEval and the
catalogue through a case study on the architecture evaluation of a real-world
tax copilot, named Luna.

</details>


### [14] [BDiff: Block-aware and Accurate Text-based Code Differencing](https://arxiv.org/abs/2510.21094)
*Yao Lu,Wanwei Liu,Tanghaoran Zhang,Kang Yang,Yang Zhang,Wenyu Xu,Longfei Sun,Xinjun Mao,Shuzheng Gao,Michael R. Lyu*

Main category: cs.SE

TL;DR: BDiff是一种基于文本的代码差异分析算法，能够识别块级和行级编辑操作，相比现有工具能生成更高质量的差异结果。


<details>
  <summary>Details</summary>
Motivation: 现有代码差异分析工具在处理跨多行的块级编辑操作时存在局限，只能表示为离散的行级操作序列，需要开发者手动关联，严重影响变更理解效率。

Method: 基于传统差异算法构建包含所有可能行映射和块映射的候选集，使用Kuhn-Munkres算法计算最优映射集，最小化编辑脚本大小并贴近开发者意图。

Result: 实验表明BDiff相比5种最先进工具（包括大语言模型）在差异结果质量上表现更好，同时保持竞争力的运行时间性能。

Conclusion: BDiff能有效识别块级编辑操作，提高代码差异分析质量；同时发现大语言模型在代码差异任务中结果质量不可靠且运行效率不可行。

Abstract: Code differencing is a fundamental technique in software engineering practice
and research. While researchers have proposed text-based differencing
techniques capable of identifying line changes over the past decade, existing
methods exhibit a notable limitation in identifying edit actions (EAs) that
operate on text blocks spanning multiple lines. Such EAs are common in
developers' practice, such as moving a code block for conditional branching or
duplicating a method definition block for overloading. Existing tools represent
such block-level operations as discrete sequences of line-level EAs, compelling
developers to manually correlate them and thereby substantially impeding the
efficiency of change comprehension. To address this issue, we propose BDiff, a
text-based differencing algorithm capable of identifying two types of
block-level EAs and five types of line-level EAs. Building on traditional
differencing algorithms, we first construct a candidate set containing all
possible line mappings and block mappings. Leveraging the Kuhn-Munkres
algorithm, we then compute the optimal mapping set that can minimize the size
of the edit script (ES) while closely aligning with the original developer's
intent. To validate the effectiveness of BDiff, we selected five
state-of-the-art tools, including large language models (LLMs), as baselines
and adopted a combined qualitative and quantitative approach to evaluate their
performance in terms of ES size, result quality, and running time. Experimental
results show that BDiff produces higher-quality differencing results than
baseline tools while maintaining competitive runtime performance. Our
experiments also show the unreliability of LLMs in code differencing tasks
regarding result quality and their infeasibility in terms of runtime
efficiency. We have implemented a web-based visual differencing tool.

</details>


### [15] [R2ComSync: Improving Code-Comment Synchronization with In-Context Learning and Reranking](https://arxiv.org/abs/2510.21106)
*Zhen Yang,Hongyi Lin,Xiao Yu,Jacky Wai Keung,Shuo Liu,Pak Yuen Patrick Chan,Yicheng Sun,Fengji Zhang*

Main category: cs.SE

TL;DR: R2ComSync是一个基于检索和重排的代码-注释同步方法，通过集成混合检索和多轮重排策略来增强LLMs在代码注释同步任务中的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的代码-注释同步方法存在泛化能力不足或需要大量任务特定学习资源的问题，而LLMs在该领域表现不佳，主要因为缺乏有效的上下文学习示例和正确候选项优先级不足。

Method: R2ComSync采用集成混合检索（同时考虑代码-注释语义和变更模式的相似性）来创建有效的ICL提示，并使用多轮重排策略（基于三个重要规则）来优先选择相对正确的候选项。

Result: 在三个CCS数据集（涵盖Java和Python）上的实验表明，R2ComSync相比五个SOTA方法表现出优越性能，生成的注释质量显著更高。

Conclusion: R2ComSync通过检索和重排策略有效提升了LLMs在代码-注释同步任务中的性能，证明了该方法在自动化软件维护中的有效性。

Abstract: Code-Comment Synchronization (CCS) aims to synchronize the comments with code
changes in an automated fashion, thereby significantly reducing the workload of
developers during software maintenance and evolution. While previous studies
have proposed various solutions that have shown success, they often exhibit
limitations, such as a lack of generalization ability or the need for extensive
task-specific learning resources. This motivates us to investigate the
potential of Large Language Models (LLMs) in this area. However, a pilot
analysis proves that LLMs fall short of State-Of-The-Art (SOTA) CCS approaches
because (1) they lack instructive demonstrations for In-Context Learning (ICL)
and (2) many correct-prone candidates are not prioritized.To tackle the above
challenges, we propose R2ComSync, an ICL-based code-Comment Synchronization
approach enhanced with Retrieval and Re-ranking. Specifically, R2ComSync
carries corresponding two novelties: (1) Ensemble hybrid retrieval. It equally
considers the similarity in both code-comment semantics and change patterns
when retrieval, thereby creating ICL prompts with effective examples. (2)
Multi-turn re-ranking strategy. We derived three significant rules through
large-scale CCS sample analysis. Given the inference results of LLMs, it
progressively exploits three re-ranking rules to prioritize relatively
correct-prone candidates. We evaluate R2ComSync using five recent LLMs on three
CCS datasets covering both Java and Python programming languages, and make
comparisons with five SOTA approaches. Extensive experiments demonstrate the
superior performance of R2ComSync against other approaches. Moreover, both
quantitative and qualitative analyses provide compelling evidence that the
comments synchronized by our proposal exhibit significantly higher quality.}

</details>


### [16] [GreenMalloc: Allocator Optimisation for Industrial Workloads](https://arxiv.org/abs/2510.21405)
*Aidan Dakhama,W. B. Langdon,Hector D. Menendez,Karine Even-Mendoza*

Main category: cs.SE

TL;DR: GreenMalloc是一个基于多目标搜索的框架，用于自动配置内存分配器。使用NSGA II算法和rand_malloc作为轻量级代理基准测试工具，优化内存分配器参数。


<details>
  <summary>Details</summary>
Motivation: 传统内存分配器配置通常需要手动调优，效率低下。需要一种自动化方法来优化内存分配器参数，以降低堆使用量同时保持运行时效率。

Method: 使用NSGA II多目标优化算法，结合rand_malloc作为轻量级代理基准测试工具，从执行轨迹中高效探索分配器参数，并将最佳配置转移到gem5系统模拟器。

Result: 在多样化工作负载下，实验结果显示平均堆使用量最多减少4.1%，同时运行时效率没有损失，甚至获得0.25%的改进。

Conclusion: GreenMalloc框架能够有效自动配置内存分配器参数，在显著降低内存使用的同时保持或略微提高运行时性能。

Abstract: We present GreenMalloc, a multi objective search-based framework for
automatically configuring memory allocators. Our approach uses NSGA II and
rand_malloc as a lightweight proxy benchmarking tool. We efficiently explore
allocator parameters from execution traces and transfer the best configurations
to gem5, a large system simulator, in a case study on two allocators: the GNU
C/CPP compiler's glibc malloc and Google's TCMalloc. Across diverse workloads,
our empirical results show up to 4.1 percantage reduction in average heap usage
without loss of runtime efficiency; indeed, we get a 0.25 percantage reduction.

</details>


### [17] [Context Engineering for AI Agents in Open-Source Software](https://arxiv.org/abs/2510.21413)
*Seyedmoein Mohsenimofidi,Matthias Galster,Christoph Treude,Sebastian Baltes*

Main category: cs.SE

TL;DR: 本文研究了AI配置文件的采用情况，分析了466个开源项目中AGENTS.md文件的使用、内容和演变。


<details>
  <summary>Details</summary>
Motivation: 随着AI编程助手向基于代理的自主方向发展，需要为AI代理提供足够的项目上下文信息。AGENTS.md作为潜在标准格式出现，但其实际采用情况尚不清楚。

Method: 对466个开源软件项目进行初步研究，分析AI配置文件的采用情况、内容信息、呈现方式及其随时间演变。

Result: 发现目前还没有建立统一的结构，上下文信息的提供方式存在很大差异（描述性、规定性、禁止性、解释性、条件性）。

Conclusion: AI配置文件的研究为研究现实世界中的提示和上下文工程提供了独特机会，需要进一步研究结构和呈现方式的改进如何影响生成内容质量。

Abstract: GenAI-based coding assistants have disrupted software development. Their next
generation is agent-based, operating with more autonomy and potentially without
human oversight. One challenge is to provide AI agents with sufficient context
about the software projects they operate in. Like humans, AI agents require
contextual information to develop solutions that are in line with the target
architecture, interface specifications, coding guidelines, standard workflows,
and other project-specific policies. Popular AI agents for software development
(e.g., Claude Code) advocate for maintaining tool-specific version-controlled
Markdown files that cover aspects such as the project structure, building and
testing, or code style. The content of these files is automatically added to
each prompt. AGENTS.md has emerged as a potential standard that consolidates
tool-specific formats. However, little is known about whether and how
developers adopt this format. Therefore, in this paper, we present the results
of a preliminary study investigating the adoption of AI configuration files in
466 open-source software projects, what information developers provide in these
files, how they present that information, and how they evolve over time. Our
findings indicate that there is no established structure yet, and that there is
a lot of variation in terms of how context is provided (descriptive,
prescriptive, prohibitive, explanatory, conditional). We see great potential in
studying which modifications in structure or presentation can positively affect
the quality of the generated content. Finally, our analysis of commits that
have modified AGENTS.md files provides first insights into how projects
continuously extend and maintain these files. We conclude the paper by
outlining how the adoption of AI configuration files in provides a unique
opportunity to study real-world prompt and context engineering.

</details>


### [18] [Does Model Size Matter? A Comparison of Small and Large Language Models for Requirements Classification](https://arxiv.org/abs/2510.21443)
*Mohammad Amin Zadenoori,Vincenzo De Martino,Jacek Dabrowski,Xavier Franch,Alessio Ferrari*

Main category: cs.SE

TL;DR: 小型语言模型(SLMs)在需求工程分类任务中几乎达到大型语言模型(LLMs)的性能，尽管模型大小相差300倍，且具有隐私、成本和本地部署优势。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在需求工程任务中表现良好，但存在计算成本高、数据共享风险和依赖外部服务的问题。小型语言模型提供了轻量级、本地可部署的替代方案。

Method: 比较了8个模型（3个LLMs和5个SLMs）在PROMISE、PROMISE Reclass和SecReq数据集上的需求分类任务表现。

Result: LLMs平均F1分数比SLMs高2%，但差异无统计学意义。SLMs在所有数据集上几乎达到LLMs性能，在PROMISE Reclass数据集上召回率甚至超过LLMs。数据集特征比模型大小对性能影响更大。

Conclusion: SLMs是需求分类任务中LLMs的有效替代方案，在隐私、成本和本地部署方面具有优势。

Abstract: [Context and motivation] Large language models (LLMs) show notable results in
natural language processing (NLP) tasks for requirements engineering (RE).
However, their use is compromised by high computational cost, data sharing
risks, and dependence on external services. In contrast, small language models
(SLMs) offer a lightweight, locally deployable alternative. [Question/problem]
It remains unclear how well SLMs perform compared to LLMs in RE tasks in terms
of accuracy. [Results] Our preliminary study compares eight models, including
three LLMs and five SLMs, on requirements classification tasks using the
PROMISE, PROMISE Reclass, and SecReq datasets. Our results show that although
LLMs achieve an average F1 score of 2% higher than SLMs, this difference is not
statistically significant. SLMs almost reach LLMs performance across all
datasets and even outperform them in recall on the PROMISE Reclass dataset,
despite being up to 300 times smaller. We also found that dataset
characteristics play a more significant role in performance than model size.
[Contribution] Our study contributes with evidence that SLMs are a valid
alternative to LLMs for requirements classification, offering advantages in
privacy, cost, and local deployability.

</details>


### [19] [Scalpel: Automotive Deep Learning Framework Testing via Assembling Model Components](https://arxiv.org/abs/2510.21451)
*Yinglong Zou,Juan Zhai,Chunrong Fang,An Guo,Jiawei Liu,Zhenyu Chen*

Main category: cs.SE

TL;DR: Scalpel是一种针对自动驾驶深度学习框架的测试方法，通过组件级模型生成来检测框架特有的质量问题，如内存崩溃和分配错误。


<details>
  <summary>Details</summary>
Motivation: 现有DL框架测试方法无法检测自动驾驶系统特有的质量问题，因为生成的测试模型缺乏多输入/输出张量处理、多模态数据处理和多级数据特征提取等关键能力。

Method: Scalpel在模型组件级别生成测试输入模型，通过维护模型组件库（头、颈、骨干网络），选择、变异和组装这些组件来构建支持自动驾驶系统所需能力的模型。

Result: 成功生成的模型被添加回组件库以丰富资源库，新生成的模型通过差分测试在自动驾驶系统中部署来测试汽车DL框架。

Conclusion: Scalpel方法能够有效检测自动驾驶DL框架特有的质量问题，解决了现有测试方法在模型生成方面的局限性。

Abstract: Deep learning (DL) plays a key role in autonomous driving systems. DL models
support perception modules, equipped with tasks such as object detection and
sensor fusion. These DL models enable vehicles to process multi-sensor inputs
to understand complex surroundings. Deploying DL models in autonomous driving
systems faces stringent challenges, including real-time processing, limited
computational resources, and strict power constraints. To address these
challenges, automotive DL frameworks (e.g., PaddleInference) have emerged to
optimize inference efficiency. However, these frameworks encounter unique
quality issues due to their more complex deployment environments, such as
crashes stemming from limited scheduled memory and incorrect memory allocation.
Unfortunately, existing DL framework testing methods fail to detect these
quality issues due to the failure in deploying generated test input models, as
these models lack three essential capabilities: (1) multi-input/output tensor
processing, (2) multi-modal data processing, and (3) multi-level data feature
extraction. These capabilities necessitate specialized model components, which
existing testing methods neglect during model generation. To bridge this gap,
we propose Scalpel, an automotive DL frameworks testing method that generates
test input models at the model component level. Scalpel generates models by
assembling model components (heads, necks, backbones) to support capabilities
required by autonomous driving systems. Specifically, Scalpel maintains and
updates a repository of model components, generating test inputs by selecting,
mutating, and assembling them. Successfully generated models are added back to
enrich the repository. Newly generated models are then deployed within the
autonomous driving system to test automotive DL frameworks via differential
testing.

</details>


### [20] [Towards Socio-Technical Topology-Aware Adaptive Threat Detection in Software Supply Chains](https://arxiv.org/abs/2510.21452)
*Thomas Welsh,Kristófer Finnsson,Brynjólfur Stefánsson,Helmut Neukirchen*

Main category: cs.SE

TL;DR: 该论文提出利用社会技术模型来支持软件供应链的自适应威胁检测，通过分析XZ Utils攻击案例，强调监控技术和社交数据可以识别可疑行为趋势，从而指导有针对性的漏洞评估。


<details>
  <summary>Details</summary>
Motivation: 软件供应链攻击日益增多，但由于其复杂性，传统的漏洞分析面临挑战。现有工作主要关注技术层面的依赖监控和组件控制，缺乏对社会技术动态的理解来指导威胁检测。

Method: 提出一个研究愿景，开发和研究使用社会技术模型来支持软件供应链的自适应威胁检测。通过分析XZ Utils攻击案例，展示如何通过监控技术和社交数据识别可疑行为。

Result: 识别出监控技术和社交数据可以检测到表明可疑行为的趋势，这些趋势可以指导有针对性和深入的漏洞评估。

Conclusion: 论文确定了实现这一愿景的挑战和研究方向，包括开发者和软件分析技术、去中心化适应以及软件供应链安全研究测试平台的需求。

Abstract: Software supply chains (SSCs) are complex systems composed of dynamic,
heterogeneous technical and social components which collectively achieve the
production and maintenance of software artefacts. Attacks on SSCs are
increasing, yet pervasive vulnerability analysis is challenging due to their
complexity. Therefore, threat detection must be targeted, to account for the
large and dynamic structure, and adaptive, to account for its change and
diversity. While current work focuses on technical approaches for monitoring
supply chain dependencies and establishing component controls, approaches which
inform threat detection through understanding the socio-technical dynamics are
lacking. We outline a position and research vision to develop and investigate
the use of socio-technical models to support adaptive threat detection of SSCs.
We motivate this approach through an analysis of the XZ Utils attack whereby
malicious actors undermined the maintainers' trust via the project's GitHub and
mailing lists. We highlight that monitoring technical and social data can
identify trends which indicate suspicious behaviour to then inform targeted and
intensive vulnerability assessment. We identify challenges and research
directions to achieve this vision considering techniques for developer and
software analysis, decentralised adaptation and the need for a test bed for
software supply chain security research.

</details>


### [21] [Risk Management for Mitigating Benchmark Failure Modes: BenchRisk](https://arxiv.org/abs/2510.21460)
*Sean McGregor,Victor Lu,Vassil Tashev,Armstrong Foundjem,Aishwarya Ramasethu,Sadegh AlMahdi Kazemi Zarkouei,Chris Knotz,Kongtao Chen,Alicia Parrish,Anka Reuel,Heather Frase*

Main category: cs.SE

TL;DR: 该研究提出了BenchRisk框架，用于评估大型语言模型(LLM)基准测试的风险，识别了57种潜在故障模式和196种缓解策略，帮助用户更可靠地评估LLM性能。


<details>
  <summary>Details</summary>
Motivation: 当前LLM基准测试存在各种故障模式，可能影响基准的偏差、方差、覆盖范围或人们理解基准证据的能力，导致用户对LLM做出错误判断。

Method: 基于NIST风险管理流程，迭代分析26个流行基准，识别故障模式和缓解策略，开发BenchRisk评分系统评估基准风险。

Result: 所有26个基准在五个维度(全面性、可理解性、一致性、正确性、持久性)中的一个或多个维度存在显著风险，BenchRisk能够比较不同基准的风险水平。

Conclusion: LLM基准测试领域存在重要研究空白，BenchRisk作为开源工具促进了风险识别和共享，帮助用户更准确地评估LLM性能。

Abstract: Large language model (LLM) benchmarks inform LLM use decisions (e.g., "is
this LLM safe to deploy for my use case and context?"). However, benchmarks may
be rendered unreliable by various failure modes that impact benchmark bias,
variance, coverage, or people's capacity to understand benchmark evidence.
Using the National Institute of Standards and Technology's risk management
process as a foundation, this research iteratively analyzed 26 popular
benchmarks, identifying 57 potential failure modes and 196 corresponding
mitigation strategies. The mitigations reduce failure likelihood and/or
severity, providing a frame for evaluating "benchmark risk," which is scored to
provide a metaevaluation benchmark: BenchRisk. Higher scores indicate that
benchmark users are less likely to reach an incorrect or unsupported conclusion
about an LLM. All 26 scored benchmarks present significant risk within one or
more of the five scored dimensions (comprehensiveness, intelligibility,
consistency, correctness, and longevity), which points to important open
research directions for the field of LLM benchmarking. The BenchRisk workflow
allows for comparison between benchmarks; as an open-source tool, it also
facilitates the identification and sharing of risks and their mitigations.

</details>


### [22] [Wisdom and Delusion of LLM Ensembles for Code Generation and Repair](https://arxiv.org/abs/2510.21513)
*Fernando Vallecillos Ruiz,Max Hort,Leon Moonen*

Main category: cs.SE

TL;DR: 研究表明，通过多样性策略组合多个LLM可以显著提升软件工程任务性能，理论上限比最佳单模型高83%，而基于共识的策略会陷入"流行度陷阱"。


<details>
  <summary>Details</summary>
Motivation: 当前追求单一大型语言模型处理所有软件工程任务既资源密集又忽略了不同模型互补性的潜力，但缺乏关于编码LLM如何互补及最佳集成策略的明确指导。

Method: 在三个软件工程基准测试中实证比较了来自五个家族的十个LLM和三种集成方法，评估模型互补性、性能差距，并测试了从候选池中选择正确解决方案的各种启发式方法。

Result: 集成性能的理论上限比最佳单模型高83%。基于共识的策略会放大常见但不正确的输出，而基于多样性的策略能实现高达95%的理论潜力，即使在小型双模型集成中也有效。

Conclusion: 多样性策略为利用多个LLM提升性能提供了成本效益高的方法，使从业者能够超越单一模型系统。

Abstract: Today's pursuit of a single Large Language Model (LMM) for all software
engineering tasks is resource-intensive and overlooks the potential benefits of
complementarity, where different models contribute unique strengths. However,
the degree to which coding LLMs complement each other and the best strategy for
maximizing an ensemble's potential are unclear, leaving practitioners without a
clear path to move beyond single-model systems.
  To address this gap, we empirically compare ten individual LLMs from five
families, and three ensembles of these LLMs across three software engineering
benchmarks covering code generation and program repair. We assess the
complementarity between models and the performance gap between the best
individual model and the ensembles. Next, we evaluate various selection
heuristics to identify correct solutions from an ensemble's candidate pool.
  We find that the theoretical upperbound for an ensemble's performance can be
83% above the best single model. Our results show that consensus-based
strategies for selecting solutions fall into a "popularity trap," amplifying
common but incorrect outputs. In contrast, a diversity-based strategy realizes
up to 95% of this theoretical potential, and proves effective even in small
two-model ensembles, enabling a cost-efficient way to enhance performance by
leveraging multiple LLMs.

</details>


### [23] [Lights-Out: An Automated Ground Segment for unstaffed Satellite Operations](https://arxiv.org/abs/2510.21516)
*Marvin Böcker,Ralph Biggins,Michael Schmeing*

Main category: cs.SE

TL;DR: 提出并实施了德国Heinrich Hertz卫星任务的自动化地面段概念，实现无人值守的全自动化操作，包括卫星跟踪、遥测和指令控制，支持用户24/7自助服务。


<details>
  <summary>Details</summary>
Motivation: 为德国Heinrich Hertz卫星通信任务开发自动化地面段，实现非工作时间完全自动化操作，提高任务效率和用户灵活性。

Method: 采用预规划自动执行调度、自动监控系统、用户自助门户等技术，实现卫星平台操作、用户实验调度和系统监控的全自动化。

Result: 成功应用于2023年7月发射的Heinrich Hertz任务，支持科学和技术实验，实现小于1分钟的快速响应能力，允许在运行实验中重新配置有效载荷。

Conclusion: 该自动化概念证明可行，为卫星任务提供了高效、灵活的操作模式，特别适合需要24/7访问和快速响应的科学实验任务。

Abstract: We present our approach for a periodically unstaffed, fully automated ground
segment. The concept is in use for the first time on the German satellite
communications mission Heinrich Hertz on behalf of the German Space Agency at
DLR. Heinrich Hertz was launched in July 2023 and offers access to scientific
and technical experiments to its users. The mission utilizes major automation
concepts for the satellite platform operations, allowing fully automated
operations outside of office hours. The concept includes tracking, telemetry
and commanding (TTC) of the satellite. Pre-planned and automatically executed
schedules enable commanding without human interaction. The user mission
schedule is planned separately from the main mission schedule and is
automatically de-conflicted. The automatic monitoring concept monitors the
systems of the satellite and all assets in the ground segment and triggers
reactions in operator-configurable ways depending on the mission needs, for
example emergency notifications or automated execution of flight operation
procedures. Additionally, the concept also puts special emphasis on a
self-service user portal that provides flexible access 24/7, even when the
control center is not staffed. The portal allows external users of the payload
to schedule pre-defined experiments, monitor the live execution of the
experiment with browser-based displays and access ground station telemetry and
dedicated RF test equipment during the time of their scheduled experiment.
Tasks can be planned long in advance as well as with a short reaction time
(less than 1 minute), which allows, for example, the reconfiguration of the
payload during a running experiment.

</details>


### [24] [Privacy by Design: Aligning GDPR and Software Engineering Specifications with a Requirements Engineering Approach](https://arxiv.org/abs/2510.21591)
*Oleksandr Kosenkov,Ehsan Zabardast,Davide Fucci,Daniel Mendez,Michael Unterkalmsteiner*

Main category: cs.SE

TL;DR: 本文研究了GDPR合规性中需求与系统规范的联合规范方法，通过建模GDPR法律概念来支持隐私设计，强调问题空间与解决方案空间的交集对实现隐私设计的重要性。


<details>
  <summary>Details</summary>
Motivation: GDPR合规需要一致的需求和系统规范，但现有方法未能充分处理GDPR中问题空间与解决方案空间的复杂交集，缺乏对从业者视角的理解。

Method: 通过回顾二手研究和相关一手研究，与从业者访谈了解实践现状和规范目标，开发并评估了基于GDPR法律概念建模的需求与系统规范方法。

Result: 基于GDPR内容建模的方法有助于捕获法律知识、支持规范透明度和可追溯性，证实了该方法满足实际需求。

Conclusion: GDPR需求需要在工程生命周期的不同抽象层次解决以实现隐私设计，法律知识应被捕获在规范中以满足不同利益相关者需求并确保合规性。

Abstract: Context: Consistent requirements and system specifications are essential for
the compliance of software systems towards the General Data Protection
Regulation (GDPR). Both artefacts need to be grounded in the original text and
conjointly assure the achievement of privacy by design (PbD). Objectives: There
is little understanding of the perspectives of practitioners on specification
objectives and goals to address PbD. Existing approaches do not account for the
complex intersection between problem and solution space expressed in GDPR. In
this study we explore the demand for conjoint requirements and system
specification for PbD and suggest an approach to address this demand. Methods:
We reviewed secondary and related primary studies and conducted interviews with
practitioners to (1) investigate the state-of-practice and (2) understand the
underlying specification objectives and goals (e.g., traceability). We
developed and evaluated an approach for requirements and systems specification
for PbD, and evaluated it against the specification objectives. Results: The
relationship between problem and solution space, as expressed in GDPR, is
instrumental in supporting PbD. We demonstrate how our approach, based on the
modeling GDPR content with original legal concepts, contributes to
specification objectives of capturing legal knowledge, supporting specification
transparency, and traceability. Conclusion: GDPR demands need to be addressed
throughout different levels of abstraction in the engineering lifecycle to
achieve PbD. Legal knowledge specified in the GDPR text should be captured in
specifications to address the demands of different stakeholders and ensure
compliance. While our results confirm the suitability of our approach to
address practical needs, we also revealed specific needs for the future
effective operationalization of the approach.

</details>
