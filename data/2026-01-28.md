<div id=toc></div>

# Table of Contents

- [cs.DB](#cs.DB) [Total: 4]
- [cs.SE](#cs.SE) [Total: 29]
- [cs.DC](#cs.DC) [Total: 5]


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [1] [Accelerating Large-Scale Cheminformatics Using a Byte-Offset Indexing Architecture for Terabyte-Scale Data Integration](https://arxiv.org/abs/2601.18921)
*Malikussaid,Septian Caesar Floresko,Sutiyo*

Main category: cs.DB

TL;DR: 本文通过字节偏移索引技术整合三大化学数据库（PubChem、ChEMBL、eMolecules），将分子属性预测数据集构建时间从100天缩短至3.2小时，性能提升740倍，并解决了InChIKey哈希碰撞问题。


<details>
  <summary>Details</summary>
Motivation: 大规模化学数据库整合是现代化学信息学研究的瓶颈，特别是机器学习应用需要高质量、多来源验证的数据集。现有方法在处理亿级数据时面临可扩展性和数据完整性问题。

Method: 采用字节偏移索引架构替代暴力搜索算法，将算法复杂度从O(N×M)降低到O(N+M)。使用无碰撞的完整InChI字符串替代存在哈希碰撞的InChIKey分子标识符，重建数据处理管道。

Result: 成功整合三大数据库，从1.76亿个数据库条目中提取出435,413个验证化合物。性能从预计100天运行时间缩短到3.2小时，实现740倍的性能提升。系统验证揭示了InChIKey标识符的哈希碰撞问题。

Conclusion: 字节偏移索引技术能够有效解决大规模科学数据整合的可扩展性问题，特别是在唯一性约束超出基于哈希的标识符能力时。该方法为大规模科学数据整合提供了可推广的原则。

Abstract: The integration of large-scale chemical databases represents a critical bottleneck in modern cheminformatics research, particularly for machine learning applications requiring high-quality, multi-source validated datasets. This paper presents a case study of integrating three major public chemical repositories: PubChem (176 million compounds), ChEMBL, and eMolecules, to construct a curated dataset for molecular property prediction. We investigate whether byte-offset indexing can practically overcome brute-force scalability limits while preserving data integrity at hundred-million scale. Our results document the progression from an intractable brute-force search algorithm with projected 100-day runtime to a byte-offset indexing architecture achieving 3.2-hour completion-a 740-fold performance improvement through algorithmic complexity reduction from O(NxM) to O(N+M). Systematic validation of 176 million database entries revealed hash collisions in InChIKey molecular identifiers, necessitating pipeline reconstruction using collision-free full InChI strings. We present performance benchmarks, quantify trade-offs between storage overhead and scientific rigor, and compare our approach with alternative large-scale integration strategies. The resulting system successfully extracted 435,413 validated compounds and demonstrates generalizable principles for large-scale scientific data integration where uniqueness constraints exceed hash-based identifier capabilities.

</details>


### [2] [Educational Database Prototype: the Simplest of All](https://arxiv.org/abs/2601.19165)
*Yi Lyu,Yiyin Shen,Takashi Matsuzawa*

Main category: cs.DB

TL;DR: EduDB是一个为教育目的设计的简单数据库原型，旨在帮助学生更全面地理解数据库系统内部设计，避免陷入实现细节的角落情况。


<details>
  <summary>Details</summary>
Motivation: 当前威斯康星大学麦迪逊分校的本科数据库课程（CS564）中，学生需要实现数据库架构的特定模块（如B+树），但可能会花费大量精力处理边界情况，而无法获得对数据库内部设计的全面理解。

Method: 开发EduDB——一个为教育目的设计的简单数据库原型，提供清晰、简洁、全面的数据库系统概览。同时开发基于EduDB的综合性系列课程项目，为学生提供一个平台来实践学期中学到的各种优化技术。

Result: 提出了EduDB教育数据库原型，旨在解决传统数据库课程项目中学生过度关注实现细节而缺乏系统整体理解的问题。

Conclusion: EduDB作为一个教育工具，能够帮助学生更好地理解数据库系统内部设计，并通过综合性课程项目平台让学生实践所学优化技术，提升学习效果。

Abstract: Database Management System (DBMS) is designed to help store and process large collections of data, and is incredibly flexible to perform various kinds of optimizations as long as it achieves serializability with a high-level interface available. The current undergraduate level DBMS course in UW-Madison (i.e., CS564) involves implementing specific modules of DB architecture, including B+ tree, but students may end up spending numerous amounts of effort on corner cases and not gaining a more comprehensive understanding of the internal design. Thus, we present EduDB, a simple database prototype for educational purposes that provides students a clean, concise, and comprehensive overview of the database system. We also attempt to develop an integrative series of course projects based on EduDB, which offers a platform for students to perform any optimization learned during the semester.

</details>


### [3] [Create Benchmarks for Data Lakes](https://arxiv.org/abs/2601.19176)
*Yi Lyu,Pei-Chieh Lo,Natan Lidukhover*

Main category: cs.DB

TL;DR: 提出一个针对数据湖系统的标准化基准测试框架，覆盖多种数据类型和工作负载，包括传统查询和相似性搜索等操作。


<details>
  <summary>Details</summary>
Motivation: 数据湖作为存储和分析异构数据的重要解决方案，在工业和学术界应用日益广泛，但缺乏标准化、全面的基准测试框架。现有基准主要针对传统数据仓库和结构化SQL工作负载，无法充分评估数据湖的多样化工作负载和访问模式。

Method: 设计一个可扩展、可复现的基准测试框架，涵盖多种数据类型和工作负载模型，包括数据检索、聚合、查询和相似性搜索。测量查询执行时间、元数据生成时间和元数据大小等关键性能指标，并在CloudLab上进行实验验证。

Result: 开发了一个能够客观比较不同数据湖实现性能的基准测试框架，该框架支持生成数据集并在真实多样的场景下评估商业和开源数据湖平台。

Conclusion: 提出的基准测试框架填补了数据湖评估领域的空白，为数据湖系统的性能比较提供了标准化工具，有助于推动数据湖技术的进一步发展。

Abstract: Data lakes have emerged as a flexible and scalable solution for storing and analyzing large volumes of heterogeneous data, including structured, semi-structured, and unstructured formats. Despite their growing adoption in both industry and academia, there is a lack of standardized and comprehensive benchmarks for evaluating the performance of data lake systems. Existing benchmarks primarily target traditional data warehouses and focus on structured SQL workloads, making them insufficient for capturing the diverse workloads and access patterns typical of data lakes.
  In this work, we propose a new benchmarking framework for data lakes that aims to provide an objective and comparative evaluation of different data lake implementations. Our benchmark covers multiple data types and workload models, including data retrieval, aggregation, querying, and similarity search, which is a common yet underexplored operation in existing benchmarks. We measure key performance metrics such as query execution time, metadata generation time, and metadata size across different scale factors. The benchmark is designed to be extensible and reproducible, enabling users to generate datasets and evaluate data lake systems under realistic and diverse scenarios. We conduct our experiments on CloudLab and demonstrate how the proposed benchmark can be used to compare both commercial and open-source data lake platforms.

</details>


### [4] [Topology-Aware Subset Repair via Entropy-Guided Density and Graph Decomposition](https://arxiv.org/abs/2601.19671)
*Guoqi Zhao,Xixian Han,Xiaolong Wan*

Main category: cs.DB

TL;DR: 提出基于拓扑感知的近似子集修复框架，通过联合密度-冲突惩罚模型解决传统密度方法在脏数据聚类、计算成本和均匀属性权重方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统子集修复方法存在多个最小修复方案，密度方法虽能优先保留高质量数据区域，但受脏数据聚类、高计算成本和均匀属性权重限制，效果有限。

Method: 提出拓扑感知近似子集修复框架，包含三层冲突检测策略、EntroCFDensity密度度量（结合信息熵和CFD权重）、冲突度测量，将冲突图分解为独立子图，开发PPIS启发式算法和MICO混合整数规划方法。

Result: 实验结果表明，该方法提高了修复准确性和鲁棒性，同时有效保留了高质量数据。

Conclusion: 提出的拓扑感知近似子集修复框架通过联合密度-冲突惩罚模型，解决了传统密度方法的局限性，在数据清洗中实现了更好的修复效果。

Abstract: Subset repair is an important data cleaning technique that enforces integrity constraints by deleting a minimal number of conflicting tuples, yet multiple minimal repairs often exist. Density-based methods address this ambiguity by favoring repairs that preserve dense, high-quality data regions; however, their effectiveness is limited by density bias from dirty clusters, high computational cost, and uniform attribute weighting. We propose a topology-aware approximate subset repair framework based on a joint density-conflict penalty model. The framework integrates three key components. First, a two-layer conflict detection strategy combines attribute inverted indexes with CFD rule grouping to efficiently identify violations. Second, we introduce EntroCFDensity, a density metric that incorporates information entropy and CFD weights to dynamically adjust attribute importance and reduce homogeneity bias. Third, a conflict degree measure is defined to complement local density, enabling a topology-adaptive penalty mechanism with dynamic weight allocation guided by the coefficient of variation. The conflict graph is further decomposed into independent subgraphs, transforming global repair into tractable local subproblems. Based on this framework, we develop two algorithms: PPIS, a scalable heuristic, and MICO, a mixed-integer programming method with theoretical guarantees. Experimental results show that our approach improves repair accuracy and robustness while effectively preserving high-quality data.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [5] [Automated structural testing of LLM-based agents: methods, framework, and case studies](https://arxiv.org/abs/2601.18827)
*Jens Kohl,Otto Kruse,Youssef Mostafa,Andre Luckow,Karsten Schroer,Thomas Riedl,Ryan French,David Katz,Manuel P. Luitz,Tanrajbir Takher,Ken E. Friedl,Céline Laurent-Winter*

Main category: cs.SE

TL;DR: 提出基于结构测试的LLM智能体测试方法，使用追踪、模拟和断言实现自动化测试，降低测试成本并提高质量


<details>
  <summary>Details</summary>
Motivation: 当前LLM智能体测试方法主要从用户角度进行验收级评估，需要人工评估、难以自动化、不利于根因分析，且测试环境昂贵

Method: 使用OpenTelemetry追踪捕获智能体轨迹，通过模拟确保可重现的LLM行为，添加断言实现自动化测试验证，支持组件级和交互级测试

Result: 实现了自动化执行和更快的根因分析，能够应用软件工程最佳实践（测试自动化金字塔、回归测试、测试驱动开发、多语言测试）

Conclusion: 结构测试方法降低了测试成本，通过更高覆盖率、可重用性和早期缺陷检测提高了智能体质量，提供了开源参考实现

Abstract: LLM-based agents are rapidly being adopted across diverse domains. Since they interact with users without supervision, they must be tested extensively. Current testing approaches focus on acceptance-level evaluation from the user's perspective. While intuitive, these tests require manual evaluation, are difficult to automate, do not facilitate root cause analysis, and incur expensive test environments. In this paper, we present methods to enable structural testing of LLM-based agents. Our approach utilizes traces (based on OpenTelemetry) to capture agent trajectories, employs mocking to enforce reproducible LLM behavior, and adds assertions to automate test verification. This enables testing agent components and interactions at a deeper technical level within automated workflows. We demonstrate how structural testing enables the adaptation of software engineering best practices to agents, including the test automation pyramid, regression testing, test-driven development, and multi-language testing. In representative case studies, we demonstrate automated execution and faster root-cause analysis. Collectively, these methods reduce testing costs and improve agent quality through higher coverage, reusability, and earlier defect detection. We provide an open source reference implementation on GitHub.

</details>


### [6] [Reducing False Positives in Static Bug Detection with LLMs: An Empirical Study in Industry](https://arxiv.org/abs/2601.18844)
*Xueying Du,Jiayi Feng,Yi Zou,Wei Xu,Jie Ma,Wei Zhang,Sisi Liu,Xin Peng,Yiling Lou*

Main category: cs.SE

TL;DR: LLM在腾讯工业环境中显著降低静态分析工具误报率，成本效益高但仍有局限


<details>
  <summary>Details</summary>
Motivation: 静态分析工具在工业环境中误报率高，导致大量人工检查成本，需要验证LLM在真实企业环境中的误报减少效果

Method: 在腾讯广告营销服务软件上，使用企业定制SAT构建433个警报数据集，通过访谈开发者并分析数据，评估多种LLM误报减少技术

Result: LLM混合技术可消除94-98%误报且召回率高，成本极低（每警报2.1-109.5秒，$0.0011-$0.12），远低于人工检查（10-20分钟）

Conclusion: LLM在工业环境中具有巨大误报减少潜力且成本效益高，但仍存在局限性，为工业应用提供了实证依据

Abstract: Static analysis tools (SATs) are widely adopted in both academia and industry for improving software quality, yet their practical use is often hindered by high false positive rates, especially in large-scale enterprise systems. These false alarms demand substantial manual inspection, creating severe inefficiencies in industrial code review. While recent work has demonstrated the potential of large language models (LLMs) for false alarm reduction on open-source benchmarks, their effectiveness in real-world enterprise settings remains unclear. To bridge this gap, we conduct the first comprehensive empirical study of diverse LLM-based false alarm reduction techniques in an industrial context at Tencent, one of the largest IT companies in China. Using data from Tencent's enterprise-customized SAT on its large-scale Advertising and Marketing Services software, we construct a dataset of 433 alarms (328 false positives, 105 true positives) covering three common bug types. Through interviewing developers and analyzing the data, our results highlight the prevalence of false positives, which wastes substantial manual effort (e.g., 10-20 minutes of manual inspection per alarm). Meanwhile, our results show the huge potential of LLMs for reducing false alarms in industrial settings (e.g., hybrid techniques of LLM and static analysis eliminate 94-98% of false positives with high recall). Furthermore, LLM-based techniques are cost-effective, with per-alarm costs as low as 2.1-109.5 seconds and $0.0011-$0.12, representing orders-of-magnitude savings compared to manual review. Finally, our case analysis further identifies key limitations of LLM-based false alarm reduction in industrial settings.

</details>


### [7] [MulVul: Retrieval-augmented Multi-Agent Code Vulnerability Detection via Cross-Model Prompt Evolution](https://arxiv.org/abs/2601.18847)
*Zihan Wu,Jie Xu,Yun Peng,Chun Yong Chong,Xiaohua Jia*

Main category: cs.SE

TL;DR: MulVul是一个检索增强的多智能体框架，通过路由-检测器架构和跨模型提示进化技术，解决了LLM在漏洞检测中的异质性问题和手动提示工程不可扩展的问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在自动化真实世界漏洞检测方面存在两个关键限制：1）漏洞模式的异质性削弱了单一统一模型的效果；2）为大量弱点类别手动设计提示是不可扩展的。

Method: 提出MulVul框架，采用粗到细策略：Router智能体预测前k个粗粒度类别，然后转发给专门的Detector智能体识别确切漏洞类型。两者都配备检索工具从漏洞知识库获取证据。设计了跨模型提示进化机制，生成器LLM迭代优化候选提示，执行器LLM验证其有效性。

Result: 在130个CWE类型上评估，MulVul达到34.79%的Macro-F1，比最佳基线提高41.5%。消融研究验证跨模型提示进化比手动提示提升51.6%性能。

Conclusion: MulVul通过多智能体架构和自动化提示优化，有效解决了LLM在漏洞检测中的异质性和可扩展性问题，显著提升了检测性能。

Abstract: Large Language Models (LLMs) struggle to automate real-world vulnerability detection due to two key limitations: the heterogeneity of vulnerability patterns undermines the effectiveness of a single unified model, and manual prompt engineering for massive weakness categories is unscalable.
  To address these challenges, we propose \textbf{MulVul}, a retrieval-augmented multi-agent framework designed for precise and broad-coverage vulnerability detection. MulVul adopts a coarse-to-fine strategy: a \emph{Router} agent first predicts the top-$k$ coarse categories and then forwards the input to specialized \emph{Detector} agents, which identify the exact vulnerability types. Both agents are equipped with retrieval tools to actively source evidence from vulnerability knowledge bases to mitigate hallucinations.
  Crucially, to automate the generation of specialized prompts, we design \emph{Cross-Model Prompt Evolution}, a prompt optimization mechanism where a generator LLM iteratively refines candidate prompts while a distinct executor LLM validates their effectiveness. This decoupling mitigates the self-correction bias inherent in single-model optimization.
  Evaluated on 130 CWE types, MulVul achieves 34.79\% Macro-F1, outperforming the best baseline by 41.5\%. Ablation studies validate cross-model prompt evolution, which boosts performance by 51.6\% over manual prompts by effectively handling diverse vulnerability patterns.

</details>


### [8] [Towards Safety-Compliant Transformer Architectures for Automotive Systems](https://arxiv.org/abs/2601.18850)
*Sven Kirchner,Nils Purschke,Chengdong Wu,Alois Knoll*

Main category: cs.SE

TL;DR: 提出将Transformer集成到汽车系统的安全框架，利用多模态基础模型通过传感器多样性和冗余性提高容错能力


<details>
  <summary>Details</summary>
Motivation: Transformer在视觉和语言任务中表现出色，但在安全关键应用中面临挑战，需要解决汽车系统中的安全集成问题

Method: 采用多模态基础模型架构，结合多个独立的模态特定编码器，将表示融合到共享潜在空间，支持单模态失效时的故障操作行为

Result: 通过结构上嵌入冗余性和多样性，在不同输入模态融合下保持一致的场景理解，提高系统鲁棒性

Conclusion: 该方法弥合了现代深度学习与已建立的功能安全实践之间的差距，为自动驾驶中可认证的AI系统铺平了道路

Abstract: Transformer-based architectures have shown remarkable performance in vision and language tasks but pose unique challenges for safety-critical applications. This paper presents a conceptual framework for integrating Transformers into automotive systems from a safety perspective. We outline how multimodal Foundation Models can leverage sensor diversity and redundancy to improve fault tolerance and robustness. Our proposed architecture combines multiple independent modality-specific encoders that fuse their representations into a shared latent space, supporting fail-operational behavior if one modality degrades. We demonstrate how different input modalities could be fused in order to maintain consistent scene understanding. By structurally embedding redundancy and diversity at the representational level, this approach bridges the gap between modern deep learning and established functional safety practices, paving the way for certifiable AI systems in autonomous driving.

</details>


### [9] [Tricky$^2$: Towards a Benchmark for Evaluating Human and LLM Error Interactions](https://arxiv.org/abs/2601.18949)
*Cole Granger,Dipin Khati,Daniel Rodriguez-Cardenas,Denys Poshyvanyk*

Main category: cs.SE

TL;DR: 构建Tricky²混合数据集，结合人类编写缺陷和LLM注入错误，用于研究人类与机器错误交互


<details>
  <summary>Details</summary>
Motivation: 研究LLM在软件开发中引入的微妙逻辑或数据误用错误如何与人类错误交互，这些错误类型与人类bug不同

Method: 使用分类指导的提示框架，在现有TrickyBugs人类编写缺陷基础上，注入GPT-5和OpenAI-oss-20b生成的错误，构建包含C++、Python、Java程序的混合数据集

Result: 创建了Tricky²数据集，包含人类单独错误、LLM单独错误、人类+LLM混合错误三个部分，支持混合来源错误行为分析、多bug修复鲁棒性和人机混合代码可靠性研究

Conclusion: 论文概述了数据集构建流程，并通过分类、定位和修复任务的小规模基线评估展示了其应用价值

Abstract: Large language models (LLMs) are increasingly integrated into software development workflows, yet they often introduce subtle logic or data-misuse errors that differ from human bugs. To study how these two error types interact, we construct Tricky$^2$, a hybrid dataset that augments the existing TrickyBugs corpus of human-written defects with errors injected by both GPT-5 and OpenAI-oss-20b across C++, Python, and Java programs. Our approach uses a taxonomy-guided prompting framework to generate machine-originated bugs while preserving original human defects and program structure. The resulting corpus spans human-only, LLM-only, and human+LLM splits, enabling analysis of mixed-origin error behavior, multi-bug repair robustness, and reliability in hybrid human-machine code. This paper outlines the dataset construction pipeline and illustrates its use through small-scale baseline evaluations of classification, localization, and repair tasks.

</details>


### [10] [The Opaque Pointer Design Pattern in Python: Towards a Pythonic PIMPL for Modularity, Encapsulation, and Stability](https://arxiv.org/abs/2601.19065)
*Antonios Saravanos,John Pazarzis,Stavros Zervoudakis,Dongnanzi Zheng*

Main category: cs.SE

TL;DR: 本文重新诠释了C++的PIMPL（指针到实现）模式，提出了一种Python化的不透明委托模式，用于在Python库中维护稳定的公共API，同时隔离内部实现变化和重量级依赖。


<details>
  <summary>Details</summary>
Motivation: Python库需要在内部实现演进、增加新后端或依赖重量级可选库时保持稳定的公共API。Python中内部对象容易被检查和导入，用户可能依赖"可访问的内部"（非公共API），这增加了重构风险并减缓了长期维护。

Method: 将C++的PIMPL模式重新诠释为Python化的不透明委托模式：小型公共对象（或模块）将其行为委托给被视为内部的单独实现对象。该模式与Python中的封装技术分类相关，包括模块级间接、外观对象和后端调度等现有实践。

Result: 展示了Python化PIMPL如何在现有代码库中用于隔离重量级依赖、支持延迟导入，并在不改变公共API的情况下实现运行时可选后端选择。识别了标准库和科学Python生态系统中已有的PIMPL类似结构。

Conclusion: 讨论了该方法的优点和权衡，并为大型、长期维护的Python库提供了关于何时适用该模式以及如何应用的实践指导。该模式有助于降低重构风险并加速长期维护。

Abstract: Python libraries often need to maintain a stable public API even as internal implementations evolve, gain new backends, or depend on heavy optional libraries. In Python, where internal objects are easy to inspect and import, users can come to rely on "reachable internals" that were never intended to be public, making refactoring risky and slowing long-term maintenance. This paper revisits the pointer-to-implementation (PIMPL) idiom from C++ and reinterprets it as a Pythonic pattern of opaque delegation: a small public object (or module) that delegates its behavior to a separate implementation object treated as internal. We situate this pattern within a broader taxonomy of encapsulation techniques in Python, relate it to existing practices such as module-level indirection, facade objects, and backend dispatch, and identify PIMPL-like structures already used in the standard library and the scientific Python ecosystem. We then show how a Pythonic PIMPL can be used in existing codebases to isolate heavy dependencies, support lazy imports, and enable runtime selection of alternative backends without changing the public API. Finally, we discuss the benefits and trade-offs of the approach and offer practical guidance on when the pattern is appropriate and how to apply it in large, long-lived Python libraries.

</details>


### [11] [Dynamic Cogeneration of Bug Reproduction Test in Agentic Program Repair](https://arxiv.org/abs/2601.19066)
*Runxiang Cheng,Michele Tufano,José Cambronero,Renyao Wei,Sherry Shi,Grant Uy,Pat Rondon,Franjo Ivančić*

Main category: cs.SE

TL;DR: 研究在自动化程序修复中同时生成修复和bug重现测试的协同生成策略，评估不同策略在Google实际bug上的效果，开发考虑测试变化的补丁选择器，证明协同生成能减少工程工作量


<details>
  <summary>Details</summary>
Motivation: 开发者希望AI生成的补丁中包含bug重现测试以增加信心，但传统APR系统通常分别生成测试和修复或只生成修复。协同生成可以简化工程流程，减少维护单独生成管道的成本。

Method: 研究代理式APR中的协同生成策略，在Google的120个人工报告bug上评估不同策略效果，开发考虑测试变化信息的补丁选择器，分析失败协同生成轨迹的根本原因。

Result: 协同生成能让APR代理为至少与专用BRT代理一样多的bug生成BRT，同时不损害合理修复的生成率，从而减少维护和协调单独修复和BRT生成管道的工程工作量。

Conclusion: 协同生成策略在自动化程序修复中是有效的，能够同时生成修复和bug重现测试，减少工程复杂度，提高开发者的信心，为大规模APR系统部署提供了实用方案。

Abstract: Bug Reproduction Tests (BRTs) have been used in many agentic Automated Program Repair (APR) systems, primarily for validating promising fixes and aiding fix generation. In practice, when developers submit a patch, they often implement the BRT alongside the fix. Our experience deploying agentic APR reveals that developers similarly desire a BRT within AI-generated patches to increase their confidence. However, canonical APR systems tend to generate BRTs and fixes separately, or focus on producing only the fix in the final patch. In this paper, we study agentic APR in the context of cogeneration, where the APR agent is instructed to generate both a fix and a BRT in the same patch. We evaluate the effectiveness of different cogeneration strategies on 120 human-reported bugs at Google and characterize different cogeneration strategies by their influence on APR agent behavior. We develop and evaluate patch selectors that account for test change information to select patches with plausible fixes (and plausible BRTs). Finally, we analyze the root causes of failed cogeneration trajectories. Importantly, we show that cogeneration allows the APR agent to generate BRTs for at least as many bugs as a dedicated BRT agent, without compromising the generation rate of plausible fixes, thereby reducing engineering effort in maintaining and coordinating separate generation pipelines for fix and BRT at scale.

</details>


### [12] [HalluJudge: A Reference-Free Hallucination Detection for Context Misalignment in Code Review Automation](https://arxiv.org/abs/2601.19072)
*Kla Tantithamthavorn,Hong Yi Lin,Patanamon Thongtanunam,Wachiraphan Charoenwet,Minwoo Jeong,Ming Wu*

Main category: cs.SE

TL;DR: HalluJudge是一个检测LLM生成代码审查评论中幻觉（无根据评论）的系统，通过上下文对齐评估，在Atlassian企业级项目中验证有效，F1分数0.85，成本仅$0.009，67%判断与开发者偏好一致。


<details>
  <summary>Details</summary>
Motivation: LLM在代码审查自动化中表现出色，但存在幻觉问题（生成的评论缺乏代码依据），这阻碍了LLM在代码审查工作流中的实际应用。需要开发无需参考的有效、可扩展的幻觉检测方法。

Method: 设计HalluJudge系统，基于上下文对齐评估生成评论的grounding。包含四种关键策略：从直接评估到结构化多分支推理（如Tree-of-Thoughts）。在Atlassian企业级软件项目中进行全面评估。

Result: HalluJudge的幻觉检测成本效益高，F1分数达0.85，平均成本仅$0.009。平均67%的HalluJudge判断与在线生产中实际LLM生成审查评论的开发者偏好一致。

Conclusion: HalluJudge可作为实用保障措施，减少开发者接触幻觉评论，促进对AI辅助代码审查的信任。该系统在真实生产环境中验证有效，能提升LLM在代码审查工作流中的可靠性。

Abstract: Large Language models (LLMs) have shown strong capabilities in code review automation, such as review comment generation, yet they suffer from hallucinations -- where the generated review comments are ungrounded in the actual code -- poses a significant challenge to the adoption of LLMs in code review workflows. To address this, we explore effective and scalable methods for a hallucination detection in LLM-generated code review comments without the reference. In this work, we design HalluJudge that aims to assess the grounding of generated review comments based on the context alignment. HalluJudge includes four key strategies ranging from direct assessment to structured multi-branch reasoning (e.g., Tree-of-Thoughts). We conduct a comprehensive evaluation of these assessment strategies across Atlassian's enterprise-scale software projects to examine the effectiveness and cost-efficiency of HalluJudge. Furthermore, we analyze the alignment between HalluJudge's judgment and developer preference of the actual LLM-generated code review comments in the real-world production. Our results show that the hallucination assessment in HalluJudge is cost-effective with an F1 score of 0.85 and an average cost of $0.009. On average, 67% of the HalluJudge assessments are aligned with the developer preference of the actual LLM-generated review comments in the online production. Our results suggest that HalluJudge can serve as a practical safeguard to reduce developers' exposure to hallucinated comments, fostering trust in AI-assisted code reviews.

</details>


### [13] [Hybrid Fault-Driven Mutation Testing for Python](https://arxiv.org/abs/2601.19088)
*Saba Alimadadi,Golnaz Gharachorlu*

Main category: cs.SE

TL;DR: 提出PyTation工具，通过7个基于Python反模式的变异算子，结合静态和动态分析，提升Python程序变异测试效果


<details>
  <summary>Details</summary>
Motivation: 现有变异测试技术难以捕捉动态类型语言（如Python）中的常见错误类型，需要针对Python特定反模式设计更有效的变异算子

Method: 提出7个基于Python常见反模式的变异算子，采用静态和动态分析结合的混合方法进行变异，最小化等价变异体

Result: PyTation生成的变异体补充了通用工具，表现出独特的测试执行行为，能发现高覆盖率测试套件的不足，产生高比例独特变异体、低交叉杀死率和低测试重叠率

Conclusion: PyTation通过针对Python反模式的变异算子，有效提升了Python程序变异测试的覆盖范围和效果，同时保持了较低的等价变异体比例

Abstract: Mutation testing is an effective technique for assessing the effectiveness of test suites by systematically injecting artificial faults into programs. However, existing mutation testing techniques fall short in capturing many types of common faults in dynamically typed languages like Python. In this paper, we introduce a novel set of seven mutation operators that are inspired by prevalent anti-patterns in Python programs, designed to complement the existing general-purpose operators and broaden the spectrum of simulated faults. We propose a mutation testing technique that utilizes a hybrid of static and dynamic analyses to mutate Python programs based on these operators while minimizing equivalent mutants. We implement our approach in a tool called PyTation and evaluate it on 13 open-source Python applications. Our results show that PyTation generates mutants that complement those from general-purpose tools, exhibiting distinct behaviour under test execution and uncovering inadequacies in high-coverage test suites. We further demonstrate that PyTation produces a high proportion of unique mutants, a low cross-kill rate, and a low test overlap ratio relative to baseline tools, highlighting its novel fault model. PyTation also incurs few equivalent mutants, aided by dynamic analysis heuristics.

</details>


### [14] [Reward Engineering for Reinforcement Learning in Software Tasks](https://arxiv.org/abs/2601.19100)
*Md Rayhanul Masud,Azmine Toushik Wasi,Salman Rahman,Md Rizwan Parvez*

Main category: cs.SE

TL;DR: 这篇论文是第一篇关于软件任务中强化学习奖励设计的系统性综述，整理了现有方法和技术，提出了三个互补维度来组织文献，并总结了软件工程任务中奖励设计的挑战和建议。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型和自主代理的发展，强化学习在代码相关任务中的应用日益增多，但软件任务的奖励设计面临独特挑战。软件目标很少是单一数值目标，通常需要代理指标（如编译通过、测试通过、质量指标）。现有奖励设计方法分散在不同领域和论文中，缺乏系统性综述来整合这些方法并展示完整的奖励设计图景。

Method: 采用系统性文献综述方法，聚焦现有奖励设计方法和技术。通过三个互补维度来结构化文献：1) 奖励信号类型（编译、测试、质量指标等），2) 奖励设计方法（稀疏/密集奖励、多目标优化等），3) 应用领域（代码生成、修复、测试等）。在每个维度内总结奖励设计选择。

Result: 提供了首个全面系统的软件任务中强化学习奖励设计综述，整理了分散在不同领域的研究工作，建立了统一的分类框架，识别了现有方法的模式和趋势，为研究人员和实践者提供了清晰的奖励设计图景。

Conclusion: 软件任务中的强化学习奖励设计是一个复杂但关键的领域，需要专门的方法来处理软件特有的挑战。论文总结了当前奖励设计空间的挑战，并提出了具体建议，为未来研究提供了方向，有助于推动强化学习在软件工程任务中的更有效应用。

Abstract: Reinforcement learning is increasingly used for code-centric tasks. These tasks include code generation, summarization, understanding, repair, testing, and optimization. This trend is growing faster with large language models and autonomous agents. A key challenge is how to design reward signals that make sense for software. In many RL problems, the reward is a clear number. In software, this is often not possible. The goal is rarely a single numeric objective. Instead, rewards are usually proxies. Common proxies check if the code compiles, passes tests, or satisfies quality metrics. Many reward designs have been proposed for code-related tasks. However, the work is scattered across areas and papers. There is no single survey that brings these approaches together and shows the full landscape of reward design for RL in software. In this survey, we provide the first systematic and comprehensive review of reward engineering for RL in software tasks. We focus on existing methods and techniques. We structure the literature along three complementary dimensions, summarizing the reward-design choices within each. We conclude with challenges and recommendations in the reward design space for SE tasks.

</details>


### [15] [Detecting and Correcting Hallucinations in LLM-Generated Code via Deterministic AST Analysis](https://arxiv.org/abs/2601.19106)
*Dipin Khati,Daniel Rodriguez-Cardenas,Paul Pantzer,Denys Poshyvanyk*

Main category: cs.SE

TL;DR: 提出一个基于静态分析的确定性后处理框架，用于检测和自动修正代码生成中的知识冲突幻觉（KCHs），通过AST解析和动态知识库验证实现高精度检测和自动修复。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型生成的代码经常包含知识冲突幻觉（KCHs），这些是细微的语义错误（如不存在的API参数），难以被传统linter检测，导致运行时失败。现有基于约束解码或非确定性LLM修复的方法对这些错误不可靠。

Method: 提出一个确定性后处理框架：1）将生成的代码解析为抽象语法树（AST）；2）通过库内省动态构建知识库（KB）；3）使用确定性规则验证AST与知识库的一致性；4）检测并自动修正API和标识符级别的冲突。该方法不执行代码，纯静态分析。

Result: 在200个手动整理的Python代码片段数据集上：检测KCHs达到100%精确率和87.6%召回率（F1分数0.934）；成功自动修正了77.0%的所有已识别幻觉。

Conclusion: 这种确定性后处理方法为概率性修复提供了可靠替代方案，展示了在可信代码生成方面的可行性，为构建可信的代码生成系统提供了明确路径。

Abstract: Large Language Models (LLMs) for code generation boost productivity but frequently introduce Knowledge Conflicting Hallucinations (KCHs), subtle, semantic errors, such as non-existent API parameters, that evade linters and cause runtime failures. Existing mitigations like constrained decoding or non-deterministic LLM-in-the-loop repair are often unreliable for these errors. This paper investigates whether a deterministic, static-analysis framework can reliably detect \textit{and} auto-correct KCHs. We propose a post-processing framework that parses generated code into an Abstract Syntax Tree (AST) and validates it against a dynamically-generated Knowledge Base (KB) built via library introspection. This non-executing approach uses deterministic rules to find and fix both API and identifier-level conflicts. On a manually-curated dataset of 200 Python snippets, our framework detected KCHs with 100\% precision and 87.6\% recall (0.934 F1-score), and successfully auto-corrected 77.0\% of all identified hallucinations. Our findings demonstrate that this deterministic post-processing approach is a viable and reliable alternative to probabilistic repair, offering a clear path toward trustworthy code generation.

</details>


### [16] [The Promise and Reality of Continuous Integration Caching: An Empirical Study of Travis CI Builds](https://arxiv.org/abs/2601.19146)
*Taher A. Ghaleb,Daniel Alencar da Costa,Ying Zou*

Main category: cs.SE

TL;DR: 对Travis CI中持续集成缓存的实证研究发现，只有30%的项目采用缓存，早期采用与项目成熟度相关，近一半未采用项目接受启用缓存的PR，缓存需要维护且实际效果有限。


<details>
  <summary>Details</summary>
Motivation: 持续集成（CI）通过自动构建软件提供早期反馈，但构建时间长会影响开发效率。CI服务提供缓存机制来加速构建，但实践中缓存的采用情况和挑战尚不清楚。

Method: 对Travis CI中的CI缓存进行大规模实证研究，分析来自1,279个GitHub项目的513,384个构建。通过提交PR启用未采用项目的缓存，收集开发者反馈，并分析缓存维护活动和报告的问题。

Result: 只有30%的项目采用CI缓存，早期采用与项目成熟度（更多依赖、提交、更长CI生命周期）相关。近一半未采用项目接受启用缓存的PR。24%的缓存项目进行维护活动，三分之一项目构建时间显著减少，但97%的构建有缓存上传，33%的项目存在过时缓存。开发者主要面临缓存损坏、过时问题。

Conclusion: CI缓存并非对所有项目都有帮助，需要持续维护，且实践中的复杂性超出许多开发者预期。非采用或延迟采用主要源于对CI缓存支持的认知有限。

Abstract: Continuous Integration (CI) provides early feedback by automatically building software, but long build durations can hinder developer productivity. CI services offer caching mechanisms to speed up builds by reusing infrequently changing artifacts, yet little is known about how caching is adopted in practice and what challenges it entails. In this paper, we conduct a large-scale empirical study of CI caching in Travis CI, analyzing 513,384 builds from 1,279 GitHub projects. We find that only 30% of projects adopt CI caching, and early adoption is strongly associated with project maturity, such as more dependencies, more commits, and longer CI lifespans. To understand why many projects do not adopt caching, we submitted pull requests enabling caching in non-adopting projects, and nearly half were accepted or merged. Developer feedback suggests that non- or late adoption mainly stems from limited awareness of CI caching support. We also examine cache maintenance and identify five common activities, performed by 24% of cache-enabled projects. Although one-third of projects see substantial build-time reductions, cache uploads occur in 97% of builds, and 33% of projects contain stale cached artifacts. Finally, our analysis of reported caching issues shows developers mainly struggle with corrupted or outdated caches or request broader caching features. Overall, CI caching does not help all projects, needs ongoing maintenance, and is more complex in practice than many developers expect.

</details>


### [17] [SE Journals in 2036: Looking Back at the Future We Need to Have](https://arxiv.org/abs/2601.19217)
*Tim Menzies,Paris Avgeriou,Robert Feldt,Mauro Pezzè,Abhik Roychoudhury,Miroslaw Staron,Sebastian Uchitel,Thomas Zimmermann*

Main category: cs.SE

TL;DR: 论文提出软件工程出版面临可扩展性危机，传统同行评审已崩溃，需要系统性改革


<details>
  <summary>Details</summary>
Motivation: 软件工程社区规模扩大且快速整合LLM等新方法，传统同行评审实践在压力下崩溃，形成"官僚异常"和"随机抽奖"机制，惩罚创新并耗尽研究人员精力

Method: 从2036年视角提出三阶段解决方案：1) 停止内斗（期刊联盟）；2) 修复流程（抽奖机制/解绑/修复基准测试墓地）；3) 修复文化（大教堂/集市模式）

Result: 论文提出了一个系统性改革框架，但作为未来视角的设想性论文，实际结果尚未实现，需要社区采纳实施

Conclusion: 软件工程出版需要根本性变革，通过期刊联盟、流程改革和文化转变来应对可扩展性危机，创造更可持续的学术生态系统

Abstract: In 2025, SE publishing faces an existential crisis of scalability. As our communities swell globally and integrate fast-moving methodologies like LLMs, traditional peer-review practices are collapsing under the strain. The "bureaucratic anomaly" of monolithic review has become mathematically unsustainable, creating a stochastic "lottery" that punishes novelty and exhausts researchers.
  This paper, written from the perspective of 2036, documents potential solutions. Here, the editors of ASE, EMSE, IST, JSS, TOSEM and TSE dream a collective dream of a brighter future. In summary first we stopped fighting (The Journal Alliance). Then we fixed the process (The Lottery / Unbundling / Fixing the Benchmark Graveyard). And then we fixed the culture (Cathedrals/Bazaars).

</details>


### [18] [LLM-based Vulnerability Detection at Project Scale: An Empirical Study](https://arxiv.org/abs/2601.19239)
*Fengjie Li,Jiajun Jiang,Dongchi Chen,Yingfei Xiong*

Main category: cs.SE

TL;DR: 该研究首次对基于LLM的漏洞检测器与传统静态分析工具进行项目级实证比较，发现LLM检测器召回率低但能发现更多独特漏洞，两者都存在高误报率，且LLM方法计算成本极高。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏对基于LLM的漏洞检测器与传统静态分析工具在项目级规模上的全面实证比较研究，需要评估这些工具的实际可用性和局限性。

Method: 评估5种最新的LLM检测方法和2种传统工具：1) 使用包含222个已知真实漏洞(C/C++和Java)的内部基准测试检测能力；2) 在24个活跃开源项目中手动检查385个警告，评估实际可用性和失败原因。

Result: 1) LLM检测器在基准测试中召回率低，但比传统工具发现更多独特漏洞；2) 两种工具在开源项目中都产生大量警告但误报率极高；3) LLM方法需要消耗数十万到数亿token，运行时间数小时到数天；4) 主要失败原因包括浅层过程间推理和错误识别源/汇对。

Conclusion: 当前基于LLM的漏洞检测器在鲁棒性、可靠性和可扩展性方面存在严重限制，需要进一步研究改进以实现更有效和实用的项目级漏洞检测。

Abstract: In this paper, we present the first comprehensive empirical study of specialized LLM-based detectors and compare them with traditional static analyzers at the project scale. Specifically, our study evaluates five latest and representative LLM-based methods and two traditional tools using: 1) an in-house benchmark of 222 known real-world vulnerabilities (C/C++ and Java) to assess detection capability, and 2) 24 active open-source projects, where we manually inspected 385 warnings to assess their practical usability and underlying root causes of failures. Our evaluation yields three key findings: First, while LLM-based detectors exhibit low recall on the in-house benchmark, they still uncover more unique vulnerabilities than traditional tools. Second, in open-source projects, both LLM-based and traditional tools generate substantial warnings but suffer from very high false discovery rates, hindering practical use. Our manual analysis further reveals shallow interprocedural reasoning and misidentified source/sink pairs as primary failure causes, with LLM-based tools exhibiting additional unique failures. Finally, LLM-based methods incurs substantial computational costs-hundreds of thousands to hundreds of millions of tokens and multi-hour to multi-day runtimes. Overall, our findings underscore critical limitations in the robustness, reliability, and scalability of current LLM-based detectors. We ultimately summarize a set of implications for future research toward more effective and practical project-scale vulnerability detection.

</details>


### [19] ["ENERGY STAR" LLM-Enabled Software Engineering Tools](https://arxiv.org/abs/2601.19260)
*Himon Thakur,Armin Moin*

Main category: cs.SE

TL;DR: 研究AI工程中支持软件工程过程的AI增强工具（如CASE工具和IDE）的能效问题，提出结合RAG和PET的方法来提升LLM代码生成的质量和能效，并建立框架测量不同规模模型的实时能耗和推理时间。


<details>
  <summary>Details</summary>
Motivation: 随着AI在软件工程工具（如CASE工具和IDE）中的普及和默认启用，AI增强的软件系统对软件开发生命周期（SDLC）的能耗模式产生了重大影响，需要研究这些系统的能效问题。

Method: 结合检索增强生成（RAG）和提示工程技术（PETs）来提升LLM代码生成的质量和能效，建立综合框架测量从125M到7B参数的不同模型架构（包括GPT-2、CodeLlama、Qwen 2.5和DeepSeek Coder）的实时能耗和推理时间。

Result: 通过实验验证了核心思想，为未来更深入的分析提供了概念验证，展示了不同规模LLM在代码生成任务中的能效表现。

Conclusion: AI增强的软件工程工具对SDLC能耗有重要影响，需要关注其能效优化，提出的RAG+PET方法为提升LLM代码生成的能效提供了可行方案，为未来研究奠定了基础。

Abstract: The discussion around AI-Engineering, that is, Software Engineering (SE) for AI-enabled Systems, cannot ignore a crucial class of software systems that are increasingly becoming AI-enhanced: Those used to enable or support the SE process, such as Computer-Aided SE (CASE) tools and Integrated Development Environments (IDEs). In this paper, we study the energy efficiency of these systems. As AI becomes seamlessly available in these tools and, in many cases, is active by default, we are entering a new era with significant implications for energy consumption patterns throughout the Software Development Lifecycle (SDLC). We focus on advanced Machine Learning (ML) capabilities provided by Large Language Models (LLMs). Our proposed approach combines Retrieval-Augmented Generation (RAG) with Prompt Engineering Techniques (PETs) to enhance both the quality and energy efficiency of LLM-based code generation. We present a comprehensive framework that measures real-time energy consumption and inference time across diverse model architectures ranging from 125M to 7B parameters, including GPT-2, CodeLlama, Qwen 2.5, and DeepSeek Coder. These LLMs, chosen for practical reasons, are sufficient to validate the core ideas and provide a proof of concept for more in-depth future analysis.

</details>


### [20] [Whitespaces Don't Lie: Feature-Driven and Embedding-Based Approaches for Detecting Machine-Generated Code](https://arxiv.org/abs/2601.19264)
*Syed Mehedi Hasan Nirob,Shamim Ehsan,Moqsadur Rahman,Summit Haque*

Main category: cs.SE

TL;DR: 该论文研究了区分人类编写代码与AI生成代码的方法，比较了基于特征和基于嵌入的检测器，发现两者都能达到很高的检测性能（ROC-AUC约0.995），其中基于特征的方法在可解释性方面有优势。


<details>
  <summary>Details</summary>
Motivation: 随着LLM能够轻松从自然语言提示生成源代码，这带来了学术诚信、作者归属和负责任AI使用的新风险，需要开发有效的代码来源检测方法。

Method: 比较两种互补方法：1）基于特征的检测器，使用轻量级、可解释的代码风格计量和结构特征；2）基于嵌入的检测器，利用预训练的代码编码器（如CodeBERT）。使用包含60万个人类编写和AI生成代码样本的大规模基准数据集进行评估。

Result: 基于特征的模型表现优异（ROC-AUC 0.995，PR-AUC 0.995，F1 0.971），基于嵌入的模型（使用CodeBERT）也很具竞争力（ROC-AUC 0.994，PR-AUC 0.994，F1 0.965）。缩进和空格相关特征提供特别强的区分线索，而嵌入能捕获更深层的语义模式并具有稍高的精确度。

Conclusion: 研究揭示了可解释性与泛化能力之间的权衡，为在学术和工业环境中部署稳健的代码来源检测提供了实用指导。两种方法都能有效区分人类编写和AI生成的代码。

Abstract: Large language models (LLMs) have made it remarkably easy to synthesize plausible source code from natural language prompts. While this accelerates software development and supports learning, it also raises new risks for academic integrity, authorship attribution, and responsible AI use. This paper investigates the problem of distinguishing human-written from machine-generated code by comparing two complementary approaches: feature-based detectors built from lightweight, interpretable stylometric and structural properties of code, and embedding-based detectors leveraging pretrained code encoders. Using a recent large-scale benchmark dataset of 600k human-written and AI-generated code samples, we find that feature-based models achieve strong performance (ROC-AUC 0.995, PR-AUC 0.995, F1 0.971), while embedding-based models with CodeBERT embeddings are also very competitive (ROC-AUC 0.994, PR-AUC 0.994, F1 0.965). Analysis shows that features tied to indentation and whitespace provide particularly discriminative cues, whereas embeddings capture deeper semantic patterns and yield slightly higher precision. These findings underscore the trade-offs between interpretability and generalization, offering practical guidance for deploying robust code-origin detection in academic and industrial contexts.

</details>


### [21] [Understanding Dominant Themes in Reviewing Agentic AI-authored Code](https://arxiv.org/abs/2601.19287)
*Md. Asif Haider,Thomas Zimmermann*

Main category: cs.SE

TL;DR: 对AI生成代码的代码审查进行大规模实证研究，分析19,450条审查评论，发现AI生成的PR审查主要关注文档、重构、格式等问题，而不仅仅是功能正确性。


<details>
  <summary>Details</summary>
Motivation: 虽然之前的研究关注了Agentic AI系统的代码生成能力，但缺乏对实际代码审查中评审人员如何响应AI生成代码的了解。本研究旨在填补这一空白，探索AI生成PR在真实GitHub仓库中的代码审查动态。

Method: 使用AIDev数据集的精选子集，分析3,177个AI生成的PR和19,450条内联审查评论。通过主题建模结合LLM辅助的语义聚类和整合，推导出12个审查评论主题分类。然后评估零样本提示的LLM是否能可靠地标注审查评论，并与人工标注进行对比。

Result: 开源LLM在审查评论级别达到78.63%的精确匹配、0.78的宏观F1分数，与人工标注者具有显著一致性。在PR级别，LLM以78%的Top-1准确率正确识别主导审查主题，平均Jaccard相似度为0.76。大规模应用发现，AI生成PR的审查主要关注文档缺失、重构需求、样式和格式问题，以及测试和安全相关关注点。

Conclusion: 虽然AI代理可以加速代码生产，但在文档、代码质量、格式等方面仍存在差距，需要针对性的人工审查监督。研究为理解AI生成代码的审查实践提供了实证基础，并展示了LLM在自动标注审查评论方面的潜力。

Abstract: While prior work has examined the generation capabilities of Agentic AI systems, little is known about how reviewers respond to AI-authored code in practice. In this paper, we present a large-scale empirical study of code review dynamics in agent-generated PRs. Using a curated subset of the AIDev dataset, we analyze 19,450 inline review comments spanning 3,177 agent-authored PRs from real-world GitHub repositories. We first derive a taxonomy of 12 review comment themes using topic modeling combined with large language model (LLM)-assisted semantic clustering and consolidation. According to this taxonomy, we then investigate whether zero-shot prompts to LLM can reliably annotate review comments. Our evaluation against human annotations shows that open-source LLM achieves reasonably high exact match (78.63%), macro F1 score (0.78), and substantial agreement with human annotators at the review comment level. At the PR level, the LLM also correctly identifies the dominant review theme with 78% Top-1 accuracy and achieves an average Jaccard similarity of 0.76, indicating strong alignment with human judgments. Applying this annotation pipeline at scale, we find that apart from functional correctness and logical changes, reviews of agent-authored PRs predominantly focus on documentation gaps, refactoring needs, styling and formatting issues, with testing and security-related concerns. These findings suggest that while AI agents can accelerate code production, there remain gaps requiring targeted human review oversight.

</details>


### [22] [Modeling Sampling Workflows for Code Repositories](https://arxiv.org/abs/2601.19316)
*Romain Lefeuvre,Maïwenn Le Goasteller,Jessie Galasso,Benoit Combemale,Quentin Perez,Houari Sahraoui*

Main category: cs.SE

TL;DR: 提出一种领域特定语言（DSL）来形式化描述代码仓库采样策略，支持对采样决策泛化性的推理，并通过Python实现验证其可行性。


<details>
  <summary>Details</summary>
Motivation: 软件工程实证研究依赖代码仓库数据集，采样策略设计直接影响研究结果的泛化性，但目前采样在软件工程研究中被低估，存在采样方法设计代表性不足和难以推理采样决策对泛化性影响两大挑战。

Method: 提出领域特定语言（DSL），通过可组合的采样操作符明确描述复杂采样策略，支持采样策略规范化和泛化性推理，并实现为Python流式API，利用采样工作流提取的统计指标进行代表性推理。

Result: DSL能够建模近期文献中报告的采样策略，通过MSR论文案例研究验证了方法的有效性，展示了DSL如何促进代表性推理。

Conclusion: 提出的DSL形式化方法能够解决软件工程研究中采样策略设计和泛化性推理的挑战，为大规模代码仓库分析提供更可靠的采样框架。

Abstract: Empirical software engineering research often depends on datasets of code repository artifacts, where sampling strategies are employed to enable large-scale analyses. The design and evaluation of these strategies are critical, as they directly influence the generalizability of research findings. However, sampling remains an underestimated aspect in software engineering research: we identify two main challenges related to (1) the design and representativeness of sampling approaches, and (2) the ability to reason about the implications of sampling decisions on generalizability. To address these challenges, we propose a Domain-Specific Language (DSL) to explicitly describe complex sampling strategies through composable sampling operators. This formalism supports both the specification and the reasoning about the generalizability of results based on the applied sampling strategies. We implement the DSL as a Python-based fluent API, and demonstrate how it facilitates representativeness reasoning using statistical indicators extracted from sampling workflows. We validate our approach through a case study of MSR papers involving code repository sampling. Our results show that the DSL can model the sampling strategies reported in recent literature.

</details>


### [23] [High-quality data augmentation for code comment classification](https://arxiv.org/abs/2601.19383)
*Thomas Borsani,Andrea Rosani,Giuseppe Di Fatta*

Main category: cs.SE

TL;DR: 提出Q-SYNTH技术，通过合成过采样和增强方法改善代码注释分类数据集的规模限制和类别不平衡问题，在NLBSE'26挑战数据集上提升分类器性能2.56%。


<details>
  <summary>Details</summary>
Motivation: 代码注释在软件开发中至关重要，但现有注释分类数据集存在规模限制和类别不平衡问题，主要依赖人工标注且不能准确反映真实代码库中的注释分布。

Method: 提出Q-SYNTH技术，包括合成过采样和增强方法，基于高质量数据生成来增强NLBSE'26挑战数据集。

Result: Q-SYNTH技术取得有希望的结果，将基础分类器的性能提升了2.56%。

Conclusion: 通过合成过采样和增强技术可以有效解决代码注释分类数据集的大小限制和类别不平衡问题，提升分类器性能。

Abstract: Code comments serve a crucial role in software development for documenting functionality, clarifying design choices, and assisting with issue tracking. They capture developers' insights about the surrounding source code, serving as an essential resource for both human comprehension and automated analysis. Nevertheless, since comments are in natural language, they present challenges for machine-based code understanding. To address this, recent studies have applied natural language processing (NLP) and deep learning techniques to classify comments according to developers' intentions. However, existing datasets for this task suffer from size limitations and class imbalance, as they rely on manual annotations and may not accurately represent the distribution of comments in real-world codebases. To overcome this issue, we introduce new synthetic oversampling and augmentation techniques based on high-quality data generation to enhance the NLBSE'26 challenge datasets. Our Synthetic Quality Oversampling Technique and Augmentation Technique (Q-SYNTH) yield promising results, improving the base classifier by $2.56\%$.

</details>


### [24] [Bridging the Socio-Emotional Gap: The Functional Dimension of Human-AI Collaboration for Software Engineering](https://arxiv.org/abs/2601.19387)
*Lekshmi Murali Rani,Richard Berntsson Svensson,Robert Feldt*

Main category: cs.SE

TL;DR: 软件工程师认为AI是智力伙伴而非社交伙伴，期望AI具备功能性协作能力而非复制人类社交情感特质，提出了"功能等价物"概念来弥补协作差距。


<details>
  <summary>Details</summary>
Motivation: 随着GenAI模型被用于支持软件工程师和开发团队，理解有效的人机协作变得日益重要。人类团队协作中的社交情感智能能增强协作，但AI系统缺乏这种能力，造成了协作动态的潜在差距。

Method: 通过半结构化访谈10名软件从业者，研究他们对人机协作中社交情感差距的看法，以及他们认为AI系统需要哪些能力来实现有效协作。

Result: 从业者目前将AI模型视为智力伙伴而非社交伙伴，对AI的社交情感属性期望低于人类队友。他们认为社交情感差距不是AI未能展现社交情感特质，而是协作能力的功能性差距（如协商责任、上下文适应、维持持续合作关系的能力）。

Conclusion: 提出了"功能等价物"概念：通过技术能力（内部认知、上下文智能、适应性学习、协作智能）实现与人类社交情感属性相当的协作结果。有效的人机协作可能需要功能性设计而非复制人类社交情感特质，从而将协作重新定义为功能对齐。

Abstract: As GenAI models are adopted to support software engineers and their development teams, understanding effective human-AI collaboration (HAIC) is increasingly important. Socio-emotional intelligence (SEI) enhances collaboration among human teammates, but its role in HAIC remains unclear. Current AI systems lack SEI capabilities that humans bring to teamwork, creating a potential gap in collaborative dynamics. In this study, we investigate how software practitioners perceive the socio-emotional gap in HAIC and what capabilities AI systems require for effective collaboration. Through semi-structured interviews with 10 practitioners, we examine how they think about collaborating with human versus AI teammates, focusing on their SEI expectations and the AI capabilities they envision. Results indicate that practitioners currently view AI models as intellectual teammates rather than social partners and expect fewer SEI attributes from them than from human teammates. However, they see the socio-emotional gap not as AIs failure to exhibit SEI traits, but as a functional gap in collaborative capabilities (AIs inability to negotiate responsibilities, adapt contextually, or maintain sustained partnerships). We introduce the concept of functional equivalents: technical capabilities (internal cognition, contextual intelligence, adaptive learning, and collaborative intelligence) that achieve collaborative outcomes comparable to human SEI attributes. Our findings suggest that effective collaboration with AI for SE tasks may benefit from functional design rather than replicating human SEI traits for SE tasks, thereby redefining collaboration as functional alignment.

</details>


### [25] [AACR-Bench: Evaluating Automatic Code Review with Holistic Repository-Level Context](https://arxiv.org/abs/2601.19494)
*Lei Zhang,Yongda Yu,Minghui Yu,Xinxin Guo,Zhengqi Zhuang,Guoping Rong,Dong Shao,Haifeng Shen,Hongyu Kuang,Zhengfeng Li,Boge Wang,Guoan Zhang,Bangyu Xiang,Xiaobing Xu*

Main category: cs.SE

TL;DR: AACR-Bench是一个用于自动化代码评审（ACR）的多语言基准测试，通过AI辅助专家验证的标注流程提供更全面的缺陷覆盖，揭示了现有评估方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有自动化代码评审基准测试存在两个关键问题：1）缺乏多语言支持，限制了评估结果的泛化能力；2）依赖原始PR评论中的噪声和不完整真实数据，限制了问题检测范围。

Method: 提出AACR-Bench基准测试，采用"AI辅助、专家验证"的标注流程，在多个编程语言中提供完整的跨文件上下文，显著增加缺陷覆盖范围。

Result: AACR-Bench实现了285%的缺陷覆盖率提升，对主流LLM的评估显示先前评估可能误判或部分捕捉了模型能力。研究发现上下文粒度/级别和检索方法选择显著影响ACR性能。

Conclusion: 该工作为ACR评估建立了更严格的标准，提供了关于LLM在ACR中应用的新见解，包括上下文粒度、检索方法选择等因素对性能的影响。

Abstract: High-quality evaluation benchmarks are pivotal for deploying Large Language Models (LLMs) in Automated Code Review (ACR). However, existing benchmarks suffer from two critical limitations: first, the lack of multi-language support in repository-level contexts, which restricts the generalizability of evaluation results; second, the reliance on noisy, incomplete ground truth derived from raw Pull Request (PR) comments, which constrains the scope of issue detection. To address these challenges, we introduce AACR-Bench a comprehensive benchmark that provides full cross-file context across multiple programming languages. Unlike traditional datasets, AACR-Bench employs an "AI-assisted, Expert-verified" annotation pipeline to uncover latent defects often overlooked in original PRs, resulting in a 285\% increase in defect coverage. Extensive evaluations of mainstream LLMs on AACR-Bench reveal that previous assessments may have either misjudged or only partially captured model capabilities due to data limitations. Our work establishes a more rigorous standard for ACR evaluation and offers new insights on LLM based ACR, i.e., the granularity/level of context and the choice of retrieval methods significantly impact ACR performance, and this influence varies depending on the LLM, programming language, and the LLM usage paradigm e.g., whether an Agent architecture is employed. The code, data, and other artifacts of our evaluation set are available at https://github.com/alibaba/aacr-bench .

</details>


### [26] [From Scattered to Structured: A Vision for Automating Architectural Knowledge Management](https://arxiv.org/abs/2601.19548)
*Jan Keim,Angelika Kaplan*

Main category: cs.SE

TL;DR: 提出一个自动化流水线，从异构软件制品中提取架构知识，构建结构化知识库，支持一致性检查、变更影响分析和自然语言问答


<details>
  <summary>Details</summary>
Motivation: 软件架构知识分散在需求文档、设计图、代码和文档等异构制品中，难以有效访问和利用。随着系统演化，这些制品间经常出现不一致，导致架构侵蚀和维护困难。

Method: 开发针对不同制品类型的专门提取器，设计统一的知识表示模式，实现一致性检查机制，集成检索增强生成技术以支持对话式知识访问。

Result: 提出一个系统性愿景和实现计划，旨在构建一个结构化知识库，支持架构一致性检查、变更影响分析和自然语言问答等关键活动。

Conclusion: 通过自动化流水线整合分散的架构知识，可以改善架构知识的可访问性和一致性，从而缓解架构侵蚀问题，提高软件维护效率。

Abstract: Software architecture is inherently knowledge-centric. The architectural knowledge is distributed across heterogeneous software artifacts such as requirements documents, design diagrams, code, and documentation, making it difficult for developers to access and utilize this knowledge effectively. Moreover, as systems evolve, inconsistencies frequently emerge between these artifacts, leading to architectural erosion and impeding maintenance activities. We envision an automated pipeline that systematically extracts architectural knowledge from diverse artifacts, links them, identifies and resolves inconsistencies, and consolidates this knowledge into a structured knowledge base. This knowledge base enables critical activities such as architecture conformance checking and change impact analysis, while supporting natural language question-answering to improve access to architectural knowledge. To realize this vision, we plan to develop specialized extractors for different artifact types, design a unified knowledge representation schema, implement consistency checking mechanisms, and integrate retrieval-augmented generation techniques for conversational knowledge access.

</details>


### [27] [Toward Architecture-Aware Evaluation Metrics for LLM Agents](https://arxiv.org/abs/2601.19583)
*Débora Souza,Patrícia Machado*

Main category: cs.SE

TL;DR: 提出了一种轻量级的、基于架构的LLM智能体评估方法，将智能体组件与可观察行为及评估指标联系起来，实现更有针对性、透明和可操作的评估。


<details>
  <summary>Details</summary>
Motivation: 当前LLM智能体评估存在碎片化问题，主要以模型为中心，忽视了架构组件（如规划器、记忆、工具路由器）对智能体行为的影响，导致诊断能力有限。

Method: 提出轻量级的架构感知方法，将智能体组件与其可观察行为以及能够评估这些行为的指标联系起来，明确测量内容和原因。

Result: 通过实际智能体应用展示了该方法，能够实现更有针对性、透明和可操作的LLM智能体评估。

Conclusion: 基于架构的评估方法能够更好地理解智能体组件如何影响行为，为LLM智能体评估提供了更系统、诊断能力更强的框架。

Abstract: LLM-based agents are becoming central to software engineering tasks, yet evaluating them remains fragmented and largely model-centric. Existing studies overlook how architectural components, such as planners, memory, and tool routers, shape agent behavior, limiting diagnostic power. We propose a lightweight, architecture-informed approach that links agent components to their observable behaviors and to the metrics capable of evaluating them. Our method clarifies what to measure and why, and we illustrate its application through real world agents, enabling more targeted, transparent, and actionable evaluation of LLM-based agents.

</details>


### [28] [The Competence Crisis: A Design Fiction on AI-Assisted Research in Software Engineering](https://arxiv.org/abs/2601.19628)
*Mairieli Wessel,Daniel Feitosa,Sangeeth Kochanthara*

Main category: cs.SE

TL;DR: 使用设计虚构方法探讨AI工具普及对软件工程研究能力退化、责任分配和学术信任的潜在影响


<details>
  <summary>Details</summary>
Motivation: 随着出版压力和生成式AI工具的普及，软件工程研究面临技能退化、责任归属和学术信任等挑战，需要前瞻性思考这些问题的潜在影响

Method: 采用设计虚构作为方法论框架，基于社区调查构建近未来研究场景的推测性虚构作品，将其作为分析工具而非预测手段

Result: 通过构建令人不安的未来场景，揭示了自动化辅助可能如何阻碍领域知识能力、验证机制和指导实践的发展

Conclusion: 论文旨在引发软件工程研究社区关于未来如何定义专业能力、分配责任和支持学习的讨论，而非提供具体解决方案

Abstract: Rising publication pressure and the routine use of generative AI tools are reshaping how software engineering research is produced, assessed, and taught. While these developments promise efficiency, they also raise concerns about skill degradation, responsibility, and trust in scholarly outputs. This vision paper employs Design Fiction as a methodological lens to examine how such concerns might materialise if current practices persist. Drawing on themes reported in a recent community survey, we construct a speculative artifact situated in a near future research setting. The fiction is used as an analytical device rather than a forecast, enabling reflection on how automated assistance might impede domain knowledge competence, verification, and mentoring practices. By presenting an intentionally unsettling scenario, the paper invites discussion on how the software engineering research community in the future will define proficiency, allocate responsibility, and support learning.

</details>


### [29] [Who Said CVE? How Vulnerability Identifiers Are Mentioned by Humans, Bots, and Agents in Pull Requests](https://arxiv.org/abs/2601.19636)
*Pien Rooijendijk,Christoph Treude,Mairieli Wessel*

Main category: cs.SE

TL;DR: 该研究分析了GitHub拉取请求中漏洞标识符（CVE、CWE、GHSA）的使用情况，比较了自主代理、机器人和人类开发者的使用模式。研究发现机器人贡献了69.1%的提及，主要在PR描述中添加少量标识符，而人类和代理使用更少但分布更广。


<details>
  <summary>Details</summary>
Motivation: 尽管CVE、CWE、GHSA等漏洞标识符是标准化的软件安全参考，但它们在实践中的使用情况尚不清楚。本研究旨在了解这些标识符在GitHub开发工作流中如何被不同参与者（自主代理、机器人、人类开发者）使用。

Method: 使用AIDev pop数据集和同一仓库的增强拉取请求集，分析谁提及漏洞标识符以及它们出现在何处。进行定量分析统计不同参与者的提及频率和位置分布，并进行定性分析理解使用场景。

Result: 机器人贡献了约69.1%的漏洞标识符提及，通常在拉取请求描述中添加少量标识符。人类和自主代理的提及较少但分布更广泛。定性分析显示机器人主要在自动依赖更新和安全审计中引用标识符，而人类和代理则用于支持修复、维护和讨论。

Conclusion: 漏洞标识符在GitHub开发工作流中的使用存在显著差异：机器人主导了标识符的提及，主要用于自动化任务；而人类和自主代理的使用虽然较少，但覆盖更多场景，包括修复、维护和讨论。这揭示了不同参与者如何利用标准化安全参考来支持软件开发实践。

Abstract: Vulnerability identifiers such as CVE, CWE, and GHSA are standardised references to known software security issues, yet their use in practice is not well understood. This paper compares vulnerability ID use in GitHub pull requests authored by autonomous agents, bots, and human developers. Using the AIDev pop dataset and an augmented set of pull requests from the same repositories, we analyse who mentions vulnerability identifiers and where they appear. Bots account for around 69.1% of all mentions, usually adding few identifiers in pull request descriptions, while human and agent mentions are rarer but span more locations. Qualitative analysis shows that bots mainly reference identifiers in automated dependency updates and audits, whereas humans and agents use them to support fixes, maintenance, and discussion.

</details>


### [30] [Using LLMs to Evaluate Architecture Documents: Results from a Digital Marketplace Environment](https://arxiv.org/abs/2601.19693)
*Frank Elberzhager,Matthias Gerbershagen,Joshua Ginkel*

Main category: cs.SE

TL;DR: 研究探讨LLM在软件架构文档评估中的应用，发现文档质量越高，LLM评估与人类专家评估的一致性越高，但存在不一致性需要进一步分析。


<details>
  <summary>Details</summary>
Motivation: 生成式AI在软件工程活动中作用日益增强，但LLM的实际效益尚不明确。本研究聚焦软件架构师，探索LLM支持的架构文档评估如何帮助改进这些工件。

Method: 在开发数字市场平台的研究项目中，使用不同LLM分析架构文档质量，并将结果与软件架构师的评估进行比较。

Result: 发现工件质量对LLM评估质量有显著影响：架构文档质量越高，LLM评估与人类专家评估的一致性越高。虽然LLM在架构任务中表现有前景，但结果显示出需要进一步分析的不一致性。

Conclusion: LLM在软件架构文档评估中具有应用潜力，但评估结果存在不一致性，需要进一步分析才能推广使用。文档质量是影响LLM评估可靠性的关键因素。

Abstract: Generative AI plays an increasing role during software engineering activities to make them, e.g., more efficient or provide better quality. However, it is often unclear how much benefit LLMs really provide. We concentrate on software architects and investigated how an LLM-supported evaluation of architecture documents can support software architects to improve such artefacts. In the context of a research project where a digital marketplace is developed and digital solutions should be analyzed, we used different LLMs to analyze the quality of architecture documents and compared the results with evaluations from software architects. We found out that the quality of the artifact has a strong influence on the quality of the LLM, i.e., the better the quality of the architecture document was, the more consistent were the LLM-based evaluation and the human expert evaluation. While using LLMs in this architecture task is promising, our results showed inconsistencies that need further analyses before generalizing them.

</details>


### [31] [AlignCoder: Aligning Retrieval with Target Intent for Repository-Level Code Completion](https://arxiv.org/abs/2601.19697)
*Tianyue Jiang,Yanli Wang,Yanlin Wang,Daya Guo,Ensheng Shi,Yuchi Ma,Jiachi Chen,Zibin Zheng*

Main category: cs.SE

TL;DR: AlignCoder是一个仓库级代码补全框架，通过查询增强机制和基于强化学习的检索器训练方法，解决了现有检索增强生成方法在仓库级代码补全中的查询-目标代码不对齐和无法有效利用推理信息的问题。


<details>
  <summary>Details</summary>
Motivation: 现有代码大语言模型在仓库级代码补全任务中表现不佳，主要因为对仓库特定上下文和领域知识的理解有限。检索增强生成方法虽然通过检索相关代码片段作为跨文件上下文有所改进，但仍存在两个根本问题：检索过程中查询与目标代码不对齐，以及现有检索方法无法有效利用推理信息。

Method: 提出AlignCoder框架，包含两个核心组件：1）查询增强机制，通过生成多个候选补全来构建增强查询，弥合初始查询与目标代码之间的语义鸿沟；2）基于强化学习的检索器训练方法，训练AlignRetriever学习利用增强查询中的推理信息进行更准确的检索。

Result: 在两个广泛使用的基准测试（CrossCodeEval和RepoEval）上评估AlignCoder，使用五个骨干代码LLM。在CrossCodeEval基准上，与基线相比EM分数提高了18.1%。结果表明该框架实现了优越的性能，并在各种代码LLM和编程语言上表现出高泛化能力。

Conclusion: AlignCoder通过创新的查询增强和强化学习检索器训练方法，有效解决了仓库级代码补全中的关键挑战，显著提升了代码补全性能，并具有良好的通用性和可扩展性。

Abstract: Repository-level code completion remains a challenging task for existing code large language models (code LLMs) due to their limited understanding of repository-specific context and domain knowledge. While retrieval-augmented generation (RAG) approaches have shown promise by retrieving relevant code snippets as cross-file context, they suffer from two fundamental problems: misalignment between the query and the target code in the retrieval process, and the inability of existing retrieval methods to effectively utilize the inference information. To address these challenges, we propose AlignCoder, a repository-level code completion framework that introduces a query enhancement mechanism and a reinforcement learning based retriever training method. Our approach generates multiple candidate completions to construct an enhanced query that bridges the semantic gap between the initial query and the target code. Additionally, we employ reinforcement learning to train an AlignRetriever that learns to leverage inference information in the enhanced query for more accurate retrieval. We evaluate AlignCoder on two widely-used benchmarks (CrossCodeEval and RepoEval) across five backbone code LLMs, demonstrating an 18.1% improvement in EM score compared to baselines on the CrossCodeEval benchmark. The results show that our framework achieves superior performance and exhibits high generalizability across various code LLMs and programming languages.

</details>


### [32] [Future of Software Engineering Research: The SIGSOFT Perspective](https://arxiv.org/abs/2601.19731)
*Massimiliano Di Penta,Kelly Blincoe,Marsha Chechik,Claire Le Goues,David Lo,Emerson Murphy-Hill,Thomas Zimmermann*

Main category: cs.SE

TL;DR: 软件工程会议规模扩大导致成本上升和形式过时，阻碍了研究人员参与，威胁社区包容性和多样性。作者基于调查数据提出SIGSOFT应采取具体措施改善会议可及性。


<details>
  <summary>Details</summary>
Motivation: 软件工程会议规模不断扩大，导致参会成本上升和会议形式过时，这为许多研究人员设置了参与障碍。这些障碍威胁到软件工程社区的包容性和全球多样性，而这些特性正是该社区成功的重要因素。

Method: 基于调查数据进行分析，识别具体问题并提出解决方案。研究关注ACM软件工程特别兴趣小组(SIGSOFT)可以采取的行动。

Result: 识别出SIGSOFT可以采取的具体措施：提高会议资金透明度、尝试混合式海报展示、扩大对代表性不足地区的推广。

Conclusion: 通过实施这些改变，SIGSOFT可以帮助确保软件工程社区保持可访问性和欢迎度，维护社区的包容性和全球多样性。

Abstract: As software engineering conferences grow in size, rising costs and outdated formats are creating barriers to participation for many researchers. These barriers threaten the inclusivity and global diversity that have contributed to the success of the SE community. Based on survey data, we identify concrete actions the ACM Special Interest Group on Software Engineering (SIGSOFT) can take to address these challenges, including improving transparency around conference funding, experimenting with hybrid poster presentations, and expanding outreach to underrepresented regions. By implementing these changes, SIGSOFT can help ensure the software engineering community remains accessible and welcoming.

</details>


### [33] [Assessing Task-based Chatbots: Snapshot and Curated Datasets for Dialogflow](https://arxiv.org/abs/2601.19787)
*Elena Masserini,Diego Clerissi,Daniela Micucci,Leonardo Mariani*

Main category: cs.SE

TL;DR: 论文提出了TOFU-D和COD两个聊天机器人数据集，包含1788个和185个验证过的聊天机器人，用于聊天机器人质量和安全性的实证研究，初步评估发现了测试覆盖不足和安全漏洞问题。


<details>
  <summary>Details</summary>
Motivation: 聊天机器人虽然广泛应用，但缺乏大规模高质量数据集限制了对其质量和可靠性的研究。现有研究受限于数据不足，难以进行系统性的实证分析。

Method: 1. 从GitHub收集1788个Dialogflow聊天机器人构建TOFU-D数据集；2. 从中筛选出185个经过验证的聊天机器人构建COD数据集；3. 使用Botium测试框架进行质量评估；4. 使用Bandit静态分析器进行安全漏洞检测。

Result: 1. 创建了两个涵盖多领域、多语言、多种实现模式的聊天机器人数据集；2. 初步评估发现聊天机器人存在测试覆盖不足的问题；3. 多个聊天机器人存在常见的安全漏洞；4. 数据集为聊天机器人质量和安全性研究提供了可靠基础。

Conclusion: 聊天机器人质量和安全性研究需要系统性的多平台方法，当前数据集为相关实证研究提供了基础，但需要更多关注测试覆盖和安全漏洞问题。

Abstract: In recent years, chatbots have gained widespread adoption thanks to their ability to assist users at any time and across diverse domains. However, the lack of large-scale curated datasets limits research on their quality and reliability. This paper presents TOFU-D, a snapshot of 1,788 Dialogflow chatbots from GitHub, and COD, a curated subset of TOFU-D including 185 validated chatbots. The two datasets capture a wide range of domains, languages, and implementation patterns, offering a sound basis for empirical studies on chatbot quality and security. A preliminary assessment using the Botium testing framework and the Bandit static analyzer revealed gaps in test coverage and frequent security vulnerabilities in several chatbots, highlighting the need for systematic, multi-Platform research on chatbot quality and security.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [34] [Trustworthy Scheduling for Big Data Applications](https://arxiv.org/abs/2601.18983)
*Dimitrios Tomaras,Vana Kalogeraki,Dimitrios Gunopulos*

Main category: cs.DC

TL;DR: X-Sched是一个使用可解释性技术为容器化环境生成资源配置指导的中间件，通过反事实解释和机器学习模型帮助用户在资源时间约束下满足SLO目标。


<details>
  <summary>Details</summary>
Motivation: 现有调度器虽然优化性能指标，但决策过程不透明，无法为开发者提供满足SLO的具体行动指导。需要一种能提供可解释性指导的方案。

Method: 提出X-Sched中间件，集成反事实解释和随机森林等机器学习模型，识别最优资源配置，为用户提供清晰的调度决策依据。

Result: 实验使用真实执行环境数据验证，证明了该方法的效率、优势和实用性。

Conclusion: X-Sched填补了现有调度器缺乏透明度和可操作指导的空白，确保任务在资源时间约束下满足性能目标，并提供清晰的决策解释。

Abstract: Recent advances in modern containerized execution environments have resulted in substantial benefits in terms of elasticity and more efficient utilization of computing resources. Although existing schedulers strive to optimize performance metrics like task execution times and resource utilization, they provide limited transparency into their decision-making processes or the specific actions developers must take to meet Service Level Objectives (SLOs). In this work, we propose X-Sched, a middleware that uses explainability techniques to generate actionable guidance on resource configurations that makes task execution in containerized environments feasible, under resource and time constraints. X-Sched addresses this gap by integrating counterfactual explanations with advanced machine learning models, such as Random Forests, to efficiently identify optimal configurations. This approach not only ensures that tasks are executed in line with performance goals but also gives users clear, actionable insights into the rationale behind scheduling decisions. Our experimental results validated with data from real-world execution environments, illustrate the efficiency, benefits and practicality of our approach.

</details>


### [35] [Axe: A Simple Unified Layout Abstraction for Machine Learning Compilers](https://arxiv.org/abs/2601.19092)
*Bohan Hou,Hongyi Jin,Guanjie Wang,Jinqi Chen,Yaxing Cai,Lijie Yang,Zihao Ye,Yaoyao Ding,Ruihang Lai,Tianqi Chen*

Main category: cs.DC

TL;DR: Axe Layout：一个硬件感知的张量布局抽象，通过命名轴将逻辑张量坐标映射到多轴物理空间，统一了跨设备分布和设备内布局的平铺、分片、复制和偏移操作。


<details>
  <summary>Details</summary>
Motivation: 现代深度学习工作负载需要在设备网格、内存层次结构和异构加速器之间协调数据和计算的位置。现有方法在处理跨设备分布和设备内布局时缺乏统一的抽象，导致优化复杂且性能受限。

Method: 提出Axe Layout硬件感知抽象，通过命名轴将逻辑张量坐标映射到多轴物理空间。基于Axe设计了一个多粒度、分布感知的DSL和编译器，能够在单个内核中组合线程本地控制和集体操作。

Result: 实验表明，这种统一方法能够在最新的GPU设备、多设备环境和加速器后端上实现接近手工调优内核的性能。

Conclusion: Axe Layout提供了一个统一的抽象来处理跨设备分布和设备内布局，通过多粒度DSL和编译器实现了高性能的深度学习工作负载优化，接近手工调优的性能水平。

Abstract: Scaling modern deep learning workloads demands coordinated placement of data and compute across device meshes, memory hierarchies, and heterogeneous accelerators. We present Axe Layout, a hardware-aware abstraction that maps logical tensor coordinates to a multi-axis physical space via named axes. Axe unifies tiling, sharding, replication, and offsets across inter-device distribution and on-device layouts, enabling collective primitives to be expressed consistently from device meshes to threads. Building on Axe, we design a multi-granularity, distribution-aware DSL and compiler that composes thread-local control with collective operators in a single kernel. Experiments show that our unified approach can bring performance close to hand-tuned kernels on across latest GPU devices and multi-device environments and accelerator backends.

</details>


### [36] [KUBEDIRECT: Unleashing the Full Power of the Cluster Manager for Serverless Computing](https://arxiv.org/abs/2601.19160)
*Sheng Qi,Zhiquan Zhang,Xuanzhe Liu,Xin Jin*

Main category: cs.DC

TL;DR: KUBEDIRECT：基于Kubernetes的FaaS集群管理器，通过绕过API Server的直接消息传递提升效率，同时保持与现有生态兼容


<details>
  <summary>Details</summary>
Motivation: 现有Kubernetes在FaaS场景下，控制器通过API Server进行消息传递成为性能瓶颈。虽然已有全新设计的解决方案，但牺牲了与现有生态系统的兼容性且需要大量工程投入。

Method: 发现FaaS平台存在共同的"窄腰"结构，其顺序特性消除了对单一真实源的需求。通过绕过API Server进行直接消息传递，并采用新颖的状态管理方案，将窄腰作为分层写回缓存来确保一致性和收敛到期望状态。

Result: KUBEDIRECT仅需为每个控制器增加约150行代码即可与Kubernetes无缝集成。实验显示，相比Knative减少26.7倍的延迟，性能与最先进的clean-slate平台Dirigent相当。

Conclusion: KUBEDIRECT在保持与Kubernetes生态系统兼容的同时，通过创新的状态管理方案实现了高效的FaaS资源管理，平衡了效率与兼容性。

Abstract: FaaS platforms rely on cluster managers like Kubernetes for resource management. Kubernetes is popular due to its state-centric APIs that decouple the control plane into modular controllers. However, to scale out a burst of FaaS instances, message passing becomes the primary bottleneck as controllers have to exchange extensive state through the API Server. Existing solutions opt for a clean-slate redesign of cluster managers, but at the expense of compatibility with existing ecosystem and substantial engineering effort.
  We present KUBEDIRECT, a Kubernetes-based cluster manager for FaaS. We find that there exists a common narrow waist across FaaS platform that allows us to achieve both efficiency and external compatibility. Our insight is that the sequential structure of the narrow waist obviates the need for a single source of truth, allowing us to bypass the API Server and perform direct message passing for efficiency. However, our approach introduces a set of ephemeral states across controllers, making it challenging to enforce end-to-end semantics due to the absence of centralized coordination. KUBEDIRECT employs a novel state management scheme that leverages the narrow waist as a hierarchical write-back cache, ensuring consistency and convergence to the desired state. KUBEDIRECT can seamlessly integrate with Kubernetes, adding ~150 LoC per controller. Experiments show that KUBEDIRECT reduces serving latency by 26.7x over Knative, and has similar performance as the state-of-the-art clean-slate platform Dirigent.

</details>


### [37] [Revisiting Parameter Server in LLM Post-Training](https://arxiv.org/abs/2601.19362)
*Xinyi Wan,Penghui Qi,Guangxing Huang,Chaoyi Ruan,Min Lin,Jialin Li*

Main category: cs.DC

TL;DR: ODC通过将FSDP中的集体通信替换为点对点通信，解决了LLM后训练中序列长度差异导致的负载不均衡问题，实现了最高36%的加速。


<details>
  <summary>Details</summary>
Motivation: 传统数据并行训练中的集体通信（如all-gather和reduce-scatter）在负载均衡时效率高，但在LLM后训练中，由于序列长度差异大，负载不均衡导致设备利用率下降，需要重新审视参数服务器范式。

Method: 提出按需通信（ODC），将FSDP中的集体通信替换为直接的点对点通信，将同步屏障从每层一次减少为每小批次一次，解耦设备间的工作负载，使快速工作者不被阻塞。

Result: 在多种LLM后训练任务中，ODC持续提高了设备利用率和训练吞吐量，相比标准FSDP实现了最高36%的加速。

Conclusion: ODC是LLM后训练中普遍存在的负载不均衡问题的优越解决方案，其实现已开源。

Abstract: Modern data parallel (DP) training favors collective communication over parameter servers (PS) for its simplicity and efficiency under balanced workloads. However, the balanced workload assumption no longer holds in large language model (LLM) post-training due to the high variance in sequence lengths. Under imbalanced workloads, collective communication creates synchronization barriers, leading to under-utilization of devices with smaller workloads. This change in training dynamics calls for a revisit of the PS paradigm for its robustness to such imbalance. We propose \textbf{On-Demand Communication (ODC)}, which adapts PS into Fully Sharded Data Parallel (FSDP) by replacing collective all-gather and reduce-scatter with direct point-to-point communication. Compared to FSDP, ODC reduces the synchronization barrier from once per layer to once per minibatch and decouples the workload on each device so that faster workers are not stalled. It also enables simpler and more effective load balancing at the minibatch level. Across diverse LLM post-training tasks, ODC consistently improves device utilization and training throughput, achieving up to a 36\% speedup over standard FSDP. These results demonstrate that ODC is a superior fit for the prevalent imbalanced workloads in LLM post-training. Our implementation of ODC and integration with FSDP is open-sourced at https://github.com/sail-sg/odc.

</details>


### [38] [Modular Foundation Model Inference at the Edge: Network-Aware Microservice Optimization](https://arxiv.org/abs/2601.19563)
*Juan Zhu,Zixin Wang,Shenghui Song,Jun Zhang,Khaled Ben Letaief*

Main category: cs.DC

TL;DR: 提出基于微服务的基础模型推理框架，采用核心服务静态部署与轻量服务动态编排的两层策略，在边缘资源受限环境下实现高QoS保障


<details>
  <summary>Details</summary>
Motivation: 云端部署基础模型存在实时性差和隐私问题，而边缘端单机执行在资源限制和网络动态下不可行，需要新的部署框架

Method: 利用核心服务（重量级）与轻量服务（敏捷）的功能不对称性，核心服务通过网络感知整数规划静态部署形成容错骨干，轻量服务通过结合有效容量理论和Lyapunov优化的在线控制器动态编排

Result: 模拟显示框架实现超过84%的平均准时任务完成率，部署成本适中，在系统负载扩展时保持强鲁棒性

Conclusion: 提出的微服务框架成功解决了边缘环境下基础模型部署的挑战，平衡了资源限制与服务质量需求

Abstract: Foundation models (FMs) unlock unprecedented multimodal and multitask intelligence, yet their cloud-centric deployment precludes real-time responsiveness and compromises user privacy. Meanwhile, monolithic execution at the edge remains infeasible under stringent resource limits and uncertain network dynamics. To bridge this gap, we propose a microservice-based FM inference framework that exploits the intrinsic functional asymmetry between heavyweight core services and agile light services. Our two-tier deployment strategy ensures robust Quality of Service (QoS) under resource contention. Specifically, core services are placed statically via a long-term network-aware integer program with sparsity constraints to form a fault-tolerant backbone. On the other hand, light services are orchestrated dynamically by a low-complexity online controller that integrates effective capacity theory with Lyapunov optimization, providing probabilistic latency guarantees under real-time workload fluctuations. Simulations demonstrate that our framework achieves over 84% average on-time task completion with moderate deployment costs and maintains strong robustness as the system load scales.

</details>
