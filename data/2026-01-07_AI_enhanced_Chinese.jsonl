{"id": "2601.02824", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2601.02824", "abs": "https://arxiv.org/abs/2601.02824", "authors": ["John R. Talburt", "Muzakkiruddin Ahmed Mohammed", "Mert Can Cakmak", "Onais Khan Mohammed", "Mahboob Khan Mohammed", "Khizer Syed", "Leon Claasssens"], "title": "Case Count Metric for Comparative Analysis of Entity Resolution Results", "comment": null, "summary": "This paper describes a new process and software system, the Case Count Metric System (CCMS), for systematically comparing and analyzing the outcomes of two different ER clustering processes acting on the same dataset when the true linking (labeling) is not known. The CCMS produces a set of counts that describe how the clusters produced by the first process are transformed by the second process based on four possible transformation scenarios. The transformations are that a cluster formed in the first process either remains unchanged, merges into a larger cluster, is partitioned into smaller clusters, or otherwise overlaps with multiple clusters formed in the second process. The CCMS produces a count for each of these cases, accounting for every cluster formed in the first process. In addition, when run in analysis mode, the CCMS program can assist the user in evaluating these changes by displaying the details for all changes or only for certain types of changes. The paper includes a detailed description of the CCMS process and program and examples of how the CCMS has been applied in university and industry research.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u540d\u4e3aCCMS\u7684\u7cfb\u7edf\uff0c\u7528\u4e8e\u5728\u771f\u5b9e\u94fe\u63a5\u672a\u77e5\u7684\u60c5\u51b5\u4e0b\uff0c\u7cfb\u7edf\u6bd4\u8f83\u548c\u5206\u6790\u4e24\u4e2a\u4e0d\u540cER\u805a\u7c7b\u8fc7\u7a0b\u5bf9\u540c\u4e00\u6570\u636e\u96c6\u7684\u7ed3\u679c\uff0c\u901a\u8fc7\u56db\u79cd\u8f6c\u6362\u573a\u666f\u7edf\u8ba1\u805a\u7c7b\u53d8\u5316\u60c5\u51b5\u3002", "motivation": "\u5728\u771f\u5b9e\u94fe\u63a5\u4fe1\u606f\u672a\u77e5\u7684\u60c5\u51b5\u4e0b\uff0c\u9700\u8981\u4e00\u79cd\u7cfb\u7edf\u65b9\u6cd5\u6765\u6bd4\u8f83\u548c\u8bc4\u4f30\u4e0d\u540c\u5b9e\u4f53\u89e3\u6790\uff08ER\uff09\u805a\u7c7b\u8fc7\u7a0b\u7684\u7ed3\u679c\u5dee\u5f02\uff0c\u4ee5\u7406\u89e3\u4e00\u4e2a\u805a\u7c7b\u8fc7\u7a0b\u5982\u4f55\u6539\u53d8\u53e6\u4e00\u4e2a\u805a\u7c7b\u8fc7\u7a0b\u7684\u8f93\u51fa\u3002", "method": "\u5f00\u53d1\u4e86\u6848\u4f8b\u8ba1\u6570\u5ea6\u91cf\u7cfb\u7edf\uff08CCMS\uff09\uff0c\u8be5\u7cfb\u7edf\u57fa\u4e8e\u56db\u79cd\u8f6c\u6362\u573a\u666f\uff08\u4fdd\u6301\u4e0d\u53d8\u3001\u5408\u5e76\u3001\u5206\u5272\u3001\u91cd\u53e0\uff09\u7edf\u8ba1\u7b2c\u4e00\u4e2a\u8fc7\u7a0b\u4ea7\u751f\u7684\u805a\u7c7b\u5728\u7b2c\u4e8c\u4e2a\u8fc7\u7a0b\u4e2d\u7684\u53d8\u5316\u60c5\u51b5\uff0c\u5e76\u63d0\u4f9b\u5206\u6790\u6a21\u5f0f\u6765\u8be6\u7ec6\u68c0\u67e5\u8fd9\u4e9b\u53d8\u5316\u3002", "result": "CCMS\u80fd\u591f\u7cfb\u7edf\u6027\u5730\u91cf\u5316\u548c\u5206\u6790\u4e24\u4e2aER\u805a\u7c7b\u8fc7\u7a0b\u4e4b\u95f4\u7684\u5dee\u5f02\uff0c\u63d0\u4f9b\u8be6\u7ec6\u7684\u8f6c\u6362\u7edf\u8ba1\uff0c\u5e76\u5728\u5927\u5b66\u548c\u5de5\u4e1a\u7814\u7a76\u4e2d\u5f97\u5230\u6210\u529f\u5e94\u7528\u3002", "conclusion": "CCMS\u4e3a\u5728\u771f\u5b9e\u94fe\u63a5\u672a\u77e5\u7684\u60c5\u51b5\u4e0b\u8bc4\u4f30ER\u805a\u7c7b\u8fc7\u7a0b\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u7cfb\u7edf\u65b9\u6cd5\uff0c\u80fd\u591f\u5e2e\u52a9\u7814\u7a76\u4eba\u5458\u7406\u89e3\u548c\u6bd4\u8f83\u4e0d\u540c\u805a\u7c7b\u7b97\u6cd5\u7684\u6027\u80fd\u5dee\u5f02\u3002"}}
{"id": "2601.03137", "categories": ["cs.DB", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.03137", "abs": "https://arxiv.org/abs/2601.03137", "authors": ["Yangfan Jiang", "Fei Wei", "Ergute Bao", "Yaliang Li", "Bolin Ding", "Yin Yang", "Xiaokui Xiao"], "title": "Accurate Table Question Answering with Accessible LLMs", "comment": "accepted for publication in the Proceedings of the IEEE International Conference on Data Engineering (ICDE) 2026", "summary": "Given a table T in a database and a question Q in natural language, the table question answering (TQA) task aims to return an accurate answer to Q based on the content of T. Recent state-of-the-art solutions leverage large language models (LLMs) to obtain high-quality answers. However, most rely on proprietary, large-scale LLMs with costly API access, posing a significant financial barrier. This paper instead focuses on TQA with smaller, open-weight LLMs that can run on a desktop or laptop. This setting is challenging, as such LLMs typically have weaker capabilities than large proprietary models, leading to substantial performance degradation with existing methods.\n  We observe that a key reason for this degradation is that prior approaches often require the LLM to solve a highly sophisticated task using long, complex prompts, which exceed the capabilities of small open-weight LLMs. Motivated by this observation, we present Orchestra, a multi-agent approach that unlocks the potential of accessible LLMs for high-quality, cost-effective TQA. Orchestra coordinates a group of LLM agents, each responsible for a relatively simple task, through a structured, layered workflow to solve complex TQA problems -- akin to an orchestra. By reducing the prompt complexity faced by each agent, Orchestra significantly improves output reliability.\n  We implement Orchestra on top of AgentScope, an open-source multi-agent framework, and evaluate it on multiple TQA benchmarks using a wide range of open-weight LLMs. Experimental results show that Orchestra achieves strong performance even with small- to medium-sized models. For example, with Qwen2.5-14B, Orchestra reaches 72.1% accuracy on WikiTQ, approaching the best prior result of 75.3% achieved with GPT-4; with larger Qwen, Llama, or DeepSeek models, Orchestra outperforms all prior methods and establishes new state-of-the-art results across all benchmarks.", "AI": {"tldr": "Orchestra\uff1a\u4e00\u79cd\u591a\u667a\u80fd\u4f53\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u590d\u6742\u8868\u683c\u95ee\u7b54\u4efb\u52a1\u5206\u89e3\u4e3a\u591a\u4e2a\u7b80\u5355\u5b50\u4efb\u52a1\uff0c\u8ba9\u5c0f\u578b\u5f00\u6e90LLM\u4e5f\u80fd\u5b9e\u73b0\u9ad8\u8d28\u91cf\u7684\u8868\u683c\u95ee\u7b54\uff0c\u663e\u8457\u964d\u4f4e\u6210\u672c\u3002", "motivation": "\u73b0\u6709\u8868\u683c\u95ee\u7b54\u7cfb\u7edf\u4f9d\u8d56\u5927\u578b\u5546\u4e1aLLM\uff0cAPI\u8bbf\u95ee\u6210\u672c\u9ad8\u6602\u3002\u5c0f\u578b\u5f00\u6e90LLM\u867d\u7136\u6210\u672c\u4f4e\uff0c\u4f46\u80fd\u529b\u8f83\u5f31\uff0c\u65e0\u6cd5\u5904\u7406\u73b0\u6709\u65b9\u6cd5\u4e2d\u590d\u6742\u7684\u63d0\u793a\u5de5\u7a0b\uff0c\u5bfc\u81f4\u6027\u80fd\u663e\u8457\u4e0b\u964d\u3002", "method": "\u63d0\u51faOrchestra\u591a\u667a\u80fd\u4f53\u65b9\u6cd5\uff0c\u534f\u8c03\u591a\u4e2aLLM\u667a\u80fd\u4f53\uff0c\u6bcf\u4e2a\u667a\u80fd\u4f53\u8d1f\u8d23\u76f8\u5bf9\u7b80\u5355\u7684\u5b50\u4efb\u52a1\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u5206\u5c42\u5de5\u4f5c\u6d41\u7a0b\u89e3\u51b3\u590d\u6742\u8868\u683c\u95ee\u7b54\u95ee\u9898\uff0c\u964d\u4f4e\u6bcf\u4e2a\u667a\u80fd\u4f53\u9762\u4e34\u7684\u63d0\u793a\u590d\u6742\u5ea6\u3002", "result": "\u5728\u591a\u4e2aTQA\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cOrchestra\u5373\u4f7f\u4f7f\u7528\u4e2d\u5c0f\u578b\u6a21\u578b\u4e5f\u80fd\u53d6\u5f97\u5f3a\u52b2\u6027\u80fd\u3002\u4f8b\u5982\uff0c\u4f7f\u7528Qwen2.5-14B\u5728WikiTQ\u4e0a\u8fbe\u523072.1%\u51c6\u786e\u7387\uff0c\u63a5\u8fd1GPT-4\u768475.3%\uff1b\u4f7f\u7528\u66f4\u5927\u7684Qwen\u3001Llama\u6216DeepSeek\u6a21\u578b\u65f6\uff0c\u5728\u6240\u6709\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u90fd\u8d85\u8d8a\u4e86\u73b0\u6709\u65b9\u6cd5\uff0c\u521b\u9020\u4e86\u65b0\u7684SOTA\u7ed3\u679c\u3002", "conclusion": "Orchestra\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u65b9\u6cd5\uff0c\u6709\u6548\u89e3\u9501\u4e86\u5c0f\u578b\u5f00\u6e90LLM\u5728\u8868\u683c\u95ee\u7b54\u4efb\u52a1\u4e2d\u7684\u6f5c\u529b\uff0c\u5b9e\u73b0\u4e86\u9ad8\u8d28\u91cf\u3001\u4f4e\u6210\u672c\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u4e3a\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e0b\u7684\u8868\u683c\u95ee\u7b54\u63d0\u4f9b\u4e86\u53ef\u884c\u8def\u5f84\u3002"}}
{"id": "2601.03229", "categories": ["cs.DB", "cs.AR"], "pdf": "https://arxiv.org/pdf/2601.03229", "abs": "https://arxiv.org/abs/2601.03229", "authors": ["Tianqi Zhang", "Flavio Ponzina", "Tajana Rosing"], "title": "SpANNS: Optimizing Approximate Nearest Neighbor Search for Sparse Vectors Using Near Memory Processing", "comment": null, "summary": "Approximate Nearest Neighbor Search (ANNS) is a fundamental operation in vector databases, enabling efficient similarity search in high-dimensional spaces. While dense ANNS has been optimized using specialized hardware accelerators, sparse ANNS remains limited by CPU-based implementations, hindering scalability. This limitation is increasingly critical as hybrid retrieval systems, combining sparse and dense embeddings, become standard in Information Retrieval (IR) pipelines. We propose SpANNS, a near-memory processing architecture for sparse ANNS. SpANNS combines a hybrid inverted index with efficient query management and runtime optimizations. The architecture is built on a CXL Type-2 near-memory platform, where a specialized controller manages query parsing and cluster filtering, while compute-enabled DIMMs perform index traversal and distance computations close to the data. It achieves 15.2x to 21.6x faster execution over the state-of-the-art CPU baselines, offering scalable and efficient solutions for sparse vector search.", "AI": {"tldr": "SpANNS\u662f\u4e00\u4e2a\u57fa\u4e8eCXL Type-2\u8fd1\u5185\u5b58\u5904\u7406\u67b6\u6784\u7684\u7a00\u758f\u8fd1\u4f3c\u6700\u8fd1\u90bb\u641c\u7d22\u7cfb\u7edf\uff0c\u901a\u8fc7\u6df7\u5408\u5012\u6392\u7d22\u5f15\u548c\u67e5\u8be2\u7ba1\u7406\u4f18\u5316\uff0c\u76f8\u6bd4CPU\u57fa\u7ebf\u5b9e\u73b015.2-21.6\u500d\u7684\u52a0\u901f\u3002", "motivation": "\u7a00\u758fANNS\u76ee\u524d\u53d7\u9650\u4e8eCPU\u5b9e\u73b0\uff0c\u800c\u6df7\u5408\u68c0\u7d22\u7cfb\u7edf\uff08\u7a00\u758f+\u7a20\u5bc6\u5d4c\u5165\uff09\u5df2\u6210\u4e3a\u4fe1\u606f\u68c0\u7d22\u6807\u51c6\u6d41\u7a0b\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u7a00\u758f\u5411\u91cf\u641c\u7d22\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51faSpANNS\u8fd1\u5185\u5b58\u5904\u7406\u67b6\u6784\uff0c\u91c7\u7528CXL Type-2\u5e73\u53f0\uff0c\u7ed3\u5408\u6df7\u5408\u5012\u6392\u7d22\u5f15\u3001\u9ad8\u6548\u67e5\u8be2\u7ba1\u7406\u548c\u8fd0\u884c\u65f6\u4f18\u5316\u3002\u4e13\u7528\u63a7\u5236\u5668\u5904\u7406\u67e5\u8be2\u89e3\u6790\u548c\u805a\u7c7b\u8fc7\u6ee4\uff0c\u8ba1\u7b97\u589e\u5f3aDIMM\u5728\u6570\u636e\u9644\u8fd1\u6267\u884c\u7d22\u5f15\u904d\u5386\u548c\u8ddd\u79bb\u8ba1\u7b97\u3002", "result": "\u76f8\u6bd4\u6700\u5148\u8fdb\u7684CPU\u57fa\u7ebf\uff0cSpANNS\u5b9e\u73b0\u4e8615.2\u500d\u523021.6\u500d\u7684\u6267\u884c\u901f\u5ea6\u63d0\u5347\uff0c\u4e3a\u7a00\u758f\u5411\u91cf\u641c\u7d22\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "SpANNS\u901a\u8fc7\u8fd1\u5185\u5b58\u5904\u7406\u67b6\u6784\u6709\u6548\u89e3\u51b3\u4e86\u7a00\u758fANNS\u7684\u6027\u80fd\u74f6\u9888\uff0c\u4e3a\u6df7\u5408\u68c0\u7d22\u7cfb\u7edf\u4e2d\u7684\u7a00\u758f\u5411\u91cf\u641c\u7d22\u63d0\u4f9b\u4e86\u786c\u4ef6\u52a0\u901f\u65b9\u6848\uff0c\u663e\u8457\u63d0\u5347\u4e86\u641c\u7d22\u6548\u7387\u3002"}}
{"id": "2601.02898", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2601.02898", "abs": "https://arxiv.org/abs/2601.02898", "authors": ["Wim Vanderbauwhede", "Lauritz Thamsen", "Jos\u00e9 Cano"], "title": "Proceedings of the 1st International Workshop on Low Carbon Computing (LOCO 2024)", "comment": "arXiv overlay proceedings for LOCO 2024. Living index of papers submitted individually", "summary": "This is the proceedings of the 1st International Workshop on Low Carbon Computing (LOCO 2024).", "AI": {"tldr": "LOCO 2024\u662f\u7b2c\u4e00\u5c4a\u4f4e\u78b3\u8ba1\u7b97\u56fd\u9645\u7814\u8ba8\u4f1a\u8bba\u6587\u96c6", "motivation": "\u968f\u7740\u8ba1\u7b97\u6280\u672f\u80fd\u8017\u548c\u78b3\u6392\u653e\u95ee\u9898\u65e5\u76ca\u7a81\u51fa\uff0c\u9700\u8981\u4e13\u95e8\u8ba8\u8bba\u4f4e\u78b3\u8ba1\u7b97\u7684\u7814\u7a76\u5e73\u53f0", "method": "\u901a\u8fc7\u56fd\u9645\u7814\u8ba8\u4f1a\u5f62\u5f0f\u6c47\u96c6\u76f8\u5173\u7814\u7a76\uff0c\u5305\u62ec\u8bba\u6587\u5f81\u96c6\u3001\u540c\u884c\u8bc4\u5ba1\u548c\u4f1a\u8bae\u4ea4\u6d41", "result": "\u6210\u529f\u4e3e\u529e\u4e86\u7b2c\u4e00\u5c4a\u4f4e\u78b3\u8ba1\u7b97\u56fd\u9645\u7814\u8ba8\u4f1a\u5e76\u51fa\u7248\u4e86\u8bba\u6587\u96c6", "conclusion": "LOCO 2024\u4e3a\u4f4e\u78b3\u8ba1\u7b97\u9886\u57df\u5efa\u7acb\u4e86\u91cd\u8981\u7684\u5b66\u672f\u4ea4\u6d41\u5e73\u53f0\uff0c\u63a8\u52a8\u4e86\u8be5\u9886\u57df\u7684\u7814\u7a76\u53d1\u5c55"}}
{"id": "2601.02399", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.02399", "abs": "https://arxiv.org/abs/2601.02399", "authors": ["Jiaxin Ai", "Yukang Feng", "Fanrui Zhang", "Jianwen Sun", "Zizhen Li", "Chuanhao Li", "Yifan Chang", "Wenxiao Wu", "Ruoxi Wang", "Mingliang Zhai", "Kaipeng Zhang"], "title": "ProSoftArena: Benchmarking Hierarchical Capabilities of Multimodal Agents in Professional Software Environments", "comment": null, "summary": "Multimodal agents are making rapid progress on general computer-use tasks, yet existing benchmarks remain largely confined to browsers and basic desktop applications, falling short in professional software workflows that dominate real-world scientific and industrial practice. To close this gap, we introduce ProSoftArena, a benchmark and platform specifically for evaluating multimodal agents in professional software environments. We establish the first capability hierarchy tailored to agent use of professional software and construct a benchmark of 436 realistic work and research tasks spanning 6 disciplines and 13 core professional applications. To ensure reliable and reproducible assessment, we build an executable real-computer environment with an execution-based evaluation framework and uniquely incorporate a human-in-the-loop evaluation paradigm. Extensive experiments show that even the best-performing agent attains only a 24.4\\% success rate on L2 tasks and completely fails on L3 multi-software workflow. In-depth analysis further provides valuable insights for addressing current agent limitations and more effective design principles, paving the way to build more capable agents in professional software settings. This project is available at: https://prosoftarena.github.io.", "AI": {"tldr": "ProSoftArena\u662f\u4e00\u4e2a\u4e13\u95e8\u7528\u4e8e\u8bc4\u4f30\u4e13\u4e1a\u8f6f\u4ef6\u73af\u5883\u4e2d\u591a\u6a21\u6001\u667a\u80fd\u4f53\u7684\u57fa\u51c6\u6d4b\u8bd5\u5e73\u53f0\uff0c\u5305\u542b436\u4e2a\u8de86\u4e2a\u5b66\u79d1\u300113\u4e2a\u4e13\u4e1a\u5e94\u7528\u7684\u771f\u5b9e\u5de5\u4f5c\u4efb\u52a1\uff0c\u901a\u8fc7\u6267\u884c\u8bc4\u4f30\u548c\u4eba\u5de5\u53c2\u4e0e\u8303\u5f0f\u8fdb\u884c\u53ef\u9760\u6d4b\u8bd5\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u4e3b\u8981\u5c40\u9650\u4e8e\u6d4f\u89c8\u5668\u548c\u57fa\u7840\u684c\u9762\u5e94\u7528\uff0c\u65e0\u6cd5\u8986\u76d6\u771f\u5b9e\u4e16\u754c\u4e2d\u5360\u636e\u4e3b\u5bfc\u5730\u4f4d\u7684\u4e13\u4e1a\u8f6f\u4ef6\u5de5\u4f5c\u6d41\u7a0b\uff0c\u8fd9\u9650\u5236\u4e86\u591a\u6a21\u6001\u667a\u80fd\u4f53\u5728\u79d1\u5b66\u548c\u5de5\u4e1a\u5b9e\u8df5\u4e2d\u7684\u5e94\u7528\u8bc4\u4f30\u3002", "method": "1) \u5efa\u7acb\u9996\u4e2a\u9488\u5bf9\u4e13\u4e1a\u8f6f\u4ef6\u4f7f\u7528\u7684\u667a\u80fd\u4f53\u80fd\u529b\u5c42\u6b21\u7ed3\u6784\uff1b2) \u6784\u5efa\u5305\u542b436\u4e2a\u771f\u5b9e\u5de5\u4f5c\u4efb\u52a1\u7684\u57fa\u51c6\u6d4b\u8bd5\uff1b3) \u5f00\u53d1\u53ef\u6267\u884c\u7684\u771f\u5b9e\u8ba1\u7b97\u673a\u73af\u5883\u4e0e\u57fa\u4e8e\u6267\u884c\u7684\u8bc4\u4f30\u6846\u67b6\uff1b4) \u72ec\u7279\u5730\u6574\u5408\u4eba\u5de5\u53c2\u4e0e\u8bc4\u4f30\u8303\u5f0f\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0c\u5373\u4f7f\u5728L2\u7ea7\u522b\u4efb\u52a1\u4e0a\uff0c\u8868\u73b0\u6700\u4f73\u7684\u667a\u80fd\u4f53\u6210\u529f\u7387\u4e5f\u4ec5\u4e3a24.4%\uff0c\u5728L3\u591a\u8f6f\u4ef6\u5de5\u4f5c\u6d41\u7a0b\u4e0a\u5b8c\u5168\u5931\u8d25\u3002\u6df1\u5165\u5206\u6790\u4e3a\u5f53\u524d\u667a\u80fd\u4f53\u5c40\u9650\u6027\u548c\u66f4\u6709\u6548\u7684\u8bbe\u8ba1\u539f\u5219\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u89c1\u89e3\u3002", "conclusion": "ProSoftArena\u586b\u8865\u4e86\u4e13\u4e1a\u8f6f\u4ef6\u73af\u5883\u4e2d\u591a\u6a21\u6001\u667a\u80fd\u4f53\u8bc4\u4f30\u7684\u7a7a\u767d\uff0c\u4e3a\u6784\u5efa\u66f4\u5f3a\u5927\u7684\u4e13\u4e1a\u8f6f\u4ef6\u667a\u80fd\u4f53\u94fa\u5e73\u4e86\u9053\u8def\uff0c\u63ed\u793a\u4e86\u5f53\u524d\u667a\u80fd\u4f53\u5728\u590d\u6742\u4e13\u4e1a\u5de5\u4f5c\u6d41\u7a0b\u4e2d\u7684\u663e\u8457\u5c40\u9650\u6027\u3002"}}
{"id": "2601.03197", "categories": ["cs.DC", "cs.MA"], "pdf": "https://arxiv.org/pdf/2601.03197", "abs": "https://arxiv.org/abs/2601.03197", "authors": ["Saurabh Agarwal", "Marco Laju", "Jayanth Srinivasa", "Myungjin Lee", "Aditya Akella"], "title": "Software-Defined Agentic Serving", "comment": null, "summary": "As multi-agent LLM pipelines grow in complexity, existing serving paradigms fail to adapt to the dynamic serving conditions. We argue that agentic serving systems should be programmable and system-aware, unlike existing serving which statically encode the parameters. In this work, we propose a new SDN-inspired agentic serving framework that helps control the key attributes of communication based on runtime state. This architecture enables serving-efficient, responsive agent systems and paves the way for high-level intent-driven agentic serving.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eSDN\uff08\u8f6f\u4ef6\u5b9a\u4e49\u7f51\u7edc\uff09\u542f\u53d1\u7684\u53ef\u7f16\u7a0b\u3001\u7cfb\u7edf\u611f\u77e5\u7684\u667a\u80fd\u4f53\u670d\u52a1\u6846\u67b6\uff0c\u4ee5\u5e94\u5bf9\u590d\u6742\u591a\u667a\u80fd\u4f53LLM\u7ba1\u9053\u4e2d\u7684\u52a8\u6001\u670d\u52a1\u6761\u4ef6\u6311\u6218", "motivation": "\u968f\u7740\u591a\u667a\u80fd\u4f53LLM\u7ba1\u9053\u65e5\u76ca\u590d\u6742\uff0c\u73b0\u6709\u670d\u52a1\u8303\u5f0f\u65e0\u6cd5\u9002\u5e94\u52a8\u6001\u670d\u52a1\u6761\u4ef6\u3002\u73b0\u6709\u670d\u52a1\u7cfb\u7edf\u9759\u6001\u7f16\u7801\u53c2\u6570\uff0c\u7f3a\u4e4f\u5bf9\u8fd0\u884c\u65f6\u72b6\u6001\u7684\u9002\u5e94\u6027", "method": "\u63d0\u51faSDN\u542f\u53d1\u7684\u667a\u80fd\u4f53\u670d\u52a1\u6846\u67b6\uff0c\u901a\u8fc7\u53ef\u7f16\u7a0b\u65b9\u5f0f\u57fa\u4e8e\u8fd0\u884c\u65f6\u72b6\u6001\u63a7\u5236\u901a\u4fe1\u5173\u952e\u5c5e\u6027\uff0c\u5b9e\u73b0\u7cfb\u7edf\u611f\u77e5\u7684\u670d\u52a1\u67b6\u6784", "result": "\u8be5\u67b6\u6784\u80fd\u591f\u5b9e\u73b0\u670d\u52a1\u6548\u7387\u9ad8\u3001\u54cd\u5e94\u6027\u5f3a\u7684\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u4e3a\u9ad8\u7ea7\u610f\u56fe\u9a71\u52a8\u7684\u667a\u80fd\u4f53\u670d\u52a1\u94fa\u5e73\u9053\u8def", "conclusion": "\u667a\u80fd\u4f53\u670d\u52a1\u7cfb\u7edf\u5e94\u5177\u5907\u53ef\u7f16\u7a0b\u6027\u548c\u7cfb\u7edf\u611f\u77e5\u80fd\u529b\uff0cSDN\u542f\u53d1\u7684\u6846\u67b6\u4e3a\u89e3\u51b3\u590d\u6742\u591a\u667a\u80fd\u4f53LLM\u7ba1\u9053\u52a8\u6001\u670d\u52a1\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6848"}}
{"id": "2601.02410", "categories": ["cs.SE", "cs.AI", "cs.CY", "cs.GR"], "pdf": "https://arxiv.org/pdf/2601.02410", "abs": "https://arxiv.org/abs/2601.02410", "authors": ["Aizierjiang Aiersilan"], "title": "The Vibe-Check Protocol: Quantifying Cognitive Offloading in AI Programming", "comment": null, "summary": "The integration of Large Language Models (LLMs) into software engineering education has driven the emergence of ``Vibe Coding,'' a paradigm where developers articulate high-level intent through natural language and delegate implementation to AI agents. While proponents argue this approach modernizes pedagogy by emphasizing conceptual design over syntactic memorization, accumulating empirical evidence raises concerns regarding skill retention and deep conceptual understanding. This paper proposes a theoretical framework to investigate the research question: \\textit{Is Vibe Coding a better way to learn software engineering?} We posit a divergence in student outcomes between those leveraging AI for acceleration versus those using it for cognitive offloading. To evaluate these educational trade-offs, we propose the \\textbf{Vibe-Check Protocol (VCP)}, a systematic benchmarking framework incorporating three quantitative metrics: the \\textit{Cold Start Refactor} ($M_{CSR}$) for modeling skill decay; \\textit{Hallucination Trap Detection} ($M_{HT}$) based on signal detection theory to evaluate error identification; and the \\textit{Explainability Gap} ($E_{gap}$) for quantifying the divergence between code complexity and conceptual comprehension. Through controlled comparisons, VCP aims to provide a quantitative basis for educators to determine the optimal pedagogical boundary: identifying contexts where Vibe Coding fosters genuine mastery and contexts where it introduces hidden technical debt and superficial competence.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faVibe-Check Protocol (VCP)\u6846\u67b6\uff0c\u901a\u8fc7\u4e09\u4e2a\u91cf\u5316\u6307\u6807\u8bc4\u4f30\"Vibe Coding\"\uff08AI\u8f85\u52a9\u7f16\u7a0b\uff09\u5728\u8f6f\u4ef6\u5de5\u7a0b\u6559\u80b2\u4e2d\u7684\u6548\u679c\uff0c\u65e8\u5728\u786e\u5b9a\u5176\u4fc3\u8fdb\u771f\u6b63\u638c\u63e1\u4e0e\u5f15\u5165\u6280\u672f\u503a\u52a1\u7684\u8fb9\u754c\u3002", "motivation": "\u968f\u7740LLM\u5728\u8f6f\u4ef6\u5de5\u7a0b\u6559\u80b2\u4e2d\u7684\u6574\u5408\uff0c\"Vibe Coding\"\uff08\u5f00\u53d1\u8005\u7528\u81ea\u7136\u8bed\u8a00\u8868\u8fbe\u610f\u56fe\uff0cAI\u4ee3\u7406\u5b9e\u73b0\uff09\u8303\u5f0f\u5174\u8d77\u3002\u867d\u7136\u652f\u6301\u8005\u8ba4\u4e3a\u8fd9\u80fd\u73b0\u4ee3\u5316\u6559\u5b66\uff0c\u5f3a\u8c03\u6982\u5ff5\u8bbe\u8ba1\u800c\u975e\u8bed\u6cd5\u8bb0\u5fc6\uff0c\u4f46\u5b9e\u8bc1\u8bc1\u636e\u663e\u793a\u5bf9\u6280\u80fd\u4fdd\u7559\u548c\u6df1\u5ea6\u6982\u5ff5\u7406\u89e3\u5b58\u5728\u62c5\u5fe7\u3002\u9700\u8981\u7cfb\u7edf\u8bc4\u4f30\u8fd9\u79cd\u6559\u80b2\u65b9\u6cd5\u7684\u5229\u5f0a\u3002", "method": "\u63d0\u51faVibe-Check Protocol (VCP)\u7cfb\u7edf\u57fa\u51c6\u6d4b\u8bd5\u6846\u67b6\uff0c\u5305\u542b\u4e09\u4e2a\u91cf\u5316\u6307\u6807\uff1a1) Cold Start Refactor (M_CSR) \u8bc4\u4f30\u6280\u80fd\u8870\u9000\uff1b2) Hallucination Trap Detection (M_HT) \u57fa\u4e8e\u4fe1\u53f7\u68c0\u6d4b\u7406\u8bba\u8bc4\u4f30\u9519\u8bef\u8bc6\u522b\u80fd\u529b\uff1b3) Explainability Gap (E_gap) \u91cf\u5316\u4ee3\u7801\u590d\u6742\u6027\u4e0e\u6982\u5ff5\u7406\u89e3\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002\u901a\u8fc7\u53d7\u63a7\u6bd4\u8f83\u8bc4\u4f30AI\u52a0\u901f\u4e0e\u8ba4\u77e5\u5378\u8f7d\u5bf9\u5b66\u751f\u6210\u679c\u7684\u5f71\u54cd\u5dee\u5f02\u3002", "result": "\u8bba\u6587\u63d0\u51fa\u7684\u662f\u7406\u8bba\u6846\u67b6\u548c\u65b9\u6cd5\u8bba\uff0c\u5c1a\u672a\u62a5\u544a\u5177\u4f53\u5b9e\u9a8c\u7ed3\u679c\u3002VCP\u6846\u67b6\u65e8\u5728\u4e3a\u6559\u80b2\u8005\u63d0\u4f9b\u91cf\u5316\u57fa\u7840\uff0c\u786e\u5b9aVibe Coding\u7684\u6700\u4f73\u6559\u5b66\u8fb9\u754c\u3002", "conclusion": "\u9700\u8981\u7cfb\u7edf\u8bc4\u4f30Vibe Coding\u5728\u8f6f\u4ef6\u5de5\u7a0b\u6559\u80b2\u4e2d\u7684\u771f\u6b63\u4ef7\u503c\uff0c\u533a\u5206AI\u8f85\u52a9\u52a0\u901f\u5b66\u4e60\u4e0e\u8ba4\u77e5\u5378\u8f7d\u7684\u4e0d\u540c\u6548\u679c\u3002VCP\u6846\u67b6\u4e3a\u8bc6\u522bVibe Coding\u4fc3\u8fdb\u771f\u6b63\u638c\u63e1\u4e0e\u5f15\u5165\u9690\u85cf\u6280\u672f\u503a\u52a1\u548c\u8868\u9762\u80fd\u529b\u7684\u573a\u666f\u63d0\u4f9b\u4e86\u65b9\u6cd5\u8bba\u57fa\u7840\u3002"}}
{"id": "2601.02421", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.02421", "abs": "https://arxiv.org/abs/2601.02421", "authors": ["Nyan Lin Zaw"], "title": "Talks that Builds: Exploring Communication factors for the Success of Emerging Professional in Product Teams", "comment": "26 pages, 0 figure. Mixed-methods study examining factors contributing to successful product design teams with emerging professionals. Submitted to Southern States Communication Association", "summary": "This paper recognizes that most organizational communication study focuses on established professionals aged above 27 with more than five years of experience. In contrast, this study examines product teams with younger emerging professionals aged 18-27 and explores which factors influence their success. While some established factors still apply, others become less relevant, and new ones such as curiosity, locational proximity, documentation, access to resources were identified in the study. Overall, this study fills a gap in the literature on how these newer factors shape team productivity and project outcomes based on the success rate of the product the team developed.", "AI": {"tldr": "\u7814\u7a76\u586b\u8865\u4e86\u5e74\u8f7b\u4e13\u4e1a\u4eba\u58eb\uff0818-27\u5c81\uff09\u4ea7\u54c1\u56e2\u961f\u6210\u529f\u56e0\u7d20\u7684\u7814\u7a76\u7a7a\u767d\uff0c\u53d1\u73b0\u597d\u5947\u5fc3\u3001\u5730\u7406\u4f4d\u7f6e\u63a5\u8fd1\u3001\u6587\u6863\u548c\u8d44\u6e90\u83b7\u53d6\u7b49\u65b0\u56e0\u7d20\u5f71\u54cd\u56e2\u961f\u6210\u529f", "motivation": "\u73b0\u6709\u7ec4\u7ec7\u6c9f\u901a\u7814\u7a76\u4e3b\u8981\u5173\u6ce827\u5c81\u4ee5\u4e0a\u3001\u67095\u5e74\u4ee5\u4e0a\u7ecf\u9a8c\u7684\u6210\u719f\u4e13\u4e1a\u4eba\u58eb\uff0c\u7f3a\u4e4f\u5bf9\u5e74\u8f7b\u65b0\u5174\u4e13\u4e1a\u4eba\u58eb\uff0818-27\u5c81\uff09\u4ea7\u54c1\u56e2\u961f\u7684\u7814\u7a76\u3002\u672c\u7814\u7a76\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u63a2\u7d22\u5f71\u54cd\u5e74\u8f7b\u56e2\u961f\u6210\u529f\u7684\u56e0\u7d20\u3002", "method": "\u7814\u7a76\u8003\u5bdf\u5e74\u8f7b\u4ea7\u54c1\u56e2\u961f\uff08\u6210\u5458\u5e74\u9f8418-27\u5c81\uff09\uff0c\u901a\u8fc7\u5206\u6790\u56e2\u961f\u5f00\u53d1\u7684\u4ea7\u54c1\u7684\u6210\u529f\u7387\uff0c\u63a2\u7d22\u5f71\u54cd\u56e2\u961f\u6210\u529f\u7684\u56e0\u7d20\u3002\u7814\u7a76\u8bc6\u522b\u4e86\u54ea\u4e9b\u4f20\u7edf\u56e0\u7d20\u4ecd\u7136\u9002\u7528\uff0c\u54ea\u4e9b\u53d8\u5f97\u4e0d\u90a3\u4e48\u76f8\u5173\uff0c\u5e76\u53d1\u73b0\u4e86\u65b0\u7684\u5f71\u54cd\u56e0\u7d20\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u4e00\u4e9b\u4f20\u7edf\u56e0\u7d20\u4ecd\u7136\u9002\u7528\uff0c\u4f46\u5176\u4ed6\u56e0\u7d20\u53d8\u5f97\u4e0d\u90a3\u4e48\u76f8\u5173\u3002\u7814\u7a76\u8bc6\u522b\u51fa\u65b0\u7684\u6210\u529f\u5f71\u54cd\u56e0\u7d20\uff0c\u5305\u62ec\u597d\u5947\u5fc3\u3001\u5730\u7406\u4f4d\u7f6e\u63a5\u8fd1\u3001\u6587\u6863\u8d28\u91cf\u548c\u8d44\u6e90\u83b7\u53d6\u3002\u8fd9\u4e9b\u65b0\u56e0\u7d20\u663e\u8457\u5f71\u54cd\u56e2\u961f\u751f\u4ea7\u529b\u548c\u9879\u76ee\u6210\u679c\u3002", "conclusion": "\u672c\u7814\u7a76\u586b\u8865\u4e86\u5e74\u8f7b\u4e13\u4e1a\u4eba\u58eb\u4ea7\u54c1\u56e2\u961f\u6210\u529f\u56e0\u7d20\u7684\u7814\u7a76\u7a7a\u767d\uff0c\u63ed\u793a\u4e86\u597d\u5947\u5fc3\u3001\u5730\u7406\u4f4d\u7f6e\u63a5\u8fd1\u3001\u6587\u6863\u548c\u8d44\u6e90\u83b7\u53d6\u7b49\u65b0\u56e0\u7d20\u5982\u4f55\u5851\u9020\u56e2\u961f\u751f\u4ea7\u529b\u548c\u9879\u76ee\u6210\u679c\uff0c\u4e3a\u7406\u89e3\u5e74\u8f7b\u56e2\u961f\u52a8\u6001\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\u3002"}}
{"id": "2601.02430", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.02430", "abs": "https://arxiv.org/abs/2601.02430", "authors": ["Chenxu Liu", "Yingjie Fu", "Wei Yang", "Ying Zhang", "Tao Xie"], "title": "WebCoderBench: Benchmarking Web Application Generation with Comprehensive and Interpretable Evaluation Metrics", "comment": null, "summary": "Web applications (web apps) have become a key arena for large language models (LLMs) to demonstrate their code generation capabilities and commercial potential. However, building a benchmark for LLM-generated web apps remains challenging due to the need for real-world user requirements, generalizable evaluation metrics without relying on ground-truth implementations or test cases, and interpretable evaluation results. To address these challenges, we introduce WebCoderBench, the first real-world-collected, generalizable, and interpretable benchmark for web app generation. WebCoderBench comprises 1,572 real user requirements, covering diverse modalities and expression styles that reflect realistic user intentions. WebCoderBench provides 24 fine-grained evaluation metrics across 9 perspectives, combining rule-based and LLM-as-a-judge paradigm for fully automated, objective, and general evaluation. Moreover, WebCoderBench adopts human-preference-aligned weights over metrics to yield interpretable overall scores. Experiments across 12 representative LLMs and 2 LLM-based agents show that there exists no dominant model across all evaluation metrics, offering an opportunity for LLM developers to optimize their models in a targeted manner for a more powerful version.", "AI": {"tldr": "WebCoderBench\u662f\u9996\u4e2a\u771f\u5b9e\u4e16\u754c\u6536\u96c6\u3001\u53ef\u6cdb\u5316\u4e14\u53ef\u89e3\u91ca\u7684\u7f51\u9875\u5e94\u7528\u751f\u6210\u57fa\u51c6\uff0c\u5305\u542b1,572\u4e2a\u771f\u5b9e\u7528\u6237\u9700\u6c42\uff0c\u63d0\u4f9b24\u4e2a\u7ec6\u7c92\u5ea6\u8bc4\u4f30\u6307\u6807\uff0c\u5b9e\u9a8c\u663e\u793a\u76ee\u524d\u6ca1\u6709\u6a21\u578b\u5728\u6240\u6709\u6307\u6807\u4e0a\u5360\u4e3b\u5bfc\u5730\u4f4d\u3002", "motivation": "\u5f53\u524dLLM\u5728\u7f51\u9875\u5e94\u7528\u4ee3\u7801\u751f\u6210\u9886\u57df\u7f3a\u4e4f\u5408\u9002\u7684\u57fa\u51c6\uff0c\u73b0\u6709\u65b9\u6cd5\u9700\u8981\u771f\u5b9e\u7528\u6237\u9700\u6c42\u3001\u4e0d\u4f9d\u8d56\u53c2\u8003\u5b9e\u73b0\u6216\u6d4b\u8bd5\u7528\u4f8b\u7684\u53ef\u6cdb\u5316\u8bc4\u4f30\u6307\u6807\uff0c\u4ee5\u53ca\u53ef\u89e3\u91ca\u7684\u8bc4\u4f30\u7ed3\u679c\u3002", "method": "\u6536\u96c61,572\u4e2a\u771f\u5b9e\u7528\u6237\u9700\u6c42\uff0c\u6db5\u76d6\u591a\u79cd\u6a21\u6001\u548c\u8868\u8fbe\u98ce\u683c\uff1b\u8bbe\u8ba124\u4e2a\u7ec6\u7c92\u5ea6\u8bc4\u4f30\u6307\u6807\u8986\u76d69\u4e2a\u7ef4\u5ea6\uff0c\u7ed3\u5408\u57fa\u4e8e\u89c4\u5219\u548cLLM\u4f5c\u4e3a\u8bc4\u5224\u8005\u7684\u65b9\u6cd5\uff1b\u91c7\u7528\u4eba\u7c7b\u504f\u597d\u5bf9\u9f50\u7684\u6743\u91cd\u5206\u914d\u4ee5\u83b7\u5f97\u53ef\u89e3\u91ca\u7684\u7efc\u5408\u8bc4\u5206\u3002", "result": "\u572812\u4e2a\u4ee3\u8868\u6027LLM\u548c2\u4e2a\u57fa\u4e8eLLM\u7684\u4ee3\u7406\u4e0a\u5b9e\u9a8c\u8868\u660e\uff0c\u6ca1\u6709\u6a21\u578b\u5728\u6240\u6709\u8bc4\u4f30\u6307\u6807\u4e0a\u5360\u4e3b\u5bfc\u5730\u4f4d\uff0c\u4e3aLLM\u5f00\u53d1\u8005\u63d0\u4f9b\u4e86\u9488\u5bf9\u6027\u4f18\u5316\u7684\u673a\u4f1a\u3002", "conclusion": "WebCoderBench\u586b\u8865\u4e86\u7f51\u9875\u5e94\u7528\u751f\u6210\u57fa\u51c6\u7684\u7a7a\u767d\uff0c\u63d0\u4f9b\u4e86\u771f\u5b9e\u3001\u53ef\u6cdb\u5316\u3001\u53ef\u89e3\u91ca\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u63ed\u793a\u4e86\u5f53\u524dLLM\u5728\u8be5\u9886\u57df\u7684\u4f18\u5316\u7a7a\u95f4\u3002"}}
{"id": "2601.02438", "categories": ["cs.SE", "cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2601.02438", "abs": "https://arxiv.org/abs/2601.02438", "authors": ["Yun Bian", "Yi Chen", "HaiQuan Wang", "ShiHao Li", "Zhe Cui"], "title": "Focus on What Matters: Fisher-Guided Adaptive Multimodal Fusion for Vulnerability Detection", "comment": null, "summary": "Software vulnerability detection is a critical task for securing software systems and can be formulated as a binary classification problem: given a code snippet, determine whether it contains a vulnerability. Existing multimodal approaches typically fuse Natural Code Sequence (NCS) representations from pretrained language models with Code Property Graph (CPG) representations from graph neural networks, often under the implicit assumption that adding a modality necessarily yields extra information. In practice, sequence and graph representations can be redundant, and fluctuations in the quality of the graph modality can dilute the discriminative signal of the dominant modality. To address this, we propose TaCCS-DFA, a framework that introduces Fisher information as a geometric measure of how sensitive feature directions are to the classification decision, enabling task-oriented complementary fusion. TaCCS-DFA online estimates a low-rank principal Fisher subspace and restricts cross-modal attention to task-sensitive directions, thereby retrieving structural features from CPG that complement the sequence modality; meanwhile, an adaptive gating mechanism dynamically adjusts the contribution of the graph modality for each sample to suppress noise propagation. Our analysis shows that, under an isotropic perturbation assumption, the proposed mechanism admits a tighter risk bound than conventional full-spectrum attention. Experiments on BigVul, Devign, and ReVeal show that TaCCS-DFA achieves strong performance across multiple backbones. With CodeT5 as the backbone, TaCCS-DFA reaches an F1 score of 87.80\\% on the highly imbalanced BigVul dataset, improving over a strong baseline Vul-LMGNNs by 6.3 percentage points while maintaining low calibration error and computational overhead.", "AI": {"tldr": "TaCCS-DFA\u662f\u4e00\u4e2a\u7528\u4e8e\u8f6f\u4ef6\u6f0f\u6d1e\u68c0\u6d4b\u7684\u591a\u6a21\u6001\u878d\u5408\u6846\u67b6\uff0c\u901a\u8fc7Fisher\u4fe1\u606f\u8fdb\u884c\u4efb\u52a1\u5bfc\u5411\u7684\u4e92\u8865\u878d\u5408\uff0c\u52a8\u6001\u8c03\u6574\u56fe\u6a21\u6001\u8d21\u732e\uff0c\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u663e\u8457\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u73b0\u6709\u591a\u6a21\u6001\u65b9\u6cd5\u901a\u5e38\u5047\u8bbe\u6dfb\u52a0\u6a21\u6001\u5fc5\u7136\u5e26\u6765\u989d\u5916\u4fe1\u606f\uff0c\u4f46\u5b9e\u9645\u4e0a\u5e8f\u5217\u548c\u56fe\u8868\u793a\u53ef\u80fd\u5b58\u5728\u5197\u4f59\uff0c\u4e14\u56fe\u6a21\u6001\u8d28\u91cf\u6ce2\u52a8\u4f1a\u7a00\u91ca\u4e3b\u5bfc\u6a21\u6001\u7684\u5224\u522b\u4fe1\u53f7\uff0c\u9700\u8981\u66f4\u667a\u80fd\u7684\u878d\u5408\u7b56\u7565\u3002", "method": "\u63d0\u51faTaCCS-DFA\u6846\u67b6\uff1a1\uff09\u4f7f\u7528Fisher\u4fe1\u606f\u4f5c\u4e3a\u51e0\u4f55\u5ea6\u91cf\uff0c\u8bc6\u522b\u5bf9\u5206\u7c7b\u51b3\u7b56\u654f\u611f\u7684\u7279\u5f81\u65b9\u5411\uff1b2\uff09\u5728\u7ebf\u4f30\u8ba1\u4f4e\u79e9\u4e3bFisher\u5b50\u7a7a\u95f4\uff0c\u5c06\u8de8\u6a21\u6001\u6ce8\u610f\u529b\u9650\u5236\u5728\u4efb\u52a1\u654f\u611f\u65b9\u5411\uff1b3\uff09\u81ea\u9002\u5e94\u95e8\u63a7\u673a\u5236\u52a8\u6001\u8c03\u6574\u6bcf\u4e2a\u6837\u672c\u7684\u56fe\u6a21\u6001\u8d21\u732e\u4ee5\u6291\u5236\u566a\u58f0\u4f20\u64ad\u3002", "result": "\u5728BigVul\u3001Devign\u548cReVeal\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u5f02\uff1a\u4ee5CodeT5\u4e3a\u9aa8\u5e72\uff0c\u5728\u9ad8\u5ea6\u4e0d\u5e73\u8861\u7684BigVul\u6570\u636e\u96c6\u4e0aF1\u5206\u6570\u8fbe\u523087.80%\uff0c\u6bd4\u5f3a\u57fa\u7ebfVul-LMGNNs\u63d0\u53476.3\u4e2a\u767e\u5206\u70b9\uff0c\u540c\u65f6\u4fdd\u6301\u4f4e\u6821\u51c6\u8bef\u5dee\u548c\u8ba1\u7b97\u5f00\u9500\u3002", "conclusion": "\u901a\u8fc7\u4efb\u52a1\u5bfc\u5411\u7684\u4e92\u8865\u878d\u5408\u548c\u81ea\u9002\u5e94\u95e8\u63a7\uff0cTaCCS-DFA\u6709\u6548\u89e3\u51b3\u4e86\u591a\u6a21\u6001\u5197\u4f59\u548c\u566a\u58f0\u95ee\u9898\uff0c\u5728\u8f6f\u4ef6\u6f0f\u6d1e\u68c0\u6d4b\u4efb\u52a1\u4e2d\u5b9e\u73b0\u4e86\u66f4\u7a33\u5065\u548c\u9ad8\u6548\u7684\u591a\u6a21\u6001\u8868\u793a\u5b66\u4e60\u3002"}}
{"id": "2601.02454", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.02454", "abs": "https://arxiv.org/abs/2601.02454", "authors": ["Saba Naqvi", "Mohammad Baqar", "Nawaz Ali Mohammad"], "title": "The Rise of Agentic Testing: Multi-Agent Systems for Robust Software Quality Assurance", "comment": "11 Pages", "summary": "Software testing has progressed toward intelligent automation, yet current AI-based test generators still suffer from static, single-shot outputs that frequently produce invalid, redundant, or non-executable tests due to the lack of execution aware feedback. This paper introduces an agentic multi-model testing framework a closed-loop, self-correcting system in which a Test Generation Agent, an Execution and Analysis Agent, and a Review and Optimization Agent collaboratively generate, execute, analyze, and refine tests until convergence. By using sandboxed execution, detailed failure reporting, and iterative regeneration or patching of failing tests, the framework autonomously improves test quality and expands coverage. Integrated into a CI/CD-compatible pipeline, it leverages reinforcement signals from coverage metrics and execution outcomes to guide refinement. Empirical evaluations on microservice based applications show up to a 60% reduction in invalid tests, 30% coverage improvement, and significantly reduced human effort compared to single-model baselines demonstrating that multi-agent, feedback-driven loops can evolve software testing into an autonomous, continuously learning quality assurance ecosystem for self-healing, high-reliability codebases.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u591a\u667a\u80fd\u4f53\u7684\u95ed\u73af\u6d4b\u8bd5\u6846\u67b6\uff0c\u901a\u8fc7\u6267\u884c\u611f\u77e5\u53cd\u9988\u548c\u8fed\u4ee3\u4f18\u5316\uff0c\u663e\u8457\u51cf\u5c11\u65e0\u6548\u6d4b\u8bd5\u5e76\u63d0\u9ad8\u8986\u76d6\u7387", "motivation": "\u5f53\u524d\u57fa\u4e8eAI\u7684\u6d4b\u8bd5\u751f\u6210\u5668\u5b58\u5728\u9759\u6001\u3001\u5355\u6b21\u8f93\u51fa\u7684\u95ee\u9898\uff0c\u7f3a\u4e4f\u6267\u884c\u611f\u77e5\u53cd\u9988\uff0c\u5bfc\u81f4\u4ea7\u751f\u65e0\u6548\u3001\u5197\u4f59\u6216\u4e0d\u53ef\u6267\u884c\u7684\u6d4b\u8bd5\u7528\u4f8b", "method": "\u91c7\u7528\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u6846\u67b6\uff1a\u6d4b\u8bd5\u751f\u6210\u667a\u80fd\u4f53\u3001\u6267\u884c\u5206\u6790\u667a\u80fd\u4f53\u548c\u8bc4\u5ba1\u4f18\u5316\u667a\u80fd\u4f53\uff0c\u901a\u8fc7\u6c99\u7bb1\u6267\u884c\u3001\u8be6\u7ec6\u5931\u8d25\u62a5\u544a\u548c\u8fed\u4ee3\u4fee\u590d\uff0c\u5f62\u6210\u95ed\u73af\u81ea\u6821\u6b63\u7cfb\u7edf", "result": "\u5728\u5fae\u670d\u52a1\u5e94\u7528\u4e2d\u5b9e\u73b0\uff1a\u65e0\u6548\u6d4b\u8bd5\u51cf\u5c1160%\uff0c\u8986\u76d6\u7387\u63d0\u534730%\uff0c\u663e\u8457\u964d\u4f4e\u4eba\u5de5\u5de5\u4f5c\u91cf\uff0c\u4f18\u4e8e\u5355\u6a21\u578b\u57fa\u7ebf\u65b9\u6cd5", "conclusion": "\u591a\u667a\u80fd\u4f53\u3001\u53cd\u9988\u9a71\u52a8\u7684\u95ed\u73af\u6d4b\u8bd5\u80fd\u591f\u5c06\u8f6f\u4ef6\u6d4b\u8bd5\u6f14\u53d8\u4e3a\u81ea\u4e3b\u3001\u6301\u7eed\u5b66\u4e60\u7684\u8d28\u91cf\u4fdd\u8bc1\u751f\u6001\u7cfb\u7edf\uff0c\u5b9e\u73b0\u81ea\u4fee\u590d\u3001\u9ad8\u53ef\u9760\u6027\u7684\u4ee3\u7801\u5e93"}}
{"id": "2601.02504", "categories": ["cs.SE", "cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2601.02504", "abs": "https://arxiv.org/abs/2601.02504", "authors": ["Elizaveta Artser", "Daniil Karol", "Anna Potriasaeva", "Aleksei Rostovskii", "Katsiaryna Dzialets", "Ekaterina Koshchenko", "Xiaotian Su", "April Yi Wang", "Anastasiia Birillo"], "title": "Enhancing Debugging Skills with AI-Powered Assistance: A Real-Time Tool for Debugging Support", "comment": "Accepted at ICSE SEET 2026, 6 pages, 2 figures", "summary": "Debugging is a crucial skill in programming education and software development, yet it is often overlooked in CS curricula. To address this, we introduce an AI-powered debugging assistant integrated into an IDE. It offers real-time support by analyzing code, suggesting breakpoints, and providing contextual hints. Using RAG with LLMs, program slicing, and custom heuristics, it enhances efficiency by minimizing LLM calls and improving accuracy. A three-level evaluation - technical analysis, UX study, and classroom tests - highlights its potential for teaching debugging.", "AI": {"tldr": "AI\u9a71\u52a8\u7684IDE\u8c03\u8bd5\u52a9\u624b\uff0c\u901a\u8fc7RAG\u3001\u7a0b\u5e8f\u5207\u7247\u548c\u542f\u53d1\u5f0f\u65b9\u6cd5\u63d0\u4f9b\u5b9e\u65f6\u8c03\u8bd5\u652f\u6301\uff0c\u51cf\u5c11LLM\u8c03\u7528\u5e76\u63d0\u9ad8\u51c6\u786e\u6027", "motivation": "\u8c03\u8bd5\u662f\u7f16\u7a0b\u6559\u80b2\u548c\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u7684\u5173\u952e\u6280\u80fd\uff0c\u4f46\u5728\u8ba1\u7b97\u673a\u79d1\u5b66\u8bfe\u7a0b\u4e2d\u7ecf\u5e38\u88ab\u5ffd\u89c6\uff0c\u9700\u8981\u5de5\u5177\u6765\u5e2e\u52a9\u5b66\u751f\u548c\u5f00\u53d1\u8005\u63d0\u9ad8\u8c03\u8bd5\u80fd\u529b", "method": "\u5728IDE\u4e2d\u96c6\u6210AI\u9a71\u52a8\u7684\u8c03\u8bd5\u52a9\u624b\uff0c\u4f7f\u7528RAG\uff08\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff09\u4e0eLLMs\u3001\u7a0b\u5e8f\u5207\u7247\u6280\u672f\u548c\u81ea\u5b9a\u4e49\u542f\u53d1\u5f0f\u65b9\u6cd5\uff0c\u63d0\u4f9b\u4ee3\u7801\u5206\u6790\u3001\u65ad\u70b9\u5efa\u8bae\u548c\u4e0a\u4e0b\u6587\u63d0\u793a", "result": "\u901a\u8fc7\u4e09\u7ea7\u8bc4\u4f30\uff08\u6280\u672f\u5206\u6790\u3001\u7528\u6237\u4f53\u9a8c\u7814\u7a76\u548c\u8bfe\u5802\u6d4b\u8bd5\uff09\u9a8c\u8bc1\u4e86\u8be5\u5de5\u5177\u5728\u8c03\u8bd5\u6559\u5b66\u4e2d\u7684\u6f5c\u529b\uff0c\u80fd\u591f\u51cf\u5c11LLM\u8c03\u7528\u6b21\u6570\u5e76\u63d0\u9ad8\u8c03\u8bd5\u51c6\u786e\u6027", "conclusion": "AI\u9a71\u52a8\u7684\u8c03\u8bd5\u52a9\u624b\u6709\u6f5c\u529b\u6539\u5584\u7f16\u7a0b\u6559\u80b2\u548c\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u7684\u8c03\u8bd5\u6559\u5b66\uff0c\u901a\u8fc7\u667a\u80fd\u8f85\u52a9\u63d0\u9ad8\u5b66\u4e60\u6548\u7387\u548c\u8c03\u8bd5\u6280\u80fd"}}
{"id": "2601.02512", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.02512", "abs": "https://arxiv.org/abs/2601.02512", "authors": ["Pelin Rabia Kuran", "Rumbidzai Chitakunye", "Vincenzo Stoico", "Ilja Heitlager", "Justus Bogner"], "title": "Green LLM Techniques in Action: How Effective Are Existing Techniques for Improving the Energy Efficiency of LLM-Based Applications in Industry?", "comment": "Accepted for publication at the 2026 International Conference on Software Engineering: Software Engineering in Practice (ICSE-SEIP'26)", "summary": "The rapid adoption of large language models (LLMs) has raised concerns about their substantial energy consumption, especially when deployed at industry scale. While several techniques have been proposed to address this, limited empirical evidence exists regarding the effectiveness of applying them to LLM-based industry applications. To fill this gap, we analyzed a chatbot application in an industrial context at Schuberg Philis, a Dutch IT services company. We then selected four techniques, namely Small and Large Model Collaboration, Prompt Optimization, Quantization, and Batching, applied them to the application in eight variations, and then conducted experiments to study their impact on energy consumption, accuracy, and response time compared to the unoptimized baseline.\n  Our results show that several techniques, such as Prompt Optimization and 2-bit Quantization, managed to reduce energy use significantly, sometimes by up to 90%. However, these techniques especially impacted accuracy negatively, to a degree that is not acceptable in practice. The only technique that achieved significant and strong energy reductions without harming the other qualities substantially was Small and Large Model Collaboration via Nvidia's Prompt Task and Complexity Classifier (NPCC) with prompt complexity thresholds. This highlights that reducing the energy consumption of LLM-based applications is not difficult in practice. However, improving their energy efficiency, i.e., reducing energy use without harming other qualities, remains challenging. Our study provides practical insights to move towards this goal.", "AI": {"tldr": "\u7814\u7a76\u5206\u6790\u4e86\u56db\u79cd\u6280\u672f\uff08\u5927\u5c0f\u6a21\u578b\u534f\u4f5c\u3001\u63d0\u793a\u4f18\u5316\u3001\u91cf\u5316\u3001\u6279\u5904\u7406\uff09\u5728\u5de5\u4e1aLLM\u5e94\u7528\u4e2d\u7684\u8282\u80fd\u6548\u679c\uff0c\u53d1\u73b0\u63d0\u793a\u4f18\u5316\u548c2\u4f4d\u91cf\u5316\u80fd\u663e\u8457\u8282\u80fd\u4f46\u635f\u5bb3\u51c6\u786e\u6027\uff0c\u53ea\u6709\u5927\u5c0f\u6a21\u578b\u534f\u4f5c\u80fd\u6709\u6548\u8282\u80fd\u4e14\u4e0d\u4e25\u91cd\u5f71\u54cd\u5176\u4ed6\u8d28\u91cf\u6307\u6807\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5de5\u4e1a\u89c4\u6a21\u90e8\u7f72\u65f6\u80fd\u8017\u5de8\u5927\uff0c\u867d\u7136\u5df2\u6709\u591a\u79cd\u8282\u80fd\u6280\u672f\u63d0\u51fa\uff0c\u4f46\u7f3a\u4e4f\u5728\u771f\u5b9e\u5de5\u4e1aLLM\u5e94\u7528\u4e2d\u7684\u5b9e\u8bc1\u7814\u7a76\uff0c\u9700\u8981\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u5728\u8377\u5170IT\u670d\u52a1\u516c\u53f8Schuberg Philis\u7684\u804a\u5929\u673a\u5668\u4eba\u5e94\u7528\u4e2d\uff0c\u9009\u62e9\u4e86\u56db\u79cd\u6280\u672f\uff08\u5927\u5c0f\u6a21\u578b\u534f\u4f5c\u3001\u63d0\u793a\u4f18\u5316\u3001\u91cf\u5316\u3001\u6279\u5904\u7406\uff09\uff0c\u521b\u5efa\u4e86\u516b\u4e2a\u53d8\u4f53\u8fdb\u884c\u5b9e\u9a8c\uff0c\u8bc4\u4f30\u5b83\u4eec\u5bf9\u80fd\u8017\u3001\u51c6\u786e\u6027\u548c\u54cd\u5e94\u65f6\u95f4\u7684\u5f71\u54cd\u3002", "result": "\u63d0\u793a\u4f18\u5316\u548c2\u4f4d\u91cf\u5316\u6280\u672f\u80fd\u663e\u8457\u964d\u4f4e\u80fd\u8017\uff08\u6700\u9ad8\u8fbe90%\uff09\uff0c\u4f46\u4e25\u91cd\u635f\u5bb3\u4e86\u51c6\u786e\u6027\uff0c\u5728\u5b9e\u9645\u4e2d\u4e0d\u53ef\u63a5\u53d7\u3002\u53ea\u6709\u901a\u8fc7Nvidia\u7684NPCC\u63d0\u793a\u590d\u6742\u5ea6\u5206\u7c7b\u5668\u7684\u5927\u5c0f\u6a21\u578b\u534f\u4f5c\u6280\u672f\uff0c\u80fd\u5728\u4e0d\u663e\u8457\u635f\u5bb3\u5176\u4ed6\u8d28\u91cf\u6307\u6807\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u663e\u8457\u8282\u80fd\u3002", "conclusion": "\u964d\u4f4eLLM\u5e94\u7528\u7684\u80fd\u8017\u5728\u5b9e\u8df5\u4e2d\u5e76\u4e0d\u56f0\u96be\uff0c\u4f46\u5b9e\u73b0\u80fd\u6548\u63d0\u5347\uff08\u5373\u5728\u4e0d\u635f\u5bb3\u5176\u4ed6\u8d28\u91cf\u7684\u60c5\u51b5\u4e0b\u8282\u80fd\uff09\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\u3002\u5927\u5c0f\u6a21\u578b\u534f\u4f5c\u662f\u5f53\u524d\u6700\u53ef\u884c\u7684\u8282\u80fd\u65b9\u6848\uff0c\u7814\u7a76\u4e3a\u5de5\u4e1a\u5b9e\u8df5\u63d0\u4f9b\u4e86\u5b9e\u7528\u89c1\u89e3\u3002"}}
{"id": "2601.02522", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.02522", "abs": "https://arxiv.org/abs/2601.02522", "authors": ["Zhinuan", "Guo", "Chushu Gao", "Justus Bogner"], "title": "On the Effectiveness of Proposed Techniques to Reduce Energy Consumption in RAG Systems: A Controlled Experiment", "comment": "Accepted for publication at the 2026 International Conference on Software Engineering: Software Engineering in Society (ICSE-SEIS'26)", "summary": "The rising energy demands of machine learning (ML), e.g., implemented in popular variants like retrieval-augmented generation (RAG) systems, have raised significant concerns about their environmental sustainability. While previous research has proposed green tactics for ML-enabled systems, their empirical evaluation within RAG systems remains largely unexplored. This study presents a controlled experiment investigating five practical techniques aimed at reducing energy consumption in RAG systems. Using a production-like RAG system developed at our collaboration partner, the Software Improvement Group, we evaluated the impact of these techniques on energy consumption, latency, and accuracy.\n  Through a total of 9 configurations spanning over 200 hours of trials using the CRAG dataset, we reveal that techniques such as increasing similarity retrieval thresholds, reducing embedding sizes, applying vector indexing, and using a BM25S reranker can significantly reduce energy usage, up to 60% in some cases. However, several techniques also led to unacceptable accuracy decreases, e.g., by up to 30% for the indexing strategies. Notably, finding an optimal retrieval threshold and reducing embedding size substantially reduced energy consumption and latency with no loss in accuracy, making these two techniques truly energy-efficient. We present the first comprehensive, empirical study on energy-efficient design techniques for RAG systems, providing guidance for developers and researchers aiming to build sustainable RAG applications.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5b9e\u9a8c\u7814\u7a76\u4e86\u4e94\u79cd\u964d\u4f4eRAG\u7cfb\u7edf\u80fd\u8017\u7684\u6280\u672f\uff0c\u53d1\u73b0\u63d0\u9ad8\u76f8\u4f3c\u5ea6\u68c0\u7d22\u9608\u503c\u548c\u51cf\u5c0f\u5d4c\u5165\u5c3a\u5bf8\u80fd\u663e\u8457\u964d\u4f4e\u80fd\u8017\u548c\u5ef6\u8fdf\u4e14\u4e0d\u5f71\u54cd\u51c6\u786e\u6027\uff0c\u800c\u5176\u4ed6\u6280\u672f\u867d\u7136\u8282\u80fd\u4f46\u4f1a\u964d\u4f4e\u51c6\u786e\u6027\u3002", "motivation": "\u968f\u7740\u673a\u5668\u5b66\u4e60\uff08\u7279\u522b\u662fRAG\u7cfb\u7edf\uff09\u80fd\u8017\u9700\u6c42\u7684\u589e\u957f\uff0c\u5176\u73af\u5883\u53ef\u6301\u7eed\u6027\u5f15\u53d1\u62c5\u5fe7\u3002\u867d\u7136\u5df2\u6709\u7814\u7a76\u63d0\u51fa\u7eff\u8272ML\u6280\u672f\uff0c\u4f46\u8fd9\u4e9b\u6280\u672f\u5728RAG\u7cfb\u7edf\u4e2d\u7684\u5b9e\u8bc1\u8bc4\u4f30\u4ecd\u5f88\u7f3a\u4e4f\u3002", "method": "\u4f7f\u7528\u5408\u4f5c\u65b9Software Improvement Group\u5f00\u53d1\u7684\u7c7b\u751f\u4ea7RAG\u7cfb\u7edf\uff0c\u901a\u8fc7\u63a7\u5236\u5b9e\u9a8c\u8bc4\u4f30\u4e94\u79cd\u8282\u80fd\u6280\u672f\uff1a\u63d0\u9ad8\u76f8\u4f3c\u5ea6\u68c0\u7d22\u9608\u503c\u3001\u51cf\u5c0f\u5d4c\u5165\u5c3a\u5bf8\u3001\u5e94\u7528\u5411\u91cf\u7d22\u5f15\u3001\u4f7f\u7528BM25S\u91cd\u6392\u5e8f\u5668\u3002\u5728CRAG\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e869\u79cd\u914d\u7f6e\u3001\u8d85\u8fc7200\u5c0f\u65f6\u7684\u8bd5\u9a8c\u3002", "result": "\u67d0\u4e9b\u6280\u672f\uff08\u5982\u63d0\u9ad8\u68c0\u7d22\u9608\u503c\u3001\u51cf\u5c0f\u5d4c\u5165\u5c3a\u5bf8\u3001\u5e94\u7528\u5411\u91cf\u7d22\u5f15\u3001\u4f7f\u7528BM25S\u91cd\u6392\u5e8f\u5668\uff09\u80fd\u663e\u8457\u964d\u4f4e\u80fd\u8017\uff0c\u6700\u9ad8\u8fbe60%\u3002\u4f46\u90e8\u5206\u6280\u672f\uff08\u5982\u7d22\u5f15\u7b56\u7565\uff09\u4f1a\u5bfc\u81f4\u51c6\u786e\u6027\u4e0b\u964d\u8fbe30%\u3002\u6700\u4f18\u68c0\u7d22\u9608\u503c\u548c\u51cf\u5c0f\u5d4c\u5165\u5c3a\u5bf8\u80fd\u5728\u4e0d\u5f71\u54cd\u51c6\u786e\u6027\u7684\u60c5\u51b5\u4e0b\u663e\u8457\u964d\u4f4e\u80fd\u8017\u548c\u5ef6\u8fdf\u3002", "conclusion": "\u8fd9\u662f\u9996\u4e2a\u5173\u4e8eRAG\u7cfb\u7edf\u8282\u80fd\u8bbe\u8ba1\u6280\u672f\u7684\u5168\u9762\u5b9e\u8bc1\u7814\u7a76\uff0c\u4e3a\u5f00\u53d1\u8005\u548c\u7814\u7a76\u4eba\u5458\u6784\u5efa\u53ef\u6301\u7eedRAG\u5e94\u7528\u63d0\u4f9b\u4e86\u6307\u5bfc\u3002\u6700\u4f18\u68c0\u7d22\u9608\u503c\u548c\u51cf\u5c0f\u5d4c\u5165\u5c3a\u5bf8\u662f\u771f\u6b63\u8282\u80fd\u7684\u6280\u672f\u9009\u62e9\u3002"}}
{"id": "2601.02559", "categories": ["cs.SE", "cs.HC"], "pdf": "https://arxiv.org/pdf/2601.02559", "abs": "https://arxiv.org/abs/2601.02559", "authors": ["Lauren Olson", "Emitz\u00e1 Guzm\u00e1n", "Florian Kunneman"], "title": "PerspectiveCoach: Exploring LLMs for Developer Reflection", "comment": "48th International Conference of Software Engineering", "summary": "Despite growing awareness of ethical challenges in software development, practitioners still lack structured tools that help them critically engage with the lived experiences of marginalized users. This paper presents PerspectiveCoach, a large language model (LLM)-powered conversational tool designed to guide developers through structured perspective-taking exercises and deepen critical reflection on how software design decisions affect marginalized communities. Through a controlled study with 18 front-end developers (balanced by sex), who interacted with the tool using a real case of online gender-based harassment, we examine how PerspectiveCoach supports ethical reasoning and engagement with user perspectives. Qualitative analysis revealed increased self-awareness, broadened perspectives, and more nuanced ethical articulation, while a complementary human-human study contextualized these findings. Text similarity analyses demonstrated that participants in the human-PerspectiveCoach study improved the fidelity of their restatements over multiple attempts, capturing both surface-level and semantic aspects of user concerns. However, human-PerspectiveCoach's restatements had a lower baseline than the human-human conversations, highlighting contextual differences in impersonal and interpersonal perspective-taking. Across the study, participants rated the tool highly for usability and relevance. This work contributes an exploratory design for LLM-powered end-user perspective-taking that supports critical, ethical self-reflection and offers empirical insights (i.e., enhancing adaptivity, centering plurality) into how such tools can help practitioners build more inclusive and socially responsive technologies.", "AI": {"tldr": "PerspectiveCoach\u662f\u4e00\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5bf9\u8bdd\u5de5\u5177\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u89c6\u89d2\u8bad\u7ec3\u5e2e\u52a9\u5f00\u53d1\u8005\u53cd\u601d\u8f6f\u4ef6\u8bbe\u8ba1\u5bf9\u8fb9\u7f18\u5316\u7fa4\u4f53\u7684\u5f71\u54cd\uff0c\u7814\u7a76\u8868\u660e\u5b83\u80fd\u63d0\u5347\u81ea\u6211\u610f\u8bc6\u3001\u62d3\u5bbd\u89c6\u89d2\u5e76\u6539\u5584\u4f26\u7406\u8868\u8fbe\u3002", "motivation": "\u5c3d\u7ba1\u8f6f\u4ef6\u5f00\u53d1\u7684\u4f26\u7406\u6311\u6218\u65e5\u76ca\u53d7\u5230\u5173\u6ce8\uff0c\u4f46\u4ece\u4e1a\u8005\u4ecd\u7f3a\u4e4f\u7ed3\u6784\u5316\u5de5\u5177\u6765\u6279\u5224\u6027\u5730\u53c2\u4e0e\u8fb9\u7f18\u5316\u7528\u6237\u7684\u771f\u5b9e\u4f53\u9a8c\u3002\u9700\u8981\u5e2e\u52a9\u5f00\u53d1\u8005\u53cd\u601d\u8f6f\u4ef6\u8bbe\u8ba1\u51b3\u7b56\u5982\u4f55\u5f71\u54cd\u8fb9\u7f18\u5316\u793e\u533a\u3002", "method": "\u5f00\u53d1\u4e86PerspectiveCoach\u2014\u2014\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5bf9\u8bdd\u5de5\u5177\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u89c6\u89d2\u8bad\u7ec3\u5f15\u5bfc\u5f00\u53d1\u8005\u3002\u8fdb\u884c\u4e86\u5bf9\u7167\u7814\u7a76\uff1a18\u540d\u524d\u7aef\u5f00\u53d1\u8005\uff08\u6027\u522b\u5e73\u8861\uff09\u4f7f\u7528\u8be5\u5de5\u5177\u5904\u7406\u5728\u7ebf\u6027\u522b\u9a9a\u6270\u7684\u771f\u5b9e\u6848\u4f8b\uff0c\u5206\u6790\u5de5\u5177\u5982\u4f55\u652f\u6301\u4f26\u7406\u63a8\u7406\u548c\u7528\u6237\u89c6\u89d2\u53c2\u4e0e\u3002\u540c\u65f6\u8fdb\u884c\u4e86\u4eba-\u4eba\u7814\u7a76\u4f5c\u4e3a\u5bf9\u7167\u3002", "result": "\u5b9a\u6027\u5206\u6790\u663e\u793a\uff1a\u53c2\u4e0e\u8005\u81ea\u6211\u610f\u8bc6\u589e\u5f3a\u3001\u89c6\u89d2\u62d3\u5bbd\u3001\u4f26\u7406\u8868\u8fbe\u66f4\u7ec6\u81f4\u3002\u6587\u672c\u76f8\u4f3c\u6027\u5206\u6790\u8868\u660e\uff0c\u4eba-PerspectiveCoach\u7814\u7a76\u4e2d\u53c2\u4e0e\u8005\u7684\u590d\u8ff0\u4fdd\u771f\u5ea6\u968f\u5c1d\u8bd5\u6b21\u6570\u63d0\u9ad8\uff0c\u80fd\u6355\u6349\u7528\u6237\u5173\u6ce8\u70b9\u7684\u8868\u5c42\u548c\u8bed\u4e49\u5c42\u9762\u3002\u4f46\u4eba-PerspectiveCoach\u7684\u590d\u8ff0\u57fa\u7ebf\u4f4e\u4e8e\u4eba-\u4eba\u5bf9\u8bdd\uff0c\u53cd\u6620\u4e86\u975e\u4eba\u9645\u548c\u4eba\u9645\u89c6\u89d2\u8bad\u7ec3\u7684\u60c5\u5883\u5dee\u5f02\u3002\u53c2\u4e0e\u8005\u5bf9\u5de5\u5177\u7684\u53ef\u7528\u6027\u548c\u76f8\u5173\u6027\u8bc4\u4ef7\u5f88\u9ad8\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u7ec8\u7aef\u7528\u6237\u89c6\u89d2\u8bad\u7ec3\u63d0\u4f9b\u4e86\u63a2\u7d22\u6027\u8bbe\u8ba1\uff0c\u652f\u6301\u6279\u5224\u6027\u4f26\u7406\u81ea\u6211\u53cd\u601d\u3002\u63d0\u4f9b\u4e86\u5b9e\u8bc1\u89c1\u89e3\uff08\u5982\u589e\u5f3a\u9002\u5e94\u6027\u3001\u5173\u6ce8\u591a\u5143\u6027\uff09\uff0c\u8868\u660e\u6b64\u7c7b\u5de5\u5177\u80fd\u5e2e\u52a9\u4ece\u4e1a\u8005\u6784\u5efa\u66f4\u5177\u5305\u5bb9\u6027\u548c\u793e\u4f1a\u54cd\u5e94\u6027\u7684\u6280\u672f\u3002"}}
{"id": "2601.02563", "categories": ["cs.SE", "cs.CL", "cs.LG", "cs.PL"], "pdf": "https://arxiv.org/pdf/2601.02563", "abs": "https://arxiv.org/abs/2601.02563", "authors": ["Viacheslav Siniaev", "Iaroslav Chelombitko", "Aleksey Komissarov"], "title": "Compressed code: the hidden effects of quantization and distillation on programming tokens", "comment": "18 pages, 1 figure and 6 tables", "summary": "Large Language Models (LLMs) have demonstrated exceptional code generation capabilities, yet their token-level mechanisms remain underexplored, particularly in compressed models. Through systematic analysis of programming language token representations, we characterize how programming languages are encoded in LLM tokenizers by analyzing their vocabulary distribution and keyword coverage patterns. We introduce a novel cold-start probability analysis method that provides insights into model behavior without requiring explicit prompts. Additionally, we present a comprehensive evaluation of how different model optimization techniques - including quantization, distillation, model scaling, and task-specific fine-tuning - affect token-level representations and code generation quality. Our experiments, supported by comprehensive probability distribution analysis and evaluation metrics, reveal critical insights into token-level behavior and provide empirically-validated guidelines for maintaining code generation quality under various optimization constraints. These findings advance both theoretical understanding of LLM code generation and practical implementation of optimized models in production environments.", "AI": {"tldr": "\u8be5\u8bba\u6587\u901a\u8fc7\u5206\u6790LLM\u4e2d\u7f16\u7a0b\u8bed\u8a00\u7684token\u8868\u793a\uff0c\u7814\u7a76\u4e86\u538b\u7f29\u6a21\u578b\u4e2d\u7684token\u7ea7\u673a\u5236\uff0c\u63d0\u51fa\u4e86\u51b7\u542f\u52a8\u6982\u7387\u5206\u6790\u65b9\u6cd5\uff0c\u5e76\u8bc4\u4f30\u4e86\u4e0d\u540c\u4f18\u5316\u6280\u672f\u5bf9\u4ee3\u7801\u751f\u6210\u8d28\u91cf\u7684\u5f71\u54cd\u3002", "motivation": "\u5c3d\u7ba1\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4ee3\u7801\u751f\u6210\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5176token\u7ea7\u673a\u5236\uff0c\u7279\u522b\u662f\u5728\u538b\u7f29\u6a21\u578b\u4e2d\uff0c\u4ecd\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\u3002\u9700\u8981\u7406\u89e3\u7f16\u7a0b\u8bed\u8a00\u5728LLM tokenizer\u4e2d\u7684\u7f16\u7801\u65b9\u5f0f\uff0c\u4ee5\u53ca\u4e0d\u540c\u4f18\u5316\u6280\u672f\u5982\u4f55\u5f71\u54cdtoken\u7ea7\u8868\u793a\u548c\u4ee3\u7801\u751f\u6210\u8d28\u91cf\u3002", "method": "1. \u7cfb\u7edf\u5206\u6790\u7f16\u7a0b\u8bed\u8a00token\u8868\u793a\uff0c\u901a\u8fc7\u8bcd\u6c47\u5206\u5e03\u548c\u5173\u952e\u8bcd\u8986\u76d6\u6a21\u5f0f\u6765\u8868\u5f81\u7f16\u7a0b\u8bed\u8a00\u5728LLM tokenizer\u4e2d\u7684\u7f16\u7801\u65b9\u5f0f\uff1b2. \u5f15\u5165\u65b0\u9896\u7684\u51b7\u542f\u52a8\u6982\u7387\u5206\u6790\u65b9\u6cd5\uff0c\u65e0\u9700\u663e\u5f0f\u63d0\u793a\u5373\u53ef\u6d1e\u5bdf\u6a21\u578b\u884c\u4e3a\uff1b3. \u5168\u9762\u8bc4\u4f30\u91cf\u5316\u3001\u84b8\u998f\u3001\u6a21\u578b\u7f29\u653e\u548c\u4efb\u52a1\u7279\u5b9a\u5fae\u8c03\u7b49\u4e0d\u540c\u4f18\u5316\u6280\u672f\u5bf9token\u7ea7\u8868\u793a\u548c\u4ee3\u7801\u751f\u6210\u8d28\u91cf\u7684\u5f71\u54cd\u3002", "result": "\u901a\u8fc7\u5168\u9762\u7684\u6982\u7387\u5206\u5e03\u5206\u6790\u548c\u8bc4\u4f30\u6307\u6807\uff0c\u5b9e\u9a8c\u63ed\u793a\u4e86token\u7ea7\u884c\u4e3a\u7684\u5173\u952e\u6d1e\u5bdf\uff0c\u5e76\u4e3a\u5728\u5404\u79cd\u4f18\u5316\u7ea6\u675f\u4e0b\u4fdd\u6301\u4ee3\u7801\u751f\u6210\u8d28\u91cf\u63d0\u4f9b\u4e86\u7ecf\u9a8c\u9a8c\u8bc1\u7684\u6307\u5bfc\u539f\u5219\u3002", "conclusion": "\u8fd9\u4e9b\u53d1\u73b0\u4e0d\u4ec5\u63a8\u8fdb\u4e86\u5bf9LLM\u4ee3\u7801\u751f\u6210\u7684\u7406\u8bba\u7406\u89e3\uff0c\u8fd8\u4e3a\u5728\u751f\u4ea7\u73af\u5883\u4e2d\u5b9e\u65bd\u4f18\u5316\u6a21\u578b\u63d0\u4f9b\u4e86\u5b9e\u7528\u6307\u5bfc\u3002"}}
{"id": "2601.02601", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.02601", "abs": "https://arxiv.org/abs/2601.02601", "authors": ["Nazanin Siavash", "Armin Moin"], "title": "State of the Quantum Software Engineering Ecosystem", "comment": null, "summary": "We study the current state of the Quantum Software Engineering (QSE) ecosystem, focusing on the achievements, activities, and engagements from academia and industry, with a special focus on successful entrepreneurial endeavors in this arena. Our research methodology is a novel one, featuring the state-of-the-art in Artificial Intelligence (AI), namely Large Language Models (LLMs), especially Generative Pretrained Transformers (GPT). We use one of such models, namely the OpenAI GPT-5 model, through the ChatGPT tool. The goal is to identify institutions and companies that are highly active and have achieved distinguished results in QSE, evidenced by peer-reviewed publications or raised capital in the venture capital market.", "AI": {"tldr": "\u8be5\u7814\u7a76\u4f7f\u7528GPT-5\u5206\u6790\u91cf\u5b50\u8f6f\u4ef6\u5de5\u7a0b\u751f\u6001\u7cfb\u7edf\u73b0\u72b6\uff0c\u8bc6\u522b\u5b66\u672f\u754c\u548c\u5de5\u4e1a\u754c\u4e2d\u5728\u8be5\u9886\u57df\u53d6\u5f97\u663e\u8457\u6210\u679c\u7684\u6d3b\u8dc3\u673a\u6784\u548c\u4f01\u4e1a", "motivation": "\u7814\u7a76\u91cf\u5b50\u8f6f\u4ef6\u5de5\u7a0b\u751f\u6001\u7cfb\u7edf\u7684\u5f53\u524d\u72b6\u6001\uff0c\u7279\u522b\u5173\u6ce8\u5b66\u672f\u754c\u548c\u5de5\u4e1a\u754c\u7684\u6210\u5c31\u3001\u6d3b\u52a8\u548c\u53c2\u4e0e\uff0c\u5c24\u5176\u662f\u6210\u529f\u7684\u521b\u4e1a\u4f01\u4e1a\u3002\u65e8\u5728\u4e86\u89e3\u8be5\u9886\u57df\u7684\u53d1\u5c55\u73b0\u72b6\u548c\u5173\u952e\u53c2\u4e0e\u8005\u3002", "method": "\u91c7\u7528\u65b0\u9896\u7684\u7814\u7a76\u65b9\u6cd5\uff0c\u5229\u7528\u6700\u5148\u8fdb\u7684\u4eba\u5de5\u667a\u80fd\u6280\u672f\u2014\u2014\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08\u7279\u522b\u662fGPT-5\uff09\uff0c\u901a\u8fc7ChatGPT\u5de5\u5177\u8fdb\u884c\u5206\u6790\u3002\u901a\u8fc7\u8bc6\u522b\u5728\u91cf\u5b50\u8f6f\u4ef6\u5de5\u7a0b\u9886\u57df\u9ad8\u5ea6\u6d3b\u8dc3\u4e14\u53d6\u5f97\u663e\u8457\u6210\u679c\u7684\u673a\u6784\u548c\u516c\u53f8\uff0c\u8fd9\u4e9b\u6210\u679c\u901a\u8fc7\u540c\u884c\u8bc4\u5ba1\u51fa\u7248\u7269\u6216\u98ce\u9669\u8d44\u672c\u5e02\u573a\u878d\u8d44\u6765\u8bc1\u660e\u3002", "result": "\u8bba\u6587\u672a\u63d0\u4f9b\u5177\u4f53\u7ed3\u679c\uff0c\u4f46\u7814\u7a76\u65b9\u6cd5\u8868\u660e\u5c06\u8bc6\u522b\u51fa\u5728\u91cf\u5b50\u8f6f\u4ef6\u5de5\u7a0b\u9886\u57df\u5177\u6709\u663e\u8457\u6210\u5c31\u7684\u673a\u6784\u548c\u516c\u53f8\uff0c\u5305\u62ec\u5b66\u672f\u673a\u6784\u548c\u6210\u529f\u83b7\u5f97\u98ce\u9669\u6295\u8d44\u7684\u4f01\u4e1a\u3002", "conclusion": "\u8be5\u7814\u7a76\u5c55\u793a\u4e86\u5229\u7528\u5148\u8fdbAI\u6280\u672f\uff08GPT-5\uff09\u5206\u6790\u65b0\u5174\u6280\u672f\u9886\u57df\u751f\u6001\u7cfb\u7edf\u7684\u521b\u65b0\u65b9\u6cd5\uff0c\u4e3a\u7406\u89e3\u91cf\u5b50\u8f6f\u4ef6\u5de5\u7a0b\u7684\u53d1\u5c55\u73b0\u72b6\u548c\u5173\u952e\u53c2\u4e0e\u8005\u63d0\u4f9b\u4e86\u65b0\u7684\u7814\u7a76\u9014\u5f84\u3002"}}
{"id": "2601.02632", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.02632", "abs": "https://arxiv.org/abs/2601.02632", "authors": ["Alireza Ezaz", "Ghazal Khodabandeh", "Majid Babaei", "Naser Ezzati-Jivan"], "title": "TAAF: A Trace Abstraction and Analysis Framework Synergizing Knowledge Graphs and LLMs", "comment": "Accepted to ICSE 2026. DOI 10.1145/3744916.3787832", "summary": "Execution traces are a critical source of information for understanding, debugging, and optimizing complex software systems. However, traces from OS kernels or large-scale applications like Chrome or MySQL are massive and difficult to analyze. Existing tools rely on predefined analyses, and custom insights often require writing domain-specific scripts, which is an error-prone and time-consuming task. This paper introduces TAAF (Trace Abstraction and Analysis Framework), a novel approach that combines time-indexing, knowledge graphs (KGs), and large language models (LLMs) to transform raw trace data into actionable insights. TAAF constructs a time-indexed KG from trace events to capture relationships among entities such as threads, CPUs, and system resources. An LLM then interprets query-specific subgraphs to answer natural-language questions, reducing the need for manual inspection and deep system expertise. To evaluate TAAF, we introduce TraceQA-100, a benchmark of 100 questions grounded in real kernel traces. Experiments across three LLMs and multiple temporal settings show that TAAF improves answer accuracy by up to 31.2%, particularly in multi-hop and causal reasoning tasks. We further analyze where graph-grounded reasoning helps and where limitations remain, offering a foundation for next-generation trace analysis tools.", "AI": {"tldr": "TAAF\u6846\u67b6\u7ed3\u5408\u65f6\u95f4\u7d22\u5f15\u77e5\u8bc6\u56fe\u8c31\u548cLLM\uff0c\u5c06\u539f\u59cb\u6267\u884c\u8f68\u8ff9\u6570\u636e\u8f6c\u5316\u4e3a\u53ef\u64cd\u4f5c\u7684\u6d1e\u5bdf\uff0c\u663e\u8457\u63d0\u5347\u8f68\u8ff9\u5206\u6790\u51c6\u786e\u7387", "motivation": "\u64cd\u4f5c\u7cfb\u7edf\u5185\u6838\u6216\u5927\u578b\u5e94\u7528\uff08\u5982Chrome\u3001MySQL\uff09\u7684\u6267\u884c\u8f68\u8ff9\u6570\u636e\u91cf\u5de8\u5927\u4e14\u96be\u4ee5\u5206\u6790\uff0c\u73b0\u6709\u5de5\u5177\u4f9d\u8d56\u9884\u5b9a\u4e49\u5206\u6790\uff0c\u81ea\u5b9a\u4e49\u6d1e\u5bdf\u9700\u8981\u7f16\u5199\u5bb9\u6613\u51fa\u9519\u4e14\u8017\u65f6\u7684\u9886\u57df\u7279\u5b9a\u811a\u672c", "method": "\u63d0\u51faTAAF\u6846\u67b6\uff0c\u7ed3\u5408\u65f6\u95f4\u7d22\u5f15\u3001\u77e5\u8bc6\u56fe\u8c31\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff1a1\uff09\u4ece\u8f68\u8ff9\u4e8b\u4ef6\u6784\u5efa\u65f6\u95f4\u7d22\u5f15\u77e5\u8bc6\u56fe\u8c31\uff0c\u6355\u6349\u7ebf\u7a0b\u3001CPU\u3001\u7cfb\u7edf\u8d44\u6e90\u7b49\u5b9e\u4f53\u5173\u7cfb\uff1b2\uff09\u4f7f\u7528LLM\u89e3\u91ca\u67e5\u8be2\u7279\u5b9a\u5b50\u56fe\u6765\u56de\u7b54\u81ea\u7136\u8bed\u8a00\u95ee\u9898", "result": "\u5f15\u5165TraceQA-100\u57fa\u51c6\u6d4b\u8bd5\uff08100\u4e2a\u57fa\u4e8e\u771f\u5b9e\u5185\u6838\u8f68\u8ff9\u7684\u95ee\u9898\uff09\uff0c\u5b9e\u9a8c\u663e\u793aTAAF\u5728\u4e09\u4e2aLLM\u548c\u591a\u79cd\u65f6\u95f4\u8bbe\u7f6e\u4e0b\uff0c\u7b54\u6848\u51c6\u786e\u7387\u63d0\u5347\u9ad8\u8fbe31.2%\uff0c\u5728\u591a\u8df3\u548c\u56e0\u679c\u63a8\u7406\u4efb\u52a1\u4e2d\u8868\u73b0\u5c24\u5176\u7a81\u51fa", "conclusion": "TAAF\u51cf\u5c11\u4e86\u624b\u52a8\u68c0\u67e5\u548c\u6df1\u5ea6\u7cfb\u7edf\u4e13\u4e1a\u77e5\u8bc6\u7684\u9700\u6c42\uff0c\u5206\u6790\u4e86\u56fe\u57fa\u7840\u63a8\u7406\u7684\u4f18\u52bf\u548c\u5c40\u9650\u6027\uff0c\u4e3a\u4e0b\u4e00\u4ee3\u8f68\u8ff9\u5206\u6790\u5de5\u5177\u5960\u5b9a\u4e86\u57fa\u7840"}}
{"id": "2601.02698", "categories": ["cs.SE", "cs.CR"], "pdf": "https://arxiv.org/pdf/2601.02698", "abs": "https://arxiv.org/abs/2601.02698", "authors": ["Manideep Reddy Chinthareddy"], "title": "Enterprise Identity Integration for AI-Assisted Developer Services: Architecture, Implementation, and Case Study", "comment": "11 pages, 3 Figures", "summary": "AI-assisted developer services are increasingly embedded in modern IDEs, yet enterprises must ensure these tools operate within existing identity, access control, and governance requirements. The Model Context Protocol (MCP) enables AI assistants to retrieve structured internal context, but its specification provides only a minimal authorization model and lacks guidance on integrating enterprise SSO. This article presents a practical architecture that incorporates OAuth 2.0 and OpenID Connect (OIDC) into MCP-enabled developer environments. It describes how IDE extensions obtain and present tokens, how MCP servers validate them through an identity provider, and how scopes and claims can enforce least-privilege access. A prototype implementation using Visual Studio Code, a Python-based MCP server, and an OIDC-compliant IdP demonstrates feasibility. A case study evaluates authentication latency, token-validation overhead, operational considerations, and AI-specific risks. The approach provides a deployable pattern for organizations adopting AI-assisted developer tools while maintaining identity assurance and auditability.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5c06OAuth 2.0\u548cOpenID Connect\u96c6\u6210\u5230MCP\u5f00\u53d1\u8005\u73af\u5883\u4e2d\u7684\u4f01\u4e1a\u7ea7\u8eab\u4efd\u9a8c\u8bc1\u67b6\u6784\uff0c\u4ee5\u89e3\u51b3AI\u8f85\u52a9\u5f00\u53d1\u5de5\u5177\u5728\u4f01\u4e1a\u73af\u5883\u4e2d\u7684\u8eab\u4efd\u7ba1\u7406\u548c\u8bbf\u95ee\u63a7\u5236\u95ee\u9898\u3002", "motivation": "\u968f\u7740AI\u8f85\u52a9\u5f00\u53d1\u670d\u52a1\u5728\u73b0\u4ee3IDE\u4e2d\u7684\u666e\u53ca\uff0c\u4f01\u4e1a\u9700\u8981\u786e\u4fdd\u8fd9\u4e9b\u5de5\u5177\u7b26\u5408\u73b0\u6709\u7684\u8eab\u4efd\u7ba1\u7406\u3001\u8bbf\u95ee\u63a7\u5236\u548c\u6cbb\u7406\u8981\u6c42\u3002MCP\u534f\u8bae\u867d\u7136\u80fd\u8ba9AI\u52a9\u624b\u83b7\u53d6\u7ed3\u6784\u5316\u5185\u90e8\u4e0a\u4e0b\u6587\uff0c\u4f46\u5176\u6388\u6743\u6a21\u578b\u8fc7\u4e8e\u7b80\u5355\uff0c\u4e14\u7f3a\u4e4f\u4f01\u4e1aSSO\u96c6\u6210\u6307\u5bfc\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5b9e\u8df5\u67b6\u6784\uff0c\u5c06OAuth 2.0\u548cOpenID Connect\u96c6\u6210\u5230MCP\u5f00\u53d1\u8005\u73af\u5883\u4e2d\u3002\u5177\u4f53\u5305\u62ec\uff1aIDE\u6269\u5c55\u83b7\u53d6\u548c\u5448\u73b0\u4ee4\u724c\u3001MCP\u670d\u52a1\u5668\u901a\u8fc7\u8eab\u4efd\u63d0\u4f9b\u5546\u9a8c\u8bc1\u4ee4\u724c\u3001\u4f7f\u7528\u8303\u56f4\u548c\u58f0\u660e\u5b9e\u65bd\u6700\u5c0f\u6743\u9650\u8bbf\u95ee\u3002\u901a\u8fc7Visual Studio Code\u3001Python MCP\u670d\u52a1\u5668\u548cOIDC\u517c\u5bb9\u7684\u8eab\u4efd\u63d0\u4f9b\u5546\u6784\u5efa\u4e86\u539f\u578b\u5b9e\u73b0\u3002", "result": "\u539f\u578b\u9a8c\u8bc1\u4e86\u65b9\u6848\u7684\u53ef\u884c\u6027\uff0c\u5e76\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u8bc4\u4f30\u4e86\u8ba4\u8bc1\u5ef6\u8fdf\u3001\u4ee4\u724c\u9a8c\u8bc1\u5f00\u9500\u3001\u8fd0\u7ef4\u8003\u8651\u56e0\u7d20\u548cAI\u7279\u5b9a\u98ce\u9669\u3002\u8be5\u67b6\u6784\u4e3a\u7ec4\u7ec7\u91c7\u7528AI\u8f85\u52a9\u5f00\u53d1\u5de5\u5177\u63d0\u4f9b\u4e86\u53ef\u90e8\u7f72\u7684\u6a21\u5f0f\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u8eab\u4efd\u4fdd\u8bc1\u548c\u53ef\u5ba1\u8ba1\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u4f9b\u4e86\u4e00\u79cd\u5b9e\u7528\u7684\u4f01\u4e1a\u7ea7\u89e3\u51b3\u65b9\u6848\uff0c\u4f7f\u7ec4\u7ec7\u80fd\u591f\u5728\u91c7\u7528AI\u8f85\u52a9\u5f00\u53d1\u5de5\u5177\u7684\u540c\u65f6\uff0c\u6ee1\u8db3\u8eab\u4efd\u7ba1\u7406\u3001\u8bbf\u95ee\u63a7\u5236\u548c\u6cbb\u7406\u8981\u6c42\uff0c\u586b\u8865\u4e86MCP\u5728\u4f01\u4e1a\u8eab\u4efd\u9a8c\u8bc1\u96c6\u6210\u65b9\u9762\u7684\u7a7a\u767d\u3002"}}
{"id": "2601.02732", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.02732", "abs": "https://arxiv.org/abs/2601.02732", "authors": ["Lingzhe Zhang", "Tong Jia", "Yunpeng Zhai", "Leyi Pan", "Chiming Duan", "Minghua He", "Mengxi Jia", "Ying Li"], "title": "Agentic Memory Enhanced Recursive Reasoning for Root Cause Localization in Microservices", "comment": "accepted by ICSE-SEIP'26", "summary": "As contemporary microservice systems become increasingly popular and complex-often comprising hundreds or even thousands of fine-grained, interdependent subsystems-they are experiencing more frequent failures. Ensuring system reliability thus demands accurate root cause localization. While many traditional graph-based and deep learning approaches have been explored for this task, they often rely heavily on pre-defined schemas that struggle to adapt to evolving operational contexts. Consequently, a number of LLM-based methods have recently been proposed. However, these methods still face two major limitations: shallow, symptom-centric reasoning that undermines accuracy, and a lack of cross-alert reuse that leads to redundant reasoning and high latency. In this paper, we conduct a comprehensive study of how Site Reliability Engineers (SREs) localize the root causes of failures, drawing insights from professionals across multiple organizations. Our investigation reveals that expert root cause analysis exhibits three key characteristics: recursiveness, multi-dimensional expansion, and cross-modal reasoning. Motivated by these findings, we introduce AMER-RCL, an agentic memory enhanced recursive reasoning framework for root cause localization in microservices. AMER-RCL employs the Recursive Reasoning RCL engine, a multi-agent framework that performs recursive reasoning on each alert to progressively refine candidate causes, while Agentic Memory incrementally accumulates and reuses reasoning from prior alerts within a time window to reduce redundant exploration and lower inference latency. Experimental results demonstrate that AMER-RCL consistently outperforms state-of-the-art methods in both localization accuracy and inference efficiency.", "AI": {"tldr": "AMER-RCL\uff1a\u4e00\u79cd\u57fa\u4e8e\u667a\u80fd\u4f53\u8bb0\u5fc6\u589e\u5f3a\u7684\u9012\u5f52\u63a8\u7406\u6846\u67b6\uff0c\u7528\u4e8e\u5fae\u670d\u52a1\u7cfb\u7edf\u4e2d\u7684\u6839\u56e0\u5b9a\u4f4d\uff0c\u901a\u8fc7\u9012\u5f52\u63a8\u7406\u548c\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u63d0\u9ad8\u51c6\u786e\u6027\uff0c\u5229\u7528\u667a\u80fd\u4f53\u8bb0\u5fc6\u51cf\u5c11\u5197\u4f59\u63a8\u7406\u964d\u4f4e\u5ef6\u8fdf\u3002", "motivation": "\u968f\u7740\u5fae\u670d\u52a1\u7cfb\u7edf\u65e5\u76ca\u590d\u6742\uff0c\u6545\u969c\u9891\u53d1\uff0c\u73b0\u6709\u6839\u56e0\u5b9a\u4f4d\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\u6027\uff1a\u4f20\u7edf\u56fe\u57fa\u548c\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u4f9d\u8d56\u9884\u5b9a\u4e49\u6a21\u5f0f\u96be\u4ee5\u9002\u5e94\u52a8\u6001\u73af\u5883\uff0c\u800c\u57fa\u4e8eLLM\u7684\u65b9\u6cd5\u5b58\u5728\u6d45\u5c42\u75c7\u72b6\u63a8\u7406\u548c\u7f3a\u4e4f\u8de8\u544a\u8b66\u91cd\u7528\u7684\u95ee\u9898\uff0c\u5bfc\u81f4\u51c6\u786e\u6027\u4e0d\u8db3\u548c\u5ef6\u8fdf\u9ad8\u3002", "method": "AMER-RCL\u6846\u67b6\u5305\u542b\u4e24\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1a1\uff09\u9012\u5f52\u63a8\u7406RCL\u5f15\u64ce\uff0c\u91c7\u7528\u591a\u667a\u80fd\u4f53\u6846\u67b6\u5bf9\u6bcf\u4e2a\u544a\u8b66\u8fdb\u884c\u9012\u5f52\u63a8\u7406\uff0c\u9010\u6b65\u7ec6\u5316\u5019\u9009\u539f\u56e0\uff1b2\uff09\u667a\u80fd\u4f53\u8bb0\u5fc6\uff0c\u5728\u65f6\u95f4\u7a97\u53e3\u5185\u589e\u91cf\u79ef\u7d2f\u548c\u91cd\u7528\u5148\u524d\u544a\u8b66\u7684\u63a8\u7406\u7ed3\u679c\uff0c\u51cf\u5c11\u5197\u4f59\u63a2\u7d22\u5e76\u964d\u4f4e\u63a8\u7406\u5ef6\u8fdf\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cAMER-RCL\u5728\u5b9a\u4f4d\u51c6\u786e\u6027\u548c\u63a8\u7406\u6548\u7387\u65b9\u9762\u5747\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\u3002", "conclusion": "\u901a\u8fc7\u6a21\u62dfSRE\u4e13\u5bb6\u7684\u9012\u5f52\u3001\u591a\u7ef4\u6269\u5c55\u548c\u8de8\u6a21\u6001\u63a8\u7406\u7279\u6027\uff0cAMER-RCL\u6846\u67b6\u80fd\u591f\u6709\u6548\u89e3\u51b3\u5fae\u670d\u52a1\u7cfb\u7edf\u4e2d\u6839\u56e0\u5b9a\u4f4d\u7684\u51c6\u786e\u6027\u548c\u6548\u7387\u95ee\u9898\uff0c\u4e3a\u590d\u6742\u7cfb\u7edf\u7684\u53ef\u9760\u6027\u4fdd\u969c\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2601.02736", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.02736", "abs": "https://arxiv.org/abs/2601.02736", "authors": ["Lingzhe Zhang", "Tong Jia", "Yunpeng Zhai", "Leyi Pan", "Chiming Duan", "Minghua He", "Pei Xiao", "Ying Li"], "title": "Hypothesize-Then-Verify: Speculative Root Cause Analysis for Microservices with Pathwise Parallelism", "comment": "accepted by ICSE-NIER'26", "summary": "Microservice systems have become the backbone of cloud-native enterprise applications due to their resource elasticity, loosely coupled architecture, and lightweight deployment. Yet, the intrinsic complexity and dynamic runtime interactions of such systems inevitably give rise to anomalies. Ensuring system reliability therefore hinges on effective root cause analysis (RCA), which entails not only localizing the source of anomalies but also characterizing the underlying failures in a timely and interpretable manner. Recent advances in intelligent RCA techniques, particularly those powered by large language models (LLMs), have demonstrated promising capabilities, as LLMs reduce reliance on handcrafted features while offering cross-platform adaptability, task generalization, and flexibility. However, existing LLM-based methods still suffer from two critical limitations: (a) limited exploration diversity, which undermines accuracy, and (b) heavy dependence on large-scale LLMs, which results in slow inference. To overcome these challenges, we propose SpecRCA, a speculative root cause analysis framework for microservices that adopts a \\textit{hypothesize-then-verify} paradigm. SpecRCA first leverages a hypothesis drafting module to rapidly generate candidate root causes, and then employs a parallel root cause verifier to efficiently validate them. Preliminary experiments on the AIOps 2022 dataset demonstrate that SpecRCA achieves superior accuracy and efficiency compared to existing approaches, highlighting its potential as a practical solution for scalable and interpretable RCA in complex microservice environments.", "AI": {"tldr": "SpecRCA\uff1a\u57fa\u4e8e\u63a8\u6d4b\u63a8\u7406\u7684\u5fae\u670d\u52a1\u6839\u56e0\u5206\u6790\u6846\u67b6\uff0c\u91c7\u7528\"\u5047\u8bbe-\u9a8c\u8bc1\"\u8303\u5f0f\uff0c\u901a\u8fc7\u5047\u8bbe\u8349\u7a3f\u6a21\u5757\u5feb\u901f\u751f\u6210\u5019\u9009\u6839\u56e0\uff0c\u5e76\u884c\u9a8c\u8bc1\u5668\u9ad8\u6548\u9a8c\u8bc1\uff0c\u5728\u51c6\u786e\u6027\u548c\u6548\u7387\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u5fae\u670d\u52a1\u7cfb\u7edf\u5df2\u6210\u4e3a\u4e91\u539f\u751f\u4f01\u4e1a\u5e94\u7528\u7684\u652f\u67f1\uff0c\u4f46\u5176\u5185\u5728\u590d\u6742\u6027\u548c\u52a8\u6001\u8fd0\u884c\u65f6\u4ea4\u4e92\u4e0d\u53ef\u907f\u514d\u5730\u5bfc\u81f4\u5f02\u5e38\u3002\u73b0\u6709\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u6839\u56e0\u5206\u6790\u65b9\u6cd5\u5b58\u5728\u4e24\u4e2a\u5173\u952e\u9650\u5236\uff1a\u63a2\u7d22\u591a\u6837\u6027\u6709\u9650\u5f71\u54cd\u51c6\u786e\u6027\uff0c\u4f9d\u8d56\u5927\u89c4\u6a21LLM\u5bfc\u81f4\u63a8\u7406\u901f\u5ea6\u6162\u3002", "method": "\u63d0\u51faSpecRCA\u6846\u67b6\uff0c\u91c7\u7528\"\u5047\u8bbe-\u9a8c\u8bc1\"\u8303\u5f0f\uff1a1\uff09\u5047\u8bbe\u8349\u7a3f\u6a21\u5757\u5feb\u901f\u751f\u6210\u5019\u9009\u6839\u56e0\uff1b2\uff09\u5e76\u884c\u6839\u56e0\u9a8c\u8bc1\u5668\u9ad8\u6548\u9a8c\u8bc1\u5019\u9009\u6839\u56e0\u3002\u8be5\u6846\u67b6\u51cf\u5c11\u5bf9\u5927\u89c4\u6a21LLM\u7684\u4f9d\u8d56\uff0c\u63d0\u9ad8\u63a2\u7d22\u591a\u6837\u6027\u3002", "result": "\u5728AIOps 2022\u6570\u636e\u96c6\u4e0a\u7684\u521d\u6b65\u5b9e\u9a8c\u8868\u660e\uff0cSpecRCA\u5728\u51c6\u786e\u6027\u548c\u6548\u7387\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5c55\u793a\u4e86\u5176\u5728\u590d\u6742\u5fae\u670d\u52a1\u73af\u5883\u4e2d\u4f5c\u4e3a\u53ef\u6269\u5c55\u3001\u53ef\u89e3\u91ca\u6839\u56e0\u5206\u6790\u89e3\u51b3\u65b9\u6848\u7684\u6f5c\u529b\u3002", "conclusion": "SpecRCA\u901a\u8fc7\u521b\u65b0\u7684\u63a8\u6d4b\u63a8\u7406\u65b9\u6cd5\u514b\u670d\u4e86\u73b0\u6709LLM\u57fa\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u5fae\u670d\u52a1\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u79cd\u5b9e\u7528\u3001\u9ad8\u6548\u4e14\u53ef\u89e3\u91ca\u7684\u6839\u56e0\u5206\u6790\u89e3\u51b3\u65b9\u6848\uff0c\u6709\u671b\u63d0\u5347\u4e91\u539f\u751f\u5e94\u7528\u7684\u53ef\u9760\u6027\u3002"}}
{"id": "2601.02868", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.02868", "abs": "https://arxiv.org/abs/2601.02868", "authors": ["Peiding Wang", "Li Zhang", "Fang Liu", "Chongyang Tao", "Yinghao Zhu"], "title": "CodeMEM: AST-Guided Adaptive Memory for Repository-Level Iterative Code Generation", "comment": "preprint", "summary": "Large language models (LLMs) substantially enhance developer productivity in repository-level code generation through interactive collaboration. However, as interactions progress, repository context must be continuously preserved and updated to integrate newly validated information. Meanwhile, the expanding session history increases cognitive burden, often leading to forgetting and the reintroduction of previously resolved errors. Existing memory management approaches show promise but remain limited by natural language-centric representations. To overcome these limitations, we propose CodeMEM, an AST-guided dynamic memory management system tailored for repository-level iterative code generation. Specifically, CodeMEM introduces the Code Context Memory component that dynamically maintains and updates repository context through AST-guided LLM operations, along with the Code Session Memory that constructs a code-centric representation of interaction history and explicitly detects and mitigates forgetting through AST-based analysis. Experimental results on the instruction-following benchmark CodeIF-Bench and the code generation benchmark CoderEval demonstrate that CodeMEM achieves state-of-the-art performance, improving instruction following by 12.2% for the current turn and 11.5% for the session level, and reducing interaction rounds by 2-3, while maintaining competitive inference latency and token efficiency.", "AI": {"tldr": "CodeMEM\uff1a\u57fa\u4e8eAST\u7684\u52a8\u6001\u5185\u5b58\u7ba1\u7406\u7cfb\u7edf\uff0c\u7528\u4e8e\u4ed3\u5e93\u7ea7\u8fed\u4ee3\u4ee3\u7801\u751f\u6210\uff0c\u901a\u8fc7AST\u5f15\u5bfc\u7684LLM\u64cd\u4f5c\u7ef4\u62a4\u4ee3\u7801\u4e0a\u4e0b\u6587\uff0c\u51cf\u5c11\u9057\u5fd8\u548c\u91cd\u590d\u9519\u8bef\uff0c\u63d0\u5347\u5f00\u53d1\u6548\u7387", "motivation": "\u73b0\u6709LLM\u5728\u4ed3\u5e93\u7ea7\u4ee3\u7801\u751f\u6210\u4e2d\u9762\u4e34\u4e0a\u4e0b\u6587\u7ef4\u62a4\u56f0\u96be\uff1a\u968f\u7740\u4ea4\u4e92\u8fdb\u884c\uff0c\u4ed3\u5e93\u4e0a\u4e0b\u6587\u9700\u8981\u6301\u7eed\u66f4\u65b0\uff0c\u540c\u65f6\u6269\u5927\u7684\u4f1a\u8bdd\u5386\u53f2\u589e\u52a0\u8ba4\u77e5\u8d1f\u62c5\uff0c\u5bfc\u81f4\u9057\u5fd8\u548c\u5df2\u89e3\u51b3\u9519\u8bef\u7684\u91cd\u590d\u51fa\u73b0\u3002\u73b0\u6709\u57fa\u4e8e\u81ea\u7136\u8bed\u8a00\u7684\u5185\u5b58\u7ba1\u7406\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\u6027\u3002", "method": "\u63d0\u51faCodeMEM\u7cfb\u7edf\uff0c\u5305\u542b\u4e24\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1a1) Code Context Memory\uff1a\u901a\u8fc7AST\u5f15\u5bfc\u7684LLM\u64cd\u4f5c\u52a8\u6001\u7ef4\u62a4\u548c\u66f4\u65b0\u4ed3\u5e93\u4e0a\u4e0b\u6587\uff1b2) Code Session Memory\uff1a\u6784\u5efa\u4ee5\u4ee3\u7801\u4e3a\u4e2d\u5fc3\u7684\u4ea4\u4e92\u5386\u53f2\u8868\u793a\uff0c\u901a\u8fc7AST\u5206\u6790\u663e\u5f0f\u68c0\u6d4b\u548c\u7f13\u89e3\u9057\u5fd8\u95ee\u9898\u3002", "result": "\u5728CodeIF-Bench\u548cCoderEval\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\uff1a\u6307\u4ee4\u9075\u5faa\u7387\u63d0\u534712.2%\uff08\u5f53\u524d\u8f6e\u6b21\uff09\u548c11.5%\uff08\u4f1a\u8bdd\u7ea7\u522b\uff09\uff0c\u4ea4\u4e92\u8f6e\u6b21\u51cf\u5c112-3\u8f6e\uff0c\u540c\u65f6\u4fdd\u6301\u6709\u7ade\u4e89\u529b\u7684\u63a8\u7406\u5ef6\u8fdf\u548ctoken\u6548\u7387\u3002", "conclusion": "CodeMEM\u901a\u8fc7AST\u5f15\u5bfc\u7684\u52a8\u6001\u5185\u5b58\u7ba1\u7406\u6709\u6548\u89e3\u51b3\u4e86\u4ed3\u5e93\u7ea7\u4ee3\u7801\u751f\u6210\u4e2d\u7684\u4e0a\u4e0b\u6587\u7ef4\u62a4\u548c\u9057\u5fd8\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86LLM\u5728\u8fed\u4ee3\u5f00\u53d1\u4e2d\u7684\u6548\u7387\u548c\u51c6\u786e\u6027\u3002"}}
{"id": "2601.02971", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.02971", "abs": "https://arxiv.org/abs/2601.02971", "authors": ["Muhammad Laiq"], "title": "Few-shot learning for security bug report identification", "comment": null, "summary": "Security bug reports require prompt identification to minimize the window of vulnerability in software systems. Traditional machine learning (ML) techniques for classifying bug reports to identify security bug reports rely heavily on large amounts of labeled data. However, datasets for security bug reports are often scarce in practice, leading to poor model performance and limited applicability in real-world settings. In this study, we propose a few-shot learning-based technique to effectively identify security bug reports using limited labeled data. We employ SetFit, a state-of-the-art few-shot learning framework that combines sentence transformers with contrastive learning and parameter-efficient fine-tuning. The model is trained on a small labeled dataset of bug reports and is evaluated on its ability to classify these reports as either security-related or non-security-related. Our approach achieves an AUC of 0.865, at best, outperforming traditional ML techniques (baselines) for all of the evaluated datasets. This highlights the potential of SetFit to effectively identify security bug reports. SetFit-based few-shot learning offers a promising alternative to traditional ML techniques to identify security bug reports. The approach enables efficient model development with minimal annotation effort, making it highly suitable for scenarios where labeled data is scarce.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u5c11\u6837\u672c\u5b66\u4e60\u7684SetFit\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u6807\u6ce8\u6570\u636e\u7a00\u7f3a\u7684\u60c5\u51b5\u4e0b\u6709\u6548\u8bc6\u522b\u5b89\u5168\u6f0f\u6d1e\u62a5\u544a\uff0c\u76f8\u6bd4\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u8868\u73b0\u66f4\u4f18\u3002", "motivation": "\u5b89\u5168\u6f0f\u6d1e\u62a5\u544a\u9700\u8981\u53ca\u65f6\u8bc6\u522b\u4ee5\u964d\u4f4e\u8f6f\u4ef6\u7cfb\u7edf\u98ce\u9669\uff0c\u4f46\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u4f9d\u8d56\u5927\u91cf\u6807\u6ce8\u6570\u636e\uff0c\u800c\u5b9e\u9645\u4e2d\u5b89\u5168\u6f0f\u6d1e\u62a5\u544a\u6570\u636e\u96c6\u5f80\u5f80\u7a00\u7f3a\uff0c\u5bfc\u81f4\u6a21\u578b\u6027\u80fd\u5dee\u4e14\u5b9e\u9645\u5e94\u7528\u53d7\u9650\u3002", "method": "\u91c7\u7528SetFit\u5c11\u6837\u672c\u5b66\u4e60\u6846\u67b6\uff0c\u7ed3\u5408\u53e5\u5b50\u8f6c\u6362\u5668\u548c\u5bf9\u6bd4\u5b66\u4e60\uff0c\u901a\u8fc7\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\uff0c\u5728\u5c11\u91cf\u6807\u6ce8\u7684\u6f0f\u6d1e\u62a5\u544a\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u8bad\u7ec3\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u8bc4\u4f30\u7684\u6240\u6709\u6570\u636e\u96c6\u4e0a\u5747\u4f18\u4e8e\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u57fa\u7ebf\u65b9\u6cd5\uff0c\u6700\u4f73AUC\u8fbe\u52300.865\uff0c\u5c55\u793a\u4e86SetFit\u5728\u8bc6\u522b\u5b89\u5168\u6f0f\u6d1e\u62a5\u544a\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u57fa\u4e8eSetFit\u7684\u5c11\u6837\u672c\u5b66\u4e60\u4e3a\u5b89\u5168\u6f0f\u6d1e\u62a5\u544a\u8bc6\u522b\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u80fd\u591f\u5728\u6807\u6ce8\u6570\u636e\u7a00\u7f3a\u7684\u60c5\u51b5\u4e0b\u9ad8\u6548\u5f00\u53d1\u6a21\u578b\uff0c\u9002\u5408\u5b9e\u9645\u5e94\u7528\u573a\u666f\u3002"}}
{"id": "2601.03009", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.03009", "abs": "https://arxiv.org/abs/2601.03009", "authors": ["Nek Dil Khan", "Javed Ali Khan", "Darvesh Khan", "Jianqiang Li", "Mumrez Khan", "Shah Fahad Khan"], "title": "A Dataset of Low-Rated Applications from the Amazon Appstore for User Feedback Analysis", "comment": null, "summary": "In todays digital landscape, end-user feedback plays a crucial role in the evolution of software applications, particularly in addressing issues that hinder user experience. While much research has focused on high-rated applications, low-rated applications often remain unexplored, despite their potential to reveal valuable insights. This study introduces a novel dataset curated from 64 low-rated applications sourced from the Amazon Software Appstore (ASA), containing 79,821 user reviews. The dataset is designed to capture the most frequent issues identified by users, which are critical for improving software quality. To further enhance the dataset utility, a subset of 6000 reviews was manually annotated to classify them into six district issue categories: user interface (UI) and user experience (UX), functionality and features, compatibility and device specificity, performance and stability, customer support and responsiveness, and security and privacy issues. This annotated dataset is a valuable resource for developing machine learning-based approaches aiming to automate the classification of user feedback into various issue types. Making both the annotated and raw datasets publicly available provides researchers and developers with a crucial tool to understand common issues in low-rated apps and inform software improvements. The comprehensive analysis and availability of this dataset lay the groundwork for data-derived solutions to improve software quality based on user feedback. Additionally, the dataset can provide opportunities for software vendors and researchers to explore various software evolution-related activities, including frequently missing features, sarcasm, and associated emotions, which will help better understand the reasons for comparatively low app ratings.", "AI": {"tldr": "\u8be5\u7814\u7a76\u521b\u5efa\u4e86\u4e00\u4e2a\u6765\u81ea\u4e9a\u9a6c\u900a\u8f6f\u4ef6\u5e94\u7528\u5546\u5e9764\u4e2a\u4f4e\u8bc4\u5206\u5e94\u7528\u768479,821\u6761\u7528\u6237\u8bc4\u8bba\u6570\u636e\u96c6\uff0c\u5176\u4e2d6,000\u6761\u8bc4\u8bba\u88ab\u624b\u52a8\u6807\u6ce8\u4e3a\u516d\u5927\u95ee\u9898\u7c7b\u522b\uff0c\u4e3a\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u7528\u6237\u53cd\u9988\u81ea\u52a8\u5206\u7c7b\u63d0\u4f9b\u8d44\u6e90\u3002", "motivation": "\u5f53\u524d\u7814\u7a76\u591a\u5173\u6ce8\u9ad8\u8bc4\u5206\u5e94\u7528\uff0c\u800c\u4f4e\u8bc4\u5206\u5e94\u7528\u5f80\u5f80\u88ab\u5ffd\u89c6\uff0c\u4f46\u5b83\u4eec\u53ef\u80fd\u63ed\u793a\u963b\u788d\u7528\u6237\u4f53\u9a8c\u7684\u5173\u952e\u95ee\u9898\u3002\u4e3a\u7406\u89e3\u4f4e\u8bc4\u5206\u5e94\u7528\u7684\u5e38\u89c1\u95ee\u9898\u5e76\u6539\u8fdb\u8f6f\u4ef6\u8d28\u91cf\uff0c\u9700\u8981\u4e13\u95e8\u7684\u6570\u636e\u96c6\u6765\u652f\u6301\u76f8\u5173\u7814\u7a76\u3002", "method": "\u4ece\u4e9a\u9a6c\u900a\u8f6f\u4ef6\u5e94\u7528\u5546\u5e97\u6536\u96c664\u4e2a\u4f4e\u8bc4\u5206\u5e94\u7528\u768479,821\u6761\u7528\u6237\u8bc4\u8bba\uff0c\u521b\u5efa\u539f\u59cb\u6570\u636e\u96c6\u3002\u8fdb\u4e00\u6b65\u624b\u52a8\u6807\u6ce8\u5176\u4e2d6,000\u6761\u8bc4\u8bba\uff0c\u5c06\u5176\u5206\u7c7b\u4e3a\u516d\u5927\u95ee\u9898\u7c7b\u522b\uff1aUI/UX\u3001\u529f\u80fd\u7279\u6027\u3001\u517c\u5bb9\u6027\u4e0e\u8bbe\u5907\u7279\u5b9a\u6027\u3001\u6027\u80fd\u4e0e\u7a33\u5b9a\u6027\u3001\u5ba2\u6237\u652f\u6301\u4e0e\u54cd\u5e94\u6027\u3001\u5b89\u5168\u4e0e\u9690\u79c1\u95ee\u9898\u3002", "result": "\u521b\u5efa\u4e86\u5305\u542b\u539f\u59cb\u548c\u6807\u6ce8\u7248\u672c\u7684\u4f4e\u8bc4\u5206\u5e94\u7528\u7528\u6237\u53cd\u9988\u6570\u636e\u96c6\uff0c\u4e3a\u7814\u7a76\u4eba\u5458\u548c\u5f00\u53d1\u8005\u63d0\u4f9b\u4e86\u7406\u89e3\u4f4e\u8bc4\u5206\u5e94\u7528\u5e38\u89c1\u95ee\u9898\u7684\u5de5\u5177\u3002\u8be5\u6570\u636e\u96c6\u652f\u6301\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u5f00\u53d1\uff0c\u53ef\u81ea\u52a8\u5206\u7c7b\u7528\u6237\u53cd\u9988\u5230\u4e0d\u540c\u95ee\u9898\u7c7b\u578b\u3002", "conclusion": "\u8be5\u6570\u636e\u96c6\u4e3a\u57fa\u4e8e\u7528\u6237\u53cd\u9988\u6539\u8fdb\u8f6f\u4ef6\u8d28\u91cf\u7684\u6570\u636e\u9a71\u52a8\u89e3\u51b3\u65b9\u6848\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u4f7f\u8f6f\u4ef6\u4f9b\u5e94\u5546\u548c\u7814\u7a76\u4eba\u5458\u80fd\u591f\u63a2\u7d22\u8f6f\u4ef6\u6f14\u5316\u76f8\u5173\u6d3b\u52a8\uff0c\u5305\u62ec\u7f3a\u5931\u529f\u80fd\u3001\u8bbd\u523a\u8bed\u6c14\u548c\u76f8\u5173\u60c5\u7eea\u5206\u6790\uff0c\u4ece\u800c\u66f4\u597d\u5730\u7406\u89e3\u5e94\u7528\u8bc4\u5206\u8f83\u4f4e\u7684\u539f\u56e0\u3002"}}
{"id": "2601.03251", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.03251", "abs": "https://arxiv.org/abs/2601.03251", "authors": ["Xue Qin", "Matthew DiGiovanni"], "title": "NavAI: A Generalizable LLM Framework for Navigation Tasks in Virtual Reality Environments", "comment": null, "summary": "Navigation is one of the fundamental tasks for automated exploration in Virtual Reality (VR). Existing technologies primarily focus on path optimization in 360-degree image datasets and 3D simulators, which cannot be directly applied to immersive VR environments. To address this gap, we present NavAI, a generalizable large language model (LLM)-based navigation framework that supports both basic actions and complex goal-directed tasks across diverse VR applications. We evaluate NavAI in three distinct VR environments through goal-oriented and exploratory tasks. Results show that it achieves high accuracy, with an 89% success rate in goal-oriented tasks. Our analysis also highlights current limitations of relying entirely on LLMs, particularly in scenarios that require dynamic goal assessment. Finally, we discuss the limitations observed during the experiments and offer insights for future research directions.", "AI": {"tldr": "NavAI\u662f\u4e00\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u901a\u7528VR\u5bfc\u822a\u6846\u67b6\uff0c\u652f\u6301\u8de8\u4e0d\u540cVR\u5e94\u7528\u7684\u57fa\u672c\u52a8\u4f5c\u548c\u590d\u6742\u76ee\u6807\u5bfc\u5411\u4efb\u52a1\uff0c\u5728\u76ee\u6807\u5bfc\u5411\u4efb\u52a1\u4e2d\u8fbe\u523089%\u7684\u6210\u529f\u7387\u3002", "motivation": "\u73b0\u6709\u5bfc\u822a\u6280\u672f\u4e3b\u8981\u4e13\u6ce8\u4e8e360\u5ea6\u56fe\u50cf\u6570\u636e\u96c6\u548c3D\u6a21\u62df\u5668\u4e2d\u7684\u8def\u5f84\u4f18\u5316\uff0c\u65e0\u6cd5\u76f4\u63a5\u5e94\u7528\u4e8e\u6c89\u6d78\u5f0fVR\u73af\u5883\uff0c\u9700\u8981\u5f00\u53d1\u9002\u7528\u4e8eVR\u7684\u901a\u7528\u5bfc\u822a\u6846\u67b6\u3002", "method": "\u63d0\u51faNavAI\uff0c\u4e00\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u901a\u7528\u5bfc\u822a\u6846\u67b6\uff0c\u652f\u6301\u8de8\u4e0d\u540cVR\u5e94\u7528\u7684\u57fa\u672c\u52a8\u4f5c\u548c\u590d\u6742\u76ee\u6807\u5bfc\u5411\u4efb\u52a1\u3002\u5728\u4e09\u4e2a\u4e0d\u540c\u7684VR\u73af\u5883\u4e2d\u901a\u8fc7\u76ee\u6807\u5bfc\u5411\u548c\u63a2\u7d22\u6027\u4efb\u52a1\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "NavAI\u5728\u76ee\u6807\u5bfc\u5411\u4efb\u52a1\u4e2d\u8fbe\u523089%\u7684\u6210\u529f\u7387\uff0c\u8868\u73b0\u51fa\u9ad8\u51c6\u786e\u6027\u3002\u5206\u6790\u63ed\u793a\u4e86\u5b8c\u5168\u4f9d\u8d56LLM\u7684\u5c40\u9650\u6027\uff0c\u7279\u522b\u662f\u5728\u9700\u8981\u52a8\u6001\u76ee\u6807\u8bc4\u4f30\u7684\u573a\u666f\u4e2d\u3002", "conclusion": "NavAI\u662f\u4e00\u4e2a\u6709\u6548\u7684VR\u5bfc\u822a\u6846\u67b6\uff0c\u4f46\u5b8c\u5168\u4f9d\u8d56LLM\u5b58\u5728\u5c40\u9650\u6027\uff0c\u7279\u522b\u662f\u5728\u52a8\u6001\u76ee\u6807\u8bc4\u4f30\u65b9\u9762\u3002\u8bba\u6587\u8ba8\u8bba\u4e86\u5b9e\u9a8c\u4e2d\u7684\u5c40\u9650\u6027\uff0c\u5e76\u4e3a\u672a\u6765\u7814\u7a76\u65b9\u5411\u63d0\u4f9b\u4e86\u89c1\u89e3\u3002"}}
