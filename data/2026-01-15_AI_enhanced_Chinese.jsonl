{"id": "2601.09216", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2601.09216", "abs": "https://arxiv.org/abs/2601.09216", "authors": ["Xinyuan Zhang", "Zijian Wang", "Chang Dao", "Juexiao Zhou"], "title": "Honesty-Aware Multi-Agent Framework for High-Fidelity Synthetic Data Generation in Digital Psychiatric Intake Doctor-Patient Interactions", "comment": null, "summary": "Data scarcity and unreliable self-reporting -- such as concealment or exaggeration -- pose fundamental challenges to psychiatric intake and assessment. We propose a multi-agent synthesis framework that explicitly models patient deception to generate high-fidelity, publicly releasable synthetic psychiatric intake records. Starting from DAIC-WOZ interviews, we construct enriched patient profiles and simulate a four-role workflow: a \\emph{Patient} completes self-rated scales and participates in a semi-structured interview under a topic-dependent honesty state; an \\emph{Assessor} selects instruments based on demographics and chief complaints; an \\emph{Evaluator} conducts the interview grounded in rater-administered scales, tracks suspicion, and completes ratings; and a \\emph{Diagnostician} integrates all evidence into a diagnostic summary. Each case links the patient profile, self-rated and rater-administered responses, interview transcript, diagnostic summary, and honesty state. We validate the framework through four complementary evaluations: diagnostic consistency and severity grading, chain-of-thought ablations, human evaluation of clinical realism and dishonesty modeling, and LLM-based comparative evaluation. The resulting corpus spans multiple disorders and severity levels, enabling controlled study of dishonesty-aware psychiatric assessment and the training and evaluation of adaptive dialogue agents.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u591a\u667a\u80fd\u4f53\u5408\u6210\u6846\u67b6\uff0c\u901a\u8fc7\u663e\u5f0f\u5efa\u6a21\u60a3\u8005\u6b3a\u9a97\u884c\u4e3a\u6765\u751f\u6210\u9ad8\u4fdd\u771f\u3001\u53ef\u516c\u5f00\u53d1\u5e03\u7684\u5408\u6210\u7cbe\u795e\u75c5\u5b66\u5165\u9662\u8bb0\u5f55\uff0c\u7528\u4e8e\u7814\u7a76\u6b3a\u9a97\u611f\u77e5\u7684\u7cbe\u795e\u75c5\u5b66\u8bc4\u4f30\u548c\u8bad\u7ec3\u81ea\u9002\u5e94\u5bf9\u8bdd\u7cfb\u7edf\u3002", "motivation": "\u7cbe\u795e\u75c5\u5b66\u5165\u9662\u548c\u8bc4\u4f30\u9762\u4e34\u6570\u636e\u7a00\u7f3a\u548c\u4e0d\u53ef\u9760\u81ea\u6211\u62a5\u544a\uff08\u5982\u9690\u7792\u6216\u5938\u5927\uff09\u7684\u57fa\u672c\u6311\u6218\uff0c\u9700\u8981\u80fd\u591f\u5904\u7406\u60a3\u8005\u6b3a\u9a97\u884c\u4e3a\u7684\u5408\u6210\u6570\u636e\u751f\u6210\u65b9\u6cd5\u3002", "method": "\u57fa\u4e8eDAIC-WOZ\u8bbf\u8c08\u6784\u5efa\u4e30\u5bcc\u7684\u60a3\u8005\u6863\u6848\uff0c\u6a21\u62df\u56db\u89d2\u8272\u5de5\u4f5c\u6d41\u7a0b\uff1a\u60a3\u8005\uff08\u5728\u4e3b\u9898\u76f8\u5173\u7684\u8bda\u5b9e\u72b6\u6001\u4e0b\u5b8c\u6210\u81ea\u8bc4\u91cf\u8868\u548c\u534a\u7ed3\u6784\u5316\u8bbf\u8c08\uff09\u3001\u8bc4\u4f30\u8005\uff08\u6839\u636e\u4eba\u53e3\u7edf\u8ba1\u5b66\u548c\u4e3b\u8bc9\u9009\u62e9\u5de5\u5177\uff09\u3001\u8bc4\u4f30\u5458\uff08\u57fa\u4e8e\u8bc4\u5206\u5458\u7ba1\u7406\u7684\u91cf\u8868\u8fdb\u884c\u8bbf\u8c08\u3001\u8ddf\u8e2a\u6000\u7591\u5e76\u5b8c\u6210\u8bc4\u5206\uff09\u3001\u8bca\u65ad\u5e08\uff08\u6574\u5408\u6240\u6709\u8bc1\u636e\u5f62\u6210\u8bca\u65ad\u603b\u7ed3\uff09\u3002", "result": "\u901a\u8fc7\u56db\u79cd\u4e92\u8865\u8bc4\u4f30\u9a8c\u8bc1\u6846\u67b6\uff1a\u8bca\u65ad\u4e00\u81f4\u6027\u548c\u4e25\u91cd\u7a0b\u5ea6\u5206\u7ea7\u3001\u601d\u7ef4\u94fe\u6d88\u878d\u3001\u4e34\u5e8a\u771f\u5b9e\u6027\u548c\u6b3a\u9a97\u5efa\u6a21\u7684\u4eba\u7c7b\u8bc4\u4f30\u3001\u57fa\u4e8eLLM\u7684\u6bd4\u8f83\u8bc4\u4f30\u3002\u751f\u6210\u7684\u8bed\u6599\u5e93\u6db5\u76d6\u591a\u79cd\u969c\u788d\u548c\u4e25\u91cd\u7a0b\u5ea6\u6c34\u5e73\u3002", "conclusion": "\u8be5\u6846\u67b6\u80fd\u591f\u751f\u6210\u5305\u542b\u60a3\u8005\u6b3a\u9a97\u884c\u4e3a\u7684\u5408\u6210\u7cbe\u795e\u75c5\u5b66\u8bb0\u5f55\uff0c\u652f\u6301\u5bf9\u6b3a\u9a97\u611f\u77e5\u7684\u7cbe\u795e\u75c5\u5b66\u8bc4\u4f30\u8fdb\u884c\u53d7\u63a7\u7814\u7a76\uff0c\u5e76\u4e3a\u8bad\u7ec3\u548c\u8bc4\u4f30\u81ea\u9002\u5e94\u5bf9\u8bdd\u7cfb\u7edf\u63d0\u4f9b\u6570\u636e\u57fa\u7840\u3002"}}
{"id": "2601.09404", "categories": ["cs.DB", "cs.HC"], "pdf": "https://arxiv.org/pdf/2601.09404", "abs": "https://arxiv.org/abs/2601.09404", "authors": ["Jun-Peng Zhu", "Boyan Niu", "Peng Cai", "Zheming Ni", "Kai Xu", "Jiajun Huang", "Shengbo Ma", "Bing Wang", "Xuan Zhou", "Guanglei Bao", "Donghui Zhang", "Liu Tang", "Qi Liu"], "title": "TiInsight: A SQL-based Automated Exploratory Data Analysis System through Large Language Models", "comment": "4 pages, 5 figures", "summary": "The SQL-based exploratory data analysis has garnered significant attention within the data analysis community. The emergence of large language models (LLMs) has facilitated the paradigm shift from manual to automated data exploration. However, existing methods generally lack the ability for cross-domain analysis, and the exploration of LLMs capabilities remains insufficient. This paper presents TiInsight, an SQL-based automated cross-domain exploratory data analysis system. First, TiInsight offers a user-friendly GUI enabling users to explore data using natural language queries. Second, TiInsight offers a robust cross-domain exploratory data analysis pipeline: hierarchical data context (i.e., HDC) generation, question clarification and decomposition, text-to-SQL (i.e., TiSQL), and data visualization (i.e., TiChart). Third, we have implemented and deployed TiInsight in the production environment of PingCAP and demonstrated its capabilities using representative datasets. The demo video is available at https://youtu.be/JzYFyYd-emI.", "AI": {"tldr": "TiInsight\u662f\u4e00\u4e2a\u57fa\u4e8eSQL\u7684\u81ea\u52a8\u5316\u8de8\u9886\u57df\u63a2\u7d22\u6027\u6570\u636e\u5206\u6790\u7cfb\u7edf\uff0c\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u67e5\u8be2\u3001\u5206\u5c42\u6570\u636e\u4e0a\u4e0b\u6587\u751f\u6210\u3001\u95ee\u9898\u6f84\u6e05\u4e0e\u5206\u89e3\u3001\u6587\u672c\u5230SQL\u8f6c\u6362\u548c\u6570\u636e\u53ef\u89c6\u5316\u7b49\u529f\u80fd\uff0c\u5b9e\u73b0\u8de8\u9886\u57df\u6570\u636e\u63a2\u7d22\u3002", "motivation": "\u73b0\u6709\u7684SQL\u63a2\u7d22\u6027\u6570\u636e\u5206\u6790\u65b9\u6cd5\u901a\u5e38\u7f3a\u4e4f\u8de8\u9886\u57df\u5206\u6790\u80fd\u529b\uff0c\u4e14\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\u6f5c\u529b\u7684\u63a2\u7d22\u4e0d\u8db3\u3002\u9700\u8981\u5f00\u53d1\u4e00\u4e2a\u80fd\u591f\u652f\u6301\u8de8\u9886\u57df\u81ea\u52a8\u63a2\u7d22\u7684\u7cfb\u7edf\u3002", "method": "TiInsight\u63d0\u4f9b\u7528\u6237\u53cb\u597d\u7684GUI\u754c\u9762\uff0c\u652f\u6301\u81ea\u7136\u8bed\u8a00\u67e5\u8be2\uff0c\u5e76\u6784\u5efa\u4e86\u8de8\u9886\u57df\u63a2\u7d22\u6027\u6570\u636e\u5206\u6790\u7ba1\u9053\uff1a\u5206\u5c42\u6570\u636e\u4e0a\u4e0b\u6587\u751f\u6210\u3001\u95ee\u9898\u6f84\u6e05\u4e0e\u5206\u89e3\u3001\u6587\u672c\u5230SQL\u8f6c\u6362\uff08TiSQL\uff09\u548c\u6570\u636e\u53ef\u89c6\u5316\uff08TiChart\uff09\u3002", "result": "TiInsight\u5df2\u5728PingCAP\u751f\u4ea7\u73af\u5883\u4e2d\u5b9e\u73b0\u548c\u90e8\u7f72\uff0c\u4f7f\u7528\u4ee3\u8868\u6027\u6570\u636e\u96c6\u5c55\u793a\u4e86\u5176\u80fd\u529b\uff0c\u63d0\u4f9b\u4e86\u6f14\u793a\u89c6\u9891\u3002", "conclusion": "TiInsight\u6210\u529f\u5b9e\u73b0\u4e86\u57fa\u4e8eSQL\u7684\u81ea\u52a8\u5316\u8de8\u9886\u57df\u63a2\u7d22\u6027\u6570\u636e\u5206\u6790\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u8de8\u9886\u57df\u5206\u6790\u65b9\u9762\u7684\u4e0d\u8db3\uff0c\u5e76\u5145\u5206\u5229\u7528\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u6f5c\u529b\u3002"}}
{"id": "2601.08856", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.08856", "abs": "https://arxiv.org/abs/2601.08856", "authors": ["Deeksha Nandal", "Riccardo Revalor", "Soham Dan", "Debjit Pal"], "title": "LAUDE: LLM-Assisted Unit Test Generation and Debugging of Hardware DEsigns", "comment": "18 Pages, 21 Figures, Submitted to ARR Review", "summary": "Unit tests are critical in the hardware design lifecycle to ensure that component design modules are functionally correct and conform to the specification before they are integrated at the system level. Thus developing unit tests targeting various design features requires deep understanding of the design functionality and creativity. When one or more unit tests expose a design failure, the debugging engineer needs to diagnose, localize, and debug the failure to ensure design correctness, which is often a painstaking and intense process. In this work, we introduce LAUDE, a unified unit-test generation and debugging framework for hardware designs that cross-pollinates the semantic understanding of the design source code with the Chain-of-Thought (CoT) reasoning capabilities of foundational Large-Language Models (LLMs). LAUDE integrates prompt engineering and design execution information to enhance its unit test generation accuracy and code debuggability. We apply LAUDE with closed- and open-source LLMs to a large corpus of buggy hardware design codes derived from the VerilogEval dataset, where generated unit tests detected bugs in up to 100% and 93% of combinational and sequential designs and debugged up to 93% and 84% of combinational and sequential designs, respectively.", "AI": {"tldr": "LAUDE\u662f\u4e00\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u786c\u4ef6\u8bbe\u8ba1\u5355\u5143\u6d4b\u8bd5\u751f\u6210\u4e0e\u8c03\u8bd5\u7edf\u4e00\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u5408\u8bbe\u8ba1\u6e90\u4ee3\u7801\u8bed\u4e49\u7406\u89e3\u548c\u94fe\u5f0f\u601d\u7ef4\u63a8\u7406\uff0c\u663e\u8457\u63d0\u5347\u6d4b\u8bd5\u751f\u6210\u51c6\u786e\u6027\u548c\u4ee3\u7801\u53ef\u8c03\u8bd5\u6027\u3002", "motivation": "\u786c\u4ef6\u8bbe\u8ba1\u4e2d\u5355\u5143\u6d4b\u8bd5\u5bf9\u786e\u4fdd\u529f\u80fd\u6b63\u786e\u6027\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5f00\u53d1\u6d4b\u8bd5\u9700\u8981\u6df1\u5165\u7406\u89e3\u8bbe\u8ba1\u529f\u80fd\u548c\u521b\u9020\u529b\uff0c\u800c\u8c03\u8bd5\u8bbe\u8ba1\u5931\u8d25\u662f\u4e00\u4e2a\u75db\u82e6\u4e14\u5bc6\u96c6\u7684\u8fc7\u7a0b\uff0c\u9700\u8981\u81ea\u52a8\u5316\u5de5\u5177\u6765\u63d0\u5347\u6548\u7387\u3002", "method": "LAUDE\u6846\u67b6\u7ed3\u5408\u63d0\u793a\u5de5\u7a0b\u548c\u8bbe\u8ba1\u6267\u884c\u4fe1\u606f\uff0c\u5c06\u8bbe\u8ba1\u6e90\u4ee3\u7801\u7684\u8bed\u4e49\u7406\u89e3\u4e0e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u94fe\u5f0f\u601d\u7ef4\u63a8\u7406\u80fd\u529b\u4ea4\u53c9\u878d\u5408\uff0c\u652f\u6301\u95ed\u6e90\u548c\u5f00\u6e90LLM\uff0c\u5e94\u7528\u4e8eVerilogEval\u6570\u636e\u96c6\u7684\u9519\u8bef\u786c\u4ef6\u8bbe\u8ba1\u4ee3\u7801\u3002", "result": "\u5728\u7ec4\u5408\u8bbe\u8ba1\u4e2d\uff0c\u751f\u6210\u7684\u5355\u5143\u6d4b\u8bd5\u68c0\u6d4b\u5230\u9ad8\u8fbe100%\u7684\u9519\u8bef\uff0c\u8c03\u8bd5\u6210\u529f\u7387\u8fbe93%\uff1b\u5728\u65f6\u5e8f\u8bbe\u8ba1\u4e2d\uff0c\u9519\u8bef\u68c0\u6d4b\u7387\u8fbe93%\uff0c\u8c03\u8bd5\u6210\u529f\u7387\u8fbe84%\u3002", "conclusion": "LAUDE\u6846\u67b6\u6210\u529f\u5c55\u793a\u4e86LLM\u5728\u786c\u4ef6\u8bbe\u8ba1\u6d4b\u8bd5\u751f\u6210\u548c\u8c03\u8bd5\u4e2d\u7684\u6709\u6548\u6027\uff0c\u80fd\u591f\u663e\u8457\u63d0\u9ad8\u786c\u4ef6\u8bbe\u8ba1\u9a8c\u8bc1\u548c\u8c03\u8bd5\u7684\u6548\u7387\u4e0e\u51c6\u786e\u6027\u3002"}}
{"id": "2601.09114", "categories": ["cs.DC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.09114", "abs": "https://arxiv.org/abs/2601.09114", "authors": ["Yufan Xia", "Marco De La Pierre", "Amanda S. Barnard", "Giuseppe Maria Junior Barca"], "title": "A Machine Learning Approach Towards Runtime Optimisation of Matrix Multiplication", "comment": "2023 IEEE International Parallel and Distributed Processing Symposium (IPDPS)", "summary": "The GEneral Matrix Multiplication (GEMM) is one of the essential algorithms in scientific computing. Single-thread GEMM implementations are well-optimised with techniques like blocking and autotuning. However, due to the complexity of modern multi-core shared memory systems, it is challenging to determine the number of threads that minimises the multi-thread GEMM runtime. We present a proof-of-concept approach to building an Architecture and Data-Structure Aware Linear Algebra (ADSALA) software library that uses machine learning to optimise the runtime performance of BLAS routines. More specifically, our method uses a machine learning model on-the-fly to automatically select the optimal number of threads for a given GEMM task based on the collected training data. Test results on two different HPC node architectures, one based on a two-socket Intel Cascade Lake and the other on a two-socket AMD Zen 3, revealed a 25 to 40 per cent speedup compared to traditional GEMM implementations in BLAS when using GEMM of memory usage within 100 MB.", "AI": {"tldr": "\u4f7f\u7528\u673a\u5668\u5b66\u4e60\u52a8\u6001\u9009\u62e9\u6700\u4f73\u7ebf\u7a0b\u6570\u4ee5\u4f18\u5316\u591a\u7ebf\u7a0bGEMM\u6027\u80fd\uff0c\u5728\u4e24\u79cdHPC\u67b6\u6784\u4e0a\u5b9e\u73b025-40%\u52a0\u901f", "motivation": "\u73b0\u4ee3\u591a\u6838\u5171\u4eab\u5185\u5b58\u7cfb\u7edf\u590d\u6742\uff0c\u96be\u4ee5\u786e\u5b9a\u6700\u5c0f\u5316\u591a\u7ebf\u7a0bGEMM\u8fd0\u884c\u65f6\u7684\u6700\u4f73\u7ebf\u7a0b\u6570\uff0c\u9700\u8981\u667a\u80fd\u4f18\u5316\u65b9\u6cd5", "method": "\u6784\u5efaADSALA\u8f6f\u4ef6\u5e93\uff0c\u4f7f\u7528\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5b9e\u65f6\u6839\u636e\u8bad\u7ec3\u6570\u636e\u4e3a\u7ed9\u5b9aGEMM\u4efb\u52a1\u81ea\u52a8\u9009\u62e9\u6700\u4f18\u7ebf\u7a0b\u6570", "result": "\u5728Intel Cascade Lake\u548cAMD Zen 3\u4e24\u79cdHPC\u8282\u70b9\u67b6\u6784\u4e0a\u6d4b\u8bd5\uff0c\u5185\u5b58\u4f7f\u7528100MB\u5185\u7684GEMM\u76f8\u6bd4\u4f20\u7edfBLAS\u5b9e\u73b0\u83b7\u5f9725-40%\u52a0\u901f", "conclusion": "\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u80fd\u6709\u6548\u4f18\u5316\u591a\u7ebf\u7a0bGEMM\u6027\u80fd\uff0cADSALA\u5e93\u4e3a\u7ebf\u6027\u4ee3\u6570\u8fd0\u7b97\u63d0\u4f9b\u4e86\u667a\u80fd\u5316\u7684\u8fd0\u884c\u65f6\u4f18\u5316\u65b9\u6848"}}
{"id": "2601.08857", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.08857", "abs": "https://arxiv.org/abs/2601.08857", "authors": ["Mustafa Degerli"], "title": "Revisiting Software Engineering Education in the Era of Large Language Models: A Curriculum Adaptation and Academic Integrity Framework", "comment": null, "summary": "The integration of Large Language Models (LLMs), such as ChatGPT and GitHub Copilot, into professional workflows is increasingly reshaping software engineering practices. These tools have lowered the cost of code generation, explanation, and testing, while introducing new forms of automation into routine development tasks. In contrast, most of the software engineering and computer engineering curricula remain closely aligned with pedagogical models that equate manual syntax production with technical competence. This growing misalignment raises concerns regarding assessment validity, learning outcomes, and the development of foundational skills. Adopting a conceptual research approach, this paper proposes a theoretical framework for analyzing how generative AI alters core software engineering competencies and introduces a pedagogical design model for LLM-integrated education. Attention is given to computer engineering programs in Turkey, where centralized regulation, large class sizes, and exam-oriented assessment practices amplify these challenges. The framework delineates how problem analysis, design, implementation, and testing increasingly shift from construction toward critique, validation, and human-AI stewardship. In addition, the paper argues that traditional plagiarism-centric integrity mechanisms are becoming insufficient, motivating a transition toward a process transparency model. While this work provides a structured proposal for curriculum adaptation, it remains a theoretical contribution; the paper concludes by outlining the need for longitudinal empirical studies to evaluate these interventions and their long-term impacts on learning.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u7406\u8bba\u6846\u67b6\u5206\u6790\u751f\u6210\u5f0fAI\u5982\u4f55\u6539\u53d8\u8f6f\u4ef6\u5de5\u7a0b\u6838\u5fc3\u80fd\u529b\uff0c\u5e76\u8bbe\u8ba1LLM\u96c6\u6210\u6559\u80b2\u6a21\u578b\uff0c\u7279\u522b\u5173\u6ce8\u571f\u8033\u5176\u8ba1\u7b97\u673a\u5de5\u7a0b\u6559\u80b2\u9762\u4e34\u7684\u6311\u6218\u3002", "motivation": "LLM\u5de5\u5177\uff08\u5982ChatGPT\u3001GitHub Copilot\uff09\u6b63\u5728\u91cd\u5851\u8f6f\u4ef6\u5de5\u7a0b\u5b9e\u8df5\uff0c\u964d\u4f4e\u4e86\u4ee3\u7801\u751f\u6210\u3001\u89e3\u91ca\u548c\u6d4b\u8bd5\u7684\u6210\u672c\uff0c\u4f46\u4f20\u7edf\u8f6f\u4ef6\u5de5\u7a0b\u6559\u80b2\u4ecd\u5f3a\u8c03\u624b\u52a8\u8bed\u6cd5\u751f\u4ea7\u4f5c\u4e3a\u6280\u672f\u80fd\u529b\u6807\u51c6\uff0c\u8fd9\u79cd\u9519\u914d\u5f15\u53d1\u4e86\u8bc4\u4f30\u6709\u6548\u6027\u3001\u5b66\u4e60\u6210\u679c\u548c\u57fa\u7840\u6280\u80fd\u53d1\u5c55\u7684\u62c5\u5fe7\u3002", "method": "\u91c7\u7528\u6982\u5ff5\u7814\u7a76\u65b9\u6cd5\uff0c\u63d0\u51fa\u7406\u8bba\u6846\u67b6\u5206\u6790\u751f\u6210\u5f0fAI\u5982\u4f55\u6539\u53d8\u8f6f\u4ef6\u5de5\u7a0b\u6838\u5fc3\u80fd\u529b\uff0c\u5e76\u5f15\u5165LLM\u96c6\u6210\u6559\u80b2\u7684\u6559\u5b66\u8bbe\u8ba1\u6a21\u578b\uff0c\u7279\u522b\u5173\u6ce8\u571f\u8033\u5176\u8ba1\u7b97\u673a\u5de5\u7a0b\u6559\u80b2\u4e2d\u96c6\u4e2d\u76d1\u7ba1\u3001\u5927\u73ed\u6559\u5b66\u548c\u8003\u8bd5\u5bfc\u5411\u8bc4\u4f30\u5b9e\u8df5\u52a0\u5267\u7684\u6311\u6218\u3002", "result": "\u6846\u67b6\u63cf\u8ff0\u4e86\u95ee\u9898\u5206\u6790\u3001\u8bbe\u8ba1\u3001\u5b9e\u73b0\u548c\u6d4b\u8bd5\u5982\u4f55\u4ece\u6784\u5efa\u8f6c\u5411\u6279\u5224\u3001\u9a8c\u8bc1\u548c\u4eba\u673a\u534f\u4f5c\u7ba1\u7406\uff0c\u6307\u51fa\u4f20\u7edf\u6284\u88ad\u68c0\u6d4b\u673a\u5236\u5df2\u4e0d\u8db3\uff0c\u9700\u8981\u5411\u8fc7\u7a0b\u900f\u660e\u5ea6\u6a21\u578b\u8fc7\u6e21\u3002", "conclusion": "\u867d\u7136\u63d0\u4f9b\u4e86\u8bfe\u7a0b\u9002\u5e94\u7684\u7ed3\u6784\u5316\u5efa\u8bae\uff0c\u4f46\u8fd9\u4ecd\u662f\u7406\u8bba\u8d21\u732e\uff0c\u9700\u8981\u7eb5\u5411\u5b9e\u8bc1\u7814\u7a76\u6765\u8bc4\u4f30\u8fd9\u4e9b\u5e72\u9884\u63aa\u65bd\u53ca\u5176\u5bf9\u5b66\u4e60\u7684\u957f\u671f\u5f71\u54cd\u3002"}}
{"id": "2601.09146", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2601.09146", "abs": "https://arxiv.org/abs/2601.09146", "authors": ["Lingkang Shangguan"], "title": "Transaction-Driven Dynamic Reconfiguration for Certificate-Based Payment Systems", "comment": "draft initial version", "summary": "We present a transaction-driven dynamic reconfiguration protocol in Modern payment systems based on Byzantine Consistent Broadcast which can achieve high performance by avoiding global transaction ordering. We demonstrate the fundamental paradigm of modern payment systems, which combines user nonce based transactions ordering with periodic system-wide consensus mechanisms. Building on this foundation, we design PDCC(Payment Dynamic Config Change), which can lead a smooth reconfiguration process without impacting the original system's performance.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u62dc\u5360\u5ead\u4e00\u81f4\u6027\u5e7f\u64ad\u7684\u4ea4\u6613\u9a71\u52a8\u52a8\u6001\u91cd\u914d\u7f6e\u534f\u8baePDCC\uff0c\u907f\u514d\u5168\u5c40\u4ea4\u6613\u6392\u5e8f\u4ee5\u5b9e\u73b0\u9ad8\u6027\u80fd\u652f\u4ed8\u7cfb\u7edf", "motivation": "\u73b0\u4ee3\u652f\u4ed8\u7cfb\u7edf\u9700\u8981\u9ad8\u6027\u80fd\u7684\u52a8\u6001\u91cd\u914d\u7f6e\u80fd\u529b\uff0c\u540c\u65f6\u907f\u514d\u5168\u5c40\u4ea4\u6613\u6392\u5e8f\u5e26\u6765\u7684\u6027\u80fd\u74f6\u9888", "method": "\u7ed3\u5408\u7528\u6237nonce\u7684\u4ea4\u6613\u6392\u5e8f\u4e0e\u5468\u671f\u6027\u7cfb\u7edf\u8303\u56f4\u5171\u8bc6\u673a\u5236\uff0c\u8bbe\u8ba1PDCC\u534f\u8bae\u5b9e\u73b0\u5e73\u6ed1\u91cd\u914d\u7f6e", "result": "PDCC\u80fd\u591f\u5728\u4e0d\u5f71\u54cd\u539f\u59cb\u7cfb\u7edf\u6027\u80fd\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u5e73\u6ed1\u7684\u91cd\u914d\u7f6e\u8fc7\u7a0b", "conclusion": "\u4ea4\u6613\u9a71\u52a8\u7684\u52a8\u6001\u91cd\u914d\u7f6e\u534f\u8bae\u4e3a\u73b0\u4ee3\u652f\u4ed8\u7cfb\u7edf\u63d0\u4f9b\u4e86\u9ad8\u6027\u80fd\u4e14\u7075\u6d3b\u7684\u914d\u7f6e\u7ba1\u7406\u65b9\u6848"}}
{"id": "2601.08858", "categories": ["cs.SE", "cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2601.08858", "abs": "https://arxiv.org/abs/2601.08858", "authors": ["Tejaswini Bollikonda"], "title": "Adaptive Trust Metrics for Multi-LLM Systems: Enhancing Reliability in Regulated Industries", "comment": "8 pages, 8 figures", "summary": "Large Language Models (LLMs) are increasingly deployed in sensitive domains such as healthcare, finance, and law, yet their integration raises pressing concerns around trust, accountability, and reliability. This paper explores adaptive trust metrics for multi LLM ecosystems, proposing a framework for quantifying and improving model reliability under regulated constraints. By analyzing system behaviors, evaluating uncertainty across multiple LLMs, and implementing dynamic monitoring pipelines, the study demonstrates practical pathways for operational trustworthiness. Case studies from financial compliance and healthcare diagnostics illustrate the applicability of adaptive trust metrics in real world settings. The findings position adaptive trust measurement as a foundational enabler for safe and scalable AI adoption in regulated industries.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u591aLLM\u751f\u6001\u7cfb\u7edf\u7684\u81ea\u9002\u5e94\u4fe1\u4efb\u5ea6\u91cf\u6846\u67b6\uff0c\u901a\u8fc7\u91cf\u5316\u6a21\u578b\u53ef\u9760\u6027\u3001\u5206\u6790\u7cfb\u7edf\u884c\u4e3a\u3001\u8bc4\u4f30\u4e0d\u786e\u5b9a\u6027\u4ee5\u53ca\u5b9e\u65bd\u52a8\u6001\u76d1\u63a7\uff0c\u4e3a\u53d7\u76d1\u7ba1\u884c\u4e1a\u4e2d\u7684AI\u90e8\u7f72\u63d0\u4f9b\u4fe1\u4efb\u4fdd\u969c\u3002", "motivation": "\u968f\u7740LLM\u5728\u533b\u7597\u3001\u91d1\u878d\u3001\u6cd5\u5f8b\u7b49\u654f\u611f\u9886\u57df\u7684\u90e8\u7f72\u65e5\u76ca\u589e\u591a\uff0c\u56f4\u7ed5\u4fe1\u4efb\u3001\u95ee\u8d23\u5236\u548c\u53ef\u9760\u6027\u7684\u62c5\u5fe7\u65e5\u76ca\u51f8\u663e\u3002\u8fd9\u4e9b\u6a21\u578b\u5728\u53d7\u76d1\u7ba1\u73af\u5883\u4e2d\u7684\u96c6\u6210\u9700\u8981\u89e3\u51b3\u4fe1\u4efb\u5ea6\u91cf\u548c\u53ef\u9760\u6027\u8bc4\u4f30\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u81ea\u9002\u5e94\u4fe1\u4efb\u5ea6\u91cf\u6846\u67b6\uff0c\u5305\u62ec\uff1a\u5206\u6790\u7cfb\u7edf\u884c\u4e3a\u3001\u8bc4\u4f30\u591a\u4e2aLLM\u4e4b\u95f4\u7684\u4e0d\u786e\u5b9a\u6027\u3001\u5b9e\u65bd\u52a8\u6001\u76d1\u63a7\u7ba1\u9053\uff0c\u5e76\u5728\u91d1\u878d\u5408\u89c4\u548c\u533b\u7597\u8bca\u65ad\u7b49\u5b9e\u9645\u573a\u666f\u4e2d\u8fdb\u884c\u6848\u4f8b\u7814\u7a76\u3002", "result": "\u7814\u7a76\u5c55\u793a\u4e86\u5728\u73b0\u5b9e\u4e16\u754c\u73af\u5883\u4e2d\u5e94\u7528\u81ea\u9002\u5e94\u4fe1\u4efb\u5ea6\u91cf\u7684\u53ef\u884c\u6027\uff0c\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u8bc1\u660e\u4e86\u8be5\u6846\u67b6\u5728\u91d1\u878d\u5408\u89c4\u548c\u533b\u7597\u8bca\u65ad\u7b49\u53d7\u76d1\u7ba1\u884c\u4e1a\u4e2d\u7684\u5b9e\u9645\u9002\u7528\u6027\u3002", "conclusion": "\u81ea\u9002\u5e94\u4fe1\u4efb\u5ea6\u91cf\u662f\u53d7\u76d1\u7ba1\u884c\u4e1a\u4e2d\u5b89\u5168\u3001\u53ef\u6269\u5c55AI\u91c7\u7528\u7684\u57fa\u7840\u63a8\u52a8\u8005\uff0c\u4e3a\u591aLLM\u751f\u6001\u7cfb\u7edf\u63d0\u4f9b\u4e86\u91cf\u5316\u4fe1\u4efb\u548c\u53ef\u9760\u6027\u7684\u5b9e\u7528\u9014\u5f84\u3002"}}
{"id": "2601.09184", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2601.09184", "abs": "https://arxiv.org/abs/2601.09184", "authors": ["Yifei Xie", "Btissam Er-Rahmadi", "Xiao Chen", "Tiejun Ma", "Jane Hillston"], "title": "Optimizing View Change for Byzantine Fault Tolerance in Parallel Consensus", "comment": null, "summary": "The parallel Byzantine Fault Tolerant (BFT) protocol is viewed as a promising solution to address the consensus scalability issue of the permissioned blockchain. One of the main challenges in parallel BFT is the view change process that happens when the leader node fails, which can lead to performance bottlenecks. Existing parallel BFT protocols typically rely on passive view change mechanisms with blind leader rotation. Such approaches frequently select unavailable or slow nodes as leaders, resulting in degraded performance. To address these challenges, we propose a View Change Optimization (VCO) model based on mixed integer programming that optimizes leader selection and follower reassignment across parallel committees by considering communication delays and failure scenarios. We applied a decomposition method with efficient subproblems and improved benders cuts to solve the VCO model. Leveraging the results of improved decomposition solution method, we propose an efficient iterative backup leader selection algorithm as views proceed. By performing experiments in Microsoft Azure cloud environments, we demonstrate that the VCO-driven parallel BFT outperforms existing configuration methods under both normal operation and faulty condition. The results show that the VCO model is effective as network size increases, making it a suitable solution for high-performance parallel BFT systems.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u6df7\u5408\u6574\u6570\u89c4\u5212\u7684\u89c6\u56fe\u53d8\u66f4\u4f18\u5316\u6a21\u578b\uff0c\u901a\u8fc7\u4f18\u5316\u9886\u5bfc\u8005\u9009\u62e9\u548c\u8ffd\u968f\u8005\u91cd\u65b0\u5206\u914d\u6765\u63d0\u5347\u5e76\u884cBFT\u534f\u8bae\u6027\u80fd\uff0c\u5728Azure\u4e91\u73af\u5883\u4e2d\u9a8c\u8bc1\u4e86\u6709\u6548\u6027\u3002", "motivation": "\u5e76\u884cBFT\u534f\u8bae\u4e2d\u7684\u89c6\u56fe\u53d8\u66f4\u8fc7\u7a0b\u5b58\u5728\u6027\u80fd\u74f6\u9888\uff0c\u73b0\u6709\u534f\u8bae\u91c7\u7528\u88ab\u52a8\u7684\u89c6\u56fe\u53d8\u66f4\u673a\u5236\u548c\u76f2\u76ee\u7684\u9886\u5bfc\u8005\u8f6e\u6362\uff0c\u7ecf\u5e38\u9009\u62e9\u4e0d\u53ef\u7528\u6216\u7f13\u6162\u8282\u70b9\u4f5c\u4e3a\u9886\u5bfc\u8005\uff0c\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u6df7\u5408\u6574\u6570\u89c4\u5212\u7684\u89c6\u56fe\u53d8\u66f4\u4f18\u5316\u6a21\u578b\uff0c\u8003\u8651\u901a\u4fe1\u5ef6\u8fdf\u548c\u6545\u969c\u573a\u666f\u4f18\u5316\u9886\u5bfc\u8005\u9009\u62e9\u548c\u8ffd\u968f\u8005\u91cd\u65b0\u5206\u914d\uff1b\u91c7\u7528\u5206\u89e3\u65b9\u6cd5\u5904\u7406\u5b50\u95ee\u9898\u5e76\u6539\u8fdbBenders\u5272\uff1b\u57fa\u4e8e\u5206\u89e3\u7ed3\u679c\u63d0\u51fa\u9ad8\u6548\u7684\u8fed\u4ee3\u5907\u4efd\u9886\u5bfc\u8005\u9009\u62e9\u7b97\u6cd5\u3002", "result": "\u5728Microsoft Azure\u4e91\u73af\u5883\u4e2d\u7684\u5b9e\u9a8c\u8868\u660e\uff0cVCO\u9a71\u52a8\u7684\u5e76\u884cBFT\u5728\u6b63\u5e38\u64cd\u4f5c\u548c\u6545\u969c\u6761\u4ef6\u4e0b\u90fd\u4f18\u4e8e\u73b0\u6709\u914d\u7f6e\u65b9\u6cd5\uff0c\u4e14\u968f\u7740\u7f51\u7edc\u89c4\u6a21\u589e\u5927\u6548\u679c\u66f4\u663e\u8457\u3002", "conclusion": "VCO\u6a21\u578b\u80fd\u6709\u6548\u89e3\u51b3\u5e76\u884cBFT\u4e2d\u7684\u89c6\u56fe\u53d8\u66f4\u6027\u80fd\u74f6\u9888\u95ee\u9898\uff0c\u4e3a\u9ad8\u6027\u80fd\u5e76\u884cBFT\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5408\u9002\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.08859", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.08859", "abs": "https://arxiv.org/abs/2601.08859", "authors": ["Bruno M. Saraiva", "Iv\u00e1n Hidalgo-Cenalmor", "Ant\u00f3nio D. Brito", "Dami\u00e1n Mart\u00ednez", "Tayla Shakespeare", "Guillaume Jacquemet", "Ricardo Henriques"], "title": "EZInput: A Cross-Environment Python Library for Easy UI Generation in Scientific Computing", "comment": null, "summary": "Researchers face a persistent barrier when applying computational algorithms with parameter configuration typically demanding programming skills, interfaces differing across environments, and settings rarely persisting between sessions. This fragmentation forces repetitive input, slows iterative exploration, and undermines reproducibility because parameter choices are difficult to record, share, and reuse. We present EZInput, a cross-runtime environment Python library enabling algorithm developers to automatically generate graphical user interfaces that make their computational tools accessible to end-users without programming expertise. EZInput employs a declarative specification system where developers define input requirements and validation constraints once; the library then handles environment detection, interface rendering, parameter validation, and session persistence across Jupyter notebooks, Google Colab, and terminal environments. This \"write once, run anywhere\" architecture enables researchers to prototype in notebooks and deploy identical parameter configurations for batch execution on remote systems without code changes or manual transcription. Parameter persistence, inspired by ImageJ/FIJI and adapted to Python workflows, saves and restores user configurations via lightweight YAML files, eliminating redundant input and producing shareable records that enhance reproducibility. EZInput supports diverse input types essential for scientific computing and it also includes built-in validation that ensures data integrity and clear feedback that reduces user friction.", "AI": {"tldr": "EZInput\u662f\u4e00\u4e2aPython\u5e93\uff0c\u8ba9\u7b97\u6cd5\u5f00\u53d1\u8005\u53ea\u9700\u5b9a\u4e49\u4e00\u6b21\u8f93\u5165\u9700\u6c42\uff0c\u5c31\u80fd\u81ea\u52a8\u751f\u6210\u8de8\u73af\u5883\u7684GUI\u754c\u9762\uff0c\u4f7f\u975e\u7f16\u7a0b\u7528\u6237\u4e5f\u80fd\u4f7f\u7528\u8ba1\u7b97\u5de5\u5177\uff0c\u5e76\u652f\u6301\u53c2\u6570\u6301\u4e45\u5316\u4ee5\u63d0\u9ad8\u53ef\u91cd\u590d\u6027\u3002", "motivation": "\u7814\u7a76\u4eba\u5458\u5728\u4f7f\u7528\u8ba1\u7b97\u7b97\u6cd5\u65f6\u9762\u4e34\u53c2\u6570\u914d\u7f6e\u9700\u8981\u7f16\u7a0b\u6280\u80fd\u3001\u4e0d\u540c\u73af\u5883\u63a5\u53e3\u4e0d\u4e00\u81f4\u3001\u8bbe\u7f6e\u96be\u4ee5\u5728\u4f1a\u8bdd\u95f4\u6301\u4e45\u4fdd\u5b58\u7b49\u95ee\u9898\uff0c\u5bfc\u81f4\u91cd\u590d\u8f93\u5165\u3001\u8fed\u4ee3\u63a2\u7d22\u7f13\u6162\uff0c\u4e14\u53c2\u6570\u9009\u62e9\u96be\u4ee5\u8bb0\u5f55\u3001\u5171\u4eab\u548c\u91cd\u7528\uff0c\u635f\u5bb3\u4e86\u7814\u7a76\u7684\u53ef\u91cd\u590d\u6027\u3002", "method": "EZInput\u91c7\u7528\u58f0\u660e\u5f0f\u89c4\u8303\u7cfb\u7edf\uff0c\u5f00\u53d1\u8005\u53ea\u9700\u5b9a\u4e49\u4e00\u6b21\u8f93\u5165\u9700\u6c42\u548c\u9a8c\u8bc1\u7ea6\u675f\uff0c\u5e93\u81ea\u52a8\u5904\u7406\u73af\u5883\u68c0\u6d4b\u3001\u754c\u9762\u6e32\u67d3\u3001\u53c2\u6570\u9a8c\u8bc1\u548c\u4f1a\u8bdd\u6301\u4e45\u5316\u3002\u652f\u6301Jupyter notebooks\u3001Google Colab\u548c\u7ec8\u7aef\u73af\u5883\uff0c\u901a\u8fc7\u8f7b\u91cf\u7ea7YAML\u6587\u4ef6\u4fdd\u5b58\u548c\u6062\u590d\u7528\u6237\u914d\u7f6e\u3002", "result": "EZInput\u5b9e\u73b0\u4e86\"\u4e00\u6b21\u7f16\u5199\uff0c\u968f\u5904\u8fd0\u884c\"\u7684\u67b6\u6784\uff0c\u4f7f\u7814\u7a76\u4eba\u5458\u80fd\u5728notebook\u4e2d\u539f\u578b\u8bbe\u8ba1\uff0c\u5e76\u5728\u8fdc\u7a0b\u7cfb\u7edf\u4e0a\u90e8\u7f72\u76f8\u540c\u7684\u53c2\u6570\u914d\u7f6e\u800c\u65e0\u9700\u4ee3\u7801\u66f4\u6539\u6216\u624b\u52a8\u8f6c\u5f55\u3002\u652f\u6301\u79d1\u5b66\u8ba1\u7b97\u6240\u9700\u7684\u5404\u79cd\u8f93\u5165\u7c7b\u578b\uff0c\u5185\u7f6e\u9a8c\u8bc1\u786e\u4fdd\u6570\u636e\u5b8c\u6574\u6027\u3002", "conclusion": "EZInput\u901a\u8fc7\u81ea\u52a8\u751f\u6210\u8de8\u73af\u5883GUI\u3001\u53c2\u6570\u6301\u4e45\u5316\u548c\u5185\u7f6e\u9a8c\u8bc1\uff0c\u964d\u4f4e\u4e86\u7b97\u6cd5\u4f7f\u7528\u7684\u6280\u672f\u95e8\u69db\uff0c\u51cf\u5c11\u4e86\u91cd\u590d\u8f93\u5165\uff0c\u63d0\u9ad8\u4e86\u7814\u7a76\u6548\u7387\u548c\u53ef\u91cd\u590d\u6027\uff0c\u7279\u522b\u9002\u5408\u79d1\u5b66\u8ba1\u7b97\u5de5\u4f5c\u6d41\u7a0b\u3002"}}
{"id": "2601.09258", "categories": ["cs.DC", "cs.LG", "cs.OS"], "pdf": "https://arxiv.org/pdf/2601.09258", "abs": "https://arxiv.org/abs/2601.09258", "authors": ["Du Yin", "Jiayi Ren", "Xiayu Sun", "Tianyao Zhou", "Haizhu Zhou", "Ruiyan Ma", "Danyang Zhang"], "title": "LatencyPrism: Online Non-intrusive Latency Sculpting for SLO-Guaranteed LLM Inference", "comment": "12 pages, 6 figures", "summary": "LLM inference latency critically determines user experience and operational costs, directly impacting throughput under SLO constraints. Even brief latency spikes degrade service quality despite acceptable average performance. However, distributed inference environments featuring diverse software frameworks and XPU architectures combined with dynamic workloads make latency analysis challenging. Constrained by intrusive designs that necessitate service restarts or even suspension, and by hardware-bound implementations that fail to adapt to heterogeneous inference environments, existing AI profiling methods are often inadequate for real-time production analysis.\n  We present LatencyPrism, the first zero-intrusion multi-platform latency sculpting system. It aims to break down the inference latency across pipeline, proactively alert on inference latency anomalies, and guarantee adherence to SLOs, all without requiring code modifications or service restarts. LatencyPrism has been deployed across thousands of XPUs for over six months. It enables low-overhead real-time monitoring at batch level with alerts triggered in milliseconds. This approach distinguishes between workload-driven latency variations and anomalies indicating underlying issues with an F1-score of 0.98. We also conduct extensive experiments and investigations into root cause analysis to demonstrate LatencyPrism's capability.", "AI": {"tldr": "LatencyPrism\uff1a\u9996\u4e2a\u96f6\u4fb5\u5165\u591a\u5e73\u53f0\u5ef6\u8fdf\u5256\u6790\u7cfb\u7edf\uff0c\u7528\u4e8eLLM\u63a8\u7406\u5ef6\u8fdf\u76d1\u63a7\u3001\u5f02\u5e38\u68c0\u6d4b\u548cSLO\u4fdd\u969c\uff0c\u65e0\u9700\u4ee3\u7801\u4fee\u6539\u6216\u670d\u52a1\u91cd\u542f", "motivation": "LLM\u63a8\u7406\u5ef6\u8fdf\u76f4\u63a5\u5f71\u54cd\u7528\u6237\u4f53\u9a8c\u548c\u8fd0\u8425\u6210\u672c\uff0c\u4f46\u73b0\u6709AI\u6027\u80fd\u5206\u6790\u65b9\u6cd5\u5b58\u5728\u4e0d\u8db3\uff1a1\uff09\u4fb5\u5165\u5f0f\u8bbe\u8ba1\u9700\u8981\u670d\u52a1\u91cd\u542f\u6216\u6682\u505c\uff1b2\uff09\u786c\u4ef6\u7ed1\u5b9a\u5b9e\u73b0\u65e0\u6cd5\u9002\u5e94\u5f02\u6784\u63a8\u7406\u73af\u5883\uff1b3\uff09\u5206\u5e03\u5f0f\u63a8\u7406\u73af\u5883\uff08\u591a\u6837\u8f6f\u4ef6\u6846\u67b6\u548cXPU\u67b6\u6784\uff09\u52a0\u4e0a\u52a8\u6001\u5de5\u4f5c\u8d1f\u8f7d\u4f7f\u5ef6\u8fdf\u5206\u6790\u56f0\u96be", "method": "LatencyPrism\u91c7\u7528\u96f6\u4fb5\u5165\u591a\u5e73\u53f0\u5ef6\u8fdf\u5256\u6790\u7cfb\u7edf\u8bbe\u8ba1\uff0c\u80fd\u591f\uff1a1\uff09\u8de8\u6d41\u6c34\u7ebf\u5206\u89e3\u63a8\u7406\u5ef6\u8fdf\uff1b2\uff09\u4e3b\u52a8\u9884\u8b66\u63a8\u7406\u5ef6\u8fdf\u5f02\u5e38\uff1b3\uff09\u4fdd\u8bc1SLO\u9075\u5b88\u3002\u7cfb\u7edf\u652f\u6301\u6279\u91cf\u7ea7\u4f4e\u5f00\u9500\u5b9e\u65f6\u76d1\u63a7\uff0c\u6beb\u79d2\u7ea7\u89e6\u53d1\u8b66\u62a5\uff0c\u65e0\u9700\u4ee3\u7801\u4fee\u6539\u6216\u670d\u52a1\u91cd\u542f", "result": "\u5df2\u5728\u6570\u5343\u4e2aXPU\u4e0a\u90e8\u7f72\u8d85\u8fc76\u4e2a\u6708\uff0c\u80fd\u591f\u533a\u5206\u5de5\u4f5c\u8d1f\u8f7d\u9a71\u52a8\u7684\u5ef6\u8fdf\u53d8\u5316\u548c\u6307\u793a\u6f5c\u5728\u95ee\u9898\u7684\u5f02\u5e38\uff0cF1\u5206\u6570\u8fbe0.98\u3002\u901a\u8fc7\u5e7f\u6cdb\u5b9e\u9a8c\u548c\u6839\u56e0\u5206\u6790\u5c55\u793a\u4e86\u7cfb\u7edf\u80fd\u529b", "conclusion": "LatencyPrism\u89e3\u51b3\u4e86\u73b0\u6709AI\u6027\u80fd\u5206\u6790\u65b9\u6cd5\u5728\u5b9e\u65f6\u751f\u4ea7\u73af\u5883\u4e2d\u7684\u4e0d\u8db3\uff0c\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u96f6\u4fb5\u5165\u5ef6\u8fdf\u76d1\u63a7\u548c\u5f02\u5e38\u68c0\u6d4b\u89e3\u51b3\u65b9\u6848\uff0c\u7279\u522b\u9002\u7528\u4e8e\u5f02\u6784\u5206\u5e03\u5f0fLLM\u63a8\u7406\u73af\u5883"}}
{"id": "2601.08884", "categories": ["cs.SE", "cs.AI", "cs.DC"], "pdf": "https://arxiv.org/pdf/2601.08884", "abs": "https://arxiv.org/abs/2601.08884", "authors": ["Samyak Jhaveri", "Cristina V. Lopes"], "title": "Bridging the Gap: Empowering Small Models in Reliable OpenACC-based Parallelization via GEPA-Optimized Prompting", "comment": null, "summary": "OpenACC lowers the barrier to GPU offloading, but writing high-performing pragma remains complex, requiring deep domain expertise in memory hierarchies, data movement, and parallelization strategies. Large Language Models (LLMs) present a promising potential solution for automated parallel code generation, but naive prompting often results in syntactically incorrect directives, uncompilable code, or performance that fails to exceed CPU baselines. We present a systematic prompt optimization approach to enhance OpenACC pragma generation without the prohibitive computational costs associated with model post-training. Leveraging the GEPA (GEnetic-PAreto) framework, we iteratively evolve prompts through a reflective feedback loop. This process utilizes crossover and mutation of instructions, guided by expert-curated gold examples and structured feedback based on clause- and clause parameter-level mismatches between the gold and predicted pragma. In our evaluation on the PolyBench suite, we observe an increase in compilation success rates for programs annotated with OpenACC pragma generated using the optimized prompts compared to those annotated using the simpler initial prompt, particularly for the \"nano\"-scale models. Specifically, with optimized prompts, the compilation success rate for GPT-4.1 Nano surged from 66.7% to 93.3%, and for GPT-5 Nano improved from 86.7% to 100%, matching or surpassing the capabilities of their significantly larger, more expensive versions. Beyond compilation, the optimized prompts resulted in a 21% increase in the number of programs that achieve functional GPU speedups over CPU baselines. These results demonstrate that prompt optimization effectively unlocks the potential of smaller, cheaper LLMs in writing stable and effective GPU-offloading directives, establishing a cost-effective pathway to automated directive-based parallelization in HPC workflows.", "AI": {"tldr": "\u4f7f\u7528\u9057\u4f20\u5e15\u7d2f\u6258\u4f18\u5316\u6846\u67b6\u6539\u8fdbOpenACC\u5e76\u884c\u4ee3\u7801\u751f\u6210\u7684\u63d0\u793a\u5de5\u7a0b\uff0c\u4f7f\u5c0f\u578bLLM\u5728\u7f16\u8bd1\u6210\u529f\u7387\u548cGPU\u52a0\u901f\u6027\u80fd\u4e0a\u8fbe\u5230\u6216\u8d85\u8fc7\u5927\u578b\u6a21\u578b\u6c34\u5e73", "motivation": "OpenACC\u964d\u4f4e\u4e86GPU\u5378\u8f7d\u7684\u95e8\u69db\uff0c\u4f46\u7f16\u5199\u9ad8\u6027\u80fd\u7684pragma\u4ecd\u7136\u590d\u6742\uff0c\u9700\u8981\u6df1\u539a\u7684\u9886\u57df\u4e13\u4e1a\u77e5\u8bc6\u3002\u5927\u8bed\u8a00\u6a21\u578b\u4e3a\u81ea\u52a8\u5316\u5e76\u884c\u4ee3\u7801\u751f\u6210\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u4f46\u7b80\u5355\u7684\u63d0\u793a\u901a\u5e38\u4f1a\u5bfc\u81f4\u8bed\u6cd5\u9519\u8bef\u3001\u65e0\u6cd5\u7f16\u8bd1\u6216\u6027\u80fd\u4e0d\u4f73\u7684\u4ee3\u7801\u3002", "method": "\u63d0\u51fa\u7cfb\u7edf\u5316\u7684\u63d0\u793a\u4f18\u5316\u65b9\u6cd5\uff0c\u5229\u7528GEPA\uff08\u9057\u4f20-\u5e15\u7d2f\u6258\uff09\u6846\u67b6\uff0c\u901a\u8fc7\u53cd\u601d\u53cd\u9988\u5faa\u73af\u8fed\u4ee3\u6f14\u5316\u63d0\u793a\u3002\u8be5\u8fc7\u7a0b\u4f7f\u7528\u6307\u4ee4\u7684\u4ea4\u53c9\u548c\u53d8\u5f02\uff0c\u4ee5\u4e13\u5bb6\u7b56\u5212\u7684\u9ec4\u91d1\u793a\u4f8b\u4e3a\u6307\u5bfc\uff0c\u5e76\u57fa\u4e8e\u9ec4\u91d1\u548c\u9884\u6d4bpragma\u4e4b\u95f4\u7684\u5b50\u53e5\u548c\u5b50\u53e5\u53c2\u6570\u7ea7\u522b\u4e0d\u5339\u914d\u63d0\u4f9b\u7ed3\u6784\u5316\u53cd\u9988\u3002", "result": "\u5728PolyBench\u5957\u4ef6\u8bc4\u4f30\u4e2d\uff0c\u4f7f\u7528\u4f18\u5316\u63d0\u793a\u751f\u6210\u7684OpenACC pragma\u7f16\u8bd1\u6210\u529f\u7387\u663e\u8457\u63d0\u9ad8\uff0c\u7279\u522b\u662f\u5bf9\u4e8e\"nano\"\u89c4\u6a21\u6a21\u578b\uff1aGPT-4.1 Nano\u4ece66.7%\u63d0\u5347\u523093.3%\uff0cGPT-5 Nano\u4ece86.7%\u63d0\u5347\u5230100%\uff0c\u8fbe\u5230\u6216\u8d85\u8fc7\u66f4\u5927\u66f4\u6602\u8d35\u7248\u672c\u7684\u80fd\u529b\u3002\u4f18\u5316\u63d0\u793a\u8fd8\u4f7f\u5b9e\u73b0GPU\u52a0\u901f\u7684\u7a0b\u5e8f\u6570\u91cf\u589e\u52a0\u4e8621%\u3002", "conclusion": "\u63d0\u793a\u4f18\u5316\u6709\u6548\u91ca\u653e\u4e86\u66f4\u5c0f\u3001\u66f4\u4fbf\u5b9cLLM\u5728\u7f16\u5199\u7a33\u5b9a\u6709\u6548GPU\u5378\u8f7d\u6307\u4ee4\u65b9\u9762\u7684\u6f5c\u529b\uff0c\u4e3aHPC\u5de5\u4f5c\u6d41\u4e2d\u57fa\u4e8e\u6307\u4ee4\u7684\u81ea\u52a8\u5316\u5e76\u884c\u5316\u5efa\u7acb\u4e86\u7ecf\u6d4e\u9ad8\u6548\u7684\u9014\u5f84\u3002"}}
{"id": "2601.09334", "categories": ["cs.DC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.09334", "abs": "https://arxiv.org/abs/2601.09334", "authors": ["Valerio Besozzi", "Matteo Della Bartola", "Patrizio Dazzi", "Marco Danelutto"], "title": "High-Performance Serverless Computing: A Systematic Literature Review on Serverless for HPC, AI, and Big Data", "comment": null, "summary": "The widespread deployment of large-scale, compute-intensive applications such as high-performance computing, artificial intelligence, and big data is leading to convergence between cloud and high-performance computing infrastructures. Cloud providers are increasingly integrating high-performance computing capabilities in their infrastructures, such as hardware accelerators and high-speed interconnects, while researchers in the high-performance computing community are starting to explore cloud-native paradigms to improve scalability, elasticity, and resource utilization. In this context, serverless computing emerges as a promising execution model to efficiently handle highly dynamic, parallel, and distributed workloads. This paper presents a comprehensive systematic literature review of 122 research articles published between 2018 and early 2025, exploring the use of the serverless paradigm to develop, deploy, and orchestrate compute-intensive applications across cloud, high-performance computing, and hybrid environments. From these, a taxonomy comprising eight primary research directions and nine targeted use case domains is proposed, alongside an analysis of recent publication trends and collaboration networks among authors, highlighting the growing interest and interconnections within this emerging research field. Overall, this work aims to offer a valuable foundation for both new researchers and experienced practitioners, guiding the development of next-generation serverless solutions for parallel compute-intensive applications.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u5bf92018-2025\u5e74\u95f4122\u7bc7\u7814\u7a76\u6587\u7ae0\u8fdb\u884c\u4e86\u7cfb\u7edf\u6027\u6587\u732e\u7efc\u8ff0\uff0c\u63a2\u8ba8\u4e86\u65e0\u670d\u52a1\u5668\u8ba1\u7b97\u5728\u4e91\u8ba1\u7b97\u3001\u9ad8\u6027\u80fd\u8ba1\u7b97\u548c\u6df7\u5408\u73af\u5883\u4e2d\u5904\u7406\u8ba1\u7b97\u5bc6\u96c6\u578b\u5e94\u7528\u7684\u4f7f\u7528\u60c5\u51b5\uff0c\u63d0\u51fa\u4e86\u5305\u542b8\u4e2a\u7814\u7a76\u65b9\u5411\u30019\u4e2a\u7528\u4f8b\u9886\u57df\u7684\u5206\u7c7b\u6cd5\u3002", "motivation": "\u968f\u7740\u9ad8\u6027\u80fd\u8ba1\u7b97\u3001\u4eba\u5de5\u667a\u80fd\u548c\u5927\u6570\u636e\u7b49\u8ba1\u7b97\u5bc6\u96c6\u578b\u5e94\u7528\u7684\u5e7f\u6cdb\u90e8\u7f72\uff0c\u4e91\u548c\u9ad8\u6027\u80fd\u8ba1\u7b97\u57fa\u7840\u8bbe\u65bd\u6b63\u5728\u878d\u5408\u3002\u4e91\u63d0\u4f9b\u5546\u6b63\u5728\u96c6\u6210\u9ad8\u6027\u80fd\u8ba1\u7b97\u80fd\u529b\uff0c\u800c\u9ad8\u6027\u80fd\u8ba1\u7b97\u793e\u533a\u5f00\u59cb\u63a2\u7d22\u4e91\u539f\u751f\u8303\u5f0f\u4ee5\u63d0\u9ad8\u53ef\u6269\u5c55\u6027\u3001\u5f39\u6027\u548c\u8d44\u6e90\u5229\u7528\u7387\u3002\u5728\u6b64\u80cc\u666f\u4e0b\uff0c\u65e0\u670d\u52a1\u5668\u8ba1\u7b97\u6210\u4e3a\u5904\u7406\u9ad8\u5ea6\u52a8\u6001\u3001\u5e76\u884c\u548c\u5206\u5e03\u5f0f\u5de5\u4f5c\u8d1f\u8f7d\u7684\u6709\u524d\u666f\u6267\u884c\u6a21\u578b\u3002", "method": "\u5bf92018\u5e74\u81f32025\u5e74\u521d\u53d1\u8868\u7684122\u7bc7\u7814\u7a76\u6587\u7ae0\u8fdb\u884c\u5168\u9762\u7684\u7cfb\u7edf\u6027\u6587\u732e\u7efc\u8ff0\uff0c\u5206\u6790\u65e0\u670d\u52a1\u5668\u8303\u5f0f\u5728\u4e91\u8ba1\u7b97\u3001\u9ad8\u6027\u80fd\u8ba1\u7b97\u548c\u6df7\u5408\u73af\u5883\u4e2d\u5f00\u53d1\u3001\u90e8\u7f72\u548c\u7f16\u6392\u8ba1\u7b97\u5bc6\u96c6\u578b\u5e94\u7528\u7684\u4f7f\u7528\u60c5\u51b5\u3002\u63d0\u51fa\u4e86\u5305\u542b8\u4e2a\u4e3b\u8981\u7814\u7a76\u65b9\u5411\u548c9\u4e2a\u76ee\u6807\u7528\u4f8b\u9886\u57df\u7684\u5206\u7c7b\u6cd5\uff0c\u5e76\u5206\u6790\u4e86\u6700\u8fd1\u7684\u53d1\u8868\u8d8b\u52bf\u548c\u4f5c\u8005\u5408\u4f5c\u7f51\u7edc\u3002", "result": "\u7814\u7a76\u5c55\u793a\u4e86\u65e0\u670d\u52a1\u5668\u8ba1\u7b97\u5728\u5904\u7406\u8ba1\u7b97\u5bc6\u96c6\u578b\u5e94\u7528\u65b9\u9762\u7684\u5e94\u7528\u73b0\u72b6\uff0c\u63d0\u51fa\u4e86\u7cfb\u7edf\u7684\u5206\u7c7b\u6846\u67b6\uff0c\u63ed\u793a\u4e86\u8be5\u65b0\u5174\u7814\u7a76\u9886\u57df\u65e5\u76ca\u589e\u957f\u7684\u5174\u8da3\u548c\u5185\u90e8\u8054\u7cfb\u3002\u901a\u8fc7\u5206\u6790\u53d1\u8868\u8d8b\u52bf\u548c\u5408\u4f5c\u7f51\u7edc\uff0c\u7a81\u51fa\u4e86\u8be5\u9886\u57df\u7684\u53d1\u5c55\u52a8\u6001\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3a\u65b0\u624b\u7814\u7a76\u4eba\u5458\u548c\u7ecf\u9a8c\u4e30\u5bcc\u7684\u4ece\u4e1a\u8005\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u57fa\u7840\uff0c\u6307\u5bfc\u4e0b\u4e00\u4ee3\u65e0\u670d\u52a1\u5668\u89e3\u51b3\u65b9\u6848\u7684\u5f00\u53d1\uff0c\u4ee5\u652f\u6301\u5e76\u884c\u8ba1\u7b97\u5bc6\u96c6\u578b\u5e94\u7528\u3002\u65e0\u670d\u52a1\u5668\u8ba1\u7b97\u5728\u878d\u5408\u4e91\u548c\u9ad8\u6027\u80fd\u8ba1\u7b97\u57fa\u7840\u8bbe\u65bd\u7684\u80cc\u666f\u4e0b\u5c55\u73b0\u51fa\u5de8\u5927\u6f5c\u529b\u3002"}}
{"id": "2601.08995", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.08995", "abs": "https://arxiv.org/abs/2601.08995", "authors": ["Brent Pappas", "Paul Gazzillo"], "title": "Build Code is Still Code: Finding the Antidote for Pipeline Poisoning", "comment": "2026 IEEE/ACM 48th International Conference on Software Engineering. April 12--18, 2026. Rio de Janeiro, Brazil. 5 pages. 3 figures. 2 code listings. 1 table", "summary": "Open source C code underpins society's computing infrastructure. Decades of work has helped harden C code against attackers, but C projects do not consist of only C code. C projects also contain build system code for automating development tasks like compilation, testing, and packaging. These build systems are critcal to software supply chain security and vulnerable to being poisoned, with the XZ Utils and SolarWinds attacks being recent examples. Existing techniques try to harden software supply chains by verifying software dependencies, but such methods ignore the build system itself. Similarly, classic software security checkers only analyze and monitor program code, not build system code. Moreover, poisoned build systems can easily circumvent tools for detecting program code vulnerabilities by disabling such checks. We present development phase isolation, a novel strategy for hardening build systems against poisoning by modeling the information and behavior permissions of build automation as if it were program code. We have prototyped this approach as a tool called Foreman, which successfully detects and warns about the poisoned test files involved in the XZ Utils attack. We outline our future plans to protect against pipeline poisoning by automatically checking development phase isolation. We envision a future where build system security checkers are as prevalent as program code checkers.", "AI": {"tldr": "Foreman\u5de5\u5177\u901a\u8fc7\u5f00\u53d1\u9636\u6bb5\u9694\u79bb\u7b56\u7565\u68c0\u6d4b\u6784\u5efa\u7cfb\u7edf\u4e2d\u6bd2\uff0c\u6210\u529f\u8bc6\u522bXZ Utils\u653b\u51fb\u4e2d\u7684\u6076\u610f\u6d4b\u8bd5\u6587\u4ef6\uff0c\u65e8\u5728\u8ba9\u6784\u5efa\u7cfb\u7edf\u5b89\u5168\u68c0\u67e5\u50cf\u4ee3\u7801\u68c0\u67e5\u4e00\u6837\u666e\u53ca\u3002", "motivation": "C\u9879\u76ee\u4e0d\u4ec5\u5305\u542bC\u4ee3\u7801\uff0c\u8fd8\u5305\u542b\u6784\u5efa\u7cfb\u7edf\u4ee3\u7801\uff08\u5982\u7f16\u8bd1\u3001\u6d4b\u8bd5\u3001\u6253\u5305\u81ea\u52a8\u5316\uff09\u3002\u73b0\u6709\u5b89\u5168\u6280\u672f\u8981\u4e48\u53ea\u9a8c\u8bc1\u8f6f\u4ef6\u4f9d\u8d56\u5ffd\u7565\u6784\u5efa\u7cfb\u7edf\u672c\u8eab\uff0c\u8981\u4e48\u53ea\u5206\u6790\u7a0b\u5e8f\u4ee3\u7801\u4e0d\u68c0\u67e5\u6784\u5efa\u7cfb\u7edf\u4ee3\u7801\u3002\u4e2d\u6bd2\u7684\u6784\u5efa\u7cfb\u7edf\u53ef\u4ee5\u8f7b\u6613\u7ed5\u8fc7\u7a0b\u5e8f\u6f0f\u6d1e\u68c0\u6d4b\u5de5\u5177\uff0cXZ Utils\u548cSolarWinds\u653b\u51fb\u5c31\u662f\u8fd1\u671f\u6848\u4f8b\u3002", "method": "\u63d0\u51fa\"\u5f00\u53d1\u9636\u6bb5\u9694\u79bb\"\u7b56\u7565\uff0c\u5c06\u6784\u5efa\u81ea\u52a8\u5316\u7684\u4fe1\u606f\u548c\u884c\u4e3a\u6743\u9650\u5efa\u6a21\u4e3a\u7a0b\u5e8f\u4ee3\u7801\u3002\u539f\u578b\u5de5\u5177Foreman\u5b9e\u73b0\u4e86\u8fd9\u79cd\u65b9\u6cd5\uff0c\u901a\u8fc7\u6743\u9650\u5efa\u6a21\u68c0\u6d4b\u6784\u5efa\u7cfb\u7edf\u4e2d\u6bd2\u3002", "result": "Foreman\u6210\u529f\u68c0\u6d4b\u5e76\u8b66\u544a\u4e86XZ Utils\u653b\u51fb\u4e2d\u6d89\u53ca\u7684\u6076\u610f\u6d4b\u8bd5\u6587\u4ef6\u3002\u5c55\u793a\u4e86\u5f00\u53d1\u9636\u6bb5\u9694\u79bb\u7b56\u7565\u5728\u68c0\u6d4b\u6784\u5efa\u7cfb\u7edf\u4e2d\u6bd2\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u6784\u5efa\u7cfb\u7edf\u5b89\u5168\u68c0\u67e5\u5668\u5e94\u8be5\u50cf\u7a0b\u5e8f\u4ee3\u7801\u68c0\u67e5\u5668\u4e00\u6837\u666e\u53ca\u3002\u672a\u6765\u8ba1\u5212\u901a\u8fc7\u81ea\u52a8\u68c0\u67e5\u5f00\u53d1\u9636\u6bb5\u9694\u79bb\u6765\u9632\u6b62\u6d41\u6c34\u7ebf\u4e2d\u6bd2\uff0c\u63d0\u5347\u8f6f\u4ef6\u4f9b\u5e94\u94fe\u5b89\u5168\u3002"}}
{"id": "2601.08998", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.08998", "abs": "https://arxiv.org/abs/2601.08998", "authors": ["Alexander Berndt", "Thomas Bach", "Rainer Gemulla", "Marcus Kessel", "Sebastian Baltes"], "title": "On the Flakiness of LLM-Generated Tests for Industrial and Open-Source Database Management Systems", "comment": "12 pages, 5 tables, 3 figures, accepted at the 48th International Conference on Software Engineering: Software Engineering in Practice (ICSE SEIP 2026)", "summary": "Flaky tests are a common problem in software testing. They produce inconsistent results when executed multiple times on the same code, invalidating the assumption that a test failure indicates a software defect. Recent work on LLM-based test generation has identified flakiness as a potential problem with generated tests. However, its prevalence and underlying causes are unclear. We examined the flakiness of LLM-generated tests in the context of four relational database management systems: SAP HANA, DuckDB, MySQL, and SQLite. We amplified test suites with two LLMs, GPT-4o and Mistral-Large-Instruct-2407, to assess the flakiness of the generated test cases. Our results suggest that generated tests have a slightly higher proportion of flaky tests compared to existing tests. Based on a manual inspection, we found that the most common root cause of flakiness was the reliance of a test on a certain order that is not guaranteed (\"unordered collection\"), which was present in 72 of 115 flaky tests (63%). Furthermore, both LLMs transferred the flakiness from the existing tests to the newly generated tests via the provided prompt context. Our experiments suggest that flakiness transfer is more prevalent in closed-source systems such as SAP HANA than in open-source systems. Our study informs developers on what types of flakiness to expect from LLM-generated tests. It also highlights the importance of providing LLMs with tailored context when employing LLMs for test generation.", "AI": {"tldr": "LLM\u751f\u6210\u7684\u6570\u636e\u5e93\u6d4b\u8bd5\u4e2d\uff0c\u4e0d\u7a33\u5b9a\u6d4b\u8bd5\u6bd4\u4f8b\u7565\u9ad8\u4e8e\u73b0\u6709\u6d4b\u8bd5\uff0c\u4e3b\u8981\u539f\u56e0\u662f\u4f9d\u8d56\u672a\u4fdd\u8bc1\u7684\u987a\u5e8f\uff08\u65e0\u5e8f\u96c6\u5408\uff09\uff0c\u4e14LLM\u4f1a\u901a\u8fc7\u63d0\u793a\u4e0a\u4e0b\u6587\u5c06\u73b0\u6709\u6d4b\u8bd5\u7684\u4e0d\u7a33\u5b9a\u6027\u4f20\u9012\u5230\u65b0\u6d4b\u8bd5\u4e2d\u3002", "motivation": "\u7814\u7a76LLM\u751f\u6210\u7684\u6d4b\u8bd5\u4e2d\u4e0d\u7a33\u5b9a\u6d4b\u8bd5\u7684\u666e\u904d\u6027\u548c\u6839\u672c\u539f\u56e0\uff0c\u7279\u522b\u662f\u5728\u5173\u7cfb\u6570\u636e\u5e93\u7ba1\u7406\u7cfb\u7edf\u73af\u5883\u4e2d\uff0c\u56e0\u4e3a\u73b0\u6709\u7814\u7a76\u5df2\u53d1\u73b0\u4e0d\u7a33\u5b9a\u6027\u662fLLM\u751f\u6210\u6d4b\u8bd5\u7684\u6f5c\u5728\u95ee\u9898\uff0c\u4f46\u5176\u666e\u904d\u6027\u548c\u539f\u56e0\u5c1a\u4e0d\u6e05\u695a\u3002", "method": "\u5728\u56db\u4e2a\u5173\u7cfb\u6570\u636e\u5e93\u7ba1\u7406\u7cfb\u7edf\uff08SAP HANA\u3001DuckDB\u3001MySQL\u3001SQLite\uff09\u4e2d\uff0c\u4f7f\u7528GPT-4o\u548cMistral-Large-Instruct-2407\u4e24\u4e2aLLM\u6269\u589e\u6d4b\u8bd5\u5957\u4ef6\uff0c\u8bc4\u4f30\u751f\u6210\u6d4b\u8bd5\u7528\u4f8b\u7684\u4e0d\u7a33\u5b9a\u6027\uff0c\u5e76\u901a\u8fc7\u624b\u52a8\u68c0\u67e5\u5206\u6790\u6839\u672c\u539f\u56e0\u3002", "result": "\u751f\u6210\u6d4b\u8bd5\u7684\u4e0d\u7a33\u5b9a\u6d4b\u8bd5\u6bd4\u4f8b\u7565\u9ad8\u4e8e\u73b0\u6709\u6d4b\u8bd5\uff1b\u4e3b\u8981\u6839\u672c\u539f\u56e0\u662f\u6d4b\u8bd5\u4f9d\u8d56\u672a\u4fdd\u8bc1\u7684\u987a\u5e8f\uff08\"\u65e0\u5e8f\u96c6\u5408\"\uff09\uff0c\u5728115\u4e2a\u4e0d\u7a33\u5b9a\u6d4b\u8bd5\u4e2d\u536072\u4e2a\uff0863%\uff09\uff1bLLM\u901a\u8fc7\u63d0\u793a\u4e0a\u4e0b\u6587\u5c06\u73b0\u6709\u6d4b\u8bd5\u7684\u4e0d\u7a33\u5b9a\u6027\u4f20\u9012\u5230\u65b0\u6d4b\u8bd5\u4e2d\uff1b\u5728\u95ed\u6e90\u7cfb\u7edf\uff08\u5982SAP HANA\uff09\u4e2d\u4e0d\u7a33\u5b9a\u6027\u4f20\u9012\u6bd4\u5f00\u6e90\u7cfb\u7edf\u66f4\u666e\u904d\u3002", "conclusion": "\u7814\u7a76\u4e3a\u5f00\u53d1\u8005\u63d0\u4f9b\u4e86\u5173\u4e8eLLM\u751f\u6210\u6d4b\u8bd5\u4e2d\u53ef\u80fd\u9047\u5230\u7684\u4e0d\u7a33\u5b9a\u6027\u7c7b\u578b\u7684\u89c1\u89e3\uff0c\u5e76\u5f3a\u8c03\u4e86\u5728\u4f7f\u7528LLM\u8fdb\u884c\u6d4b\u8bd5\u751f\u6210\u65f6\u63d0\u4f9b\u5b9a\u5236\u5316\u4e0a\u4e0b\u6587\u7684\u91cd\u8981\u6027\uff0c\u7279\u522b\u662f\u8981\u907f\u514d\u4e0d\u7a33\u5b9a\u6027\u4ece\u73b0\u6709\u6d4b\u8bd5\u4f20\u9012\u5230\u65b0\u6d4b\u8bd5\u3002"}}
{"id": "2601.09393", "categories": ["cs.SE", "cs.DC", "cs.PF"], "pdf": "https://arxiv.org/pdf/2601.09393", "abs": "https://arxiv.org/abs/2601.09393", "authors": ["Zirui Wang", "Guangba Yu", "Michael R. Lyu"], "title": "AI-NativeBench: An Open-Source White-Box Agentic Benchmark Suite for AI-Native Systems", "comment": null, "summary": "The transition from Cloud-Native to AI-Native architectures is fundamentally reshaping software engineering, replacing deterministic microservices with probabilistic agentic services. However, this shift renders traditional black-box evaluation paradigms insufficient: existing benchmarks measure raw model capabilities while remaining blind to system-level execution dynamics. To bridge this gap, we introduce AI-NativeBench, the first application-centric and white-box AI-Native benchmark suite grounded in Model Context Protocol (MCP) and Agent-to-Agent (A2A) standards. By treating agentic spans as first-class citizens within distributed traces, our methodology enables granular analysis of engineering characteristics beyond simple capabilities. Leveraging this benchmark across 21 system variants, we uncover critical engineering realities invisible to traditional metrics: a parameter paradox where lightweight models often surpass flagships in protocol adherence, a pervasive inference dominance that renders protocol overhead secondary, and an expensive failure pattern where self-healing mechanisms paradoxically act as cost multipliers on unviable workflows. This work provides the first systematic evidence to guide the transition from measuring model capability to engineering reliable AI-Native systems. To facilitate reproducibility and further research, we have open-sourced the benchmark and dataset.", "AI": {"tldr": "AI-NativeBench\uff1a\u9996\u4e2a\u57fa\u4e8eMCP\u548cA2A\u6807\u51c6\u7684\u5e94\u7528\u4e2d\u5fc3\u5316\u767d\u76d2AI\u539f\u751f\u57fa\u51c6\u6d4b\u8bd5\u5957\u4ef6\uff0c\u63ed\u793a\u4f20\u7edf\u9ed1\u76d2\u8bc4\u4f30\u65e0\u6cd5\u53d1\u73b0\u7684\u7cfb\u7edf\u7ea7\u5de5\u7a0b\u7279\u6027", "motivation": "\u4ece\u4e91\u539f\u751f\u5411AI\u539f\u751f\u67b6\u6784\u8f6c\u578b\u4e2d\uff0c\u4f20\u7edf\u9ed1\u76d2\u8bc4\u4f30\u8303\u5f0f\u5df2\u4e0d\u8db3\u591f\uff0c\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u4ec5\u8861\u91cf\u539f\u59cb\u6a21\u578b\u80fd\u529b\u800c\u5ffd\u89c6\u7cfb\u7edf\u7ea7\u6267\u884c\u52a8\u6001\uff0c\u9700\u8981\u65b0\u7684\u8bc4\u4f30\u65b9\u6cd5", "method": "\u5f15\u5165AI-NativeBench\u57fa\u51c6\u5957\u4ef6\uff0c\u57fa\u4e8e\u6a21\u578b\u4e0a\u4e0b\u6587\u534f\u8bae(MCP)\u548c\u4ee3\u7406\u5230\u4ee3\u7406(A2A)\u6807\u51c6\uff0c\u5c06\u4ee3\u7406\u8de8\u5ea6\u4f5c\u4e3a\u5206\u5e03\u5f0f\u8ddf\u8e2a\u4e2d\u7684\u4e00\u7b49\u516c\u6c11\uff0c\u5b9e\u73b0\u7ec6\u7c92\u5ea6\u5de5\u7a0b\u7279\u6027\u5206\u6790", "result": "\u572821\u4e2a\u7cfb\u7edf\u53d8\u4f53\u4e0a\u53d1\u73b0\u4f20\u7edf\u6307\u6807\u65e0\u6cd5\u63ed\u793a\u7684\u5173\u952e\u5de5\u7a0b\u73b0\u5b9e\uff1a\u53c2\u6570\u6096\u8bba\uff08\u8f7b\u91cf\u6a21\u578b\u5728\u534f\u8bae\u9075\u5faa\u4e0a\u5e38\u4f18\u4e8e\u65d7\u8230\u6a21\u578b\uff09\u3001\u666e\u904d\u63a8\u7406\u4e3b\u5bfc\uff08\u534f\u8bae\u5f00\u9500\u6b21\u8981\uff09\u3001\u6602\u8d35\u5931\u8d25\u6a21\u5f0f\uff08\u81ea\u6108\u673a\u5236\u5728\u4e0d\u53ef\u884c\u5de5\u4f5c\u6d41\u4e0a\u6210\u4e3a\u6210\u672c\u500d\u589e\u5668\uff09", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3a\u4ece\u8861\u91cf\u6a21\u578b\u80fd\u529b\u8f6c\u5411\u5de5\u7a0b\u53ef\u9760AI\u539f\u751f\u7cfb\u7edf\u63d0\u4f9b\u4e86\u9996\u4e2a\u7cfb\u7edf\u6027\u8bc1\u636e\uff0c\u5f00\u6e90\u57fa\u51c6\u548c\u6570\u636e\u96c6\u4fc3\u8fdb\u53ef\u590d\u73b0\u6027\u548c\u8fdb\u4e00\u6b65\u7814\u7a76"}}
{"id": "2601.09171", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.09171", "abs": "https://arxiv.org/abs/2601.09171", "authors": ["Dohyun Kim", "Sanggu Han", "Sangmin Woo", "Joonha Jang", "Jaehoon Kim", "Changhun Song", "Yongdae Kim"], "title": "SafePlanner: Testing Safety of the Automated Driving System Plan Model", "comment": null, "summary": "In this work, we present SafePlanner, a systematic testing framework for identifying safety-critical flaws in the Plan model of Automated Driving Systems (ADS). SafePlanner targets two core challenges: generating structurally meaningful test scenarios and detecting hazardous planning behaviors. To maximize coverage, SafePlanner performs a structural analysis of the Plan model implementation - specifically, its scene-transition logic and hierarchical control flow - and uses this insight to extract feasible scene transitions from code. It then composes test scenarios by combining these transitions with non-player vehicle (NPC) behaviors. Guided fuzzing is applied to explore the behavioral space of the Plan model under these scenarios. We evaluate SafePlanner on Baidu Apollo, a production-grade level 4 ADS. It generates 20635 test cases and detects 520 hazardous behaviors, grouped into 15 root causes through manual analysis. For four of these, we applied patches based on our analysis; the issues disappeared, and no apparent side effects were observed. SafePlanner achieves 83.63 percent function and 63.22 percent decision coverage on the Plan model, outperforming baselines in both bug discovery and efficiency.", "AI": {"tldr": "SafePlanner\u662f\u4e00\u4e2a\u7cfb\u7edf\u5316\u6d4b\u8bd5\u6846\u67b6\uff0c\u7528\u4e8e\u68c0\u6d4b\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u89c4\u5212\u6a21\u578b\u4e2d\u7684\u5b89\u5168\u5173\u952e\u7f3a\u9677\uff0c\u901a\u8fc7\u7ed3\u6784\u5206\u6790\u548c\u5f15\u5bfc\u5f0f\u6a21\u7cca\u6d4b\u8bd5\u751f\u6210\u6709\u610f\u4e49\u7684\u6d4b\u8bd5\u573a\u666f\u5e76\u53d1\u73b0\u5371\u9669\u884c\u4e3a\u3002", "motivation": "\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u7684\u89c4\u5212\u6a21\u578b\u5b58\u5728\u5b89\u5168\u5173\u952e\u7f3a\u9677\uff0c\u9700\u8981\u7cfb\u7edf\u5316\u7684\u6d4b\u8bd5\u65b9\u6cd5\u6765\u751f\u6210\u6709\u610f\u4e49\u7684\u6d4b\u8bd5\u573a\u666f\u5e76\u68c0\u6d4b\u5371\u9669\u89c4\u5212\u884c\u4e3a\u3002", "method": "\u5bf9\u89c4\u5212\u6a21\u578b\u5b9e\u73b0\u8fdb\u884c\u7ed3\u6784\u5206\u6790\uff0c\u63d0\u53d6\u53ef\u884c\u7684\u573a\u666f\u8f6c\u6362\uff0c\u7ed3\u5408NPC\u884c\u4e3a\u7ec4\u5408\u6d4b\u8bd5\u573a\u666f\uff0c\u5e76\u5e94\u7528\u5f15\u5bfc\u5f0f\u6a21\u7cca\u6d4b\u8bd5\u6765\u63a2\u7d22\u89c4\u5212\u6a21\u578b\u7684\u884c\u4e3a\u7a7a\u95f4\u3002", "result": "\u5728\u767e\u5ea6Apollo\u7cfb\u7edf\u4e0a\u751f\u621020635\u4e2a\u6d4b\u8bd5\u7528\u4f8b\uff0c\u68c0\u6d4b\u5230520\u4e2a\u5371\u9669\u884c\u4e3a\uff0c\u5206\u4e3a15\u4e2a\u6839\u672c\u539f\u56e0\uff0c\u4fee\u590d\u5176\u4e2d4\u4e2a\u95ee\u9898\u540e\u672a\u89c2\u5bdf\u5230\u660e\u663e\u526f\u4f5c\u7528\uff0c\u51fd\u6570\u8986\u76d6\u7387\u8fbe83.63%\uff0c\u51b3\u7b56\u8986\u76d6\u7387\u8fbe63.22%\u3002", "conclusion": "SafePlanner\u80fd\u6709\u6548\u53d1\u73b0\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u89c4\u5212\u6a21\u578b\u4e2d\u7684\u5b89\u5168\u7f3a\u9677\uff0c\u5728\u9519\u8bef\u53d1\u73b0\u548c\u6d4b\u8bd5\u6548\u7387\u65b9\u9762\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002"}}
{"id": "2601.09440", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.09440", "abs": "https://arxiv.org/abs/2601.09440", "authors": ["Yi Gao", "Xing Hu", "Tongtong Xu", "Jiali Zhao", "Xiaohu Yang", "Xin Xia"], "title": "DepRadar: Agentic Coordination for Context Aware Defect Impact Analysis in Deep Learning Libraries", "comment": "Published in 48th International Conference on Software Engineering (ICSE 2026)", "summary": "Deep learning libraries like Transformers and Megatron are now widely adopted in modern AI programs. However, when these libraries introduce defects, ranging from silent computation errors to subtle performance regressions, it is often challenging for downstream users to assess whether their own programs are affected. Such impact analysis requires not only understanding the defect semantics but also checking whether the client code satisfies complex triggering conditions involving configuration flags, runtime environments, and indirect API usage. We present DepRadar, an agent coordination framework for fine grained defect and impact analysis in DL library updates. DepRadar coordinates four specialized agents across three steps: 1. the PR Miner and Code Diff Analyzer extract structured defect semantics from commits or pull requests, 2. the Orchestrator Agent synthesizes these signals into a unified defect pattern with trigger conditions, and 3. the Impact Analyzer checks downstream programs to determine whether the defect can be triggered. To improve accuracy and explainability, DepRadar integrates static analysis with DL-specific domain rules for defect reasoning and client side tracing. We evaluate DepRadar on 157 PRs and 70 commits across two representative DL libraries. It achieves 90% precision in defect identification and generates high quality structured fields (average field score 1.6). On 122 client programs, DepRadar identifies affected cases with 90% recall and 80% precision, substantially outperforming other baselines.", "AI": {"tldr": "DepRadar\uff1a\u57fa\u4e8e\u591a\u667a\u80fd\u4f53\u534f\u8c03\u7684\u6df1\u5ea6\u5b66\u4e60\u5e93\u7f3a\u9677\u5f71\u54cd\u5206\u6790\u6846\u67b6\uff0c\u80fd\u591f\u4ece\u5e93\u66f4\u65b0\u4e2d\u63d0\u53d6\u7f3a\u9677\u8bed\u4e49\u5e76\u5206\u6790\u4e0b\u6e38\u7a0b\u5e8f\u662f\u5426\u53d7\u5f71\u54cd", "motivation": "\u6df1\u5ea6\u5b66\u4e60\u5e93\uff08\u5982Transformers\u3001Megatron\uff09\u7684\u7f3a\u9677\u4f1a\u4ee5\u9759\u9ed8\u8ba1\u7b97\u9519\u8bef\u6216\u6027\u80fd\u56de\u5f52\u7b49\u5f62\u5f0f\u5f71\u54cd\u4e0b\u6e38\u7a0b\u5e8f\uff0c\u4f46\u7528\u6237\u96be\u4ee5\u5224\u65ad\u81ea\u5df1\u7684\u7a0b\u5e8f\u662f\u5426\u53d7\u5f71\u54cd\uff0c\u56e0\u4e3a\u9700\u8981\u7406\u89e3\u7f3a\u9677\u8bed\u4e49\u5e76\u68c0\u67e5\u590d\u6742\u7684\u89e6\u53d1\u6761\u4ef6", "method": "DepRadar\u534f\u8c03\u56db\u4e2a\u4e13\u95e8\u667a\u80fd\u4f53\u5206\u4e09\u6b65\u5de5\u4f5c\uff1a1) PR\u6316\u6398\u5668\u548c\u4ee3\u7801\u5dee\u5f02\u5206\u6790\u5668\u4ece\u63d0\u4ea4\u4e2d\u63d0\u53d6\u7ed3\u6784\u5316\u7f3a\u9677\u8bed\u4e49\uff1b2) \u534f\u8c03\u5668\u667a\u80fd\u4f53\u5c06\u8fd9\u4e9b\u4fe1\u53f7\u5408\u6210\u4e3a\u7edf\u4e00\u7684\u7f3a\u9677\u6a21\u5f0f\u53ca\u89e6\u53d1\u6761\u4ef6\uff1b3) \u5f71\u54cd\u5206\u6790\u5668\u68c0\u67e5\u4e0b\u6e38\u7a0b\u5e8f\u662f\u5426\u80fd\u89e6\u53d1\u7f3a\u9677\u3002\u6846\u67b6\u7ed3\u5408\u9759\u6001\u5206\u6790\u548c\u6df1\u5ea6\u5b66\u4e60\u7279\u5b9a\u9886\u57df\u89c4\u5219\u4ee5\u63d0\u9ad8\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027", "result": "\u5728\u4e24\u4e2a\u4ee3\u8868\u6027DL\u5e93\u7684157\u4e2aPR\u548c70\u4e2a\u63d0\u4ea4\u4e0a\u8bc4\u4f30\uff0c\u7f3a\u9677\u8bc6\u522b\u7cbe\u5ea6\u8fbe90%\uff0c\u751f\u6210\u9ad8\u8d28\u91cf\u7ed3\u6784\u5316\u5b57\u6bb5\uff08\u5e73\u5747\u5b57\u6bb5\u5f97\u52061.6\uff09\u3002\u5728122\u4e2a\u5ba2\u6237\u7aef\u7a0b\u5e8f\u4e0a\uff0c\u8bc6\u522b\u53d7\u5f71\u54cd\u6848\u4f8b\u7684\u53ec\u56de\u7387\u8fbe90%\uff0c\u7cbe\u5ea6\u8fbe80%\uff0c\u663e\u8457\u4f18\u4e8e\u5176\u4ed6\u57fa\u7ebf\u65b9\u6cd5", "conclusion": "DepRadar\u80fd\u591f\u6709\u6548\u5206\u6790\u6df1\u5ea6\u5b66\u4e60\u5e93\u66f4\u65b0\u4e2d\u7684\u7f3a\u9677\u53ca\u5176\u5bf9\u4e0b\u6e38\u7a0b\u5e8f\u7684\u5f71\u54cd\uff0c\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u534f\u8c03\u548c\u9886\u57df\u7279\u5b9a\u89c4\u5219\u5b9e\u73b0\u4e86\u9ad8\u7cbe\u5ea6\u548c\u9ad8\u53ec\u56de\u7387\u7684\u7f3a\u9677\u5f71\u54cd\u5206\u6790"}}
{"id": "2601.09456", "categories": ["cs.SE", "cs.DL"], "pdf": "https://arxiv.org/pdf/2601.09456", "abs": "https://arxiv.org/abs/2601.09456", "authors": ["Stephan Ferenz", "Oliver Werth", "Astrid Nie\u00dfe"], "title": "Towards a Metadata Schema for Energy Research Software", "comment": null, "summary": "Domain-specific metadata schemas are essential to improve the findability and reusability of research software and to follow the FAIR4RS principles. However, many domains, including energy research, lack established metadata schemas. To address this gap, we developed a metadata schema for energy research software based on a requirement analysis and evaluated it through user testing. Our results show that the schema balances the need for formalization and interoperability, while also meeting the specific needs of energy researchers. Meanwhile, the testing showed that a good presentation of the required information is key to enable researchers to create the required metadata. This paper provides insights into the challenges and opportunities of designing a metadata schema for energy research software.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u80fd\u6e90\u7814\u7a76\u8f6f\u4ef6\u7684\u5143\u6570\u636e\u6a21\u5f0f\uff0c\u901a\u8fc7\u9700\u6c42\u5206\u6790\u548c\u7528\u6237\u6d4b\u8bd5\u8bc4\u4f30\uff0c\u5e73\u8861\u4e86\u5f62\u5f0f\u5316\u3001\u4e92\u64cd\u4f5c\u6027\u548c\u9886\u57df\u7279\u5b9a\u9700\u6c42", "motivation": "\u8bb8\u591a\u9886\u57df\uff08\u5305\u62ec\u80fd\u6e90\u7814\u7a76\uff09\u7f3a\u4e4f\u5df2\u5efa\u7acb\u7684\u5143\u6570\u636e\u6a21\u5f0f\uff0c\u800c\u9886\u57df\u7279\u5b9a\u7684\u5143\u6570\u636e\u6a21\u5f0f\u5bf9\u4e8e\u63d0\u9ad8\u7814\u7a76\u8f6f\u4ef6\u7684\u53ef\u53d1\u73b0\u6027\u548c\u53ef\u91cd\u7528\u6027\u4ee5\u53ca\u9075\u5faaFAIR4RS\u539f\u5219\u81f3\u5173\u91cd\u8981", "method": "\u57fa\u4e8e\u9700\u6c42\u5206\u6790\u5f00\u53d1\u4e86\u80fd\u6e90\u7814\u7a76\u8f6f\u4ef6\u7684\u5143\u6570\u636e\u6a21\u5f0f\uff0c\u5e76\u901a\u8fc7\u7528\u6237\u6d4b\u8bd5\u8fdb\u884c\u8bc4\u4f30", "result": "\u8be5\u6a21\u5f0f\u5728\u5f62\u5f0f\u5316\u3001\u4e92\u64cd\u4f5c\u6027\u548c\u6ee1\u8db3\u80fd\u6e90\u7814\u7a76\u4eba\u5458\u7279\u5b9a\u9700\u6c42\u4e4b\u95f4\u53d6\u5f97\u4e86\u5e73\u8861\uff1b\u6d4b\u8bd5\u663e\u793a\u826f\u597d\u7684\u4fe1\u606f\u5448\u73b0\u5bf9\u4e8e\u7814\u7a76\u4eba\u5458\u521b\u5efa\u6240\u9700\u5143\u6570\u636e\u81f3\u5173\u91cd\u8981", "conclusion": "\u672c\u6587\u63d0\u4f9b\u4e86\u8bbe\u8ba1\u80fd\u6e90\u7814\u7a76\u8f6f\u4ef6\u5143\u6570\u636e\u6a21\u5f0f\u7684\u6311\u6218\u548c\u673a\u9047\u7684\u89c1\u89e3\uff0c\u5f3a\u8c03\u4e86\u826f\u597d\u4fe1\u606f\u5448\u73b0\u7684\u91cd\u8981\u6027"}}
{"id": "2601.09612", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.09612", "abs": "https://arxiv.org/abs/2601.09612", "authors": ["Khairul Alam", "Banani Roy"], "title": "Analyzing GitHub Issues and Pull Requests in nf-core Pipelines: Insights into nf-core Pipeline Repositories", "comment": "12 pages", "summary": "Scientific Workflow Management Systems (SWfMSs) such as Nextflow have become essential software frameworks for conducting reproducible, scalable, and portable computational analyses in data-intensive fields like genomics, transcriptomics, and proteomics. Building on Nextflow, the nf-core community curates standardized, peer-reviewed pipelines that follow strict testing, documentation, and governance guidelines. Despite its broad adoption, little is known about the challenges users face during the development and maintenance of these pipelines. This paper presents an empirical study of 25,173 issues and pull requests from these pipelines to uncover recurring challenges, management practices, and perceived difficulties. Using BERTopic modeling, we identify 13 key challenges, including pipeline development and integration, bug fixing, integrating genomic data, managing CI configurations, and handling version updates. We then examine issue resolution dynamics, showing that 89.38\\% of issues and pull requests are eventually closed, with half resolved within three days. Statistical analysis reveals that the presence of labels (large effect, $\u03b4$ = 0.94) and code snippets (medium effect, $\u03b4$ = 0.50) significantly improve resolution likelihood. Further analysis reveals that tool development and repository maintenance poses the most significant challenges, followed by testing pipelines and CI configurations, and debugging containerized pipelines. Overall, this study provides actionable insights into the collaborative development and maintenance of nf-core pipelines, highlighting opportunities to enhance their usability, sustainability, and reproducibility.", "AI": {"tldr": "\u5bf9nf-core\u79d1\u5b66\u5de5\u4f5c\u6d41\u7ba1\u9053\u768425,173\u4e2aissue\u548cPR\u8fdb\u884c\u5b9e\u8bc1\u7814\u7a76\uff0c\u8bc6\u522b\u51fa13\u4e2a\u5173\u952e\u6311\u6218\uff0c\u5206\u6790\u89e3\u51b3\u52a8\u6001\uff0c\u53d1\u73b0\u6807\u7b7e\u548c\u4ee3\u7801\u7247\u6bb5\u80fd\u663e\u8457\u63d0\u9ad8\u89e3\u51b3\u6982\u7387\u3002", "motivation": "\u5c3d\u7ba1Nextflow\u548cnf-core\u5728\u6570\u636e\u5bc6\u96c6\u578b\u79d1\u5b66\u9886\u57df\u88ab\u5e7f\u6cdb\u91c7\u7528\uff0c\u4f46\u7528\u6237\u5728\u8fd9\u4e9b\u7ba1\u9053\u5f00\u53d1\u548c\u7ef4\u62a4\u8fc7\u7a0b\u4e2d\u9762\u4e34\u7684\u5177\u4f53\u6311\u6218\u5c1a\u4e0d\u6e05\u695a\u3002\u672c\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u5b9e\u8bc1\u5206\u6790\u63ed\u793a\u8fd9\u4e9b\u6311\u6218\u548c\u7ba1\u7406\u5b9e\u8df5\u3002", "method": "\u4f7f\u7528BERTopic\u4e3b\u9898\u5efa\u6a21\u5206\u679025,173\u4e2aissue\u548cpull request\uff0c\u8bc6\u522b\u5173\u952e\u6311\u6218\u7c7b\u522b\u3002\u901a\u8fc7\u7edf\u8ba1\u5206\u6790issue\u89e3\u51b3\u52a8\u6001\uff0c\u5305\u62ec\u89e3\u51b3\u65f6\u95f4\u3001\u89e3\u51b3\u6982\u7387\u4e0e\u6807\u7b7e\u3001\u4ee3\u7801\u7247\u6bb5\u7b49\u56e0\u7d20\u7684\u5173\u7cfb\u3002", "result": "\u8bc6\u522b\u51fa13\u4e2a\u5173\u952e\u6311\u6218\uff1a\u7ba1\u9053\u5f00\u53d1\u4e0e\u96c6\u6210\u3001bug\u4fee\u590d\u3001\u57fa\u56e0\u7ec4\u6570\u636e\u96c6\u6210\u3001CI\u914d\u7f6e\u7ba1\u7406\u3001\u7248\u672c\u66f4\u65b0\u7b49\u300289.38%\u7684issue\u548cPR\u6700\u7ec8\u88ab\u5173\u95ed\uff0c\u534a\u6570\u57283\u5929\u5185\u89e3\u51b3\u3002\u6807\u7b7e\uff08\u5927\u6548\u5e94\uff0c\u03b4=0.94\uff09\u548c\u4ee3\u7801\u7247\u6bb5\uff08\u4e2d\u6548\u5e94\uff0c\u03b4=0.50\uff09\u663e\u8457\u63d0\u9ad8\u89e3\u51b3\u53ef\u80fd\u6027\u3002\u5de5\u5177\u5f00\u53d1\u548c\u4ed3\u5e93\u7ef4\u62a4\u662f\u6700\u5177\u6311\u6218\u6027\u7684\u4efb\u52a1\u3002", "conclusion": "\u7814\u7a76\u4e3anf-core\u7ba1\u9053\u7684\u534f\u4f5c\u5f00\u53d1\u548c\u7ef4\u62a4\u63d0\u4f9b\u4e86\u53ef\u64cd\u4f5c\u7684\u89c1\u89e3\uff0c\u5f3a\u8c03\u4e86\u589e\u5f3a\u5176\u53ef\u7528\u6027\u3001\u53ef\u6301\u7eed\u6027\u548c\u53ef\u91cd\u590d\u6027\u7684\u673a\u4f1a\u3002\u6807\u7b7e\u7cfb\u7edf\u548c\u4ee3\u7801\u7247\u6bb5\u7684\u4f7f\u7528\u80fd\u663e\u8457\u6539\u5584\u95ee\u9898\u89e3\u51b3\u6548\u7387\u3002"}}
{"id": "2601.09616", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.09616", "abs": "https://arxiv.org/abs/2601.09616", "authors": ["Tarannum Shaila Zaman", "Zhihui Yan", "Chen Wang", "Chadni Islam", "Jiangfan Shi", "Tingting Yu"], "title": "SysPro: Reproducing System-level Concurrency Bugs from Bug Reports", "comment": "Accepted in JSS", "summary": "Reproducing system-level concurrency bugs requires both input data and the precise interleaving order of system calls. This process is challenging because such bugs are non-deterministic, and bug reports often lack the detailed information needed. Additionally, the unstructured nature of reports written in natural language makes it difficult to extract necessary details. Existing tools are inadequate to reproduce these bugs due to their inability to manage the specific interleaving at the system call level. To address these challenges, we propose SysPro, a novel approach that automatically extracts relevant system call names from bug reports and identifies their locations in the source code. It generates input data by utilizing information retrieval, regular expression matching, and the category-partition method. This extracted input and interleaving data are then used to reproduce bugs through dynamic source code instrumentation. Our empirical study on real-world benchmarks demonstrates that SysPro is both effective and efficient at localizing and reproducing system-level concurrency bugs from bug reports.", "AI": {"tldr": "SysPro\uff1a\u4e00\u79cd\u4ecebug\u62a5\u544a\u4e2d\u81ea\u52a8\u63d0\u53d6\u7cfb\u7edf\u8c03\u7528\u4fe1\u606f\u5e76\u751f\u6210\u8f93\u5165\u6570\u636e\u4ee5\u590d\u73b0\u7cfb\u7edf\u7ea7\u5e76\u53d1bug\u7684\u65b0\u65b9\u6cd5", "motivation": "\u7cfb\u7edf\u7ea7\u5e76\u53d1bug\u7684\u590d\u73b0\u9700\u8981\u8f93\u5165\u6570\u636e\u548c\u7cbe\u786e\u7684\u7cfb\u7edf\u8c03\u7528\u4ea4\u9519\u987a\u5e8f\uff0c\u4f46bug\u62a5\u544a\u901a\u5e38\u7f3a\u4e4f\u8fd9\u4e9b\u8be6\u7ec6\u4fe1\u606f\uff0c\u4e14\u73b0\u6709\u5de5\u5177\u65e0\u6cd5\u6709\u6548\u5904\u7406\u7cfb\u7edf\u8c03\u7528\u7ea7\u522b\u7684\u4ea4\u9519\u95ee\u9898", "method": "SysPro\u81ea\u52a8\u4ecebug\u62a5\u544a\u4e2d\u63d0\u53d6\u76f8\u5173\u7cfb\u7edf\u8c03\u7528\u540d\u79f0\u5e76\u5728\u6e90\u4ee3\u7801\u4e2d\u5b9a\u4f4d\uff0c\u901a\u8fc7\u4fe1\u606f\u68c0\u7d22\u3001\u6b63\u5219\u8868\u8fbe\u5f0f\u5339\u914d\u548c\u7c7b\u522b\u5212\u5206\u65b9\u6cd5\u751f\u6210\u8f93\u5165\u6570\u636e\uff0c\u6700\u540e\u901a\u8fc7\u52a8\u6001\u6e90\u4ee3\u7801\u63d2\u6869\u590d\u73b0bug", "result": "\u5728\u771f\u5b9e\u4e16\u754c\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5b9e\u8bc1\u7814\u7a76\u8868\u660e\uff0cSysPro\u5728\u4ecebug\u62a5\u544a\u4e2d\u5b9a\u4f4d\u548c\u590d\u73b0\u7cfb\u7edf\u7ea7\u5e76\u53d1bug\u65b9\u9762\u65e2\u6709\u6548\u53c8\u9ad8\u6548", "conclusion": "SysPro\u4e3a\u89e3\u51b3\u7cfb\u7edf\u7ea7\u5e76\u53d1bug\u590d\u73b0\u7684\u6311\u6218\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u65b9\u6cd5\uff0c\u80fd\u591f\u81ea\u52a8\u5904\u7406\u81ea\u7136\u8bed\u8a00bug\u62a5\u544a\u4e2d\u7684\u4fe1\u606f\u63d0\u53d6\u548cbug\u590d\u73b0"}}
{"id": "2601.09695", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.09695", "abs": "https://arxiv.org/abs/2601.09695", "authors": ["Michael Konstantinou", "Renzo Degiovanni", "Mike Papadakis"], "title": "How well LLM-based test generation techniques perform with newer LLM versions?", "comment": null, "summary": "The rapid evolution of Large Language Models (LLMs) has strongly impacted software engineering, leading to a growing number of studies on automated unit test generation. However, the standalone use of LLMs without post-processing has proven insufficient, often producing tests that fail to compile or achieve high coverage. Several techniques have been proposed to address these issues, reporting improvements in test compilation and coverage. While important, LLM-based test generation techniques have been evaluated against relatively weak baselines (for todays' standards), i.e., old LLM versions and relatively weak prompts, which may exacerbate the performance contribution of the approaches. In other words, stronger (newer) LLMs may obviate any advantage these techniques bring. We investigate this issue by replicating four state-of-the-art LLM-based test generation tools, HITS, SymPrompt, TestSpark, and CoverUp that include engineering components aimed at guiding the test generation process through compilation and execution feedback, and evaluate their relative effectiveness and efficiency over a plain LLM test generation method. We integrate current LLM versions in all approaches and run an experiment on 393 classes and 3,657 methods. Our results show that the plain LLM approach can outperform previous state-of-the-art approaches in all test effectiveness metrics we used: line coverage (by 17.72%), branch coverage (by 19.80%) and mutation score (by 20.92%), and it does so at a comparable cost (LLM queries). We also observe that the granularity at which the plain LLM is applied has a significant impact on the cost. We therefore propose targeting first the program classes, where test generation is more efficient, and then the uncovered methods to reduce the number of LLM requests. This strategy achieves comparable (slightly higher) effectiveness while requiring about 20% fewer LLM requests.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\uff0c\u5728\u5355\u5143\u6d4b\u8bd5\u751f\u6210\u4efb\u52a1\u4e2d\uff0c\u4f7f\u7528\u6700\u65b0LLM\u7684\u7b80\u5355\u65b9\u6cd5\u53ef\u4ee5\u8d85\u8d8a\u73b0\u6709\u7684\u590d\u6742\u6280\u672f\uff0c\u5728\u4ee3\u7801\u8986\u76d6\u7387\u7b49\u6307\u6807\u4e0a\u8868\u73b0\u66f4\u597d\uff0c\u4e14\u6210\u672c\u76f8\u5f53\u3002\u5efa\u8bae\u91c7\u7528\u5148\u7c7b\u540e\u65b9\u6cd5\u7684\u7b56\u7565\u8fdb\u4e00\u6b65\u51cf\u5c11LLM\u8c03\u7528\u6b21\u6570\u3002", "motivation": "\u73b0\u6709LLM\u6d4b\u8bd5\u751f\u6210\u6280\u672f\u901a\u5e38\u57fa\u4e8e\u8f83\u5f31\u7684LLM\u7248\u672c\u8fdb\u884c\u8bc4\u4f30\uff0c\u53ef\u80fd\u5938\u5927\u4e86\u8fd9\u4e9b\u6280\u672f\u7684\u4f18\u52bf\u3002\u968f\u7740LLM\u7684\u5feb\u901f\u53d1\u5c55\uff0c\u9700\u8981\u91cd\u65b0\u8bc4\u4f30\u8fd9\u4e9b\u590d\u6742\u6280\u672f\u76f8\u5bf9\u4e8e\u7b80\u5355\u4f7f\u7528\u6700\u65b0LLM\u7684\u6548\u679c\u3002", "method": "\u590d\u5236\u4e86\u56db\u79cd\u6700\u5148\u8fdb\u7684LLM\u6d4b\u8bd5\u751f\u6210\u5de5\u5177\uff08HITS\u3001SymPrompt\u3001TestSpark\u3001CoverUp\uff09\uff0c\u5e76\u5c06\u5b83\u4eec\u4e0e\u7b80\u5355\u7684LLM\u6d4b\u8bd5\u751f\u6210\u65b9\u6cd5\u8fdb\u884c\u6bd4\u8f83\u3002\u5728393\u4e2a\u7c7b\u548c3,657\u4e2a\u65b9\u6cd5\u4e0a\u8fdb\u884c\u5b9e\u9a8c\uff0c\u4f7f\u7528\u6700\u65b0\u7684LLM\u7248\u672c\uff0c\u8bc4\u4f30\u6d4b\u8bd5\u6548\u679c\u548c\u6548\u7387\u3002", "result": "\u7b80\u5355LLM\u65b9\u6cd5\u5728\u6240\u6709\u6d4b\u8bd5\u6548\u679c\u6307\u6807\u4e0a\u90fd\u4f18\u4e8e\u73b0\u6709\u6280\u672f\uff1a\u884c\u8986\u76d6\u7387\u63d0\u9ad817.72%\uff0c\u5206\u652f\u8986\u76d6\u7387\u63d0\u9ad819.80%\uff0c\u53d8\u5f02\u6d4b\u8bd5\u5206\u6570\u63d0\u9ad820.92%\uff0c\u4e14LLM\u67e5\u8be2\u6210\u672c\u76f8\u5f53\u3002\u91c7\u7528\u5148\u7c7b\u540e\u65b9\u6cd5\u7684\u7b56\u7565\u53ef\u4ee5\u51cf\u5c11\u7ea620%\u7684LLM\u8bf7\u6c42\u3002", "conclusion": "\u6700\u65b0LLM\u7684\u7b80\u5355\u4f7f\u7528\u5df2\u7ecf\u80fd\u591f\u8d85\u8d8a\u590d\u6742\u7684\u6d4b\u8bd5\u751f\u6210\u6280\u672f\uff0c\u5efa\u8bae\u4f18\u5148\u4f7f\u7528\u6700\u65b0LLM\u8fdb\u884c\u6d4b\u8bd5\u751f\u6210\uff0c\u5e76\u91c7\u7528\u5148\u7c7b\u540e\u65b9\u6cd5\u7684\u7b56\u7565\u6765\u4f18\u5316\u6210\u672c\u6548\u76ca\u3002"}}
{"id": "2601.09703", "categories": ["cs.SE", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.09703", "abs": "https://arxiv.org/abs/2601.09703", "authors": ["Sicong Liu", "Yanxian Huang", "Mingwei Liu", "Jiachi Chen", "Ensheng Shi", "Yuchi Ma", "Hongyu Zhang", "Yin Zhang", "Yanlin Wang"], "title": "ShortCoder: Knowledge-Augmented Syntax Optimization for Token-Efficient Code Generation", "comment": null, "summary": "Code generation tasks aim to automate the conversion of user requirements into executable code, significantly reducing manual development efforts and enhancing software productivity. The emergence of large language models (LLMs) has significantly advanced code generation, though their efficiency is still impacted by certain inherent architectural constraints. Each token generation necessitates a complete inference pass, requiring persistent retention of contextual information in memory and escalating resource consumption. While existing research prioritizes inference-phase optimizations such as prompt compression and model quantization, the generation phase remains underexplored. To tackle these challenges, we propose a knowledge-infused framework named ShortCoder, which optimizes code generation efficiency while preserving semantic equivalence and readability. In particular, we introduce: (1) ten syntax-level simplification rules for Python, derived from AST-preserving transformations, achieving 18.1% token reduction without functional compromise; (2) a hybrid data synthesis pipeline integrating rule-based rewriting with LLM-guided refinement, producing ShorterCodeBench, a corpus of validated tuples of original code and simplified code with semantic consistency; (3) a fine-tuning strategy that injects conciseness awareness into the base LLMs. Extensive experimental results demonstrate that ShortCoder consistently outperforms state-of-the-art methods on HumanEval, achieving an improvement of 18.1%-37.8% in generation efficiency over previous methods while ensuring the performance of code generation.", "AI": {"tldr": "ShortCoder\u662f\u4e00\u4e2a\u77e5\u8bc6\u6ce8\u5165\u6846\u67b6\uff0c\u901a\u8fc7\u4ee3\u7801\u8bed\u6cd5\u7ea7\u7b80\u5316\u3001\u6df7\u5408\u6570\u636e\u5408\u6210\u548c\u5fae\u8c03\u7b56\u7565\uff0c\u5728\u4fdd\u6301\u8bed\u4e49\u7b49\u4ef7\u6027\u548c\u53ef\u8bfb\u6027\u7684\u540c\u65f6\uff0c\u663e\u8457\u63d0\u5347\u4ee3\u7801\u751f\u6210\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4ee3\u7801\u751f\u6210\u65f6\u5b58\u5728\u6548\u7387\u95ee\u9898\uff1a\u6bcf\u4e2atoken\u751f\u6210\u90fd\u9700\u8981\u5b8c\u6574\u63a8\u7406\u8fc7\u7a0b\uff0c\u9700\u8981\u6301\u7eed\u4fdd\u7559\u4e0a\u4e0b\u6587\u4fe1\u606f\uff0c\u5bfc\u81f4\u8d44\u6e90\u6d88\u8017\u5927\u3002\u5f53\u524d\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u63a8\u7406\u9636\u6bb5\u4f18\u5316\uff0c\u800c\u751f\u6210\u9636\u6bb5\u7814\u7a76\u4e0d\u8db3\u3002", "method": "1) \u63d0\u51fa10\u4e2aPython\u8bed\u6cd5\u7ea7\u7b80\u5316\u89c4\u5219\uff0c\u57fa\u4e8eAST\u4fdd\u6301\u8f6c\u6362\uff0c\u5b9e\u73b018.1%\u7684token\u7f29\u51cf\uff1b2) \u8bbe\u8ba1\u6df7\u5408\u6570\u636e\u5408\u6210\u7ba1\u9053\uff0c\u7ed3\u5408\u89c4\u5219\u91cd\u5199\u548cLLM\u5f15\u5bfc\u7cbe\u70bc\uff0c\u521b\u5efaShorterCodeBench\u8bed\u6599\u5e93\uff1b3) \u5f00\u53d1\u5fae\u8c03\u7b56\u7565\uff0c\u5c06\u7b80\u6d01\u6027\u610f\u8bc6\u6ce8\u5165\u57fa\u7840LLMs\u3002", "result": "\u5728HumanEval\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cShortCoder\u59cb\u7ec8\u4f18\u4e8e\u6700\u5148\u8fdb\u65b9\u6cd5\uff0c\u4ee3\u7801\u751f\u6210\u6548\u7387\u6bd4\u5148\u524d\u65b9\u6cd5\u63d0\u534718.1%-37.8%\uff0c\u540c\u65f6\u4fdd\u6301\u4ee3\u7801\u751f\u6210\u6027\u80fd\u3002", "conclusion": "ShortCoder\u901a\u8fc7\u4f18\u5316\u4ee3\u7801\u751f\u6210\u6548\u7387\uff0c\u89e3\u51b3\u4e86LLMs\u5728\u4ee3\u7801\u751f\u6210\u4e2d\u7684\u8d44\u6e90\u6d88\u8017\u95ee\u9898\uff0c\u5728\u4fdd\u6301\u8bed\u4e49\u7b49\u4ef7\u6027\u548c\u53ef\u8bfb\u6027\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u6548\u7387\uff0c\u4e3a\u4ee3\u7801\u751f\u6210\u4efb\u52a1\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
