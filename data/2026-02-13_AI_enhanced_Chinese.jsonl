{"id": "2602.11443", "categories": ["cs.DB", "cs.IR"], "pdf": "https://arxiv.org/pdf/2602.11443", "abs": "https://arxiv.org/abs/2602.11443", "authors": ["Abylay Amanbayev", "Brian Tsan", "Tri Dang", "Florin Rusu"], "title": "Filtered Approximate Nearest Neighbor Search in Vector Databases: System Design and Performance Analysis", "comment": "The artifacts are available at: https://github.com/aabylay/ANN-benchmark-HQ", "summary": "Retrieval-Augmented Generation (RAG) applications increasingly rely on Filtered Approximate Nearest Neighbor Search (FANNS) to combine semantic retrieval with metadata constraints. While algorithmic innovations for FANNS have been proposed, there remains a lack of understanding regarding how generic filtering strategies perform within Vector Databases. In this work, we systematize the taxonomy of filtering strategies and evaluate their integration into FAISS, Milvus, and pgvector. To provide a robust benchmarking framework, we introduce a new relational dataset, \\textit{MoReVec}, consisting of two tables, featuring 768-dimensional text embeddings and a rich schema of metadata attributes. We further propose the \\textit{Global-Local Selectivity (GLS)} correlation metric to quantify the relationship between filters and query vectors.\n  Our experiments reveal that algorithmic adaptations within the engine often override raw index performance. Specifically, we find that: (1) \\textit{Milvus} achieves superior recall stability through hybrid approximate/exact execution; (2) \\textit{pgvector}'s cost-based query optimizer frequently selects suboptimal execution plans, favoring approximate index scans even when exact sequential scans would yield perfect recall at comparable latency; and (3) partition-based indexes (IVFFlat) outperform graph-based indexes (HNSW) for low-selectivity queries. To facilitate this analysis, we extend the widely-used \\textit{ANN-Benchmarks} to support filtered vector search and make it available online. Finally, we synthesize our findings into a set of practical guidelines for selecting index types and configuring query optimizers for hybrid search workloads.", "AI": {"tldr": "\u7cfb\u7edf\u5316\u8bc4\u4f30\u5411\u91cf\u6570\u636e\u5e93\u4e2d\u8fc7\u6ee4\u7b56\u7565\u6027\u80fd\uff0c\u63d0\u51fa\u65b0\u6570\u636e\u96c6\u548cGLS\u76f8\u5173\u6027\u6307\u6807\uff0c\u53d1\u73b0\u7b97\u6cd5\u9002\u914d\u6bd4\u539f\u59cb\u7d22\u5f15\u6027\u80fd\u66f4\u91cd\u8981\uff0c\u4e3a\u6df7\u5408\u641c\u7d22\u63d0\u4f9b\u5b9e\u7528\u6307\u5357", "motivation": "\u867d\u7136\u68c0\u7d22\u589e\u5f3a\u751f\u6210(RAG)\u5e94\u7528\u8d8a\u6765\u8d8a\u4f9d\u8d56\u8fc7\u6ee4\u8fd1\u4f3c\u6700\u8fd1\u90bb\u641c\u7d22(FANNS)\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u901a\u7528\u8fc7\u6ee4\u7b56\u7565\u5728\u5411\u91cf\u6570\u636e\u5e93\u4e2d\u6027\u80fd\u7684\u7cfb\u7edf\u7406\u89e3", "method": "\u7cfb\u7edf\u5316\u8fc7\u6ee4\u7b56\u7565\u5206\u7c7b\u5b66\uff0c\u5728FAISS\u3001Milvus\u548cpgvector\u4e2d\u8bc4\u4f30\u96c6\u6210\u6548\u679c\uff0c\u63d0\u51fa\u65b0\u6570\u636e\u96c6MoReVec\u548cGLS\u76f8\u5173\u6027\u6307\u6807\uff0c\u6269\u5c55ANN-Benchmarks\u652f\u6301\u8fc7\u6ee4\u5411\u91cf\u641c\u7d22", "result": "\u53d1\u73b0\u7b97\u6cd5\u9002\u914d\u6bd4\u539f\u59cb\u7d22\u5f15\u6027\u80fd\u66f4\u91cd\u8981\uff1aMilvus\u901a\u8fc7\u6df7\u5408\u8fd1\u4f3c/\u7cbe\u786e\u6267\u884c\u5b9e\u73b0\u66f4\u597d\u7684\u53ec\u56de\u7a33\u5b9a\u6027\uff1bpgvector\u7684\u57fa\u4e8e\u6210\u672c\u7684\u67e5\u8be2\u4f18\u5316\u5668\u7ecf\u5e38\u9009\u62e9\u6b21\u4f18\u6267\u884c\u8ba1\u5212\uff1b\u5206\u533a\u7d22\u5f15(IVFFlat)\u5728\u4f4e\u9009\u62e9\u6027\u67e5\u8be2\u4e2d\u4f18\u4e8e\u56fe\u7d22\u5f15(HNSW)", "conclusion": "\u4e3a\u6df7\u5408\u641c\u7d22\u5de5\u4f5c\u8d1f\u8f7d\u63d0\u4f9b\u4e86\u9009\u62e9\u7d22\u5f15\u7c7b\u578b\u548c\u914d\u7f6e\u67e5\u8be2\u4f18\u5316\u5668\u7684\u5b9e\u7528\u6307\u5357\uff0c\u6269\u5c55\u7684\u57fa\u51c6\u6d4b\u8bd5\u5de5\u5177\u53ef\u7528\u4e8e\u8fdb\u4e00\u6b65\u7814\u7a76"}}
{"id": "2602.11573", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2602.11573", "abs": "https://arxiv.org/abs/2602.11573", "authors": ["Wenyang Zhou", "Jiadong Xie", "Yingfan Liu", "Zhihao Yin", "Jeffrey Xu Yu", "Hui Li", "Zhangqian Mu", "Xiaotian Qiao", "Jiangtao Cui"], "title": "Fast Tuning the Index Construction Parameters of Proximity Graphs in Vector Databases", "comment": null, "summary": "k-approximate nearest neighbor search (k-ANNS) in high-dimensional vector spaces is a fundamental problem across many fields. With the advent of vector databases and retrieval-augmented generation, k-ANNS has garnered increasing attention. Among existing methods, proximity graphs (PG) based approaches are the state-of-the-art (SOTA) methods. However, the construction parameters of PGs significantly impact their search performance. Before constructing a PG for a given dataset, it is essential to tune these parameters, which first recommends a set of promising parameters and then estimates the quality of each parameter by building the corresponding PG and then testing its k-ANNS performance. Given that the construction complexity of PGs is superlinear, building and evaluating graph indexes accounts for the primary cost of parameter tuning. Unfortunately, there is currently no method considered and optimized this process.In this paper, we introduce FastPGT, an efficient framework for tuning the PG construction parameters. FastPGT accelerates parameter estimation by building multiple PGs simultaneously, thereby reducing repeated computations. Moreover, we modify the SOTA tuning model to recommend multiple parameters at once, which can be efficiently estimated using our method of building multiple PGs simultaneously. Through extensive experiments on real-world datasets, we demonstrate that FastPGT achieves up to 2.37x speedup over the SOTA method VDTuner, without compromising tuning quality.", "AI": {"tldr": "FastPGT\uff1a\u4e00\u79cd\u9ad8\u6548\u8c03\u4f18\u8fd1\u90bb\u56fe\u6784\u5efa\u53c2\u6570\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u540c\u65f6\u6784\u5efa\u591a\u4e2a\u56fe\u51cf\u5c11\u91cd\u590d\u8ba1\u7b97\uff0c\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5VDTuner\u5b9e\u73b0\u6700\u9ad82.37\u500d\u52a0\u901f", "motivation": "\u9ad8\u7ef4\u5411\u91cf\u7a7a\u95f4\u4e2d\u7684k-\u8fd1\u4f3c\u6700\u8fd1\u90bb\u641c\u7d22\u5728\u5411\u91cf\u6570\u636e\u5e93\u548c\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u4e2d\u81f3\u5173\u91cd\u8981\u3002\u8fd1\u90bb\u56fe\u65b9\u6cd5\u867d\u4e3a\u5f53\u524d\u6700\u4f18\uff0c\u4f46\u5176\u6784\u5efa\u53c2\u6570\u5bf9\u641c\u7d22\u6027\u80fd\u5f71\u54cd\u663e\u8457\uff0c\u800c\u53c2\u6570\u8c03\u4f18\u8fc7\u7a0b\u9700\u8981\u53cd\u590d\u6784\u5efa\u548c\u6d4b\u8bd5\u56fe\u7d22\u5f15\uff0c\u8ba1\u7b97\u6210\u672c\u9ad8\u6602\u3002\u73b0\u6709\u65b9\u6cd5\u672a\u9488\u5bf9\u8fd9\u4e00\u8fc7\u7a0b\u8fdb\u884c\u4f18\u5316\u3002", "method": "\u63d0\u51faFastPGT\u6846\u67b6\uff1a1\uff09\u901a\u8fc7\u540c\u65f6\u6784\u5efa\u591a\u4e2a\u8fd1\u90bb\u56fe\u6765\u52a0\u901f\u53c2\u6570\u8bc4\u4f30\uff0c\u51cf\u5c11\u91cd\u590d\u8ba1\u7b97\uff1b2\uff09\u4fee\u6539\u73b0\u6709\u6700\u4f18\u8c03\u4f18\u6a21\u578b\uff0c\u4f7f\u5176\u80fd\u4e00\u6b21\u6027\u63a8\u8350\u591a\u4e2a\u53c2\u6570\uff0c\u4fbf\u4e8e\u5229\u7528\u540c\u65f6\u6784\u5efa\u591a\u56fe\u7684\u65b9\u6cd5\u8fdb\u884c\u9ad8\u6548\u8bc4\u4f30\u3002", "result": "\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cFastPGT\u76f8\u6bd4\u5f53\u524d\u6700\u4f18\u65b9\u6cd5VDTuner\u5b9e\u73b0\u4e86\u6700\u9ad82.37\u500d\u7684\u52a0\u901f\uff0c\u4e14\u4e0d\u727a\u7272\u8c03\u4f18\u8d28\u91cf\u3002", "conclusion": "FastPGT\u6709\u6548\u89e3\u51b3\u4e86\u8fd1\u90bb\u56fe\u6784\u5efa\u53c2\u6570\u8c03\u4f18\u4e2d\u7684\u8ba1\u7b97\u74f6\u9888\u95ee\u9898\uff0c\u901a\u8fc7\u540c\u65f6\u6784\u5efa\u591a\u4e2a\u56fe\u7684\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u8c03\u4f18\u6548\u7387\uff0c\u4e3a\u9ad8\u7ef4\u5411\u91cf\u641c\u7d22\u7684\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u7684\u53c2\u6570\u4f18\u5316\u65b9\u6848\u3002"}}
{"id": "2602.11756", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2602.11756", "abs": "https://arxiv.org/abs/2602.11756", "authors": ["Luigi Asprino", "Enrico Daga"], "title": "Towards a theory of Fa\u00e7ade-X data access: satisfiability of SPARQL basic graph patterns", "comment": null, "summary": "Data integration is the primary use case for knowledge graphs. However, integrated data are not typically graphs but come in different formats, for example, CSV, XML, or a relational database. Fa\u00e7ade-X is a recently proposed method for providing direct access to an open-ended set of data formats. The method includes a meta-model that specialises RDF to fit general data structures. This model allows to express SPARQL queries targeting data sources with those structures. Previous work formalised Fa\u00e7ade-X and demonstrated how it can theoretically represent any format expressible with a context-free grammar, as well as the relational model. A reference implementation, SPARQL Anything, demonstrates the feasibility of the approach in practice. It is noteworthy that Fa\u00e7ade-X utilises a fraction of RDF, and, consequently, not all SPARQL queries yield a solution (i.e. are satisfiable) when evaluated over a Fa\u00e7ade-X graph. In this article, we consolidate Fa\u00e7ade-X, and we study the satisfiability of basic graph patterns. The theory is accompanied by an algorithm for deciding the satisfiability of basic graph patterns on Fa\u00e7ade-X data sources. Furthermore, we provide extensive experiments with a proof-of-concept implementation, demonstrating practical feasibility, including with real-world queries. Our results pave the way for studying query execution strategies for Fa\u00e7ade-X data access with SPARQL and supporting developers to build more efficient data integration systems for knowledge graphs.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76Fa\u00e7ade-X\u6570\u636e\u8bbf\u95ee\u65b9\u6cd5\u4e2d\u57fa\u672c\u56fe\u6a21\u5f0f\u7684\u6ee1\u8db3\u6027\u95ee\u9898\uff0c\u63d0\u51fa\u7406\u8bba\u6846\u67b6\u548c\u7b97\u6cd5\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u53ef\u884c\u6027\u3002", "motivation": "\u77e5\u8bc6\u56fe\u8c31\u6570\u636e\u96c6\u6210\u9700\u8981\u5904\u7406\u591a\u79cd\u683c\u5f0f\u7684\u6570\u636e\u6e90\uff0cFa\u00e7ade-X\u65b9\u6cd5\u867d\u7136\u80fd\u63d0\u4f9b\u7edf\u4e00\u8bbf\u95ee\uff0c\u4f46\u5e76\u975e\u6240\u6709SPARQL\u67e5\u8be2\u90fd\u80fd\u5728Fa\u00e7ade-X\u56fe\u4e0a\u5f97\u5230\u89e3\u3002\u9700\u8981\u7814\u7a76\u57fa\u672c\u56fe\u6a21\u5f0f\u7684\u6ee1\u8db3\u6027\u95ee\u9898\u6765\u652f\u6301\u66f4\u9ad8\u6548\u7684\u6570\u636e\u96c6\u6210\u7cfb\u7edf\u3002", "method": "\u63d0\u51faFa\u00e7ade-X\u7684\u5de9\u56fa\u7406\u8bba\u6846\u67b6\uff0c\u7814\u7a76\u57fa\u672c\u56fe\u6a21\u5f0f\u5728Fa\u00e7ade-X\u6570\u636e\u6e90\u4e0a\u7684\u6ee1\u8db3\u6027\u95ee\u9898\uff0c\u8bbe\u8ba1\u76f8\u5e94\u7684\u5224\u5b9a\u7b97\u6cd5\uff0c\u5e76\u901a\u8fc7\u6982\u5ff5\u9a8c\u8bc1\u5b9e\u73b0\u8fdb\u884c\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "result": "\u5efa\u7acb\u4e86Fa\u00e7ade-X\u57fa\u672c\u56fe\u6a21\u5f0f\u6ee1\u8db3\u6027\u7684\u7406\u8bba\u6846\u67b6\uff0c\u5f00\u53d1\u4e86\u5224\u5b9a\u7b97\u6cd5\uff0c\u5b9e\u9a8c\u8bc1\u660e\u8be5\u65b9\u6cd5\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u53ef\u884c\uff0c\u5305\u62ec\u5904\u7406\u771f\u5b9e\u4e16\u754c\u67e5\u8be2\u3002", "conclusion": "\u7814\u7a76\u6210\u679c\u4e3a\u7814\u7a76Fa\u00e7ade-X\u6570\u636e\u8bbf\u95ee\u7684SPARQL\u67e5\u8be2\u6267\u884c\u7b56\u7565\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u6709\u52a9\u4e8e\u5f00\u53d1\u66f4\u9ad8\u6548\u7684\u77e5\u8bc6\u56fe\u8c31\u6570\u636e\u96c6\u6210\u7cfb\u7edf\u3002"}}
{"id": "2602.11890", "categories": ["cs.DB", "cs.CG", "cs.RO", "eess.IV"], "pdf": "https://arxiv.org/pdf/2602.11890", "abs": "https://arxiv.org/abs/2602.11890", "authors": ["Giannis Spiliopoulos", "Alexandros Troupiotis-Kapeliaris", "Kostas Patroumpas", "Nikolaos Liapis", "Dimitrios Skoutas", "Dimitris Zissis", "Nikos Bikakis"], "title": "Data-Driven Trajectory Imputation for Vessel Mobility Analysis", "comment": "International Conference on Extending Database Technology (EDBT 2026)", "summary": "Modeling vessel activity at sea is critical for a wide range of applications, including route planning, transportation logistics, maritime safety, and environmental monitoring. Over the past two decades, the Automatic Identification System (AIS) has enabled real-time monitoring of hundreds of thousands of vessels, generating huge amounts of data daily. One major challenge in using AIS data is the presence of large gaps in vessel trajectories, often caused by coverage limitations or intentional transmission interruptions. These gaps can significantly degrade data quality, resulting in inaccurate or incomplete analysis. State-of-the-art imputation approaches have mainly been devised to tackle gaps in vehicle trajectories, even when the underlying road network is not considered. But the motion patterns of sailing vessels differ substantially, e.g., smooth turns, maneuvering near ports, or navigating in adverse weather conditions. In this application paper, we propose HABIT, a lightweight, configurable H3 Aggregation-Based Imputation framework for vessel Trajectories. This data-driven framework provides a valuable means to impute missing trajectory segments by extracting, analyzing, and indexing motion patterns from historical AIS data. Our empirical study over AIS data across various timeframes, densities, and vessel types reveals that HABIT produces maritime trajectory imputations performing comparably to baseline methods in terms of accuracy, while performing better in terms of latency while accounting for vessel characteristics and their motion patterns.", "AI": {"tldr": "HABIT\uff1a\u57fa\u4e8eH3\u805a\u5408\u7684\u8f7b\u91cf\u7ea7\u53ef\u914d\u7f6e\u8239\u8236\u8f68\u8ff9\u63d2\u8865\u6846\u67b6\uff0c\u5229\u7528\u5386\u53f2AIS\u6570\u636e\u63d0\u53d6\u548c\u5206\u6790\u8239\u8236\u8fd0\u52a8\u6a21\u5f0f\u6765\u586b\u8865\u8f68\u8ff9\u7f3a\u5931\u6bb5", "motivation": "AIS\u6570\u636e\u4e2d\u5b58\u5728\u5927\u91cf\u8f68\u8ff9\u7f3a\u5931\u6bb5\uff0c\u4e25\u91cd\u5f71\u54cd\u6570\u636e\u8d28\u91cf\u548c\u5206\u6790\u51c6\u786e\u6027\u3002\u73b0\u6709\u63d2\u8865\u65b9\u6cd5\u4e3b\u8981\u9488\u5bf9\u8f66\u8f86\u8f68\u8ff9\u8bbe\u8ba1\uff0c\u672a\u5145\u5206\u8003\u8651\u8239\u8236\u7279\u6709\u7684\u8fd0\u52a8\u6a21\u5f0f\uff08\u5982\u5e73\u6ed1\u8f6c\u5f2f\u3001\u6e2f\u53e3\u673a\u52a8\u3001\u6076\u52a3\u5929\u6c14\u822a\u884c\u7b49\uff09", "method": "\u63d0\u51faHABIT\u6846\u67b6\uff0c\u57fa\u4e8eH3\u5730\u7406\u7f51\u683c\u7cfb\u7edf\uff0c\u4ece\u5386\u53f2AIS\u6570\u636e\u4e2d\u63d0\u53d6\u3001\u5206\u6790\u548c\u7d22\u5f15\u8239\u8236\u8fd0\u52a8\u6a21\u5f0f\uff0c\u901a\u8fc7\u6570\u636e\u9a71\u52a8\u65b9\u5f0f\u586b\u8865\u7f3a\u5931\u8f68\u8ff9\u6bb5\u3002\u6846\u67b6\u8f7b\u91cf\u7ea7\u4e14\u53ef\u914d\u7f6e", "result": "\u5728\u4e0d\u540c\u65f6\u95f4\u6bb5\u3001\u6570\u636e\u5bc6\u5ea6\u548c\u8239\u8236\u7c7b\u578b\u7684AIS\u6570\u636e\u4e0a\u8fdb\u884c\u5b9e\u8bc1\u7814\u7a76\uff0cHABIT\u5728\u51c6\u786e\u6027\u4e0a\u4e0e\u57fa\u7ebf\u65b9\u6cd5\u76f8\u5f53\uff0c\u5728\u5ef6\u8fdf\u6027\u80fd\u65b9\u9762\u8868\u73b0\u66f4\u597d\uff0c\u540c\u65f6\u8003\u8651\u4e86\u8239\u8236\u7279\u6027\u548c\u8fd0\u52a8\u6a21\u5f0f", "conclusion": "HABIT\u4e3a\u8239\u8236\u8f68\u8ff9\u63d2\u8865\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u5904\u7406AIS\u6570\u636e\u4e2d\u7684\u7f3a\u5931\u6bb5\uff0c\u5728\u4fdd\u6301\u51c6\u786e\u6027\u7684\u540c\u65f6\u63d0\u5347\u8ba1\u7b97\u6548\u7387\uff0c\u9002\u7528\u4e8e\u6d77\u4e8b\u76d1\u63a7\u3001\u5b89\u5168\u3001\u7269\u6d41\u7b49\u591a\u79cd\u5e94\u7528"}}
{"id": "2602.11362", "categories": ["cs.DC", "cs.DB"], "pdf": "https://arxiv.org/pdf/2602.11362", "abs": "https://arxiv.org/abs/2602.11362", "authors": ["Reginald Frank", "Soujanya Ponnapalli", "Octavio Lomeli", "Neil Giridharan", "Marcos K Aguilera", "Natacha Crooks"], "title": "Real Life Is Uncertain. Consensus Should Be Too!", "comment": "HotOS '25: Proceedings of the 2025 Workshop on Hot Topics in Operating Systems", "summary": "Modern distributed systems rely on consensus protocols to build a fault-tolerant-core upon which they can build applications. Consensus protocols are correct under a specific failure model, where up to $f$ machines can fail. We argue that this $f$-threshold failure model oversimplifies the real world and limits potential opportunities to optimize for cost or performance. We argue instead for a probabilistic failure model that captures the complex and nuanced nature of faults observed in practice. Probabilistic consensus protocols can explicitly leverage individual machine \\textit{failure curves} and explore side-stepping traditional bottlenecks such as majority quorum intersection, enabling systems that are more reliable, efficient, cost-effective, and sustainable.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4e3b\u5f20\u7528\u6982\u7387\u6027\u6545\u969c\u6a21\u578b\u66ff\u4ee3\u4f20\u7edf\u7684f\u9608\u503c\u6545\u969c\u6a21\u578b\uff0c\u4ee5\u66f4\u771f\u5b9e\u5730\u53cd\u6620\u5b9e\u9645\u6545\u969c\u60c5\u51b5\uff0c\u5e76\u4f18\u5316\u5171\u8bc6\u534f\u8bae\u7684\u6210\u672c\u548c\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u5171\u8bc6\u534f\u8bae\u57fa\u4e8ef\u9608\u503c\u6545\u969c\u6a21\u578b\uff08\u6700\u591af\u53f0\u673a\u5668\u6545\u969c\uff09\uff0c\u4f46\u8be5\u6a21\u578b\u8fc7\u5ea6\u7b80\u5316\u4e86\u73b0\u5b9e\u4e16\u754c\uff0c\u9650\u5236\u4e86\u5728\u6210\u672c\u6216\u6027\u80fd\u65b9\u9762\u7684\u4f18\u5316\u673a\u4f1a\u3002\u5b9e\u9645\u6545\u969c\u5177\u6709\u590d\u6742\u6027\u548c\u7ec6\u5fae\u5dee\u522b\uff0c\u9700\u8981\u66f4\u7cbe\u786e\u7684\u6a21\u578b\u6765\u6355\u6349\u3002", "method": "\u63d0\u51fa\u6982\u7387\u6027\u6545\u969c\u6a21\u578b\uff0c\u5229\u7528\u4e2a\u4f53\u673a\u5668\u7684\"\u6545\u969c\u66f2\u7ebf\"\u6765\u66f4\u7cbe\u786e\u5730\u63cf\u8ff0\u6545\u969c\u884c\u4e3a\u3002\u8be5\u65b9\u6cd5\u5141\u8bb8\u7ed5\u8fc7\u4f20\u7edf\u74f6\u9888\uff08\u5982\u591a\u6570\u4ef2\u88c1\u4ea4\u96c6\uff09\uff0c\u63a2\u7d22\u66f4\u7075\u6d3b\u7684\u5171\u8bc6\u673a\u5236\u3002", "result": "\u6982\u7387\u6027\u5171\u8bc6\u534f\u8bae\u80fd\u591f\u66f4\u51c6\u786e\u5730\u53cd\u6620\u5b9e\u9645\u6545\u969c\u6a21\u5f0f\uff0c\u4e3a\u7cfb\u7edf\u8bbe\u8ba1\u63d0\u4f9b\u66f4\u591a\u4f18\u5316\u7a7a\u95f4\uff0c\u6709\u671b\u5b9e\u73b0\u66f4\u53ef\u9760\u3001\u9ad8\u6548\u3001\u7ecf\u6d4e\u4e14\u53ef\u6301\u7eed\u7684\u5206\u5e03\u5f0f\u7cfb\u7edf\u3002", "conclusion": "\u6982\u7387\u6027\u6545\u969c\u6a21\u578b\u6bd4\u4f20\u7edf\u9608\u503c\u6a21\u578b\u66f4\u80fd\u53cd\u6620\u73b0\u5b9e\u6545\u969c\u60c5\u51b5\uff0c\u4e3a\u5171\u8bc6\u534f\u8bae\u8bbe\u8ba1\u5f00\u8f9f\u4e86\u65b0\u65b9\u5411\uff0c\u80fd\u591f\u6784\u5efa\u66f4\u9002\u5e94\u5b9e\u9645\u73af\u5883\u7684\u5206\u5e03\u5f0f\u7cfb\u7edf\u3002"}}
{"id": "2602.11209", "categories": ["cs.SE", "cs.CR"], "pdf": "https://arxiv.org/pdf/2602.11209", "abs": "https://arxiv.org/abs/2602.11209", "authors": ["Ziyi Yang", "Kalit Inani", "Keshav Kabra", "Vima Gupta", "Anand Padmanabha Iyer"], "title": "SAFuzz: Semantic-Guided Adaptive Fuzzing for LLM-Generated Code", "comment": "11 pages, 6 figures, 4 tables", "summary": "While AI-coding assistants accelerate software development, current testing frameworks struggle to keep pace with the resulting volume of AI-generated code. Traditional fuzzing techniques often allocate resources uniformly and lack semantic awareness of algorithmic vulnerability patterns, leading to inefficient resource usage and missed vulnerabilities. To address these limitations, we present a hybrid testing framework that leverages LLM-guided adaptive fuzzing to detect algorithmic vulnerabilities efficiently. Our system SAFuzz integrates prompt-based behavioral diversification, harness generation with problem-specific oracles, and an LLM-based predictor to enable adaptive resource allocation and dynamic early stopping. Evaluating SAFuzz on CSES algorithmic problems, we improve vulnerability discrimination precision from 77.9% to 85.7% and achieve a 1.71x reduction in time cost compared to SOTA GreenFuzz while maintaining comparable recall. We further observe that combining our approach with existing unit test generation methods yields complementary gains, increasing the bug detection recall from 67.3% to 79.5%.", "AI": {"tldr": "SAFuzz\uff1a\u4e00\u79cd\u7ed3\u5408LLM\u5f15\u5bfc\u81ea\u9002\u5e94\u6a21\u7cca\u6d4b\u8bd5\u7684\u6df7\u5408\u6d4b\u8bd5\u6846\u67b6\uff0c\u7528\u4e8e\u9ad8\u6548\u68c0\u6d4bAI\u751f\u6210\u4ee3\u7801\u4e2d\u7684\u7b97\u6cd5\u6f0f\u6d1e\uff0c\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u63d0\u5347\u68c0\u6d4b\u7cbe\u5ea6\u5e76\u51cf\u5c11\u65f6\u95f4\u6210\u672c\u3002", "motivation": "\u5f53\u524d\u6d4b\u8bd5\u6846\u67b6\u96be\u4ee5\u8ddf\u4e0aAI\u7f16\u7801\u52a9\u624b\u751f\u6210\u4ee3\u7801\u7684\u901f\u5ea6\uff0c\u4f20\u7edf\u6a21\u7cca\u6d4b\u8bd5\u65b9\u6cd5\u8d44\u6e90\u5206\u914d\u5747\u5300\u4e14\u7f3a\u4e4f\u5bf9\u7b97\u6cd5\u6f0f\u6d1e\u6a21\u5f0f\u7684\u8bed\u4e49\u7406\u89e3\uff0c\u5bfc\u81f4\u8d44\u6e90\u4f7f\u7528\u6548\u7387\u4f4e\u4e0b\u548c\u6f0f\u6d1e\u9057\u6f0f\u3002", "method": "\u63d0\u51faSAFuzz\u6df7\u5408\u6d4b\u8bd5\u6846\u67b6\uff0c\u6574\u5408\u57fa\u4e8e\u63d0\u793a\u7684\u884c\u4e3a\u591a\u6837\u5316\u3001\u5e26\u6709\u95ee\u9898\u7279\u5b9a\u9884\u8a00\u673a\u7684\u6d4b\u8bd5\u7528\u4f8b\u751f\u6210\uff0c\u4ee5\u53ca\u57fa\u4e8eLLM\u7684\u9884\u6d4b\u5668\u6765\u5b9e\u73b0\u81ea\u9002\u5e94\u8d44\u6e90\u5206\u914d\u548c\u52a8\u6001\u65e9\u671f\u505c\u6b62\u3002", "result": "\u5728CSES\u7b97\u6cd5\u95ee\u9898\u4e0a\u8bc4\u4f30\uff0c\u5c06\u6f0f\u6d1e\u5224\u522b\u7cbe\u5ea6\u4ece77.9%\u63d0\u5347\u523085.7%\uff0c\u76f8\u6bd4SOTA GreenFuzz\u51cf\u5c111.71\u500d\u65f6\u95f4\u6210\u672c\uff0c\u540c\u65f6\u4fdd\u6301\u76f8\u5f53\u7684\u53ec\u56de\u7387\uff1b\u4e0e\u73b0\u6709\u5355\u5143\u6d4b\u8bd5\u751f\u6210\u65b9\u6cd5\u7ed3\u5408\u53ef\u5c06bug\u68c0\u6d4b\u53ec\u56de\u7387\u4ece67.3%\u63d0\u5347\u523079.5%\u3002", "conclusion": "SAFuzz\u901a\u8fc7LLM\u5f15\u5bfc\u7684\u81ea\u9002\u5e94\u6a21\u7cca\u6d4b\u8bd5\u6709\u6548\u89e3\u51b3\u4e86AI\u751f\u6210\u4ee3\u7801\u6d4b\u8bd5\u7684\u6311\u6218\uff0c\u5728\u7cbe\u5ea6\u548c\u6548\u7387\u4e0a\u5747\u6709\u663e\u8457\u63d0\u5347\uff0c\u5e76\u80fd\u4e0e\u73b0\u6709\u65b9\u6cd5\u5f62\u6210\u4e92\u8865\u589e\u76ca\u3002"}}
{"id": "2602.11949", "categories": ["cs.DB", "cs.FL"], "pdf": "https://arxiv.org/pdf/2602.11949", "abs": "https://arxiv.org/abs/2602.11949", "authors": ["Victor Marsault", "Antoine Meyer"], "title": "Designing and Comparing RPQ Semantics", "comment": "30 pages, 1 figure", "summary": "Modern property graph database query languages such as Cypher, PGQL, GSQL, and the standard GQL draw inspiration from the formalism of regular path queries (RPQs). In order to output walks explicitly, they depart from the classical and well-studied homomorphism semantics. However, it then becomes difficult to present results to users because RPQs may match infinitely many walks. The aforementioned languages use ad-hoc criteria to select a finite subset of those matches. For instance, Cypher uses trail semantics, discarding walks with repeated edges; PGQL and GSQL use shortest walk semantics, retaining only the walks of minimal length among all matched walks; and GQL allows users to choose from several semantics. Even though there is academic research on these semantics, it focuses almost exclusively on evaluation efficiency.\n  In an attempt to better understand, choose and design RPQ semantics, we present a framework to categorize and compare them according to other criteria. We formalize several possible properties, pertaining to the study of RPQ semantics seen as mathematical functions mapping a database and a query to a finite set of walks. We show that some properties are mutually exclusive, or cannot be met. We also give several new RPQ semantics as examples. Some of them may provide ideas for the design of new semantics for future graph database query languages.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u6846\u67b6\u6765\u5206\u7c7b\u548c\u6bd4\u8f83\u5c5e\u6027\u56fe\u6570\u636e\u5e93\u67e5\u8be2\u8bed\u8a00\u4e2d\u7684\u6b63\u5219\u8def\u5f84\u67e5\u8be2\u8bed\u4e49\uff0c\u5206\u6790\u4e86\u4e0d\u540c\u8bed\u4e49\u7684\u6570\u5b66\u7279\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u65b0\u7684\u8bed\u4e49\u8bbe\u8ba1\u601d\u8def\u3002", "motivation": "\u73b0\u4ee3\u5c5e\u6027\u56fe\u6570\u636e\u5e93\u67e5\u8be2\u8bed\u8a00\uff08\u5982Cypher\u3001PGQL\u3001GSQL\u3001GQL\uff09\u867d\u7136\u57fa\u4e8e\u6b63\u5219\u8def\u5f84\u67e5\u8be2\uff0c\u4f46\u4e3a\u4e86\u663e\u5f0f\u8f93\u51fa\u8def\u5f84\uff0c\u5b83\u4eec\u504f\u79bb\u4e86\u7ecf\u5178\u7684\u540c\u6001\u8bed\u4e49\uff0c\u5bfc\u81f4\u67e5\u8be2\u53ef\u80fd\u5339\u914d\u65e0\u9650\u591a\u6761\u8def\u5f84\u3002\u8fd9\u4e9b\u8bed\u8a00\u4f7f\u7528\u4e0d\u540c\u7684\u4e34\u65f6\u6807\u51c6\u6765\u9009\u62e9\u6709\u9650\u5b50\u96c6\uff08\u5982Cypher\u4f7f\u7528\u8f68\u8ff9\u8bed\u4e49\uff0cPGQL/GSQL\u4f7f\u7528\u6700\u77ed\u8def\u5f84\u8bed\u4e49\uff09\uff0c\u7f3a\u4e4f\u7edf\u4e00\u7684\u7406\u8bba\u6846\u67b6\u6765\u7406\u89e3\u548c\u6bd4\u8f83\u8fd9\u4e9b\u8bed\u4e49\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u4e2a\u5f62\u5f0f\u5316\u6846\u67b6\uff0c\u5c06RPQ\u8bed\u4e49\u89c6\u4e3a\u4ece\u6570\u636e\u5e93\u548c\u67e5\u8be2\u5230\u6709\u9650\u8def\u5f84\u96c6\u5408\u7684\u6570\u5b66\u51fd\u6570\u3002\u4ed6\u4eec\u5b9a\u4e49\u4e86\u4e00\u7cfb\u5217\u53ef\u80fd\u7684\u6027\u8d28\uff0c\u5e76\u5206\u6790\u8fd9\u4e9b\u6027\u8d28\u4e4b\u95f4\u7684\u517c\u5bb9\u6027\uff08\u54ea\u4e9b\u6027\u8d28\u4e92\u65a5\u6216\u4e0d\u53ef\u540c\u65f6\u6ee1\u8db3\uff09\u3002\u901a\u8fc7\u8fd9\u4e2a\u6846\u67b6\uff0c\u4ed6\u4eec\u63d0\u51fa\u4e86\u51e0\u4e2a\u65b0\u7684RPQ\u8bed\u4e49\u4f5c\u4e3a\u793a\u4f8b\u3002", "result": "\u7814\u7a76\u8868\u660e\u67d0\u4e9b\u8bed\u4e49\u6027\u8d28\u662f\u76f8\u4e92\u6392\u65a5\u7684\uff0c\u6709\u4e9b\u6027\u8d28\u65e0\u6cd5\u540c\u65f6\u6ee1\u8db3\u3002\u4f5c\u8005\u63d0\u51fa\u7684\u65b0RPQ\u8bed\u4e49\u4e3a\u672a\u6765\u56fe\u6570\u636e\u5e93\u67e5\u8be2\u8bed\u8a00\u7684\u8bed\u4e49\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u65b0\u7684\u601d\u8def\u548c\u53ef\u80fd\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u7406\u89e3\u548c\u6bd4\u8f83\u4e0d\u540cRPQ\u8bed\u4e49\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\uff0c\u6709\u52a9\u4e8e\u66f4\u597d\u5730\u9009\u62e9\u3001\u8bbe\u8ba1\u548c\u8bc4\u4f30\u56fe\u6570\u636e\u5e93\u67e5\u8be2\u8bed\u8a00\u7684\u8bed\u4e49\u3002\u63d0\u51fa\u7684\u65b0\u8bed\u4e49\u53ef\u80fd\u4e3a\u672a\u6765\u8bed\u8a00\u8bbe\u8ba1\u63d0\u4f9b\u7075\u611f\uff0c\u63a8\u52a8\u8be5\u9886\u57df\u5411\u66f4\u7cfb\u7edf\u5316\u7684\u65b9\u5411\u53d1\u5c55\u3002"}}
{"id": "2602.11456", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2602.11456", "abs": "https://arxiv.org/abs/2602.11456", "authors": ["Chaoyi Ruan", "Geng Luo", "Xinyi Wan", "Long Zhao", "Qinghe Wang", "Jiaan Zhu", "Duling Xu", "Guanbin Xu", "Dehui Wei", "Xiang Liu", "Cheng Li", "Haifeng Sun", "Congcong Miao", "Jialin Li"], "title": "RL over Commodity Networks: Overcoming the Bandwidth Barrier with Lossless Sparse Deltas", "comment": null, "summary": "LLM post-training with reinforcement learning (RL) requires frequent synchronization of large model parameters between the trainer and distributed rollout actors. High-throughput RL post-training therefore relies on dedicated RDMA HPC clusters, an infrastructure cost most organizations cannot absorb. A natural alternative is to aggregate loosely-coupled GPUs over standard Ethernet and WAN links, but this commodity connectivity cannot sustain full-weight broadcasts: synchronizing an 8B model can take over 100~seconds on bandwidth-limited links, while rollout generation typically takes tens of seconds.\n  Toward making RL practical in this regime, we observe that RL fine-tuning yields highly sparse per-step updates, with only around 1\\% of parameter elements changing. Atop this insight, we present SparrowRL, a novel high-performance RL training system that preserves bit-exact updates without dropping or quantizing information, designed for commodity-networked, loosely-coupled GPU resources. SparrowRL represents each step as a sparse delta checkpoint, pipelines delta extraction with multi-stream transmission, overlaps transfer with rollout generation, and coordinates heterogeneous workers with throughput- and bandwidth-aware scheduling plus lease-based fault tolerance. On Qwen3 models from 4B to 14B deployed across up to four geographic regions, SparrowRL reduces per-step transfer payload by 79$\\times$ for Qwen3-8B and improves throughput by 2.4--9.5$\\times$ over full-weight broadcast across WAN, narrowing the throughput gap relative to an ideal RDMA single-datacenter baseline to within 8.91\\%. By leveraging on-demand, cross-cloud GPUs over commodity links, SparrowRL delivers 1.21--1.59$\\times$ higher tokens per dollar than reserved RDMA clusters at comparable throughput.", "AI": {"tldr": "SparrowRL\uff1a\u9488\u5bf9\u677e\u6563\u8026\u5408GPU\u96c6\u7fa4\u7684\u7a00\u758f\u589e\u91cfRL\u8bad\u7ec3\u7cfb\u7edf\uff0c\u901a\u8fc7\u4ec5\u4f20\u8f931%\u53d8\u5316\u7684\u53c2\u6570\uff0c\u5728\u666e\u901a\u7f51\u7edc\u73af\u5883\u4e0b\u5b9e\u73b0\u63a5\u8fd1RDMA\u96c6\u7fa4\u7684\u6027\u80fd", "motivation": "\u4f20\u7edfRL\u540e\u8bad\u7ec3\u9700\u8981\u9891\u7e41\u540c\u6b65\u5927\u6a21\u578b\u53c2\u6570\uff0c\u4f9d\u8d56\u6602\u8d35\u7684RDMA HPC\u96c6\u7fa4\u3002\u666e\u901a\u4ee5\u592a\u7f51/WAN\u8fde\u63a5\u65e0\u6cd5\u627f\u53d7\u5168\u6743\u91cd\u5e7f\u64ad\uff088B\u6a21\u578b\u540c\u6b65\u9700100+\u79d2\uff09\uff0c\u9650\u5236\u4e86RL\u8bad\u7ec3\u7684\u666e\u53ca\u6027", "method": "\u57fa\u4e8eRL\u5fae\u8c03\u4ea7\u751f\u7a00\u758f\u66f4\u65b0\u7684\u89c2\u5bdf\uff08\u4ec51%\u53c2\u6570\u53d8\u5316\uff09\uff0c\u8bbe\u8ba1\u7a00\u758f\u589e\u91cf\u68c0\u67e5\u70b9\u8868\u793a\uff0c\u5c06\u589e\u91cf\u63d0\u53d6\u4e0e\u591a\u6d41\u4f20\u8f93\u6d41\u6c34\u7ebf\u5316\uff0c\u4f20\u8f93\u4e0e\u751f\u6210\u91cd\u53e0\uff0c\u7ed3\u5408\u541e\u5410\u91cf\u548c\u5e26\u5bbd\u611f\u77e5\u8c03\u5ea6\u53ca\u79df\u7ea6\u5bb9\u9519", "result": "\u57284B-14B Qwen3\u6a21\u578b\u8de84\u4e2a\u5730\u7406\u533a\u57df\u90e8\u7f72\u4e2d\uff0cSparrowRL\u5c068B\u6a21\u578b\u6bcf\u6b65\u4f20\u8f93\u8d1f\u8f7d\u51cf\u5c1179\u500d\uff0cWAN\u4e0a\u541e\u5410\u91cf\u63d0\u53472.4-9.5\u500d\uff0c\u4e0e\u7406\u60f3RDMA\u5355\u6570\u636e\u4e2d\u5fc3\u57fa\u7ebf\u7684\u5dee\u8ddd\u7f29\u5c0f\u52308.91%", "conclusion": "SparrowRL\u4f7fRL\u8bad\u7ec3\u5728\u666e\u901a\u7f51\u7edc\u677e\u6563\u8026\u5408GPU\u96c6\u7fa4\u4e0a\u53ef\u884c\uff0c\u901a\u8fc7\u6309\u9700\u8de8\u4e91GPU\u63d0\u4f9b\u6bd4\u9884\u7559RDMA\u96c6\u7fa4\u9ad81.21-1.59\u500d\u7684\u6bcf\u7f8e\u5143token\u6570\uff0c\u964d\u4f4e\u4e86RL\u8bad\u7ec3\u57fa\u7840\u8bbe\u65bd\u6210\u672c"}}
{"id": "2602.11210", "categories": ["cs.SE", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.11210", "abs": "https://arxiv.org/abs/2602.11210", "authors": ["Danlong Yuan", "Wei Wu", "Zhengren Wang", "Xueliang Zhao", "Huishuai Zhang", "Dongyan Zhao"], "title": "SWE-MiniSandbox: Container-Free Reinforcement Learning for Building Software Engineering Agents", "comment": "ICML under review", "summary": "Reinforcement learning (RL) has become a key paradigm for training software engineering (SWE) agents, but existing pipelines typically rely on per-task containers for isolation. At scale, pre-built container images incur substantial storage overhead, slow environment setup, and require container-management privileges. We propose SWE-MiniSandbox, a lightweight, container-free method that enables scalable RL training of SWE agents without sacrificing isolation. Instead of relying on per-instance containers, SWE-MiniSandbox executes each task in an isolated workspace backed by kernel-level mechanisms, substantially reducing system overhead. It leverages lightweight environment pre-caching techniques to eliminate the need for bulky container images. As a result, our approach lowers disk usage to approximately 5\\% of that required by container-based pipelines and reduces environment preparation time to about 25\\% of the container baseline. Empirical results demonstrate that SWE-MiniSandbox achieves evaluation performance comparable to standard container-based pipelines. By removing the dependency on heavy container infrastructure, SWE-MiniSandbox offers a practical and accessible foundation for scaling RL-based SWE agents, particularly in resource-constrained research environments.", "AI": {"tldr": "SWE-MiniSandbox\uff1a\u4e00\u79cd\u8f7b\u91cf\u7ea7\u3001\u65e0\u5bb9\u5668\u7684RL\u8bad\u7ec3\u65b9\u6cd5\uff0c\u7528\u4e8e\u8f6f\u4ef6\u5de5\u7a0b\u4ee3\u7406\uff0c\u901a\u8fc7\u5185\u6838\u7ea7\u9694\u79bb\u673a\u5236\u66ff\u4ee3\u4f20\u7edf\u5bb9\u5668\uff0c\u663e\u8457\u964d\u4f4e\u5b58\u50a8\u5f00\u9500\u548c\u51c6\u5907\u65f6\u95f4\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u5bb9\u5668\u7684RL\u8bad\u7ec3\u7ba1\u9053\u5b58\u5728\u5b58\u50a8\u5f00\u9500\u5927\u3001\u73af\u5883\u8bbe\u7f6e\u6162\u3001\u9700\u8981\u5bb9\u5668\u7ba1\u7406\u6743\u9650\u7b49\u95ee\u9898\uff0c\u9650\u5236\u4e86\u8f6f\u4ef6\u5de5\u7a0b\u4ee3\u7406\u7684\u53ef\u6269\u5c55\u6027\uff0c\u7279\u522b\u662f\u5728\u8d44\u6e90\u53d7\u9650\u7684\u7814\u7a76\u73af\u5883\u4e2d\u3002", "method": "\u63d0\u51faSWE-MiniSandbox\u65b9\u6cd5\uff0c\u4f7f\u7528\u5185\u6838\u7ea7\u673a\u5236\u4e3a\u6bcf\u4e2a\u4efb\u52a1\u521b\u5efa\u9694\u79bb\u5de5\u4f5c\u7a7a\u95f4\uff0c\u66ff\u4ee3\u4f20\u7edf\u7684\u6bcf\u5b9e\u4f8b\u5bb9\u5668\uff1b\u91c7\u7528\u8f7b\u91cf\u7ea7\u73af\u5883\u9884\u7f13\u5b58\u6280\u672f\uff0c\u6d88\u9664\u5bf9\u5e9e\u5927\u5bb9\u5668\u955c\u50cf\u7684\u4f9d\u8d56\u3002", "result": "\u78c1\u76d8\u4f7f\u7528\u91cf\u964d\u81f3\u5bb9\u5668\u57fa\u7ebf\u7684\u7ea65%\uff0c\u73af\u5883\u51c6\u5907\u65f6\u95f4\u51cf\u5c11\u81f3\u7ea625%\uff0c\u540c\u65f6\u4fdd\u6301\u4e0e\u6807\u51c6\u5bb9\u5668\u7ba1\u9053\u76f8\u5f53\u7684\u8bc4\u4f30\u6027\u80fd\u3002", "conclusion": "SWE-MiniSandbox\u901a\u8fc7\u6d88\u9664\u5bf9\u91cd\u578b\u5bb9\u5668\u57fa\u7840\u8bbe\u65bd\u7684\u4f9d\u8d56\uff0c\u4e3aRL\u9a71\u52a8\u7684\u8f6f\u4ef6\u5de5\u7a0b\u4ee3\u7406\u63d0\u4f9b\u4e86\u5b9e\u7528\u4e14\u53ef\u8bbf\u95ee\u7684\u6269\u5c55\u57fa\u7840\uff0c\u7279\u522b\u9002\u5408\u8d44\u6e90\u53d7\u9650\u7684\u7814\u7a76\u73af\u5883\u3002"}}
{"id": "2602.12064", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2602.12064", "abs": "https://arxiv.org/abs/2602.12064", "authors": ["Yafeng Nan", "Haifeng Sun", "Zirui Zhuang", "Qi Qi", "Guojun Chu", "Jianxin Liao", "Dan Pei", "Jingyu Wang"], "title": "DIVER: A Robust Text-to-SQL System with Dynamic Interactive Value Linking and Evidence Reasoning", "comment": "Accepted by SIGMOD 2026", "summary": "In the era of large language models, Text-to-SQL, as a natural language interface for databases, is playing an increasingly important role. The sota Text-to-SQL models have achieved impressive accuracy, but their performance critically relies on expert-written evidence, which typically clarifies schema and value linking that existing models struggle to identify. Such limitations stem from the ambiguity of user queries and, more importantly, the complexity of comprehending large-scale and dynamic database values. Consequently, in real-world scenarios where expert assistance is unavailable, existing methods suffer a severe performance collapse, with execution accuracy dropping by over 10%. This underscores their lack of robustness. To address this, we propose DIVER, a robust system that automates evidence reasoning with dynamic interactive value linking. It leverages a compatible toolbox containing diverse tools to probe the database. Then, restricted by a structured workspace (CoTF, Chain of Thoughts and Facts), it reflects based on probe results and selects a new tool for next round of probing. Through this automatically iterative process, DIVER identifies schema and value linking missed by existing methods. Based on these accurate linkings, DIVER is able to infer correct usage of SQL functions and formulas and generate high-quality evidence, achieving robust Text-to-SQL without expert assistance. Extensive experiments demonstrate that: 1) The DIVER system significantly enhances the robustness of various Text-to-SQL models, improving performance by up to 10.82% in Execution Accuracy (EX) and 16.09% in Valid Efficiency Score (VES). 2) Our dynamic interactive value linking significantly improves the robustness of existing systems and the accuracy of schema and value linking, especially when confronted with challenges posed by large-scale, dynamic database values.", "AI": {"tldr": "DIVER\u662f\u4e00\u4e2a\u901a\u8fc7\u52a8\u6001\u4ea4\u4e92\u5f0f\u503c\u94fe\u63a5\u81ea\u52a8\u8fdb\u884c\u8bc1\u636e\u63a8\u7406\u7684\u9c81\u68d2Text-to-SQL\u7cfb\u7edf\uff0c\u65e0\u9700\u4e13\u5bb6\u534f\u52a9\u5373\u53ef\u5904\u7406\u5927\u89c4\u6a21\u52a8\u6001\u6570\u636e\u5e93\u503c\uff0c\u663e\u8457\u63d0\u5347\u73b0\u6709\u6a21\u578b\u7684\u9c81\u68d2\u6027\u3002", "motivation": "\u73b0\u6709SOTA Text-to-SQL\u6a21\u578b\u4e25\u91cd\u4f9d\u8d56\u4e13\u5bb6\u7f16\u5199\u7684\u8bc1\u636e\u6765\u6f84\u6e05\u6a21\u5f0f\u548c\u503c\u94fe\u63a5\uff0c\u5728\u73b0\u5b9e\u573a\u666f\u4e2d\u7f3a\u4e4f\u4e13\u5bb6\u534f\u52a9\u65f6\u6027\u80fd\u4f1a\u4e25\u91cd\u4e0b\u964d\uff08\u6267\u884c\u51c6\u786e\u7387\u4e0b\u964d\u8d85\u8fc710%\uff09\uff0c\u8fd9\u6e90\u4e8e\u7528\u6237\u67e5\u8be2\u7684\u6a21\u7cca\u6027\u548c\u5927\u89c4\u6a21\u52a8\u6001\u6570\u636e\u5e93\u503c\u7684\u590d\u6742\u6027\u3002", "method": "DIVER\u4f7f\u7528\u5305\u542b\u591a\u6837\u5316\u5de5\u5177\u7684\u517c\u5bb9\u5de5\u5177\u7bb1\u63a2\u6d4b\u6570\u636e\u5e93\uff0c\u5728\u7ed3\u6784\u5316\u5de5\u4f5c\u7a7a\u95f4\uff08CoTF\uff1a\u601d\u7ef4\u94fe\u548c\u4e8b\u5b9e\u94fe\uff09\u7684\u7ea6\u675f\u4e0b\uff0c\u57fa\u4e8e\u63a2\u6d4b\u7ed3\u679c\u8fdb\u884c\u53cd\u601d\u5e76\u9009\u62e9\u65b0\u5de5\u5177\u8fdb\u884c\u4e0b\u4e00\u8f6e\u63a2\u6d4b\u3002\u901a\u8fc7\u8fd9\u79cd\u81ea\u52a8\u8fed\u4ee3\u8fc7\u7a0b\u8bc6\u522b\u73b0\u6709\u65b9\u6cd5\u9057\u6f0f\u7684\u6a21\u5f0f\u548c\u503c\u94fe\u63a5\uff0c\u4ece\u800c\u63a8\u65adSQL\u51fd\u6570\u548c\u516c\u5f0f\u7684\u6b63\u786e\u7528\u6cd5\u5e76\u751f\u6210\u9ad8\u8d28\u91cf\u8bc1\u636e\u3002", "result": "1) DIVER\u7cfb\u7edf\u663e\u8457\u589e\u5f3a\u4e86\u5404\u79cdText-to-SQL\u6a21\u578b\u7684\u9c81\u68d2\u6027\uff0c\u5728\u6267\u884c\u51c6\u786e\u7387\uff08EX\uff09\u4e0a\u63d0\u5347\u9ad8\u8fbe10.82%\uff0c\u5728\u6709\u6548\u6548\u7387\u5206\u6570\uff08VES\uff09\u4e0a\u63d0\u5347\u9ad8\u8fbe16.09%\u30022) \u52a8\u6001\u4ea4\u4e92\u5f0f\u503c\u94fe\u63a5\u663e\u8457\u63d0\u9ad8\u4e86\u73b0\u6709\u7cfb\u7edf\u7684\u9c81\u68d2\u6027\u548c\u6a21\u5f0f\u4e0e\u503c\u94fe\u63a5\u7684\u51c6\u786e\u6027\uff0c\u7279\u522b\u662f\u5728\u9762\u5bf9\u5927\u89c4\u6a21\u52a8\u6001\u6570\u636e\u5e93\u503c\u7684\u6311\u6218\u65f6\u3002", "conclusion": "DIVER\u901a\u8fc7\u81ea\u52a8\u5316\u7684\u52a8\u6001\u4ea4\u4e92\u5f0f\u503c\u94fe\u63a5\u5b9e\u73b0\u4e86\u65e0\u9700\u4e13\u5bb6\u534f\u52a9\u7684\u9c81\u68d2Text-to-SQL\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u73b0\u5b9e\u573a\u666f\u4e2d\u56e0\u7f3a\u4e4f\u4e13\u5bb6\u8bc1\u636e\u800c\u6027\u80fd\u5d29\u6e83\u7684\u95ee\u9898\uff0c\u4e3a\u5904\u7406\u5927\u89c4\u6a21\u52a8\u6001\u6570\u636e\u5e93\u503c\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.11544", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2602.11544", "abs": "https://arxiv.org/abs/2602.11544", "authors": ["Yiming Zhou", "Kaiping Xue", "Enhong Chen"], "title": "Differentially Private Perturbed Push-Sum Protocol and Its Application in Non-Convex Optimization", "comment": null, "summary": "In decentralized networks, nodes cannot ensure that their shared information will be securely preserved by their neighbors, making privacy vulnerable to inference by curious nodes. Adding calibrated random noise before communication to satisfy differential privacy offers a proven defense; however, most existing methods are tailored to specific downstream tasks and lack a general, protocol-level privacy-preserving solution. To bridge this gap, we propose Differentially Private Perturbed Push-Sum (DPPS), a lightweight differential privacy protocol for decentralized communication. Since protocol-level differential privacy introduces the unique challenge of obtaining the sensitivity for each communication round, DPPS introduces a novel sensitivity estimation mechanism that requires each node to compute and broadcast only one scalar per round, enabling rigorous differential privacy guarantees. This design allows DPPS to serve as a plug-and-play, low-cost privacy-preserving solution for downstream applications built on it. To provide a concrete instantiation of DPPS and better balance the privacy-utility trade-off, we design PartPSP, a privacy-preserving decentralized algorithm for non-convex optimization that integrates a partial communication mechanism. By partitioning model parameters into local and shared components and applying DPPS only to the shared parameters, PartPSP reduces the dimensionality of consensus data, thereby lowering the magnitude of injected noise and improving optimization performance. We theoretically prove that PartPSP converges under non-convex objectives and, with partial communication, achieves better optimization performance under the same privacy budget. Experimental results validate the effectiveness of DPPS's privacy-preserving and demonstrate that PartPSP outperforms existing privacy-preserving decentralized optimization algorithms.", "AI": {"tldr": "\u63d0\u51faDPPS\u534f\u8bae\u7ea7\u5dee\u5206\u9690\u79c1\u65b9\u6848\u548cPartPSP\u975e\u51f8\u4f18\u5316\u7b97\u6cd5\uff0c\u901a\u8fc7\u654f\u611f\u5ea6\u4f30\u8ba1\u548c\u90e8\u5206\u901a\u4fe1\u673a\u5236\u5e73\u8861\u9690\u79c1\u4e0e\u6548\u7528", "motivation": "\u73b0\u6709\u53bb\u4e2d\u5fc3\u5316\u7f51\u7edc\u9690\u79c1\u4fdd\u62a4\u65b9\u6cd5\u591a\u4e3a\u7279\u5b9a\u4e0b\u6e38\u4efb\u52a1\u8bbe\u8ba1\uff0c\u7f3a\u4e4f\u901a\u7528\u534f\u8bae\u7ea7\u89e3\u51b3\u65b9\u6848\uff0c\u4e14\u9690\u79c1\u4fdd\u62a4\u4f1a\u5f71\u54cd\u4f18\u5316\u6027\u80fd", "method": "1) DPPS\u534f\u8bae\uff1a\u8f7b\u91cf\u7ea7\u5dee\u5206\u9690\u79c1\u901a\u4fe1\u534f\u8bae\uff0c\u5f15\u5165\u654f\u611f\u5ea6\u4f30\u8ba1\u673a\u5236\uff0c\u6bcf\u8f6e\u53ea\u9700\u5e7f\u64ad\u4e00\u4e2a\u6807\u91cf\uff1b2) PartPSP\u7b97\u6cd5\uff1a\u5c06\u6a21\u578b\u53c2\u6570\u5206\u4e3a\u672c\u5730\u548c\u5171\u4eab\u4e24\u90e8\u5206\uff0c\u4ec5\u5bf9\u5171\u4eab\u53c2\u6570\u5e94\u7528DPPS\uff0c\u964d\u4f4e\u566a\u58f0\u6ce8\u5165\u91cf", "result": "\u7406\u8bba\u8bc1\u660ePartPSP\u5728\u975e\u51f8\u76ee\u6807\u4e0b\u6536\u655b\uff0c\u90e8\u5206\u901a\u4fe1\u673a\u5236\u5728\u76f8\u540c\u9690\u79c1\u9884\u7b97\u4e0b\u83b7\u5f97\u66f4\u597d\u4f18\u5316\u6027\u80fd\uff1b\u5b9e\u9a8c\u9a8c\u8bc1DPPS\u9690\u79c1\u4fdd\u62a4\u6709\u6548\u6027\uff0cPartPSP\u4f18\u4e8e\u73b0\u6709\u9690\u79c1\u4fdd\u62a4\u53bb\u4e2d\u5fc3\u5316\u4f18\u5316\u7b97\u6cd5", "conclusion": "DPPS\u63d0\u4f9b\u901a\u7528\u534f\u8bae\u7ea7\u9690\u79c1\u4fdd\u62a4\u65b9\u6848\uff0cPartPSP\u901a\u8fc7\u90e8\u5206\u901a\u4fe1\u673a\u5236\u5e73\u8861\u9690\u79c1\u4e0e\u6548\u7528\uff0c\u4e3a\u53bb\u4e2d\u5fc3\u5316\u7f51\u7edc\u63d0\u4f9b\u9ad8\u6548\u9690\u79c1\u4fdd\u62a4\u6846\u67b6"}}
{"id": "2602.11223", "categories": ["cs.SE", "cs.HC"], "pdf": "https://arxiv.org/pdf/2602.11223", "abs": "https://arxiv.org/abs/2602.11223", "authors": ["Micheal P. Papazoglou", "Bernd J. Kr\u00e4mer", "Mira Raheem", "Amal Elgammal"], "title": "Patient Digital Twins for Chronic Care: Technical Hurdles, Lessons Learned, and the Road Ahead", "comment": "Feature Article, Patient Medical Digital Twins, Under Review in IEEE SOftware", "summary": "Chronic diseases constitute the principal burden of morbidity, mortality, and healthcare costs worldwide, yet current health systems remain fragmented and predominantly reactive. Patient Medical Digital Twins (PMDTs) offer a paradigm shift: holistic, continuously updated digital counterparts of patients that integrate clinical, genomic, lifestyle, and quality-of-life data. We report early implementations of PMDTs via ontology-driven modeling and federated analytics pilots. Insights from the QUALITOP oncology study and a distributed AI platform confirm both feasibility and challenges: aligning with HL7 FHIR and OMOP standards, embedding privacy governance, scaling federated queries, and designing intuitive clinician interfaces. We also highlight technical gains, such as automated reasoning over multimodal blueprints and predictive analytics for patient outcomes. By reflecting on these experiences, we outline actionable insights for software engineers and identify opportunities, such as DSLs and model-driven engineering, to advance PMDTs toward trustworthy, adaptive chronic care ecosystems.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u60a3\u8005\u533b\u7597\u6570\u5b57\u5b6a\u751f\uff08PMDT\uff09\u5728\u6162\u6027\u75c5\u7ba1\u7406\u4e2d\u7684\u5e94\u7528\uff0c\u901a\u8fc7\u672c\u4f53\u9a71\u52a8\u5efa\u6a21\u548c\u8054\u90a6\u5206\u6790\u8bd5\u70b9\u5c55\u793a\u4e86\u5176\u53ef\u884c\u6027\uff0c\u5e76\u5206\u6790\u4e86\u6280\u672f\u6311\u6218\u548c\u672a\u6765\u53d1\u5c55\u65b9\u5411\u3002", "motivation": "\u6162\u6027\u75be\u75c5\u662f\u5168\u7403\u53d1\u75c5\u3001\u6b7b\u4ea1\u548c\u533b\u7597\u6210\u672c\u7684\u4e3b\u8981\u8d1f\u62c5\uff0c\u4f46\u5f53\u524d\u7684\u533b\u7597\u7cfb\u7edf\u4ecd\u7136\u5206\u6563\u4e14\u4e3b\u8981\u662f\u88ab\u52a8\u53cd\u5e94\u5f0f\u7684\u3002\u60a3\u8005\u533b\u7597\u6570\u5b57\u5b6a\u751f\uff08PMDT\uff09\u63d0\u4f9b\u4e86\u4e00\u4e2a\u8303\u5f0f\u8f6c\u53d8\u7684\u673a\u4f1a\uff1a\u521b\u5efa\u5168\u9762\u3001\u6301\u7eed\u66f4\u65b0\u7684\u60a3\u8005\u6570\u5b57\u526f\u672c\uff0c\u6574\u5408\u4e34\u5e8a\u3001\u57fa\u56e0\u7ec4\u3001\u751f\u6d3b\u65b9\u5f0f\u548c\u751f\u6d3b\u8d28\u91cf\u6570\u636e\u3002", "method": "\u91c7\u7528\u672c\u4f53\u9a71\u52a8\u5efa\u6a21\u548c\u8054\u90a6\u5206\u6790\u8bd5\u70b9\u65b9\u6cd5\uff0c\u901a\u8fc7QUALITOP\u80bf\u7624\u5b66\u7814\u7a76\u548c\u5206\u5e03\u5f0fAI\u5e73\u53f0\u8fdb\u884c\u5b9e\u65bd\u3002\u6280\u672f\u5b9e\u73b0\u5305\u62ec\u4e0eHL7 FHIR\u548cOMOP\u6807\u51c6\u5bf9\u9f50\u3001\u5d4c\u5165\u9690\u79c1\u6cbb\u7406\u3001\u6269\u5c55\u8054\u90a6\u67e5\u8be2\u4ee5\u53ca\u8bbe\u8ba1\u76f4\u89c2\u7684\u4e34\u5e8a\u533b\u751f\u754c\u9762\u3002", "result": "\u65e9\u671f\u5b9e\u65bd\u8bc1\u5b9e\u4e86PMDT\u7684\u53ef\u884c\u6027\uff0c\u4f46\u4e5f\u9762\u4e34\u6311\u6218\uff1a\u6807\u51c6\u5bf9\u9f50\u3001\u9690\u79c1\u6cbb\u7406\u3001\u8054\u90a6\u67e5\u8be2\u6269\u5c55\u548c\u754c\u9762\u8bbe\u8ba1\u3002\u6280\u672f\u6210\u679c\u5305\u62ec\u591a\u6a21\u6001\u84dd\u56fe\u7684\u81ea\u52a8\u63a8\u7406\u548c\u60a3\u8005\u7ed3\u679c\u7684\u9884\u6d4b\u5206\u6790\u3002", "conclusion": "\u901a\u8fc7\u53cd\u601d\u8fd9\u4e9b\u7ecf\u9a8c\uff0c\u4e3a\u8f6f\u4ef6\u5de5\u7a0b\u5e08\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89c1\u89e3\uff0c\u5e76\u786e\u5b9a\u4e86\u673a\u4f1a\u9886\u57df\uff08\u5982\u9886\u57df\u7279\u5b9a\u8bed\u8a00\u548c\u6a21\u578b\u9a71\u52a8\u5de5\u7a0b\uff09\uff0c\u4ee5\u63a8\u52a8PMDT\u5411\u53ef\u4fe1\u8d56\u3001\u81ea\u9002\u5e94\u7684\u6162\u6027\u62a4\u7406\u751f\u6001\u7cfb\u7edf\u53d1\u5c55\u3002"}}
{"id": "2602.11686", "categories": ["cs.DC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.11686", "abs": "https://arxiv.org/abs/2602.11686", "authors": ["Xinyi Liu", "Yujie Wang", "Fangcheng Fu", "Xuefeng Xiao", "Huixia Li", "Jiashi Li", "Bin Cui"], "title": "LAER-MoE: Load-Adaptive Expert Re-layout for Efficient Mixture-of-Experts Training", "comment": "19 pages, 12 figures, the paper will be presented at ASPLOS 2026", "summary": "Expert parallelism is vital for effectively training Mixture-of-Experts (MoE) models, enabling different devices to host distinct experts, with each device processing different input data. However, during expert parallel training, dynamic routing results in significant load imbalance among experts: a handful of overloaded experts hinder overall iteration, emerging as a training bottleneck.\n  In this paper, we introduce LAER-MoE, an efficient MoE training framework. The core of LAER-MoE is a novel parallel paradigm, Fully Sharded Expert Parallel (FSEP), which fully partitions each expert parameter by the number of devices and restores partial experts at expert granularity through All-to-All communication during training. This allows for flexible re-layout of expert parameters during training to enhance load balancing. In particular, we perform fine-grained scheduling of communication operations to minimize communication overhead. Additionally, we develop a load balancing planner to formulate re-layout strategies of experts and routing schemes for tokens during training. We perform experiments on an A100 cluster, and the results indicate that our system achieves up to 1.69x acceleration compared to the current state-of-the-art training systems. Source code available at https://github.com/PKU-DAIR/Hetu-Galvatron/tree/laer-moe.", "AI": {"tldr": "LAER-MoE\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684MoE\u8bad\u7ec3\u6846\u67b6\uff0c\u901a\u8fc7\u5b8c\u5168\u5206\u7247\u4e13\u5bb6\u5e76\u884c(FSEP)\u548c\u8d1f\u8f7d\u5747\u8861\u89c4\u5212\u5668\u89e3\u51b3\u4e13\u5bb6\u5e76\u884c\u8bad\u7ec3\u4e2d\u7684\u8d1f\u8f7d\u4e0d\u5747\u8861\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u6700\u9ad81.69\u500d\u7684\u8bad\u7ec3\u52a0\u901f\u3002", "motivation": "\u4e13\u5bb6\u5e76\u884c\u8bad\u7ec3\u4e2d\uff0c\u52a8\u6001\u8def\u7531\u5bfc\u81f4\u4e13\u5bb6\u95f4\u8d1f\u8f7d\u4e25\u91cd\u4e0d\u5747\u8861\uff0c\u5c11\u6570\u8fc7\u8f7d\u4e13\u5bb6\u6210\u4e3a\u8bad\u7ec3\u74f6\u9888\uff0c\u9650\u5236\u4e86MoE\u6a21\u578b\u7684\u8bad\u7ec3\u6548\u7387\u3002", "method": "\u63d0\u51fa\u5b8c\u5168\u5206\u7247\u4e13\u5bb6\u5e76\u884c(FSEP)\u8303\u5f0f\uff0c\u5c06\u6bcf\u4e2a\u4e13\u5bb6\u53c2\u6570\u5b8c\u5168\u5206\u7247\u5230\u6240\u6709\u8bbe\u5907\uff0c\u901a\u8fc7All-to-All\u901a\u4fe1\u5728\u8bad\u7ec3\u671f\u95f4\u6309\u4e13\u5bb6\u7c92\u5ea6\u6062\u590d\u90e8\u5206\u4e13\u5bb6\u53c2\u6570\uff0c\u5b9e\u73b0\u4e13\u5bb6\u53c2\u6570\u7684\u7075\u6d3b\u91cd\u5e03\u5c40\uff1b\u91c7\u7528\u7ec6\u7c92\u5ea6\u901a\u4fe1\u8c03\u5ea6\u51cf\u5c11\u5f00\u9500\uff0c\u5e76\u5f00\u53d1\u8d1f\u8f7d\u5747\u8861\u89c4\u5212\u5668\u5236\u5b9a\u4e13\u5bb6\u91cd\u5e03\u5c40\u7b56\u7565\u548ctoken\u8def\u7531\u65b9\u6848\u3002", "result": "\u5728A100\u96c6\u7fa4\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cLAER-MoE\u76f8\u6bd4\u5f53\u524d\u6700\u5148\u8fdb\u7684\u8bad\u7ec3\u7cfb\u7edf\u5b9e\u73b0\u4e86\u6700\u9ad81.69\u500d\u7684\u52a0\u901f\u3002", "conclusion": "LAER-MoE\u901a\u8fc7\u521b\u65b0\u7684\u5b8c\u5168\u5206\u7247\u4e13\u5bb6\u5e76\u884c\u8303\u5f0f\u548c\u8d1f\u8f7d\u5747\u8861\u89c4\u5212\uff0c\u6709\u6548\u89e3\u51b3\u4e86MoE\u8bad\u7ec3\u4e2d\u7684\u8d1f\u8f7d\u4e0d\u5747\u8861\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8bad\u7ec3\u6548\u7387\u3002"}}
{"id": "2602.11224", "categories": ["cs.SE", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.11224", "abs": "https://arxiv.org/abs/2602.11224", "authors": ["Hubert M. Pysklo", "Artem Zhuravel", "Patrick D. Watson"], "title": "Agent-Diff: Benchmarking LLM Agents on Enterprise API Tasks via Code Execution with State-Diff-Based Evaluation", "comment": "Pre-Print. Under review for KDD 2026", "summary": "We present Agent-Diff, a novel benchmarking framework for evaluating agentic Large Language Models (LLMs) on real-world tasks that execute code via external APIs. Agentic LLM performance varies due to differences in models, external tool access, prompt structures, and agentic frameworks. Benchmarks must make fundamental trade-offs between a sandboxed approach that controls for variation in software environments and more ecologically valid approaches employing real services. Agent-Diff attempts to capture the desirable features of both of these approaches by including access to the real API interfaces for software services while sandboxing the environment in which calls are made, processed, and evaluated. This approach relies on two key innovations. The first is a novel state-diff contract, which separates process from outcome - rather than fuzzy trace or parameter matching, we define task success as whether the expected change in environment state was achieved. The second is a novel sandbox that provides a standardized scripting layer that all models use to execute code against external APIs (Slack, Box, Linear, Google Calendar). Thus, we can evaluate different agentic LLMs against a standardized set of contracts using a unified sandbox while still evaluating their performance on real-world service interfaces. Using the Agent-Diff framework, we provide benchmarks for nine LLMs across 224 tasks utilizing enterprise software workflows. In addition, we evaluate the robustness of the framework with ablation experiments to assess the contribution of access to API documentation on benchmark performance. Code and data: https://github.com/agent-diff-bench/agent-diff.", "AI": {"tldr": "Agent-Diff\u662f\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30\u57fa\u4e8e\u4ee3\u7801\u6267\u884c\u7684\u667a\u80fd\u4f53LLM\u7684\u57fa\u51c6\u6846\u67b6\uff0c\u901a\u8fc7\u6c99\u76d2\u5316\u771f\u5b9eAPI\u63a5\u53e3\u8bbf\u95ee\uff0c\u4f7f\u7528\u72b6\u6001\u5dee\u5f02\u5408\u7ea6\u5b9a\u4e49\u4efb\u52a1\u6210\u529f\u6807\u51c6\uff0c\u5728\u6807\u51c6\u5316\u73af\u5883\u4e2d\u8bc4\u4f30\u4e0d\u540c\u6a21\u578b\u5728\u771f\u5b9e\u4f01\u4e1a\u8f6f\u4ef6\u5de5\u4f5c\u6d41\u4e2d\u7684\u8868\u73b0\u3002", "motivation": "\u5f53\u524d\u667a\u80fd\u4f53LLM\u7684\u8bc4\u4f30\u9762\u4e34\u6311\u6218\uff1a\u6a21\u578b\u6027\u80fd\u5dee\u5f02\u5927\uff0c\u53d7\u5916\u90e8\u5de5\u5177\u8bbf\u95ee\u3001\u63d0\u793a\u7ed3\u6784\u3001\u667a\u80fd\u4f53\u6846\u67b6\u7b49\u591a\u79cd\u56e0\u7d20\u5f71\u54cd\u3002\u73b0\u6709\u57fa\u51c6\u9700\u8981\u5728\u6c99\u76d2\u5316\u63a7\u5236\u53d8\u91cf\u548c\u751f\u6001\u6709\u6548\u6027\u4e4b\u95f4\u6743\u8861\uff0c\u7f3a\u4e4f\u65e2\u80fd\u4f7f\u7528\u771f\u5b9eAPI\u63a5\u53e3\u53c8\u80fd\u6807\u51c6\u5316\u8bc4\u4f30\u73af\u5883\u7684\u65b9\u6cd5\u3002", "method": "1. \u72b6\u6001\u5dee\u5f02\u5408\u7ea6\uff1a\u5c06\u8fc7\u7a0b\u4e0e\u7ed3\u679c\u5206\u79bb\uff0c\u901a\u8fc7\u73af\u5883\u72b6\u6001\u7684\u9884\u671f\u53d8\u5316\u5b9a\u4e49\u4efb\u52a1\u6210\u529f\uff0c\u800c\u975e\u6a21\u7cca\u7684\u8f68\u8ff9\u6216\u53c2\u6570\u5339\u914d\u30022. \u6807\u51c6\u5316\u6c99\u76d2\uff1a\u63d0\u4f9b\u7edf\u4e00\u7684\u811a\u672c\u5c42\uff0c\u6240\u6709\u6a21\u578b\u90fd\u901a\u8fc7\u8be5\u5c42\u6267\u884c\u4ee3\u7801\u8bbf\u95ee\u5916\u90e8API\uff08Slack\u3001Box\u3001Linear\u3001Google Calendar\u7b49\uff09\u3002", "result": "1. \u5f00\u53d1\u4e86Agent-Diff\u6846\u67b6\uff0c\u652f\u6301\u5bf99\u4e2aLLM\u5728224\u4e2a\u4f01\u4e1a\u8f6f\u4ef6\u5de5\u4f5c\u6d41\u4efb\u52a1\u4e0a\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\u30022. \u901a\u8fc7\u6d88\u878d\u5b9e\u9a8c\u8bc4\u4f30\u4e86API\u6587\u6863\u8bbf\u95ee\u5bf9\u57fa\u51c6\u6027\u80fd\u7684\u8d21\u732e\uff0c\u9a8c\u8bc1\u4e86\u6846\u67b6\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "Agent-Diff\u6210\u529f\u7ed3\u5408\u4e86\u6c99\u76d2\u5316\u63a7\u5236\u548c\u751f\u6001\u6709\u6548\u6027\u7684\u4f18\u52bf\uff0c\u901a\u8fc7\u72b6\u6001\u5dee\u5f02\u5408\u7ea6\u548c\u6807\u51c6\u5316\u6c99\u76d2\uff0c\u4e3a\u667a\u80fd\u4f53LLM\u5728\u771f\u5b9e\u4e16\u754c\u4efb\u52a1\u4e0a\u7684\u8bc4\u4f30\u63d0\u4f9b\u4e86\u7edf\u4e00\u3001\u53ef\u6bd4\u8f83\u7684\u57fa\u51c6\u6846\u67b6\u3002"}}
{"id": "2602.11741", "categories": ["cs.DC", "cs.DB", "cs.PF", "cs.SE"], "pdf": "https://arxiv.org/pdf/2602.11741", "abs": "https://arxiv.org/abs/2602.11741", "authors": ["Bo Guan"], "title": "Designing Scalable Rate Limiting Systems: Algorithms, Architecture, and Distributed Solutions", "comment": "27 pages, 8 figures, 2 tables", "summary": "Designing a rate limiter that is simultaneously accurate, available, and scalable presents a fundamental challenge in distributed systems, primarily due to the trade-offs between algorithmic precision, availability, consistency, and partition tolerance. This article presents a concrete architecture for a distributed rate limiting system in a production-grade environment. Our design chooses the in-memory cache database, the Redis, along with its Sorted Set data structure, which provides $O(log (N))$ time complexity operation for the key-value pair dataset with efficiency and low latency, and maintains precision. The core contribution is quantifying the accuracy and memory cost trade-off of the chosen Rolling Window as the implemented rate limiting algorithm against the Token Bucket and Fixed Window algorithms. In addition, we explain how server-side Lua scripting is critical to bundling cleanup, counting, and insertion into a single atomic operation, thereby eliminating race conditions in concurrent environments. In the system architecture, we propose a three-layer architecture that manages the storage and updating of the limit rules. Through script load by hashing the rule parameters, rules can be changed without modifying the cached scripts. Furthermore, we analyze the deployment of this architecture on a Redis Cluster, which provides the availability and scalability by data sharding and replication. We explain the acceptance of AP (Availability and Partition Tolerance) from the CAP theorem as the pragmatic engineering trade-off for this use case.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eRedis Sorted Set\u7684\u5206\u5e03\u5f0f\u9650\u6d41\u7cfb\u7edf\u67b6\u6784\uff0c\u901a\u8fc7Rolling Window\u7b97\u6cd5\u5728\u51c6\u786e\u6027\u548c\u5185\u5b58\u6210\u672c\u4e4b\u95f4\u53d6\u5f97\u5e73\u8861\uff0c\u91c7\u7528\u4e09\u5c42\u67b6\u6784\u7ba1\u7406\u9650\u6d41\u89c4\u5219\uff0c\u5e76\u5728Redis Cluster\u4e0a\u90e8\u7f72\u4ee5\u5b9e\u73b0\u53ef\u7528\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002", "motivation": "\u8bbe\u8ba1\u4e00\u4e2a\u540c\u65f6\u5177\u5907\u51c6\u786e\u6027\u3001\u53ef\u7528\u6027\u548c\u53ef\u6269\u5c55\u6027\u7684\u9650\u6d41\u5668\u662f\u5206\u5e03\u5f0f\u7cfb\u7edf\u7684\u57fa\u672c\u6311\u6218\uff0c\u4e3b\u8981\u6e90\u4e8e\u7b97\u6cd5\u7cbe\u5ea6\u3001\u53ef\u7528\u6027\u3001\u4e00\u81f4\u6027\u548c\u5206\u533a\u5bb9\u5fcd\u6027\u4e4b\u95f4\u7684\u6743\u8861\u3002\u9700\u8981\u627e\u5230\u4e00\u79cd\u80fd\u5728\u751f\u4ea7\u73af\u5883\u4e2d\u5b9e\u9645\u5e94\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u91c7\u7528Redis\u5185\u5b58\u7f13\u5b58\u6570\u636e\u5e93\u53ca\u5176Sorted Set\u6570\u636e\u7ed3\u6784\uff0c\u63d0\u4f9bO(log(N))\u65f6\u95f4\u590d\u6742\u5ea6\u64cd\u4f5c\uff1b\u5b9e\u73b0Rolling Window\u9650\u6d41\u7b97\u6cd5\uff1b\u4f7f\u7528\u670d\u52a1\u5668\u7aefLua\u811a\u672c\u5c06\u6e05\u7406\u3001\u8ba1\u6570\u548c\u63d2\u5165\u6346\u7ed1\u4e3a\u539f\u5b50\u64cd\u4f5c\uff1b\u8bbe\u8ba1\u4e09\u5c42\u67b6\u6784\u7ba1\u7406\u9650\u6d41\u89c4\u5219\uff1b\u5728Redis Cluster\u4e0a\u90e8\u7f72\uff0c\u901a\u8fc7\u6570\u636e\u5206\u7247\u548c\u590d\u5236\u63d0\u4f9b\u53ef\u7528\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002", "result": "\u91cf\u5316\u4e86Rolling Window\u7b97\u6cd5\u76f8\u5bf9\u4e8eToken Bucket\u548cFixed Window\u7b97\u6cd5\u5728\u51c6\u786e\u6027\u548c\u5185\u5b58\u6210\u672c\u4e4b\u95f4\u7684\u6743\u8861\uff1b\u901a\u8fc7Lua\u811a\u672c\u6d88\u9664\u4e86\u5e76\u53d1\u73af\u5883\u4e2d\u7684\u7ade\u6001\u6761\u4ef6\uff1b\u901a\u8fc7\u89c4\u5219\u53c2\u6570\u54c8\u5e0c\u5b9e\u73b0\u89c4\u5219\u53d8\u66f4\u800c\u65e0\u9700\u4fee\u6539\u7f13\u5b58\u811a\u672c\uff1b\u63a5\u53d7CAP\u5b9a\u7406\u4e2d\u7684AP\uff08\u53ef\u7528\u6027\u548c\u5206\u533a\u5bb9\u5fcd\u6027\uff09\u4f5c\u4e3a\u5b9e\u9645\u5de5\u7a0b\u6743\u8861\u3002", "conclusion": "\u63d0\u51fa\u7684\u5206\u5e03\u5f0f\u9650\u6d41\u7cfb\u7edf\u67b6\u6784\u5728\u751f\u4ea7\u73af\u5883\u4e2d\u662f\u53ef\u884c\u7684\uff0c\u901a\u8fc7Redis Sorted Set\u548cRolling Window\u7b97\u6cd5\u5728\u6548\u7387\u3001\u4f4e\u5ef6\u8fdf\u548c\u7cbe\u5ea6\u4e4b\u95f4\u53d6\u5f97\u5e73\u8861\uff0c\u91c7\u7528\u4e09\u5c42\u67b6\u6784\u548cRedis Cluster\u90e8\u7f72\u6ee1\u8db3\u4e86\u53ef\u7528\u6027\u548c\u53ef\u6269\u5c55\u6027\u9700\u6c42\uff0c\u63a5\u53d7AP\u6743\u8861\u662f\u5b9e\u9645\u5de5\u7a0b\u4e2d\u7684\u5408\u7406\u9009\u62e9\u3002"}}
{"id": "2602.11411", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.11411", "abs": "https://arxiv.org/abs/2602.11411", "authors": ["Yang Liu", "Armstrong Foundjem", "Xingfang Wu", "Heng Li", "Foutse Khomh"], "title": "Improving the Robustness of Large Language Models for Code Tasks via Fine-tuning with Perturbed Data", "comment": null, "summary": "Context: In the fast-paced evolution of software development, Large Language Models (LLMs) have become indispensable tools for tasks such as code generation, completion, analysis, and bug fixing. Ensuring the robustness of these models against potential vulnerabilities from handling diverse inputs is critical, as variations in input can lead to incorrect or insecure code outputs.\n  Objective: This work aims to improve the robustness of LLMs for coding-related tasks against potential adversarial inputs. Specifically, we investigate how fine-tuning LLMs with perturbed datasets impacts their robustness against input perturbations.\n  Method: We systematically evaluated LLM robustness by fine-tuning models using datasets perturbed at character-level, word-level, and sentence-level, comparing results against base models and models fine-tuned on unperturbed datasets.\n  Results: Fine-tuning LLMs with perturbed datasets significantly improves model robustness (RD usually drops around 4\\% - 6\\%), especially for models with relatively weak robustness. However, this fine-tuning process typically results in a slight performance decrease (pass@1 usually drops around 1\\% - 3\\%) compared to fine-tuning with unperturbed datasets, although occasional performance improvements are observed.\n  Conclusion \\& Implications: Fine-tuning LLMs for coding tasks with perturbed data effectively enhances their robustness at the cost of a minor performance reduction, emphasizing the importance of balancing the robustness and performance of LLMs for coding applications.", "AI": {"tldr": "\u901a\u8fc7\u4f7f\u7528\u6270\u52a8\u6570\u636e\u96c6\u5fae\u8c03LLMs\uff0c\u53ef\u4ee5\u663e\u8457\u63d0\u5347\u4ee3\u7801\u76f8\u5173\u4efb\u52a1\u4e2d\u5bf9\u8f93\u5165\u6270\u52a8\u7684\u9c81\u68d2\u6027\uff0c\u4f46\u4f1a\u5e26\u6765\u8f7b\u5fae\u7684\u6027\u80fd\u4e0b\u964d\u3002", "motivation": "\u968f\u7740LLMs\u5728\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u65e5\u76ca\u91cd\u8981\uff0c\u786e\u4fdd\u8fd9\u4e9b\u6a21\u578b\u5904\u7406\u591a\u6837\u5316\u8f93\u5165\u65f6\u7684\u9c81\u68d2\u6027\u81f3\u5173\u91cd\u8981\uff0c\u56e0\u4e3a\u8f93\u5165\u53d8\u5316\u53ef\u80fd\u5bfc\u81f4\u9519\u8bef\u6216\u4e0d\u5b89\u5168\u7684\u4ee3\u7801\u8f93\u51fa\u3002", "method": "\u7cfb\u7edf\u8bc4\u4f30LLM\u9c81\u68d2\u6027\uff0c\u901a\u8fc7\u5728\u5b57\u7b26\u7ea7\u3001\u8bcd\u7ea7\u548c\u53e5\u5b50\u7ea7\u6270\u52a8\u7684\u6570\u636e\u96c6\u4e0a\u5fae\u8c03\u6a21\u578b\uff0c\u5e76\u4e0e\u57fa\u7840\u6a21\u578b\u53ca\u5728\u672a\u6270\u52a8\u6570\u636e\u96c6\u4e0a\u5fae\u8c03\u7684\u6a21\u578b\u8fdb\u884c\u6bd4\u8f83\u3002", "result": "\u4f7f\u7528\u6270\u52a8\u6570\u636e\u96c6\u5fae\u8c03\u663e\u8457\u63d0\u9ad8\u4e86\u6a21\u578b\u9c81\u68d2\u6027\uff08RD\u901a\u5e38\u4e0b\u964d4%-6%\uff09\uff0c\u7279\u522b\u662f\u5bf9\u4e8e\u9c81\u68d2\u6027\u76f8\u5bf9\u8f83\u5f31\u7684\u6a21\u578b\u3002\u4f46\u76f8\u6bd4\u672a\u6270\u52a8\u6570\u636e\u96c6\u5fae\u8c03\uff0c\u901a\u5e38\u4f1a\u5bfc\u81f4\u8f7b\u5fae\u6027\u80fd\u4e0b\u964d\uff08pass@1\u901a\u5e38\u4e0b\u964d1%-3%\uff09\uff0c\u5076\u5c14\u4e5f\u80fd\u89c2\u5bdf\u5230\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "\u4f7f\u7528\u6270\u52a8\u6570\u636e\u5fae\u8c03LLMs\u80fd\u6709\u6548\u589e\u5f3a\u4ee3\u7801\u4efb\u52a1\u7684\u9c81\u68d2\u6027\uff0c\u4ee3\u4ef7\u662f\u8f7b\u5fae\u6027\u80fd\u4e0b\u964d\uff0c\u5f3a\u8c03\u4e86\u5728\u4ee3\u7801\u5e94\u7528\u4e2d\u5e73\u8861\u9c81\u68d2\u6027\u548c\u6027\u80fd\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2602.11998", "categories": ["cs.DC", "cs.NI"], "pdf": "https://arxiv.org/pdf/2602.11998", "abs": "https://arxiv.org/abs/2602.11998", "authors": ["Ramakant kumar"], "title": "An Auction-Based Mechanism for Optimal Task Allocation and Resource Aware Containerization", "comment": null, "summary": "Distributed computing has enabled cooperation between multiple computing devices for the simultaneous execution of resource-hungry tasks. Such execution also plays a pivotal role in the parallel execution of numerous tasks in the Internet of Things (IoT) environment. Leveraging the computing resources of multiple devices, the offloading and processing of computationintensive tasks can be carried out more efficiently. However, managing resources and optimizing costs remain challenging for successfully executing tasks in cloud-based containerization for IoT. This paper proposes AUC-RAC, an auction-based mechanism for efficient offloading of computation tasks among multiple local servers in the context of IoT devices. The approach leverages the concept of Docker swarm, which connects multiple local servers in the form of Manager Node (MN) and Worker Nodes (WNs). It uses Docker containerization to execute tasks simultaneously. In this system, IoT devices send tasks to the MN, which then sends the task details to all its WNs to participate in the auction-based bidding process. The auctionbased bidding process optimizes the allocation of computation tasks among multiple systems, considering their resource sufficiency. The experimental analysis establishes that the approach offers improved offloading and computation-intensive services for IoT devices by enabling cooperation between local servers.", "AI": {"tldr": "\u63d0\u51faAUC-RAC\u62cd\u5356\u673a\u5236\uff0c\u901a\u8fc7Docker Swarm\u8fde\u63a5\u591a\u4e2a\u672c\u5730\u670d\u52a1\u5668\uff0c\u4f18\u5316\u7269\u8054\u7f51\u8bbe\u5907\u8ba1\u7b97\u4efb\u52a1\u5378\u8f7d\u548c\u5206\u914d", "motivation": "\u5206\u5e03\u5f0f\u8ba1\u7b97\u4f7f\u591a\u4e2a\u8ba1\u7b97\u8bbe\u5907\u80fd\u591f\u534f\u4f5c\u6267\u884c\u8d44\u6e90\u5bc6\u96c6\u578b\u4efb\u52a1\uff0c\u5728\u7269\u8054\u7f51\u73af\u5883\u4e2d\u5e76\u884c\u6267\u884c\u4efb\u52a1\u81f3\u5173\u91cd\u8981\u3002\u7136\u800c\uff0c\u5728\u57fa\u4e8e\u4e91\u7684\u7269\u8054\u7f51\u5bb9\u5668\u5316\u4e2d\uff0c\u7ba1\u7406\u8d44\u6e90\u548c\u4f18\u5316\u6210\u672c\u4ecd\u7136\u662f\u6210\u529f\u6267\u884c\u4efb\u52a1\u7684\u6311\u6218\u3002", "method": "\u63d0\u51faAUC-RAC\u62cd\u5356\u673a\u5236\uff0c\u5229\u7528Docker Swarm\u8fde\u63a5\u591a\u4e2a\u672c\u5730\u670d\u52a1\u5668\uff08\u7ba1\u7406\u8282\u70b9\u548c\u5de5\u4f5c\u8282\u70b9\uff09\uff0c\u4f7f\u7528Docker\u5bb9\u5668\u5316\u540c\u65f6\u6267\u884c\u4efb\u52a1\u3002\u7269\u8054\u7f51\u8bbe\u5907\u5c06\u4efb\u52a1\u53d1\u9001\u7ed9\u7ba1\u7406\u8282\u70b9\uff0c\u7ba1\u7406\u8282\u70b9\u5c06\u4efb\u52a1\u8be6\u60c5\u53d1\u9001\u7ed9\u6240\u6709\u5de5\u4f5c\u8282\u70b9\u53c2\u4e0e\u62cd\u5356\u7ade\u6807\u8fc7\u7a0b\uff0c\u57fa\u4e8e\u8d44\u6e90\u5145\u8db3\u6027\u4f18\u5316\u8ba1\u7b97\u4efb\u52a1\u5206\u914d\u3002", "result": "\u5b9e\u9a8c\u5206\u6790\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u901a\u8fc7\u5b9e\u73b0\u672c\u5730\u670d\u52a1\u5668\u4e4b\u95f4\u7684\u534f\u4f5c\uff0c\u4e3a\u7269\u8054\u7f51\u8bbe\u5907\u63d0\u4f9b\u4e86\u6539\u8fdb\u7684\u5378\u8f7d\u548c\u8ba1\u7b97\u5bc6\u96c6\u578b\u670d\u52a1\u3002", "conclusion": "AUC-RAC\u62cd\u5356\u673a\u5236\u80fd\u591f\u6709\u6548\u4f18\u5316\u7269\u8054\u7f51\u73af\u5883\u4e2d\u8ba1\u7b97\u4efb\u52a1\u7684\u5378\u8f7d\u548c\u5206\u914d\uff0c\u63d0\u9ad8\u8d44\u6e90\u5229\u7528\u6548\u7387\u548c\u670d\u52a1\u8d28\u91cf\u3002"}}
{"id": "2602.11435", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.11435", "abs": "https://arxiv.org/abs/2602.11435", "authors": ["Haolin Li", "Michael Coblenz"], "title": "A Grounded Theory of Debugging in Professional Software Engineering Practice", "comment": "Accepted by FSE'26", "summary": "Debugging is a central yet complex activity in software engineering. Prior studies have documented debugging strategies and tool usage, but little theory explains how experienced developers reason about bugs in large, real-world codebases. We conducted a qualitative study using a grounded theory approach. We observed seven professional developers and five professional live-coding streamers working on 17 debugging tasks in their own codebases, capturing diverse contexts of debugging. We theorize debugging as a structured, iterative diagnostic process in which programmers update a mental model of the system to guide information gathering. Developers gather information by alternating between navigation and execution strategies, employing forward and backward tracing modes of reasoning and adapting these approaches according to codebase context, complexity, and familiarity. Developers also gather external resources to complement code-based evidence, with their experience enabling them to systematically construct a mental model. We contribute a grounded theory of professional debugging that surfaces the human-centered dimensions of the practice, with implications for tool design and software engineering education.", "AI": {"tldr": "\u4e13\u4e1a\u5f00\u53d1\u8005\u7684\u8c03\u8bd5\u662f\u4e00\u4e2a\u7ed3\u6784\u5316\u7684\u8bca\u65ad\u8fc7\u7a0b\uff0c\u4ed6\u4eec\u901a\u8fc7\u66f4\u65b0\u7cfb\u7edf\u5fc3\u667a\u6a21\u578b\u6765\u6307\u5bfc\u4fe1\u606f\u6536\u96c6\uff0c\u4ea4\u66ff\u4f7f\u7528\u5bfc\u822a\u548c\u6267\u884c\u7b56\u7565\uff0c\u7ed3\u5408\u6b63\u5411\u548c\u53cd\u5411\u63a8\u7406\u6a21\u5f0f\uff0c\u5e76\u6839\u636e\u4ee3\u7801\u5e93\u4e0a\u4e0b\u6587\u3001\u590d\u6742\u6027\u548c\u719f\u6089\u5ea6\u8c03\u6574\u65b9\u6cd5\u3002", "motivation": "\u8c03\u8bd5\u662f\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u7684\u6838\u5fc3\u4f46\u590d\u6742\u6d3b\u52a8\u3002\u5148\u524d\u7814\u7a76\u8bb0\u5f55\u4e86\u8c03\u8bd5\u7b56\u7565\u548c\u5de5\u5177\u4f7f\u7528\uff0c\u4f46\u7f3a\u4e4f\u89e3\u91ca\u7ecf\u9a8c\u4e30\u5bcc\u7684\u5f00\u53d1\u8005\u5982\u4f55\u5728\u5927\u578b\u771f\u5b9e\u4ee3\u7801\u5e93\u4e2d\u63a8\u7406bug\u7684\u7406\u8bba\u3002\u672c\u7814\u7a76\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7406\u8bba\u7a7a\u767d\u3002", "method": "\u91c7\u7528\u624e\u6839\u7406\u8bba\u65b9\u6cd5\u7684\u5b9a\u6027\u7814\u7a76\uff0c\u89c2\u5bdf7\u540d\u4e13\u4e1a\u5f00\u53d1\u8005\u548c5\u540d\u4e13\u4e1a\u76f4\u64ad\u7f16\u7801\u8005\u5728\u4ed6\u4eec\u81ea\u5df1\u7684\u4ee3\u7801\u5e93\u4e2d\u5904\u740617\u4e2a\u8c03\u8bd5\u4efb\u52a1\uff0c\u6355\u6349\u8c03\u8bd5\u7684\u591a\u6837\u5316\u4e0a\u4e0b\u6587\u3002", "result": "\u8c03\u8bd5\u88ab\u7406\u8bba\u5316\u4e3a\u7ed3\u6784\u5316\u7684\u8fed\u4ee3\u8bca\u65ad\u8fc7\u7a0b\uff0c\u5f00\u53d1\u8005\u901a\u8fc7\u4ea4\u66ff\u5bfc\u822a\u548c\u6267\u884c\u7b56\u7565\u6536\u96c6\u4fe1\u606f\uff0c\u4f7f\u7528\u6b63\u5411\u548c\u53cd\u5411\u8ffd\u8e2a\u63a8\u7406\u6a21\u5f0f\uff0c\u5e76\u6839\u636e\u4ee3\u7801\u5e93\u4e0a\u4e0b\u6587\u3001\u590d\u6742\u6027\u548c\u719f\u6089\u5ea6\u8c03\u6574\u65b9\u6cd5\u3002\u4ed6\u4eec\u8fd8\u4f1a\u6536\u96c6\u5916\u90e8\u8d44\u6e90\u8865\u5145\u4ee3\u7801\u8bc1\u636e\uff0c\u5229\u7528\u7ecf\u9a8c\u7cfb\u7edf\u6784\u5efa\u5fc3\u667a\u6a21\u578b\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e13\u4e1a\u8c03\u8bd5\u7684\u624e\u6839\u7406\u8bba\uff0c\u63ed\u793a\u4e86\u5b9e\u8df5\u4e2d\u7684\u4eba\u4e3a\u4e2d\u5fc3\u7ef4\u5ea6\uff0c\u5bf9\u5de5\u5177\u8bbe\u8ba1\u548c\u8f6f\u4ef6\u5de5\u7a0b\u6559\u80b2\u5177\u6709\u91cd\u8981\u542f\u793a\u3002"}}
{"id": "2602.12070", "categories": ["cs.DC", "math.PR"], "pdf": "https://arxiv.org/pdf/2602.12070", "abs": "https://arxiv.org/abs/2602.12070", "authors": ["Zixi Cai", "Kuowen Chen", "Shengquan Du", "Tsvi Kopelowitz", "Seth Pettie", "Ben Plosk"], "title": "Contention Resolution, With and Without a Global Clock", "comment": null, "summary": "In the Contention Resolution problem $n$ parties each wish to have exclusive use of a shared resource for one unit of time. The problem has been studied since the early 1970s, under a variety of assumptions on feedback given to the parties, how the parties wake up, knowledge of $n$, and so on. The most consistent assumption is that parties do not have access to a global clock, only their local time since wake-up. This is surprising because the assumption of a global clock is both technologically realistic and algorithmically interesting. It enriches the problem, and opens the door to entirely new techniques. Our primary results are: [1] We design a new Contention Resolution protocol that guarantees latency $$O\\left(\\left(n\\log\\log n\\log^{(3)} n\\log^{(4)} n\\cdots \\log^{(\\log^* n)} n\\right)\\cdot 2^{\\log^* n}\\right) \\le n(\\log\\log n)^{1+o(1)}$$ in expectation and with high probability. This already establishes at least a roughly $\\log n$ complexity gap between randomized protocols in GlobalClock and LocalClock. [2] Prior analyses of randomized ContentionResolution protocols in LocalClock guaranteed a certain latency with high probability, i.e., with probability $1-1/\\text{poly}(n)$. We observe that it is just as natural to measure expected latency, and prove a $\\log n$-factor complexity gap between the two objectives for memoryless protocols. The In-Expectation complexity is $\u0398(n \\log n/\\log\\log n)$ whereas the With-High-Probability latency is $\u0398(n\\log^2 n/\\log\\log n)$. Three of these four upper and lower bounds are new. [3] Given the complexity separation above, one would naturally want a ContentionResolution protocol that is optimal under both the In-Expectation and With-High-Probability metrics. This is impossible! It is even impossible to achieve In-Expectation latency $o(n\\log^2 n/(\\log\\log n)^2)$ and With-High-Probability latency $n\\log^{O(1)} n$ simultaneously.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5168\u5c40\u65f6\u949f\u4e0e\u672c\u5730\u65f6\u949f\u5047\u8bbe\u4e0b\u7684\u7ade\u4e89\u89e3\u51b3\u534f\u8bae\uff0c\u5c55\u793a\u4e86\u5168\u5c40\u65f6\u949f\u5e26\u6765\u7684\u7b97\u6cd5\u4f18\u52bf\uff0c\u5206\u6790\u4e86\u671f\u671b\u5ef6\u8fdf\u4e0e\u9ad8\u6982\u7387\u5ef6\u8fdf\u4e4b\u95f4\u7684\u590d\u6742\u5ea6\u5dee\u8ddd\uff0c\u5e76\u8bc1\u660e\u4e86\u65e0\u6cd5\u540c\u65f6\u4f18\u5316\u4e24\u79cd\u5ef6\u8fdf\u6307\u6807\u3002", "motivation": "\u7ade\u4e89\u89e3\u51b3\u662f\u5206\u5e03\u5f0f\u8ba1\u7b97\u4e2d\u7684\u7ecf\u5178\u95ee\u9898\uff0c\u4f20\u7edf\u7814\u7a76\u5047\u8bbe\u5404\u65b9\u53ea\u80fd\u8bbf\u95ee\u672c\u5730\u65f6\u949f\uff08\u81ea\u5524\u9192\u4ee5\u6765\u7684\u65f6\u95f4\uff09\u3002\u672c\u6587\u7684\u52a8\u673a\u662f\u63a2\u7d22\u5168\u5c40\u65f6\u949f\u5047\u8bbe\uff0c\u8fd9\u5728\u6280\u672f\u4e0a\u66f4\u73b0\u5b9e\u4e14\u7b97\u6cd5\u4e0a\u66f4\u6709\u8da3\uff0c\u80fd\u591f\u4e30\u5bcc\u95ee\u9898\u5e76\u5f15\u5165\u65b0\u6280\u672f\u3002", "method": "\u8bbe\u8ba1\u4e86\u65b0\u7684\u7ade\u4e89\u89e3\u51b3\u534f\u8bae\uff0c\u5206\u6790\u4e86\u5168\u5c40\u65f6\u949f\u4e0e\u672c\u5730\u65f6\u949f\u5047\u8bbe\u4e0b\u7684\u6027\u80fd\u5dee\u5f02\u3002\u7814\u7a76\u4e86\u671f\u671b\u5ef6\u8fdf\u4e0e\u9ad8\u6982\u7387\u5ef6\u8fdf\u4e24\u79cd\u5ea6\u91cf\u6807\u51c6\u4e0b\u7684\u590d\u6742\u5ea6\u5dee\u8ddd\uff0c\u5e76\u8bc1\u660e\u4e86\u540c\u65f6\u4f18\u5316\u4e24\u79cd\u6307\u6807\u7684\u4e0d\u53ef\u884c\u6027\u3002", "result": "1) \u8bbe\u8ba1\u4e86\u5168\u5c40\u65f6\u949f\u4e0b\u7684\u65b0\u534f\u8bae\uff0c\u5ef6\u8fdf\u4e3aO(n(log log n)^{1+o(1)})\uff0c\u6bd4\u672c\u5730\u65f6\u949f\u534f\u8bae\u6709\u7ea6log n\u7684\u590d\u6742\u5ea6\u4f18\u52bf\uff1b2) \u53d1\u73b0\u671f\u671b\u5ef6\u8fdf\u4e0e\u9ad8\u6982\u7387\u5ef6\u8fdf\u4e4b\u95f4\u5b58\u5728log n\u56e0\u5b50\u5dee\u8ddd\uff1b3) \u8bc1\u660e\u65e0\u6cd5\u540c\u65f6\u4f18\u5316\u4e24\u79cd\u5ef6\u8fdf\u6307\u6807\u3002", "conclusion": "\u5168\u5c40\u65f6\u949f\u5047\u8bbe\u4e3a\u7ade\u4e89\u89e3\u51b3\u95ee\u9898\u5e26\u6765\u4e86\u7b97\u6cd5\u4f18\u52bf\uff0c\u671f\u671b\u5ef6\u8fdf\u4e0e\u9ad8\u6982\u7387\u5ef6\u8fdf\u4e4b\u95f4\u5b58\u5728\u56fa\u6709\u7684\u590d\u6742\u5ea6\u5dee\u8ddd\uff0c\u4e14\u65e0\u6cd5\u540c\u65f6\u4f18\u5316\u4e24\u79cd\u6307\u6807\uff0c\u8fd9\u4e3a\u5206\u5e03\u5f0f\u534f\u8bae\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u65b0\u7684\u7406\u8bba\u89c1\u89e3\u3002"}}
{"id": "2602.11447", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.11447", "abs": "https://arxiv.org/abs/2602.11447", "authors": ["Zixuan Feng", "Katie Kimura", "Bianca Trinkenreich", "Igor Steinmacher", "Marco Gerosa", "Anita Sarma"], "title": "Addressing OSS Community Managers' Challenges in Contributor Retention", "comment": null, "summary": "Open-source software (OSS) community managers face significant challenges in retaining contributors, as they must monitor activity and engagement while navigating complex dynamics of collaboration. Current tools designed for managing contributor retention (e.g., dashboards) fall short by providing retrospective rather than predictive insights to identify potential disengagement early. Without understanding how to anticipate and prevent disengagement, new solutions risk burdening community managers rather than supporting retention management. Following the Design Science Research paradigm, we employed a mixed-methods approach for problem identification and solution design to address contributor retention. To identify the challenges hindering retention management in OSS, we conducted semi-structured interviews, a multi-vocal literature review, and community surveys. Then through an iterative build-evaluate cycle, we developed and refined strategies for diagnosing retention risks and informing engagement efforts. We operationalized these strategies into a web-based prototype, incorporating feedback from 100+ OSS practitioners, and conducted an in situ evaluation across two OSS communities. Our study offers (1) empirical insights into the challenges of contributor retention management in OSS, (2) actionable strategies that support OSS community managers' retention efforts, and (3) a practical framework for future research in developing or validating theories about OSS sustainability.", "AI": {"tldr": "\u8be5\u7814\u7a76\u9488\u5bf9\u5f00\u6e90\u8f6f\u4ef6\u793e\u533a\u8d21\u732e\u8005\u6d41\u5931\u95ee\u9898\uff0c\u5f00\u53d1\u4e86\u4e00\u4e2a\u9884\u6d4b\u6027\u5206\u6790\u6846\u67b6\u548c\u539f\u578b\u5de5\u5177\uff0c\u5e2e\u52a9\u793e\u533a\u7ba1\u7406\u8005\u63d0\u524d\u8bc6\u522b\u6f5c\u5728\u6d41\u5931\u98ce\u9669\u5e76\u91c7\u53d6\u5e72\u9884\u63aa\u65bd\u3002", "motivation": "\u5f00\u6e90\u8f6f\u4ef6\u793e\u533a\u7ba1\u7406\u8005\u9762\u4e34\u8d21\u732e\u8005\u6d41\u5931\u7684\u6311\u6218\uff0c\u73b0\u6709\u5de5\u5177\uff08\u5982\u4eea\u8868\u677f\uff09\u4ec5\u63d0\u4f9b\u56de\u987e\u6027\u5206\u6790\u800c\u975e\u9884\u6d4b\u6027\u6d1e\u5bdf\uff0c\u65e0\u6cd5\u65e9\u671f\u8bc6\u522b\u6f5c\u5728\u6d41\u5931\u98ce\u9669\uff0c\u5bfc\u81f4\u7ba1\u7406\u8005\u8d1f\u62c5\u52a0\u91cd\u800c\u975e\u83b7\u5f97\u652f\u6301\u3002", "method": "\u91c7\u7528\u8bbe\u8ba1\u79d1\u5b66\u7814\u7a76\u8303\u5f0f\uff0c\u901a\u8fc7\u6df7\u5408\u65b9\u6cd5\u8fdb\u884c\u95ee\u9898\u8bc6\u522b\u548c\u89e3\u51b3\u65b9\u6848\u8bbe\u8ba1\uff1a\u5305\u62ec\u534a\u7ed3\u6784\u5316\u8bbf\u8c08\u3001\u591a\u58f0\u6587\u732e\u7efc\u8ff0\u3001\u793e\u533a\u8c03\u67e5\uff0c\u7136\u540e\u901a\u8fc7\u8fed\u4ee3\u7684\u6784\u5efa-\u8bc4\u4f30\u5faa\u73af\u5f00\u53d1\u5e76\u5b8c\u5584\u6d41\u5931\u98ce\u9669\u8bca\u65ad\u7b56\u7565\uff0c\u6700\u7ec8\u5b9e\u73b0\u4e3a\u57fa\u4e8eWeb\u7684\u539f\u578b\uff0c\u5e76\u6536\u96c6\u4e86100\u591a\u540d\u5f00\u6e90\u4ece\u4e1a\u8005\u7684\u53cd\u9988\uff0c\u5728\u4e24\u4e2a\u5f00\u6e90\u793e\u533a\u8fdb\u884c\u4e86\u5b9e\u5730\u8bc4\u4f30\u3002", "result": "\u7814\u7a76\u63d0\u4f9b\u4e86\uff1a(1) \u5173\u4e8e\u5f00\u6e90\u8f6f\u4ef6\u8d21\u732e\u8005\u6d41\u5931\u7ba1\u7406\u6311\u6218\u7684\u5b9e\u8bc1\u89c1\u89e3\uff1b(2) \u652f\u6301\u5f00\u6e90\u793e\u533a\u7ba1\u7406\u8005\u6d41\u5931\u7ba1\u7406\u5de5\u4f5c\u7684\u53ef\u64cd\u4f5c\u7b56\u7565\uff1b(3) \u4e3a\u672a\u6765\u5f00\u53d1\u6216\u9a8c\u8bc1\u5f00\u6e90\u53ef\u6301\u7eed\u6027\u7406\u8bba\u7814\u7a76\u7684\u5b9e\u7528\u6846\u67b6\u3002", "conclusion": "\u8be5\u7814\u7a76\u6210\u529f\u5f00\u53d1\u4e86\u4e00\u4e2a\u9884\u6d4b\u6027\u5206\u6790\u6846\u67b6\u548c\u5de5\u5177\u539f\u578b\uff0c\u80fd\u591f\u5e2e\u52a9\u5f00\u6e90\u793e\u533a\u7ba1\u7406\u8005\u66f4\u6709\u6548\u5730\u7ba1\u7406\u8d21\u732e\u8005\u6d41\u5931\u95ee\u9898\uff0c\u4e3a\u5f00\u6e90\u53ef\u6301\u7eed\u6027\u7814\u7a76\u63d0\u4f9b\u4e86\u7406\u8bba\u548c\u5b9e\u8df5\u57fa\u7840\u3002"}}
{"id": "2602.12151", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2602.12151", "abs": "https://arxiv.org/abs/2602.12151", "authors": ["Youhe Jiang", "Fangcheng Fu", "Taiyi Wang", "Guoliang He", "Eiko Yoneki"], "title": "OServe: Accelerating LLM Serving via Spatial-Temporal Workload Orchestration", "comment": null, "summary": "Serving Large Language Models (LLMs) can benefit immensely from parallelizing both the model and input requests across multiple devices, but incoming workloads exhibit substantial spatial and temporal heterogeneity. Spatially, workloads comprise heterogeneous requests with varying compute and memory demands. Temporally, workload composition varies over time. Nevertheless, existing systems typically assume spatially uniform and temporally stable workloads, employing a homogeneous, static model deployment. This mismatch between the assumption and real-world spatial-temporal heterogeneity results in suboptimal performance. We present OServe, an LLM serving system with heterogeneous and flexible model deployment that addresses both spatial and temporal heterogeneity. First, OServe introduces a novel workload-aware scheduling algorithm that optimizes heterogeneous model deployments according to real-time workload characteristics. Second, OServe proposes an efficient workload-adaptive switching method that migrates model deployments in response to predicted workload changes. Experiments on real-world traces show that OServe improves performance by up to 2$\\times$ (average: 1.5$\\times$) compared to state-of-the-art serving systems.", "AI": {"tldr": "OServe\u662f\u4e00\u4e2a\u9488\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u670d\u52a1\u7684\u7cfb\u7edf\uff0c\u901a\u8fc7\u5f02\u6784\u7075\u6d3b\u6a21\u578b\u90e8\u7f72\u89e3\u51b3\u5de5\u4f5c\u8d1f\u8f7d\u7684\u65f6\u7a7a\u5f02\u8d28\u6027\u95ee\u9898\uff0c\u76f8\u6bd4\u73b0\u6709\u7cfb\u7edf\u6027\u80fd\u63d0\u5347\u6700\u9ad82\u500d\u3002", "motivation": "\u73b0\u6709LLM\u670d\u52a1\u7cfb\u7edf\u901a\u5e38\u5047\u8bbe\u5de5\u4f5c\u8d1f\u8f7d\u5728\u7a7a\u95f4\u4e0a\u5747\u5300\u3001\u65f6\u95f4\u4e0a\u7a33\u5b9a\uff0c\u91c7\u7528\u540c\u8d28\u9759\u6001\u6a21\u578b\u90e8\u7f72\uff0c\u4f46\u5b9e\u9645\u5de5\u4f5c\u8d1f\u8f7d\u5b58\u5728\u663e\u8457\u7684\u65f6\u7a7a\u5f02\u8d28\u6027\uff08\u7a7a\u95f4\u4e0a\u8bf7\u6c42\u8ba1\u7b97\u5185\u5b58\u9700\u6c42\u5404\u5f02\uff0c\u65f6\u95f4\u4e0a\u5de5\u4f5c\u8d1f\u8f7d\u7ec4\u6210\u52a8\u6001\u53d8\u5316\uff09\uff0c\u5bfc\u81f4\u6027\u80fd\u6b21\u4f18\u3002", "method": "1. \u5f15\u5165\u65b0\u9896\u7684\u5de5\u4f5c\u8d1f\u8f7d\u611f\u77e5\u8c03\u5ea6\u7b97\u6cd5\uff0c\u6839\u636e\u5b9e\u65f6\u5de5\u4f5c\u8d1f\u8f7d\u7279\u5f81\u4f18\u5316\u5f02\u6784\u6a21\u578b\u90e8\u7f72\uff1b2. \u63d0\u51fa\u9ad8\u6548\u7684\u5de5\u4f5c\u8d1f\u8f7d\u81ea\u9002\u5e94\u5207\u6362\u65b9\u6cd5\uff0c\u6839\u636e\u9884\u6d4b\u7684\u5de5\u4f5c\u8d1f\u8f7d\u53d8\u5316\u8fc1\u79fb\u6a21\u578b\u90e8\u7f72\u3002", "result": "\u5728\u771f\u5b9e\u4e16\u754c\u8ddf\u8e2a\u5b9e\u9a8c\u4e2d\uff0cOServe\u76f8\u6bd4\u6700\u5148\u8fdb\u7684\u670d\u52a1\u7cfb\u7edf\u6027\u80fd\u63d0\u5347\u6700\u9ad82\u500d\uff08\u5e73\u57471.5\u500d\uff09\u3002", "conclusion": "OServe\u901a\u8fc7\u5f02\u6784\u7075\u6d3b\u6a21\u578b\u90e8\u7f72\u6709\u6548\u89e3\u51b3\u4e86LLM\u670d\u52a1\u4e2d\u7684\u65f6\u7a7a\u5f02\u8d28\u6027\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u670d\u52a1\u6027\u80fd\u3002"}}
{"id": "2602.11487", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.11487", "abs": "https://arxiv.org/abs/2602.11487", "authors": ["Asmar Muqeet", "Shaukat Ali", "Paolo Arcaini"], "title": "Search-Based Quantum Program Testing via Commuting Pauli String", "comment": null, "summary": "Quantum software testing is important for reliable quantum software engineering. Despite recent advances, existing quantum software testing approaches rely on simple test inputs and statistical oracles, costly program specifications, and limited validation on real quantum computers. To address these challenges, we propose SB-QOPS, a search-based quantum program testing approach via commuting Pauli strings. SB-QOPS, as a direct extension to a previously proposed QOPS approach, redefines test cases in terms of Pauli strings and introduces a measurement-centric oracle that exploits their commutation properties, enabling effective testing of quantum programs while reducing the need for full program specifications. By systematically exploring the search space through an expectation-value-based fitness function, SB-QOPS improves test budget utilization and increases the likelihood of uncovering subtle faults. We conduct a large-scale empirical evaluation on quantum circuits of up to 29 qubits on real quantum computers and emulators. We assess three search strategies: Genetic Algorithm, Hill Climbing, and the (1+1) Evolutionary Algorithm, and evaluate SB-QOPS under both simulated and real noisy conditions. Experiments span three quantum computing platforms: IBM, IQM, and Quantinuum. Results show that SB-QOPS significantly outperforms QOPS, achieving a fault-detection score of 100% for circuits up to 29 qubits, and demonstrating portability across quantum platforms.", "AI": {"tldr": "SB-QOPS\u662f\u4e00\u79cd\u57fa\u4e8e\u641c\u7d22\u7684\u91cf\u5b50\u7a0b\u5e8f\u6d4b\u8bd5\u65b9\u6cd5\uff0c\u901a\u8fc7\u4ea4\u6362Pauli\u5b57\u7b26\u4e32\u548c\u6d4b\u91cf\u4e2d\u5fc3\u5316\u9884\u8a00\u673a\uff0c\u6709\u6548\u6d4b\u8bd5\u91cf\u5b50\u7a0b\u5e8f\u5e76\u51cf\u5c11\u5bf9\u5b8c\u6574\u7a0b\u5e8f\u89c4\u8303\u7684\u9700\u6c42\u3002", "motivation": "\u73b0\u6709\u91cf\u5b50\u8f6f\u4ef6\u6d4b\u8bd5\u65b9\u6cd5\u4f9d\u8d56\u7b80\u5355\u6d4b\u8bd5\u8f93\u5165\u548c\u7edf\u8ba1\u9884\u8a00\u673a\uff0c\u9700\u8981\u6602\u8d35\u7684\u7a0b\u5e8f\u89c4\u8303\uff0c\u4e14\u5728\u771f\u5b9e\u91cf\u5b50\u8ba1\u7b97\u673a\u4e0a\u7684\u9a8c\u8bc1\u6709\u9650\u3002\u9700\u8981\u66f4\u6709\u6548\u7684\u6d4b\u8bd5\u65b9\u6cd5\u6765\u5e94\u5bf9\u8fd9\u4e9b\u6311\u6218\u3002", "method": "SB-QOPS\u5c06\u6d4b\u8bd5\u7528\u4f8b\u91cd\u65b0\u5b9a\u4e49\u4e3aPauli\u5b57\u7b26\u4e32\uff0c\u5f15\u5165\u5229\u7528\u5176\u4ea4\u6362\u6027\u8d28\u7684\u6d4b\u91cf\u4e2d\u5fc3\u5316\u9884\u8a00\u673a\uff0c\u901a\u8fc7\u57fa\u4e8e\u671f\u671b\u503c\u7684\u9002\u5e94\u5ea6\u51fd\u6570\u7cfb\u7edf\u63a2\u7d22\u641c\u7d22\u7a7a\u95f4\uff0c\u63d0\u9ad8\u6d4b\u8bd5\u9884\u7b97\u5229\u7528\u7387\u3002", "result": "\u5728\u771f\u5b9e\u91cf\u5b50\u8ba1\u7b97\u673a\u548c\u6a21\u62df\u5668\u4e0a\u5bf9\u6700\u591a29\u4e2a\u91cf\u5b50\u6bd4\u7279\u7684\u7535\u8def\u8fdb\u884c\u5927\u89c4\u6a21\u8bc4\u4f30\uff0cSB-QOPS\u663e\u8457\u4f18\u4e8eQOPS\uff0c\u5bf9\u6700\u591a29\u4e2a\u91cf\u5b50\u6bd4\u7279\u7684\u7535\u8def\u5b9e\u73b0100%\u7684\u6545\u969c\u68c0\u6d4b\u5206\u6570\uff0c\u5e76\u5c55\u793a\u8de8\u91cf\u5b50\u5e73\u53f0\u7684\u79fb\u690d\u6027\u3002", "conclusion": "SB-QOPS\u901a\u8fc7\u641c\u7d22\u7b56\u7565\u548c\u6d4b\u91cf\u4e2d\u5fc3\u5316\u9884\u8a00\u673a\u6709\u6548\u89e3\u51b3\u4e86\u91cf\u5b50\u7a0b\u5e8f\u6d4b\u8bd5\u7684\u6311\u6218\uff0c\u5728\u771f\u5b9e\u91cf\u5b50\u8ba1\u7b97\u673a\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u5177\u6709\u8de8\u5e73\u53f0\u79fb\u690d\u6027\uff0c\u4e3a\u91cf\u5b50\u8f6f\u4ef6\u6d4b\u8bd5\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.11514", "categories": ["cs.SE", "cs.AI", "cs.CV", "cs.HC"], "pdf": "https://arxiv.org/pdf/2602.11514", "abs": "https://arxiv.org/abs/2602.11514", "authors": ["Sidong Feng", "Chunyang Chen"], "title": "How Smart Is Your GUI Agent? A Framework for the Future of Software Interaction", "comment": null, "summary": "GUI agents are rapidly becoming a new interaction to software, allowing people to navigate web, desktop and mobile rather than execute them click by click. Yet ``agent'' is described with radically different degrees of autonomy, obscuring capability, responsibility and risk. We call for conceptual clarity through GUI Agent Autonomy Levels (GAL), a six-level framework that makes autonomy explicit and helps benchmark progress toward trustworthy software interaction.", "AI": {"tldr": "\u63d0\u51faGUI Agent Autonomy Levels (GAL)\u516d\u5c42\u6846\u67b6\uff0c\u7528\u4e8e\u660e\u786eGUI\u4ee3\u7406\u7684\u81ea\u4e3b\u6027\u7a0b\u5ea6\uff0c\u5e2e\u52a9\u8861\u91cf\u53ef\u4fe1\u8f6f\u4ef6\u4ea4\u4e92\u7684\u8fdb\u5c55", "motivation": "\u5f53\u524dGUI\u4ee3\u7406\u88ab\u63cf\u8ff0\u4e3a\u5177\u6709\u622a\u7136\u4e0d\u540c\u7684\u81ea\u4e3b\u6027\u7a0b\u5ea6\uff0c\u8fd9\u6a21\u7cca\u4e86\u5176\u80fd\u529b\u3001\u8d23\u4efb\u548c\u98ce\u9669\uff0c\u9700\u8981\u6982\u5ff5\u6e05\u6670\u5316", "method": "\u63d0\u51faGUI Agent Autonomy Levels (GAL)\u516d\u5c42\u6846\u67b6\uff0c\u4f7f\u81ea\u4e3b\u6027\u660e\u786e\u5316", "result": "\u5efa\u7acb\u4e86\u7cfb\u7edf\u5316\u7684\u81ea\u4e3b\u6027\u8bc4\u4f30\u6846\u67b6\uff0c\u6709\u52a9\u4e8e\u57fa\u51c6\u6d4b\u8bd5\u53ef\u4fe1\u8f6f\u4ef6\u4ea4\u4e92\u7684\u8fdb\u5c55", "conclusion": "GAL\u6846\u67b6\u4e3aGUI\u4ee3\u7406\u63d0\u4f9b\u4e86\u6982\u5ff5\u6e05\u6670\u5ea6\uff0c\u6709\u52a9\u4e8e\u660e\u786e\u80fd\u529b\u3001\u8d23\u4efb\u548c\u98ce\u9669\uff0c\u63a8\u52a8\u53ef\u4fe1\u8f6f\u4ef6\u4ea4\u4e92\u7684\u53d1\u5c55"}}
{"id": "2602.11671", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.11671", "abs": "https://arxiv.org/abs/2602.11671", "authors": ["Minh Le-Anh", "Huyen Nguyen", "Khanh An Tran", "Nam Le Hai", "Linh Ngo Van", "Nghi D. Q. Bui", "Bach Le"], "title": "Do Not Treat Code as Natural Language: Implications for Repository-Level Code Generation and Beyond", "comment": "Accepted to FSE 2026", "summary": "Large language models for code (CodeLLMs) have demonstrated remarkable success in standalone code completion and generation, sometimes even surpassing human performance, yet their effectiveness diminishes in repository-level settings where cross-file dependencies and structural context are essential. Existing Retrieval-Augmented Generation (RAG) approaches often borrow strategies from NLP, relying on chunking-based indexing and similarity-based retrieval. Chunking results in the loss of coherence between code units and overlooks structural relationships, while similarity-driven methods frequently miss functionally relevant dependencies such as helper functions, classes, or global variables. To address these limitations, we present Hydra, a repository-level code generation framework that treats code as structured code rather than natural language. Our approach introduces (i) a structure-aware indexing strategy that represents repositories as hierarchical trees of functions, classes, and variables, preserving code structure and dependencies, (ii) a lightweight dependency-aware retriever (DAR) that explicitly identifies and retrieves the true dependencies required by a target function, and (iii) a hybrid retrieval mechanism that combines DAR with similarity-based retrieval to provide both essential building blocks and practical usage examples. Extensive experiments on the challenging DevEval and RepoExec benchmarks, both requiring function implementation from real-world repositories with complex large repository context, show that Hydra achieves state-of-the-art performance across open- and closed-source CodeLLMs. Notably, our method establishes a new state of the art in repository-level code generation, surpassing strongest baseline by over 5% in Pass@1 and even enabling smaller models to match or exceed the performance of much larger ones that rely on existing retrievers.", "AI": {"tldr": "Hydra\u662f\u4e00\u4e2a\u4ed3\u5e93\u7ea7\u4ee3\u7801\u751f\u6210\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u6784\u611f\u77e5\u7d22\u5f15\u548c\u4f9d\u8d56\u611f\u77e5\u68c0\u7d22\u89e3\u51b3\u73b0\u6709RAG\u65b9\u6cd5\u5728\u4ee3\u7801\u751f\u6210\u4e2d\u5ffd\u7565\u4ee3\u7801\u7ed3\u6784\u548c\u4f9d\u8d56\u5173\u7cfb\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u7684\u4ee3\u7801\u751f\u6210\u65b9\u6cd5\u4e3b\u8981\u501f\u9274NLP\u7b56\u7565\uff0c\u4f7f\u7528\u5206\u5757\u7d22\u5f15\u548c\u76f8\u4f3c\u6027\u68c0\u7d22\uff0c\u5bfc\u81f4\u4ee3\u7801\u5355\u5143\u95f4\u8fde\u8d2f\u6027\u4e22\u5931\uff0c\u5ffd\u7565\u7ed3\u6784\u5173\u7cfb\uff0c\u4e14\u76f8\u4f3c\u6027\u9a71\u52a8\u65b9\u6cd5\u7ecf\u5e38\u9519\u8fc7\u529f\u80fd\u76f8\u5173\u7684\u4f9d\u8d56\uff08\u5982\u8f85\u52a9\u51fd\u6570\u3001\u7c7b\u3001\u5168\u5c40\u53d8\u91cf\uff09\u3002", "method": "\u63d0\u51faHydra\u6846\u67b6\uff1a1) \u7ed3\u6784\u611f\u77e5\u7d22\u5f15\u7b56\u7565\uff0c\u5c06\u4ed3\u5e93\u8868\u793a\u4e3a\u51fd\u6570\u3001\u7c7b\u548c\u53d8\u91cf\u7684\u5c42\u6b21\u6811\uff0c\u4fdd\u7559\u4ee3\u7801\u7ed3\u6784\u548c\u4f9d\u8d56\uff1b2) \u8f7b\u91cf\u7ea7\u4f9d\u8d56\u611f\u77e5\u68c0\u7d22\u5668\uff0c\u663e\u5f0f\u8bc6\u522b\u548c\u68c0\u7d22\u76ee\u6807\u51fd\u6570\u6240\u9700\u7684\u771f\u5b9e\u4f9d\u8d56\uff1b3) \u6df7\u5408\u68c0\u7d22\u673a\u5236\uff0c\u7ed3\u5408\u4f9d\u8d56\u611f\u77e5\u68c0\u7d22\u548c\u76f8\u4f3c\u6027\u68c0\u7d22\uff0c\u63d0\u4f9b\u57fa\u672c\u6784\u5efa\u5757\u548c\u5b9e\u9645\u4f7f\u7528\u793a\u4f8b\u3002", "result": "\u5728DevEval\u548cRepoExec\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u5728Pass@1\u4e0a\u8d85\u8fc7\u6700\u5f3a\u57fa\u7ebf5%\u4ee5\u4e0a\uff0c\u751a\u81f3\u80fd\u8ba9\u8f83\u5c0f\u6a21\u578b\u5339\u914d\u6216\u8d85\u8fc7\u4f9d\u8d56\u73b0\u6709\u68c0\u7d22\u5668\u7684\u66f4\u5927\u6a21\u578b\u6027\u80fd\u3002", "conclusion": "Hydra\u901a\u8fc7\u5c06\u4ee3\u7801\u89c6\u4e3a\u7ed3\u6784\u5316\u4ee3\u7801\u800c\u975e\u81ea\u7136\u8bed\u8a00\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u4ed3\u5e93\u7ea7\u4ee3\u7801\u751f\u6210\u4e2d\u7684\u7ed3\u6784\u4f9d\u8d56\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4ee3\u7801\u5927\u6a21\u578b\u5728\u590d\u6742\u4ed3\u5e93\u73af\u5883\u4e0b\u7684\u6027\u80fd\u3002"}}
{"id": "2602.11692", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.11692", "abs": "https://arxiv.org/abs/2602.11692", "authors": ["Shashiwadana Nirmani", "Hourieh Khalajzadeh", "Mojtaba Shahin", "Xiao Liu"], "title": "Beyond Code: Empirical Insights into How Team Dynamics Influence OSS Project Selection", "comment": null, "summary": "Open-source software (OSS) development relies on effective collaboration among distributed contributors. Yet, current OSS project recommendation systems primarily emphasize technical attributes, overlooking the collaboration and community aspects that influence contributors' decisions to join and remain in projects. This study investigates how team dynamics within OSS communities influence project selection and how these preferences vary across contributors' motivations. We conducted an online survey with 198 OSS practitioners, combining quantitative and qualitative analyses to capture contributors' perceptions of team dynamics. The results reveal that communication-related team dynamics such as responsiveness, tone, and clarity of replies are consistently prioritized across practitioners. However, the relative importance of these team dynamics differs according to contributors' motivations. For instance, practitioners motivated by gaining reputation or networking preferred inclusive project communities that encouraged diverse participation. These findings highlight that understanding how team dynamics align with contributors' motivations provides valuable insights into practitioners' project selection behaviour. Those insights can inform the design of future human-aware project recommendation systems that better account for social collaboration quality and motivational fit.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u5f00\u6e90\u8d21\u732e\u8005\u5728\u9009\u62e9\u9879\u76ee\u65f6\uff0c\u9664\u4e86\u6280\u672f\u56e0\u7d20\u5916\uff0c\u56e2\u961f\u52a8\u6001\uff08\u5982\u6c9f\u901a\u54cd\u5e94\u6027\u3001\u8bed\u6c14\u3001\u56de\u590d\u6e05\u6670\u5ea6\uff09\u662f\u91cd\u8981\u8003\u91cf\u56e0\u7d20\uff0c\u4e14\u8fd9\u4e9b\u504f\u597d\u591a\u4e0e\u8d21\u732e\u8005\u7684\u52a8\u673a\u7c7b\u578b\u76f8\u5173\u3002", "motivation": "\u5f53\u524d\u5f00\u6e90\u9879\u76ee\u63a8\u8350\u7cfb\u7edf\u4e3b\u8981\u5173\u6ce8\u6280\u672f\u5c5e\u6027\uff0c\u5ffd\u89c6\u4e86\u5f71\u54cd\u8d21\u732e\u8005\u52a0\u5165\u548c\u7559\u5b58\u7684\u534f\u4f5c\u4e0e\u793e\u533a\u56e0\u7d20\u3002\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u56e2\u961f\u52a8\u6001\u5982\u4f55\u5f71\u54cd\u9879\u76ee\u9009\u62e9\uff0c\u4ee5\u53ca\u8fd9\u4e9b\u504f\u597d\u5982\u4f55\u968f\u8d21\u732e\u8005\u52a8\u673a\u800c\u53d8\u5316\u3002", "method": "\u5bf9198\u540d\u5f00\u6e90\u4ece\u4e1a\u8005\u8fdb\u884c\u5728\u7ebf\u8c03\u67e5\uff0c\u7ed3\u5408\u5b9a\u91cf\u548c\u5b9a\u6027\u5206\u6790\u65b9\u6cd5\uff0c\u6355\u6349\u8d21\u732e\u8005\u5bf9\u56e2\u961f\u52a8\u6001\u7684\u611f\u77e5\u3002", "result": "\u6c9f\u901a\u76f8\u5173\u7684\u56e2\u961f\u52a8\u6001\uff08\u54cd\u5e94\u6027\u3001\u8bed\u6c14\u3001\u56de\u590d\u6e05\u6670\u5ea6\uff09\u5728\u6240\u6709\u4ece\u4e1a\u8005\u4e2d\u4e00\u81f4\u88ab\u4f18\u5148\u8003\u8651\u3002\u4f46\u8fd9\u4e9b\u56e2\u961f\u52a8\u6001\u7684\u76f8\u5bf9\u91cd\u8981\u6027\u56e0\u8d21\u732e\u8005\u52a8\u673a\u800c\u5f02\uff1a\u8ffd\u6c42\u58f0\u8a89\u6216\u793e\u4ea4\u7f51\u7edc\u7684\u4ece\u4e1a\u8005\u66f4\u504f\u597d\u9f13\u52b1\u591a\u6837\u53c2\u4e0e\u7684\u5305\u5bb9\u6027\u793e\u533a\u3002", "conclusion": "\u7406\u89e3\u56e2\u961f\u52a8\u6001\u5982\u4f55\u4e0e\u8d21\u732e\u8005\u52a8\u673a\u76f8\u5339\u914d\uff0c\u80fd\u4e3a\u4ece\u4e1a\u8005\u7684\u9879\u76ee\u9009\u62e9\u884c\u4e3a\u63d0\u4f9b\u5b9d\u8d35\u89c1\u89e3\u3002\u8fd9\u4e9b\u53d1\u73b0\u53ef\u4e3a\u8bbe\u8ba1\u672a\u6765\"\u4eba\u7c7b\u611f\u77e5\"\u7684\u9879\u76ee\u63a8\u8350\u7cfb\u7edf\u63d0\u4f9b\u53c2\u8003\uff0c\u66f4\u597d\u5730\u8003\u8651\u793e\u4ea4\u534f\u4f5c\u8d28\u91cf\u548c\u52a8\u673a\u5339\u914d\u3002"}}
{"id": "2602.11724", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.11724", "abs": "https://arxiv.org/abs/2602.11724", "authors": ["Xiwen Teoh", "Yun Lin", "Duc-Minh Nguyen", "Ruofei Ren", "Wenjie Zhang", "Jin Song Dong"], "title": "WebTestPilot: Agentic End-to-End Web Testing against Natural Language Specification by Inferring Oracles with Symbolized GUI Elements", "comment": null, "summary": "Visual language model (VLM) agents show great promise in automating end-to-end (E2E) web testing against requirements in natural language. However, the probabilistic nature of language models can have inherent hallucinations. Therefore, given a detected inconsistency between the requirement and the web application, it is hard to distinguish whether it stems from the hallucination or a real application bug. Addressing this issue presents two core technical challenges: the implicit oracle inference challenge, where the agent must act as its own oracle to implicitly decide if the application's behavior is correct without guidance, and the probabilistic inference challenge, where an LLM's inconsistent reasoning undermines its trustworthiness as an oracle. Existing LLM-based approaches fail to capture such implicit oracles, either by treating any page navigation that doesn't crash as a success, or by checking each state in isolation, thus missing bugs dependent on context from prior steps.\n  We introduce WebTestPilot, an LLM-based agent designed to address these challenges. WebTestPilot uses (1) a symbolization layer which detects and symbolizes critical GUI elements on the web application into symbols (i.e., variables) and (2) translates natural language specification into a sequence of steps, each of which is equipped with inferred pre- and post-conditions over the symbols as an oracle. This oracle captures data, temporal, and causal dependencies, enabling the validation of implicit requirements. To advance research in this area, we build a benchmark of bug-injected web apps for evaluating NL-to-E2E testing. The results show that WebTestPilot achieves a task completion rate of 99%, with 96% precision and 96% recall in bug detection, outperforming the best baseline (+70 precision, +27 recall). The agent generalizes across diverse natural language inputs and model scales.", "AI": {"tldr": "WebTestPilot\uff1a\u4e00\u4e2a\u57fa\u4e8eLLM\u7684\u4ee3\u7406\uff0c\u901a\u8fc7\u7b26\u53f7\u5316GUI\u5143\u7d20\u548c\u63a8\u65ad\u524d\u540e\u6761\u4ef6\u4f5c\u4e3a\u9690\u5f0f\u9884\u8a00\u673a\uff0c\u89e3\u51b3VLM\u4ee3\u7406\u5728Web\u6d4b\u8bd5\u4e2d\u7684\u5e7b\u89c9\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347bug\u68c0\u6d4b\u7cbe\u5ea6\u548c\u53ec\u56de\u7387\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8e\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08VLM\uff09\u7684\u4ee3\u7406\u5728\u7aef\u5230\u7aefWeb\u6d4b\u8bd5\u4e2d\u5b58\u5728\u56fa\u6709\u5e7b\u89c9\u95ee\u9898\uff1a\u5f53\u68c0\u6d4b\u5230\u9700\u6c42\u4e0eWeb\u5e94\u7528\u4e0d\u4e00\u81f4\u65f6\uff0c\u96be\u4ee5\u533a\u5206\u662f\u6a21\u578b\u5e7b\u89c9\u8fd8\u662f\u771f\u5b9e\u5e94\u7528bug\u3002\u8fd9\u6d89\u53ca\u4e24\u4e2a\u6838\u5fc3\u6280\u672f\u6311\u6218\uff1a1\uff09\u9690\u5f0f\u9884\u8a00\u673a\u63a8\u65ad\u6311\u6218\uff08\u4ee3\u7406\u9700\u81ea\u884c\u5224\u65ad\u5e94\u7528\u884c\u4e3a\u662f\u5426\u6b63\u786e\uff09\uff1b2\uff09\u6982\u7387\u63a8\u65ad\u6311\u6218\uff08LLM\u7684\u4e0d\u4e00\u81f4\u63a8\u7406\u524a\u5f31\u4e86\u5176\u4f5c\u4e3a\u9884\u8a00\u673a\u7684\u53ef\u4fe1\u5ea6\uff09\u3002\u73b0\u6709\u65b9\u6cd5\u65e0\u6cd5\u6709\u6548\u6355\u83b7\u9690\u5f0f\u9884\u8a00\u673a\u3002", "method": "WebTestPilot\u91c7\u7528\u4e24\u79cd\u5173\u952e\u6280\u672f\uff1a1\uff09\u7b26\u53f7\u5316\u5c42\uff1a\u68c0\u6d4b\u5e76\u5c06\u5173\u952eGUI\u5143\u7d20\u7b26\u53f7\u5316\u4e3a\u53d8\u91cf\uff1b2\uff09\u5c06\u81ea\u7136\u8bed\u8a00\u89c4\u8303\u8f6c\u6362\u4e3a\u6b65\u9aa4\u5e8f\u5217\uff0c\u6bcf\u4e2a\u6b65\u9aa4\u914d\u5907\u57fa\u4e8e\u7b26\u53f7\u63a8\u65ad\u7684\u524d\u540e\u6761\u4ef6\u4f5c\u4e3a\u9884\u8a00\u673a\u3002\u8be5\u9884\u8a00\u673a\u6355\u83b7\u6570\u636e\u3001\u65f6\u95f4\u548c\u56e0\u679c\u4f9d\u8d56\uff0c\u4ece\u800c\u9a8c\u8bc1\u9690\u5f0f\u9700\u6c42\u3002", "result": "\u5728\u6ce8\u5165bug\u7684Web\u5e94\u7528\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cWebTestPilot\u8fbe\u523099%\u7684\u4efb\u52a1\u5b8c\u6210\u7387\uff0cbug\u68c0\u6d4b\u7cbe\u5ea696%\u3001\u53ec\u56de\u738796%\uff0c\u663e\u8457\u4f18\u4e8e\u6700\u4f73\u57fa\u7ebf\uff08\u7cbe\u5ea6\u63d0\u534770%\uff0c\u53ec\u56de\u7387\u63d0\u534727\uff09\u3002\u8be5\u4ee3\u7406\u80fd\u6cdb\u5316\u5230\u4e0d\u540c\u7684\u81ea\u7136\u8bed\u8a00\u8f93\u5165\u548c\u6a21\u578b\u89c4\u6a21\u3002", "conclusion": "WebTestPilot\u901a\u8fc7\u7b26\u53f7\u5316GUI\u5143\u7d20\u548c\u63a8\u65ad\u524d\u540e\u6761\u4ef6\u4f5c\u4e3a\u9690\u5f0f\u9884\u8a00\u673a\uff0c\u6709\u6548\u89e3\u51b3\u4e86VLM\u4ee3\u7406\u5728Web\u6d4b\u8bd5\u4e2d\u7684\u5e7b\u89c9\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86bug\u68c0\u6d4b\u7684\u51c6\u786e\u6027\u548c\u53ef\u9760\u6027\uff0c\u4e3a\u81ea\u7136\u8bed\u8a00\u5230\u7aef\u5230\u7aef\u6d4b\u8bd5\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.11746", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.11746", "abs": "https://arxiv.org/abs/2602.11746", "authors": ["Nafiz Imtiaz Khan", "Vladimir Filkov"], "title": "Leveraging Language Models to Discover Evidence-Based Actions for OSS Sustainability", "comment": null, "summary": "When successful, Open Source Software (OSS) projects create enormous value, but most never reach a sustainable state. Recent work has produced accurate models that forecast OSS sustainability, yet these models rarely tell maintainers what to do: their features are often high-level socio-technical signals that are not directly actionable. Decades of empirical software engineering research have accumulated a large but underused body of evidence on concrete practices that improve project health.\n  We close this gap by using LLMs as evidence miners over the SE literature. We design a RAG-pipeline and a two-layer prompting strategy that extract researched actionables (ReACTs): concise, evidence-linked recommendations mapping to specific OSS practices. In the first layer, we systematically explore open LLMs and prompting techniques, selecting the best-performing combination to derive candidate ReACTs from 829 ICSE and FSE papers. In the second layer, we apply follow-up prompting to filter hallucinations, extract impact and evidence, and assess soundness and precision.\n  Our pipeline yields 1,922 ReACTs, of which 1,312 pass strict quality criteria and are organized into practice-oriented categories connectable to project signals from tools like APEX. The result is a reproducible, scalable approach turning scattered research findings into structured, evidence-based actions guiding OSS projects toward sustainability.", "AI": {"tldr": "\u4f7f\u7528LLM\u4ece\u8f6f\u4ef6\u5de5\u7a0b\u6587\u732e\u4e2d\u6316\u6398\u8bc1\u636e\uff0c\u751f\u6210\u53ef\u64cd\u4f5c\u7684\u3001\u6709\u7814\u7a76\u652f\u6301\u7684OSS\u9879\u76ee\u53ef\u6301\u7eed\u6027\u5efa\u8bae\uff08ReACTs\uff09", "motivation": "\u73b0\u6709OSS\u53ef\u6301\u7eed\u6027\u9884\u6d4b\u6a21\u578b\u867d\u7136\u51c6\u786e\uff0c\u4f46\u7279\u5f81\u5f80\u5f80\u662f\u9ad8\u5c42\u6b21\u7684\u793e\u4f1a\u6280\u672f\u4fe1\u53f7\uff0c\u4e0d\u76f4\u63a5\u53ef\u64cd\u4f5c\u3002\u5927\u91cf\u8f6f\u4ef6\u5de5\u7a0b\u5b9e\u8bc1\u7814\u7a76\u79ef\u7d2f\u4e86\u6539\u5584\u9879\u76ee\u5065\u5eb7\u7684\u5177\u4f53\u5b9e\u8df5\u8bc1\u636e\uff0c\u4f46\u672a\u88ab\u5145\u5206\u5229\u7528\u3002", "method": "\u8bbe\u8ba1RAG\u7ba1\u9053\u548c\u4e24\u5c42\u63d0\u793a\u7b56\u7565\uff1a\u7b2c\u4e00\u5c42\u63a2\u7d22\u5f00\u6e90LLM\u548c\u63d0\u793a\u6280\u672f\uff0c\u4ece829\u7bc7ICSE\u548cFSE\u8bba\u6587\u4e2d\u63d0\u53d6\u5019\u9009ReACTs\uff1b\u7b2c\u4e8c\u5c42\u5e94\u7528\u540e\u7eed\u63d0\u793a\u8fc7\u6ee4\u5e7b\u89c9\uff0c\u63d0\u53d6\u5f71\u54cd\u548c\u8bc1\u636e\uff0c\u8bc4\u4f30\u5408\u7406\u6027\u548c\u7cbe\u786e\u5ea6\u3002", "result": "\u751f\u62101,922\u4e2aReACTs\uff0c\u5176\u4e2d1,312\u4e2a\u901a\u8fc7\u4e25\u683c\u8d28\u91cf\u6807\u51c6\uff0c\u7ec4\u7ec7\u6210\u9762\u5411\u5b9e\u8df5\u7684\u7c7b\u522b\uff0c\u53ef\u4e0eAPEX\u7b49\u5de5\u5177\u7684\u9879\u76ee\u4fe1\u53f7\u8fde\u63a5\u3002", "conclusion": "\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u91cd\u590d\u3001\u53ef\u6269\u5c55\u7684\u65b9\u6cd5\uff0c\u5c06\u5206\u6563\u7684\u7814\u7a76\u53d1\u73b0\u8f6c\u5316\u4e3a\u7ed3\u6784\u5316\u3001\u57fa\u4e8e\u8bc1\u636e\u7684\u884c\u52a8\uff0c\u6307\u5bfcOSS\u9879\u76ee\u5b9e\u73b0\u53ef\u6301\u7eed\u6027\u3002"}}
{"id": "2602.11750", "categories": ["cs.SE", "cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2602.11750", "abs": "https://arxiv.org/abs/2602.11750", "authors": ["Jiazheng Sun", "Mingxuan Li", "Yingying Zhang", "Jiayang Niu", "Yachen Wu", "Ruihan Jin", "Shuyu Lei", "Pengrongrui Tan", "Zongyu Zhang", "Ruoyi Wang", "Jiachen Yang", "Boyu Yang", "Jiacheng Liu", "Xin Peng"], "title": "AmbiBench: Benchmarking Mobile GUI Agents Beyond One-Shot Instructions in the Wild", "comment": "21 pages, 7 figures", "summary": "Benchmarks are paramount for gauging progress in the domain of Mobile GUI Agents. In practical scenarios, users frequently fail to articulate precise directives containing full task details at the onset, and their expressions are typically ambiguous. Consequently, agents are required to converge on the user's true intent via active clarification and interaction during execution. However, existing benchmarks predominantly operate under the idealized assumption that user-issued instructions are complete and unequivocal. This paradigm focuses exclusively on assessing single-turn execution while overlooking the alignment capability of the agent. To address this limitation, we introduce AmbiBench, the first benchmark incorporating a taxonomy of instruction clarity to shift evaluation from unidirectional instruction following to bidirectional intent alignment. Grounded in Cognitive Gap theory, we propose a taxonomy of four clarity levels: Detailed, Standard, Incomplete, and Ambiguous. We construct a rigorous dataset of 240 ecologically valid tasks across 25 applications, subject to strict review protocols. Furthermore, targeting evaluation in dynamic environments, we develop MUSE (Mobile User Satisfaction Evaluator), an automated framework utilizing an MLLM-as-a-judge multi-agent architecture. MUSE performs fine-grained auditing across three dimensions: Outcome Effectiveness, Execution Quality, and Interaction Quality. Empirical results on AmbiBench reveal the performance boundaries of SoTA agents across different clarity levels, quantify the gains derived from active interaction, and validate the strong correlation between MUSE and human judgment. This work redefines evaluation standards, laying the foundation for next-generation agents capable of truly understanding user intent.", "AI": {"tldr": "AmbiBench\uff1a\u9996\u4e2a\u9488\u5bf9\u79fb\u52a8GUI\u667a\u80fd\u4f53\u7684\u610f\u56fe\u5bf9\u9f50\u57fa\u51c6\uff0c\u5f15\u5165\u6307\u4ee4\u6e05\u6670\u5ea6\u5206\u7c7b\uff0c\u8bc4\u4f30\u667a\u80fd\u4f53\u5728\u6a21\u7cca\u6307\u4ee4\u4e0b\u7684\u4e3b\u52a8\u6f84\u6e05\u548c\u4ea4\u4e92\u80fd\u529b", "motivation": "\u73b0\u6709\u57fa\u51c6\u5047\u8bbe\u7528\u6237\u6307\u4ee4\u5b8c\u6574\u660e\u786e\uff0c\u53ea\u8bc4\u4f30\u5355\u8f6e\u6267\u884c\uff0c\u5ffd\u89c6\u4e86\u667a\u80fd\u4f53\u7684\u610f\u56fe\u5bf9\u9f50\u80fd\u529b\u3002\u5b9e\u9645\u573a\u666f\u4e2d\u7528\u6237\u6307\u4ee4\u901a\u5e38\u6a21\u7cca\u4e0d\u5b8c\u6574\uff0c\u9700\u8981\u667a\u80fd\u4f53\u901a\u8fc7\u4ea4\u4e92\u6f84\u6e05\u610f\u56fe", "method": "\u57fa\u4e8e\u8ba4\u77e5\u5dee\u8ddd\u7406\u8bba\u63d0\u51fa\u56db\u79cd\u6307\u4ee4\u6e05\u6670\u5ea6\u5206\u7c7b\uff1a\u8be6\u7ec6\u3001\u6807\u51c6\u3001\u4e0d\u5b8c\u6574\u3001\u6a21\u7cca\u3002\u6784\u5efa\u5305\u542b240\u4e2a\u751f\u6001\u6709\u6548\u4efb\u52a1\u7684\u4e25\u683c\u6570\u636e\u96c6\uff0c\u5f00\u53d1MUSE\u81ea\u52a8\u5316\u8bc4\u4f30\u6846\u67b6\uff0c\u91c7\u7528MLLM-as-a-judge\u591a\u667a\u80fd\u4f53\u67b6\u6784\u8fdb\u884c\u4e09\u7ef4\u5ea6\u7ec6\u7c92\u5ea6\u8bc4\u4f30", "result": "\u63ed\u793a\u4e86\u6700\u5148\u8fdb\u667a\u80fd\u4f53\u5728\u4e0d\u540c\u6e05\u6670\u5ea6\u6c34\u5e73\u4e0b\u7684\u6027\u80fd\u8fb9\u754c\uff0c\u91cf\u5316\u4e86\u4e3b\u52a8\u4ea4\u4e92\u5e26\u6765\u7684\u6536\u76ca\uff0c\u9a8c\u8bc1\u4e86MUSE\u8bc4\u4f30\u4e0e\u4eba\u7c7b\u5224\u65ad\u7684\u5f3a\u76f8\u5173\u6027", "conclusion": "\u91cd\u65b0\u5b9a\u4e49\u4e86\u8bc4\u4f30\u6807\u51c6\uff0c\u4e3a\u771f\u6b63\u7406\u89e3\u7528\u6237\u610f\u56fe\u7684\u4e0b\u4e00\u4ee3\u667a\u80fd\u4f53\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u4ece\u5355\u5411\u6307\u4ee4\u6267\u884c\u8f6c\u5411\u53cc\u5411\u610f\u56fe\u5bf9\u9f50"}}
{"id": "2602.11887", "categories": ["cs.SE", "cs.CR"], "pdf": "https://arxiv.org/pdf/2602.11887", "abs": "https://arxiv.org/abs/2602.11887", "authors": ["Javier Ron", "Martin Monperrus"], "title": "Verifiable Provenance of Software Artifacts with Zero-Knowledge Compilation", "comment": null, "summary": "Verifying that a compiled binary originates from its claimed source code is a fundamental security requirement, called source code provenance. Achieving verifiable source code provenance in practice remains challenging. The most popular technique, called reproducible builds, requires difficult matching and reexecution of build toolchains and environments. We propose a novel approach to verifiable provenance based on compiling software with zero-knowledge virtual machines (zkVMs). By executing a compiler within a zkVM, our system produces both the compiled output and a cryptographic proof attesting that the compilation was performed on the claimed source code with the claimed compiler. We implement a proof-of-concept implementation using the RISC Zero zkVM and the ChibiCC C compiler, and evaluate it on 200 synthetic programs as well as 31 OpenSSL and 21 libsodium source files. Our results show that zk-compilation is applicable to real-world software and provides strong security guarantees: all adversarial tests targeting compiler substitution, source tampering, output manipulation, and replay attacks are successfully blocked.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u96f6\u77e5\u8bc6\u865a\u62df\u673a\uff08zkVM\uff09\u7684\u6e90\u4ee3\u7801\u6eaf\u6e90\u9a8c\u8bc1\u65b9\u6cd5\uff0c\u901a\u8fc7\u5728zkVM\u4e2d\u6267\u884c\u7f16\u8bd1\u5668\u751f\u6210\u7f16\u8bd1\u8f93\u51fa\u548c\u5bc6\u7801\u5b66\u8bc1\u660e\uff0c\u9a8c\u8bc1\u6e90\u4ee3\u7801\u548c\u7f16\u8bd1\u5668\u7684\u771f\u5b9e\u6027\u3002", "motivation": "\u5f53\u524d\u6e90\u4ee3\u7801\u6eaf\u6e90\u9a8c\u8bc1\u5728\u5b9e\u8df5\u4e2d\u4ecd\u7136\u56f0\u96be\uff0c\u6700\u6d41\u884c\u7684\u53ef\u91cd\u73b0\u6784\u5efa\u6280\u672f\u9700\u8981\u5339\u914d\u548c\u91cd\u65b0\u6267\u884c\u6784\u5efa\u5de5\u5177\u94fe\u548c\u73af\u5883\uff0c\u8fc7\u7a0b\u590d\u6742\u3002\u9700\u8981\u4e00\u79cd\u66f4\u7b80\u5355\u6709\u6548\u7684\u9a8c\u8bc1\u65b9\u6cd5\u3002", "method": "\u5728\u96f6\u77e5\u8bc6\u865a\u62df\u673a\uff08zkVM\uff09\u4e2d\u6267\u884c\u7f16\u8bd1\u5668\uff0c\u751f\u6210\u7f16\u8bd1\u8f93\u51fa\u548c\u5bc6\u7801\u5b66\u8bc1\u660e\uff0c\u8bc1\u660e\u7f16\u8bd1\u662f\u5728\u58f0\u660e\u7684\u6e90\u4ee3\u7801\u548c\u7f16\u8bd1\u5668\u4e0a\u6267\u884c\u7684\u3002\u4f7f\u7528RISC Zero zkVM\u548cChibiCC C\u7f16\u8bd1\u5668\u5b9e\u73b0\u6982\u5ff5\u9a8c\u8bc1\u3002", "result": "\u5728200\u4e2a\u5408\u6210\u7a0b\u5e8f\u300131\u4e2aOpenSSL\u548c21\u4e2alibsodium\u6e90\u6587\u4ef6\u4e0a\u8bc4\u4f30\uff0czk\u7f16\u8bd1\u9002\u7528\u4e8e\u5b9e\u9645\u8f6f\u4ef6\uff0c\u6210\u529f\u963b\u6b62\u4e86\u6240\u6709\u9488\u5bf9\u7f16\u8bd1\u5668\u66ff\u6362\u3001\u6e90\u4ee3\u7801\u7be1\u6539\u3001\u8f93\u51fa\u64cd\u7eb5\u548c\u91cd\u653e\u653b\u51fb\u7684\u5bf9\u6297\u6027\u6d4b\u8bd5\u3002", "conclusion": "\u57fa\u4e8ezkVM\u7684\u7f16\u8bd1\u65b9\u6cd5\u4e3a\u6e90\u4ee3\u7801\u6eaf\u6e90\u63d0\u4f9b\u4e86\u5f3a\u5927\u7684\u5b89\u5168\u4fdd\u8bc1\uff0c\u80fd\u591f\u6709\u6548\u9a8c\u8bc1\u4e8c\u8fdb\u5236\u6587\u4ef6\u662f\u5426\u6765\u81ea\u58f0\u660e\u7684\u6e90\u4ee3\u7801\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u7684\u590d\u6742\u6027\u6311\u6218\u3002"}}
{"id": "2602.11904", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.11904", "abs": "https://arxiv.org/abs/2602.11904", "authors": ["Weixing Zhang", "Bowen Jiang", "Yuhong Fu", "Anne Koziolek", "Regina Hebig", "Daniel Str\u00fcber"], "title": "Leveraging LLMs to support co-evolution between definitions and instances of textual DSLs: A Systematic Evaluation", "comment": null, "summary": "Software languages evolve over time for reasons such as feature additions. When grammars evolve, textual instances that originally conformed to them may become outdated. While model-driven engineering provides many techniques for co-evolving models with metamodel changes, these approaches are not designed for textual DSLs and may lose human-relevant information such as layout and comments. This study systematically evaluates the potential of large language models (LLMs) for co-evolving grammars and instances of textual DSLs. Using Claude Sonnet 4.5 and GPT-5.2 across ten case languages with ten runs each, we assess both correctness and preservation of human-oriented information. Results show strong performance on small-scale cases ($\\geq$94% precision and recall for instances requiring fewer than 20 modified lines), but performance degraded with scale: Claude maintains 85% recall at 40 lines, while GPT fails on the largest instances. Response time increases substantially with instance size, and grammar evolution complexity and deletion granularity affect performance more than change type. These findings clarify when LLM-based co-evolution is effective and where current limitations remain.", "AI": {"tldr": "LLMs\u5728\u6587\u672cDSL\u8bed\u6cd5\u548c\u5b9e\u4f8b\u534f\u540c\u6f14\u5316\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u4f46\u89c4\u6a21\u589e\u5927\u65f6\u6027\u80fd\u4e0b\u964d\uff0cClaude\u572840\u884c\u4fee\u6539\u65f6\u4fdd\u630185%\u53ec\u56de\u7387\uff0cGPT\u5728\u5927\u5b9e\u4f8b\u4e0a\u5931\u8d25", "motivation": "\u6587\u672cDSL\u8bed\u6cd5\u6f14\u5316\u65f6\uff0c\u73b0\u6709\u6a21\u578b\u9a71\u52a8\u5de5\u7a0b\u65b9\u6cd5\u65e0\u6cd5\u4fdd\u7559\u5e03\u5c40\u548c\u6ce8\u91ca\u7b49\u4eba\u6027\u5316\u4fe1\u606f\uff0c\u9700\u8981\u8bc4\u4f30LLMs\u5728\u534f\u540c\u6f14\u5316\u4e2d\u7684\u6f5c\u529b", "method": "\u4f7f\u7528Claude Sonnet 4.5\u548cGPT-5.2\u572810\u4e2a\u6848\u4f8b\u8bed\u8a00\u4e0a\u5404\u8fd0\u884c10\u6b21\uff0c\u8bc4\u4f30\u6b63\u786e\u6027\u548c\u4eba\u6027\u5316\u4fe1\u606f\u4fdd\u7559\u80fd\u529b", "result": "\u5c0f\u89c4\u6a21\u6848\u4f8b\u8868\u73b0\u4f18\u79c0\uff08\u226594%\u7cbe\u786e\u7387\u548c\u53ec\u56de\u7387\uff0c\u4fee\u6539\u5c11\u4e8e20\u884c\uff09\uff0c\u4f46\u89c4\u6a21\u589e\u5927\u65f6\u6027\u80fd\u4e0b\u964d\uff1aClaude\u572840\u884c\u65f6\u4fdd\u630185%\u53ec\u56de\u7387\uff0cGPT\u5728\u5927\u5b9e\u4f8b\u4e0a\u5931\u8d25\uff1b\u54cd\u5e94\u65f6\u95f4\u968f\u5b9e\u4f8b\u89c4\u6a21\u663e\u8457\u589e\u52a0", "conclusion": "LLM\u5728\u6587\u672cDSL\u534f\u540c\u6f14\u5316\u4e2d\u6709\u6548\uff0c\u4f46\u5f53\u524d\u9650\u5236\u5728\u4e8e\u89c4\u6a21\u6269\u5c55\u6027\uff0c\u8bed\u6cd5\u6f14\u5316\u590d\u6742\u6027\u548c\u5220\u9664\u7c92\u5ea6\u6bd4\u53d8\u66f4\u7c7b\u578b\u5f71\u54cd\u66f4\u5927"}}
{"id": "2602.11911", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.11911", "abs": "https://arxiv.org/abs/2602.11911", "authors": ["Giuseppe Crupi", "Rosalia Tufano", "Gabriele Bavota"], "title": "Improving Code Generation via Small Language Model-as-a-judge", "comment": "Accepted to the 48th International Conference on Software Engineering (ICSE 2026)", "summary": "Large language models (LLMs) have shown remarkable capabilities in automated code generation. While effective for mainstream languages, they may underperform on less common or domain-specific languages, prompting companies to develop in-house code generators. While open-source models can be trained for this, only LLMs with tens of billions of parameters match the performance of commercial tools, demanding costly training and deployment. Recent work proposed supporting code generation with smaller models (SLMs) by generating multiple candidate solutions and using another SLM to select the most likely correct one. The most recent work in this area is the one by Sun et al. [29] presenting RankEF, a T5 model trained to rank code solutions using both execution-based and non-execution-based information. However, Sun et al. do not assess the T5 ranker's classification accuracy, that is, how often it misjudges correct implementations as incorrect or vice versa, leaving open questions about the reliability of LMs as code correctness judges for other tasks (e.g., automated code review). Moreover, their experiments involve relatively old models, making it unclear the extent to which such a methodology would still help companies in cheaply training their own code generators with performance comparable to those of massive LLMs. We present a study addressing these limitations. We train several state-of-the-art SLMs as code correctness judges and assess their ability to discriminate between correct and wrong implementations. We show that modern SLMs outperform RankEF, even without exploiting execution-based information. When used as code rankers, they achieve higher performance gains than RankEF and perform competitively with LLMs 5-25x larger, at a fraction of the cost.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4f7f\u7528\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u4ee3\u7801\u6b63\u786e\u6027\u5224\u65ad\u5668\uff0c\u53d1\u73b0\u73b0\u4ee3SLMs\u5728\u533a\u5206\u6b63\u786e\u4e0e\u9519\u8bef\u4ee3\u7801\u5b9e\u73b0\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u80fd\u4ee5\u4f4e\u6210\u672c\u8fbe\u5230\u4e0e\u5927\u578bLLMs\u76f8\u5f53\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u4ee3\u7801\u751f\u6210\u65b9\u6cd5\u4e2d\uff0c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5bf9\u4e0d\u5e38\u89c1\u6216\u9886\u57df\u7279\u5b9a\u8bed\u8a00\u8868\u73b0\u4e0d\u4f73\uff0c\u800c\u5f00\u6e90\u6a21\u578b\u9700\u8981\u6570\u5341\u4ebf\u53c2\u6570\u624d\u80fd\u5339\u914d\u5546\u4e1a\u5de5\u5177\u6027\u80fd\uff0c\u6210\u672c\u9ad8\u6602\u3002\u73b0\u6709RankEF\u65b9\u6cd5\u672a\u8bc4\u4f30\u5206\u7c7b\u51c6\u786e\u6027\uff0c\u4e14\u4f7f\u7528\u76f8\u5bf9\u9648\u65e7\u7684\u6a21\u578b\uff0c\u65e0\u6cd5\u786e\u5b9a\u8be5\u65b9\u6cd5\u662f\u5426\u4ecd\u80fd\u5e2e\u52a9\u516c\u53f8\u4f4e\u6210\u672c\u8bad\u7ec3\u81ea\u5df1\u7684\u4ee3\u7801\u751f\u6210\u5668\u3002", "method": "\u8bad\u7ec3\u591a\u4e2a\u6700\u5148\u8fdb\u7684\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u4ee3\u7801\u6b63\u786e\u6027\u5224\u65ad\u5668\uff0c\u8bc4\u4f30\u5b83\u4eec\u533a\u5206\u6b63\u786e\u4e0e\u9519\u8bef\u4ee3\u7801\u5b9e\u73b0\u7684\u80fd\u529b\u3002\u5c06\u73b0\u4ee3SLMs\u7528\u4f5c\u4ee3\u7801\u6392\u5e8f\u5668\uff0c\u5e76\u4e0e\u73b0\u6709\u65b9\u6cd5RankEF\u8fdb\u884c\u6bd4\u8f83\u3002", "result": "\u73b0\u4ee3SLMs\u5728\u4ee3\u7801\u6b63\u786e\u6027\u5224\u65ad\u65b9\u9762\u4f18\u4e8eRankEF\uff0c\u5373\u4f7f\u4e0d\u4f7f\u7528\u6267\u884c\u4fe1\u606f\u3002\u4f5c\u4e3a\u4ee3\u7801\u6392\u5e8f\u5668\u65f6\uff0c\u5b83\u4eec\u6bd4RankEF\u83b7\u5f97\u66f4\u9ad8\u7684\u6027\u80fd\u63d0\u5347\uff0c\u5e76\u4e14\u4ee5\u4f4e\u6210\u672c\u8fbe\u5230\u6bd4\u81ea\u8eab\u59275-25\u500d\u7684\u5927\u578bLLMs\u7684\u7ade\u4e89\u6027\u6027\u80fd\u3002", "conclusion": "\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u53ef\u4ee5\u4f5c\u4e3a\u6709\u6548\u7684\u4ee3\u7801\u6b63\u786e\u6027\u5224\u65ad\u5668\uff0c\u4ee5\u4f4e\u6210\u672c\u5b9e\u73b0\u4e0e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u76f8\u5f53\u7684\u6027\u80fd\uff0c\u4e3a\u516c\u53f8\u5728\u7279\u5b9a\u9886\u57df\u5f00\u53d1\u9ad8\u6548\u4ee3\u7801\u751f\u6210\u5668\u63d0\u4f9b\u4e86\u7ecf\u6d4e\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.11925", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.11925", "abs": "https://arxiv.org/abs/2602.11925", "authors": ["Giuseppe Crupi", "Rosalia Tufano", "Gabriele Bavota"], "title": "Studying Quality Improvements Recommended via Manual and Automated Code Review", "comment": "Accepted at the 34th International Conference on Program Comprehension (ICPC 2026)", "summary": "Several Deep Learning (DL)-based techniques have been proposed to automate code review. Still, it is unclear the extent to which these approaches can recommend quality improvements as a human reviewer. We study the similarities and differences between code reviews performed by humans and those automatically generated by DL models, using ChatGPT-4 as representative of the latter. In particular, we run a mining-based study in which we collect and manually inspect 739 comments posted by human reviewers to suggest code changes in 240 PRs. The manual inspection aims at classifying the type of quality improvement recommended by human reviewers (e.g., rename variable/constant). Then, we ask ChatGPT to perform a code review on the same PRs and we compare the quality improvements it recommends against those suggested by the human reviewers. We show that while, on average, ChatGPT tends to recommend a higher number of code changes as compared to human reviewers (~2.4x more), it can only spot 10% of the quality issues reported by humans. However, ~40% of the additional comments generated by the LLM point to meaningful quality issues. In short, our findings show the complementarity of manual and AI-based code review. This finding suggests that, in its current state, DL-based code review can be used as a further quality check on top of the one performed by humans, but should not be considered as a valid alternative to them nor as a mean to save code review time, since human reviewers would still need to perform their manual inspection while also validating the quality issues reported by the DL-based technique.", "AI": {"tldr": "\u7814\u7a76\u6bd4\u8f83\u4eba\u7c7b\u4e0eChatGPT-4\u5728\u4ee3\u7801\u5ba1\u67e5\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0AI\u80fd\u53d1\u73b0\u66f4\u591a\u95ee\u9898\u4f46\u4ec5\u80fd\u8bc6\u522b10%\u7684\u4eba\u7c7b\u53d1\u73b0\u7684\u8d28\u91cf\u95ee\u9898\uff0c\u4e24\u8005\u5177\u6709\u4e92\u8865\u6027", "motivation": "\u867d\u7136\u5df2\u6709\u8bb8\u591a\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u4ee3\u7801\u5ba1\u67e5\u81ea\u52a8\u5316\u6280\u672f\uff0c\u4f46\u5c1a\u4e0d\u6e05\u695a\u8fd9\u4e9b\u65b9\u6cd5\u80fd\u5426\u50cf\u4eba\u7c7b\u5ba1\u67e5\u8005\u4e00\u6837\u63a8\u8350\u8d28\u91cf\u6539\u8fdb\u3002\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7a76\u4eba\u7c7b\u4e0eAI\u4ee3\u7801\u5ba1\u67e5\u7684\u76f8\u4f3c\u6027\u548c\u5dee\u5f02", "method": "\u901a\u8fc7\u6316\u6398\u7814\u7a76\u6536\u96c6240\u4e2aPR\u4e2d\u7684739\u6761\u4eba\u7c7b\u8bc4\u8bba\uff0c\u624b\u52a8\u5206\u7c7b\u8d28\u91cf\u6539\u8fdb\u7c7b\u578b\uff1b\u7136\u540e\u8ba9ChatGPT\u5ba1\u67e5\u76f8\u540cPR\uff0c\u6bd4\u8f83\u4e24\u8005\u63a8\u8350\u7684\u8d28\u91cf\u6539\u8fdb", "result": "ChatGPT\u5e73\u5747\u63a8\u8350\u4ee3\u7801\u53d8\u66f4\u6570\u91cf\u662f\u4eba\u7c7b\u76842.4\u500d\uff0c\u4f46\u4ec5\u80fd\u53d1\u73b010%\u7684\u4eba\u7c7b\u62a5\u544a\u7684\u8d28\u91cf\u95ee\u9898\uff1b\u7ea640%\u7684AI\u989d\u5916\u8bc4\u8bba\u6307\u5411\u6709\u610f\u4e49\u7684\u8d28\u95ee\u9898", "conclusion": "\u4eba\u7c7b\u4e0eAI\u4ee3\u7801\u5ba1\u67e5\u5177\u6709\u4e92\u8865\u6027\uff0c\u5f53\u524dAI\u53ea\u80fd\u4f5c\u4e3a\u4eba\u7c7b\u5ba1\u67e5\u7684\u989d\u5916\u8d28\u91cf\u68c0\u67e5\uff0c\u4e0d\u80fd\u66ff\u4ee3\u4eba\u7c7b\u5ba1\u67e5\u6216\u8282\u7701\u5ba1\u67e5\u65f6\u95f4\uff0c\u56e0\u4e3a\u4eba\u7c7b\u4ecd\u9700\u9a8c\u8bc1AI\u62a5\u544a\u7684\u95ee\u9898"}}
{"id": "2602.11988", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.11988", "abs": "https://arxiv.org/abs/2602.11988", "authors": ["Thibaud Gloaguen", "Niels M\u00fcndler", "Mark M\u00fcller", "Veselin Raychev", "Martin Vechev"], "title": "Evaluating AGENTS.md: Are Repository-Level Context Files Helpful for Coding Agents?", "comment": null, "summary": "A widespread practice in software development is to tailor coding agents to repositories using context files, such as AGENTS.md, by either manually or automatically generating them. Although this practice is strongly encouraged by agent developers, there is currently no rigorous investigation into whether such context files are actually effective for real-world tasks. In this work, we study this question and evaluate coding agents' task completion performance in two complementary settings: established SWE-bench tasks from popular repositories, with LLM-generated context files following agent-developer recommendations, and a novel collection of issues from repositories containing developer-committed context files.\n  Across multiple coding agents and LLMs, we find that context files tend to reduce task success rates compared to providing no repository context, while also increasing inference cost by over 20%. Behaviorally, both LLM-generated and developer-provided context files encourage broader exploration (e.g., more thorough testing and file traversal), and coding agents tend to respect their instructions. Ultimately, we conclude that unnecessary requirements from context files make tasks harder, and human-written context files should describe only minimal requirements.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\uff1a\u4e3a\u4ee3\u7801\u751f\u6210\u4ee3\u7406\u63d0\u4f9b\u4e0a\u4e0b\u6587\u6587\u4ef6\uff08\u5982AGENTS.md\uff09\u53cd\u800c\u4f1a\u964d\u4f4e\u4efb\u52a1\u6210\u529f\u7387\u5e76\u589e\u52a020%\u4ee5\u4e0a\u63a8\u7406\u6210\u672c\uff0c\u5efa\u8bae\u4eba\u7c7b\u7f16\u5199\u7684\u4e0a\u4e0b\u6587\u6587\u4ef6\u5e94\u4ec5\u63cf\u8ff0\u6700\u5c0f\u9700\u6c42\u3002", "motivation": "\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u666e\u904d\u5b58\u5728\u4e3a\u4ee3\u7801\u751f\u6210\u4ee3\u7406\u5b9a\u5236\u4e0a\u4e0b\u6587\u6587\u4ef6\uff08\u5982AGENTS.md\uff09\u7684\u505a\u6cd5\uff0c\u867d\u7136\u4ee3\u7406\u5f00\u53d1\u8005\u5f3a\u70c8\u63a8\u8350\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u8fd9\u4e9b\u4e0a\u4e0b\u6587\u6587\u4ef6\u5728\u5b9e\u9645\u4efb\u52a1\u4e2d\u6709\u6548\u6027\u7684\u4e25\u8c28\u7814\u7a76\u3002", "method": "\u5728\u4e24\u4e2a\u4e92\u8865\u8bbe\u7f6e\u4e2d\u8bc4\u4f30\u4ee3\u7801\u4ee3\u7406\u7684\u4efb\u52a1\u5b8c\u6210\u6027\u80fd\uff1a1) \u4f7f\u7528LLM\u751f\u6210\u7684\u4e0a\u4e0b\u6587\u6587\u4ef6\u8bc4\u4f30SWE-bench\u57fa\u51c6\u4efb\u52a1\uff1b2) \u4f7f\u7528\u5305\u542b\u5f00\u53d1\u8005\u63d0\u4ea4\u7684\u4e0a\u4e0b\u6587\u6587\u4ef6\u7684\u65b0\u95ee\u9898\u96c6\u5408\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u4e0a\u4e0b\u6587\u6587\u4ef6\u76f8\u6bd4\u4e0d\u63d0\u4f9b\u4ed3\u5e93\u4e0a\u4e0b\u6587\u4f1a\u964d\u4f4e\u4efb\u52a1\u6210\u529f\u7387\uff0c\u540c\u65f6\u589e\u52a020%\u4ee5\u4e0a\u63a8\u7406\u6210\u672c\u3002\u4e0a\u4e0b\u6587\u6587\u4ef6\u9f13\u52b1\u66f4\u5e7f\u6cdb\u7684\u63a2\u7d22\uff08\u5982\u66f4\u5f7b\u5e95\u7684\u6d4b\u8bd5\u548c\u6587\u4ef6\u904d\u5386\uff09\uff0c\u4ee3\u7406\u503e\u5411\u4e8e\u9075\u5faa\u5176\u6307\u4ee4\u3002", "conclusion": "\u4e0a\u4e0b\u6587\u6587\u4ef6\u4e2d\u7684\u4e0d\u5fc5\u8981\u8981\u6c42\u4f1a\u4f7f\u4efb\u52a1\u53d8\u5f97\u66f4\u96be\uff0c\u4eba\u7c7b\u7f16\u5199\u7684\u4e0a\u4e0b\u6587\u6587\u4ef6\u5e94\u4ec5\u63cf\u8ff0\u6700\u5c0f\u9700\u6c42\uff0c\u907f\u514d\u8fc7\u5ea6\u7ea6\u675f\u3002"}}
{"id": "2602.12038", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.12038", "abs": "https://arxiv.org/abs/2602.12038", "authors": ["Yuejun Guo", "Qiang Hu", "Qiang Tang", "Yves Le Traon"], "title": "An Empirical Study of the Imbalance Issue in Software Vulnerability Detection", "comment": "This paper was accepted by the 28th European Symposium on Research in Computer Security (ESORICS), 2023", "summary": "Vulnerability detection is crucial to protect software security. Nowadays, deep learning (DL) is the most promising technique to automate this detection task, leveraging its superior ability to extract patterns and representations within extensive code volumes. Despite its promise, DL-based vulnerability detection remains in its early stages, with model performance exhibiting variability across datasets. Drawing insights from other well-explored application areas like computer vision, we conjecture that the imbalance issue (the number of vulnerable code is extremely small) is at the core of the phenomenon. To validate this, we conduct a comprehensive empirical study involving nine open-source datasets and two state-of-the-art DL models. The results confirm our conjecture. We also obtain insightful findings on how existing imbalance solutions perform in vulnerability detection. It turns out that these solutions perform differently as well across datasets and evaluation metrics. Specifically: 1) Focal loss is more suitable to improve the precision, 2) mean false error and class-balanced loss encourages the recall, and 3) random over-sampling facilitates the F1-measure. However, none of them excels across all metrics. To delve deeper, we explore external influences on these solutions and offer insights for developing new solutions.", "AI": {"tldr": "\u8be5\u7814\u7a76\u9a8c\u8bc1\u4e86\u4ee3\u7801\u6f0f\u6d1e\u68c0\u6d4b\u4e2d\u6570\u636e\u4e0d\u5e73\u8861\u95ee\u9898\u662f\u5bfc\u81f4\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u6027\u80fd\u4e0d\u7a33\u5b9a\u7684\u6838\u5fc3\u539f\u56e0\uff0c\u5e76\u901a\u8fc7\u5b9e\u8bc1\u7814\u7a76\u53d1\u73b0\u73b0\u6709\u4e0d\u5e73\u8861\u89e3\u51b3\u65b9\u6848\u5728\u4e0d\u540c\u6570\u636e\u96c6\u548c\u8bc4\u4f30\u6307\u6807\u4e0a\u8868\u73b0\u5404\u5f02\uff0c\u4f46\u6ca1\u6709\u4e00\u4e2a\u80fd\u5728\u6240\u6709\u6307\u6807\u4e0a\u90fd\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u5c3d\u7ba1\u6df1\u5ea6\u5b66\u4e60\u5728\u81ea\u52a8\u5316\u6f0f\u6d1e\u68c0\u6d4b\u65b9\u9762\u524d\u666f\u5e7f\u9614\uff0c\u4f46\u73b0\u6709\u6a21\u578b\u5728\u4e0d\u540c\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4e0d\u7a33\u5b9a\u3002\u7814\u7a76\u8005\u63a8\u6d4b\u8fd9\u53ef\u80fd\u6e90\u4e8e\u6570\u636e\u4e0d\u5e73\u8861\u95ee\u9898\uff08\u6f0f\u6d1e\u4ee3\u7801\u6570\u91cf\u6781\u5c11\uff09\uff0c\u9700\u8981\u9a8c\u8bc1\u8fd9\u4e00\u5047\u8bbe\u5e76\u63a2\u7d22\u73b0\u6709\u4e0d\u5e73\u8861\u89e3\u51b3\u65b9\u6848\u5728\u6f0f\u6d1e\u68c0\u6d4b\u4e2d\u7684\u8868\u73b0\u3002", "method": "\u4f7f\u75289\u4e2a\u5f00\u6e90\u6570\u636e\u96c6\u548c2\u4e2a\u6700\u5148\u8fdb\u7684\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u8fdb\u884c\u5168\u9762\u7684\u5b9e\u8bc1\u7814\u7a76\uff0c\u9a8c\u8bc1\u6570\u636e\u4e0d\u5e73\u8861\u95ee\u9898\u7684\u5f71\u54cd\uff0c\u5e76\u6d4b\u8bd5\u591a\u79cd\u73b0\u6709\u4e0d\u5e73\u8861\u89e3\u51b3\u65b9\u6848\uff08\u5982Focal loss\u3001mean false error\u3001class-balanced loss\u3001\u968f\u673a\u8fc7\u91c7\u6837\u7b49\uff09\u5728\u6f0f\u6d1e\u68c0\u6d4b\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002", "result": "\u7814\u7a76\u8bc1\u5b9e\u4e86\u6570\u636e\u4e0d\u5e73\u8861\u662f\u5bfc\u81f4\u6a21\u578b\u6027\u80fd\u4e0d\u7a33\u5b9a\u7684\u6838\u5fc3\u539f\u56e0\u3002\u73b0\u6709\u4e0d\u5e73\u8861\u89e3\u51b3\u65b9\u6848\u5728\u4e0d\u540c\u6570\u636e\u96c6\u548c\u8bc4\u4f30\u6307\u6807\u4e0a\u8868\u73b0\u5404\u5f02\uff1aFocal loss\u66f4\u9002\u5408\u63d0\u9ad8\u7cbe\u786e\u7387\uff0cmean false error\u548cclass-balanced loss\u80fd\u63d0\u5347\u53ec\u56de\u7387\uff0c\u968f\u673a\u8fc7\u91c7\u6837\u6709\u52a9\u4e8e\u6539\u5584F1\u5206\u6570\uff0c\u4f46\u6ca1\u6709\u4e00\u4e2a\u89e3\u51b3\u65b9\u6848\u80fd\u5728\u6240\u6709\u6307\u6807\u4e0a\u90fd\u8868\u73b0\u51fa\u8272\u3002", "conclusion": "\u6570\u636e\u4e0d\u5e73\u8861\u786e\u5b9e\u662f\u6f0f\u6d1e\u68c0\u6d4b\u4e2d\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u6027\u80fd\u4e0d\u7a33\u5b9a\u7684\u5173\u952e\u56e0\u7d20\u3002\u73b0\u6709\u4e0d\u5e73\u8861\u89e3\u51b3\u65b9\u6848\u5404\u6709\u4fa7\u91cd\u4f46\u90fd\u4e0d\u5168\u9762\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u63a2\u7d22\u5916\u90e8\u5f71\u54cd\u56e0\u7d20\u5e76\u5f00\u53d1\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u6765\u5168\u9762\u63d0\u5347\u6f0f\u6d1e\u68c0\u6d4b\u6027\u80fd\u3002"}}
{"id": "2602.12058", "categories": ["cs.SE", "cs.AI", "cs.FL"], "pdf": "https://arxiv.org/pdf/2602.12058", "abs": "https://arxiv.org/abs/2602.12058", "authors": ["Zhiyong Chen", "Jialun Cao", "Chang Xu", "Shing-Chi Cheung"], "title": "ModelWisdom: An Integrated Toolkit for TLA+ Model Visualization, Digest and Repair", "comment": "Accepted by FM 2026 Research Track (Tool)", "summary": "Model checking in TLA+ provides strong correctness guarantees, yet practitioners continue to face significant challenges in interpreting counterexamples, understanding large state-transition graphs, and repairing faulty models. These difficulties stem from the limited explainability of raw model-checker output and the substantial manual effort required to trace violations back to source specifications. Although the TLA+ Toolbox includes a state diagram viewer, it offers only a static, fully expanded graph without folding, color highlighting, or semantic explanations, which limits its scalability and interpretability. We present ModelWisdom, an interactive environment that uses visualization and large language models to make TLA+ model checking more interpretable and actionable. ModelWisdom offers: (i) Model Visualization, with colorized violation highlighting, click-through links from transitions to TLA+ code, and mapping between violating states and broken properties; (ii) Graph Optimization, including tree-based structuring and node/edge folding to manage large models; (iii) Model Digest, which summarizes and explains subgraphs via large language models (LLMs) and performs preprocessing and partial explanations; and (iv) Model Repair, which extracts error information and supports iterative debugging. Together, these capabilities turn raw model-checker output into an interactive, explainable workflow, improving understanding and reducing debugging effort for nontrivial TLA+ specifications. The website to ModelWisdom is available: https://model-wisdom.pages.dev. A demonstrative video can be found at https://www.youtube.com/watch?v=plyZo30VShA.", "AI": {"tldr": "ModelWisdom\u662f\u4e00\u4e2a\u4ea4\u4e92\u5f0f\u73af\u5883\uff0c\u901a\u8fc7\u53ef\u89c6\u5316\u6280\u672f\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u589e\u5f3aTLA+\u6a21\u578b\u68c0\u67e5\u7684\u53ef\u89e3\u91ca\u6027\uff0c\u63d0\u4f9b\u53ef\u89c6\u5316\u3001\u56fe\u4f18\u5316\u3001\u6a21\u578b\u6458\u8981\u548c\u6a21\u578b\u4fee\u590d\u529f\u80fd\u3002", "motivation": "TLA+\u6a21\u578b\u68c0\u67e5\u867d\u7136\u63d0\u4f9b\u5f3a\u6b63\u786e\u6027\u4fdd\u8bc1\uff0c\u4f46\u5b9e\u8df5\u4e2d\u5b58\u5728\u89e3\u91ca\u53cd\u4f8b\u56f0\u96be\u3001\u7406\u89e3\u5927\u578b\u72b6\u6001\u8f6c\u79fb\u56fe\u56f0\u96be\u3001\u4fee\u590d\u9519\u8bef\u6a21\u578b\u56f0\u96be\u7b49\u95ee\u9898\u3002\u73b0\u6709TLA+\u5de5\u5177\u7bb1\u7684\u53ef\u89c6\u5316\u5de5\u5177\u529f\u80fd\u6709\u9650\uff0c\u7f3a\u4e4f\u6298\u53e0\u3001\u989c\u8272\u9ad8\u4eae\u548c\u8bed\u4e49\u89e3\u91ca\uff0c\u9650\u5236\u4e86\u53ef\u6269\u5c55\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002", "method": "\u5f00\u53d1ModelWisdom\u4ea4\u4e92\u73af\u5883\uff0c\u5305\u542b\u56db\u4e2a\u6838\u5fc3\u529f\u80fd\uff1a1) \u6a21\u578b\u53ef\u89c6\u5316\uff08\u989c\u8272\u5316\u8fdd\u89c4\u9ad8\u4eae\u3001\u70b9\u51fb\u94fe\u63a5\u4ece\u8f6c\u6362\u5230TLA+\u4ee3\u7801\u3001\u8fdd\u89c4\u72b6\u6001\u4e0e\u5c5e\u6027\u6620\u5c04\uff09\uff1b2) \u56fe\u4f18\u5316\uff08\u57fa\u4e8e\u6811\u7684\u7ed3\u6784\u5316\u3001\u8282\u70b9/\u8fb9\u6298\u53e0\uff09\uff1b3) \u6a21\u578b\u6458\u8981\uff08\u901a\u8fc7LLM\u603b\u7ed3\u89e3\u91ca\u5b50\u56fe\u3001\u9884\u5904\u7406\u548c\u90e8\u5206\u89e3\u91ca\uff09\uff1b4) \u6a21\u578b\u4fee\u590d\uff08\u63d0\u53d6\u9519\u8bef\u4fe1\u606f\u3001\u652f\u6301\u8fed\u4ee3\u8c03\u8bd5\uff09\u3002", "result": "ModelWisdom\u5c06\u539f\u59cb\u6a21\u578b\u68c0\u67e5\u5668\u8f93\u51fa\u8f6c\u5316\u4e3a\u4ea4\u4e92\u5f0f\u3001\u53ef\u89e3\u91ca\u7684\u5de5\u4f5c\u6d41\uff0c\u63d0\u9ad8\u4e86\u5bf9\u590d\u6742TLA+\u89c4\u8303\u7684\u7406\u89e3\uff0c\u51cf\u5c11\u4e86\u8c03\u8bd5\u5de5\u4f5c\u91cf\u3002\u63d0\u4f9b\u4e86\u7f51\u7ad9\u548c\u6f14\u793a\u89c6\u9891\u3002", "conclusion": "ModelWisdom\u901a\u8fc7\u53ef\u89c6\u5316\u6280\u672f\u548cLLM\u589e\u5f3a\u4e86TLA+\u6a21\u578b\u68c0\u67e5\u7684\u53ef\u89e3\u91ca\u6027\u548c\u53ef\u64cd\u4f5c\u6027\uff0c\u5c06\u539f\u59cb\u8f93\u51fa\u8f6c\u5316\u4e3a\u4ea4\u4e92\u5f0f\u5de5\u4f5c\u6d41\uff0c\u663e\u8457\u6539\u5584\u4e86\u7406\u89e3\u548c\u8c03\u8bd5\u4f53\u9a8c\u3002"}}
{"id": "2602.12079", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.12079", "abs": "https://arxiv.org/abs/2602.12079", "authors": ["Alessandro Aneggi", "Vincenzo Stoico", "Andrea Janes"], "title": "Performance Antipatterns: Angel or Devil for Power Consumption?", "comment": null, "summary": "Performance antipatterns are known to degrade the responsiveness of microservice-based systems, but their impact on energy consumption remains largely unexplored. This paper empirically investigates whether widely studied performance antipatterns defined by Smith and Williams also negatively influence power usage. We implement ten antipatterns as isolated microservices and evaluate them under controlled load conditions, collecting synchronized measurements of performance, CPU and DRAM power consumption, and resource utilization across 30 repeated runs per antipattern. The results show that while all antipatterns degrade performance as expected, only a subset exhibit a statistically significant relationship between response time and increased power consumption. Specifically, several antipatterns reach CPU saturation, capping power draw regardless of rising response time, whereas others (\\eg Unnecessary Processing, The Ramp) demonstrate energy-performance coupling indicative of inefficiency. Our results show that, while all injected performance antipatterns increase response time as expected, only a subset also behaves as clear energy antipatterns, with several cases reaching a nearly constant CPU power level where additional slowdowns mainly translate into longer execution time rather than higher instantaneous power consumption. The study provides a systematic foundation for identifying performance antipatterns that also behave as energy antipatterns and offers actionable insights for designing more energy-efficient microservices architectures.", "AI": {"tldr": "\u7814\u7a76\u9a8c\u8bc1\u4e86\u6027\u80fd\u53cd\u6a21\u5f0f\u4e0d\u4ec5\u964d\u4f4e\u5fae\u670d\u52a1\u54cd\u5e94\u901f\u5ea6\uff0c\u90e8\u5206\u8fd8\u4f1a\u663e\u8457\u589e\u52a0\u80fd\u8017\uff0c\u4f46\u5e76\u975e\u6240\u6709\u6027\u80fd\u95ee\u9898\u90fd\u8f6c\u5316\u4e3a\u80fd\u8017\u95ee\u9898", "motivation": "\u867d\u7136\u5df2\u77e5\u6027\u80fd\u53cd\u6a21\u5f0f\u4f1a\u964d\u4f4e\u5fae\u670d\u52a1\u7cfb\u7edf\u54cd\u5e94\u6027\uff0c\u4f46\u5b83\u4eec\u5bf9\u80fd\u8017\u7684\u5f71\u54cd\u5c1a\u672a\u5145\u5206\u7814\u7a76\u3002\u672c\u6587\u65e8\u5728\u5b9e\u8bc1\u63a2\u7a76Smith\u548cWilliams\u5b9a\u4e49\u7684\u6027\u80fd\u53cd\u6a21\u5f0f\u662f\u5426\u4e5f\u4f1a\u5bf9\u80fd\u8017\u4ea7\u751f\u8d1f\u9762\u5f71\u54cd", "method": "\u5c0610\u79cd\u53cd\u6a21\u5f0f\u5b9e\u73b0\u4e3a\u72ec\u7acb\u5fae\u670d\u52a1\uff0c\u5728\u53d7\u63a7\u8d1f\u8f7d\u6761\u4ef6\u4e0b\u8bc4\u4f30\uff0c\u6536\u96c6\u6027\u80fd\u3001CPU\u548cDRAM\u529f\u8017\u3001\u8d44\u6e90\u5229\u7528\u7387\u7b49\u540c\u6b65\u6d4b\u91cf\u6570\u636e\uff0c\u6bcf\u79cd\u53cd\u6a21\u5f0f\u8fdb\u884c30\u6b21\u91cd\u590d\u8fd0\u884c", "result": "\u6240\u6709\u53cd\u6a21\u5f0f\u90fd\u5982\u9884\u671f\u964d\u4f4e\u4e86\u6027\u80fd\uff0c\u4f46\u53ea\u6709\u90e8\u5206\u53cd\u6a21\u5f0f\u5728\u54cd\u5e94\u65f6\u95f4\u548c\u529f\u8017\u589e\u52a0\u4e4b\u95f4\u8868\u73b0\u51fa\u7edf\u8ba1\u5b66\u663e\u8457\u5173\u7cfb\u3002\u4e00\u4e9b\u53cd\u6a21\u5f0f\u8fbe\u5230CPU\u9971\u548c\uff0c\u9650\u5236\u4e86\u529f\u8017\u589e\u957f\uff1b\u800c\u53e6\u4e00\u4e9b\u53cd\u6a21\u5f0f\uff08\u5982\u4e0d\u5fc5\u8981\u5904\u7406\u3001The Ramp\uff09\u663e\u793a\u51fa\u80fd\u6548-\u6027\u80fd\u8026\u5408\u7684\u4f4e\u6548\u7279\u5f81", "conclusion": "\u867d\u7136\u6240\u6709\u6ce8\u5165\u7684\u6027\u80fd\u53cd\u6a21\u5f0f\u90fd\u4f1a\u589e\u52a0\u54cd\u5e94\u65f6\u95f4\uff0c\u4f46\u53ea\u6709\u90e8\u5206\u540c\u65f6\u8868\u73b0\u4e3a\u660e\u663e\u7684\u80fd\u8017\u53cd\u6a21\u5f0f\u3002\u7814\u7a76\u4e3a\u8bc6\u522b\u65e2\u662f\u6027\u80fd\u95ee\u9898\u53c8\u662f\u80fd\u8017\u95ee\u9898\u7684\u53cd\u6a21\u5f0f\u63d0\u4f9b\u4e86\u7cfb\u7edf\u57fa\u7840\uff0c\u5e76\u4e3a\u8bbe\u8ba1\u66f4\u8282\u80fd\u7684\u5fae\u670d\u52a1\u67b6\u6784\u63d0\u4f9b\u4e86\u53ef\u64cd\u4f5c\u7684\u89c1\u89e3"}}
{"id": "2602.12081", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.12081", "abs": "https://arxiv.org/abs/2602.12081", "authors": ["Alessandro Aneggi", "Xiaozhou Li", "Andrea Janes"], "title": "PPTAM$\u03b7$: Energy Aware CI/CD Pipeline for Container Based Applications", "comment": null, "summary": "Modern container-based microservices evolve through rapid deployment cycles, but CI/CD pipelines still rarely measure energy consumption, even though prior work shows that design patterns, code smells and refactorings affect energy efficiency. We present PPTAM$\u03b7$, an automated pipeline that integrates power and energy measurement into GitLab CI for containerised API systems, coordinating load generation, container monitoring and hardware power probes to collect comparable metrics at each commit. The pipeline makes energy visible to developers, supports version comparison for test engineers and enables trend analysis for researchers. We evaluate PPTAM$\u03b7$ on a JWT-authenticated API across four commits, collecting performance and energy metrics and summarising the architecture, measurement methodology and validation.", "AI": {"tldr": "PPTAM\u03b7\uff1a\u81ea\u52a8\u5316\u6d41\u6c34\u7ebf\uff0c\u96c6\u6210\u80fd\u8017\u6d4b\u91cf\u5230GitLab CI\u4e2d\uff0c\u7528\u4e8e\u5bb9\u5668\u5316API\u7cfb\u7edf\uff0c\u534f\u8c03\u8d1f\u8f7d\u751f\u6210\u3001\u5bb9\u5668\u76d1\u63a7\u548c\u786c\u4ef6\u529f\u7387\u63a2\u9488\uff0c\u5728\u6bcf\u4e2a\u63d0\u4ea4\u6536\u96c6\u53ef\u6bd4\u8f83\u7684\u6307\u6807\u3002", "motivation": "\u73b0\u4ee3\u57fa\u4e8e\u5bb9\u5668\u7684\u5fae\u670d\u52a1\u901a\u8fc7\u5feb\u901f\u90e8\u7f72\u5468\u671f\u6f14\u8fdb\uff0c\u4f46CI/CD\u6d41\u6c34\u7ebf\u5f88\u5c11\u6d4b\u91cf\u80fd\u8017\uff0c\u5c3d\u7ba1\u5148\u524d\u5de5\u4f5c\u8868\u660e\u8bbe\u8ba1\u6a21\u5f0f\u3001\u4ee3\u7801\u5f02\u5473\u548c\u91cd\u6784\u4f1a\u5f71\u54cd\u80fd\u6e90\u6548\u7387\u3002\u9700\u8981\u4f7f\u80fd\u8017\u5bf9\u5f00\u53d1\u8005\u53ef\u89c1\u3002", "method": "PPTAM\u03b7\u81ea\u52a8\u5316\u6d41\u6c34\u7ebf\u96c6\u6210\u529f\u7387\u548c\u80fd\u8017\u6d4b\u91cf\u5230GitLab CI\u4e2d\uff0c\u534f\u8c03\u8d1f\u8f7d\u751f\u6210\u3001\u5bb9\u5668\u76d1\u63a7\u548c\u786c\u4ef6\u529f\u7387\u63a2\u9488\uff0c\u4e3a\u6bcf\u4e2a\u63d0\u4ea4\u6536\u96c6\u53ef\u6bd4\u8f83\u7684\u6307\u6807\u3002\u652f\u6301\u5f00\u53d1\u8005\u67e5\u770b\u80fd\u8017\u3001\u6d4b\u8bd5\u5de5\u7a0b\u5e08\u8fdb\u884c\u7248\u672c\u6bd4\u8f83\u3001\u7814\u7a76\u4eba\u5458\u8fdb\u884c\u8d8b\u52bf\u5206\u6790\u3002", "result": "\u5728JWT\u8ba4\u8bc1\u7684API\u4e0a\u8bc4\u4f30PPTAM\u03b7\uff0c\u8de8\u8d8a\u56db\u4e2a\u63d0\u4ea4\u6536\u96c6\u6027\u80fd\u548c\u80fd\u8017\u6307\u6807\uff0c\u603b\u7ed3\u67b6\u6784\u3001\u6d4b\u91cf\u65b9\u6cd5\u548c\u9a8c\u8bc1\u3002", "conclusion": "PPTAM\u03b7\u4f7f\u80fd\u8017\u5728CI/CD\u6d41\u6c34\u7ebf\u4e2d\u53ef\u89c1\uff0c\u652f\u6301\u7248\u672c\u6bd4\u8f83\u548c\u8d8b\u52bf\u5206\u6790\uff0c\u6709\u52a9\u4e8e\u63d0\u9ad8\u5bb9\u5668\u5316API\u7cfb\u7edf\u7684\u80fd\u6e90\u6548\u7387\u610f\u8bc6\u3002"}}
{"id": "2602.12144", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.12144", "abs": "https://arxiv.org/abs/2602.12144", "authors": ["Muhammad Ahmad Khan", "Hasnain Ali", "Muneeb Rana", "Muhammad Saqib Ilyas", "Abdul Ali Bangash"], "title": "On the Adoption of AI Coding Agents in Open-source Android and iOS Development", "comment": "Accepted at MSR 2026 Mining Challenge track", "summary": "AI coding agents are increasingly contributing to software development, yet their impact on mobile development has received little empirical attention. In this paper, we present the first category-level empirical study of agent-generated code in open-source mobile app projects. We analyzed PR acceptance behaviors across mobile platforms, agents, and task categories using 2,901 AI-authored pull requests (PRs) in 193 verified Android and iOS open-source GitHub repositories in the AIDev dataset. We find that Android projects have received 2x more AI-authored PRs and have achieved higher PR acceptance rate (71%) than iOS (63%), with significant agent-level variation on Android. Across task categories, PRs with routine tasks (feature, fix, and ui) achieve the highest acceptance, while structural changes like refactor and build achieve lower success and longer resolution times. Furthermore, our evolution analysis shows improvement in PR resolution time on Android through mid-2025 before it declined again. Our findings offer the first evidence-based characterization of AI agents effects on OSS mobile projects and establish empirical baselines for evaluating agent-generated contributions to design platform aware agentic systems.", "AI": {"tldr": "\u9996\u7bc7\u9488\u5bf9\u5f00\u6e90\u79fb\u52a8\u9879\u76ee\u4e2dAI\u4ee3\u7406\u751f\u6210\u4ee3\u7801\u7684\u7c7b\u522b\u7ea7\u5b9e\u8bc1\u7814\u7a76\uff0c\u5206\u6790Android\u548ciOS\u9879\u76ee\u4e2d2,901\u4e2aAI\u7f16\u5199\u7684PR\u63a5\u53d7\u884c\u4e3a\uff0c\u53d1\u73b0Android\u9879\u76ee\u63a5\u53d7\u66f4\u591aAI PR\u4e14\u63a5\u53d7\u7387\u66f4\u9ad8\uff0c\u4e0d\u540c\u4efb\u52a1\u7c7b\u522b\u63a5\u53d7\u7387\u5dee\u5f02\u663e\u8457\u3002", "motivation": "AI\u7f16\u7801\u4ee3\u7406\u5728\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u65e5\u76ca\u91cd\u8981\uff0c\u4f46\u5176\u5bf9\u79fb\u52a8\u5f00\u53d1\u7684\u5f71\u54cd\u7f3a\u4e4f\u5b9e\u8bc1\u7814\u7a76\u3002\u9700\u8981\u4e86\u89e3AI\u4ee3\u7406\u5728\u4e0d\u540c\u79fb\u52a8\u5e73\u53f0\u3001\u4e0d\u540c\u4efb\u52a1\u7c7b\u522b\u4e2d\u7684\u4ee3\u7801\u8d21\u732e\u63a5\u53d7\u60c5\u51b5\uff0c\u4e3a\u8bbe\u8ba1\u5e73\u53f0\u611f\u77e5\u7684\u4ee3\u7406\u7cfb\u7edf\u63d0\u4f9b\u4f9d\u636e\u3002", "method": "\u4f7f\u7528AIDev\u6570\u636e\u96c6\u4e2d\u76842,901\u4e2aAI\u7f16\u5199\u7684pull requests\uff0c\u5206\u6790193\u4e2a\u5df2\u9a8c\u8bc1\u7684Android\u548ciOS\u5f00\u6e90GitHub\u4ed3\u5e93\u3002\u7814\u7a76\u8de8\u79fb\u52a8\u5e73\u53f0\u3001AI\u4ee3\u7406\u548c\u4efb\u52a1\u7c7b\u522b\u7684PR\u63a5\u53d7\u884c\u4e3a\uff0c\u5305\u62ec\u63a5\u53d7\u7387\u3001\u89e3\u51b3\u65f6\u95f4\u7b49\u6307\u6807\uff0c\u5e76\u8fdb\u884c\u6f14\u5316\u5206\u6790\u3002", "result": "Android\u9879\u76ee\u63a5\u6536\u7684AI PR\u6570\u91cf\u662fiOS\u76842\u500d\uff0c\u4e14\u63a5\u53d7\u7387\u66f4\u9ad8\uff0871% vs 63%\uff09\u3002\u5e38\u89c4\u4efb\u52a1\uff08\u529f\u80fd\u3001\u4fee\u590d\u3001UI\uff09PR\u63a5\u53d7\u7387\u6700\u9ad8\uff0c\u91cd\u6784\u548c\u6784\u5efa\u7b49\u7ed3\u6784\u6027\u53d8\u66f4\u63a5\u53d7\u7387\u8f83\u4f4e\u4e14\u89e3\u51b3\u65f6\u95f4\u66f4\u957f\u3002Android\u9879\u76ee\u7684PR\u89e3\u51b3\u65f6\u95f4\u57282025\u5e74\u4e2d\u524d\u6709\u6240\u6539\u5584\u3002", "conclusion": "\u8fd9\u662f\u9996\u4e2a\u57fa\u4e8e\u8bc1\u636e\u7684AI\u4ee3\u7406\u5bf9\u5f00\u6e90\u79fb\u52a8\u9879\u76ee\u5f71\u54cd\u7684\u7279\u5f81\u63cf\u8ff0\uff0c\u4e3a\u8bc4\u4f30\u4ee3\u7406\u751f\u6210\u4ee3\u7801\u8d21\u732e\u5efa\u7acb\u4e86\u5b9e\u8bc1\u57fa\u51c6\u3002\u7814\u7a76\u7ed3\u679c\u4e3a\u8bbe\u8ba1\u5e73\u53f0\u611f\u77e5\u7684\u4ee3\u7406\u7cfb\u7edf\u63d0\u4f9b\u4e86\u91cd\u8981\u53c2\u8003\uff0c\u8868\u660e\u5e73\u53f0\u5dee\u5f02\u548c\u4efb\u52a1\u7c7b\u578b\u663e\u8457\u5f71\u54cdAI\u4ee3\u7801\u8d21\u732e\u7684\u63a5\u53d7\u5ea6\u3002"}}
{"id": "2602.12256", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.12256", "abs": "https://arxiv.org/abs/2602.12256", "authors": ["Alex Chudic", "G\u00fcl \u00c7al\u0131kl\u0131"], "title": "Automated Test Suite Enhancement Using Large Language Models with Few-shot Prompting", "comment": "13 pages, 3 figures, accepted to ICPC 2026 (34th International Conference on Program Comprehension)", "summary": "Unit testing is essential for verifying the functional correctness of code modules (e.g., classes, methods), but manually writing unit tests is often labor-intensive and time-consuming. Unit tests generated by tools that employ traditional approaches, such as search-based software testing (SBST), lack readability, naturalness, and practical usability. LLMs have recently provided promising results and become integral to developers' daily practices. Consequently, software repositories now include a mix of human-written tests, LLM-generated tests, and those from tools employing traditional approaches such as SBST. While LLMs' zero-shot capabilities have been widely studied, their few-shot learning potential for unit test generation remains underexplored. Few-shot prompting enables LLMs to learn from examples in the prompt, and automatically retrieving such examples could enhance test suites. This paper empirically investigates how few-shot prompting with different test artifact sources, comprising human, SBST, or LLM, affects the quality of LLM-generated unit tests as program comprehension artifacts and their contribution to improving existing test suites by evaluating not only correctness and coverage but also readability, cognitive complexity, and maintainability in hybrid human-AI codebases. We conducted experiments on HumanEval and ClassEval datasets using GPT-4o, which is integrated into GitHub Copilot and widely used among developers. We also assessed retrieval-based methods for selecting relevant examples. Our results show that LLMs can generate high-quality tests via few-shot prompting, with human-written examples producing the best coverage and correctness. Additionally, selecting examples based on the combined similarity of problem description and code consistently yields the most effective few-shot prompts.", "AI": {"tldr": "\u672c\u6587\u5b9e\u8bc1\u7814\u7a76\u4e0d\u540c\u6d4b\u8bd5\u6837\u4f8b\u6765\u6e90\uff08\u4eba\u5de5\u3001SBST\u3001LLM\uff09\u5bf9LLM\u751f\u6210\u5355\u5143\u6d4b\u8bd5\u8d28\u91cf\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u4eba\u5de5\u7f16\u5199\u7684\u6837\u4f8b\u80fd\u4ea7\u751f\u6700\u4f73\u8986\u76d6\u7387\u548c\u6b63\u786e\u6027\uff0c\u4e14\u57fa\u4e8e\u95ee\u9898\u63cf\u8ff0\u548c\u4ee3\u7801\u76f8\u4f3c\u6027\u9009\u62e9\u6837\u4f8b\u6548\u679c\u6700\u597d\u3002", "motivation": "\u5355\u5143\u6d4b\u8bd5\u5bf9\u4ee3\u7801\u529f\u80fd\u9a8c\u8bc1\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u624b\u52a8\u7f16\u5199\u8017\u65f6\u8d39\u529b\u3002\u4f20\u7edf\u5de5\u5177\uff08\u5982SBST\uff09\u751f\u6210\u7684\u6d4b\u8bd5\u7f3a\u4e4f\u53ef\u8bfb\u6027\u548c\u5b9e\u7528\u6027\uff0c\u800cLLM\u5728\u96f6\u6837\u672c\u6d4b\u8bd5\u751f\u6210\u65b9\u9762\u5df2\u6709\u7814\u7a76\uff0c\u4f46\u5176\u5c11\u6837\u672c\u5b66\u4e60\u6f5c\u529b\u5c1a\u672a\u5145\u5206\u63a2\u7d22\u3002\u5f53\u524d\u4ee3\u7801\u5e93\u4e2d\u6df7\u5408\u4e86\u4eba\u5de5\u3001LLM\u548c\u4f20\u7edf\u5de5\u5177\u751f\u6210\u7684\u6d4b\u8bd5\uff0c\u9700\u8981\u8bc4\u4f30\u4e0d\u540c\u6765\u6e90\u6837\u4f8b\u5bf9LLM\u751f\u6210\u6d4b\u8bd5\u8d28\u91cf\u7684\u5f71\u54cd\u3002", "method": "\u4f7f\u7528GPT-4o\u5728HumanEval\u548cClassEval\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5b9e\u9a8c\uff0c\u7814\u7a76\u4e0d\u540c\u6d4b\u8bd5\u6837\u4f8b\u6765\u6e90\uff08\u4eba\u5de5\u3001SBST\u3001LLM\uff09\u5bf9\u5c11\u6837\u672c\u63d0\u793a\u6548\u679c\u7684\u5f71\u54cd\u3002\u8bc4\u4f30\u57fa\u4e8e\u68c0\u7d22\u7684\u65b9\u6cd5\u9009\u62e9\u76f8\u5173\u6837\u4f8b\uff0c\u5305\u62ec\u57fa\u4e8e\u95ee\u9898\u63cf\u8ff0\u548c\u4ee3\u7801\u76f8\u4f3c\u6027\u7684\u7ec4\u5408\u65b9\u6cd5\u3002\u4e0d\u4ec5\u8bc4\u4f30\u6b63\u786e\u6027\u548c\u8986\u76d6\u7387\uff0c\u8fd8\u8bc4\u4f30\u53ef\u8bfb\u6027\u3001\u8ba4\u77e5\u590d\u6742\u5ea6\u548c\u53ef\u7ef4\u62a4\u6027\u3002", "result": "LLM\u901a\u8fc7\u5c11\u6837\u672c\u63d0\u793a\u80fd\u751f\u6210\u9ad8\u8d28\u91cf\u6d4b\u8bd5\uff0c\u5176\u4e2d\u4eba\u5de5\u7f16\u5199\u7684\u6837\u4f8b\u4ea7\u751f\u6700\u4f73\u8986\u76d6\u7387\u548c\u6b63\u786e\u6027\u3002\u57fa\u4e8e\u95ee\u9898\u63cf\u8ff0\u548c\u4ee3\u7801\u76f8\u4f3c\u6027\u7ec4\u5408\u9009\u62e9\u6837\u4f8b\u7684\u65b9\u6cd5\u80fd\u6301\u7eed\u4ea7\u751f\u6700\u6709\u6548\u7684\u5c11\u6837\u672c\u63d0\u793a\u3002\u6d4b\u8bd5\u8d28\u91cf\u8bc4\u4f30\u5305\u62ec\u591a\u4e2a\u7ef4\u5ea6\uff1a\u6b63\u786e\u6027\u3001\u8986\u76d6\u7387\u3001\u53ef\u8bfb\u6027\u3001\u8ba4\u77e5\u590d\u6742\u5ea6\u548c\u53ef\u7ef4\u62a4\u6027\u3002", "conclusion": "\u5c11\u6837\u672c\u63d0\u793a\u80fd\u6709\u6548\u63d0\u5347LLM\u751f\u6210\u5355\u5143\u6d4b\u8bd5\u7684\u8d28\u91cf\uff0c\u4eba\u5de5\u7f16\u5199\u7684\u6837\u4f8b\u662f\u6700\u4f73\u6765\u6e90\u3002\u57fa\u4e8e\u95ee\u9898\u63cf\u8ff0\u548c\u4ee3\u7801\u76f8\u4f3c\u6027\u9009\u62e9\u6837\u4f8b\u7684\u68c0\u7d22\u65b9\u6cd5\u6548\u679c\u6700\u597d\u3002\u8fd9\u5bf9\u6df7\u5408\u4eba\u673a\u4ee3\u7801\u5e93\u4e2d\u6d4b\u8bd5\u5957\u4ef6\u7684\u6539\u8fdb\u5177\u6709\u5b9e\u9645\u610f\u4e49\u3002"}}
