<div id=toc></div>

# Table of Contents

- [cs.DC](#cs.DC) [Total: 5]
- [cs.SE](#cs.SE) [Total: 16]
- [cs.DB](#cs.DB) [Total: 2]


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [1] [The SAP Cloud Infrastructure Dataset: A Reality Check of Scheduling and Placement of VMs in Cloud Computing](https://arxiv.org/abs/2510.23911)
*Arno Uhlig,Iris Braun,Matthias Wählisch*

Main category: cs.DC

TL;DR: 分析SAP云平台中虚拟机调度和放置问题，基于1800个管理程序和48000个VM的30天数据，发现资源分配存在显著优化空间，包括CPU争用、资源不平衡和过度配置等问题。


<details>
  <summary>Details</summary>
Motivation: 解决分布式环境中资源分配的基本挑战，特别是在企业级云平台中优化虚拟机调度和放置，以提高资源利用效率。

Method: 通过可观测性工具收集30天内1800个管理程序和48000个VM的细粒度时间序列遥测数据，分析企业级工作负载的资源使用情况。

Result: 发现多个次优调度情况：CPU资源争用超过40%，CPU就绪时间达220秒，计算主机严重不平衡（CPU利用率高达99%），超过80%的VM使用不到70%的分配资源。

Conclusion: 基于研究结果，提出了新型放置和调度算法的设计要求，并为优化资源分配提供指导，同时公开数据集以支持未来大规模云基础设施调度研究。

Abstract: Allocating resources in a distributed environment is a fundamental challenge.
In this paper, we analyze the scheduling and placement of virtual machines
(VMs) in the cloud platform of SAP, the world's largest enterprise resource
planning software vendor. Based on data from roughly 1,800 hypervisors and
48,000 VMs within a 30-day observation period, we highlight potential
improvements for workload management. The data was measured through
observability tooling that tracks resource usage and performance metrics across
the entire infrastructure. In contrast to existing datasets, ours uniquely
offers fine-grained time-series telemetry data of fully virtualized
enterprise-level workloads from both long-running and memory-intensive SAP
S/4HANA and diverse, general-purpose applications. Our key findings include
several suboptimal scheduling situations, such as CPU resource contention
exceeding 40%, CPU ready times of up to 220 seconds, significantly imbalanced
compute hosts with a maximum CPU~utilization on intra-building block hosts of
up to 99%, and overprovisioned CPU and memory resources resulting into over 80%
of VMs using less than 70% of the provided resources. Bolstered by these
findings, we derive requirements for the design and implementation of novel
placement and scheduling algorithms and provide guidance to optimize resource
allocations. We make the full dataset used in this study publicly available to
enable data-driven evaluations of scheduling approaches for large-scale cloud
infrastructures in future research.

</details>


### [2] [A GPU-based Compressible Combustion Solver for Applications Exhibiting Disparate Space and Time Scales](https://arxiv.org/abs/2510.23993)
*Anthony Carreon,Jagmohan Singh,Shivank Sharma,Shuzhi Zhang,Venkat Raman*

Main category: cs.DC

TL;DR: 开发了基于AMReX框架的高性能可压缩反应流求解器，针对多GPU环境优化，解决了内存访问模式、计算负载均衡和化学反应局部化等性能瓶颈，在燃烧应用中实现了2-5倍的性能提升。


<details>
  <summary>Details</summary>
Motivation: 高速化学反应流存在显著的计算挑战，由于空间和时间尺度的差异，刚性化学动力学通常主导模拟时间。现有的GPU可压缩燃烧求解器在内存管理、负载均衡和处理化学反应高度局部化方面存在关键限制。

Method: 基于AMReX框架构建多GPU优化的可压缩反应流求解器，通过列优先存储优化内存访问模式，采用批量稀疏积分策略处理化学动力学计算负载变化，并为自适应网格细化应用实现多GPU负载分配。

Result: 在氢-空气爆轰和超声速横流射流等代表性燃烧应用中，相比初始GPU实现实现了2-5倍的性能提升，在1-96个NVIDIA H100 GPU上具有接近理想的弱扩展性。屋顶线分析显示对流（约10倍）和化学（约4倍）例程的算术强度显著提高。

Conclusion: 该求解器通过针对GPU性能瓶颈的优化策略，有效利用了GPU内存带宽和计算资源，为大规模化学反应流模拟提供了高性能解决方案。

Abstract: High-speed chemically active flows present significant computational
challenges due to their disparate space and time scales, where stiff chemistry
often dominates simulation time. While modern supercomputing scientific codes
achieve exascale performance by leveraging graphics processing units (GPUs),
existing GPU-based compressible combustion solvers face critical limitations in
memory management, load balancing, and handling the highly localized nature of
chemical reactions. To this end, we present a high-performance compressible
reacting flow solver built on the AMReX framework and optimized for multi-GPU
settings. Our approach addresses three GPU performance bottlenecks: memory
access patterns through column-major storage optimization, computational
workload variability via a bulk-sparse integration strategy for chemical
kinetics, and multi-GPU load distribution for adaptive mesh refinement
applications. The solver adapts existing matrix-based chemical kinetics
formulations to multigrid contexts. Using representative combustion
applications including hydrogen-air detonations and jet in supersonic crossflow
configurations, we demonstrate $2-5\times$ performance improvements over
initial GPU implementations with near-ideal weak scaling across $1-96$ NVIDIA
H100 GPUs. Roofline analysis reveals substantial improvements in arithmetic
intensity for both convection ($\sim 10 \times$) and chemistry ($\sim 4
\times$) routines, confirming efficient utilization of GPU memory bandwidth and
computational resources.

</details>


### [3] [Towards Exascale Computing for Astrophysical Simulation Leveraging the Leonardo EuroHPC System](https://arxiv.org/abs/2510.24175)
*Nitin Shukla,Alessandro Romeo,Caterina Caravita,Michael Redenti,Radim Vavrik,Lubomir Riha,Andrea Mignone,Marco Rossazza,Stefano Truzzi,Luca Tornatore,Antonio Ragagnin,Tiago Castro,Geray S. Karademir,Klaus Dolag,Pranab J. Deka,Fabio Bacchini,Rostislav-Paul Wilhelm,Daniele Gregori,Elisabetta Boella*

Main category: cs.DC

TL;DR: SPACE中心通过协作优化三个天体物理代码在Leonardo系统上的性能，初步测试显示在1024个GPU上达到80%的扩展效率。


<details>
  <summary>Details</summary>
Motivation: 为现有和下一代加速器开发和重新设计天体物理、宇宙学和空间等离子体数值代码，以支持大规模模拟。

Method: 使用性能分析工具分析三个旗舰代码（gPLUTO、OpenGadget3和iPIC3D）在单节点和多节点上的性能表现。

Result: 所有三个代码都实现了高效扩展，在1024个GPU上达到80%的可扩展性。

Conclusion: SPACE中心的协作策略成功优化了天体物理代码在exascale时代的性能表现。

Abstract: Developing and redesigning astrophysical, cosmological, and space plasma
numerical codes for existing and next-generation accelerators is critical for
enabling large-scale simulations. To address these challenges, the SPACE Center
of Excellence (SPACE-CoE) fosters collaboration between scientists, code
developers, and high-performance computing experts to optimize applications for
the exascale era. This paper presents our strategy and initial results on the
Leonardo system at CINECA for three flagship codes, namely gPLUTO, OpenGadget3
and iPIC3D, using profiling tools to analyze performance on single and multiple
nodes. Preliminary tests show all three codes scale efficiently, reaching 80%
scalability up to 1,024 GPUs.

</details>


### [4] [CoMPSeT: A Framework for Comparing Multiparty Session Types](https://arxiv.org/abs/2510.24205)
*Telmo Ribeiro,José Proença,Mário Florido*

Main category: cs.DC

TL;DR: 提出了CoMPSeT工具，用于比较和分析多会话类型(MPST)的不同特性，帮助研究人员和教师更好地理解全局编排协议


<details>
  <summary>Details</summary>
Motivation: 并发系统设计复杂，现有的MPST变种各有特定功能和特性，需要一个工具来提供对不同MPST特性的清晰洞察

Method: 选择代表性MPST示例集，提供机制来组合不同特性，并动画化和比较具体示例的语义

Result: 开发了开源的CoMPSeT工具，编译为JavaScript，可直接在浏览器中执行

Conclusion: CoMPSeT对想要更好理解MPST领域的研究人员和想要解释全局编排的教师都很有用

Abstract: Concurrent systems are often complex and difficult to design. Choreographic
languages, such as Multiparty Session Types (MPST), allow the description of
global protocols of interactions by capturing valid patterns of interactions
between participants. Many variations of MPST exist, each one with its rather
specific features and idiosyncrasies. Here we propose a tool (CoMPSeT) that
provides clearer insights over different features in existing MPST. We select a
representative set of MPST examples and provide mechanisms to combine different
features and to animate and compare the semantics of concrete examples. CoMPSeT
is open-source, compiled into JavaScript, and can be directly executed from any
browser, becoming useful both for researchers who want to better understand the
landscape of MPST and for teachers who want to explain global choreographies.

</details>


### [5] [ARIMA_PLUS: Large-scale, Accurate, Automatic and Interpretable In-Database Time Series Forecasting and Anomaly Detection in Google BigQuery](https://arxiv.org/abs/2510.24452)
*Xi Cheng,Weijie Shen,Haoming Chen,Chaoyi Shen,Jean Ortega,Jiashang Liu,Steve Thomas,Honglin Zheng,Haoyun Wu,Yuxiang Li,Casey Lichtendahl,Jenny Ortiz,Gang Liu,Haiyang Qi,Omid Fatemieh,Chris Fry,Jing Jing Long*

Main category: cs.DC

TL;DR: ARIMA_PLUS是一个新颖的时间序列预测和异常检测框架，结合了准确可解释的模型和可扩展的云基础设施，在42个公共数据集上表现出优于统计方法和神经网络模型的性能。


<details>
  <summary>Details</summary>
Motivation: 解决大规模时间序列自动预测和异常检测的效率问题，同时确保结果的可解释性以融入业务洞察。

Method: 采用顺序模块化结构处理时间序列的不同组件（节假日效应、季节性、趋势、异常），每个模块都有增强改进，并建立统一框架同时处理预测和异常检测任务。

Result: 在Monash预测库的42个公共数据集上，ARIMA_PLUS不仅优于传统统计方法（ETS、ARIMA、TBATS、Prophet），也优于新的神经网络模型（DeepAR、N-BEATS、PatchTST、TimeMixer）。在基础设施方面，能够以每秒18000个时间序列的吞吐量，在1.5小时内预测1亿个时间序列。

Conclusion: ARIMA_PLUS通过结合准确可解释的模型和可扩展的云基础设施，成功解决了大规模时间序列预测和异常检测的效率和可解释性挑战。

Abstract: Time series forecasting and anomaly detection are common tasks for
practitioners in industries such as retail, manufacturing, advertising and
energy. Two unique challenges stand out: (1) efficiently and accurately
forecasting time series or detecting anomalies in large volumes automatically;
and (2) ensuring interpretability of results to effectively incorporate
business insights. We present ARIMA_PLUS, a novel framework to overcome these
two challenges by a unique combination of (a) accurate and interpretable time
series models and (b) scalable and fully managed system infrastructure. The
model has a sequential and modular structure to handle different components of
the time series, including holiday effects, seasonality, trend, and anomalies,
which enables high interpretability of the results. Novel enhancements are made
to each module, and a unified framework is established to address both
forecasting and anomaly detection tasks simultaneously. In terms of accuracy,
its comprehensive benchmark on the 42 public datasets in the Monash forecasting
repository shows superior performance over not only well-established
statistical alternatives (such as ETS, ARIMA, TBATS, Prophet) but also newer
neural network models (such as DeepAR, N-BEATS, PatchTST, TimeMixer). In terms
of infrastructure, it is directly built into the query engine of BigQuery in
Google Cloud. It uses a simple SQL interface and automates tedious
technicalities such as data cleaning and model selection. It automatically
scales with managed cloud computational and storage resources, making it
possible to forecast 100 million time series using only 1.5 hours with a
throughput of more than 18000 time series per second. In terms of
interpretability, we present several case studies to demonstrate time series
insights it generates and customizability it offers.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [6] [AI-Driven Development of a Publishing Imprint: Xynapse Traces](https://arxiv.org/abs/2510.23627)
*Fred Zimmerman*

Main category: cs.SE

TL;DR: Xynapse Traces是一个实验性出版品牌，通过人机融合方法实现出版流程自动化，将上市时间从6-12个月缩短至2-4周，成本降低80%，第一年出版52本书，质量指标优异。


<details>
  <summary>Details</summary>
Motivation: 探索人机协作的新出版模式，通过算法和人类方法的融合来提升出版效率，降低成本和门槛，使小众市场变得可行。

Method: 采用配置驱动架构和多模型AI集成框架，包括持续创意流水线、锦标赛式评估、转录冥想实践的创新代码设计、从创意到生产和分发的全面自动化，以及定义品牌使命的出版者角色。

Result: 实现了90%的上市时间缩减（从6-12个月到2-4周），80%的成本降低，第一年出版52本书，99%的引用准确率和100%的验证成功率。

Conclusion: 该系统为图书出版业的未来提供了新范式，展示了人机协作如何使复杂出版能力民主化，并使之前不可行的小众市场变得可及。

Abstract: Xynapse Traces is an experimental publishing imprint created via a fusion of
human and algorithmic methods using a configuration-driven architecture and a
multi-model AI integration framework. The system achieved a remarkable 90%
reduction in time-to-market (from a typical 6-12 months to just 2-4 weeks),
with 80% cost reduction compared to traditional imprint development, while
publishing 52 books in its first year and maintaining exceptional quality
metrics, including 99% citation accuracy and 100% validation success after
initial corrections. Key technical innovations include a continuous ideation
pipeline with tournament-style evaluation, a novel codex design for
transcriptive meditation practice, comprehensive automation spanning from
ideation through production and distribution, and publisher personas that
define and guide the imprint's mission. The system also integrates automated
verification with human oversight, ensuring that gains in speed do not
compromise publishing standards. This effort has significant implications for
the future of book publishing, suggesting new paradigms for human-AI
collaboration that democratize access to sophisticated publishing capabilities
and make previously unviable niche markets accessible.

</details>


### [7] [VisCoder2: Building Multi-Language Visualization Coding Agents](https://arxiv.org/abs/2510.23642)
*Yuansheng Ni,Songcheng Cai,Xiangchao Chen,Jiarong Liang,Zhiheng Lyu,Jiaqi Deng,Kai Zou,Ping Nie,Fei Yuan,Xiang Yue,Wenhu Chen*

Main category: cs.SE

TL;DR: 提出了VisCode-Multi-679K数据集、VisPlotBench基准和VisCoder2模型系列，显著提升了多语言可视化代码生成和调试能力。


<details>
  <summary>Details</summary>
Motivation: 现有LLM在可视化代码生成中存在语言覆盖有限、执行不可靠、缺乏迭代修正机制等问题，且受限于窄数据集和基准测试。

Method: 构建包含679K验证样本的多语言数据集VisCode-Multi-679K，创建VisPlotBench评估基准，并训练VisCoder2多语言可视化模型。

Result: VisCoder2显著优于开源基线，接近GPT-4.1性能，通过迭代自调试在32B规模达到82.4%整体执行通过率。

Conclusion: 提出的资源和方法有效解决了多语言可视化代码生成的关键挑战，为开发更可靠的可视化编码代理奠定了基础。

Abstract: Large language models (LLMs) have recently enabled coding agents capable of
generating, executing, and revising visualization code. However, existing
models often fail in practical workflows due to limited language coverage,
unreliable execution, and lack of iterative correction mechanisms. Progress has
been constrained by narrow datasets and benchmarks that emphasize single-round
generation and single-language tasks. To address these challenges, we introduce
three complementary resources for advancing visualization coding agents.
VisCode-Multi-679K is a large-scale, supervised dataset containing 679K
validated and executable visualization samples with multi-turn correction
dialogues across 12 programming languages. VisPlotBench is a benchmark for
systematic evaluation, featuring executable tasks, rendered outputs, and
protocols for both initial generation and multi-round self-debug. Finally, we
present VisCoder2, a family of multi-language visualization models trained on
VisCode-Multi-679K. Experiments show that VisCoder2 significantly outperforms
strong open-source baselines and approaches the performance of proprietary
models like GPT-4.1, with further gains from iterative self-debug, reaching
82.4% overall execution pass rate at the 32B scale, particularly in symbolic or
compiler-dependent languages.

</details>


### [8] [Agentsway -- Software Development Methodology for AI Agents-based Teams](https://arxiv.org/abs/2510.23664)
*Eranga Bandara,Ross Gore,Xueping Liang,Sachini Rajapakse,Isurunima Kularathne,Pramoda Karunarathna,Peter Foytik,Sachin Shetty,Ravi Mukkamala,Abdul Rahman,Amin Hass,Ng Wee Keong,Kasun De Zoysa,Aruna Withanage,Nilaan Loganathan*

Main category: cs.SE

TL;DR: 提出了Agentsway框架，这是首个专门为AI代理协作的软件开发方法论，通过定义不同角色的AI代理和人类编排，解决传统方法在AI代理环境中的不足。


<details>
  <summary>Details</summary>
Motivation: 传统软件开发方法（如Agile、Kanban等）是为人类团队设计的，在AI代理参与规划、编码、测试和持续学习的环境中越来越不适用，需要专门的方法论来解决这一方法学差距。

Method: Agentsway框架围绕人类编排和隐私保护协作构建，定义了规划、提示、编码、测试和微调等不同角色的专门AI代理，通过集成微调LLM和高级推理模型实现迭代改进和自适应学习。

Result: 该框架增强了领域特定推理和可解释决策，通过协调使用多个微调LLM嵌入负责任AI原则，确保平衡、透明和可问责的决策制定。

Conclusion: Agentsway通过形式化代理中心协作、集成隐私设计原则和定义可衡量指标，推动了软件工程的发展，代表了迈向AI原生、自我改进软件开发方法论的基础性步骤。

Abstract: The emergence of Agentic AI is fundamentally transforming how software is
designed, developed, and maintained. Traditional software development
methodologies such as Agile, Kanban, ShapeUp, etc, were originally designed for
human-centric teams and are increasingly inadequate in environments where
autonomous AI agents contribute to planning, coding, testing, and continuous
learning. To address this methodological gap, we present "Agentsway" a novel
software development framework designed for ecosystems where AI agents operate
as first-class collaborators. Agentsway introduces a structured lifecycle
centered on human orchestration, and privacy-preserving collaboration among
specialized AI agents. The framework defines distinct roles for planning,
prompting, coding, testing, and fine-tuning agents, each contributing to
iterative improvement and adaptive learning throughout the development process.
By integrating fine-tuned LLMs that leverage outputs and feedback from
different agents throughout the development cycle as part of a retrospective
learning process, Agentsway enhances domain-specific reasoning, and explainable
decision-making across the entire software development lifecycle. Responsible
AI principles are further embedded across the agents through the coordinated
use of multiple fine-tuned LLMs and advanced reasoning models, ensuring
balanced, transparent, and accountable decision-making. This work advances
software engineering by formalizing agent-centric collaboration, integrating
privacy-by-design principles, and defining measurable metrics for productivity
and trust. Agentsway represents a foundational step toward the next generation
of AI-native, self-improving software development methodologies. To the best of
our knowledge, this is the first research effort to introduce a dedicated
methodology explicitly designed for AI agent-based software engineering teams.

</details>


### [9] [RefleXGen:The unexamined code is not worth using](https://arxiv.org/abs/2510.23674)
*Bin Wang,Hui Li,AoFan Liu,BoTao Yang,Ao Yang,YiLu Zhong,Weixiang Huang,Yanping Zhang,Runhuai Huang,Weimin Zeng*

Main category: cs.SE

TL;DR: RefleXGen通过结合检索增强生成(RAG)和LLM自反思机制，无需大量资源即可显著提升代码生成安全性，在多个模型上实现4.5%-13.6%的安全改进。


<details>
  <summary>Details</summary>
Motivation: 代码生成中的安全问题是应用大语言模型的关键挑战，传统方法如微调模型或构建专用安全代码数据集需要大量资源，需要更高效的安全增强方案。

Method: RefleXGen方法整合检索增强生成(RAG)技术与LLM的引导自反思机制，通过自我评估和反思迭代优化代码生成过程，无需大量资源投入。

Result: 实验结果显示RefleXGen显著提升多个模型的代码安全性：GPT-3.5 Turbo提升13.6%，GPT-4o提升6.7%，CodeQwen提升4.5%，Gemini提升5.8%。

Conclusion: 提高模型自反思质量是增强AI生成代码安全性的有效实用策略，RefleXGen为代码安全提供了资源高效的新途径。

Abstract: Security in code generation remains a pivotal challenge when applying large
language models (LLMs). This paper introduces RefleXGen, an innovative method
that significantly enhances code security by integrating Retrieval-Augmented
Generation (RAG) techniques with guided self-reflection mechanisms inherent in
LLMs. Unlike traditional approaches that rely on fine-tuning LLMs or developing
specialized secure code datasets - processes that can be resource-intensive -
RefleXGen iteratively optimizes the code generation process through
self-assessment and reflection without the need for extensive resources. Within
this framework, the model continuously accumulates and refines its knowledge
base, thereby progressively improving the security of the generated code.
Experimental results demonstrate that RefleXGen substantially enhances code
security across multiple models, achieving a 13.6% improvement with GPT-3.5
Turbo, a 6.7% improvement with GPT-4o, a 4.5% improvement with CodeQwen, and a
5.8% improvement with Gemini. Our findings highlight that improving the quality
of model self-reflection constitutes an effective and practical strategy for
strengthening the security of AI-generated code.

</details>


### [10] [TDFlow: Agentic Workflows for Test Driven Software Engineering](https://arxiv.org/abs/2510.23761)
*Kevin Han,Siddharth Maddikayala,Tim Knappe,Om Patel,Austen Liao,Amir Barati Farimani*

Main category: cs.SE

TL;DR: TDFlow是一个基于测试驱动的智能工作流，将仓库级软件工程重构为测试解决任务，通过分解为四个专门子代理来提升性能，在SWE-Bench基准测试中达到88.8%通过率。


<details>
  <summary>Details</summary>
Motivation: 解决仓库级软件工程修复问题，通过测试驱动的方法将复杂任务分解为专门子任务，减轻单个代理的长上下文负担并提高性能。

Method: 使用测试驱动的工作流，将软件修复分解为四个组件：补丁提议、调试、补丁修订和可选测试生成，每个由专门子代理负责。

Result: 在SWE-Bench Lite上达到88.8%通过率（比次优系统提升27.8%），在SWE-Bench Verified上达到94.3%，仅发现7例测试作弊。

Conclusion: 现代LLM在精心设计的测试驱动工作流中已能达到人类水平的测试解决能力，完全自主仓库修复的最终挑战在于生成有效的复现测试。

Abstract: We introduce TDFlow, a novel test-driven agentic workflow that frames
repository-scale software engineering as a test-resolution task, specifically
designed to solve human-written tests. Given a set of tests, TDFlow repeatedly
proposes, revises, and debugs repository-scale patches using precisely
engineered sub-agents and tightly constrained tools. The workflow decomposes
software engineering program repair into four components governed by respective
sub-agents. This simple, forced decoupling of patch proposing, debugging, patch
revision, and optional test generation (1) reduces long-context burden on any
individual sub-agent, (2) focuses each sub-agent on specific, pre-defined
sub-tasks, and (3) allows for specialized performance improvement on specific
sub-tasks. When provided human-written tests, TDFlow attains 88.8% pass rate on
SWE-Bench Lite (an absolute improvement of 27.8% over the next best system) and
94.3% on SWE-Bench Verified. Manual inspection of the 800 TDFlow runs within
SWE-Bench Lite and Verified uncover only 7 instances of test hacking, which
were subsequently counted as failures. Furthermore, we show that the primary
obstacle to human-level software engineering performance lies within writing
successful reproduction tests. We envision a human-LLM interactive system
powered by TDFlow where human developers write tests solved by LLM systems.
Together, these results indicate that modern LLMs, when embedded in a narrowly
engineered, test-driven workflow, already achieve human-level test resolution
-- with the final frontier for fully autonomous repository repair being the
accurate generation of valid reproduction tests.

</details>


### [11] [Evaluating the effectiveness of LLM-based interoperability](https://arxiv.org/abs/2510.23893)
*Rodrigo Falcão,Stefan Schweitzer,Julien Siebert,Emily Calvet,Frank Elberzhager*

Main category: cs.SE

TL;DR: 该研究评估了13个开源大语言模型在农业互操作性用例中的表现，发现qwen2.5-coder:32b模型在大多数情况下能有效实现系统自主互操作，但在涉及单位转换的复杂场景中需要特定策略。


<details>
  <summary>Details</summary>
Motivation: 随着系统变得越来越动态和异构，互操作性挑战日益突出。传统方法需要人工开发互操作构件，耗费开发时间。研究旨在利用大语言模型实现系统在运行时自主互操作，无需人工干预。

Method: 选取13个开源LLM，在农业互操作性用例中构建四个版本的数据集。每个模型在每个数据集版本上运行三次，采用DIRECT和CODEGEN两种策略，比较模型效果和结果一致性。

Result: qwen2.5-coder:32b在两种策略下表现最佳：DIRECT策略在三个数据集版本中平均pass@1≥0.99，CODEGEN策略平均pass@1≥0.89。在包含单位转换的第四个数据集版本中，所有模型使用DIRECT策略失败，但qwen2.5-coder:32b使用CODEGEN策略仍能达到平均pass@1=0.75。

Conclusion: 某些LLM能够实现系统自主互操作。建议在不同领域进一步评估，并研究可靠性策略。

Abstract: Background: Systems of systems are becoming increasingly dynamic and
heterogeneous, and this adds pressure on the long-standing challenge of
interoperability. Besides its technical aspect, interoperability has also an
economic side, as development time efforts are required to build the
interoperability artifacts. Objectives: With the recent advances in the field
of large language models (LLMs), we aim at analyzing the effectiveness of
LLM-based strategies to make systems interoperate autonomously, at runtime,
without human intervention. Method: We selected 13 open source LLMs and curated
four versions of a dataset in the agricultural interoperability use case. We
performed three runs of each model with each version of the dataset, using two
different strategies. Then we compared the effectiveness of the models and the
consistency of their results across multiple runs. Results: qwen2.5-coder:32b
was the most effective model using both strategies DIRECT (average pass@1 >=
0.99) and CODEGEN (average pass@1 >= 0.89) in three out of four dataset
versions. In the fourth dataset version, which included an unit conversion, all
models using the strategy DIRECT failed, whereas using CODEGEN
qwen2.5-coder:32b succeeded with an average pass@1 = 0.75. Conclusion: Some
LLMs can make systems interoperate autonomously. Further evaluation in
different domains is recommended, and further research on reliability
strategies should be conducted.

</details>


### [12] [Validating Alerts in Cloud-Native Observability](https://arxiv.org/abs/2510.23970)
*Maria C. Borges,Julian Legler,Lucca Di Benedetto*

Main category: cs.SE

TL;DR: 本文介绍了一个用于可观测性实验工具OXN的新警报扩展，让工程师能在开发早期测试和验证警报规则，避免运行时问题。


<details>
  <summary>Details</summary>
Motivation: 现代可靠性工程中，警报设计面临挑战：需要在及早发现问题与最小化误报之间取得平衡，且警报代码很少被执行和检查。业界缺乏支持系统化警报设计和验证的工具。

Method: 开发了OXN工具的警报扩展，允许工程师在开发阶段进行警报实验，调整规则并在设计时验证警报触发行为。

Result: 工程师现在可以在设计时调优规则并常规验证警报的触发行为，避免未来运行时出现问题。

Conclusion: OXN的警报扩展为工程师提供了系统化设计和验证警报的能力，解决了传统警报设计中的挑战。

Abstract: Observability and alerting form the backbone of modern reliability
engineering. Alerts help teams catch faults early before they turn into
production outages and serve as first clues for troubleshooting. However,
designing effective alerts is challenging. They need to strike a fine balance
between catching issues early and minimizing false alarms. On top of this,
alerts often cover uncommon faults, so the code is rarely executed and
therefore rarely checked. To address these challenges, several industry
practitioners advocate for testing alerting code with the same rigor as
application code. Still, there's a lack of tools that support such systematic
design and validation of alerts.
  This paper introduces a new alerting extension for the observability
experimentation tool OXN. It lets engineers experiment with alerts early during
development. With OXN, engineers can now tune rules at design time and
routinely validate the firing behavior of their alerts, avoiding future
problems at runtime.

</details>


### [13] [Lifecycle-Aware code generation: Leveraging Software Engineering Phases in LLMs](https://arxiv.org/abs/2510.24019)
*Xing Xing,Wei Wang,Lipeng Ma,Weidong Yang,Junjie Zheng*

Main category: cs.SE

TL;DR: 提出了一种生命周期感知的代码生成框架，通过引入需求分析、状态机建模和伪代码等中间产物，在训练和推理阶段系统性地整合软件开发流程，显著提升代码正确性。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型代码生成方法大多采用从问题描述到代码的直接单步翻译，忽视了结构化的软件工程实践，需要更符合标准软件开发流程的方法。

Method: 设计生命周期感知框架，在训练和推理阶段系统整合需求分析、状态机建模和伪代码等中间产物，采用多步推理而非单步生成。

Result: 生命周期级微调使代码正确性提升高达75%，多步推理始终优于单步生成，开源LLM经微调后性能可匹敌或略优于预训练代码模型。在DeepSeek-Coder-1.3B上相对CodeBLEU分别比ChatGPT-3.5、ChatGPT-4o-mini、DeepSeek-R1和LLaMA-8B提升34.3%、20.0%、11.2%和22.3%。

Conclusion: 中间产物对最终代码质量均有独特贡献，其中状态机建模影响最大，该框架在训练数据减少80%时仍保持稳健，证明了其有效性。

Abstract: Recent progress in large language models (LLMs) has advanced automatic code
generation, yet most approaches rely on direct, single-step translation from
problem descriptions to code, disregarding structured software engineering
practices. We introduce a lifecycle-aware framework that systematically
incorporates intermediate artifacts such as requirements analysis, state
machine modeling, and pseudocode into both the training and inference stages.
This design aligns code generation with standard software development phases
and enables more structured reasoning. Experiments show that lifecycle-level
fine-tuning improves code correctness by up to 75% over the same model before
fine-tuning, with performance gains compounding across intermediate stages.
Multi-step inference consistently surpasses single-step generation,
demonstrating the effectiveness of intermediate scaffolding. Notably,
open-source LLMs, once fine-tuned under our framework, match or slightly
outperform models pretrained on code. When applied to DeepSeek-Coder-1.3B, our
framework yields relative CodeBLEU improvements of 34.3%, 20.0%, 11.2%, and
22.3% over ChatGPT-3.5, ChatGPT-4o-mini, DeepSeek-R1, and LLaMA-8B,
respectively. Our pipeline also proves robust with up to 80\% less training
data, confirming its resilience. Ablation studies further reveal that each
intermediate artifact contributes distinctly to final code quality, with state
machine modeling yielding the most substantial impact. Our source code and
detailed experimental data are available at
https://anonymous.4open.science/r/Lifecycle-Aware-3CCB.

</details>


### [14] [Monitoring and Observability of Machine Learning Systems: Current Practices and Gaps](https://arxiv.org/abs/2510.24142)
*Joran Leest,Ilias Gerostathopoulos,Patricia Lago,Claudia Raibulet*

Main category: cs.SE

TL;DR: 该研究通过焦点小组会议实证分析了机器学习系统的可观测性实践，发现ML系统会静默失败而非崩溃，并识别了当前实践中的差距。


<details>
  <summary>Details</summary>
Motivation: 机器学习系统会静默失败（做出错误决策而非崩溃），虽然可观测性对ML运维至关重要，但缺乏关于实践者实际捕获内容的实证证据。

Method: 通过在多个领域进行七个焦点小组会议，收集ML系统及其环境中系统捕获的信息，并分析如何用于验证模型、检测诊断故障和解释性能下降。

Result: 编制了实践者系统捕获的信息目录，并映射了他们如何使用这些信息进行模型验证、故障检测诊断和性能下降解释。

Conclusion: 识别了当前实践中的差距，并为建立ML可观测性实践的工具设计和研究提供了启示。

Abstract: Production machine learning (ML) systems fail silently -- not with crashes,
but through wrong decisions. While observability is recognized as critical for
ML operations, there is a lack empirical evidence of what practitioners
actually capture. This study presents empirical results on ML observability in
practice through seven focus group sessions in several domains. We catalog the
information practitioners systematically capture across ML systems and their
environment and map how they use it to validate models, detect and diagnose
faults, and explain observed degradations. Finally, we identify gaps in current
practice and outline implications for tooling design and research to establish
ML observability practices.

</details>


### [15] [Investigating Software Aging in LLM-Generated Software Systems](https://arxiv.org/abs/2510.24188)
*César Santos,Ermeson Andrade,Roberto Natella*

Main category: cs.SE

TL;DR: 本研究通过实验调查了LLM生成的软件在持续执行中的老化现象，发现存在显著的内存增长、响应时间增加和性能不稳定性。


<details>
  <summary>Details</summary>
Motivation: 随着LLM自动生成软件的广泛应用，对其长期可靠性的了解不足，特别是持续执行下的老化问题。

Method: 使用Bolt平台和Baxbench标准化提示生成四个面向服务的应用程序，进行50小时负载测试，持续监控资源使用、响应时间和吞吐量。

Result: 所有应用程序都显示出显著的软件老化证据，包括渐进式内存增长、响应时间增加和性能不稳定，统计分析确认了这些趋势。

Conclusion: 自动生成软件需要考虑老化问题，这为未来研究缓解策略和长期可靠性评估提供了基础。

Abstract: Automatically generated software, especially code produced by Large Language
Models (LLMs), is increasingly adopted to accelerate development and reduce
manual effort. However, little is known about the long-term reliability of such
systems under sustained execution. In this paper, we experimentally investigate
the phenomenon of software aging in applications generated by LLM-based tools.
Using the Bolt platform and standardized prompts from Baxbench, we generated
four service-oriented applications and subjected them to 50-hour load tests.
Resource usage, response time, and throughput were continuously monitored to
detect degradation patterns. The results reveal significant evidence of
software aging, including progressive memory growth, increased response time,
and performance instability across all applications. Statistical analyzes
confirm these trends and highlight variability in the severity of aging
according to the type of application. Our findings show the need to consider
aging in automatically generated software and provide a foundation for future
studies on mitigation strategies and long-term reliability evaluation.

</details>


### [16] [MAGNET: A Multi-Graph Attentional Network for Code Clone Detection](https://arxiv.org/abs/2510.24241)
*Zixian Zhang,Takfarinas Saber*

Main category: cs.SE

TL;DR: 提出MAGNET多图注意力框架，联合利用AST、CFG和DFG表示来捕获源代码的语法和语义特征，在代码克隆检测任务上达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有代码克隆检测方法通常依赖单一表示（如AST、CFG、DFG），只能捕获代码语义的部分方面。混合方法虽然出现，但其融合策略通常是手工设计且效果不佳。

Method: MAGNET框架整合残差图神经网络与节点级自注意力来学习局部和长程依赖，引入门控交叉注意力机制进行细粒度图间交互，并使用Set2Set池化将多图嵌入融合为统一的程序级表示。

Result: 在BigCloneBench和Google Code Jam数据集上的实验表明，MAGNET分别达到96.5%和99.2%的F1分数，实现了最先进的性能。消融研究证实了多图融合和各注意力组件的关键贡献。

Conclusion: MAGNET通过多图注意力框架有效捕获代码的语法和语义特征，在代码克隆检测任务上表现出色，证明了多图融合和注意力机制的重要性。

Abstract: Code clone detection is a fundamental task in software engineering that
underpins refactoring, debugging, plagiarism detection, and vulnerability
analysis. Existing methods often rely on singular representations such as
abstract syntax trees (ASTs), control flow graphs (CFGs), and data flow graphs
(DFGs), which capture only partial aspects of code semantics. Hybrid approaches
have emerged, but their fusion strategies are typically handcrafted and
ineffective. In this study, we propose MAGNET, a multi-graph attentional
framework that jointly leverages AST, CFG, and DFG representations to capture
syntactic and semantic features of source code. MAGNET integrates residual
graph neural networks with node-level self-attention to learn both local and
long-range dependencies, introduces a gated cross-attention mechanism for
fine-grained inter-graph interactions, and employs Set2Set pooling to fuse
multi-graph embeddings into unified program-level representations. Extensive
experiments on BigCloneBench and Google Code Jam demonstrate that MAGNET
achieves state-of-the-art performance with an overall F1 score of 96.5\% and
99.2\% on the two datasets, respectively. Ablation studies confirm the critical
contributions of multi-graph fusion and each attentional component. Our code is
available at https://github.com/ZixianReid/Multigraph_match

</details>


### [17] [Developer Productivity with GenAI](https://arxiv.org/abs/2510.24265)
*Sadia Afroz,Zixuan Feng,Katie Kimura,Bianca Trinkenreich,Igor Steinmacher,Anita Sarma*

Main category: cs.SE

TL;DR: 研究调查生成式AI工具对开发者生产力的影响，发现虽然开发者速度变快，但软件质量和满意度并未显著提升，体现了生产力悖论。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI工具在软件开发中的普及，需要明确这些工具在何时何地真正提升生产力，因为现有证据尚不清晰。

Method: 对415名软件从业者进行问卷调查，使用SPACE框架（满意度与幸福感、绩效、活动、沟通与协作、效率与流畅性）评估AI辅助开发对生产力的影响。

Result: 按AI使用频率分层的结果显示整体生产力变化有限，开发者速度提升但软件质量未改善，满意度也未提高。

Conclusion: 生成式AI工具在软件开发中存在生产力悖论 - 开发者变快但未创造更好软件或获得更高满足感。

Abstract: Generative AI (GenAI) tools are increasingly being adopted in software
development as productivity aids. However, evidence regarding where and when
these tools actually enhance productivity is unclear. In this paper, we
investigate how GenAI adoption affects different dimensions of developer
productivity. We surveyed 415 software practitioners to capture their
perceptions of productivity changes associated with AI-assisted development
using the SPACE framework - Satisfaction and well-being, Performance, Activity,
Communication and collaboration, and Efficiency and flow. Our results,
disaggregated by frequency of AI usage, reveal limited overall productivity
change, highlighting the productivity paradox in which developers become faster
but do not necessarily create better software or feel more fulfilled.

</details>


### [18] [Automatically Benchmarking LLM Code Agents through Agent-Driven Annotation and Evaluation](https://arxiv.org/abs/2510.24358)
*Lingyue Fu,Bolun Zhang,Hao Guan,Yaoming Zhu,Lin Qiu,Weiwen Liu,Xuezhi Cao,Xunliang Cai,Weinan Zhang,Yong Yu*

Main category: cs.SE

TL;DR: 提出了PRDBench基准测试，通过智能体驱动的流水线构建包含50个真实Python项目的基准，解决现有代码智能体评估的高标注成本和僵化评估指标问题。


<details>
  <summary>Details</summary>
Motivation: 现有代码智能体评估基准存在高标注成本、专业知识要求高以及主要依赖单元测试的僵化评估指标等局限性。

Method: 采用智能体驱动的基准构建流水线，结合人类监督生成多样化的项目级任务；使用Agent-as-a-Judge范式对智能体输出进行评分。

Result: 构建了包含50个真实Python项目、涵盖20个领域的PRDBench基准，具有丰富数据源、高任务复杂性和灵活评估指标。

Conclusion: PRDBench为代码智能体和评估智能体的能力评估提供了可扩展且鲁棒的框架，有效解决了标注和评估的挑战。

Abstract: Recent advances in code agents have enabled automated software development at
the project level, supported by large language models (LLMs) and widely adopted
tools. However, existing benchmarks for code agent evaluation face two major
limitations: high annotation cost and expertise requirements, and rigid
evaluation metrics that rely primarily on unit tests. To address these
challenges, we propose an agent-driven benchmark construction pipeline that
leverages human supervision to efficiently generate diverse and challenging
project-level tasks. Based on this approach, we introduce PRDBench, a novel
benchmark comprising 50 real-world Python projects across 20 domains, each with
structured Product Requirement Document (PRD) requirements, comprehensive
evaluation criteria, and reference implementations. PRDBench features rich data
sources, high task complexity, and flexible metrics. We further employ an
Agent-as-a-Judge paradigm to score agent outputs, enabling the evaluation of
various test types beyond unit tests. Extensive experiments on PRDBench
demonstrate its effectiveness in assessing the capabilities of both code agents
and evaluation agents, providing a scalable and robust framework for annotation
and evaluation.

</details>


### [19] [LLM-as-a-Judge for Software Engineering: Literature Review, Vision, and the Road Ahead](https://arxiv.org/abs/2510.24367)
*Junda He,Jieke Shi,Terry Yue Zhuo,Christoph Treude,Jiamou Sun,Zhenchang Xing,Xiaoning Du,David Lo*

Main category: cs.SE

TL;DR: 本文提出LLM-as-a-Judge框架，旨在解决LLM生成软件制品评估的瓶颈问题，通过利用LLM的推理能力实现自动化、规模化的人类级评估。


<details>
  <summary>Details</summary>
Motivation: LLM在软件工程中的快速集成产生了大量软件制品，但缺乏可扩展、可靠的评估方法。人工评估成本高，传统自动指标无法捕捉细微质量差异。

Method: 采用LLM-as-a-Judge范式，利用LLM的高级推理能力进行自动化评估，提供文献综述、分析局限性、识别研究差距并制定详细路线图。

Result: LLM-as-a-Judge在软件工程领域仍处于早期阶段，但具有实现人类级细微评估的潜力。

Conclusion: 到2030年，这些框架有望成为可靠、稳健、可扩展的人类替代方案，能够进行一致、多方面的制品评估，最终提升软件制品评估的可扩展性。

Abstract: The rapid integration of Large Language Models (LLMs) into software
engineering (SE) has revolutionized tasks like code generation, producing a
massive volume of software artifacts. This surge has exposed a critical
bottleneck: the lack of scalable, reliable methods to evaluate these outputs.
Human evaluation is costly and time-consuming, while traditional automated
metrics like BLEU fail to capture nuanced quality aspects. In response, the
LLM-as-a-Judge paradigm - using LLMs for automated evaluation - has emerged.
This approach leverages the advanced reasoning of LLMs, offering a path toward
human-like nuance at automated scale. However, LLM-as-a-Judge research in SE is
still in its early stages. This forward-looking SE 2030 paper aims to steer the
community toward advancing LLM-as-a-Judge for evaluating LLM-generated software
artifacts. We provide a literature review of existing SE studies, analyze their
limitations, identify key research gaps, and outline a detailed roadmap. We
envision these frameworks as reliable, robust, and scalable human surrogates
capable of consistent, multi-faceted artifact evaluation by 2030. Our work aims
to foster research and adoption of LLM-as-a-Judge frameworks, ultimately
improving the scalability of software artifact evaluation.

</details>


### [20] [CodeWiki: Automated Repository-Level Documentation at Scale](https://arxiv.org/abs/2510.24428)
*Nguyen Hoang Anh,Minh Le-Anh,Bach Le,Nghi D. Q. Bui*

Main category: cs.SE

TL;DR: CodeWiki是首个开源的全仓库级别代码文档框架，通过分层分解、递归代理处理和文本视觉合成，在7种编程语言上实现高质量的仓库级文档生成，性能超越现有闭源系统。


<details>
  <summary>Details</summary>
Motivation: 开发人员58%的时间用于理解代码库，但现有LLM只能在函数级别生成文档，无法处理仓库级别的架构模式和跨模块交互，需要解决仓库级文档生成的挑战。

Method: 采用三个创新：分层分解保持架构上下文、递归代理处理与动态委托、文本和视觉工件的合成（包括架构图和数据流）。

Result: 在CodeWikiBench基准测试中，CodeWiki使用专有模型获得68.79%质量分数，开源替代方案获得64.80%，优于现有闭源系统。

Conclusion: CodeWiki证明了在真实世界仓库中实现可扩展、准确文档生成的可行性，为仓库级代码理解提供了有效解决方案。

Abstract: Developers spend nearly 58% of their time understanding codebases, yet
maintaining comprehensive documentation remains challenging due to complexity
and manual effort. While recent Large Language Models (LLMs) show promise for
function-level documentation, they fail at the repository level, where
capturing architectural patterns and cross-module interactions is essential. We
introduce CodeWiki, the first open-source framework for holistic
repository-level documentation across seven programming languages. CodeWiki
employs three innovations: (i) hierarchical decomposition that preserves
architectural context, (ii) recursive agentic processing with dynamic
delegation, and (iii) synthesis of textual and visual artifacts including
architecture diagrams and data flows. We also present CodeWikiBench, the first
repository-level documentation benchmark with multi-level rubrics and agentic
assessment. CodeWiki achieves 68.79% quality score with proprietary models and
64.80% with open-source alternatives, outperforming existing closed-source
systems and demonstrating scalable, accurate documentation for real-world
repositories.

</details>


### [21] [The Divine Software Engineering Comedy -- Inferno: The Okinawa Files](https://arxiv.org/abs/2510.24483)
*Michele Lanza*

Main category: cs.SE

TL;DR: 作者基于2024年6月在日本冲绳举办的软件工程未来研讨会(FUSE)的经历，对软件工程的未来提出了三个噩梦般的预测：不懂技术的软件开发者、快速遗忘教训的领域、以及技术爆炸式增长。


<details>
  <summary>Details</summary>
Motivation: 作者参加FUSE研讨会后，对软件工程领域的未来发展方向感到担忧，希望通过讽刺和批判的方式揭示当前存在的问题。

Method: 基于研讨会讨论内容，结合个人观察和思考，采用讽刺和批判的视角进行分析。

Result: 识别出软件工程面临的三个主要挑战：缺乏真正理解的开发者、领域知识快速流失、技术过度增殖。

Conclusion: 作者认为软件工程的未来前景堪忧，如同慢动作的车祸，虽然能预见问题但无法避免。

Abstract: In June 2024 I co-organized the FUture of Software Engineering symposium in
Okinawa, Japan. Me, Andrian Marcus, Takashi Kobayashi and Shinpei Hayashi were
general chairs, Nicole Novielli, Kevin Moran, Yutaro Kashiwa and Masanari Kondo
were program chairs, some members of my group, Carmen Armenti, Stefano
Campanella, Roberto Minelli, were the tables, can't have a room with only
chairs, after all. We invited a crowd of people to discuss what future software
engineering has. FUSE became a 3-day marathon on whether there is actually a
future at all for SE. This essay is a slightly dark take about what I saw at
that event, very loosely based on the discussions that took place, adding some
healthy sarcasm and cynicism, the intellectual salt and pepper I never seem to
run out of. I listened to the brilliant people who gathered to talk about where
we're headed, and distilled three nightmares headed in our direction: software
makers who don't know what they're doing, but get the job done anyway, a field
moving so fast it can't remember its own lessons, and technologies multiplying
like rabbits in Spring. So, let's start. The future, eh? The future of software
engineering looks like a car crash in slow motion: you can see it coming but
you can't look away. The thing is...

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [22] [Odyssey: An End-to-End System for Pareto-Optimal Serverless Query Processing](https://arxiv.org/abs/2510.24307)
*Shyam Jesalpura,Shengda Zhu,Amir Shaikhha,Antonio Barbalace,Boris Grot*

Main category: cs.DB

TL;DR: Odyssey是一个端到端的无服务器原生数据分析管道，集成了查询规划器、成本模型和执行引擎，能自动生成和评估无服务器查询计划，在成本和性能之间找到帕累托最优解。


<details>
  <summary>Details</summary>
Motivation: 现有无服务器数据分析工作主要关注执行引擎，假设存在"良好"的查询执行计划或依赖用户指导来构建这样的计划。然而，即使是简单的分析查询在无服务器环境中也有巨大的可能计划空间，不同计划在性能和成本上差异显著。

Method: 利用状态空间剪枝启发式和新的搜索算法，自动生成和评估无服务器查询计划，识别平衡成本和性能的帕累托最优计划。

Result: 评估表明Odyssey能准确预测货币成本和延迟，在成本和/或延迟方面持续优于AWS Athena。

Conclusion: Odyssey提供了一个完整的无服务器数据分析解决方案，能够自动优化查询计划，在无服务器环境中实现更好的成本效益和性能表现。

Abstract: Running data analytics queries on serverless (FaaS) workers has been shown to
be cost- and performance-efficient for a variety of real-world scenarios,
including intermittent query arrival patterns, sudden load spikes and
management challenges that afflict managed VM clusters. Alas, existing
serverless data analytics works focus primarily on the serverless execution
engine and assume the existence of a "good" query execution plan or rely on
user guidance to construct such a plan. Meanwhile, even simple analytics
queries on serverless have a huge space of possible plans, with vast
differences in both performance and cost among plans.
  This paper introduces Odyssey, an end-to-end serverless-native data analytics
pipeline that integrates a query planner, cost model and execution engine.
Odyssey automatically generates and evaluates serverless query plans, utilizing
state space pruning heuristics and a novel search algorithm to identify
Pareto-optimal plans that balance cost and performance with low latency even
for complex queries. Our evaluations demonstrate that Odyssey accurately
predicts both monetary cost and latency, and consistently outperforms AWS
Athena on cost and/or latency.

</details>


### [23] [Evaluating Joinable Column Discovery Approaches for Context-Aware Search](https://arxiv.org/abs/2510.24599)
*Harsha Kokel,Aamod Khatiwada,Tejaswini Pedapati,Haritha Ananthakrishnan,Oktie Hassanzadeh,Horst Samulowitz,Kavitha Srinivas*

Main category: cs.DB

TL;DR: 对可连接列发现方法进行综合实验评估，比较语法和语义技术在七个基准测试上的表现，分析六个关键标准的影响，发现集成方法优于单一标准方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注语法重叠和语义相似性，但缺乏对不同数据特征下方法性能的理解，以及多标准如何影响发现效果的深入分析。

Method: 在七个基准测试上比较语法和语义技术，分析六个关键标准（唯一值、交集大小、连接大小、反向连接大小、值语义、元数据语义），并研究通过集成排序组合这些标准的效果。

Result: 元数据和值语义对数据湖至关重要，基于大小的标准在关系数据库中作用更强，集成方法始终优于单一标准方法。

Conclusion: 集成多个标准可提高连接发现的鲁棒性，不同数据上下文需要不同的方法选择，提供了基于数据集特征选择合适方法的实用指南。

Abstract: Joinable Column Discovery is a critical challenge in automating enterprise
data analysis. While existing approaches focus on syntactic overlap and
semantic similarity, there remains limited understanding of which methods
perform best for different data characteristics and how multiple criteria
influence discovery effectiveness. We present a comprehensive experimental
evaluation of joinable column discovery methods across diverse scenarios. Our
study compares syntactic and semantic techniques on seven benchmarks covering
relational databases and data lakes. We analyze six key criteria -- unique
values, intersection size, join size, reverse join size, value semantics, and
metadata semantics -- and examine how combining them through ensemble ranking
affects performance. Our analysis reveals differences in method behavior across
data contexts and highlights the benefits of integrating multiple criteria for
robust join discovery. We provide empirical evidence on when each criterion
matters, compare pre-trained embedding models for semantic joins, and offer
practical guidelines for selecting suitable methods based on dataset
characteristics. Our findings show that metadata and value semantics are
crucial for data lakes, size-based criteria play a stronger role in relational
databases, and ensemble approaches consistently outperform single-criterion
methods.

</details>
