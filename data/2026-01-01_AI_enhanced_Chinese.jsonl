{"id": "2512.23925", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2512.23925", "abs": "https://arxiv.org/abs/2512.23925", "authors": ["Amir Shaikhha"], "title": "Hojabr: Towards a Theory of Everything for AI and Data Analytics", "comment": null, "summary": "Modern data analytics pipelines increasingly combine relational queries, graph processing, and tensor computation within a single application, but existing systems remain fragmented across paradigms, execution models, and research communities. This fragmentation results in repeated optimization efforts, limited interoperability, and strict separation between logical abstractions and physical execution strategies.\n  We propose Hojabr as a unified declarative intermediate language to address this problem. Hojabr integrates relational algebra, tensor algebra, and constraint-based reasoning within a single higher-order algebraic framework, in which joins, aggregations, tensor contractions, and recursive computations are expressed uniformly. Physical choices, such as join algorithms, execution models, and sparse versus dense tensor representations, are handled as constraint-specialization decisions rather than as separate formalisms. Hojabr supports bidirectional translation with existing declarative languages, enabling programs to be both lowered into Hojabr for analysis and optimization and lifted back into their original declarative form. By making semantic, structural, and algebraic properties explicit, and by supporting extensibility across the compilation stack, Hojabr enables systematic reasoning and reuse of optimization techniques across database systems, machine learning frameworks, and compiler infrastructures.", "AI": {"tldr": "Hojabr\u662f\u4e00\u4e2a\u7edf\u4e00\u7684\u58f0\u660e\u6027\u4e2d\u95f4\u8bed\u8a00\uff0c\u96c6\u6210\u4e86\u5173\u7cfb\u4ee3\u6570\u3001\u5f20\u91cf\u4ee3\u6570\u548c\u57fa\u4e8e\u7ea6\u675f\u7684\u63a8\u7406\uff0c\u901a\u8fc7\u9ad8\u9636\u4ee3\u6570\u6846\u67b6\u7edf\u4e00\u8868\u8fbe\u8fde\u63a5\u3001\u805a\u5408\u3001\u5f20\u91cf\u6536\u7f29\u548c\u9012\u5f52\u8ba1\u7b97\uff0c\u652f\u6301\u8de8\u6570\u636e\u5e93\u7cfb\u7edf\u3001\u673a\u5668\u5b66\u4e60\u6846\u67b6\u548c\u7f16\u8bd1\u5668\u57fa\u7840\u8bbe\u65bd\u7684\u4f18\u5316\u6280\u672f\u590d\u7528\u3002", "motivation": "\u73b0\u4ee3\u6570\u636e\u5206\u6790\u7ba1\u9053\u5c06\u5173\u7cfb\u67e5\u8be2\u3001\u56fe\u5904\u7406\u548cTensor\u8ba1\u7b97\u7ed3\u5408\u5728\u5355\u4e2a\u5e94\u7528\u4e2d\uff0c\u4f46\u73b0\u6709\u7cfb\u7edf\u5728\u4e0d\u540c\u8303\u5f0f\u3001\u6267\u884c\u6a21\u578b\u548c\u7814\u7a76\u793e\u533a\u95f4\u5b58\u5728\u788e\u7247\u5316\uff0c\u5bfc\u81f4\u91cd\u590d\u4f18\u5316\u5de5\u4f5c\u3001\u6709\u9650\u4e92\u64cd\u4f5c\u6027\u4ee5\u53ca\u903b\u8f91\u62bd\u8c61\u4e0e\u7269\u7406\u6267\u884c\u7b56\u7565\u4e4b\u95f4\u7684\u4e25\u683c\u5206\u79bb\u3002", "method": "\u63d0\u51faHojabr\u4f5c\u4e3a\u7edf\u4e00\u7684\u58f0\u660e\u6027\u4e2d\u95f4\u8bed\u8a00\uff0c\u5728\u5355\u4e2a\u9ad8\u9636\u4ee3\u6570\u6846\u67b6\u4e2d\u96c6\u6210\u5173\u7cfb\u4ee3\u6570\u3001\u5f20\u91cf\u4ee3\u6570\u548c\u57fa\u4e8e\u7ea6\u675f\u7684\u63a8\u7406\uff0c\u5c06\u8fde\u63a5\u7b97\u6cd5\u3001\u6267\u884c\u6a21\u578b\u548c\u7a00\u758f/\u5bc6\u96c6\u5f20\u91cf\u8868\u793a\u7b49\u7269\u7406\u9009\u62e9\u4f5c\u4e3a\u7ea6\u675f\u7279\u5316\u51b3\u7b56\u5904\u7406\uff0c\u652f\u6301\u4e0e\u73b0\u6709\u58f0\u660e\u6027\u8bed\u8a00\u7684\u53cc\u5411\u7ffb\u8bd1\u3002", "result": "Hojabr\u901a\u8fc7\u4f7f\u8bed\u4e49\u3001\u7ed3\u6784\u548c\u4ee3\u6570\u5c5e\u6027\u663e\u5f0f\u5316\uff0c\u5e76\u652f\u6301\u7f16\u8bd1\u6808\u7684\u53ef\u6269\u5c55\u6027\uff0c\u5b9e\u73b0\u4e86\u8de8\u6570\u636e\u5e93\u7cfb\u7edf\u3001\u673a\u5668\u5b66\u4e60\u6846\u67b6\u548c\u7f16\u8bd1\u5668\u57fa\u7840\u8bbe\u65bd\u7684\u7cfb\u7edf\u5316\u63a8\u7406\u548c\u4f18\u5316\u6280\u672f\u590d\u7528\u3002", "conclusion": "Hojabr\u4e3a\u89e3\u51b3\u6570\u636e\u5206\u6790\u7ba1\u9053\u4e2d\u8de8\u8303\u5f0f\u788e\u7247\u5316\u95ee\u9898\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u4e2d\u95f4\u8bed\u8a00\u6846\u67b6\uff0c\u901a\u8fc7\u96c6\u6210\u591a\u79cd\u4ee3\u6570\u7cfb\u7edf\u548c\u652f\u6301\u53cc\u5411\u7ffb\u8bd1\uff0c\u5b9e\u73b0\u4e86\u4f18\u5316\u6280\u672f\u7684\u7cfb\u7edf\u5316\u590d\u7528\u548c\u8de8\u9886\u57df\u4e92\u64cd\u4f5c\u6027\u3002"}}
{"id": "2512.24078", "categories": ["cs.DB", "cs.CG", "cs.IR"], "pdf": "https://arxiv.org/pdf/2512.24078", "abs": "https://arxiv.org/abs/2512.24078", "authors": ["Junyu Liao", "Ashwin Lall", "Mitsunori Ogihara", "Raymond Wong"], "title": "High-dimensional Regret Minimization", "comment": null, "summary": "Multi-criteria decision making in large databases is very important in real world applications. Recently, an interactive query has been studied extensively in the database literature with the advantage of both the top-k query (with limited output size) and the skyline query (which does not require users to explicitly specify their preference function). This approach iteratively asks the user to select the one preferred within a set of options. Based on rounds of feedback, the query learns the implicit preference and returns the most favorable as a recommendation.\n  However, many modern applications in areas like housing or financial product markets feature datasets with hundreds of attributes. Existing interactive algorithms either fail to scale or require excessive user interactions (often exceeding 1000 rounds). Motivated by this, we propose FHDR (Fast High-Dimensional Reduction), a novel framework that takes less than 0.01s with fewer than 30 rounds of interaction. It is considered a breakthrough in the field of interactive queries since most, if not all, existing studies are not scalable to high-dimensional datasets.\n  Extensive experiments demonstrate that FHDR outperforms the best-known algorithms by at least an order of magnitude in execution time and up to several orders of magnitude in terms of the number of interactions required, establishing a new state of the art for scalable interactive regret minimization.", "AI": {"tldr": "FHDR\u6846\u67b6\u901a\u8fc7\u5feb\u901f\u9ad8\u7ef4\u964d\u7ef4\u6280\u672f\uff0c\u5728\u5c11\u4e8e30\u8f6e\u4ea4\u4e92\u548c0.01\u79d2\u5185\u89e3\u51b3\u5927\u89c4\u6a21\u9ad8\u7ef4\u6570\u636e\u96c6\u4e0a\u7684\u4ea4\u4e92\u5f0f\u67e5\u8be2\u95ee\u9898\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u4ee3\u5e94\u7528\uff08\u5982\u4f4f\u623f\u3001\u91d1\u878d\u4ea7\u54c1\u5e02\u573a\uff09\u7684\u6570\u636e\u96c6\u901a\u5e38\u5305\u542b\u6570\u767e\u4e2a\u5c5e\u6027\uff0c\u73b0\u6709\u4ea4\u4e92\u5f0f\u7b97\u6cd5\u8981\u4e48\u65e0\u6cd5\u6269\u5c55\u5230\u9ad8\u7ef4\u6570\u636e\uff0c\u8981\u4e48\u9700\u8981\u8fc7\u591a\u7528\u6237\u4ea4\u4e92\uff08\u5e38\u8d85\u8fc71000\u8f6e\uff09\uff0c\u8fd9\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u4e0d\u53ef\u884c\u3002", "method": "\u63d0\u51faFHDR\uff08\u5feb\u901f\u9ad8\u7ef4\u964d\u7ef4\uff09\u6846\u67b6\uff0c\u901a\u8fc7\u9ad8\u6548\u7684\u964d\u7ef4\u6280\u672f\u51cf\u5c11\u4ea4\u4e92\u8f6e\u6570\uff0c\u5728\u4fdd\u6301\u67e5\u8be2\u8d28\u91cf\u7684\u540c\u65f6\u5927\u5e45\u964d\u4f4e\u8ba1\u7b97\u590d\u6742\u5ea6\u3002", "result": "\u5b9e\u9a8c\u8868\u660eFHDR\u5728\u8fd0\u884c\u65f6\u95f4\u4e0a\u6bd4\u73b0\u6709\u6700\u4f73\u7b97\u6cd5\u81f3\u5c11\u5feb\u4e00\u4e2a\u6570\u91cf\u7ea7\uff0c\u5728\u4ea4\u4e92\u8f6e\u6570\u4e0a\u5feb\u51e0\u4e2a\u6570\u91cf\u7ea7\uff0c\u4ec5\u9700\u5c11\u4e8e30\u8f6e\u4ea4\u4e92\u548c\u4e0d\u52300.01\u79d2\u5373\u53ef\u5b8c\u6210\u67e5\u8be2\u3002", "conclusion": "FHDR\u4e3a\u53ef\u6269\u5c55\u7684\u4ea4\u4e92\u5f0f\u9057\u61be\u6700\u5c0f\u5316\u5efa\u7acb\u4e86\u65b0\u7684\u6280\u672f\u6807\u51c6\uff0c\u662f\u4ea4\u4e92\u5f0f\u67e5\u8be2\u9886\u57df\u7684\u91cd\u8981\u7a81\u7834\uff0c\u9996\u6b21\u5b9e\u73b0\u4e86\u5bf9\u9ad8\u7ef4\u6570\u636e\u96c6\u7684\u9ad8\u6548\u5904\u7406\u3002"}}
{"id": "2512.24824", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2512.24824", "abs": "https://arxiv.org/abs/2512.24824", "authors": ["Yuzhen Chen", "Bin Yao"], "title": "LMG Index: A Robust Learned Index for Multi-Dimensional Performance Balance", "comment": null, "summary": "Index structures are fundamental for efficient query processing on large-scale datasets. Learned indexes model the indexing process as a prediction problem to overcome the inherent trade-offs of traditional indexes. However, most existing learned indexes optimize only for limited objectives like query latency or space usage, neglecting other practical evaluation dimensions such as update efficiency and stability. Moreover, many learned indexes rely on assumptions about data distributions or workloads, lacking theoretical guarantees when facing unknown or evolving scenarios, which limits their generality in real-world systems.\n  In this paper, we propose LMIndex, a robust framework for learned indexing that leverages a efficient query/update top-layer structure (theoretically $O(1)$ when the key type is fixed) and a efficient optimal error threshold training algorithm (approach $O(1)$ in practice). Building upon this, we develop LMG (LMIndex with gaps), a variant employing a novel gap allocation strategy to enhance update performance and maintain stability under dynamic workloads. Extensive evaluations show that LMG achieves competitive or leading performance, including bulk loading (up to 8.25$\\times$ faster), point queries (up to 1.49$\\times$ faster), range queries (up to 4.02$\\times$ faster than B+Tree), update (up to 1.5$\\times$ faster on read-write workloads), stability (up to 82.59$\\times$ lower coefficient of variation), and space usage (up to 1.38$\\times$ smaller). These results demonstrate that LMG effectively breaks the multi-dimensional performance trade-offs inherent in state-of-the-art approaches, offering a balanced and versatile framework.", "AI": {"tldr": "LMIndex\u662f\u4e00\u4e2a\u9c81\u68d2\u7684\u673a\u5668\u5b66\u4e60\u7d22\u5f15\u6846\u67b6\uff0c\u901a\u8fc7\u9ad8\u6548\u67e5\u8be2/\u66f4\u65b0\u9876\u5c42\u7ed3\u6784\u548c\u6700\u4f18\u8bef\u5dee\u9608\u503c\u8bad\u7ec3\u7b97\u6cd5\uff0c\u4ee5\u53caLMG\u53d8\u4f53\u7684\u95f4\u9699\u5206\u914d\u7b56\u7565\uff0c\u5728\u591a\u7ef4\u5ea6\u6027\u80fd\u4e0a\u53d6\u5f97\u7a81\u7834\u6027\u5e73\u8861\u3002", "motivation": "\u73b0\u6709\u673a\u5668\u5b66\u4e60\u7d22\u5f15\u5927\u591a\u53ea\u4f18\u5316\u67e5\u8be2\u5ef6\u8fdf\u6216\u7a7a\u95f4\u4f7f\u7528\u7b49\u6709\u9650\u76ee\u6807\uff0c\u5ffd\u7565\u4e86\u66f4\u65b0\u6548\u7387\u548c\u7a33\u5b9a\u6027\u7b49\u5b9e\u9645\u8bc4\u4f30\u7ef4\u5ea6\uff0c\u4e14\u4f9d\u8d56\u6570\u636e\u5206\u5e03\u5047\u8bbe\uff0c\u7f3a\u4e4f\u7406\u8bba\u4fdd\u8bc1\uff0c\u9650\u5236\u4e86\u5728\u771f\u5b9e\u7cfb\u7edf\u4e2d\u7684\u901a\u7528\u6027\u3002", "method": "\u63d0\u51faLMIndex\u6846\u67b6\uff1a1) \u9ad8\u6548\u67e5\u8be2/\u66f4\u65b0\u9876\u5c42\u7ed3\u6784\uff08\u7406\u8bba\u4e0aO(1)\u590d\u6742\u5ea6\uff09\uff1b2) \u9ad8\u6548\u6700\u4f18\u8bef\u5dee\u9608\u503c\u8bad\u7ec3\u7b97\u6cd5\uff08\u5b9e\u8df5\u4e2d\u63a5\u8fd1O(1))\uff1b3) \u5f00\u53d1LMG\u53d8\u4f53\uff0c\u91c7\u7528\u65b0\u9896\u7684\u95f4\u9699\u5206\u914d\u7b56\u7565\u63d0\u5347\u66f4\u65b0\u6027\u80fd\u548c\u52a8\u6001\u5de5\u4f5c\u8d1f\u8f7d\u4e0b\u7684\u7a33\u5b9a\u6027\u3002", "result": "LMG\u5728\u591a\u7ef4\u5ea6\u6027\u80fd\u4e0a\u8868\u73b0\u4f18\u5f02\uff1a\u6279\u91cf\u52a0\u8f7d\u5feb8.25\u500d\uff0c\u70b9\u67e5\u8be2\u5feb1.49\u500d\uff0c\u8303\u56f4\u67e5\u8be2\u6bd4B+\u6811\u5feb4.02\u500d\uff0c\u8bfb\u5199\u5de5\u4f5c\u8d1f\u8f7d\u66f4\u65b0\u5feb1.5\u500d\uff0c\u7a33\u5b9a\u6027\u63d0\u534782.59\u500d\uff08\u53d8\u5f02\u7cfb\u6570\u964d\u4f4e\uff09\uff0c\u7a7a\u95f4\u4f7f\u7528\u51cf\u5c111.38\u500d\u3002", "conclusion": "LMG\u6709\u6548\u7a81\u7834\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u591a\u7ef4\u5ea6\u6027\u80fd\u4e0a\u7684\u6743\u8861\uff0c\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5e73\u8861\u4e14\u901a\u7528\u7684\u6846\u67b6\uff0c\u5728\u67e5\u8be2\u6027\u80fd\u3001\u66f4\u65b0\u6548\u7387\u3001\u7a33\u5b9a\u6027\u548c\u7a7a\u95f4\u4f7f\u7528\u7b49\u65b9\u9762\u5b9e\u73b0\u4e86\u5168\u9762\u4f18\u5316\u3002"}}
{"id": "2512.23742", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.23742", "abs": "https://arxiv.org/abs/2512.23742", "authors": ["Guangxi Fan", "Tianliang Ma", "Xuguang Sun", "Xun Wang", "Kain Lu Low", "Leilai Shao"], "title": "AgenticTCAD: A LLM-based Multi-Agent Framework for Automated TCAD Code Generation and Device Optimization", "comment": "7 pages, 7 figures, 2 tables", "summary": "With the continued scaling of advanced technology nodes, the design-technology co-optimization (DTCO) paradigm has become increasingly critical, rendering efficient device design and optimization essential. In the domain of TCAD simulation, however, the scarcity of open-source resources hinders language models from generating valid TCAD code. To overcome this limitation, we construct an open-source TCAD dataset curated by experts and fine-tune a domain-specific model for TCAD code generation. Building on this foundation, we propose AgenticTCAD, a natural language - driven multi-agent framework that enables end-to-end automated device design and optimization. Validation on a 2 nm nanosheet FET (NS-FET) design shows that AgenticTCAD achieves the International Roadmap for Devices and Systems (IRDS)-2024 device specifications within 4.2 hours, whereas human experts required 7.1 days with commercial tools.", "AI": {"tldr": "\u63d0\u51faAgenticTCAD\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5b9e\u73b0\u81ea\u7136\u8bed\u8a00\u9a71\u52a8\u7684\u81ea\u52a8\u5316TCAD\u8bbe\u5907\u8bbe\u8ba1\u4e0e\u4f18\u5316\uff0c\u76f8\u6bd4\u4eba\u5de5\u4e13\u5bb6\u5927\u5e45\u63d0\u5347\u6548\u7387", "motivation": "\u968f\u7740\u5148\u8fdb\u6280\u672f\u8282\u70b9\u7684\u6301\u7eed\u5fae\u7f29\uff0c\u8bbe\u8ba1-\u6280\u672f\u534f\u540c\u4f18\u5316(DTCO)\u53d8\u5f97\u65e5\u76ca\u5173\u952e\uff0c\u4f46TCAD\u4eff\u771f\u9886\u57df\u7f3a\u4e4f\u5f00\u6e90\u8d44\u6e90\u963b\u788d\u4e86\u8bed\u8a00\u6a21\u578b\u751f\u6210\u6709\u6548TCAD\u4ee3\u7801", "method": "\u6784\u5efa\u4e13\u5bb6\u7b56\u5212\u7684\u5f00\u6e90TCAD\u6570\u636e\u96c6\uff0c\u5fae\u8c03\u9886\u57df\u7279\u5b9a\u6a21\u578b\u7528\u4e8eTCAD\u4ee3\u7801\u751f\u6210\uff0c\u5e76\u5728\u6b64\u57fa\u7840\u4e0a\u63d0\u51faAgenticTCAD\u2014\u2014\u81ea\u7136\u8bed\u8a00\u9a71\u52a8\u7684\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u5b9e\u73b0\u7aef\u5230\u7aef\u81ea\u52a8\u5316\u8bbe\u5907\u8bbe\u8ba1\u4e0e\u4f18\u5316", "result": "\u57282\u7eb3\u7c73\u7eb3\u7c73\u7247FET\u8bbe\u8ba1\u9a8c\u8bc1\u4e2d\uff0cAgenticTCAD\u57284.2\u5c0f\u65f6\u5185\u8fbe\u5230IRDS-2024\u8bbe\u5907\u89c4\u683c\uff0c\u800c\u4eba\u7c7b\u4e13\u5bb6\u4f7f\u7528\u5546\u4e1a\u5de5\u5177\u9700\u89817.1\u5929", "conclusion": "AgenticTCAD\u6846\u67b6\u663e\u8457\u63d0\u5347\u4e86TCAD\u8bbe\u5907\u8bbe\u8ba1\u4e0e\u4f18\u5316\u7684\u6548\u7387\u548c\u81ea\u52a8\u5316\u6c34\u5e73\uff0c\u4e3a\u89e3\u51b3DTCO\u6311\u6218\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848"}}
{"id": "2512.23737", "categories": ["cs.DC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.23737", "abs": "https://arxiv.org/abs/2512.23737", "authors": ["Aswathnarayan Muthukrishnan Kirubakaran", "Adithya Parthasarathy", "Nitin Saksena", "Ram Sekhar Bodala", "Akshay Deshpande", "Suhas Malempati", "Shiva Carimireddy", "Abhirup Mazumder"], "title": "Governing Cloud Data Pipelines with Agentic AI", "comment": "https://www.ijcstjournal.org/volume-13/issue-6/IJCST-V13I6P44.pdf", "summary": "Cloud data pipelines increasingly operate under dynamic workloads, evolving schemas, cost constraints, and strict governance requirements. Despite advances in cloud-native orchestration frameworks, most production pipelines rely on static configurations and reactive operational practices, resulting in prolonged recovery times, inefficient resource utilization, and high manual overhead. This paper presents Agentic Cloud Data Engineering, a policy-aware control architecture that integrates bounded AI agents into the governance and control plane of cloud data pipelines. In Agentic Cloud Data Engineering platform, specialized agents analyze pipeline telemetry and metadata, reason over declarative cost and compliance policies, and propose constrained operational actions such as adaptive resource reconfiguration, schema reconciliation, and automated failure recovery. All agent actions are validated against governance policies to ensure predictable and auditable behavior. We evaluate Agentic Cloud Data Engineering platform using representative batch and streaming analytics workloads constructed from public enterprise-style datasets. Experimental results show that Agentic Cloud Data Engineering platform reduces mean pipeline recovery time by up to 45%, lowers operational cost by approximately 25%, and decreases manual intervention events by over 70% compared to static orchestration, while maintaining data freshness and policy compliance. These results demonstrate that policy-bounded agentic control provides an effective and practical approach for governing cloud data pipelines in enterprise environments.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faAgentic Cloud Data Engineering\u5e73\u53f0\uff0c\u901a\u8fc7\u7b56\u7565\u611f\u77e5\u7684AI\u4ee3\u7406\u67b6\u6784\u5b9e\u73b0\u4e91\u6570\u636e\u7ba1\u9053\u7684\u81ea\u4e3b\u6cbb\u7406\uff0c\u76f8\u6bd4\u9759\u6001\u7f16\u6392\u53ef\u51cf\u5c1145%\u6062\u590d\u65f6\u95f4\u3001\u964d\u4f4e25%\u8fd0\u8425\u6210\u672c\u3001\u51cf\u5c1170%\u4eba\u5de5\u5e72\u9884\u3002", "motivation": "\u5f53\u524d\u4e91\u6570\u636e\u7ba1\u9053\u9762\u4e34\u52a8\u6001\u5de5\u4f5c\u8d1f\u8f7d\u3001\u6a21\u5f0f\u6f14\u5316\u3001\u6210\u672c\u7ea6\u675f\u548c\u4e25\u683c\u6cbb\u7406\u8981\u6c42\uff0c\u4f46\u5927\u591a\u6570\u751f\u4ea7\u7ba1\u9053\u4f9d\u8d56\u9759\u6001\u914d\u7f6e\u548c\u88ab\u52a8\u64cd\u4f5c\u5b9e\u8df5\uff0c\u5bfc\u81f4\u6062\u590d\u65f6\u95f4\u957f\u3001\u8d44\u6e90\u5229\u7528\u7387\u4f4e\u3001\u4eba\u5de5\u5f00\u9500\u5927\u3002", "method": "\u63d0\u51fa\u7b56\u7565\u611f\u77e5\u7684\u63a7\u5236\u67b6\u6784\uff0c\u5c06\u6709\u9650AI\u4ee3\u7406\u96c6\u6210\u5230\u4e91\u6570\u636e\u7ba1\u9053\u7684\u6cbb\u7406\u548c\u63a7\u5236\u5e73\u9762\u4e2d\u3002\u4e13\u95e8\u4ee3\u7406\u5206\u6790\u7ba1\u9053\u9065\u6d4b\u548c\u5143\u6570\u636e\uff0c\u57fa\u4e8e\u58f0\u660e\u6027\u6210\u672c\u548c\u5408\u89c4\u7b56\u7565\u8fdb\u884c\u63a8\u7406\uff0c\u63d0\u51fa\u53d7\u9650\u64cd\u4f5c\u884c\u52a8\uff08\u5982\u81ea\u9002\u5e94\u8d44\u6e90\u91cd\u914d\u7f6e\u3001\u6a21\u5f0f\u534f\u8c03\u3001\u81ea\u52a8\u6545\u969c\u6062\u590d\uff09\uff0c\u6240\u6709\u4ee3\u7406\u884c\u52a8\u90fd\u7ecf\u8fc7\u6cbb\u7406\u7b56\u7565\u9a8c\u8bc1\u4ee5\u786e\u4fdd\u53ef\u9884\u6d4b\u548c\u53ef\u5ba1\u8ba1\u884c\u4e3a\u3002", "result": "\u4f7f\u7528\u4ee3\u8868\u6027\u6279\u5904\u7406\u548c\u6d41\u5206\u6790\u5de5\u4f5c\u8d1f\u8f7d\u8fdb\u884c\u5b9e\u9a8c\uff0c\u7ed3\u679c\u663e\u793a\uff1a\u76f8\u6bd4\u9759\u6001\u7f16\u6392\uff0c\u5e73\u53f0\u53ef\u5c06\u5e73\u5747\u7ba1\u9053\u6062\u590d\u65f6\u95f4\u51cf\u5c1145%\uff0c\u8fd0\u8425\u6210\u672c\u964d\u4f4e\u7ea625%\uff0c\u624b\u52a8\u5e72\u9884\u4e8b\u4ef6\u51cf\u5c1170%\u4ee5\u4e0a\uff0c\u540c\u65f6\u4fdd\u6301\u6570\u636e\u65b0\u9c9c\u5ea6\u548c\u7b56\u7565\u5408\u89c4\u6027\u3002", "conclusion": "\u7b56\u7565\u7ea6\u675f\u7684\u4ee3\u7406\u63a7\u5236\u4e3a\u4f01\u4e1a\u5728\u4e91\u6570\u636e\u7ba1\u9053\u6cbb\u7406\u65b9\u9762\u63d0\u4f9b\u4e86\u6709\u6548\u5b9e\u7528\u7684\u65b9\u6cd5\uff0c\u80fd\u591f\u663e\u8457\u63d0\u5347\u81ea\u52a8\u5316\u6c34\u5e73\u548c\u8fd0\u8425\u6548\u7387\u3002"}}
{"id": "2512.23743", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.23743", "abs": "https://arxiv.org/abs/2512.23743", "authors": ["Yunguo Yu"], "title": "Hybrid-Code: A Privacy-Preserving, Redundant Multi-Agent Framework for Reliable Local Clinical Coding", "comment": "18 pages, 1 figure, original research paper", "summary": "Clinical coding automation using cloud-based Large Language Models (LLMs) poses privacy risks and latency bottlenecks, rendering them unsuitable for on-premise healthcare deployment. We introduce Hybrid-Code, a hybrid neuro-symbolic multi-agent framework for local clinical coding that ensures production reliability through redundancy and verification. Our system comprises two agents: a Coder that attempts language model-based semantic reasoning using BioMistral-7B but falls back to deterministic keyword matching when model output is unreliable, ensuring pipeline completion; and an Auditor that verifies codes against a 257-code knowledge base and clinical evidence. Evaluating on 1,000 MIMIC-III discharge summaries, we demonstrate no hallucinated codes among accepted outputs within the knowledge base, 24.47% verification rate, and 34.11% coverage (95% CI: 31.2%--37.0%) with 86%+ language model utilization. The Auditor filtered invalid format codes and provided evidence-based quality control (75.53% rejection rate) while ensuring no patient data leaves the hospital firewall. The hybrid architecture -- combining language model semantic understanding (when successful), deterministic fallback (when the model fails), and symbolic verification (always active) -- ensures both reliability and privacy preservation, addressing critical barriers to AI adoption in healthcare. Our key finding is that reliability through redundancy is more valuable than pure model performance in production healthcare systems, where system failures are unacceptable.", "AI": {"tldr": "Hybrid-Code\u662f\u4e00\u4e2a\u6df7\u5408\u795e\u7ecf\u7b26\u53f7\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u7528\u4e8e\u672c\u5730\u4e34\u5e8a\u7f16\u7801\uff0c\u7ed3\u5408\u8bed\u8a00\u6a21\u578b\u8bed\u4e49\u63a8\u7406\u3001\u786e\u5b9a\u6027\u56de\u9000\u548c\u7b26\u53f7\u9a8c\u8bc1\uff0c\u786e\u4fdd\u751f\u4ea7\u53ef\u9760\u6027\u548c\u9690\u79c1\u4fdd\u62a4\u3002", "motivation": "\u57fa\u4e8e\u4e91\u7684LLM\u4e34\u5e8a\u7f16\u7801\u81ea\u52a8\u5316\u5b58\u5728\u9690\u79c1\u98ce\u9669\u548c\u5ef6\u8fdf\u74f6\u9888\uff0c\u4e0d\u9002\u5408\u672c\u5730\u533b\u7597\u90e8\u7f72\uff0c\u9700\u8981\u4e00\u79cd\u53ef\u9760\u4e14\u4fdd\u62a4\u9690\u79c1\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u91c7\u7528\u6df7\u5408\u795e\u7ecf\u7b26\u53f7\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff1aCoder\u667a\u80fd\u4f53\u4f7f\u7528BioMistral-7B\u8fdb\u884c\u8bed\u4e49\u63a8\u7406\uff0c\u5931\u8d25\u65f6\u56de\u9000\u5230\u786e\u5b9a\u6027\u5173\u952e\u8bcd\u5339\u914d\uff1bAuditor\u667a\u80fd\u4f53\u9a8c\u8bc1\u4ee3\u7801\u662f\u5426\u7b26\u5408257\u4e2a\u4ee3\u7801\u77e5\u8bc6\u5e93\u548c\u4e34\u5e8a\u8bc1\u636e\u3002", "result": "\u57281000\u4e2aMIMIC-III\u51fa\u9662\u6458\u8981\u4e0a\u8bc4\u4f30\uff1a\u77e5\u8bc6\u5e93\u5185\u63a5\u53d7\u8f93\u51fa\u65e0\u5e7b\u89c9\u4ee3\u7801\uff0c\u9a8c\u8bc1\u738724.47%\uff0c\u8986\u76d6\u738734.11%\uff0895% CI: 31.2%-37.0%\uff09\uff0c\u8bed\u8a00\u6a21\u578b\u5229\u7528\u738786%+\uff0c\u62d2\u7edd\u738775.53%\uff0c\u786e\u4fdd\u60a3\u8005\u6570\u636e\u4e0d\u79bb\u5f00\u533b\u9662\u9632\u706b\u5899\u3002", "conclusion": "\u6df7\u5408\u67b6\u6784\u7ed3\u5408\u8bed\u8a00\u6a21\u578b\u8bed\u4e49\u7406\u89e3\u3001\u786e\u5b9a\u6027\u56de\u9000\u548c\u7b26\u53f7\u9a8c\u8bc1\uff0c\u786e\u4fdd\u53ef\u9760\u6027\u548c\u9690\u79c1\u4fdd\u62a4\u3002\u5728\u751f\u4ea7\u533b\u7597\u7cfb\u7edf\u4e2d\uff0c\u901a\u8fc7\u5197\u4f59\u5b9e\u73b0\u7684\u53ef\u9760\u6027\u6bd4\u7eaf\u6a21\u578b\u6027\u80fd\u66f4\u6709\u4ef7\u503c\u3002"}}
{"id": "2512.23952", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2512.23952", "abs": "https://arxiv.org/abs/2512.23952", "authors": ["Yongmin Zhang", "Pengyu Huang", "Mingyi Dong", "Jing Yao"], "title": "Squeezing Edge Performance: A Sensitivity-Aware Container Management for Heterogeneous Tasks", "comment": null, "summary": "Edge computing enables latency-critical applications to process data close to end devices, yet task heterogeneity and limited resources pose significant challenges to efficient orchestration. This paper presents a measurement-driven, container-based resource management framework for intra-node optimization on a single edge server hosting multiple heterogeneous applications. Extensive profiling experiments are conducted to derive a nonlinear fitting model that characterizes the relationship among CPU/memory allocations and processing latency across diverse workloads, enabling reliable estimation of performance under varying configurations and providing quantitative support for subsequent optimization. Using this model and a queueing-based delay formulation, we formulate a mixed-integer nonlinear programming (MINLP) problem to jointly minimize system latency and power consumption, which is shown to be NP-hard. The problem is decomposed into tractable convex subproblems and solved through a two-stage container-based resource management scheme (CRMS) combining convex optimization and greedy refinement. The proposed scheme achieves polynomial-time complexity and supports quasi-dynamic execution under global resource constraints. Simulation results demonstrate that CRMS reduces latency by over 14\\% and improves energy efficiency compared with heuristic and search-based baselines, offering a practical and scalable solution for heterogeneous edge environments with dynamic workload characteristics.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u6d4b\u91cf\u7684\u5bb9\u5668\u8d44\u6e90\u7ba1\u7406\u6846\u67b6CRMS\uff0c\u901a\u8fc7\u975e\u7ebf\u6027\u62df\u5408\u6a21\u578b\u548c\u4e24\u9636\u6bb5\u4f18\u5316\uff0c\u5728\u8fb9\u7f18\u670d\u52a1\u5668\u4e0a\u8054\u5408\u6700\u5c0f\u5316\u5ef6\u8fdf\u548c\u529f\u8017\uff0c\u76f8\u6bd4\u57fa\u7ebf\u964d\u4f4e14%\u5ef6\u8fdf\u5e76\u63d0\u5347\u80fd\u6548\u3002", "motivation": "\u8fb9\u7f18\u8ba1\u7b97\u4e2d\u4efb\u52a1\u5f02\u6784\u6027\u548c\u8d44\u6e90\u6709\u9650\u6027\u5bf9\u9ad8\u6548\u7f16\u6392\u5e26\u6765\u6311\u6218\uff0c\u9700\u8981\u9488\u5bf9\u5355\u8fb9\u7f18\u670d\u52a1\u5668\u4e0a\u591a\u5f02\u6784\u5e94\u7528\u7684\u8d44\u6e90\u7ba1\u7406\u65b9\u6848\uff0c\u4ee5\u4f18\u5316\u5ef6\u8fdf\u548c\u80fd\u8017\u3002", "method": "1) \u901a\u8fc7\u5927\u91cf\u5256\u6790\u5b9e\u9a8c\u5efa\u7acbCPU/\u5185\u5b58\u5206\u914d\u4e0e\u5904\u7406\u5ef6\u8fdf\u7684\u975e\u7ebf\u6027\u62df\u5408\u6a21\u578b\uff1b2) \u57fa\u4e8e\u961f\u5217\u5ef6\u8fdf\u516c\u5f0f\u6784\u5efaMINLP\u95ee\u9898\uff1b3) \u5c06NP\u96be\u95ee\u9898\u5206\u89e3\u4e3a\u53ef\u5904\u7406\u7684\u51f8\u5b50\u95ee\u9898\uff1b4) \u63d0\u51fa\u4e24\u9636\u6bb5\u5bb9\u5668\u8d44\u6e90\u7ba1\u7406\u65b9\u6848CRMS\uff0c\u7ed3\u5408\u51f8\u4f18\u5316\u548c\u8d2a\u5a6a\u7ec6\u5316\u3002", "result": "CRMS\u76f8\u6bd4\u542f\u53d1\u5f0f\u548c\u57fa\u4e8e\u641c\u7d22\u7684\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5ef6\u8fdf\u964d\u4f4e\u8d85\u8fc714%\uff0c\u80fd\u6548\u63d0\u5347\uff0c\u5177\u6709\u591a\u9879\u5f0f\u65f6\u95f4\u590d\u6742\u5ea6\u548c\u51c6\u52a8\u6001\u6267\u884c\u80fd\u529b\uff0c\u9002\u7528\u4e8e\u52a8\u6001\u5de5\u4f5c\u8d1f\u8f7d\u7684\u5f02\u6784\u8fb9\u7f18\u73af\u5883\u3002", "conclusion": "\u63d0\u51fa\u7684\u6d4b\u91cf\u9a71\u52a8\u5bb9\u5668\u8d44\u6e90\u7ba1\u7406\u6846\u67b6\u4e3a\u5f02\u6784\u8fb9\u7f18\u73af\u5883\u63d0\u4f9b\u4e86\u5b9e\u7528\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u975e\u7ebf\u6027\u5efa\u6a21\u548c\u4e24\u9636\u6bb5\u4f18\u5316\u6709\u6548\u5e73\u8861\u5ef6\u8fdf\u548c\u529f\u8017\uff0c\u652f\u6301\u52a8\u6001\u5de5\u4f5c\u8d1f\u8f7d\u7279\u6027\u3002"}}
{"id": "2512.23746", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.23746", "abs": "https://arxiv.org/abs/2512.23746", "authors": ["Wei Li", "Yan Zou", "Yixin Liang", "Jos\u00e9 Moura", "Shawn Blanton"], "title": "DEFT: Differentiable Automatic Test Pattern Generation", "comment": null, "summary": "Modern IC complexity drives test pattern growth, with the majority of patterns targeting a small set of hard-to-detect (HTD) faults. This motivates new ATPG algorithms to improve test effectiveness specifically for HTD faults. This paper presents DEFT (Differentiable Automatic Test Pattern Generation), a new ATPG approach that reformulates the discrete ATPG problem as a continuous optimization task. DEFT introduces a mathematically grounded reparameterization that aligns the expected continuous objective with discrete fault-detection semantics, enabling reliable gradient-based pattern generation. To ensure scalability and stability on deep circuit graphs, DEFT integrates a custom CUDA kernel for efficient forward-backward propagation and applies gradient normalization to mitigate vanishing gradients. Compared to a leading commercial tool on two industrial benchmarks, DEFT improves HTD fault detection by 21.1% and 48.9% on average under the same pattern budget and comparable runtime. DEFT also supports practical ATPG settings such as partial assignment pattern generation, producing patterns with 19.3% fewer 0/1 bits while still detecting 35% more faults. These results indicate DEFT is a promising and effective ATPG engine, offering a valuable complement to existing heuristic.", "AI": {"tldr": "DEFT\u5c06\u79bb\u6563ATPG\u95ee\u9898\u8f6c\u5316\u4e3a\u8fde\u7eed\u4f18\u5316\u4efb\u52a1\uff0c\u901a\u8fc7\u53ef\u5fae\u5206\u7684\u6570\u5b66\u91cd\u53c2\u6570\u5316\u5b9e\u73b0\u68af\u5ea6\u9a71\u52a8\u7684\u6d4b\u8bd5\u6a21\u5f0f\u751f\u6210\uff0c\u663e\u8457\u63d0\u5347\u96be\u68c0\u6d4b\u6545\u969c\u7684\u8986\u76d6\u7387\u3002", "motivation": "\u73b0\u4ee3IC\u590d\u6742\u6027\u5bfc\u81f4\u6d4b\u8bd5\u6a21\u5f0f\u6570\u91cf\u6fc0\u589e\uff0c\u5176\u4e2d\u5927\u90e8\u5206\u6a21\u5f0f\u9488\u5bf9\u5c11\u6570\u96be\u68c0\u6d4b\u6545\u969c\uff0c\u9700\u8981\u65b0\u7684ATPG\u7b97\u6cd5\u4e13\u95e8\u63d0\u9ad8\u5bf9\u8fd9\u7c7b\u6545\u969c\u7684\u6d4b\u8bd5\u6548\u679c\u3002", "method": "\u63d0\u51faDEFT\u65b9\u6cd5\uff0c\u5c06\u79bb\u6563ATPG\u95ee\u9898\u91cd\u65b0\u8868\u8ff0\u4e3a\u8fde\u7eed\u4f18\u5316\u4efb\u52a1\uff0c\u5f15\u5165\u6570\u5b66\u57fa\u7840\u7684\u91cd\u53c2\u6570\u5316\u4f7f\u8fde\u7eed\u76ee\u6807\u4e0e\u79bb\u6563\u6545\u969c\u68c0\u6d4b\u8bed\u4e49\u5bf9\u9f50\uff0c\u652f\u6301\u68af\u5ea6\u9a71\u52a8\u6a21\u5f0f\u751f\u6210\u3002\u4e3a\u5e94\u5bf9\u6df1\u5ea6\u7535\u8def\u56fe\u7684\u53ef\u6269\u5c55\u6027\u548c\u7a33\u5b9a\u6027\u95ee\u9898\uff0c\u96c6\u6210\u5b9a\u5236CUDA\u5185\u6838\u5b9e\u73b0\u9ad8\u6548\u524d\u5411-\u53cd\u5411\u4f20\u64ad\uff0c\u5e76\u5e94\u7528\u68af\u5ea6\u5f52\u4e00\u5316\u7f13\u89e3\u68af\u5ea6\u6d88\u5931\u95ee\u9898\u3002", "result": "\u5728\u4e24\u4e2a\u5de5\u4e1a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u4e0e\u9886\u5148\u5546\u4e1a\u5de5\u5177\u76f8\u6bd4\uff0c\u5728\u76f8\u540c\u6a21\u5f0f\u9884\u7b97\u548c\u53ef\u6bd4\u8fd0\u884c\u65f6\u95f4\u4e0b\uff0cDEFT\u5c06\u96be\u68c0\u6d4b\u6545\u969c\u68c0\u6d4b\u7387\u5e73\u5747\u63d0\u9ad821.1%\u548c48.9%\u3002\u5728\u90e8\u5206\u8d4b\u503c\u6a21\u5f0f\u751f\u6210\u7b49\u5b9e\u9645ATPG\u8bbe\u7f6e\u4e2d\uff0cDEFT\u751f\u6210\u7684\u6a21\u5f0f\u51cf\u5c11\u4e8619.3%\u76840/1\u6bd4\u7279\uff0c\u540c\u65f6\u4ecd\u80fd\u68c0\u6d4b\u51fa35%\u66f4\u591a\u7684\u6545\u969c\u3002", "conclusion": "DEFT\u662f\u4e00\u79cd\u6709\u524d\u666f\u4e14\u6709\u6548\u7684ATPG\u5f15\u64ce\uff0c\u4e3a\u73b0\u6709\u542f\u53d1\u5f0f\u65b9\u6cd5\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u8865\u5145\uff0c\u901a\u8fc7\u53ef\u5fae\u5206\u4f18\u5316\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u96be\u68c0\u6d4b\u6545\u969c\u7684\u6d4b\u8bd5\u6548\u679c\u3002"}}
{"id": "2512.24286", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2512.24286", "abs": "https://arxiv.org/abs/2512.24286", "authors": ["Yanbing Yang", "Huiling Zhu", "Wenchi Cheng", "Jingqing Wang", "Changrun Chen", "Jiangzhou Wang"], "title": "Data Heterogeneity-Aware Client Selection for Federated Learning in Wireless Networks", "comment": null, "summary": "Federated Learning (FL) enables mobile edge devices, functioning as clients, to collaboratively train a decentralized model while ensuring local data privacy. However, the efficiency of FL in wireless networks is limited not only by constraints on communication and computational resources but also by significant data heterogeneity among clients, particularly in large-scale networks. This paper first presents a theoretical analysis of the impact of client data heterogeneity on global model generalization error, which can result in repeated training cycles, increased energy consumption, and prolonged latency. Based on the theoretical insights, an optimization problem is formulated to jointly minimize learning latency and energy consumption while constraining generalization error. A joint client selection and resource allocation (CSRA) approach is then proposed, employing a series of convex optimization and relaxation techniques. Extensive simulation results demonstrate that the proposed CSRA scheme yields higher test accuracy, reduced learning latency, and lower energy consumption compared to baseline methods that do not account for data heterogeneity.", "AI": {"tldr": "\u63d0\u51fa\u8054\u5408\u5ba2\u6237\u7aef\u9009\u62e9\u4e0e\u8d44\u6e90\u5206\u914d(CSRA)\u65b9\u6848\uff0c\u89e3\u51b3\u8054\u90a6\u5b66\u4e60\u4e2d\u6570\u636e\u5f02\u6784\u6027\u5bfc\u81f4\u7684\u6cdb\u5316\u8bef\u5dee\u3001\u5ef6\u8fdf\u548c\u80fd\u8017\u95ee\u9898", "motivation": "\u8054\u90a6\u5b66\u4e60\u5728\u65e0\u7ebf\u7f51\u7edc\u4e2d\u7684\u6548\u7387\u53d7\u9650\u4e8e\u901a\u4fe1\u8ba1\u7b97\u8d44\u6e90\u548c\u5ba2\u6237\u7aef\u6570\u636e\u5f02\u6784\u6027\uff0c\u7279\u522b\u662f\u5927\u89c4\u6a21\u7f51\u7edc\u4e2d\u6570\u636e\u5f02\u6784\u6027\u4f1a\u5bfc\u81f4\u91cd\u590d\u8bad\u7ec3\u3001\u80fd\u8017\u589e\u52a0\u548c\u5ef6\u8fdf\u5ef6\u957f", "method": "\u9996\u5148\u7406\u8bba\u5206\u6790\u5ba2\u6237\u7aef\u6570\u636e\u5f02\u6784\u6027\u5bf9\u5168\u5c40\u6a21\u578b\u6cdb\u5316\u8bef\u5dee\u7684\u5f71\u54cd\uff0c\u7136\u540e\u6784\u5efa\u8054\u5408\u6700\u5c0f\u5316\u5b66\u4e60\u5ef6\u8fdf\u548c\u80fd\u8017\u7684\u4f18\u5316\u95ee\u9898\uff0c\u63d0\u51fa\u57fa\u4e8e\u51f8\u4f18\u5316\u548c\u677e\u5f1b\u6280\u672f\u7684\u8054\u5408\u5ba2\u6237\u7aef\u9009\u62e9\u4e0e\u8d44\u6e90\u5206\u914d(CSRA)\u65b9\u6cd5", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u76f8\u6bd4\u4e0d\u8003\u8651\u6570\u636e\u5f02\u6784\u6027\u7684\u57fa\u7ebf\u65b9\u6cd5\uff0cCSRA\u65b9\u6848\u80fd\u83b7\u5f97\u66f4\u9ad8\u7684\u6d4b\u8bd5\u7cbe\u5ea6\u3001\u66f4\u4f4e\u7684\u5b66\u4e60\u5ef6\u8fdf\u548c\u66f4\u4f4e\u7684\u80fd\u8017", "conclusion": "\u901a\u8fc7\u8054\u5408\u8003\u8651\u5ba2\u6237\u7aef\u9009\u62e9\u548c\u8d44\u6e90\u5206\u914d\uff0c\u5e76\u57fa\u4e8e\u6570\u636e\u5f02\u6784\u6027\u7406\u8bba\u5206\u6790\uff0c\u53ef\u4ee5\u6709\u6548\u63d0\u5347\u8054\u90a6\u5b66\u4e60\u5728\u65e0\u7ebf\u7f51\u7edc\u4e2d\u7684\u6548\u7387\u548c\u6027\u80fd"}}
{"id": "2512.23747", "categories": ["cs.SE", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2512.23747", "abs": "https://arxiv.org/abs/2512.23747", "authors": ["Abhinav Parmar", "Abhisek Panigrahi", "Abhishek Kumar Dwivedi", "Abhishek Bhattacharya", "Adarsh Ramachandra", "Aditya Choudhary", "Aditya Garg", "Aditya Raj", "Alankrit Bhatt", "Alpesh Yadav", "Anant Vishnu", "Ananthu Pillai", "Ankush Kumar", "Aryan Patnaik", "Aswatha Narayanan S", "Avanish Raj Singh", "Bhavya Shree Gadda", "Brijesh Pankajbhai Kachhadiya", "Buggala Jahnavi", "Chidurala Nithin Krishna", "Chintan Shah", "Chunduru Akshaya", "Debarshi Banerjee", "Debrup Dey", "Deepa R.", "Deepika B G", "Faiz ur Rahman", "Gagan Gayari", "Gudhi Jagadeesh Kumar Naidu", "Gursimar Singh", "Harshal Tyagi", "Harshini K", "James Mani Vathalloor", "Jayarama Nettar", "Jayashree Gajjam", "Joe Walter Sugil George", "Kamalakara Sri Krishna Tadepalli", "Kamalkumar Rathinasamy", "Karan Chaurasia", "Karthikeyan S", "Kashish Arora", "Kaushal Desai", "Khushboo Buwade", "Kiran Manjrekar", "Malikireddy Venkata Sai Likhitha", "Manjunath A", "Mitali Mahavir Bedmutha", "Mohammed Rafee Tarafdar", "Nikhil Tiwari", "Nikitha K Gigi", "Pavan Ravikumar", "Pendyala Swarnanjali", "Piyush Anand", "Prakash Chandrasekar", "Prasanna Bhalchandra Gawade", "Prasanth Sivan", "Preeti Khurana", "Priyanshi Babbar", "Rajab Ali Mondal", "Rajesh Kumar Vissapragada", "Rajeshwari Ganesan", "Rajeswari Koppisetti", "Ramjee R.", "Ramkumar Thiruppathisamy", "Rani G. S.", "S Reka", "Samarth Gupta", "Sandeep Reddy Kothakota", "Sarathy K", "Sathyanarayana Sampath Kumar", "Saurabh Kumar", "Shashank Khasare", "Shenbaga Devi Venkatesh Kumar", "Shiva Rama Krishna Parvatham", "Shoeb Shaikh", "Shrishanmathi A", "Shubham Pathak", "Sree Samhita Koppaka", "Sreenivasa Raghavan K S", "Sreeram Venkatasubramanian", "Suprabha Desai Bojja", "Swetha R", "Syed Ahmed", "Chinmai Harshitha Thota", "Tushar Yadav", "Veeravelly Kusumitha", "V V S S Prasanth Patnaik", "Vidya Sri Sesetti", "Vijayakeerthi K", "Vikram Raj Bakshi", "Vinay K K", "Vinoth Kumar Loganathan", "Vipin Tiwari", "Vivek Kumar Shrivastav", "V Venkata Sri Datta Charan", "Wasim Akhtar Khan"], "title": "State-of-the-art Small Language Coder Model: Mify-Coder", "comment": null, "summary": "We present Mify-Coder, a 2.5B-parameter code model trained on 4.2T tokens using a compute-optimal strategy built on the Mify-2.5B foundation model. Mify-Coder achieves comparable accuracy and safety while significantly outperforming much larger baseline models on standard coding and function-calling benchmarks, demonstrating that compact models can match frontier-grade models in code generation and agent-driven workflows. Our training pipeline combines high-quality curated sources with synthetic data generated through agentically designed prompts, refined iteratively using enterprise-grade evaluation datasets. LLM-based quality filtering further enhances data density, enabling frugal yet effective training. Through disciplined exploration of CPT-SFT objectives, data mixtures, and sampling dynamics, we deliver frontier-grade code intelligence within a single continuous training trajectory. Empirical evidence shows that principled data and compute discipline allow smaller models to achieve competitive accuracy, efficiency, and safety compliance. Quantized variants of Mify-Coder enable deployment on standard desktop environments without requiring specialized hardware.", "AI": {"tldr": "Mify-Coder\u662f\u4e00\u4e2a2.5B\u53c2\u6570\u7684\u4ee3\u7801\u6a21\u578b\uff0c\u901a\u8fc7\u8ba1\u7b97\u6700\u4f18\u7b56\u7565\u57284.2T token\u4e0a\u8bad\u7ec3\uff0c\u5728\u4ee3\u7801\u751f\u6210\u548c\u51fd\u6570\u8c03\u7528\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8d85\u8d8a\u66f4\u5927\u6a21\u578b\uff0c\u8bc1\u660e\u7d27\u51d1\u6a21\u578b\u80fd\u8fbe\u5230\u524d\u6cbf\u6027\u80fd\u3002", "motivation": "\u63a2\u7d22\u5982\u4f55\u901a\u8fc7\u6570\u636e\u8d28\u91cf\u548c\u8ba1\u7b97\u6548\u7387\u7684\u4f18\u5316\uff0c\u8ba9\u66f4\u5c0f\u7684\u6a21\u578b\u5728\u4ee3\u7801\u751f\u6210\u548c\u667a\u80fd\u4f53\u9a71\u52a8\u5de5\u4f5c\u6d41\u4e2d\u8fbe\u5230\u4e0e\u524d\u6cbf\u5927\u6a21\u578b\u76f8\u5f53\u7684\u6027\u80fd\uff0c\u540c\u65f6\u964d\u4f4e\u90e8\u7f72\u6210\u672c\u3002", "method": "\u57fa\u4e8eMify-2.5B\u57fa\u7840\u6a21\u578b\uff0c\u91c7\u7528\u8ba1\u7b97\u6700\u4f18\u8bad\u7ec3\u7b56\u7565\uff0c\u7ed3\u5408\u9ad8\u8d28\u91cf\u4eba\u5de5\u6807\u6ce8\u6570\u636e\u548c\u901a\u8fc7\u667a\u80fd\u4f53\u8bbe\u8ba1\u63d0\u793a\u751f\u6210\u7684\u5408\u6210\u6570\u636e\uff0c\u4f7f\u7528LLM\u8d28\u91cf\u8fc7\u6ee4\u589e\u5f3a\u6570\u636e\u5bc6\u5ea6\uff0c\u63a2\u7d22CPT-SFT\u76ee\u6807\u3001\u6570\u636e\u6df7\u5408\u548c\u91c7\u6837\u52a8\u6001\u3002", "result": "Mify-Coder\u5728\u6807\u51c6\u4ee3\u7801\u548c\u51fd\u6570\u8c03\u7528\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u8d85\u8d8a\u66f4\u5927\u7684\u57fa\u7ebf\u6a21\u578b\uff0c\u8fbe\u5230\u53ef\u6bd4\u7684\u51c6\u786e\u6027\u548c\u5b89\u5168\u6027\uff0c\u91cf\u5316\u53d8\u4f53\u53ef\u5728\u6807\u51c6\u684c\u9762\u73af\u5883\u90e8\u7f72\u800c\u65e0\u9700\u4e13\u7528\u786c\u4ef6\u3002", "conclusion": "\u901a\u8fc7\u539f\u5219\u6027\u7684\u6570\u636e\u548c\u8ba1\u7b97\u7eaa\u5f8b\uff0c\u5c0f\u578b\u6a21\u578b\u80fd\u591f\u5b9e\u73b0\u6709\u7ade\u4e89\u529b\u7684\u51c6\u786e\u6027\u3001\u6548\u7387\u548c\u5b89\u5168\u5408\u89c4\u6027\uff0c\u4e3a\u4ee3\u7801\u667a\u80fd\u63d0\u4f9b\u7ecf\u6d4e\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.24449", "categories": ["cs.DC", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.24449", "abs": "https://arxiv.org/abs/2512.24449", "authors": ["Bo Jiang", "Taolue Yang", "Youyuan Liu", "Xubin He", "Sheng Di", "Sian Jin"], "title": "PackKV: Reducing KV Cache Memory Footprint through LLM-Aware Lossy Compression", "comment": null, "summary": "Transformer-based large language models (LLMs) have demonstrated remarkable potential across a wide range of practical applications. However, long-context inference remains a significant challenge due to the substantial memory requirements of the key-value (KV) cache, which can scale to several gigabytes as sequence length and batch size increase. In this paper, we present \\textbf{PackKV}, a generic and efficient KV cache management framework optimized for long-context generation. %, which synergistically supports both latency-critical and throughput-critical inference scenarios. PackKV introduces novel lossy compression techniques specifically tailored to the characteristics of KV cache data, featuring a careful co-design of compression algorithms and system architecture. Our approach is compatible with the dynamically growing nature of the KV cache while preserving high computational efficiency. Experimental results show that, under the same and minimum accuracy drop as state-of-the-art quantization methods, PackKV achieves, on average, \\textbf{153.2}\\% higher memory reduction rate for the K cache and \\textbf{179.6}\\% for the V cache. Furthermore, PackKV delivers extremely high execution throughput, effectively eliminating decompression overhead and accelerating the matrix-vector multiplication operation. Specifically, PackKV achieves an average throughput improvement of \\textbf{75.7}\\% for K and \\textbf{171.7}\\% for V across A100 and RTX Pro 6000 GPUs, compared to cuBLAS matrix-vector multiplication kernels, while demanding less GPU memory bandwidth. Code available on https://github.com/BoJiang03/PackKV", "AI": {"tldr": "PackKV\u662f\u4e00\u4e2a\u9488\u5bf9\u957f\u4e0a\u4e0b\u6587\u751f\u6210\u7684KV\u7f13\u5b58\u7ba1\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u4e13\u95e8\u8bbe\u8ba1\u7684\u65e0\u635f\u538b\u7f29\u6280\u672f\uff0c\u5728\u4fdd\u6301\u7cbe\u5ea6\u7684\u540c\u65f6\u663e\u8457\u51cf\u5c11\u5185\u5b58\u5360\u7528\u5e76\u63d0\u5347\u8ba1\u7b97\u541e\u5410\u91cf\u3002", "motivation": "Transformer\u5927\u8bed\u8a00\u6a21\u578b\u7684\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\u9762\u4e34KV\u7f13\u5b58\u5185\u5b58\u5360\u7528\u8fc7\u5927\u7684\u6311\u6218\uff0c\u968f\u7740\u5e8f\u5217\u957f\u5ea6\u548c\u6279\u6b21\u5927\u5c0f\u589e\u52a0\uff0cKV\u7f13\u5b58\u53ef\u8fbe\u6570GB\uff0c\u9650\u5236\u4e86\u5b9e\u9645\u5e94\u7528\u3002", "method": "\u63d0\u51faPackKV\u6846\u67b6\uff0c\u9488\u5bf9KV\u7f13\u5b58\u6570\u636e\u7279\u6027\u8bbe\u8ba1\u4e13\u95e8\u7684\u538b\u7f29\u7b97\u6cd5\u548c\u7cfb\u7edf\u67b6\u6784\u534f\u540c\u8bbe\u8ba1\uff0c\u652f\u6301\u52a8\u6001\u589e\u957f\u7684KV\u7f13\u5b58\uff0c\u4fdd\u6301\u9ad8\u8ba1\u7b97\u6548\u7387\u3002", "result": "\u5728\u76f8\u540c\u7cbe\u5ea6\u635f\u5931\u4e0b\uff0c\u76f8\u6bd4\u73b0\u6709\u91cf\u5316\u65b9\u6cd5\uff0cPackKV\u5e73\u5747\u5b9e\u73b0K\u7f13\u5b58153.2%\u3001V\u7f13\u5b58179.6%\u7684\u5185\u5b58\u51cf\u5c11\u7387\uff1b\u5728A100\u548cRTX Pro 6000 GPU\u4e0a\uff0c\u76f8\u6bd4cuBLAS\u77e9\u9635\u5411\u91cf\u4e58\u6cd5\uff0c\u5e73\u5747\u541e\u5410\u91cf\u63d0\u5347K\u4e3a75.7%\u3001V\u4e3a171.7%\u3002", "conclusion": "PackKV\u662f\u4e00\u4e2a\u9ad8\u6548\u901a\u7528\u7684KV\u7f13\u5b58\u7ba1\u7406\u6846\u67b6\uff0c\u80fd\u6709\u6548\u89e3\u51b3\u957f\u4e0a\u4e0b\u6587\u751f\u6210\u4e2d\u7684\u5185\u5b58\u74f6\u9888\u95ee\u9898\uff0c\u540c\u65f6\u63d0\u4f9b\u9ad8\u8ba1\u7b97\u541e\u5410\u91cf\uff0c\u4e3a\u5b9e\u9645\u90e8\u7f72\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2512.23769", "categories": ["cs.SE", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.23769", "abs": "https://arxiv.org/abs/2512.23769", "authors": ["Ranit Debnath Akash", "Ashish Kumar", "Verya Monjezi", "Ashutosh Trivedi", "Gang", "Tan", "Saeid Tizpaz-Niari"], "title": "Uncovering Discrimination Clusters: Quantifying and Explaining Systematic Fairness Violations", "comment": "In 40th IEEE/ACM International Conference on Automated Software Engineering (ASE 2025)", "summary": "Fairness in algorithmic decision-making is often framed in terms of individual fairness, which requires that similar individuals receive similar outcomes. A system violates individual fairness if there exists a pair of inputs differing only in protected attributes (such as race or gender) that lead to significantly different outcomes-for example, one favorable and the other unfavorable. While this notion highlights isolated instances of unfairness, it fails to capture broader patterns of systematic or clustered discrimination that may affect entire subgroups. We introduce and motivate the concept of discrimination clustering, a generalization of individual fairness violations. Rather than detecting single counterfactual disparities, we seek to uncover regions of the input space where small perturbations in protected features lead to k-significantly distinct clusters of outcomes. That is, for a given input, we identify a local neighborhood-differing only in protected attributes-whose members' outputs separate into many distinct clusters. These clusters reveal significant arbitrariness in treatment solely based on protected attributes that help expose patterns of algorithmic bias that elude pairwise fairness checks. We present HyFair, a hybrid technique that combines formal symbolic analysis (via SMT and MILP solvers) to certify individual fairness with randomized search to discover discriminatory clusters. This combination enables both formal guarantees-when no counterexamples exist-and the detection of severe violations that are computationally challenging for symbolic methods alone. Given a set of inputs exhibiting high k-unfairness, we introduce a novel explanation method to generate interpretable, decision-tree-style artifacts. Our experiments demonstrate that HyFair outperforms state-of-the-art fairness verification and local explanation methods.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\"\u6b67\u89c6\u805a\u7c7b\"\u6982\u5ff5\uff0c\u6269\u5c55\u4e2a\u4f53\u516c\u5e73\u6027\u68c0\u6d4b\uff0c\u4e0d\u4ec5\u80fd\u53d1\u73b0\u5355\u4e2a\u53cd\u4e8b\u5b9e\u5dee\u5f02\uff0c\u8fd8\u80fd\u8bc6\u522b\u8f93\u5165\u7a7a\u95f4\u4e2d\u53d7\u4fdd\u62a4\u7279\u5f81\u5fae\u5c0f\u53d8\u5316\u5bfc\u81f4\u591a\u4e2a\u4e0d\u540c\u7ed3\u679c\u805a\u7c7b\u7684\u7cfb\u7edf\u6027\u6b67\u89c6\u6a21\u5f0f\u3002", "motivation": "\u4f20\u7edf\u4e2a\u4f53\u516c\u5e73\u6027\u53ea\u5173\u6ce8\u76f8\u4f3c\u4e2a\u4f53\u5e94\u83b7\u5f97\u76f8\u4f3c\u7ed3\u679c\uff0c\u4f46\u4ec5\u80fd\u68c0\u6d4b\u5b64\u7acb\u7684\u516c\u5e73\u6027\u8fdd\u53cd\uff0c\u65e0\u6cd5\u6355\u6349\u5f71\u54cd\u6574\u4e2a\u5b50\u7fa4\u7684\u7cfb\u7edf\u6027\u6216\u805a\u7c7b\u6b67\u89c6\u6a21\u5f0f\u3002\u9700\u8981\u66f4\u5168\u9762\u7684\u65b9\u6cd5\u6765\u63ed\u793a\u7b97\u6cd5\u504f\u89c1\u7684\u7ed3\u6784\u6027\u6a21\u5f0f\u3002", "method": "\u63d0\u51faHyFair\u6df7\u5408\u6280\u672f\uff1a\u7ed3\u5408\u5f62\u5f0f\u7b26\u53f7\u5206\u6790\uff08\u901a\u8fc7SMT\u548cMILP\u6c42\u89e3\u5668\uff09\u6765\u9a8c\u8bc1\u4e2a\u4f53\u516c\u5e73\u6027\uff0c\u4ee5\u53ca\u968f\u673a\u641c\u7d22\u6765\u53d1\u73b0\u6b67\u89c6\u805a\u7c7b\u3002\u5f15\u5165\u65b0\u9896\u7684\u89e3\u91ca\u65b9\u6cd5\uff0c\u4e3a\u9ad8k-\u4e0d\u516c\u5e73\u6027\u8f93\u5165\u751f\u6210\u53ef\u89e3\u91ca\u7684\u51b3\u7b56\u6811\u98ce\u683c\u89e3\u91ca\u3002", "result": "\u5b9e\u9a8c\u8868\u660eHyFair\u5728\u516c\u5e73\u6027\u9a8c\u8bc1\u548c\u5c40\u90e8\u89e3\u91ca\u65b9\u6cd5\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u6280\u672f\u3002\u8be5\u65b9\u6cd5\u65e2\u80fd\u63d0\u4f9b\u5f62\u5f0f\u5316\u4fdd\u8bc1\uff08\u5f53\u65e0\u53cd\u4f8b\u65f6\uff09\uff0c\u53c8\u80fd\u68c0\u6d4b\u7b26\u53f7\u65b9\u6cd5\u5355\u72ec\u96be\u4ee5\u8ba1\u7b97\u7684\u4e25\u91cd\u8fdd\u53cd\u60c5\u51b5\u3002", "conclusion": "\u6b67\u89c6\u805a\u7c7b\u6982\u5ff5\u6269\u5c55\u4e86\u4e2a\u4f53\u516c\u5e73\u6027\u6846\u67b6\uff0c\u80fd\u63ed\u793a\u7b97\u6cd5\u51b3\u7b56\u4e2d\u66f4\u5e7f\u6cdb\u7684\u7cfb\u7edf\u6027\u504f\u89c1\u6a21\u5f0f\u3002HyFair\u6df7\u5408\u65b9\u6cd5\u5728\u516c\u5e73\u6027\u9a8c\u8bc1\u548c\u89e3\u91ca\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4e3a\u68c0\u6d4b\u548c\u7406\u89e3\u7b97\u6cd5\u6b67\u89c6\u63d0\u4f9b\u4e86\u66f4\u5168\u9762\u7684\u5de5\u5177\u3002"}}
{"id": "2512.24511", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2512.24511", "abs": "https://arxiv.org/abs/2512.24511", "authors": ["Mikaila J. Gossman", "Avinash Maurya", "Bogdan Nicolae", "Jon C. Calhoun"], "title": "Understanding LLM Checkpoint/Restore I/O Strategies and Patterns", "comment": "SCA/HPCAsia 2026 Workshops: Supercomputing Asia and International Conference on High Performance Computing in the Asia Pacific Region Workshops", "summary": "As LLMs and foundation models scale, checkpoint/restore has become a critical pattern for training and inference. With 3D parallelism (tensor, pipeline, data), checkpointing involves many processes, each managing numerous tensors of varying shapes and sizes, that must be persisted frequently to stable storage (e.g., parallel file systems). This turns checkpoint/restore into a big-data I/O problem characterized by volume, variety, and velocity. The workflow must traverse the full storage stack -- from GPU memory through host memory and local storage to external repositories -- whose tiers differ by orders of magnitude in performance, creating bottlenecks under concurrency even with asynchronous flush/prefetch. Kernel-accelerated I/O libraries such as \\texttt{liburing} may mitigate these issues versus POSIX, but their effectiveness for LLM checkpointing remains underexplored. We develop microbenchmarks to quantify trade-offs when using \\texttt{liburing}, evaluating how aggregation, alignment, and I/O coalescing interact under buffered and direct I/O. We find that uncoalesced small-buffer operations halve throughput relative to synthetic workloads, while file system-aware aggregation restores bandwidth and reduces metadata overhead. Compared to state-of-the-art LLM checkpointing engines, our approach achieves up to $3.9\\times$ higher write throughput than DataStates-LLM and $7.6\\times$ higher than TorchSnapshot. These results highlight the need for aggregation and coalescing strategies that align with modern file systems and I/O backends.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86LLM\u8bad\u7ec3\u4e2d\u68c0\u67e5\u70b9/\u6062\u590d\u7684I/O\u6027\u80fd\u95ee\u9898\uff0c\u901a\u8fc7liburing\u5e93\u4f18\u5316\u5b9e\u73b0\u4e86\u6bd4\u73b0\u6709\u65b9\u6848\u6700\u9ad87.6\u500d\u7684\u541e\u5410\u91cf\u63d0\u5347", "motivation": "\u968f\u7740LLM\u548c\u57fa\u7840\u6a21\u578b\u89c4\u6a21\u6269\u5927\uff0c\u68c0\u67e5\u70b9/\u6062\u590d\u6210\u4e3a\u8bad\u7ec3\u548c\u63a8\u7406\u7684\u5173\u952e\u6a21\u5f0f\u3002\u57283D\u5e76\u884c\uff08\u5f20\u91cf\u3001\u6d41\u6c34\u7ebf\u3001\u6570\u636e\uff09\u67b6\u6784\u4e0b\uff0c\u68c0\u67e5\u70b9\u6d89\u53ca\u5927\u91cf\u8fdb\u7a0b\u7ba1\u7406\u5404\u79cd\u5f62\u72b6\u5927\u5c0f\u7684\u5f20\u91cf\uff0c\u9700\u8981\u9891\u7e41\u6301\u4e45\u5316\u5230\u7a33\u5b9a\u5b58\u50a8\uff0c\u8fd9\u5e26\u6765\u4e86\u5927\u6570\u636eI/O\u95ee\u9898\uff08\u6570\u636e\u91cf\u5927\u3001\u79cd\u7c7b\u591a\u3001\u9891\u7387\u9ad8\uff09\u3002\u5b58\u50a8\u6808\u5404\u5c42\u7ea7\u6027\u80fd\u5dee\u5f02\u5de8\u5927\uff0c\u5373\u4f7f\u4f7f\u7528\u5f02\u6b65\u5237\u65b0/\u9884\u53d6\u4e5f\u4f1a\u5728\u5e76\u53d1\u4e0b\u4ea7\u751f\u74f6\u9888\u3002", "method": "\u5f00\u53d1\u5fae\u57fa\u51c6\u6d4b\u8bd5\u6765\u91cf\u5316\u4f7f\u7528liburing\u5e93\u65f6\u7684\u6743\u8861\uff0c\u8bc4\u4f30\u805a\u5408\u3001\u5bf9\u9f50\u548cI/O\u5408\u5e76\u5728\u4e0d\u540cI/O\u6a21\u5f0f\u4e0b\u7684\u4ea4\u4e92\u6548\u679c\u3002\u7814\u7a76\u6587\u4ef6\u7cfb\u7edf\u611f\u77e5\u7684\u805a\u5408\u7b56\u7565\uff0c\u5e76\u4e0e\u73b0\u6709LLM\u68c0\u67e5\u70b9\u5f15\u64ce\u8fdb\u884c\u6bd4\u8f83\u3002", "result": "\u672a\u5408\u5e76\u7684\u5c0f\u7f13\u51b2\u533a\u64cd\u4f5c\u4f7f\u541e\u5410\u91cf\u76f8\u6bd4\u5408\u6210\u5de5\u4f5c\u8d1f\u8f7d\u51cf\u534a\uff0c\u800c\u6587\u4ef6\u7cfb\u7edf\u611f\u77e5\u7684\u805a\u5408\u6062\u590d\u4e86\u5e26\u5bbd\u5e76\u51cf\u5c11\u4e86\u5143\u6570\u636e\u5f00\u9500\u3002\u76f8\u6bd4\u6700\u5148\u8fdb\u7684LLM\u68c0\u67e5\u70b9\u5f15\u64ce\uff0c\u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e86\u6bd4DataStates-LLM\u9ad83.9\u500d\u7684\u5199\u5165\u541e\u5410\u91cf\uff0c\u6bd4TorchSnapshot\u9ad87.6\u500d\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\u9700\u8981\u5f00\u53d1\u4e0e\u73b0\u4ee3\u6587\u4ef6\u7cfb\u7edf\u548cI/O\u540e\u7aef\u5bf9\u9f50\u7684\u805a\u5408\u548c\u5408\u5e76\u7b56\u7565\uff0c\u4ee5\u4f18\u5316LLM\u68c0\u67e5\u70b9\u6027\u80fd\u3002liburing\u7b49\u5185\u6838\u52a0\u901fI/O\u5e93\u5728LLM\u68c0\u67e5\u70b9\u573a\u666f\u4e2d\u5177\u6709\u663e\u8457\u4f18\u52bf\u3002"}}
{"id": "2512.23780", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.23780", "abs": "https://arxiv.org/abs/2512.23780", "authors": ["Denesa Zyberaj", "Pascal Hirmer", "Marco Aiello", "Stefan Wagner"], "title": "Test Case Specification Techniques and System Testing Tools in the Automotive Industry: A Review", "comment": "This is the author accepted manuscript (AAM) of a paper accepted for publication in The Journal of Systems and Software (Elsevier). The final published version will be available via the journal", "summary": "The automotive domain is shifting to software-centric development to meet regulation, market pressure, and feature velocity. This shift increases embedded systems' complexity and strains testing capacity. Despite relevant standards, a coherent system-testing methodology that spans heterogeneous, legacy-constrained toolchains remains elusive, and practice often depends on individual expertise rather than a systematic strategy. We derive challenges and requirements from a systematic literature review (SLR), complemented by industry experience and practice. We map them to test case specification techniques and testing tools, evaluating their suitability for automotive testing using PRISMA. Our contribution is a curated catalog that supports technique/tool selection and can inform future testing frameworks and improvements. We synthesize nine recurring challenge areas across the life cycle, such as requirements quality and traceability, variability management, and toolchain fragmentation. We then provide a prioritized criteria catalog that recommends model-based planning, interoperable and traceable toolchains, requirements uplift, pragmatic automation and virtualization, targeted AI and formal methods, actionable metrics, and lightweight organizational practices.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u6c7d\u8f66\u8f6f\u4ef6\u6d4b\u8bd5\u65b9\u6cd5\u5b66\u6311\u6218\uff0c\u901a\u8fc7\u7cfb\u7edf\u6587\u732e\u7efc\u8ff0\u548c\u884c\u4e1a\u7ecf\u9a8c\u5206\u6790\uff0c\u5efa\u7acb\u6280\u672f/\u5de5\u5177\u9009\u62e9\u76ee\u5f55\uff0c\u63a8\u8350\u6a21\u578b\u5316\u89c4\u5212\u3001\u53ef\u4e92\u64cd\u4f5c\u5de5\u5177\u94fe\u7b49\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u6c7d\u8f66\u9886\u57df\u5411\u8f6f\u4ef6\u4e2d\u5fc3\u5f00\u53d1\u8f6c\u578b\uff0c\u5bfc\u81f4\u5d4c\u5165\u5f0f\u7cfb\u7edf\u590d\u6742\u6027\u589e\u52a0\uff0c\u6d4b\u8bd5\u80fd\u529b\u7d27\u5f20\u3002\u73b0\u6709\u6807\u51c6\u4e0b\u7f3a\u4e4f\u8de8\u5f02\u6784\u3001\u9057\u7559\u7ea6\u675f\u5de5\u5177\u94fe\u7684\u8fde\u8d2f\u7cfb\u7edf\u6d4b\u8bd5\u65b9\u6cd5\u5b66\uff0c\u5b9e\u8df5\u4f9d\u8d56\u4e2a\u4eba\u7ecf\u9a8c\u800c\u975e\u7cfb\u7edf\u7b56\u7565\u3002", "method": "\u901a\u8fc7\u7cfb\u7edf\u6587\u732e\u7efc\u8ff0(SLR)\u7ed3\u5408\u884c\u4e1a\u7ecf\u9a8c\uff0c\u8bc6\u522b\u6311\u6218\u548c\u9700\u6c42\uff0c\u6620\u5c04\u5230\u6d4b\u8bd5\u7528\u4f8b\u89c4\u8303\u6280\u672f\u548c\u6d4b\u8bd5\u5de5\u5177\uff0c\u4f7f\u7528PRISMA\u8bc4\u4f30\u5176\u5728\u6c7d\u8f66\u6d4b\u8bd5\u4e2d\u7684\u9002\u7528\u6027\u3002", "result": "\u5efa\u7acb\u4e86\u652f\u6301\u6280\u672f/\u5de5\u5177\u9009\u62e9\u7684\u7cbe\u9009\u76ee\u5f55\uff0c\u8bc6\u522b\u51fa\u751f\u547d\u5468\u671f\u4e2d\u7684\u4e5d\u4e2a\u91cd\u590d\u6311\u6218\u9886\u57df\uff08\u5982\u9700\u6c42\u8d28\u91cf\u3001\u53ef\u53d8\u6027\u7ba1\u7406\u3001\u5de5\u5177\u94fe\u788e\u7247\u5316\uff09\uff0c\u63d0\u4f9b\u4f18\u5148\u6807\u51c6\u76ee\u5f55\u3002", "conclusion": "\u63a8\u8350\u6a21\u578b\u5316\u89c4\u5212\u3001\u53ef\u4e92\u64cd\u4f5c\u548c\u53ef\u8ffd\u6eaf\u5de5\u5177\u94fe\u3001\u9700\u6c42\u63d0\u5347\u3001\u5b9e\u7528\u81ea\u52a8\u5316\u548c\u865a\u62df\u5316\u3001\u9488\u5bf9\u6027AI\u548c\u5f62\u5f0f\u5316\u65b9\u6cd5\u3001\u53ef\u64cd\u4f5c\u6307\u6807\u3001\u8f7b\u91cf\u7ea7\u7ec4\u7ec7\u5b9e\u8df5\u4f5c\u4e3a\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.24667", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2512.24667", "abs": "https://arxiv.org/abs/2512.24667", "authors": ["Mingyi Li", "Xiao Zhang", "Ruisheng Zheng", "Hongjian Shi", "Yuan Yuan", "Xiuzhen Cheng", "Dongxiao Yu"], "title": "Distributed Bilevel Optimization with Dual Pruning for Resource-limited Clients", "comment": null, "summary": "With the development of large-scale models, traditional distributed bilevel optimization algorithms cannot be applied directly in low-resource clients. The key reason lies in the excessive computation involved in optimizing both the lower- and upper-level functions. Thus, we present the first resource-adaptive distributed bilevel optimization framework with a second-order free hypergradient estimator, which allows each client to optimize the submodels adapted to the available resources. Due to the coupled influence of partial outer parameters x and inner parameters y, it's challenging to theoretically analyze the upper bound regarding the globally averaged hypergradient for full model parameters. The error bound of inner parameter also needs to be reformulated since the local partial training. The provable theorems show that both RABO and RAFBO can achieve an asymptotically optimal convergence rate of $O(1/\\sqrt{C_x^{\\ast}Q})$, which is dominated by the minimum coverage of the outer parameter $C_x^{\\ast}$. Extensive experiments on two different tasks demonstrate the effectiveness and computation efficiency of our proposed methods.", "AI": {"tldr": "\u63d0\u51fa\u9996\u4e2a\u8d44\u6e90\u81ea\u9002\u5e94\u7684\u5206\u5e03\u5f0f\u53cc\u5c42\u4f18\u5316\u6846\u67b6RABO/RAFBO\uff0c\u901a\u8fc7\u4e8c\u9636\u81ea\u7531\u8d85\u68af\u5ea6\u4f30\u8ba1\u5668\uff0c\u4f7f\u5ba2\u6237\u7aef\u80fd\u6839\u636e\u53ef\u7528\u8d44\u6e90\u4f18\u5316\u5b50\u6a21\u578b\uff0c\u8fbe\u5230\u6e10\u8fd1\u6700\u4f18\u6536\u655b\u7387\u3002", "motivation": "\u968f\u7740\u5927\u89c4\u6a21\u6a21\u578b\u53d1\u5c55\uff0c\u4f20\u7edf\u5206\u5e03\u5f0f\u53cc\u5c42\u4f18\u5316\u7b97\u6cd5\u65e0\u6cd5\u76f4\u63a5\u5e94\u7528\u4e8e\u4f4e\u8d44\u6e90\u5ba2\u6237\u7aef\uff0c\u4e3b\u8981\u539f\u56e0\u662f\u540c\u65f6\u4f18\u5316\u4e0a\u4e0b\u5c42\u51fd\u6570\u6d89\u53ca\u8fc7\u591a\u8ba1\u7b97\u3002", "method": "\u63d0\u51fa\u8d44\u6e90\u81ea\u9002\u5e94\u5206\u5e03\u5f0f\u53cc\u5c42\u4f18\u5316\u6846\u67b6\uff0c\u5305\u542b\u4e8c\u9636\u81ea\u7531\u8d85\u68af\u5ea6\u4f30\u8ba1\u5668\uff0c\u5141\u8bb8\u5ba2\u6237\u7aef\u6839\u636e\u53ef\u7528\u8d44\u6e90\u4f18\u5316\u5b50\u6a21\u578b\u3002\u7531\u4e8e\u90e8\u5206\u5916\u5c42\u53c2\u6570x\u548c\u5185\u5c42\u53c2\u6570y\u7684\u8026\u5408\u5f71\u54cd\uff0c\u7406\u8bba\u5206\u6790\u5168\u5c40\u5e73\u5747\u8d85\u68af\u5ea6\u4e0a\u754c\u5177\u6709\u6311\u6218\u6027\u3002", "result": "\u7406\u8bba\u8bc1\u660eRABO\u548cRAFBO\u90fd\u80fd\u8fbe\u5230\u6e10\u8fd1\u6700\u4f18\u6536\u655b\u7387$O(1/\\sqrt{C_x^{\\ast}Q})$\uff0c\u5176\u4e2d$C_x^{\\ast}$\u4e3a\u5916\u5c42\u53c2\u6570\u7684\u6700\u5c0f\u8986\u76d6\u5ea6\u3002\u5728\u4e24\u4e2a\u4e0d\u540c\u4efb\u52a1\u4e0a\u7684\u5b9e\u9a8c\u8bc1\u660e\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u548c\u8ba1\u7b97\u6548\u7387\u3002", "conclusion": "\u63d0\u51fa\u7684\u8d44\u6e90\u81ea\u9002\u5e94\u5206\u5e03\u5f0f\u53cc\u5c42\u4f18\u5316\u6846\u67b6\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u5728\u4f4e\u8d44\u6e90\u73af\u5883\u4e0b\u7684\u8ba1\u7b97\u74f6\u9888\uff0c\u901a\u8fc7\u7406\u8bba\u5206\u6790\u548c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u548c\u9ad8\u6548\u6027\u3002"}}
{"id": "2512.23782", "categories": ["cs.SE", "cs.CY"], "pdf": "https://arxiv.org/pdf/2512.23782", "abs": "https://arxiv.org/abs/2512.23782", "authors": ["Kessia Nepomuceno", "Fabio Petrillo"], "title": "A Systematic Mapping on Software Fairness: Focus, Trends and Industrial Context", "comment": null, "summary": "Context: Fairness in systems has emerged as a critical concern in software engineering, garnering increasing attention as the field has advanced in recent years. While several guidelines have been proposed to address fairness, achieving a comprehensive understanding of research solutions for ensuring fairness in software systems remains challenging. Objectives: This paper presents a systematic literature mapping to explore and categorize current advancements in fairness solutions within software engineering, focusing on three key dimensions: research trends, research focus, and viability in industrial contexts. Methods: We develop a classification framework to organize research on software fairness from a fresh perspective, applying it to 95 selected studies and analyzing their potential for industrial adoption. Results: Our findings reveal that software fairness research is expanding, yet it remains heavily focused on methods and algorithms. It primarily focuses on post-processing and group fairness, with less emphasis on early-stage interventions, individual fairness metrics, and understanding bias root causes. Additionally fairness research remains largely academic, with limited industry collaboration and low to medium Technology Readiness Level (TRL), indicating that industrial transferability remains distant. Conclusion: Our results underscore the need to incorporate fairness considerations across all stages of the software development life-cycle and to foster greater collaboration between academia and industry. This analysis provides a comprehensive overview of the field, offering a foundation to guide future research and practical applications of fairness in software systems.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u7cfb\u7edf\u6587\u732e\u6620\u5c04\uff0c\u5206\u6790\u4e86\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u516c\u5e73\u6027\u7814\u7a76\u7684\u73b0\u72b6\uff0c\u53d1\u73b0\u7814\u7a76\u4e3b\u8981\u96c6\u4e2d\u5728\u7b97\u6cd5\u65b9\u6cd5\u3001\u540e\u5904\u7406\u548c\u7fa4\u4f53\u516c\u5e73\u6027\uff0c\u7f3a\u4e4f\u65e9\u671f\u5e72\u9884\u3001\u4e2a\u4f53\u516c\u5e73\u6027\u6307\u6807\u548c\u5de5\u4e1a\u5e94\u7528\u3002", "motivation": "\u968f\u7740\u8f6f\u4ef6\u5de5\u7a0b\u9886\u57df\u7684\u53d1\u5c55\uff0c\u7cfb\u7edf\u516c\u5e73\u6027\u5df2\u6210\u4e3a\u5173\u952e\u5173\u6ce8\u70b9\u3002\u5c3d\u7ba1\u5df2\u6709\u4e00\u4e9b\u6307\u5bfc\u539f\u5219\uff0c\u4f46\u5bf9\u8f6f\u4ef6\u7cfb\u7edf\u4e2d\u786e\u4fdd\u516c\u5e73\u6027\u7684\u7814\u7a76\u89e3\u51b3\u65b9\u6848\u4ecd\u7f3a\u4e4f\u5168\u9762\u7406\u89e3\u3002\u672c\u6587\u65e8\u5728\u63a2\u7d22\u548c\u5206\u7c7b\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u516c\u5e73\u6027\u89e3\u51b3\u65b9\u6848\u7684\u5f53\u524d\u8fdb\u5c55\u3002", "method": "\u91c7\u7528\u7cfb\u7edf\u6587\u732e\u6620\u5c04\u65b9\u6cd5\uff0c\u5f00\u53d1\u4e86\u4e00\u4e2a\u5206\u7c7b\u6846\u67b6\uff0c\u4ece\u65b0\u89c6\u89d2\u7ec4\u7ec7\u8f6f\u4ef6\u516c\u5e73\u6027\u7814\u7a76\uff0c\u5e94\u7528\u4e8e95\u7bc7\u9009\u5b9a\u7814\u7a76\uff0c\u5e76\u5206\u6790\u5176\u5de5\u4e1a\u91c7\u7528\u6f5c\u529b\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff1a\u8f6f\u4ef6\u516c\u5e73\u6027\u7814\u7a76\u6b63\u5728\u6269\u5c55\uff0c\u4f46\u4e3b\u8981\u96c6\u4e2d\u5728\u65b9\u6cd5\u548c\u7b97\u6cd5\u4e0a\uff1b\u4e3b\u8981\u5173\u6ce8\u540e\u5904\u7406\u548c\u7fa4\u4f53\u516c\u5e73\u6027\uff0c\u8f83\u5c11\u5173\u6ce8\u65e9\u671f\u5e72\u9884\u3001\u4e2a\u4f53\u516c\u5e73\u6027\u6307\u6807\u548c\u504f\u89c1\u6839\u6e90\u7406\u89e3\uff1b\u7814\u7a76\u4e3b\u8981\u5728\u5b66\u672f\u754c\uff0c\u5de5\u4e1a\u5408\u4f5c\u6709\u9650\uff0c\u6280\u672f\u5c31\u7eea\u6c34\u5e73\u4f4e\u5230\u4e2d\u7b49\uff0c\u5de5\u4e1a\u53ef\u8f6c\u79fb\u6027\u4ecd\u9065\u8fdc\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u5f3a\u8c03\u9700\u8981\u5728\u8f6f\u4ef6\u5f00\u53d1\u751f\u547d\u5468\u671f\u7684\u6240\u6709\u9636\u6bb5\u7eb3\u5165\u516c\u5e73\u6027\u8003\u8651\uff0c\u5e76\u4fc3\u8fdb\u5b66\u672f\u754c\u4e0e\u5de5\u4e1a\u754c\u4e4b\u95f4\u66f4\u7d27\u5bc6\u7684\u5408\u4f5c\u3002\u8be5\u5206\u6790\u63d0\u4f9b\u4e86\u8be5\u9886\u57df\u7684\u5168\u9762\u6982\u8ff0\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u548c\u8f6f\u4ef6\u7cfb\u7edf\u4e2d\u516c\u5e73\u6027\u7684\u5b9e\u9645\u5e94\u7528\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2512.24914", "categories": ["cs.DC", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.24914", "abs": "https://arxiv.org/abs/2512.24914", "authors": ["Vinoth Punniyamoorthy", "Akash Kumar Agarwal", "Bikesh Kumar", "Abhirup Mazumder", "Kabilan Kannan", "Sumit Saha"], "title": "AI-Driven Cloud Resource Optimization for Multi-Cluster Environments", "comment": null, "summary": "Modern cloud-native systems increasingly rely on multi-cluster deployments to support scalability, resilience, and geographic distribution. However, existing resource management approaches remain largely reactive and cluster-centric, limiting their ability to optimize system-wide behavior under dynamic workloads. These limitations result in inefficient resource utilization, delayed adaptation, and increased operational overhead across distributed environments. This paper presents an AI-driven framework for adaptive resource optimization in multi-cluster cloud systems. The proposed approach integrates predictive learning, policy-aware decision-making, and continuous feedback to enable proactive and coordinated resource management across clusters. By analyzing cross-cluster telemetry and historical execution patterns, the framework dynamically adjusts resource allocation to balance performance, cost, and reliability objectives. A prototype implementation demonstrates improved resource efficiency, faster stabilization during workload fluctuations, and reduced performance variability compared to conventional reactive approaches. The results highlight the effectiveness of intelligent, self-adaptive infrastructure management as a key enabler for scalable and resilient cloud platforms.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eAI\u7684\u591a\u96c6\u7fa4\u4e91\u7cfb\u7edf\u81ea\u9002\u5e94\u8d44\u6e90\u4f18\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u9884\u6d4b\u5b66\u4e60\u548c\u534f\u8c03\u7ba1\u7406\u63d0\u5347\u8d44\u6e90\u6548\u7387\u4e0e\u7cfb\u7edf\u7a33\u5b9a\u6027", "motivation": "\u73b0\u4ee3\u4e91\u539f\u751f\u7cfb\u7edf\u4f9d\u8d56\u591a\u96c6\u7fa4\u90e8\u7f72\u5b9e\u73b0\u53ef\u6269\u5c55\u6027\u548c\u5f39\u6027\uff0c\u4f46\u73b0\u6709\u8d44\u6e90\u7ba1\u7406\u65b9\u6cd5\u591a\u4e3a\u53cd\u5e94\u5f0f\u548c\u96c6\u7fa4\u4e2d\u5fc3\u5316\uff0c\u5bfc\u81f4\u8d44\u6e90\u5229\u7528\u7387\u4f4e\u3001\u9002\u5e94\u5ef6\u8fdf\u548c\u8fd0\u7ef4\u5f00\u9500\u5927", "method": "\u96c6\u6210\u9884\u6d4b\u5b66\u4e60\u3001\u7b56\u7565\u611f\u77e5\u51b3\u7b56\u548c\u6301\u7eed\u53cd\u9988\u7684AI\u9a71\u52a8\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u6790\u8de8\u96c6\u7fa4\u9065\u6d4b\u6570\u636e\u548c\u5386\u53f2\u6267\u884c\u6a21\u5f0f\uff0c\u52a8\u6001\u8c03\u6574\u8d44\u6e90\u5206\u914d\u4ee5\u5e73\u8861\u6027\u80fd\u3001\u6210\u672c\u548c\u53ef\u9760\u6027\u76ee\u6807", "result": "\u539f\u578b\u5b9e\u73b0\u663e\u793a\u76f8\u6bd4\u4f20\u7edf\u53cd\u5e94\u5f0f\u65b9\u6cd5\uff0c\u8d44\u6e90\u6548\u7387\u63d0\u5347\u3001\u5de5\u4f5c\u8d1f\u8f7d\u6ce2\u52a8\u65f6\u7a33\u5b9a\u66f4\u5feb\u3001\u6027\u80fd\u53d8\u5f02\u6027\u964d\u4f4e", "conclusion": "\u667a\u80fd\u81ea\u9002\u5e94\u57fa\u7840\u8bbe\u65bd\u7ba1\u7406\u662f\u5b9e\u73b0\u53ef\u6269\u5c55\u548c\u5f39\u6027\u4e91\u5e73\u53f0\u7684\u5173\u952e\u4f7f\u80fd\u6280\u672f"}}
{"id": "2512.23844", "categories": ["cs.SE", "cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2512.23844", "abs": "https://arxiv.org/abs/2512.23844", "authors": ["Tao Dong", "Harini Sampath", "Ja Young Lee", "Sherry Y. Shi", "Andrew Macvean"], "title": "From Correctness to Collaboration: Toward a Human-Centered Framework for Evaluating AI Agent Behavior in Software Engineering", "comment": null, "summary": "As Large Language Models (LLMs) evolve from code generators into collaborative partners for software engineers, our methods for evaluation are lagging. Current benchmarks, focused on code correctness, fail to capture the nuanced, interactive behaviors essential for successful human-AI partnership. To bridge this evaluation gap, this paper makes two core contributions. First, we present a foundational taxonomy of desirable agent behaviors for enterprise software engineering, derived from an analysis of 91 sets of user-defined agent rules. This taxonomy defines four key expectations of agent behavior: Adhere to Standards and Processes, Ensure Code Quality and Reliability, Solving Problems Effectively, and Collaborating with the User.\n  Second, recognizing that these expectations are not static, we introduce the Context-Adaptive Behavior (CAB) Framework. This emerging framework reveals how behavioral expectations shift along two empirically-derived axes: the Time Horizon (from immediate needs to future ideals), established through interviews with 15 expert engineers, and the Type of Work (from enterprise production to rapid prototyping, for example), identified through a prompt analysis of a prototyping agent. Together, these contributions offer a human-centered foundation for designing and evaluating the next generation of AI agents, moving the field's focus from the correctness of generated code toward the dynamics of true collaborative intelligence.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u8bc4\u4f30LLM\u4f5c\u4e3a\u8f6f\u4ef6\u5de5\u7a0b\u534f\u4f5c\u4f19\u4f34\u7684\u65b0\u6846\u67b6\uff0c\u5305\u62ec\u884c\u4e3a\u5206\u7c7b\u6cd5\u548c\u4e0a\u4e0b\u6587\u81ea\u9002\u5e94\u884c\u4e3a\u6846\u67b6\uff0c\u4ee5\u5f25\u8865\u5f53\u524d\u4ec5\u5173\u6ce8\u4ee3\u7801\u6b63\u786e\u6027\u7684\u8bc4\u4f30\u4e0d\u8db3\u3002", "motivation": "\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4ece\u4ee3\u7801\u751f\u6210\u5668\u6f14\u53d8\u4e3a\u8f6f\u4ef6\u5de5\u7a0b\u5e08\u7684\u534f\u4f5c\u4f19\u4f34\uff0c\u5f53\u524d\u7684\u8bc4\u4f30\u65b9\u6cd5\u6ede\u540e\u3002\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u4ec5\u5173\u6ce8\u4ee3\u7801\u6b63\u786e\u6027\uff0c\u672a\u80fd\u6355\u6349\u6210\u529f\u4eba\u673a\u534f\u4f5c\u6240\u9700\u7684\u7ec6\u5fae\u4ea4\u4e92\u884c\u4e3a\u3002", "method": "1. \u5206\u679091\u7ec4\u7528\u6237\u5b9a\u4e49\u7684\u4ee3\u7406\u89c4\u5219\uff0c\u63d0\u51fa\u4f01\u4e1a\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u7406\u60f3\u4ee3\u7406\u884c\u4e3a\u7684\u57fa\u7840\u5206\u7c7b\u6cd5\uff1b2. \u5f15\u5165\u4e0a\u4e0b\u6587\u81ea\u9002\u5e94\u884c\u4e3a\u6846\u67b6\uff0c\u63ed\u793a\u884c\u4e3a\u671f\u671b\u5982\u4f55\u6cbf\u4e24\u4e2a\u7ecf\u9a8c\u63a8\u5bfc\u7684\u8f74\u53d8\u5316\uff1a\u65f6\u95f4\u8303\u56f4\u548c\u4efb\u52a1\u7c7b\u578b\u3002", "result": "\u5efa\u7acb\u4e86\u5305\u542b\u56db\u4e2a\u5173\u952e\u671f\u671b\u7684\u884c\u4e3a\u5206\u7c7b\u6cd5\uff1a\u9075\u5faa\u6807\u51c6\u548c\u6d41\u7a0b\u3001\u786e\u4fdd\u4ee3\u7801\u8d28\u91cf\u548c\u53ef\u9760\u6027\u3001\u6709\u6548\u89e3\u51b3\u95ee\u9898\u3001\u4e0e\u7528\u6237\u534f\u4f5c\u3002\u540c\u65f6\u5f00\u53d1\u4e86CAB\u6846\u67b6\uff0c\u663e\u793a\u884c\u4e3a\u671f\u671b\u5982\u4f55\u968f\u4e0a\u4e0b\u6587\u52a8\u6001\u53d8\u5316\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u8bbe\u8ba1\u548c\u8bc4\u4f30\u4e0b\u4e00\u4ee3AI\u4ee3\u7406\u63d0\u4f9b\u4e86\u4ee5\u4eba\u4e3a\u672c\u7684\u57fa\u7840\uff0c\u5c06\u9886\u57df\u7126\u70b9\u4ece\u751f\u6210\u4ee3\u7801\u7684\u6b63\u786e\u6027\u8f6c\u5411\u771f\u6b63\u7684\u534f\u4f5c\u667a\u80fd\u52a8\u6001\uff0c\u586b\u8865\u4e86\u5f53\u524d\u8bc4\u4f30\u65b9\u6cd5\u7684\u7a7a\u767d\u3002"}}
{"id": "2512.25059", "categories": ["cs.DC", "cs.LG", "cs.NI"], "pdf": "https://arxiv.org/pdf/2512.25059", "abs": "https://arxiv.org/abs/2512.25059", "authors": ["Wei Wang", "Nengneng Yu", "Sixian Xiong", "Zaoxing Liu"], "title": "Reliable and Resilient Collective Communication Library for LLM Training and Serving", "comment": null, "summary": "Modern ML training and inference now span tens to tens of thousands of GPUs, where network faults can waste 10--15\\% of GPU hours due to slow recovery. Common network errors and link fluctuations trigger timeouts that often terminate entire jobs, forcing expensive checkpoint rollback during training and request reprocessing during inference. We present R$^2$CCL, a fault-tolerant communication library that provides lossless, low-overhead failover by exploiting multi-NIC hardware. R$^2$CCL performs rapid connection migration, bandwidth-aware load redistribution, and resilient collective algorithms to maintain progress under failures. We evaluate R$^2$CCL on two 8-GPU H100 InfiniBand servers and via large-scale ML simulators modeling hundreds of GPUs with diverse failure patterns. Experiments show that R$^2$CCL is highly robust to NIC failures, incurring less than 1\\% training and less than 3\\% inference overheads. R$^2$CCL outperforms baselines AdapCC and DejaVu by 12.18$\\times$ and 47$\\times$, respectively.", "AI": {"tldr": "R\u00b2CCL\u662f\u4e00\u4e2a\u5bb9\u9519\u901a\u4fe1\u5e93\uff0c\u5229\u7528\u591aNIC\u786c\u4ef6\u5b9e\u73b0\u65e0\u635f\u3001\u4f4e\u5f00\u9500\u7684\u6545\u969c\u8f6c\u79fb\uff0c\u663e\u8457\u51cf\u5c11GPU\u8bad\u7ec3\u548c\u63a8\u7406\u4e2d\u7684\u7f51\u7edc\u6545\u969c\u6062\u590d\u65f6\u95f4\u3002", "motivation": "\u73b0\u4ee3ML\u8bad\u7ec3\u548c\u63a8\u7406\u6d89\u53ca\u5927\u91cfGPU\uff0c\u7f51\u7edc\u6545\u969c\u4f1a\u5bfc\u81f410-15%\u7684GPU\u65f6\u95f4\u6d6a\u8d39\u5728\u7f13\u6162\u7684\u6062\u590d\u4e0a\u3002\u5e38\u89c1\u7684\u7f51\u7edc\u9519\u8bef\u548c\u94fe\u8def\u6ce2\u52a8\u4f1a\u89e6\u53d1\u8d85\u65f6\uff0c\u5bfc\u81f4\u6574\u4e2a\u4f5c\u4e1a\u7ec8\u6b62\uff0c\u8feb\u4f7f\u8bad\u7ec3\u65f6\u8fdb\u884c\u6602\u8d35\u7684\u68c0\u67e5\u70b9\u56de\u6eda\u548c\u63a8\u7406\u65f6\u8bf7\u6c42\u91cd\u65b0\u5904\u7406\u3002", "method": "R\u00b2CCL\u901a\u8fc7\u5229\u7528\u591aNIC\u786c\u4ef6\uff0c\u6267\u884c\u5feb\u901f\u8fde\u63a5\u8fc1\u79fb\u3001\u5e26\u5bbd\u611f\u77e5\u8d1f\u8f7d\u91cd\u65b0\u5206\u914d\u548c\u5f39\u6027\u96c6\u4f53\u7b97\u6cd5\uff0c\u5728\u6545\u969c\u4e0b\u4fdd\u6301\u8fdb\u5c55\u3002\u5b83\u63d0\u4f9b\u65e0\u635f\u3001\u4f4e\u5f00\u9500\u7684\u6545\u969c\u8f6c\u79fb\u80fd\u529b\u3002", "result": "R\u00b2CCL\u5bf9NIC\u6545\u969c\u5177\u6709\u9ad8\u5ea6\u9c81\u68d2\u6027\uff0c\u8bad\u7ec3\u5f00\u9500\u5c0f\u4e8e1%\uff0c\u63a8\u7406\u5f00\u9500\u5c0f\u4e8e3%\u3002\u57288-GPU H100 InfiniBand\u670d\u52a1\u5668\u548c\u6a21\u62df\u6570\u767e\u4e2aGPU\u7684\u5927\u89c4\u6a21ML\u6a21\u62df\u5668\u4e0a\u8bc4\u4f30\uff0cR\u00b2CCL\u5206\u522b\u6bd4\u57fa\u7ebfAdapCC\u548cDejaVu\u5feb12.18\u500d\u548c47\u500d\u3002", "conclusion": "R\u00b2CCL\u901a\u8fc7\u9ad8\u6548\u7684\u6545\u969c\u8f6c\u79fb\u673a\u5236\u663e\u8457\u51cf\u5c11\u4e86ML\u8bad\u7ec3\u548c\u63a8\u7406\u4e2d\u7684\u7f51\u7edc\u6545\u969c\u6062\u590d\u5f00\u9500\uff0c\u63d0\u9ad8\u4e86GPU\u5229\u7528\u7387\u548c\u7cfb\u7edf\u53ef\u9760\u6027\u3002"}}
{"id": "2512.23875", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.23875", "abs": "https://arxiv.org/abs/2512.23875", "authors": ["Mohsen Hesamolhokama", "Behnam Rohani", "Amirahmad Shafiee", "MohammadAmin Fazli", "Jafar Habibi"], "title": "From Illusion to Insight: Change-Aware File-Level Software Defect Prediction Using Agentic AI", "comment": null, "summary": "Much of the reported progress in file-level software defect prediction (SDP) is, in reality, nothing but an illusion of accuracy. Over the last decades, machine learning and deep learning models have reported increasing performance across software versions. However, since most files persist across releases and retain their defect labels, standard evaluation rewards label-persistence bias rather than reasoning about code changes. To address this issue, we reformulate SDP as a change-aware prediction task, in which models reason over code changes of a file within successive project versions, rather than relying on static file snapshots. Building on this formulation, we propose an LLM-driven, change-aware, multi-agent debate framework. Our experiments on multiple PROMISE projects show that traditional models achieve inflated F1, while failing on rare but critical defect-transition cases. In contrast, our change-aware reasoning and multi-agent debate framework yields more balanced performance across evolution subsets and significantly improves sensitivity to defect introductions. These results highlight fundamental flaws in current SDP evaluation practices and emphasize the need for change-aware reasoning in practical defect prediction. The source code is publicly available.", "AI": {"tldr": "\u8be5\u8bba\u6587\u6307\u51fa\u4f20\u7edf\u6587\u4ef6\u7ea7\u8f6f\u4ef6\u7f3a\u9677\u9884\u6d4b\u5b58\u5728\u51c6\u786e\u7387\u5e7b\u89c9\uff0c\u63d0\u51fa\u57fa\u4e8e\u4ee3\u7801\u53d8\u66f4\u7684\u9884\u6d4b\u65b9\u6cd5\u548cLLM\u9a71\u52a8\u7684\u591a\u667a\u80fd\u4f53\u8fa9\u8bba\u6846\u67b6\uff0c\u663e\u8457\u63d0\u5347\u5bf9\u7f3a\u9677\u5f15\u5165\u7684\u654f\u611f\u6027\u3002", "motivation": "\u4f20\u7edf\u8f6f\u4ef6\u7f3a\u9677\u9884\u6d4b\u65b9\u6cd5\u5b58\u5728\u4e25\u91cd\u95ee\u9898\uff1a\u5927\u591a\u6570\u6587\u4ef6\u5728\u591a\u4e2a\u7248\u672c\u4e2d\u6301\u7eed\u5b58\u5728\u5e76\u4fdd\u6301\u7f3a\u9677\u6807\u7b7e\uff0c\u6807\u51c6\u8bc4\u4f30\u65b9\u6cd5\u5956\u52b1\u7684\u662f\u6807\u7b7e\u6301\u7eed\u6027\u504f\u5dee\u800c\u975e\u5bf9\u4ee3\u7801\u53d8\u66f4\u7684\u63a8\u7406\uff0c\u5bfc\u81f4\u62a5\u544a\u7684\u6027\u80fd\u63d0\u5347\u5b9e\u9645\u4e0a\u662f\u51c6\u786e\u7387\u5e7b\u89c9\u3002", "method": "1. \u5c06\u8f6f\u4ef6\u7f3a\u9677\u9884\u6d4b\u91cd\u65b0\u5b9a\u4e49\u4e3a\u53d8\u66f4\u611f\u77e5\u7684\u9884\u6d4b\u4efb\u52a1\uff0c\u6a21\u578b\u9700\u8981\u5728\u8fde\u7eed\u9879\u76ee\u7248\u672c\u4e2d\u63a8\u7406\u6587\u4ef6\u7684\u4ee3\u7801\u53d8\u66f4\uff0c\u800c\u975e\u4f9d\u8d56\u9759\u6001\u6587\u4ef6\u5feb\u7167\uff1b2. \u63d0\u51faLLM\u9a71\u52a8\u7684\u3001\u53d8\u66f4\u611f\u77e5\u7684\u591a\u667a\u80fd\u4f53\u8fa9\u8bba\u6846\u67b6\u3002", "result": "\u5728\u591a\u4e2aPROMISE\u9879\u76ee\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff1a\u4f20\u7edf\u6a21\u578b\u5728F1\u5206\u6570\u4e0a\u8868\u73b0\u865a\u9ad8\uff0c\u4f46\u5728\u5173\u952e\u7684\u7f3a\u9677\u8f6c\u6362\u6848\u4f8b\u4e0a\u5931\u8d25\uff1b\u800c\u53d8\u66f4\u611f\u77e5\u63a8\u7406\u548c\u591a\u667a\u80fd\u4f53\u8fa9\u8bba\u6846\u67b6\u5728\u4e0d\u540c\u6f14\u5316\u5b50\u96c6\u4e0a\u8868\u73b0\u66f4\u5747\u8861\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u5bf9\u7f3a\u9677\u5f15\u5165\u7684\u654f\u611f\u6027\u3002", "conclusion": "\u5f53\u524d\u8f6f\u4ef6\u7f3a\u9677\u9884\u6d4b\u8bc4\u4f30\u5b9e\u8df5\u5b58\u5728\u6839\u672c\u6027\u7f3a\u9677\uff0c\u9700\u8981\u5728\u5b9e\u8df5\u4e2d\u91c7\u7528\u53d8\u66f4\u611f\u77e5\u7684\u63a8\u7406\u65b9\u6cd5\u3002\u63d0\u51fa\u7684\u53d8\u66f4\u611f\u77e5\u591a\u667a\u80fd\u4f53\u8fa9\u8bba\u6846\u67b6\u4e3a\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6848\u3002"}}
{"id": "2512.23982", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.23982", "abs": "https://arxiv.org/abs/2512.23982", "authors": ["Hung-Fu Chang", "MohammadShokrolah Shirazi", "Lizhou Cao", "Supannika Koolmanojwong Mobasser"], "title": "Coding With AI: From a Reflection on Industrial Practices to Future Computer Science and Software Engineering Education", "comment": "21 pages, 5 figures", "summary": "Recent advances in large language models (LLMs) have introduced new paradigms in software development, including vibe coding, AI-assisted coding, and agentic coding, fundamentally reshaping how software is designed, implemented, and maintained. Prior research has primarily examined AI-based coding at the individual level or in educational settings, leaving industrial practitioners' perspectives underexplored. This paper addresses this gap by investigating how LLM coding tools are used in professional practice, the associated concerns and risks, and the resulting transformations in development workflows, with particular attention to implications for computing education. We conducted a qualitative analysis of 57 curated YouTube videos published between late 2024 and 2025, capturing reflections and experiences shared by practitioners. Following a filtering and quality assessment process, the selected sources were analyzed to compare LLM-based and traditional programming, identify emerging risks, and characterize evolving workflows. Our findings reveal definitions of AI-based coding practices, notable productivity gains, and lowered barriers to entry. Practitioners also report a shift in development bottlenecks toward code review and concerns regarding code quality, maintainability, security vulnerabilities, ethical issues, erosion of foundational problem-solving skills, and insufficient preparation of entry-level engineers. Building on these insights, we discuss implications for computer science and software engineering education and argue for curricular shifts toward problem-solving, architectural thinking, code review, and early project-based learning that integrates LLM tools. This study offers an industry-grounded perspective on AI-based coding and provides guidance for aligning educational practices with rapidly evolving professional realities.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7\u5206\u679057\u4e2aYouTube\u89c6\u9891\uff0c\u63a2\u8ba8\u4e86LLM\u7f16\u7801\u5de5\u5177\u5728\u4e13\u4e1a\u5b9e\u8df5\u4e2d\u7684\u5e94\u7528\u3001\u76f8\u5173\u98ce\u9669\u4ee5\u53ca\u5bf9\u8f6f\u4ef6\u5f00\u53d1\u5de5\u4f5c\u6d41\u7a0b\u7684\u5f71\u54cd\uff0c\u7279\u522b\u5173\u6ce8\u5bf9\u8ba1\u7b97\u673a\u6559\u80b2\u7684\u542f\u793a\u3002", "motivation": "\u5148\u524d\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u4e2a\u4f53\u5c42\u9762\u6216\u6559\u80b2\u73af\u5883\u4e2d\u7684AI\u7f16\u7801\uff0c\u7f3a\u4e4f\u5bf9\u5de5\u4e1a\u4ece\u4e1a\u8005\u89c6\u89d2\u7684\u6df1\u5165\u63a2\u7d22\u3002\u672c\u7814\u7a76\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u4e86\u89e3LLM\u7f16\u7801\u5de5\u5177\u5728\u4e13\u4e1a\u5b9e\u8df5\u4e2d\u7684\u5b9e\u9645\u5e94\u7528\u3001\u76f8\u5173\u98ce\u9669\u548c\u62c5\u5fe7\uff0c\u4ee5\u53ca\u5f00\u53d1\u5de5\u4f5c\u6d41\u7a0b\u7684\u8f6c\u53d8\u3002", "method": "\u5bf92024\u5e74\u672b\u81f32025\u5e74\u95f4\u53d1\u5e03\u768457\u4e2a\u7cbe\u9009YouTube\u89c6\u9891\u8fdb\u884c\u5b9a\u6027\u5206\u6790\uff0c\u8fd9\u4e9b\u89c6\u9891\u8bb0\u5f55\u4e86\u4ece\u4e1a\u8005\u7684\u53cd\u601d\u548c\u7ecf\u9a8c\u3002\u7ecf\u8fc7\u7b5b\u9009\u548c\u8d28\u91cf\u8bc4\u4f30\u540e\uff0c\u5206\u6790\u6bd4\u8f83\u4e86\u57fa\u4e8eLLM\u7684\u7f16\u7a0b\u4e0e\u4f20\u7edf\u7f16\u7a0b\uff0c\u8bc6\u522b\u4e86\u65b0\u5174\u98ce\u9669\uff0c\u5e76\u63cf\u8ff0\u4e86\u4e0d\u65ad\u6f14\u53d8\u7684\u5de5\u4f5c\u6d41\u7a0b\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff1a1\uff09\u5b9a\u4e49\u4e86AI\u7f16\u7801\u5b9e\u8df5\uff1b2\uff09\u663e\u8457\u7684\u751f\u4ea7\u529b\u63d0\u5347\u548c\u8fdb\u5165\u95e8\u69db\u964d\u4f4e\uff1b3\uff09\u5f00\u53d1\u74f6\u9888\u8f6c\u5411\u4ee3\u7801\u5ba1\u67e5\uff1b4\uff09\u4ece\u4e1a\u8005\u62c5\u5fe7\u4ee3\u7801\u8d28\u91cf\u3001\u53ef\u7ef4\u62a4\u6027\u3001\u5b89\u5168\u6f0f\u6d1e\u3001\u4f26\u7406\u95ee\u9898\u3001\u57fa\u7840\u95ee\u9898\u89e3\u51b3\u80fd\u529b\u4fb5\u8680\u4ee5\u53ca\u521d\u7ea7\u5de5\u7a0b\u5e08\u51c6\u5907\u4e0d\u8db3\u3002", "conclusion": "\u7814\u7a76\u4e3a\u8ba1\u7b97\u673a\u79d1\u5b66\u548c\u8f6f\u4ef6\u5de5\u7a0b\u6559\u80b2\u63d0\u4f9b\u4e86\u542f\u793a\uff0c\u4e3b\u5f20\u8bfe\u7a0b\u6539\u9769\u5e94\u8f6c\u5411\u95ee\u9898\u89e3\u51b3\u3001\u67b6\u6784\u601d\u7ef4\u3001\u4ee3\u7801\u5ba1\u67e5\u4ee5\u53ca\u65e9\u671f\u6574\u5408LLM\u5de5\u5177\u7684\u9879\u76ee\u5f0f\u5b66\u4e60\uff0c\u4f7f\u6559\u80b2\u5b9e\u8df5\u4e0e\u5feb\u901f\u6f14\u53d8\u7684\u4e13\u4e1a\u73b0\u5b9e\u4fdd\u6301\u4e00\u81f4\u3002"}}
{"id": "2512.24159", "categories": ["cs.SE", "cs.AI", "cs.FL"], "pdf": "https://arxiv.org/pdf/2512.24159", "abs": "https://arxiv.org/abs/2512.24159", "authors": ["Natalia Garanina", "Vladimir Zyubin", "Igor Anureev"], "title": "Developing controlled natural language for formal specification patterns using AI assistants", "comment": null, "summary": "Using an AI assistant, we developed a method for systematically constructing controlled natural language for requirements based on formal specification patterns containing logical attributes. The method involves three stages: 1) compiling a generalized natural language requirement pattern that utilizes all attributes of the formal specification template; 2) generating, using the AI assistant, a corpus of natural language requirement patterns, reduced by partially evaluating attributes (the developed prompt utilizes the generalized template, attribute definitions, and specific formal semantics of the requirement patterns); and 3) formalizing the syntax of the controlled natural language based on an analysis of the grammatical structure of the resulting patterns. The method has been tested for event-driven temporal requirements.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8eAI\u52a9\u624b\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5f62\u5f0f\u5316\u89c4\u8303\u6a21\u5f0f\u6784\u5efa\u53d7\u63a7\u81ea\u7136\u8bed\u8a00\u9700\u6c42\uff0c\u5305\u542b\u4e09\u4e2a\u9636\u6bb5\uff1a\u7f16\u8bd1\u901a\u7528\u6a21\u677f\u3001\u751f\u6210\u8bed\u6599\u5e93\u3001\u5f62\u5f0f\u5316\u8bed\u6cd5\u3002", "motivation": "\u4f20\u7edf\u9700\u6c42\u5de5\u7a0b\u4e2d\u81ea\u7136\u8bed\u8a00\u9700\u6c42\u5b58\u5728\u6b67\u4e49\u548c\u4e0d\u4e00\u81f4\u95ee\u9898\uff0c\u800c\u5f62\u5f0f\u5316\u65b9\u6cd5\u53c8\u96be\u4ee5\u88ab\u9886\u57df\u4e13\u5bb6\u7406\u89e3\u3002\u9700\u8981\u4e00\u79cd\u65e2\u80fd\u4fdd\u6301\u5f62\u5f0f\u5316\u7cbe\u786e\u6027\uff0c\u53c8\u80fd\u8ba9\u975e\u6280\u672f\u4e13\u5bb6\u7406\u89e3\u7684\u4e2d\u95f4\u8868\u793a\u65b9\u6cd5\u3002", "method": "\u4e09\u9636\u6bb5\u65b9\u6cd5\uff1a1) \u7f16\u8bd1\u5305\u542b\u5f62\u5f0f\u5316\u6a21\u677f\u6240\u6709\u5c5e\u6027\u7684\u901a\u7528\u81ea\u7136\u8bed\u8a00\u9700\u6c42\u6a21\u5f0f\uff1b2) \u4f7f\u7528AI\u52a9\u624b\u901a\u8fc7\u90e8\u5206\u5c5e\u6027\u8bc4\u4f30\u751f\u6210\u81ea\u7136\u8bed\u8a00\u9700\u6c42\u6a21\u5f0f\u8bed\u6599\u5e93\uff1b3) \u57fa\u4e8e\u7ed3\u679c\u6a21\u5f0f\u7684\u8bed\u6cd5\u7ed3\u6784\u5206\u6790\uff0c\u5f62\u5f0f\u5316\u53d7\u63a7\u81ea\u7136\u8bed\u8a00\u7684\u8bed\u6cd5\u3002", "result": "\u8be5\u65b9\u6cd5\u5df2\u9488\u5bf9\u4e8b\u4ef6\u9a71\u52a8\u7684\u65f6\u5e8f\u9700\u6c42\u8fdb\u884c\u4e86\u6d4b\u8bd5\uff0c\u80fd\u591f\u7cfb\u7edf\u6027\u5730\u6784\u5efa\u53d7\u63a7\u81ea\u7136\u8bed\u8a00\uff0c\u5c06\u5f62\u5f0f\u5316\u89c4\u8303\u8f6c\u5316\u4e3a\u66f4\u6613\u7406\u89e3\u7684\u81ea\u7136\u8bed\u8a00\u8868\u793a\u3002", "conclusion": "AI\u8f85\u52a9\u7684\u53d7\u63a7\u81ea\u7136\u8bed\u8a00\u6784\u5efa\u65b9\u6cd5\u4e3a\u9700\u6c42\u5de5\u7a0b\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u6865\u6881\uff0c\u65e2\u80fd\u4fdd\u6301\u5f62\u5f0f\u5316\u7cbe\u786e\u6027\uff0c\u53c8\u80fd\u63d0\u9ad8\u53ef\u7406\u89e3\u6027\uff0c\u7279\u522b\u9002\u7528\u4e8e\u4e8b\u4ef6\u9a71\u52a8\u7684\u65f6\u5e8f\u9700\u6c42\u573a\u666f\u3002"}}
{"id": "2512.24183", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.24183", "abs": "https://arxiv.org/abs/2512.24183", "authors": ["Nan Jia", "Wangchao Sang", "Pengfei Lin", "Xiangping Chen", "Yuan Huang", "Yi Liu", "Mingliang Li"], "title": "CoHalLo: code hallucination localization via probing hidden layer vector", "comment": null, "summary": "The localization of code hallucinations aims to identify specific lines of code containing hallucinations, helping developers to improve the reliability of AI-generated code more efficiently. Although recent studies have adopted several methods to detect code hallucination, most of these approaches remain limited to coarse-grained detection and lack specialized techniques for fine-grained hallucination localization. This study introduces a novel method, called CoHalLo, which achieves line-level code hallucination localization by probing the hidden-layer vectors from hallucination detection models. CoHalLo uncovers the key syntactic information driving the model's hallucination judgments and locates the hallucinating code lines accordingly. Specifically, we first fine-tune the hallucination detection model on manually annotated datasets to ensure that it learns features pertinent to code syntactic information. Subsequently, we designed a probe network that projects high-dimensional latent vectors onto a low-dimensional syntactic subspace, generating vector tuples and reconstructing the predicted abstract syntax tree (P-AST). By comparing P-AST with the original abstract syntax tree (O-AST) extracted from the input AI-generated code, we identify the key syntactic structures associated with hallucinations. This information is then used to pinpoint hallucinated code lines. To evaluate CoHalLo's performance, we manually collected a dataset of code hallucinations. The experimental results show that CoHalLo achieves a Top-1 accuracy of 0.4253, Top-3 accuracy of 0.6149, Top-5 accuracy of 0.7356, Top-10 accuracy of 0.8333, IFA of 5.73, Recall@1% Effort of 0.052721, and Effort@20% Recall of 0.155269, which outperforms the baseline methods.", "AI": {"tldr": "CoHalLo\uff1a\u4e00\u79cd\u901a\u8fc7\u63a2\u6d4b\u5e7b\u89c9\u68c0\u6d4b\u6a21\u578b\u7684\u9690\u85cf\u5c42\u5411\u91cf\u6765\u5b9e\u73b0\u884c\u7ea7\u4ee3\u7801\u5e7b\u89c9\u5b9a\u4f4d\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u6bd4\u8f83\u9884\u6d4b\u62bd\u8c61\u8bed\u6cd5\u6811\u548c\u539f\u59cb\u62bd\u8c61\u8bed\u6cd5\u6811\u6765\u5b9a\u4f4d\u5e7b\u89c9\u4ee3\u7801\u884c\u3002", "motivation": "\u73b0\u6709\u4ee3\u7801\u5e7b\u89c9\u68c0\u6d4b\u65b9\u6cd5\u5927\u591a\u662f\u7c97\u7c92\u5ea6\u7684\uff0c\u7f3a\u4e4f\u4e13\u95e8\u7684\u7ec6\u7c92\u5ea6\u5e7b\u89c9\u5b9a\u4f4d\u6280\u672f\uff0c\u96be\u4ee5\u5e2e\u52a9\u5f00\u53d1\u8005\u9ad8\u6548\u63d0\u9ad8AI\u751f\u6210\u4ee3\u7801\u7684\u53ef\u9760\u6027\u3002", "method": "\u9996\u5148\u5728\u4eba\u5de5\u6807\u6ce8\u6570\u636e\u96c6\u4e0a\u5fae\u8c03\u5e7b\u89c9\u68c0\u6d4b\u6a21\u578b\uff0c\u4f7f\u5176\u5b66\u4e60\u4ee3\u7801\u8bed\u6cd5\u7279\u5f81\uff1b\u7136\u540e\u8bbe\u8ba1\u63a2\u9488\u7f51\u7edc\u5c06\u9ad8\u7ef4\u6f5c\u5728\u5411\u91cf\u6295\u5f71\u5230\u4f4e\u7ef4\u8bed\u6cd5\u5b50\u7a7a\u95f4\uff0c\u751f\u6210\u5411\u91cf\u5143\u7ec4\u5e76\u91cd\u6784\u9884\u6d4b\u62bd\u8c61\u8bed\u6cd5\u6811\uff1b\u901a\u8fc7\u6bd4\u8f83\u9884\u6d4bAST\u548c\u539f\u59cbAST\u6765\u8bc6\u522b\u4e0e\u5e7b\u89c9\u76f8\u5173\u7684\u5173\u952e\u8bed\u6cd5\u7ed3\u6784\uff0c\u4ece\u800c\u5b9a\u4f4d\u5e7b\u89c9\u4ee3\u7801\u884c\u3002", "result": "CoHalLo\u5728\u624b\u52a8\u6536\u96c6\u7684\u4ee3\u7801\u5e7b\u89c9\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u5f02\uff1aTop-1\u51c6\u786e\u73870.4253\uff0cTop-3\u51c6\u786e\u73870.6149\uff0cTop-5\u51c6\u786e\u73870.7356\uff0cTop-10\u51c6\u786e\u73870.8333\uff0cIFA\u4e3a5.73\uff0cRecall@1% Effort\u4e3a0.052721\uff0cEffort@20% Recall\u4e3a0.155269\uff0c\u5747\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "CoHalLo\u901a\u8fc7\u63a2\u6d4b\u5e7b\u89c9\u68c0\u6d4b\u6a21\u578b\u7684\u9690\u85cf\u5c42\u5411\u91cf\uff0c\u6210\u529f\u5b9e\u73b0\u4e86\u884c\u7ea7\u4ee3\u7801\u5e7b\u89c9\u5b9a\u4f4d\uff0c\u4e3a\u5f00\u53d1\u8005\u63d0\u4f9b\u4e86\u66f4\u7cbe\u7ec6\u7684\u4ee3\u7801\u53ef\u9760\u6027\u6539\u8fdb\u5de5\u5177\u3002"}}
{"id": "2512.24462", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.24462", "abs": "https://arxiv.org/abs/2512.24462", "authors": ["Yoonha Cha", "Victoria Jackson", "Lauren Shu", "Stacy Branham", "Andr\u00e9 van der Hoek"], "title": "\"Game Changer\" or \"Overenthusiastic Drunk Acquaintance\"? Generative AI Use by Blind and Low Vision Software Professionals in the Workplace", "comment": "13 pages", "summary": "The software development workplace poses numerous technical and collaborative accessibility challenges for blind and low vision software professionals (BLVSPs). Though Generative AI (GenAI) is increasingly adopted within the software development industry and has been a rapidly growing topic of interest in research, to date, the unique perspectives of BLVSPs have yet to be consulted. We report on a qualitative study involving 39 semi-structured interviews with BLVSPs about what the introduction of GenAI has meant for their work. We found that BLVSPs used GenAI for many software development tasks, resulting in benefits such as increased productivity and accessibility. However, significant costs were also accompanied by GenAI use as they were more vulnerable to hallucinations than their sighted colleagues. Sometimes, organizational policies prevented use. Based on our findings, we discuss the higher-risks and higher-returns that BLVSPs had to carefully weigh when deciding whether and when to use GenAI tools for work.", "AI": {"tldr": "\u7814\u7a76\u901a\u8fc739\u4f4d\u89c6\u969c\u8f6f\u4ef6\u4e13\u4e1a\u4eba\u58eb\u8bbf\u8c08\uff0c\u63a2\u8ba8\u751f\u6210\u5f0fAI\u5bf9\u5176\u8f6f\u4ef6\u5f00\u53d1\u5de5\u4f5c\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u867d\u7136\u80fd\u63d0\u9ad8\u751f\u4ea7\u529b\u548c\u53ef\u8bbf\u95ee\u6027\uff0c\u4f46\u4e5f\u9762\u4e34\u5e7b\u89c9\u98ce\u9669\u548c\u7ec4\u7ec7\u653f\u7b56\u9650\u5236\uff0c\u5448\u73b0\u9ad8\u98ce\u9669\u9ad8\u56de\u62a5\u7684\u6743\u8861", "motivation": "\u8f6f\u4ef6\u5f00\u53d1\u5de5\u4f5c\u573a\u6240\u5bf9\u89c6\u969c\u4e13\u4e1a\u4eba\u58eb\u5b58\u5728\u6280\u672f\u548c\u534f\u4f5c\u53ef\u8bbf\u95ee\u6027\u6311\u6218\uff0c\u867d\u7136\u751f\u6210\u5f0fAI\u5728\u8f6f\u4ef6\u5f00\u53d1\u884c\u4e1a\u65e5\u76ca\u666e\u53ca\uff0c\u4f46\u5c1a\u672a\u54a8\u8be2\u89c6\u969c\u4e13\u4e1a\u4eba\u58eb\u7684\u72ec\u7279\u89c6\u89d2", "method": "\u5bf939\u4f4d\u89c6\u969c\u8f6f\u4ef6\u4e13\u4e1a\u4eba\u58eb\u8fdb\u884c\u534a\u7ed3\u6784\u5316\u8bbf\u8c08\u7684\u5b9a\u6027\u7814\u7a76\uff0c\u63a2\u8ba8\u751f\u6210\u5f0fAI\u5f15\u5165\u5bf9\u5176\u5de5\u4f5c\u7684\u610f\u4e49", "result": "\u89c6\u969c\u4e13\u4e1a\u4eba\u58eb\u5c06\u751f\u6210\u5f0fAI\u7528\u4e8e\u591a\u79cd\u5f00\u53d1\u4efb\u52a1\uff0c\u83b7\u5f97\u751f\u4ea7\u529b\u63d0\u5347\u548c\u53ef\u8bbf\u95ee\u6027\u6539\u5584\uff0c\u4f46\u6bd4\u660e\u773c\u540c\u4e8b\u66f4\u5bb9\u6613\u53d7\u5230AI\u5e7b\u89c9\u5f71\u54cd\uff0c\u6709\u65f6\u7ec4\u7ec7\u653f\u7b56\u4e5f\u9650\u5236\u4f7f\u7528", "conclusion": "\u89c6\u969c\u4e13\u4e1a\u4eba\u58eb\u5728\u4f7f\u7528\u751f\u6210\u5f0fAI\u5de5\u5177\u65f6\u9700\u8981\u4ed4\u7ec6\u6743\u8861\u9ad8\u98ce\u9669\u548c\u9ad8\u56de\u62a5\uff0c\u7814\u7a76\u63ed\u793a\u4e86\u8fd9\u4e00\u7279\u6b8a\u7fa4\u4f53\u9762\u4e34\u7684\u72ec\u7279\u6311\u6218\u548c\u673a\u9047"}}
{"id": "2512.24530", "categories": ["cs.SE", "cs.PF"], "pdf": "https://arxiv.org/pdf/2512.24530", "abs": "https://arxiv.org/abs/2512.24530", "authors": ["Nikolaos Mavrogeorgis", "Christos Vasiladiotis", "Pei Mu", "Amir Khordadi", "Bj\u00f6rn Franke", "Antonio Barbalace"], "title": "A Magnified View into Heterogeneous-ISA Thread Migration Performance without State Transformation", "comment": null, "summary": "Heterogeneous-ISA processor designs have attracted considerable research interest. However, unlike their homogeneous-ISA counterparts, explicit software support for bridging ISA heterogeneity is required. The lack of a compilation toolchain ready to support heterogeneous-ISA targets has been a major factor hindering research in this exciting emerging area. For any such compiler, \"getting right\" the mechanics involved in state transformation upon migration and doing this efficiently is of critical importance. In particular, any runtime conversion of the current program stack from one architecture to another would be prohibitively expensive. In this paper, we design and develop Unifico, a new multi-ISA compiler that generates binaries that maintain the same stack layout during their execution on either architecture. Unifico avoids the need for runtime stack transformation, thus eliminating overheads associated with ISA migration. Additional responsibilities of the Unifico compiler backend include maintenance of a uniform ABI and virtual address space across ISAs. Unifico is implemented using the LLVM compiler infrastructure, and we are currently targeting the x86-64 and ARMv8 ISAs. We have evaluated Unifico across a range of compute-intensive NAS benchmarks and show its minimal impact on overall execution time, where less than 6% (10%) overhead is introduced on average for high-end (low-end) processors. We also analyze the performance impact of Unifico's key design features and demonstrate that they can be further optimized to mitigate this impact. When compared against the state-of-the-art Popcorn compiler, Unifico reduces binary size overhead from ~200% to ~10%, whilst eliminating the stack transformation overhead during ISA migration.", "AI": {"tldr": "Unifico\u662f\u4e00\u4e2a\u591aISA\u7f16\u8bd1\u5668\uff0c\u901a\u8fc7\u4fdd\u6301\u8de8\u67b6\u6784\u7684\u76f8\u540c\u6808\u5e03\u5c40\u6765\u6d88\u9664\u8fd0\u884c\u65f6\u6808\u8f6c\u6362\u5f00\u9500\uff0c\u76f8\u6bd4\u73b0\u6709\u65b9\u6848\u5927\u5e45\u51cf\u5c11\u4e8c\u8fdb\u5236\u5927\u5c0f\u5f00\u9500\u3002", "motivation": "\u5f02\u6784ISA\u5904\u7406\u5668\u8bbe\u8ba1\u9700\u8981\u8f6f\u4ef6\u652f\u6301\u6765\u6865\u63a5ISA\u5f02\u6784\u6027\uff0c\u4f46\u7f3a\u4e4f\u652f\u6301\u5f02\u6784ISA\u76ee\u6807\u7684\u7f16\u8bd1\u5de5\u5177\u94fe\u963b\u788d\u4e86\u8be5\u9886\u57df\u7814\u7a76\u3002\u73b0\u6709\u65b9\u6848\u4e2d\u8fd0\u884c\u65f6\u6808\u8f6c\u6362\u6210\u672c\u8fc7\u9ad8\u3002", "method": "\u8bbe\u8ba1\u5f00\u53d1Unifico\u7f16\u8bd1\u5668\uff0c\u751f\u6210\u5728\u4e24\u79cd\u67b6\u6784\u4e0a\u6267\u884c\u65f6\u4fdd\u6301\u76f8\u540c\u6808\u5e03\u5c40\u7684\u4e8c\u8fdb\u5236\u6587\u4ef6\uff0c\u907f\u514d\u8fd0\u884c\u65f6\u6808\u8f6c\u6362\uff0c\u7ef4\u62a4\u7edf\u4e00\u7684ABI\u548c\u865a\u62df\u5730\u5740\u7a7a\u95f4\u3002\u57fa\u4e8eLLVM\u5b9e\u73b0\uff0c\u9488\u5bf9x86-64\u548cARMv8 ISA\u3002", "result": "\u5728NAS\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cUnifico\u5f15\u5165\u7684\u5e73\u5747\u5f00\u9500\u5c0f\u4e8e6%\uff08\u9ad8\u7aef\u5904\u7406\u5668\uff09\u548c10%\uff08\u4f4e\u7aef\u5904\u7406\u5668\uff09\u3002\u76f8\u6bd4\u73b0\u6709Popcorn\u7f16\u8bd1\u5668\uff0c\u5c06\u4e8c\u8fdb\u5236\u5927\u5c0f\u5f00\u9500\u4ece~200%\u964d\u4f4e\u5230~10%\uff0c\u540c\u65f6\u6d88\u9664\u4e86ISA\u8fc1\u79fb\u65f6\u7684\u6808\u8f6c\u6362\u5f00\u9500\u3002", "conclusion": "Unifico\u901a\u8fc7\u6d88\u9664\u8fd0\u884c\u65f6\u6808\u8f6c\u6362\u5f00\u9500\uff0c\u4e3a\u5f02\u6784ISA\u5904\u7406\u5668\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u7f16\u8bd1\u652f\u6301\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u4e8c\u8fdb\u5236\u5927\u5c0f\u5f00\u9500\uff0c\u5176\u8bbe\u8ba1\u7279\u6027\u53ef\u8fdb\u4e00\u6b65\u4f18\u5316\u4ee5\u51cf\u8f7b\u6027\u80fd\u5f71\u54cd\u3002"}}
{"id": "2512.24560", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.24560", "abs": "https://arxiv.org/abs/2512.24560", "authors": ["David Gros", "Prem Devanbu"], "title": "Localized Calibrated Uncertainty in Code Language Models", "comment": null, "summary": "Large Language models (LLMs) can generate complicated source code from natural language prompts. However, LLMs can generate output that deviates from what the user wants, requiring supervision and editing. To support this process, we offer techniques to localize where generations might be misaligned from user intent. We first create a dataset of \"Minimal Intent Aligning Patches\" of repaired LLM generated programs. Each program uses test cases to verify correctness. After creating a dataset of programs, we measure how well various techniques can assign a well-calibrated probability to indicate which parts of code will be edited in a minimal patch (i.e., give a probability that corresponds with empirical odds it is edited). We compare white-box probing (where we propose a technique for efficient arbitrary-span querying), against black-box reflective and self-consistency based approaches. We find probes with a small supervisor model can achieve low calibration error and Brier Skill Score of approx 0.2 estimating edited lines on code generated by models many orders of magnitude larger. We discuss the generalizability of the techniques, and the connections to AI oversight and control, finding a probe trained only on code shows some signs of generalizing to natural language errors if new probability scaling is allowed.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5f00\u53d1\u4e86\u5b9a\u4f4dLLM\u751f\u6210\u4ee3\u7801\u4e2d\u4e0e\u7528\u6237\u610f\u56fe\u4e0d\u7b26\u90e8\u5206\u7684\u6280\u672f\uff0c\u901a\u8fc7\u521b\u5efa\"\u6700\u5c0f\u610f\u56fe\u5bf9\u9f50\u8865\u4e01\"\u6570\u636e\u96c6\uff0c\u6bd4\u8f83\u4e86\u767d\u76d2\u63a2\u6d4b\u4e0e\u9ed1\u76d2\u53cd\u5c04\u65b9\u6cd5\u5728\u9884\u6d4b\u4ee3\u7801\u7f16\u8f91\u4f4d\u7f6e\u4e0a\u7684\u6548\u679c\u3002", "motivation": "LLM\u751f\u6210\u7684\u4ee3\u7801\u53ef\u80fd\u504f\u79bb\u7528\u6237\u610f\u56fe\uff0c\u9700\u8981\u76d1\u7763\u548c\u7f16\u8f91\u3002\u4e3a\u4e86\u652f\u6301\u8fd9\u4e00\u8fc7\u7a0b\uff0c\u9700\u8981\u6280\u672f\u6765\u5b9a\u4f4d\u751f\u6210\u4ee3\u7801\u4e2d\u53ef\u80fd\u4e0d\u5339\u914d\u7528\u6237\u610f\u56fe\u7684\u90e8\u5206\u3002", "method": "\u9996\u5148\u521b\u5efa\u5305\u542b\"\u6700\u5c0f\u610f\u56fe\u5bf9\u9f50\u8865\u4e01\"\u7684\u6570\u636e\u96c6\uff0c\u4f7f\u7528\u6d4b\u8bd5\u7528\u4f8b\u9a8c\u8bc1\u6b63\u786e\u6027\u3002\u7136\u540e\u6bd4\u8f83\u591a\u79cd\u6280\u672f\uff1a\u767d\u76d2\u63a2\u6d4b\uff08\u63d0\u51fa\u9ad8\u6548\u4efb\u610f\u8de8\u5ea6\u67e5\u8be2\u6280\u672f\uff09\u3001\u9ed1\u76d2\u53cd\u5c04\u548c\u57fa\u4e8e\u81ea\u4e00\u81f4\u6027\u7684\u65b9\u6cd5\uff0c\u8bc4\u4f30\u5b83\u4eec\u4e3a\u4ee3\u7801\u7f16\u8f91\u90e8\u5206\u5206\u914d\u6821\u51c6\u6982\u7387\u7684\u80fd\u529b\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u4f7f\u7528\u5c0f\u578b\u76d1\u7763\u6a21\u578b\u7684\u63a2\u9488\u80fd\u591f\u5b9e\u73b0\u8f83\u4f4e\u7684\u6821\u51c6\u8bef\u5dee\uff0cBrier\u6280\u80fd\u5f97\u5206\u7ea6\u4e3a0.2\uff0c\u80fd\u591f\u6709\u6548\u9884\u6d4b\u7531\u5927\u6a21\u578b\u751f\u6210\u7684\u4ee3\u7801\u4e2d\u9700\u8981\u7f16\u8f91\u7684\u884c\u3002\u63a2\u9488\u4ec5\u901a\u8fc7\u4ee3\u7801\u8bad\u7ec3\u5c31\u80fd\u5728\u4e00\u5b9a\u7a0b\u5ea6\u4e0a\u6cdb\u5316\u5230\u81ea\u7136\u8bed\u8a00\u9519\u8bef\u3002", "conclusion": "\u8be5\u6280\u672f\u4e3aAI\u76d1\u7763\u548c\u63a7\u5236\u63d0\u4f9b\u4e86\u65b0\u65b9\u6cd5\uff0c\u5c0f\u578b\u76d1\u7763\u6a21\u578b\u80fd\u591f\u6709\u6548\u5b9a\u4f4d\u5927\u6a21\u578b\u751f\u6210\u4ee3\u7801\u4e2d\u7684\u9519\u8bef\uff0c\u4e14\u663e\u793a\u51fa\u4e00\u5b9a\u7684\u8de8\u9886\u57df\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2512.24570", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.24570", "abs": "https://arxiv.org/abs/2512.24570", "authors": ["Shiqi Kuang", "Zhao Tian", "Tao Xiao", "Dong Wang", "Junjie Chen"], "title": "On the Effectiveness of Training Data Optimization for LLM-based Code Generation: An Empirical Study", "comment": null, "summary": "Large language models (LLMs) have achieved remarkable progress in code generation, largely driven by the availability of high-quality code datasets for effective training. To further improve data quality, numerous training data optimization techniques have been proposed; however, their overall effectiveness has not been systematically evaluated. To bridge this gap, we conduct the first large-scale empirical study, examining five widely-used training data optimization techniques and their pairwise combinations for LLM-based code generation across three benchmarks and four LLMs. Our results show that data synthesis is the most effective technique for improving functional correctness and reducing code smells, although it performs relatively worse on code maintainability compared to data refactoring, cleaning, and selection. Regarding combinations, we find that most combinations do not further improve functional correctness but can effectively enhance code quality (code smells and maintainability). Among all combinations, data synthesis combined with data refactoring achieves the strongest overall performance. Furthermore, our fine-grained analysis reinforces these findings and provides deeper insights into how individual techniques and their combinations influence code generation effectiveness. Overall, this work represents a first step toward a systematic understanding of training data optimization and combination strategies, offering practical guidance for future research and deployment in LLM-based code generation.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u5927\u89c4\u6a21\u5b9e\u8bc1\u7814\u7a76\u4e86\u4e94\u79cd\u5e38\u7528\u8bad\u7ec3\u6570\u636e\u4f18\u5316\u6280\u672f\u53ca\u5176\u7ec4\u5408\u5bf9LLM\u4ee3\u7801\u751f\u6210\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u6570\u636e\u5408\u6210\u5728\u529f\u80fd\u6b63\u786e\u6027\u4e0a\u6700\u6709\u6548\uff0c\u800c\u6570\u636e\u5408\u6210\u4e0e\u6570\u636e\u91cd\u6784\u7684\u7ec4\u5408\u8868\u73b0\u6700\u4f73\u3002", "motivation": "\u5c3d\u7ba1\u5df2\u6709\u591a\u79cd\u8bad\u7ec3\u6570\u636e\u4f18\u5316\u6280\u672f\u88ab\u63d0\u51fa\u4ee5\u63d0\u5347\u4ee3\u7801\u751f\u6210\u8d28\u91cf\uff0c\u4f46\u8fd9\u4e9b\u6280\u672f\u7684\u6574\u4f53\u6548\u679c\u5c1a\u672a\u5f97\u5230\u7cfb\u7edf\u8bc4\u4f30\u3002\u4e3a\u4e86\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u672c\u6587\u65e8\u5728\u901a\u8fc7\u5927\u89c4\u6a21\u5b9e\u8bc1\u7814\u7a76\uff0c\u4e3aLLM\u4ee3\u7801\u751f\u6210\u7684\u8bad\u7ec3\u6570\u636e\u4f18\u5316\u63d0\u4f9b\u7cfb\u7edf\u7406\u89e3\u548c\u5b9e\u8df5\u6307\u5bfc\u3002", "method": "\u5bf9\u4e94\u79cd\u5e7f\u6cdb\u4f7f\u7528\u7684\u8bad\u7ec3\u6570\u636e\u4f18\u5316\u6280\u672f\u53ca\u5176\u4e24\u4e24\u7ec4\u5408\u8fdb\u884c\u5927\u89c4\u6a21\u5b9e\u8bc1\u7814\u7a76\uff0c\u6db5\u76d6\u4e09\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u548c\u56db\u4e2a\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u901a\u8fc7\u7ec6\u7c92\u5ea6\u5206\u6790\u6df1\u5165\u63a2\u8ba8\u5404\u9879\u6280\u672f\u53ca\u5176\u7ec4\u5408\u5bf9\u4ee3\u7801\u751f\u6210\u6548\u679c\u7684\u5f71\u54cd\u3002", "result": "\u6570\u636e\u5408\u6210\u5728\u63d0\u5347\u529f\u80fd\u6b63\u786e\u6027\u548c\u51cf\u5c11\u4ee3\u7801\u5f02\u5473\u65b9\u9762\u6700\u6709\u6548\uff0c\u4f46\u5728\u4ee3\u7801\u53ef\u7ef4\u62a4\u6027\u4e0a\u76f8\u5bf9\u8f83\u5dee\uff1b\u5927\u591a\u6570\u7ec4\u5408\u4e0d\u80fd\u8fdb\u4e00\u6b65\u63d0\u5347\u529f\u80fd\u6b63\u786e\u6027\uff0c\u4f46\u80fd\u6709\u6548\u63d0\u5347\u4ee3\u7801\u8d28\u91cf\uff1b\u6570\u636e\u5408\u6210\u4e0e\u6570\u636e\u91cd\u6784\u7684\u7ec4\u5408\u5728\u6240\u6709\u7ec4\u5408\u4e2d\u8868\u73b0\u6700\u5f3a\u3002", "conclusion": "\u672c\u7814\u7a76\u4e3a\u8bad\u7ec3\u6570\u636e\u4f18\u5316\u548c\u7ec4\u5408\u7b56\u7565\u63d0\u4f9b\u4e86\u7cfb\u7edf\u7406\u89e3\uff0c\u4e3a\u672a\u6765LLM\u4ee3\u7801\u751f\u6210\u7684\u7814\u7a76\u548c\u90e8\u7f72\u63d0\u4f9b\u4e86\u5b9e\u7528\u6307\u5bfc\uff0c\u662f\u8fc8\u5411\u7cfb\u7edf\u5316\u8bad\u7ec3\u6570\u636e\u4f18\u5316\u7684\u7b2c\u4e00\u6b65\u3002"}}
{"id": "2512.24594", "categories": ["cs.SE", "cs.LO"], "pdf": "https://arxiv.org/pdf/2512.24594", "abs": "https://arxiv.org/abs/2512.24594", "authors": ["Zhongyi Wang", "Tengjie Lin", "Mingshuai Chen", "Haokun Li", "Mingqi Yang", "Xiao Yi", "Shengchao Qin", "Yixing Luo", "Xiaofeng Li", "Bin Gu", "Liqiang Lu", "Jianwei Yin"], "title": "A Tale of 1001 LoC: Potential Runtime Error-Guided Specification Synthesis for Verifying Large-Scale Programs", "comment": "Accepted at OOPSLA 2026", "summary": "Fully automated verification of large-scale software and hardware systems is arguably the holy grail of formal methods. Large language models (LLMs) have recently demonstrated their potential for enhancing the degree of automation in formal verification by, e.g., generating formal specifications as essential to deductive verification, yet exhibit poor scalability due to long-context reasoning limitations and, more importantly, the difficulty of inferring complex, interprocedural specifications. This paper presents Preguss -- a modular, fine-grained framework for automating the generation and refinement of formal specifications. Preguss synergizes between static analysis and deductive verification by steering two components in a divide-and-conquer fashion: (i) potential runtime error-guided construction and prioritization of verification units, and (ii) LLM-aided synthesis of interprocedural specifications at the unit level. We show that Preguss substantially outperforms state-of-the-art LLM-based approaches and, in particular, it enables highly automated RTE-freeness verification for real-world programs with over a thousand LoC, with a reduction of 80.6%~88.9% human verification effort.", "AI": {"tldr": "Preguss\u662f\u4e00\u4e2a\u6a21\u5757\u5316\u3001\u7ec6\u7c92\u5ea6\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u5408\u9759\u6001\u5206\u6790\u548c\u6f14\u7ece\u9a8c\u8bc1\uff0c\u81ea\u52a8\u5316\u751f\u6210\u548c\u7cbe\u5316\u5f62\u5f0f\u5316\u89c4\u7ea6\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u5927\u89c4\u6a21\u7a0b\u5e8f\u9a8c\u8bc1\u7684\u4eba\u5de5\u5de5\u4f5c\u91cf\u3002", "motivation": "\u5927\u89c4\u6a21\u8f6f\u4ef6\u548c\u786c\u4ef6\u7cfb\u7edf\u7684\u5168\u81ea\u52a8\u9a8c\u8bc1\u662f\u5f62\u5f0f\u5316\u65b9\u6cd5\u7684\u7ec8\u6781\u76ee\u6807\u3002\u867d\u7136\u5927\u8bed\u8a00\u6a21\u578b\u5728\u589e\u5f3a\u5f62\u5f0f\u5316\u9a8c\u8bc1\u81ea\u52a8\u5316\u65b9\u9762\u663e\u793a\u51fa\u6f5c\u529b\uff0c\u4f46\u7531\u4e8e\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\u9650\u5236\u548c\u63a8\u65ad\u590d\u6742\u8fc7\u7a0b\u95f4\u89c4\u7ea6\u7684\u56f0\u96be\uff0c\u5176\u53ef\u6269\u5c55\u6027\u8f83\u5dee\u3002", "method": "Preguss\u91c7\u7528\u5206\u6cbb\u7b56\u7565\uff0c\u7ed3\u5408\u9759\u6001\u5206\u6790\u548c\u6f14\u7ece\u9a8c\u8bc1\uff1a1) \u57fa\u4e8e\u6f5c\u5728\u8fd0\u884c\u65f6\u9519\u8bef\u6307\u5bfc\u6784\u5efa\u548c\u4f18\u5148\u5904\u7406\u9a8c\u8bc1\u5355\u5143\uff1b2) \u5728\u5355\u5143\u7ea7\u522b\u4f7f\u7528LLM\u8f85\u52a9\u5408\u6210\u8fc7\u7a0b\u95f4\u89c4\u7ea6\u3002", "result": "Preguss\u663e\u8457\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u57fa\u4e8eLLM\u7684\u65b9\u6cd5\uff0c\u80fd\u591f\u5bf9\u8d85\u8fc7\u5343\u884c\u4ee3\u7801\u7684\u5b9e\u9645\u7a0b\u5e8f\u8fdb\u884c\u9ad8\u5ea6\u81ea\u52a8\u5316\u7684RTE\u65e0\u9519\u8bef\u9a8c\u8bc1\uff0c\u51cf\u5c11\u4e8680.6%~88.9%\u7684\u4eba\u5de5\u9a8c\u8bc1\u5de5\u4f5c\u91cf\u3002", "conclusion": "Preguss\u901a\u8fc7\u6a21\u5757\u5316\u3001\u7ec6\u7c92\u5ea6\u7684\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86LLM\u5728\u5f62\u5f0f\u5316\u9a8c\u8bc1\u4e2d\u7684\u53ef\u6269\u5c55\u6027\u95ee\u9898\uff0c\u4e3a\u5b9e\u73b0\u5927\u89c4\u6a21\u7cfb\u7edf\u81ea\u52a8\u5316\u9a8c\u8bc1\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.24630", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.24630", "abs": "https://arxiv.org/abs/2512.24630", "authors": ["Md Nahidul Islam Opu", "Shahidul Islam", "Muhammad Asaduzzaman", "Shaiful Chowdhury"], "title": "How Do Agentic AI Systems Address Performance Optimizations? A BERTopic-Based Analysis of Pull Requests", "comment": null, "summary": "LLM-based software engineering is influencing modern software development. In addition to correctness, prior studies have also examined the performance of software artifacts generated by AI agents. However, it is unclear how exactly the agentic AI systems address performance concerns in practice. In this paper, we present an empirical study of performance-related pull requests generated by AI agents. Using LLM-assisted detection and BERTopic-based topic modeling, we identified 52 performance-related topics grouped into 10 higher-level categories. Our results show that AI agents apply performance optimizations across diverse layers of the software stack and that the type of optimization significantly affects pull request acceptance rates and review times. We also found that performance optimization by AI agents primarily occurs during the development phase, with less focus on the maintenance phase. Our findings provide empirical evidence that can support the evaluation and improvement of agentic AI systems with respect to their performance optimization behaviors and review outcomes.", "AI": {"tldr": "\u8be5\u8bba\u6587\u901a\u8fc7\u5b9e\u8bc1\u7814\u7a76\u5206\u6790\u4e86AI\u4ee3\u7406\u751f\u6210\u7684\u6027\u80fd\u76f8\u5173PR\uff0c\u8bc6\u522b\u4e8652\u4e2a\u6027\u80fd\u4e3b\u9898\u548c10\u4e2a\u9ad8\u5c42\u7c7b\u522b\uff0c\u53d1\u73b0AI\u4ee3\u7406\u5728\u4e0d\u540c\u8f6f\u4ef6\u6808\u5c42\u6b21\u5e94\u7528\u6027\u80fd\u4f18\u5316\uff0c\u4e14\u4f18\u5316\u7c7b\u578b\u663e\u8457\u5f71\u54cdPR\u63a5\u53d7\u7387\u548c\u5ba1\u67e5\u65f6\u95f4\u3002", "motivation": "\u968f\u7740\u57fa\u4e8eLLM\u7684\u8f6f\u4ef6\u5de5\u7a0b\u5f71\u54cd\u73b0\u4ee3\u8f6f\u4ef6\u5f00\u53d1\uff0c\u9664\u4e86\u6b63\u786e\u6027\u5916\uff0c\u5148\u524d\u7814\u7a76\u4e5f\u8003\u5bdf\u4e86AI\u4ee3\u7406\u751f\u6210\u7684\u8f6f\u4ef6\u5de5\u4ef6\u7684\u6027\u80fd\u3002\u7136\u800c\uff0c\u76ee\u524d\u5c1a\u4e0d\u6e05\u695a\u4ee3\u7406\u5f0fAI\u7cfb\u7edf\u5728\u5b9e\u8df5\u4e2d\u5982\u4f55\u5177\u4f53\u5904\u7406\u6027\u80fd\u95ee\u9898\uff0c\u56e0\u6b64\u9700\u8981\u5b9e\u8bc1\u7814\u7a76AI\u4ee3\u7406\u751f\u6210\u7684\u6027\u80fd\u76f8\u5173PR\u3002", "method": "\u91c7\u7528LLM\u8f85\u52a9\u68c0\u6d4b\u548c\u57fa\u4e8eBERTopic\u7684\u4e3b\u9898\u5efa\u6a21\u65b9\u6cd5\uff0c\u8bc6\u522b\u6027\u80fd\u76f8\u5173\u7684pull requests\uff0c\u5c0652\u4e2a\u6027\u80fd\u76f8\u5173\u4e3b\u9898\u5206\u7ec4\u4e3a10\u4e2a\u9ad8\u5c42\u7c7b\u522b\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff1a1) AI\u4ee3\u7406\u5728\u8f6f\u4ef6\u6808\u7684\u4e0d\u540c\u5c42\u6b21\u5e94\u7528\u6027\u80fd\u4f18\u5316\uff1b2) \u4f18\u5316\u7c7b\u578b\u663e\u8457\u5f71\u54cdPR\u63a5\u53d7\u7387\u548c\u5ba1\u67e5\u65f6\u95f4\uff1b3) AI\u4ee3\u7406\u7684\u6027\u80fd\u4f18\u5316\u4e3b\u8981\u53d1\u751f\u5728\u5f00\u53d1\u9636\u6bb5\uff0c\u7ef4\u62a4\u9636\u6bb5\u5173\u6ce8\u8f83\u5c11\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u4e3a\u8bc4\u4f30\u548c\u6539\u8fdb\u4ee3\u7406\u5f0fAI\u7cfb\u7edf\u7684\u6027\u80fd\u4f18\u5316\u884c\u4e3a\u548c\u5ba1\u67e5\u7ed3\u679c\u63d0\u4f9b\u4e86\u5b9e\u8bc1\u8bc1\u636e\uff0c\u6709\u52a9\u4e8e\u66f4\u597d\u5730\u7406\u89e3\u548c\u4f18\u5316AI\u4ee3\u7406\u5728\u8f6f\u4ef6\u6027\u80fd\u65b9\u9762\u7684\u5b9e\u8df5\u3002"}}
{"id": "2512.24635", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.24635", "abs": "https://arxiv.org/abs/2512.24635", "authors": ["Zhili Huang", "Ling Xu", "Chao Liu", "Weifeng Sun", "Xu Zhang", "Yan Lei", "Meng Yan", "Hongyu Zhang"], "title": "DynaFix: Iterative Automated Program Repair Driven by Execution-Level Dynamic Information", "comment": "22 pages, 7 figures, preprint version", "summary": "Automated Program Repair (APR) aims to automatically generate correct patches for buggy programs. Recent approaches leveraging large language models (LLMs) have shown promise but face limitations. Most rely solely on static analysis, ignoring runtime behaviors. Some attempt to incorporate dynamic signals, but these are often restricted to training or fine-tuning, or injected only once into the repair prompt, without iterative use. This fails to fully capture program execution. Current iterative repair frameworks typically rely on coarse-grained feedback, such as pass/fail results or exception types, and do not leverage fine-grained execution-level information effectively. As a result, models struggle to simulate human stepwise debugging, limiting their effectiveness in multi-step reasoning and complex bug repair.\n  To address these challenges, we propose DynaFix, an execution-level dynamic information-driven APR method that iteratively leverages runtime information to refine the repair process. In each repair round, DynaFix captures execution-level dynamic information such as variable states, control-flow paths, and call stacks, transforming them into structured prompts to guide LLMs in generating candidate patches. If a patch fails validation, DynaFix re-executes the modified program to collect new execution information for the next attempt. This iterative loop incrementally improves patches based on updated feedback, similar to the stepwise debugging practices of human developers. We evaluate DynaFix on the Defects4J v1.2 and v2.0 benchmarks. DynaFix repairs 186 single-function bugs, a 10% improvement over state-of-the-art baselines, including 38 bugs previously unrepaired. It achieves correct patches within at most 35 attempts, reducing the patch search space by 70% compared with existing methods, thereby demonstrating both effectiveness and efficiency in repairing complex bugs.", "AI": {"tldr": "DynaFix\uff1a\u4e00\u79cd\u57fa\u4e8e\u6267\u884c\u7ea7\u52a8\u6001\u4fe1\u606f\u7684\u8fed\u4ee3\u5f0f\u7a0b\u5e8f\u4fee\u590d\u65b9\u6cd5\uff0c\u901a\u8fc7\u8fd0\u884c\u65f6\u4fe1\u606f\uff08\u53d8\u91cf\u72b6\u6001\u3001\u63a7\u5236\u6d41\u8def\u5f84\u3001\u8c03\u7528\u6808\uff09\u6307\u5bfcLLM\u751f\u6210\u8865\u4e01\uff0c\u663e\u8457\u63d0\u5347\u4fee\u590d\u6548\u679c\u548c\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8eLLM\u7684\u81ea\u52a8\u7a0b\u5e8f\u4fee\u590d\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u9759\u6001\u5206\u6790\uff0c\u5ffd\u7565\u8fd0\u884c\u65f6\u884c\u4e3a\uff1b\u5373\u4f7f\u5c1d\u8bd5\u878d\u5165\u52a8\u6001\u4fe1\u53f7\uff0c\u4e5f\u4ec5\u9650\u4e8e\u8bad\u7ec3\u9636\u6bb5\u6216\u5355\u6b21\u63d0\u793a\u6ce8\u5165\uff0c\u65e0\u6cd5\u6709\u6548\u5229\u7528\u7ec6\u7c92\u5ea6\u6267\u884c\u4fe1\u606f\u3002\u73b0\u6709\u8fed\u4ee3\u4fee\u590d\u6846\u67b6\u901a\u5e38\u4f9d\u8d56\u7c97\u7c92\u5ea6\u53cd\u9988\uff08\u5982\u901a\u8fc7/\u5931\u8d25\u7ed3\u679c\uff09\uff0c\u65e0\u6cd5\u6a21\u62df\u4eba\u7c7b\u9010\u6b65\u8c03\u8bd5\u8fc7\u7a0b\uff0c\u9650\u5236\u4e86\u591a\u6b65\u63a8\u7406\u548c\u590d\u6742bug\u4fee\u590d\u80fd\u529b\u3002", "method": "DynaFix\u662f\u4e00\u79cd\u6267\u884c\u7ea7\u52a8\u6001\u4fe1\u606f\u9a71\u52a8\u7684APR\u65b9\u6cd5\uff0c\u5728\u6bcf\u8f6e\u4fee\u590d\u4e2d\u6355\u83b7\u8fd0\u884c\u65f6\u4fe1\u606f\uff08\u53d8\u91cf\u72b6\u6001\u3001\u63a7\u5236\u6d41\u8def\u5f84\u3001\u8c03\u7528\u6808\uff09\uff0c\u5c06\u5176\u8f6c\u5316\u4e3a\u7ed3\u6784\u5316\u63d0\u793a\u6765\u6307\u5bfcLLM\u751f\u6210\u5019\u9009\u8865\u4e01\u3002\u5982\u679c\u8865\u4e01\u9a8c\u8bc1\u5931\u8d25\uff0c\u91cd\u65b0\u6267\u884c\u4fee\u6539\u540e\u7684\u7a0b\u5e8f\u6536\u96c6\u65b0\u7684\u6267\u884c\u4fe1\u606f\u8fdb\u884c\u4e0b\u4e00\u8f6e\u5c1d\u8bd5\uff0c\u5f62\u6210\u7c7b\u4f3c\u4eba\u7c7b\u9010\u6b65\u8c03\u8bd5\u7684\u8fed\u4ee3\u5faa\u73af\u3002", "result": "\u5728Defects4J v1.2\u548cv2.0\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cDynaFix\u4fee\u590d\u4e86186\u4e2a\u5355\u51fd\u6570bug\uff0c\u6bd4\u6700\u5148\u8fdb\u57fa\u7ebf\u63d0\u534710%\uff0c\u5176\u4e2d\u5305\u62ec38\u4e2a\u4e4b\u524d\u672a\u4fee\u590d\u7684bug\u3002\u6700\u591a35\u6b21\u5c1d\u8bd5\u5185\u83b7\u5f97\u6b63\u786e\u8865\u4e01\uff0c\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u5c06\u8865\u4e01\u641c\u7d22\u7a7a\u95f4\u51cf\u5c1170%\uff0c\u5728\u4fee\u590d\u590d\u6742bug\u65b9\u9762\u5c55\u73b0\u51fa\u6709\u6548\u6027\u548c\u6548\u7387\u3002", "conclusion": "DynaFill\u901a\u8fc7\u8fed\u4ee3\u5229\u7528\u7ec6\u7c92\u5ea6\u6267\u884c\u7ea7\u52a8\u6001\u4fe1\u606f\uff0c\u663e\u8457\u63d0\u5347\u4e86\u81ea\u52a8\u7a0b\u5e8f\u4fee\u590d\u7684\u6548\u679c\uff0c\u80fd\u591f\u66f4\u597d\u5730\u6a21\u62df\u4eba\u7c7b\u8c03\u8bd5\u8fc7\u7a0b\uff0c\u5728\u590d\u6742bug\u4fee\u590d\u548c\u591a\u6b65\u63a8\u7406\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4e3a\u57fa\u4e8eLLM\u7684APR\u65b9\u6cd5\u63d0\u4f9b\u4e86\u65b0\u7684\u65b9\u5411\u3002"}}
{"id": "2512.24636", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.24636", "abs": "https://arxiv.org/abs/2512.24636", "authors": ["Tanjum Motin Mitul", "Md. Masud Mazumder", "Md Nahidul Islam Opu", "Shaiful Chowdhury"], "title": "How Do Agentic AI Systems Deal With Software Energy Concerns? A Pull Request-Based Study", "comment": null, "summary": "As Software Engineering enters its new era (SE 3.0), AI coding agents increasingly automate software development workflows. However, it remains unclear how exactly these agents recognize and address software energy concerns-an issue growing in importance due to large-scale data centers, energy-hungry language models, and battery-constrained devices. In this paper, we examined the energy awareness of agent-authored pull requests (PRs) using a publicly available dataset. We identified 216 energy-explicit PRs and conducted a thematic analysis, deriving a taxonomy of energy-aware work. Our further analysis of the applied optimization techniques shows that most align with established research recommendations. Although building and running these agents is highly energy intensive, encouragingly, the results indicate that they exhibit energy awareness when generating software artifacts. However, optimization-related PRs are accepted less frequently than others, largely due to their negative impact on maintainability.", "AI": {"tldr": "\u7814\u7a76\u5206\u6790\u4e86AI\u7f16\u7801\u4ee3\u7406\u5728\u751f\u6210\u8f6f\u4ef6\u62c9\u53d6\u8bf7\u6c42\u65f6\u7684\u80fd\u6e90\u610f\u8bc6\uff0c\u53d1\u73b0\u867d\u7136AI\u4ee3\u7406\u672c\u8eab\u80fd\u8017\u9ad8\uff0c\u4f46\u5728\u751f\u6210\u4ee3\u7801\u65f6\u786e\u5b9e\u8868\u73b0\u51fa\u80fd\u6e90\u610f\u8bc6\uff0c\u4e0d\u8fc7\u80fd\u6e90\u4f18\u5316\u76f8\u5173\u7684PR\u63a5\u53d7\u7387\u8f83\u4f4e\u3002", "motivation": "\u968f\u7740\u8f6f\u4ef6\u5de5\u7a0b\u8fdb\u5165SE 3.0\u65f6\u4ee3\uff0cAI\u7f16\u7801\u4ee3\u7406\u65e5\u76ca\u81ea\u52a8\u5316\u8f6f\u4ef6\u5f00\u53d1\u6d41\u7a0b\uff0c\u4f46\u5c1a\u4e0d\u6e05\u695a\u8fd9\u4e9b\u4ee3\u7406\u5982\u4f55\u8bc6\u522b\u548c\u5904\u7406\u8f6f\u4ef6\u80fd\u6e90\u95ee\u9898\u3002\u8003\u8651\u5230\u5927\u89c4\u6a21\u6570\u636e\u4e2d\u5fc3\u3001\u80fd\u8017\u9ad8\u7684\u8bed\u8a00\u6a21\u578b\u548c\u7535\u6c60\u53d7\u9650\u8bbe\u5907\uff0c\u8f6f\u4ef6\u80fd\u6e90\u95ee\u9898\u53d8\u5f97\u8d8a\u6765\u8d8a\u91cd\u8981\u3002", "method": "\u4f7f\u7528\u516c\u5f00\u6570\u636e\u96c6\u5206\u6790\u4ee3\u7406\u751f\u6210\u7684\u62c9\u53d6\u8bf7\u6c42\uff08PRs\uff09\uff0c\u8bc6\u522b\u51fa216\u4e2a\u660e\u786e\u6d89\u53ca\u80fd\u6e90\u7684PRs\uff0c\u8fdb\u884c\u4e3b\u9898\u5206\u6790\u5e76\u6784\u5efa\u80fd\u6e90\u610f\u8bc6\u5de5\u4f5c\u7684\u5206\u7c7b\u6cd5\uff0c\u8fdb\u4e00\u6b65\u5206\u6790\u5e94\u7528\u7684\u4f18\u5316\u6280\u672f\u3002", "result": "\u5927\u591a\u6570\u4f18\u5316\u6280\u672f\u4e0e\u73b0\u6709\u7814\u7a76\u5efa\u8bae\u4e00\u81f4\uff1b\u867d\u7136\u6784\u5efa\u548c\u8fd0\u884cAI\u4ee3\u7406\u672c\u8eab\u80fd\u8017\u5f88\u9ad8\uff0c\u4f46\u5b83\u4eec\u5728\u751f\u6210\u8f6f\u4ef6\u5de5\u4ef6\u65f6\u8868\u73b0\u51fa\u80fd\u6e90\u610f\u8bc6\uff1b\u7136\u800c\uff0c\u80fd\u6e90\u4f18\u5316\u76f8\u5173\u7684PRs\u63a5\u53d7\u7387\u4f4e\u4e8e\u5176\u4ed6PRs\uff0c\u4e3b\u8981\u56e0\u4e3a\u5bf9\u53ef\u7ef4\u62a4\u6027\u4ea7\u751f\u8d1f\u9762\u5f71\u54cd\u3002", "conclusion": "AI\u7f16\u7801\u4ee3\u7406\u5728\u751f\u6210\u8f6f\u4ef6\u65f6\u786e\u5b9e\u5177\u6709\u80fd\u6e90\u610f\u8bc6\uff0c\u4f46\u80fd\u6e90\u4f18\u5316\u76f8\u5173\u7684\u4ee3\u7801\u4fee\u6539\u5f80\u5f80\u56e0\u53ef\u7ef4\u62a4\u6027\u95ee\u9898\u800c\u88ab\u62d2\u7edd\uff0c\u9700\u8981\u5728\u80fd\u6e90\u6548\u7387\u548c\u4ee3\u7801\u8d28\u91cf\u4e4b\u95f4\u627e\u5230\u5e73\u8861\u3002"}}
{"id": "2512.24656", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.24656", "abs": "https://arxiv.org/abs/2512.24656", "authors": ["Mir Mohammad Yousuf", "Shabir Ahmad Sofi"], "title": "Characterizing Bugs and Quality Attributes in Quantum Software: A Large-Scale Empirical Study", "comment": null, "summary": "Quantum Software Engineering (QSE) is essential for ensuring the reliability and maintainability of hybrid quantum-classical systems, yet empirical evidence on how bugs emerge and affect quality in real-world quantum projects remains limited. This study presents the first ecosystem-scale longitudinal analysis of software defects across 123 open source quantum repositories from 2012 to 2024, spanning eight functional categories, including full-stack libraries, simulators, annealing, algorithms, compilers, assembly, cryptography, and experimental computing. Using a mixed method approach combining repository mining, static code analysis, issue metadata extraction, and a validated rule-based classification framework, we analyze 32,296 verified bug reports. Results show that full-stack libraries and compilers are the most defect-prone categories due to circuit, gate, and transpilation-related issues, while simulators are mainly affected by measurement and noise modeling errors. Classical bugs primarily impact usability and interoperability, whereas quantum-specific bugs disproportionately degrade performance, maintainability, and reliability. Longitudinal analysis indicates ecosystem maturation, with defect densities peaking between 2017 and 2021 and declining thereafter. High-severity defects cluster in cryptography, experimental computing, and compiler toolchains. Repositories employing automated testing detect more defects and resolve issues faster. A negative binomial regression further shows that automated testing is associated with an approximate 60 percent reduction in expected defect incidence. Overall, this work provides the first large-scale data-driven characterization of quantum software defects and offers empirical guidance for improving testing, documentation, and maintainability practices in QSE.", "AI": {"tldr": "\u5bf9123\u4e2a\u5f00\u6e90\u91cf\u5b50\u9879\u76ee\uff082012-2024\u5e74\uff09\u768432,296\u4e2a\u5df2\u9a8c\u8bc1bug\u62a5\u544a\u8fdb\u884c\u9996\u6b21\u751f\u6001\u7cfb\u7edf\u89c4\u6a21\u7eb5\u5411\u5206\u6790\uff0c\u63ed\u793a\u4e86\u91cf\u5b50\u8f6f\u4ef6\u7f3a\u9677\u7684\u7279\u5f81\u3001\u5206\u5e03\u548c\u6f14\u5316\u89c4\u5f8b\u3002", "motivation": "\u91cf\u5b50\u8f6f\u4ef6\u5de5\u7a0b(QSE)\u5bf9\u786e\u4fdd\u6df7\u5408\u91cf\u5b50-\u7ecf\u5178\u7cfb\u7edf\u7684\u53ef\u9760\u6027\u548c\u53ef\u7ef4\u62a4\u6027\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5173\u4e8e\u771f\u5b9e\u91cf\u5b50\u9879\u76ee\u4e2dbug\u5982\u4f55\u51fa\u73b0\u53ca\u5f71\u54cd\u8d28\u91cf\u7684\u5b9e\u8bc1\u8bc1\u636e\u4ecd\u7136\u6709\u9650\u3002", "method": "\u91c7\u7528\u6df7\u5408\u65b9\u6cd5\uff1a\u7ed3\u5408\u4ed3\u5e93\u6316\u6398\u3001\u9759\u6001\u4ee3\u7801\u5206\u6790\u3001\u95ee\u9898\u5143\u6570\u636e\u63d0\u53d6\u548c\u7ecf\u8fc7\u9a8c\u8bc1\u7684\u57fa\u4e8e\u89c4\u5219\u7684\u5206\u7c7b\u6846\u67b6\uff0c\u5206\u67908\u4e2a\u529f\u80fd\u7c7b\u522b\uff08\u5168\u6808\u5e93\u3001\u6a21\u62df\u5668\u3001\u9000\u706b\u3001\u7b97\u6cd5\u3001\u7f16\u8bd1\u5668\u3001\u6c47\u7f16\u3001\u5bc6\u7801\u5b66\u3001\u5b9e\u9a8c\u8ba1\u7b97\uff09\u7684\u91cf\u5b50\u9879\u76ee\u3002", "result": "\u5168\u6808\u5e93\u548c\u7f16\u8bd1\u5668\u662f\u6700\u5bb9\u6613\u51fa\u9519\u7684\u7c7b\u522b\uff08\u7535\u8def\u3001\u95e8\u548c\u8f6c\u8bd1\u76f8\u5173\u95ee\u9898\uff09\uff1b\u6a21\u62df\u5668\u4e3b\u8981\u53d7\u6d4b\u91cf\u548c\u566a\u58f0\u5efa\u6a21\u9519\u8bef\u5f71\u54cd\u3002\u7ecf\u5178bug\u4e3b\u8981\u5f71\u54cd\u53ef\u7528\u6027\u548c\u4e92\u64cd\u4f5c\u6027\uff0c\u800c\u91cf\u5b50\u7279\u5b9abug\u4e0d\u6210\u6bd4\u4f8b\u5730\u964d\u4f4e\u6027\u80fd\u3001\u53ef\u7ef4\u62a4\u6027\u548c\u53ef\u9760\u6027\u3002\u7f3a\u9677\u5bc6\u5ea6\u57282017-2021\u5e74\u8fbe\u5230\u5cf0\u503c\u540e\u4e0b\u964d\u3002\u91c7\u7528\u81ea\u52a8\u5316\u6d4b\u8bd5\u7684\u4ed3\u5e93\u80fd\u68c0\u6d4b\u66f4\u591a\u7f3a\u9677\u5e76\u66f4\u5feb\u89e3\u51b3\u95ee\u9898\u3002", "conclusion": "\u8fd9\u662f\u9996\u6b21\u5927\u89c4\u6a21\u6570\u636e\u9a71\u52a8\u7684\u91cf\u5b50\u8f6f\u4ef6\u7f3a\u9677\u7279\u5f81\u63cf\u8ff0\uff0c\u4e3a\u6539\u8fdbQSE\u4e2d\u7684\u6d4b\u8bd5\u3001\u6587\u6863\u548c\u7ef4\u62a4\u5b9e\u8df5\u63d0\u4f9b\u4e86\u5b9e\u8bc1\u6307\u5bfc\u3002\u8d1f\u4e8c\u9879\u56de\u5f52\u663e\u793a\u81ea\u52a8\u5316\u6d4b\u8bd5\u4e0e\u9884\u671f\u7f3a\u9677\u53d1\u751f\u7387\u964d\u4f4e\u7ea660%\u76f8\u5173\u3002"}}
{"id": "2512.24858", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.24858", "abs": "https://arxiv.org/abs/2512.24858", "authors": ["Ke Ma", "Jianjun Huang", "Wei You", "Bin Liang", "Jingzheng Wu", "Yanjun Wu", "Yuanjun Gong"], "title": "Feature Slice Matching for Precise Bug Detection", "comment": "Accepted by FSE2026", "summary": "Measuring the function similarity to detect bugs is effective, but the statements unrelated to the bugs can impede the performance due to the noise interference. Suppressing the noise interference in existing works does not manage the tough job, i.e., eliminating the noise in the targets. In this paper, we propose MATUS to mitigate the target noise for precise bug detection based on similarity measurement. Feature slices are extracted from both the buggy query and the targets to represent the semantic feature of (potential) bug logics. In particular, MATUS guides the target slicing with the prior knowledge from the buggy code, in an end-to-end way to pinpoint the slicing criterion in the targets. All feature slices are embedded and compared based on the vector similarity. Buggy candidates are audited to confirm unknown bugs in the targets. Experiments show that MATUS holds advantages in bug detection for real-world projects with acceptable efficiency. In total, MATUS has spotted 31 unknown bugs in the Linux kernel. All of them have been confirmed by the kernel developers, and 11 have been assigned CVEs.", "AI": {"tldr": "MATUS\u901a\u8fc7\u7279\u5f81\u5207\u7247\u548c\u7aef\u5230\u7aef\u76ee\u6807\u566a\u58f0\u6291\u5236\u6280\u672f\uff0c\u63d0\u5347\u57fa\u4e8e\u76f8\u4f3c\u6027\u6d4b\u91cf\u7684bug\u68c0\u6d4b\u7cbe\u5ea6\uff0c\u5728Linux\u5185\u6838\u4e2d\u53d1\u73b031\u4e2a\u672a\u77e5bug", "motivation": "\u73b0\u6709\u57fa\u4e8e\u51fd\u6570\u76f8\u4f3c\u6027\u7684bug\u68c0\u6d4b\u65b9\u6cd5\u53d7\u65e0\u5173\u8bed\u53e5\uff08\u566a\u58f0\uff09\u5e72\u6270\uff0c\u7279\u522b\u662f\u76ee\u6807\u4ee3\u7801\u4e2d\u7684\u566a\u58f0\u96be\u4ee5\u6d88\u9664\uff0c\u5f71\u54cd\u68c0\u6d4b\u6027\u80fd", "method": "1. \u4ecebuggy\u67e5\u8be2\u548c\u76ee\u6807\u4ee3\u7801\u4e2d\u63d0\u53d6\u7279\u5f81\u5207\u7247\u8868\u793a\u8bed\u4e49\u7279\u5f81\uff1b2. \u5229\u7528buggy\u4ee3\u7801\u7684\u5148\u9a8c\u77e5\u8bc6\u6307\u5bfc\u76ee\u6807\u5207\u7247\uff0c\u7aef\u5230\u7aef\u786e\u5b9a\u5207\u7247\u6807\u51c6\uff1b3. \u6240\u6709\u7279\u5f81\u5207\u7247\u5d4c\u5165\u5411\u91cf\u5e76\u57fa\u4e8e\u76f8\u4f3c\u6027\u6bd4\u8f83\uff1b4. \u5ba1\u8ba1\u5019\u9009bug\u786e\u8ba4\u672a\u77e5\u6f0f\u6d1e", "result": "MATUS\u5728\u771f\u5b9e\u9879\u76ee\u4e2d\u5177\u6709bug\u68c0\u6d4b\u4f18\u52bf\u4e14\u6548\u7387\u53ef\u63a5\u53d7\uff0c\u5728Linux\u5185\u6838\u4e2d\u53d1\u73b031\u4e2a\u672a\u77e5bug\uff0c\u5168\u90e8\u5f97\u5230\u5185\u6838\u5f00\u53d1\u8005\u786e\u8ba4\uff0c\u5176\u4e2d11\u4e2a\u88ab\u5206\u914dCVE\u7f16\u53f7", "conclusion": "MATUS\u901a\u8fc7\u6291\u5236\u76ee\u6807\u566a\u58f0\u5b9e\u73b0\u4e86\u66f4\u7cbe\u786e\u7684\u57fa\u4e8e\u76f8\u4f3c\u6027\u7684bug\u68c0\u6d4b\uff0c\u5728\u771f\u5b9e\u4e16\u754c\u9879\u76ee\u4e2d\u9a8c\u8bc1\u4e86\u6709\u6548\u6027"}}
{"id": "2512.24941", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.24941", "abs": "https://arxiv.org/abs/2512.24941", "authors": ["Zhiyong Zhang", "Xiaoyan Zhang", "Xiaoqi Li"], "title": "Securing High-Concurrency Ticket Sales: A Framework Based on Microservice", "comment": null, "summary": "The railway ticketing system is one of the most important public service infrastructure. In peak periods such as holidays, it is often faced with the challenge of high concurrency scenarios because of a large number of users accessing at the same time. The traditional aggregation architecture can not meet the peak user requirements because of its insufficient fault tolerance and low ability. Therefore, the system needs to use microservice architecture for development, and add multiple security methods to ensure that the system can have good stability and data consistency under high concurrency scenarios, and can respond quickly to user requests. This paper introduces the use of B/S architecture and Spring Cloud to design and develop a railway ticket purchase system that can maintain stability and reliability under high concurrency scenarios, and formulate multiple security design methods for the system. This system integrates a range of functions, such as real-time train inquiries, dynamic seat updates, online seat selection, and ticket purchasing, effectively addressing common problems associated with offline ticket purchasing, such as long queues and delayed information. It enables a complete online process from inquiry and booking to payment and refunds. Furthermore, the \"add passenger\" function allows users to purchase tickets for others, extending the convenience of online ticketing to people with limited internet access. The system design prioritizes security and stability, while also focusing on high performance, and achieves these goals through a carefully designed architecture and the integration of multiple middleware components. After the completion of the system development, the core interface of the system is tested, and then the results are analyzed. The test data proves that the system has good ability and stability under high concurrency.", "AI": {"tldr": "\u57fa\u4e8eSpring Cloud\u5fae\u670d\u52a1\u67b6\u6784\u7684\u94c1\u8def\u8d2d\u7968\u7cfb\u7edf\uff0c\u901a\u8fc7B/S\u67b6\u6784\u548c\u591a\u79cd\u5b89\u5168\u8bbe\u8ba1\uff0c\u5728\u9ad8\u5e76\u53d1\u573a\u666f\u4e0b\u4fdd\u6301\u7a33\u5b9a\u6027\u548c\u53ef\u9760\u6027\uff0c\u5b9e\u73b0\u4ece\u67e5\u8be2\u5230\u652f\u4ed8\u7684\u5168\u6d41\u7a0b\u5728\u7ebf\u670d\u52a1\u3002", "motivation": "\u4f20\u7edf\u805a\u5408\u67b6\u6784\u5728\u8282\u5047\u65e5\u7b49\u9ad8\u5e76\u53d1\u573a\u666f\u4e0b\u5b58\u5728\u5bb9\u9519\u6027\u4e0d\u8db3\u548c\u5904\u7406\u80fd\u529b\u4f4e\u7684\u95ee\u9898\uff0c\u65e0\u6cd5\u6ee1\u8db3\u5cf0\u503c\u7528\u6237\u9700\u6c42\uff0c\u9700\u8981\u91c7\u7528\u5fae\u670d\u52a1\u67b6\u6784\u6765\u63d0\u5347\u7cfb\u7edf\u7684\u7a33\u5b9a\u6027\u3001\u6570\u636e\u4e00\u81f4\u6027\u548c\u54cd\u5e94\u901f\u5ea6\u3002", "method": "\u91c7\u7528B/S\u67b6\u6784\u548cSpring Cloud\u5fae\u670d\u52a1\u6846\u67b6\u8fdb\u884c\u7cfb\u7edf\u8bbe\u8ba1\u4e0e\u5f00\u53d1\uff0c\u96c6\u6210\u591a\u79cd\u4e2d\u95f4\u4ef6\u7ec4\u4ef6\uff0c\u5236\u5b9a\u591a\u91cd\u5b89\u5168\u8bbe\u8ba1\u65b9\u6cd5\uff0c\u5b9e\u73b0\u5b9e\u65f6\u8f66\u6b21\u67e5\u8be2\u3001\u52a8\u6001\u5ea7\u4f4d\u66f4\u65b0\u3001\u5728\u7ebf\u9009\u5ea7\u3001\u8d2d\u7968\u7b49\u529f\u80fd\u3002", "result": "\u7cfb\u7edf\u5f00\u53d1\u5b8c\u6210\u540e\u5bf9\u6838\u5fc3\u63a5\u53e3\u8fdb\u884c\u6d4b\u8bd5\uff0c\u6d4b\u8bd5\u6570\u636e\u8bc1\u660e\u7cfb\u7edf\u5728\u9ad8\u5e76\u53d1\u573a\u666f\u4e0b\u5177\u6709\u826f\u597d\u7684\u5904\u7406\u80fd\u529b\u548c\u7a33\u5b9a\u6027\uff0c\u80fd\u591f\u5feb\u901f\u54cd\u5e94\u7528\u6237\u8bf7\u6c42\u3002", "conclusion": "\u57fa\u4e8e\u5fae\u670d\u52a1\u67b6\u6784\u7684\u94c1\u8def\u8d2d\u7968\u7cfb\u7edf\u80fd\u591f\u6709\u6548\u89e3\u51b3\u4f20\u7edf\u7ebf\u4e0b\u8d2d\u7968\u7684\u6392\u961f\u65f6\u95f4\u957f\u3001\u4fe1\u606f\u5ef6\u8fdf\u7b49\u95ee\u9898\uff0c\u901a\u8fc7\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u67b6\u6784\u548c\u4e2d\u95f4\u4ef6\u96c6\u6210\uff0c\u5b9e\u73b0\u4e86\u5b89\u5168\u3001\u7a33\u5b9a\u3001\u9ad8\u6027\u80fd\u7684\u5728\u7ebf\u8d2d\u7968\u670d\u52a1\u3002"}}
