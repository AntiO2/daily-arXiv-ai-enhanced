{"id": "2510.13857", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.13857", "abs": "https://arxiv.org/abs/2510.13857", "authors": ["Qiang Xu", "Xiangyu Wen", "Changran Xu", "Zeju Li", "Jianyuan Zhong"], "title": "From Craft to Constitution: A Governance-First Paradigm for Principled Agent Engineering", "comment": null, "summary": "The advent of powerful Large Language Models (LLMs) has ushered in an ``Age\nof the Agent,'' enabling autonomous systems to tackle complex goals. However,\nthe transition from prototype to production is hindered by a pervasive ``crisis\nof craft,'' resulting in agents that are brittle, unpredictable, and ultimately\nuntrustworthy in mission-critical applications. This paper argues this crisis\nstems from a fundamental paradigm mismatch -- attempting to command inherently\nprobabilistic processors with the deterministic mental models of traditional\nsoftware engineering. To solve this crisis, we introduce a governance-first\nparadigm for principled agent engineering, embodied in a formal architecture we\ncall ArbiterOS."}
{"id": "2510.13859", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.13859", "abs": "https://arxiv.org/abs/2510.13859", "authors": ["Ruchit Rawal", "Jeffrey Yang Fan Chiang", "Chihao Shen", "Jeffery Siyuan Tian", "Aastha Mahajan", "Tom Goldstein", "Yizheng Chen"], "title": "Benchmarking Correctness and Security in Multi-Turn Code Generation", "comment": null, "summary": "AI coding assistants powered by large language models (LLMs) have transformed\nsoftware development, significantly boosting productivity. While existing\nbenchmarks evaluate the correctness and security of LLM-generated code, they\nare typically limited to single-turn tasks that do not reflect the iterative\nnature of real-world development. We introduce MT-Sec, the first benchmark to\nsystematically evaluate both correctness and security in multi-turn coding\nscenarios. We construct this using a synthetic data pipeline that transforms\nexisting single-turn tasks into semantically aligned multi-turn interaction\nsequences, allowing reuse of original test suites while modeling the complexity\nof real-world coding processes. We evaluate 32 open- and closed-source models,\nand three agent-scaffolding on MT-Sec and observe a consistent 20-27% drop in\n\"correct and secure\" outputs from single-turn to multi-turn settings -- even\namong state-of-the-art models. Beyond full-program generation, we also evaluate\nmodels on multi-turn code-diff generation -- an unexplored yet practically\nrelevant setting -- and find that models perform worse here, with increased\nrates of functionally incorrect and insecure outputs. Finally, we find that\nwhile agent scaffoldings boost single-turn code generation performance, they\nare not quite as effective in multi-turn evaluations. Together, these findings\nhighlight the need for benchmarks that jointly evaluate correctness and\nsecurity in multi-turn, real-world coding workflows."}
{"id": "2510.13914", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.13914", "abs": "https://arxiv.org/abs/2510.13914", "authors": ["Janghan Yoon", "Jaegwan Cho", "Junhyeok Kim", "Jiwan Chung", "Jaehyun Jeon", "Youngjae Yu"], "title": "A11YN: aligning LLMs for accessible web UI code generation", "comment": null, "summary": "Large language models (LLMs) have recently demonstrated strong capabilities\nin generating functional and aesthetic web interfaces directly from\ninstructions. However, these models often replicate accessibility flaws from\ntheir training data, resulting in interfaces that exclude users with diverse\nneeds and contexts. To address this gap, we introduce A11yn, the first method\nthat aligns code-generating LLMs to reliably produce accessibility-compliant\nweb UIs. A11yn optimizes a novel reward function that penalizes violations of\nthe Web Content Accessibility Guidelines (WCAG), with penalties scaled to the\nseverity of each violation as identified by an accessibility testing engine. To\nsupport training, we construct UIReq-6.8K, a dataset of 6,800 diverse\ninstructions for web UI generation. For evaluation, we introduce RealUIReq-300,\na benchmark of 300 real-world web UI requests grounded and manually curated\nfrom public web pages, spanning a broad range of use cases. Empirical results\nshow that A11yn significantly outperforms strong baselines, lowering the\nInaccessibility Rate by 60% over the base model while preserving semantic\nfidelity and visual quality of generated UIs. These findings demonstrate that\naccessibility can be systematically optimized within LLMs, showing the\nfeasibility of aligning code generation for accessibility."}
{"id": "2510.14024", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2510.14024", "abs": "https://arxiv.org/abs/2510.14024", "authors": ["Thanh Son Phung", "Douglas Thain"], "title": "Efficiently Executing High-throughput Lightweight LLM Inference Applications on Heterogeneous Opportunistic GPU Clusters with Pervasive Context Management", "comment": null, "summary": "The rise of Generative AI introduces a new class of HPC workloads that\nintegrates lightweight LLMs with traditional high-throughput applications to\naccelerate scientific discovery. The current design of HPC clusters is\ninadequate to support this new class however, either incurring long wait times\non static batch queues or repeatedly paying expensive LLM startup costs upon\nresource preemption. To circumvent both the long queues and high startup costs,\nwe propose to \"decouple\" the LLM initialization context from the actual LLM\ninferences, and retain the context in GPUs until it is no longer needed, a\ntechnique we term \"Pervasive Context Management\". We transform a fact\nverification application to enable this technique, allowing it to reduce its\nexecution time by 72.1% (from 3 hours to 48 minutes) using the same amount of\nGPUs, and scale opportunistically on 32.8% of all GPUs in the cluster and\nfurther reduce the execution time to 13 minutes."}
{"id": "2510.13992", "categories": ["cs.SE", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.13992", "abs": "https://arxiv.org/abs/2510.13992", "authors": ["Quoc Hung Le", "Thanh Le-Cong", "Bach Le", "Bowen Xu"], "title": "Signature in Code Backdoor Detection, how far are we?", "comment": "20 pages, 3 figures", "summary": "As Large Language Models (LLMs) become increasingly integrated into software\ndevelopment workflows, they also become prime targets for adversarial attacks.\nAmong these, backdoor attacks are a significant threat, allowing attackers to\nmanipulate model outputs through hidden triggers embedded in training data.\nDetecting such backdoors remains a challenge, and one promising approach is the\nuse of Spectral Signature defense methods that identify poisoned data by\nanalyzing feature representations through eigenvectors. While some prior works\nhave explored Spectral Signatures for backdoor detection in neural networks,\nrecent studies suggest that these methods may not be optimally effective for\ncode models. In this paper, we revisit the applicability of Spectral\nSignature-based defenses in the context of backdoor attacks on code models. We\nsystematically evaluate their effectiveness under various attack scenarios and\ndefense configurations, analyzing their strengths and limitations. We found\nthat the widely used setting of Spectral Signature in code backdoor detection\nis often suboptimal. Hence, we explored the impact of different settings of the\nkey factors. We discovered a new proxy metric that can more accurately estimate\nthe actual performance of Spectral Signature without model retraining after the\ndefense."}
{"id": "2510.14050", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2510.14050", "abs": "https://arxiv.org/abs/2510.14050", "authors": ["Michael Mandulak", "Sayan Ghosh", "S M Ferdous", "Mahantesh Halappanavar", "George Slota"], "title": "Anonymized Network Sensing using C++26 std::execution on GPUs", "comment": null, "summary": "Large-scale network sensing plays a vital role in network traffic analysis\nand characterization. As network packet data grows increasingly large, parallel\nmethods have become mainstream for network analytics. While effective,\nGPU-based implementations still face start-up challenges in host-device memory\nmanagement and porting complex workloads on devices, among others. To mitigate\nthese challenges, composable frameworks have emerged using modern C++\nprogramming language, for efficiently deploying analytics tasks on GPUs.\nSpecifically, the recent C++26 Senders model of asynchronous data operation\nchaining provides a simple interface for bulk pushing tasks to varied device\nexecution contexts.\n  Considering the prominence of contemporary dense-GPU platforms and\nvendor-leveraged software libraries, such a programming model consider GPUs as\nfirst-class execution resources (compared to traditional host-centric\nprogramming models), allowing convenient development of multi-GPU application\nworkloads via expressive and standardized asynchronous semantics. In this\npaper, we discuss practical aspects of developing the Anonymized Network\nSensing Graph Challenge on dense-GPU systems using the recently proposed C++26\nSenders model. Adopting a generic and productive programming model does not\nnecessarily impact the critical-path performance (as compared to low-level\nproprietary vendor-based programming models): our commodity library-based\nimplementation achieves up to 55x performance improvements on 8x NVIDIA A100\nGPUs as compared to the reference serial GraphBLAS baseline."}
{"id": "2510.14631", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2510.14631", "abs": "https://arxiv.org/abs/2510.14631", "authors": ["UÃ©lison Jean Lopes dos Santos", "Alessandro Ferri", "Szilard Nistor", "Riccardo Tommasini", "Carsten Binnig", "Manisha Luthra"], "title": "Towards a Multimodal Stream Processing System", "comment": null, "summary": "In this paper, we present a vision for a new generation of multimodal\nstreaming systems that embed MLLMs as first-class operators, enabling real-time\nquery processing across multiple modalities. Achieving this is non-trivial:\nwhile recent work has integrated MLLMs into databases for multimodal queries,\nstreaming systems require fundamentally different approaches due to their\nstrict latency and throughput requirements. Our approach proposes novel\noptimizations at all levels, including logical, physical, and semantic query\ntransformations that reduce model load to improve throughput while preserving\naccuracy. We demonstrate this with \\system{}, a prototype leveraging such\noptimizations to improve performance by more than an order of magnitude.\nMoreover, we discuss a research roadmap that outlines open research challenges\nfor building a scalable and efficient multimodal stream processing systems."}
{"id": "2510.14036", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.14036", "abs": "https://arxiv.org/abs/2510.14036", "authors": ["Qiushi Wu", "Yue Xiao", "Dhilung Kirat", "Kevin Eykholt", "Jiyong Jang", "Douglas Lee Schales"], "title": "One Bug, Hundreds Behind: LLMs for Large-Scale Bug Discovery", "comment": null, "summary": "Fixing bugs in large programs is a challenging task that demands substantial\ntime and effort. Once a bug is found, it is reported to the project\nmaintainers, who work with the reporter to fix it and eventually close the\nissue. However, across the program, there are often similar code segments,\nwhich may also contain the bug, but were missed during discovery. Finding and\nfixing each recurring bug instance individually is labor intensive. Even more\nconcerning, bug reports can inadvertently widen the attack surface as they\nprovide attackers with an exploitable pattern that may be unresolved in other\nparts of the program.\n  In this paper, we explore these Recurring Pattern Bugs (RPBs) that appear\nrepeatedly across various code segments of a program or even in different\nprograms, stemming from a same root cause, but are unresolved. Our\ninvestigation reveals that RPBs are widespread and can significantly compromise\nthe security of software programs. This paper introduces BugStone, a program\nanalysis system empowered by LLVM and a Large Language Model (LLM). The key\nobservation is that many RPBs have one patched instance, which can be leveraged\nto identify a consistent error pattern, such as a specific API misuse. By\nexamining the entire program for this pattern, it is possible to identify\nsimilar sections of code that may be vulnerable. Starting with 135 unique RPBs,\nBugStone identified more than 22K new potential issues in the Linux kernel.\nManual analysis of 400 of these findings confirmed that 246 were valid. We also\ncreated a dataset from over 1.9K security bugs reported by 23 recent top-tier\nconference works. We manually annotate the dataset, identify 80 recurring\npatterns and 850 corresponding fixes. Even with a cost-efficient model choice,\nBugStone achieved 92.2% precision and 79.1% pairwise accuracy on the dataset."}
{"id": "2510.14126", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2510.14126", "abs": "https://arxiv.org/abs/2510.14126", "authors": ["Nikos Pagonas", "Yeounoh Chung", "Kostis Kaffes", "Arvind Krishnamurthy"], "title": "Cortex: Workflow-Aware Resource Pooling and Scheduling for Agentic Serving", "comment": null, "summary": "We introduce Cortex, a prototype workflow-aware serving platform designed for\nagentic workloads. The core principle of Cortex is stage isolation: it\nprovisions dedicated resource pools for each distinct stage of an agentic\nworkflow. This simple yet powerful strategy mitigates inter-stage interference\nin compute and memory, leading to better KV cache utilization, higher\nthroughput, and more predictable performance. By customizing resource\nallocation and scheduling within each distinct stage of agentic workflows,\nCortex lays the groundwork for more advanced, agent-native serving paradigms,\nincluding malleable resource management, speculative execution of workflow\nbranches, and a shared, multi-tiered cache for \"agentic state.\""}
{"id": "2510.14115", "categories": ["cs.SE", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.14115", "abs": "https://arxiv.org/abs/2510.14115", "authors": ["Philipp Bauerfeind", "Amir Salarpour", "David Fernandez", "Pedram MohajerAnsari", "Johannes Reschke", "Mert D. PesÃ©"], "title": "David vs. Goliath: A comparative study of different-sized LLMs for code generation in the domain of automotive scenario generation", "comment": null, "summary": "Scenario simulation is central to testing autonomous driving systems. Scenic,\na domain-specific language (DSL) for CARLA, enables precise and reproducible\nscenarios, but NL-to-Scenic generation with large language models (LLMs)\nsuffers from scarce data, limited reproducibility, and inconsistent metrics. We\nintroduce NL2Scenic, an open dataset and framework with 146 NL/Scenic pairs, a\ndifficulty-stratified 30-case test split, an Example Retriever, and 14\nprompting variants (ZS, FS, CoT, SP, MoT). We evaluate 13 models: four\nproprietary (GPT-4o, GPT-5, Claude-Sonnet-4, Gemini-2.5-pro) and nine\nopen-source code models (Qwen2.5Coder 0.5B-32B; CodeLlama 7B/13B/34B), using\ntext metrics (BLEU, ChrF, EDIT-SIM, CrystalBLEU) and execution metrics\n(compilation and generation), and compare them with an expert study (n=11).\nEDIT-SIM correlates best with human judgments; we also propose EDIT-COMP (F1 of\nEDIT-SIM and compilation) as a robust dataset-level proxy that improves ranking\nfidelity. GPT-4o performs best overall, while Qwen2.5Coder-14B reaches about 88\npercent of its expert score on local hardware. Retrieval-augmented prompting,\nFew-Shot with Example Retriever (FSER), consistently boosts smaller models, and\nscaling shows diminishing returns beyond mid-size, with Qwen2.5Coder\noutperforming CodeLlama at comparable scales. NL2Scenic and EDIT-COMP offer a\nstandardized, reproducible basis for evaluating Scenic code generation and\nindicate that mid-size open-source models are practical, cost-effective options\nfor autonomous-driving scenario programming."}
{"id": "2510.14147", "categories": ["cs.DC", "cs.CG", "cs.DS"], "pdf": "https://arxiv.org/pdf/2510.14147", "abs": "https://arxiv.org/abs/2510.14147", "authors": ["Gabriel Raulet", "Dmitriy Morozov", "Aydin Buluc", "Katherine Yelick"], "title": "Distributed-Memory Parallel Algorithms for Fixed-Radius Near Neighbor Graph Construction", "comment": "11 pages, 5 figures, 3 tables", "summary": "Computing fixed-radius near-neighbor graphs is an important first step for\nmany data analysis algorithms. Near-neighbor graphs connect points that are\nclose under some metric, endowing point clouds with a combinatorial structure.\nAs computing power and data acquisition methods advance, diverse sources of\nlarge scientific datasets would greatly benefit from scalable solutions to this\ncommon subroutine for downstream analysis. Prior work on parallel nearest\nneighbors has made great progress in problems like k-nearest and approximate\nnearest neighbor search problems, with particular attention on Euclidean\nspaces. Yet many applications need exact solutions and non-Euclidean metrics.\nThis paper presents a scalable sparsity-aware distributed memory algorithm\nusing cover trees to compute near-neighbor graphs in general metric spaces. We\nprovide a shared-memory algorithm for cover tree construction and demonstrate\nits competitiveness with state-of-the-art fixed-radius search data structures.\nWe then introduce two distributed-memory algorithms for the near-neighbor graph\nproblem, a simple point-partitioning strategy and a spatial-partitioning\nstrategy, which leverage the cover tree algorithm on each node. Our algorithms\nexhibit parallel scaling across a variety of real and synthetic datasets for\nboth traditional and non-traditional metrics. On real world high dimensional\ndatasets with one million points, we achieve speedups up to 678.34x over the\nstate-of-the-art using 1024 cores for graphs with 70 neighbors per vertex (on\naverage), and up to 1590.99x using 4096 cores for graphs with 500 neighbors per\nvertex (on average)."}
{"id": "2510.14279", "categories": ["cs.SE", "cs.PL"], "pdf": "https://arxiv.org/pdf/2510.14279", "abs": "https://arxiv.org/abs/2510.14279", "authors": ["Evangelos Lamprou", "Seong-Heon Jung", "Mayank Keoliya", "Lukas Lazarek", "Konstantinos Kallas", "Michael Greenberg", "Nikos Vasilakis"], "title": "Caruca: Effective and Efficient Specification Mining for Opaque Software Components", "comment": null, "summary": "A wealth of state-of-the-art systems demonstrate impressive improvements in\nperformance, security, and reliability on programs composed of opaque\ncomponents, such as Unix shell commands. To reason about commands, these\nsystems require partial specifications. However, creating such specifications\nis a manual, laborious, and error-prone process, limiting the practicality of\nthese systems. This paper presents Caruca, a system for automatic specification\nmining for opaque commands. To overcome the challenge of language diversity\nacross commands, Caruca first instruments a large language model to translate a\ncommand's user-facing documentation into a structured invocation syntax. Using\nthis representation, Caruca explores the space of syntactically valid command\ninvocations and execution environments. Caruca concretely executes each\ncommand-environment pair, interposing at the system-call and filesystem level\nto extract key command properties such as parallelizability and filesystem pre-\nand post-conditions. These properties can be exported in multiple specification\nformats and are immediately usable by existing systems. Applying Caruca across\n60 GNU Coreutils, POSIX, and third-party commands across several\nspecification-dependent systems shows that Caruca generates correct\nspecifications for all but one case, completely eliminating manual effort from\nthe process and currently powering the full specifications for a\nstate-of-the-art static analysis tool."}
{"id": "2510.14151", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2510.14151", "abs": "https://arxiv.org/abs/2510.14151", "authors": ["Saeed Moradi", "Koosha Esmaeilzadeh Khorasani", "Sara Rouhani"], "title": "Privacy-Preserving and Incentive-Driven Relay-Based Framework for Cross-Domain Blockchain Interoperability", "comment": null, "summary": "Interoperability is essential for transforming blockchains from isolated\nnetworks into collaborative ecosystems, unlocking their full potential. While\nsignificant progress has been made in public blockchain interoperability,\nbridging permissioned and permissionless blockchains poses unique challenges\ndue to differences in access control, architectures, and security requirements.\nThis paper introduces a blockchain-agnostic framework to enable\ninteroperability between permissioned and permissionless networks. Leveraging\ncryptographic techniques, the framework ensures secure data exchanges. Its\nlightweight architectural design simplifies implementation and maintenance,\nwhile the integration of Clover and Dandelion++ protocols enhances transaction\nanonymity. Performance evaluations demonstrate the framework's effectiveness in\nachieving secure and efficient interoperability by measuring the forwarding\ntime, the throughput, the availability, and their collusion impact of the\nsystem across heterogeneous blockchain ecosystems."}
{"id": "2510.14292", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.14292", "abs": "https://arxiv.org/abs/2510.14292", "authors": ["Haolin Pan", "Hongbin Zhang", "Mingjie Xing", "Yanjun Wu"], "title": "A Hybrid, Knowledge-Guided Evolutionary Framework for Personalized Compiler Auto-Tuning", "comment": null, "summary": "Compiler pass auto-tuning is critical for enhancing software performance, yet\nfinding the optimal pass sequence for a specific program is an NP-hard problem.\nTraditional, general-purpose optimization flags like -O3 and -Oz adopt a\none-size-fits-all approach, often failing to unlock a program's full\nperformance potential. To address this challenge, we propose a novel Hybrid,\nKnowledge-Guided Evolutionary Framework. This framework intelligently guides\nonline, personalized optimization using knowledge extracted from a large-scale\noffline analysis phase. During the offline stage, we construct a comprehensive\ncompilation knowledge base composed of four key components: (1) Pass Behavioral\nVectors to quantitatively capture the effectiveness of each optimization; (2)\nPass Groups derived from clustering these vectors based on behavior similarity;\n(3) a Synergy Pass Graph to model beneficial sequential interactions; and (4) a\nlibrary of Prototype Pass Sequences evolved for distinct program types. In the\nonline stage, a bespoke genetic algorithm leverages this rich knowledge base\nthrough specially designed, knowledge-infused genetic operators. These\noperators transform the search by performing semantically-aware recombination\nand targeted, restorative mutations. On a suite of seven public datasets, our\nframework achieves an average of 11.0% additional LLVM IR instruction reduction\nover the highly-optimized opt -Oz baseline, demonstrating its state-of-the-art\ncapability in discovering personalized, high-performance optimization\nsequences."}
{"id": "2510.14186", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2510.14186", "abs": "https://arxiv.org/abs/2510.14186", "authors": ["Pengkun Ren", "Hai Dong", "Nasrin Sohrabi", "Zahir Tari", "Pengcheng Zhang"], "title": "Proof-Carrying Fair Ordering: Asymmetric Verification for BFT via Incremental Graphs", "comment": "18 pages, 4 figures", "summary": "Byzantine Fault-Tolerant (BFT) consensus protocols ensure agreement on\ntransaction ordering despite malicious actors, but unconstrained ordering power\nenables sophisticated value extraction attacks like front running and sandwich\nattacks - a critical threat to blockchain systems. Order-fair consensus curbs\nadversarial value extraction by constraining how leaders may order\ntransactions. While state-of-the-art protocols such as Themis attain strong\nguarantees through graph-based ordering, they ask every replica to re-run the\nleader's expensive ordering computation for validation - an inherently\nsymmetric and redundant paradigm. We present AUTIG, a high-performance,\npluggable order-fairness service that breaks this symmetry. Our key insight is\nthat verifying a fair order does not require re-computing it. Instead,\nverification can be reduced to a stateless audit of succinct, verifiable\nassertions about the ordering graph's properties. AUTIG realizes this via an\nasymmetric architecture: the leader maintains a persistent\nUnconfirmed-Transaction Incremental Graph (UTIG) to amortize graph construction\nacross rounds and emits a structured proof of fairness with each proposal;\nfollowers validate the proof without maintaining historical state. AUTIG\nintroduces three critical innovations: (i) incremental graph maintenance driven\nby threshold-crossing events and state changes; (ii) a decoupled pipeline that\noverlaps leader-side collection/update/extraction with follower-side stateless\nverification; and (iii) a proof design covering all internal pairs in the\nfinalized prefix plus a frontier completeness check to rule out hidden external\ndependencies. We implement AUTIG and evaluate it against symmetric graph-based\nbaselines under partial synchrony. Experiments show higher throughput and lower\nend-to-end latency while preserving gamma-batch-order-fairness."}
{"id": "2510.14339", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.14339", "abs": "https://arxiv.org/abs/2510.14339", "authors": ["Jialu Zhang", "Jialiang Gu", "Wangmeiyu Zhang", "JosÃ© Pablo Cambronero", "John Kolesar", "Ruzica Piskac", "Daming Li", "Hanyuan Shi"], "title": "A Systematic Study of Time Limit Exceeded Errors in Online Programming Assignments", "comment": null, "summary": "Online programming platforms such as Codeforces and LeetCode attract millions\nof users seeking to learn to program or refine their skills for industry\ninterviews. A major challenge for these users is the Time Limit Exceeded (TLE)\nerror, triggered when a program exceeds the execution time bound. Although\ndesigned as a performance safeguard, TLE errors are difficult to resolve: error\nmessages provide no diagnostic insight, platform support is minimal, and\nexisting debugging tools offer little help. As a result, many users abandon\ntheir submissions after repeated TLE failures.\n  This paper presents the first large-scale empirical study of TLE errors in\nonline programming. We manually analyzed 1000 Codeforces submissions with TLE\nerrors, classified their root causes, and traced how users attempted to fix\nthem. Our analysis shows that TLE errors often arise not only from inefficient\nalgorithms but also from infinite loops, improper data structure use, and\ninefficient I/O, challenging the conventional view that TLEs are purely\nperformance issues.\n  Guided by these findings, we introduce Nettle, the first automated repair\ntool specifically designed for TLE errors, and Nettle-Eval, the first framework\nfor evaluating TLE repairs. Integrating LLMs with targeted automated feedback\ngenerated by the compiler and test cases, Nettle produces small, correct code\nedits that eliminate TLEs while preserving functionality. Evaluated on the same\n1000 real-world cases, Nettle achieves a 98.5% fix rate, far exceeding the\nstrongest LLM baseline, and all of its repairs pass both Nettle-Eval and the\nplatform's official checker, confirming the reliability of our framework."}
{"id": "2510.14392", "categories": ["cs.DC", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.14392", "abs": "https://arxiv.org/abs/2510.14392", "authors": ["Hongtao Lyu", "Boyue Liu", "Mingyu Wu", "Haibo Chen"], "title": "FairBatching: Fairness-Aware Batch Formation for LLM Inference", "comment": null, "summary": "Large language model (LLM) inference systems face a fundamental tension\nbetween minimizing Time-to-First-Token (TTFT) latency for new requests and\nmaintaining a high, steady token generation rate (low Time-Per-Output-Token, or\nTPOT) for ongoing requests. Existing stall-free batching schedulers proposed by\nSarathi, while effective at preventing decode stalls, introduce significant\ncomputational unfairness. They prioritize decode tasks excessively,\nsimultaneously leading to underutilized decode slack and unnecessary prefill\nqueuing delays, which collectively degrade the system's overall quality of\nservice (QoS).\n  This work identifies the root cause of this unfairness: the non-monotonic\nnature of Time-Between-Tokens (TBT) as a scheduling metric and the rigid\ndecode-prioritizing policy that fails to adapt to dynamic workload bursts. We\ntherefore propose FairBatching, a novel LLM inference scheduler that enforces\nfair resource allocation between prefill and decode tasks. It features an\nadaptive batch capacity determination mechanism, which dynamically adjusts the\ncomputational budget to improve the GPU utilization without triggering SLO\nviolations. Its fair and dynamic batch formation algorithm breaks away from the\ndecode-prioritizing paradigm, allowing computation resources to be reclaimed\nfrom bursting decode tasks to serve prefill surges, achieving global fairness.\nFurthermore, FairBatching provides a novel load estimation method, enabling\nmore effective coordination with upper-level schedulers. Implemented and\nevaluated on realistic traces, FairBatching significantly reduces TTFT tail\nlatency by up to 2.29x while robustly maintaining TPOT SLOs, achieving overall\n20.0% improvement in single-node capacity and 54.3% improvement in\ncluster-level capacity."}
{"id": "2510.14341", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.14341", "abs": "https://arxiv.org/abs/2510.14341", "authors": ["Xu He", "Shu Wang", "Kun Sun"], "title": "PathFix: Automated Program Repair with Expected Path", "comment": "This is the author's version of a paper accepted at SecDev 2025\n  (IEEE)", "summary": "Automated program repair (APR) techniques are effective in fixing inevitable\ndefects in software, enhancing development efficiency and software robustness.\nHowever, due to the difficulty of generating precise specifications, existing\nAPR methods face two main challenges: generating too many plausible patch\ncandidates and overfitting them to partial test cases. To tackle these\nchallenges, we introduce a new APR method named PathFix, which leverages\npath-sensitive constraints extracted from correct execution paths to generate\npatches for repairing buggy code. It is based on one observation: if a buggy\nprogram is repairable, at least one expected path is supposed to replace the\nfault path in the patched program. PathFix operates in four main steps. First,\nit traces fault paths reaching the fault output in the buggy program. Second,\nit derives expected paths by analyzing the desired correct output on the\ncontrol flow graph, where an expected path defines how a feasible patch leads\nto the correct execution. Third, PathFix generates and evaluates patches by\nsolving state constraints along the expected path. Fourth, we validate the\ncorrectness of the generated patch. To further enhance repair performance and\nmitigate scalability issues introduced by path-sensitive analysis, we integrate\na large language model (LLM) into our framework. Experimental results show that\nPathFix outperforms existing solutions, particularly in handling complex\nprogram structures such as loops and recursion."}
{"id": "2510.14580", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2510.14580", "abs": "https://arxiv.org/abs/2510.14580", "authors": ["Hyein Woo", "Miryeong Kwon", "Jiseon Kim", "Eunjee Na", "Hanjin Choi", "Seonghyeon Jang", "Myoungsoo Jung"], "title": "ScalePool: Hybrid XLink-CXL Fabric for Composable Resource Disaggregation in Unified Scale-up Domains", "comment": null, "summary": "This paper proposes ScalePool, a novel cluster architecture designed to\ninterconnect numerous accelerators using unified hardware interconnects rather\nthan traditional long-distance networking. ScalePool integrates\nAccelerator-Centric Links (XLink) and Compute Express Link (CXL) into a unified\nXLink-CXL hybrid fabric. Specifically, ScalePool employs XLink for\nintra-cluster, low-latency accelerator communication, while using hierarchical\nCXL-based switching fabrics for scalable and coherent inter-cluster memory\nsharing. By abstracting interfaces through CXL, ScalePool structurally resolves\ninteroperability constraints, enabling heterogeneous cluster operation and\ncomposable resource disaggregation. In addition, ScalePool introduces explicit\nmemory tiering: the latency-critical tier-1 combines accelerator-local memory\nwith coherence-centric CXL and XLink, whereas the highcapacity tier-2 employs\ndedicated memory nodes interconnected by a CXL-based fabric, achieving scalable\nand efficient memory pooling. Evaluation results show that ScalePool\naccelerates LLM training by 1.22x on average and up to 1.84x compared to\nconventional RDMA-based environments. Furthermore, the proposed tier-2 memory\ndisaggregation strategy reduces latency by up to 4.5x for memory-intensive\nworkloads."}
{"id": "2510.14465", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.14465", "abs": "https://arxiv.org/abs/2510.14465", "authors": ["Adem Ait", "Gwendal Jouneaux", "Javier Luis CÃ¡novas Izquierdo", "Jordi Cabot"], "title": "Towards Automated Governance: A DSL for Human-Agent Collaboration in Software Projects", "comment": "Accepted in the 40th IEEE/ACM International Conference on Automated\n  Software Engineering, ASE 2025", "summary": "The stakeholders involved in software development are becoming increasingly\ndiverse, with both human contributors from varied backgrounds and AI-powered\nagents collaborating together in the process. This situation presents unique\ngovernance challenges, particularly in Open-Source Software (OSS) projects,\nwhere explicit policies are often lacking or unclear. This paper presents the\nvision and foundational concepts for a novel Domain-Specific Language (DSL)\ndesigned to define and enforce rich governance policies in systems involving\ndiverse stakeholders, including agents. This DSL offers a pathway towards more\nrobust, adaptable, and ultimately automated governance, paving the way for more\neffective collaboration in software projects, especially OSS ones."}
{"id": "2510.14599", "categories": ["cs.DC", "D.4.1; C.4; C.1.4; D.1.3"], "pdf": "https://arxiv.org/pdf/2510.14599", "abs": "https://arxiv.org/abs/2510.14599", "authors": ["Michal Konopa", "Jan Fesl", "Ladislav Ber Ã¡nek"], "title": "JASDA: Introducing Job-Aware Scheduling in Scheduler-Driven Job Atomization", "comment": "25 pages", "summary": "The increasing complexity and temporal variability of workloads on\nMIG-enabled GPUs challenge the scalability of traditional centralized\nscheduling. Building upon the SJA concept, this paper introduces JASDA-a novel\nparadigm that extends SJA from a largely centralized scheduling model toward a\nfully decentralized negotiation process. In JASDA, jobs actively generate and\nscore feasible subjobs in response to scheduler-announced execution windows,\nwhile the scheduler performs policy-driven clearing that balances utilization,\nfairness, and temporal responsiveness. This bidirectional, iterative\ninteraction embeds feedback, calibration, and probabilistic safety directly\ninto the scheduling loop, enabling adaptive and transparent decision-making. By\ncoupling principles from auction theory and online optimization with the\ntemporal granularity of GPU workloads, JASDA provides a scalable foundation for\nmarket-aware and fairness-driven resource management-bridging theoretical\nscheduling models with practical deployment in modern MIG-enabled environments\nrelevant to Artificial Intelligence and Agriculture 4.0."}
{"id": "2510.14509", "categories": ["cs.SE", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.14509", "abs": "https://arxiv.org/abs/2510.14509", "authors": ["Jingyao Liu", "Chen Huang", "Zhizhao Guan", "Wenqiang Lei", "Yang Deng"], "title": "E2Edev: Benchmarking Large Language Models in End-to-End Software Development Task", "comment": null, "summary": "E2EDev comprises (i) a fine-grained set of user requirements, (ii) {multiple\nBDD test scenarios with corresponding Python step implementations for each\nrequirement}, and (iii) a fully automated testing pipeline built on the Behave\nframework. To ensure its quality while reducing the annotation effort, E2EDev\nleverages our proposed Human-in-the-Loop Multi-Agent Annotation Framework\n(HITL-MAA). {By evaluating various E2ESD frameworks and LLM backbones with\nE2EDev}, our analysis reveals a persistent struggle to effectively solve these\ntasks, underscoring the critical need for more effective and cost-efficient\nE2ESD solutions. Our codebase and benchmark are publicly available at\nhttps://github.com/SCUNLP/E2EDev."}
{"id": "2510.14622", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2510.14622", "abs": "https://arxiv.org/abs/2510.14622", "authors": ["Miryeong Kwon", "Donghyun Gouk", "Hyein Woo", "Junhee Kim", "Jinwoo Baek", "Kyungkuk Nam", "Sangyoon Ji", "Jiseon Kim", "Hanyeoreum Bae", "Junhyeok Jang", "Hyunwoo You", "Junseok Moon", "Myoungsoo Jung"], "title": "MPI-over-CXL: Enhancing Communication Efficiency in Distributed HPC Systems", "comment": null, "summary": "MPI implementations commonly rely on explicit memory-copy operations,\nincurring overhead from redundant data movement and buffer management. This\noverhead notably impacts HPC workloads involving intensive inter-processor\ncommunication. In response, we introduce MPI-over-CXL, a novel MPI\ncommunication paradigm leveraging CXL, which provides cache-coherent shared\nmemory across multiple hosts. MPI-over-CXL replaces traditional data-copy\nmethods with direct shared memory access, significantly reducing communication\nlatency and memory bandwidth usage. By mapping shared memory regions directly\ninto the virtual address spaces of MPI processes, our design enables efficient\npointer-based communication, eliminating redundant copying operations. To\nvalidate this approach, we implement a comprehensive hardware and software\nenvironment, including a custom CXL 3.2 controller, FPGA-based multi-host\nemulation, and dedicated software stack. Our evaluations using representative\nbenchmarks demonstrate substantial performance improvements over conventional\nMPI systems, underscoring MPI-over-CXL's potential to enhance efficiency and\nscalability in large-scale HPC environments."}
{"id": "2510.14625", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.14625", "abs": "https://arxiv.org/abs/2510.14625", "authors": ["Mehrdad Saadatmand", "Abbas Khan", "Beatriz Marin", "Ana C. R Paiva", "Nele Van Asch", "Graham Moran", "Felix Cammaerts", "Monique Snoeck", "Alexandra Mendes"], "title": "Software Testing Education and Industry Needs - Report from the ENACTEST EU Project", "comment": "* The paper is going to appear in the proceedings of the 26th\n  International Conference on Product-Focused Software Process Improvement\n  (PROFES 2025). To cite the paper, please check and refer to the PROFES 2025\n  proceedings", "summary": "The evolving landscape of software development demands that software testers\ncontinuously adapt to new tools, practices, and acquire new skills. This study\ninvestigates software testing competency needs in industry, identifies\nknowledge gaps in current testing education, and highlights competencies and\ngaps not addressed in academic literature. This is done by conducting two focus\ngroup sessions and interviews with professionals across diverse domains,\nincluding railway industry, healthcare, and software consulting and performing\na curated small-scale scoping review. The study instrument, co-designed by\nmembers of the ENACTEST project consortium, was developed collaboratively and\nrefined through multiple iterations to ensure comprehensive coverage of\nindustry needs and educational gaps. In particular, by performing a thematic\nqualitative analysis, we report our findings and observations regarding:\nprofessional training methods, challenges in offering training in industry,\ndifferent ways of evaluating the quality of training, identified knowledge gaps\nwith respect to academic education and industry needs, future needs and trends\nin testing education, and knowledge transfer methods within companies. Finally,\nthe scoping review results confirm knowledge gaps in areas such as AI testing,\nsecurity testing and soft skills."}
{"id": "2510.14686", "categories": ["cs.DC", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.14686", "abs": "https://arxiv.org/abs/2510.14686", "authors": ["Tongxuan Liu", "Tao Peng", "Peijun Yang", "Xiaoyang Zhao", "Xiusheng Lu", "Weizhe Huang", "Zirui Liu", "Xiaoyu Chen", "Zhiwei Liang", "Jun Xiong", "Donghe Jin", "Minchao Zhang", "Jinrong Guo", "Yingxu Deng", "Xu Zhang", "Xianzhe Dong", "Siqi Wang", "Siyu Wu", "Yu Wu", "Zihan Tang", "Yuting Zeng", "Yanshu Wang", "Jinguang Liu", "Meng Kang", "Menxin Li", "Yunlong Wang", "Yiming Liu", "Xiaolong Ma", "Yifan Wang", "Yichen Zhang", "Jinrun Yin", "Keyang Zheng", "Jiawei Yin", "Jun Zhang", "Ziyue Wang", "Xiaobo Lin", "Liangyu Liu", "Liwei Lan", "Yang Liu", "Chunhua Peng", "Han Liu", "Songcheng Ren", "Xuezhu Wang", "Yunheng Shen", "Yi Wang", "Guyue Liu", "Hui Chen", "Tong Yang", "Hailong Yang", "Jing Li", "Guiguang Ding", "Ke Zhang"], "title": "xLLM Technical Report", "comment": "39 pages", "summary": "We introduce xLLM, an intelligent and efficient Large Language Model (LLM)\ninference framework designed for high-performance, large-scale enterprise-grade\nserving, with deep optimizations for diverse AI accelerators. To address these\nchallenges, xLLM builds a novel decoupled service-engine architecture. At the\nservice layer, xLLM-Service features an intelligent scheduling module that\nefficiently processes multimodal requests and co-locates online and offline\ntasks through unified elastic scheduling to maximize cluster utilization. This\nmodule also relies on a workload-adaptive dynamic Prefill-Decode (PD)\ndisaggregation policy and a novel Encode-Prefill-Decode (EPD) disaggregation\npolicy designed for multimodal inputs. Furthermore, it incorporates a\ndistributed architecture to provide global KV Cache management and robust\nfault-tolerant capabilities for high availability. At the engine layer,\nxLLM-Engine co-optimizes system and algorithm designs to fully saturate\ncomputing resources. This is achieved through comprehensive multi-layer\nexecution pipeline optimizations, an adaptive graph mode and an xTensor memory\nmanagement. xLLM-Engine also further integrates algorithmic enhancements such\nas optimized speculative decoding and dynamic EPLB, collectively serving to\nsubstantially boost throughput and inference efficiency. Extensive evaluations\ndemonstrate that xLLM delivers significantly superior performance and resource\nefficiency. Under identical TPOT constraints, xLLM achieves throughput up to\n1.7x that of MindIE and 2.2x that of vLLM-Ascend with Qwen-series models, while\nmaintaining an average throughput of 1.7x that of MindIE with Deepseek-series\nmodels. xLLM framework is publicly available at\nhttps://github.com/jd-opensource/xllm and\nhttps://github.com/jd-opensource/xllm-service."}
{"id": "2510.14635", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.14635", "abs": "https://arxiv.org/abs/2510.14635", "authors": ["Qingyao Li", "Xinyi Dai", "Weiwen Liu", "Xiangyang Li", "Yasheng Wang", "Ruiming Tang", "Yong Yu", "Weinan Zhang"], "title": "ATGen: Adversarial Reinforcement Learning for Test Case Generation", "comment": null, "summary": "Large Language Models (LLMs) excel at code generation, yet their outputs\noften contain subtle bugs, for which effective test cases are a critical\nbottleneck. Existing test generation methods, whether based on prompting or\nsupervised fine-tuning, rely on static datasets. This imposes a\n``fixed-difficulty ceiling'', fundamentally limiting their ability to uncover\nnovel or more complex bugs beyond their training scope. To overcome this, we\nintroduce ATGen, a framework that trains a test case generator via adversarial\nreinforcement learning. ATGen pits a test generator against an adversarial code\ngenerator that continuously crafts harder bugs to evade the current policy.\nThis dynamic loop creates a curriculum of increasing difficulty challenging\ncurrent policy. The test generator is optimized via Reinforcement Learning (RL)\nto jointly maximize ``Output Accuracy'' and ``Attack Success'', enabling it to\nlearn a progressively stronger policy that breaks the fixed-difficulty ceiling\nof static training. Extensive experiments demonstrate that ATGen significantly\noutperforms state-of-the-art baselines. We further validate its practical\nutility, showing it serves as both a more effective filter for Best-of-N\ninference and a higher-quality reward source for training code generation\nmodels. Our work establishes a new, dynamic paradigm for improving the\nreliability of LLM-generated code."}
{"id": "2510.14730", "categories": ["cs.DC", "cs.AR"], "pdf": "https://arxiv.org/pdf/2510.14730", "abs": "https://arxiv.org/abs/2510.14730", "authors": ["Alejandro Cano", "CristÃ³bal Camarero", "Carmen MartÃ­nez", "RamÃ³n Beivide"], "title": "Deadlock-free routing for Full-mesh networks without using Virtual Channels", "comment": null, "summary": "High-radix, low-diameter networks like HyperX and Dragonfly use a Full-mesh\ncore, and rely on multiple virtual channels (VCs) to avoid packet deadlocks in\nadaptive routing. However, VCs introduce significant overhead in the switch in\nterms of area, power, and design complexity, limiting the switch scalability.\nThis paper starts by revisiting VC-less routing through link ordering schemes\nin Full-mesh networks, which offer implementation simplicity but suffer from\nperformance degradation under adversarial traffic. Thus, to overcome these\nchallenges, we propose TERA (Topology-Embedded Routing Algorithm), a novel\nrouting algorithm which employs an embedded physical subnetwork to provide\ndeadlock-free non-minimal paths without using VCs.\n  In a Full-mesh network, TERA outperforms link ordering routing algorithms by\n80% when dealing with adversarial traffic, and up to 100% in application\nkernels. Furthermore, compared to other VC-based approaches, it reduces buffer\nrequirements by 50%, while maintaining comparable latency and throughput.\nLastly, early results from a 2D-HyperX evaluation show that TERA outperforms\nstate-of-the-art algorithms that use the same number of VCs, achieving\nperformance improvements of up to 32%."}
{"id": "2510.14653", "categories": ["cs.SE", "cs.RO"], "pdf": "https://arxiv.org/pdf/2510.14653", "abs": "https://arxiv.org/abs/2510.14653", "authors": ["Sven Tarlowski", "Lutz Eckstein"], "title": "Requirement Identification for Traffic Simulations in Driving Simulators", "comment": "2 Pages, 1 figure", "summary": "This paper addresses the challenge of ensuring realistic traffic conditions\nby proposing a methodology that systematically identifies traffic simulation\nrequirements. Using a structured approach based on sub-goals in each study\nphase, specific technical needs are derived for microscopic levels, agent\nmodels, and visual representation. The methodology aims to maintain a high\ndegree of fidelity, enhancing both the validity of experimental outcomes and\nparticipant engagement. By providing a clear link between study objectives and\ntraffic simulation design, this approach supports robust automotive development\nand testing."}
{"id": "2510.14798", "categories": ["cs.DC", "cs.DS", "math.PR"], "pdf": "https://arxiv.org/pdf/2510.14798", "abs": "https://arxiv.org/abs/2510.14798", "authors": ["Petra Berenbrink", "Tom Friedetzky", "Peter Kling", "Lars Nagel"], "title": "Balls and Bins and the Infinite Process with Random Deletions", "comment": null, "summary": "We consider an infinite balls-into-bins process with deletions where in each\ndiscrete step $t$ a coin is tossed as to whether, with probability $\\beta(t)\n\\in (0,1)$, a new ball is allocated using the Greedy[2] strategy (which places\nthe ball in the lower loaded of two bins sampled uniformly at random) or, with\nremaining probability $1-\\beta(t)$, a ball is deleted from a non-empty bin\nchosen uniformly at random. Let $n$ be the number of bins and $m(t)$ the total\nload at time $t$. We are interested in bounding the discrepancy $x_{\\max}(t) -\nm(t)/n$ (current maximum load relative to current average) and the overload\n$x_{\\max}(t) - m_{\\max}(t)/n$ (current maximum load relative to highest average\nobserved so far).\n  We prove that at an arbitrarily chosen time $t$ the total number of balls\nabove the average is $O(n)$ and that the discrepancy is $ O(\\log(n))$. For the\ndiscrepancy, we provide a matching lower bound. Furthermore we prove that at an\narbitrarily chosen time $t$ the overload is $\\log\\log(n)+O(1)$. For \"good\"\ninsertion probability sequences (in which the average load of time intervals\nwith polynomial length increases in expectation) we show that even the\ndiscrepancy is bounded by $\\log\\log(n)+O(1)$.\n  One of our main analytical tools is a layered induction, as per [ABKU99].\nSince our model allows for rather more general scenarios than what was\npreviously considered, the formal analysis requires some extra ingredients as\nwell, in particular a detailed potential analysis. Furthermore, we simplify the\nsetup by applying probabilistic couplings to obtain certain \"recovery\"\nproperties, which eliminate much of the need for intricate and careful\nconditioning elsewhere in the analysis."}
{"id": "2510.14700", "categories": ["cs.SE", "cs.CR"], "pdf": "https://arxiv.org/pdf/2510.14700", "abs": "https://arxiv.org/abs/2510.14700", "authors": ["Bin Liu", "Yanjie Zhao", "Guoai Xu", "Haoyu Wang"], "title": "LLM Agents for Automated Web Vulnerability Reproduction: Are We There Yet?", "comment": null, "summary": "Large language model (LLM) agents have demonstrated remarkable capabilities\nin software engineering and cybersecurity tasks, including code generation,\nvulnerability discovery, and automated testing. One critical but underexplored\napplication is automated web vulnerability reproduction, which transforms\nvulnerability reports into working exploits. Although recent advances suggest\npromising potential, challenges remain in applying LLM agents to real-world web\nvulnerability reproduction scenarios. In this paper, we present the first\ncomprehensive evaluation of state-of-the-art LLM agents for automated web\nvulnerability reproduction. We systematically assess 20 agents from software\nengineering, cybersecurity, and general domains across 16 dimensions, including\ntechnical capabilities, environment adaptability, and user experience factors,\non 3 representative web vulnerabilities. Based on the results, we select three\ntop-performing agents (OpenHands, SWE-agent, and CAI) for in-depth evaluation\non our benchmark dataset of 80 real-world CVEs spanning 7 vulnerability types\nand 6 web technologies. Our results reveal that while LLM agents achieve\nreasonable success on simple library-based vulnerabilities, they consistently\nfail on complex service-based vulnerabilities requiring multi-component\nenvironments. Complex environment configurations and authentication barriers\ncreate a gap where agents can execute exploit code but fail to trigger actual\nvulnerabilities. We observe high sensitivity to input guidance, with\nperformance degrading by over 33% under incomplete authentication information.\nOur findings highlight the significant gap between current LLM agent\ncapabilities and the demands of reliable automated vulnerability reproduction,\nemphasizing the need for advances in environmental adaptation and autonomous\nproblem-solving capabilities."}
{"id": "2510.14778", "categories": ["cs.SE", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.14778", "abs": "https://arxiv.org/abs/2510.14778", "authors": ["Maor Reuben", "Ido Mendel", "Or Feldman", "Moshe Kravchik", "Mordehai Guri", "Rami Puzis"], "title": "Leveraging Code Cohesion Analysis to Identify Source Code Supply Chain Attacks", "comment": null, "summary": "Supply chain attacks significantly threaten software security with malicious\ncode injections within legitimate projects. Such attacks are very rare but may\nhave a devastating impact. Detecting spurious code injections using automated\ntools is further complicated as it often requires deciphering the intention of\nboth the inserted code and its context. In this study, we propose an\nunsupervised approach for highlighting spurious code injections by quantifying\ncohesion disruptions in the source code. Using a name-prediction-based cohesion\n(NPC) metric, we analyze how function cohesion changes when malicious code is\nintroduced compared to natural cohesion fluctuations. An analysis of 54,707\nfunctions over 369 open-source C++ repositories reveals that code injection\nreduces cohesion and shifts naming patterns toward shorter, less descriptive\nnames compared to genuine function updates. Considering the sporadic nature of\nreal supply-chain attacks, we evaluate the proposed method with extreme\ntest-set imbalance and show that monitoring high-cohesion functions with NPC\ncan effectively detect functions with injected code, achieving a Precision@100\nof 36.41% at a 1:1,000 ratio and 12.47% at 1:10,000. These results suggest that\nautomated cohesion measurements, in general, and name-prediction-based\ncohesion, in particular, may help identify supply chain attacks, improving\nsource code integrity."}
{"id": "2510.14928", "categories": ["cs.SE", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.14928", "abs": "https://arxiv.org/abs/2510.14928", "authors": ["Eric Christopher", "Kevin Crossan", "Wolff Dobson", "Chris Kennelly", "Drew Lewis", "Kun Lin", "Martin Maas", "Parthasarathy Ranganathan", "Emma Rapati", "Brian Yang"], "title": "Instruction Set Migration at Warehouse Scale", "comment": null, "summary": "Migrating codebases from one instruction set architecture (ISA) to another is\na major engineering challenge. A recent example is the adoption of Arm (in\naddition to x86) across the major Cloud hyperscalers. Yet, this problem has\nseen limited attention by the academic community. Most work has focused on\nstatic and dynamic binary translation, and the traditional conventional wisdom\nhas been that this is the primary challenge.\n  In this paper, we show that this is no longer the case. Modern ISA migrations\ncan often build on a robust open-source ecosystem, making it possible to\nrecompile all relevant software from scratch. This introduces a new and\nmultifaceted set of challenges, which are different from binary translation.\n  By analyzing a large-scale migration from x86 to Arm at Google, spanning\nalmost 40,000 code commits, we derive a taxonomy of tasks involved in ISA\nmigration. We show how Google automated many of the steps involved, and\ndemonstrate how AI can play a major role in automatically addressing these\ntasks. We identify tasks that remain challenging and highlight research\nchallenges that warrant further attention."}
