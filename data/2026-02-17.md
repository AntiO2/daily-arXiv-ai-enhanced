<div id=toc></div>

# Table of Contents

- [cs.DC](#cs.DC) [Total: 5]
- [cs.DB](#cs.DB) [Total: 8]
- [cs.SE](#cs.SE) [Total: 21]


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [1] [TEG: Exascale Cluster Governance via Non-Equilibrium Thermodynamics and Langevin Dynamics](https://arxiv.org/abs/2602.13789)
*Zhengyan Chu*

Main category: cs.DC

TL;DR: 提出TEG（热经济调控器），一种基于热力学原理的去中心化集群治理架构，用于解决Exascale规模下传统编排系统的物理极限问题


<details>
  <summary>Details</summary>
Motivation: 随着云计算向Exascale规模（10^5+节点）扩展，以Kubernetes为代表的传统"牛顿式"编排范式面临物理极限。集中式确定性调度模型存在O(N)延迟扩展、队头阻塞和热力学盲区等问题，无法管理下一代AI工作负载的随机混沌特性

Method: 提出TEG架构，将计算集群建模为远离平衡态的耗散结构。用Langevin代理替代全局调度器，在Holographic势场上执行布朗运动，将决策复杂度降至O(1)。通过Landau相变机制调节全局阻尼（税收）来物理消除死锁，采用Token蒸发机制模拟熵耗散防止经济通胀

Result: 理论分析证明：1）系统通过Dual-Number Damping渐近收敛到纳什均衡；2）OOM灾难性故障通过OS级Airlock Mutex转化为可管理的Glassy状态；3）使用高阶控制屏障函数在高惯性条件下数学保证安全性

Conclusion: TEG表明，涌现秩序而非确定性控制是Exascale可扩展性的必要条件。热力学治理范式为超大规模计算集群提供了新的理论基础

Abstract: As cloud computing scales toward the Exascale regime ($10^5+$ nodes), the prevailing "Newtonian" orchestration paradigm -- exemplified by Kubernetes -- approaches fundamental physical limits. The centralized, deterministic scheduling model suffers from $O(N)$ latency scaling, "Head-of-Line" blocking, and thermodynamic blindness, rendering it incapable of managing the stochastic chaos of next-generation AI workloads. This paper proposes a paradigm shift from orchestration to Thermodynamic Governance. We model the compute cluster not as a static state machine, but as a Dissipative Structure far from equilibrium. We introduce TEG (Thermo-Economic Governor), a decentralized architecture that establishes a rigorous topological isomorphism between cluster resource contention and many-body physics. TEG replaces the global scheduler with Langevin Agents that execute Brownian motion on a Holographic Potential Field, reducing decision complexity to $O(1)$. System stability is maintained via a macro-scale Landau Phase Transition mechanism, which modulates global damping (taxation) to physically dissolve deadlocks. Crucially, we enforce Token Evaporation to mirror entropy dissipation, preventing economic inflation and ensuring an open thermodynamic system. We provide formal theoretical analysis proving that: (1) The system converges asymptotically to a Nash Equilibrium via Dual-Number Damping; (2) OOM catastrophic failures are converted into manageable Glassy States via an OS-level Airlock Mutex; and (3) Safety is mathematically guaranteed under high inertia using High-Order Control Barrier Functions (HOCBF). TEG demonstrates that emergent order, rather than deterministic control, is the necessary condition for Exascale scalability.

</details>


### [2] [ML-ECS: A Collaborative Multimodal Learning Framework for Edge-Cloud Synergies](https://arxiv.org/abs/2602.14107)
*Yuze Liu,Shibo Chu,Tiehua Zhang,Hao Zhou,Zhishu Shen,Jinze Wang,Jianzhong Qi,Feng Xia*

Main category: cs.DC

TL;DR: ML-ECS是一个边缘-云协同的多模态学习框架，通过跨模态对比学习、自适应多模态调优、模态感知模型聚合和SLM增强的CCL，解决边缘环境中模态异质性和模型结构异质性问题，实现高效隐私保护的多模态学习。


<details>
  <summary>Details</summary>
Motivation: 边缘-云协同为隐私保护的基础模型部署提供了有前景的范式，但实际边缘环境中存在模态异质性（不同域具有不同模态组合）和模型结构异质性（不同模态特定编码器/融合模块），这给协同多模态学习带来了挑战。

Method: 提出ML-ECS框架，包含四个组件：1) 跨模态对比学习(CCL)在共享潜在空间中对齐模态表示；2) 自适应多模态调优(AMT)保留本地数据集的领域特定知识；3) 模态感知模型聚合(MMA)鲁棒地聚合模型并缓解缺失模态引起的噪声；4) SLM增强的CCL(SE-CCL)促进云与边缘之间的双向知识转移。

Result: 在各种多模态任务上的实验结果表明，ML-ECS在不同模态可用性下始终优于最先进的基线方法，Rouge-LSum指标提升5.44%到12.08%，同时改善了客户端和服务器端性能。通过仅通信低秩LoRA参数和融合表示，实现了高通信效率，仅需总参数量的0.65%。

Conclusion: ML-ECS有效解决了边缘环境中协同多模态学习的异质性问题，通过创新的组件设计实现了高效的知识共享和隐私保护，为边缘-云协同的多模态学习提供了实用解决方案。

Abstract: Edge-cloud synergies provide a promising paradigm for privacy-preserving deployment of foundation models, where lightweight on-device models adapt to domain-specific data and cloud-hosted models coordinate knowledge sharing. However, in real-world edge environments, collaborative multimodal learning is challenged by modality heterogeneity (different modality combinations across domains) and model-structure heterogeneity (different modality-specific encoders/fusion modules. To address these issues, we propose ML-ECS, a collaborative multimodal learning framework that enables joint training between a server-based model and heterogeneous edge models. This framework consists of four components: (1) cross-modal contrastive learning (CCL) to align modality representations in a shared latent space, (2) adaptive multimodal tuning (AMT) to preserve domain-specific knowledge from local datasets, (3) modality-aware model aggregation (MMA) to robustly aggregate while mitigating noise caused by missing modalities, and (4) SLM-enhanced CCL (SE-CCL) to facilitate bidirectional knowledge transfer between cloud and edge. Experimental results on various multimodal tasks show that \pname consistently outperform state-of-the-art baselines under varying modality availability, achieving improvements of 5.44% to 12.08% in Rouge-LSum and improving both client- and server-side performance. In addition, by communicating only low-rank LoRA parameters and fused representations, ML-ECS achieves high communication efficiency, requiring only 0.65% of the total parameter volume.

</details>


### [3] [Floe: Federated Specialization for Real-Time LLM-SLM Inference](https://arxiv.org/abs/2602.14302)
*Chunlin Tian,Kahou Tam,Yebo Wu,Shuaihang Zhong,Li Li,Nicholas D. Lane,Chengzhong Xu*

Main category: cs.DC

TL;DR: Floe是一个混合联邦学习框架，将云端大语言模型与边缘设备上的轻量小语言模型结合，实现低延迟、隐私保护的实时推理。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在实时系统中部署面临计算需求大和隐私问题两大挑战，需要在资源受限的边缘设备上实现低延迟、隐私保护的推理。

Method: 1) 云端黑盒LLM与边缘SLMs混合架构；2) 异构感知的LoRA适配策略；3) 日志级融合机制协调边缘与云端模型；4) 个人数据和微调保持在设备端。

Result: 实验表明Floe能增强用户隐私和个性化，显著提升模型性能，并在实时约束下减少边缘设备的推理延迟。

Conclusion: Floe框架有效解决了LLM在实时系统中的部署挑战，通过混合联邦学习实现了隐私保护、低延迟和高性能的边缘推理。

Abstract: Deploying large language models (LLMs) in real-time systems remains challenging due to their substantial computational demands and privacy concerns. We propose Floe, a hybrid federated learning framework designed for latency-sensitive, resource-constrained environments. Floe combines a cloud-based black-box LLM with lightweight small language models (SLMs) on edge devices to enable low-latency, privacy-preserving inference. Personal data and fine-tuning remain on-device, while the cloud LLM contributes general knowledge without exposing proprietary weights. A heterogeneity-aware LoRA adaptation strategy enables efficient edge deployment across diverse hardware, and a logit-level fusion mechanism enables real-time coordination between edge and cloud models. Extensive experiments demonstrate that Floe enhances user privacy and personalization. Moreover, it significantly improves model performance and reduces inference latency on edge devices under real-time constraints compared with baseline approaches.

</details>


### [4] [Efficient Multi-round LLM Inference over Disaggregated Serving](https://arxiv.org/abs/2602.14516)
*Wenhao He,Youhe Jiang,Penghao Zhao,Quanqing Xu,Eiko Yoneki,Bin Cui,Fangcheng Fu*

Main category: cs.DC

TL;DR: AMPD是一个针对多轮LLM推理的新型解耦服务框架，通过自适应调度预填充工作负载来优化SLO达成率


<details>
  <summary>Details</summary>
Motivation: 随着LLM多轮工作流（如自主代理和迭代检索）的普及，现有的预填充-解码解耦服务范式无法有效处理多轮推理中的交错工作负载模式，导致增量预填充工作负载和两阶段模型部署处理不理想

Method: AMPD框架基于实时工作负载协调预填充工作，自适应决定在哪里执行这些工作负载以及如何调度它们，以最大化SLO达成率。同时为场景定制规划算法，推导两阶段的最优资源分配和并行策略

Result: 实证结果表明，与最先进的基线相比，AMPD显著提高了SLO达成率

Conclusion: AMPD为多轮LLM推理提供了一个有效的解耦服务解决方案，通过智能调度和资源规划解决了现有系统在处理交错工作负载模式时的不足

Abstract: With the rapid evolution of Large Language Models (LLMs), multi-round workflows, such as autonomous agents and iterative retrieval, have become increasingly prevalent. However, this raises hurdles for serving LLMs under prefill-decode (PD) disaggregation, a widely adopted paradigm that separates the compute-bound prefill phase and memory-bound decode phase onto individual resources. Specifically, existing systems overlook the interleaved prefill-decode workload pattern in multi-round inference, leading to sub-optimal handling of the incremental prefill workloads and model deployment for the two phases.
  In this work, we present AMPD, a brand new disaggregated serving framework for multi-round LLM inference. The core of AMPD is to coordinate the prefill workloads based on real-time workloads by adaptively determining where to carry out these workloads and how they are scheduled, in order to maximize service level objective (SLO) attainment. In addition, we tailor a planning algorithm for our scenario, facilitating the deduction of optimal resource allocation and parallel strategies for the two phases. Empirical results demonstrate that AMPD substantially improves SLO attainment compared to state-of-the-art baselines.

</details>


### [5] [Evaluation of Dynamic Vector Bin Packing for Virtual Machine Placement](https://arxiv.org/abs/2602.14704)
*Zong Yu Lee,Xueyan Tang*

Main category: cs.DC

TL;DR: 本文评估了云环境中虚拟机放置问题的最先进算法，在非预知、预知和学习增强三种在线设置下进行实验，使用真实Azure数据集，并提出了新的算法改进。


<details>
  <summary>Details</summary>
Motivation: 虚拟机放置是云计算中的关键挑战，影响数据中心物理机资源的高效利用。该问题可建模为最小使用时间动态向量装箱问题，但现有算法在不同场景下的性能需要系统评估。

Method: 将虚拟机放置问题建模为MinUsageTime DVBP问题，在三种设置下评估算法：非预知（虚拟机寿命未知）、预知（寿命已知）和学习增强（寿命预测）。除了文献中的算法，还开发了新的算法和改进方案。使用Microsoft Azure真实数据集进行实证实验。

Result: 通过真实数据集实验，分析了不同算法在三种设置下的性能表现，探讨了算法结构和在实际中表现良好的设计元素。

Conclusion: 论文提供了虚拟机放置算法在不同在线设置下的系统评估，识别了有效的算法设计元素，为实际云环境中的资源管理提供了实用见解。

Abstract: Virtual machine placement is a crucial challenge in cloud computing for efficiently utilizing physical machine resources in data centers. Virtual machine placement can be formulated as a MinUsageTime Dynamic Vector Bin Packing (DVBP) problem, aiming to minimize the total usage time of the physical machines. This paper evaluates state-of-the-art MinUsageTime DVBP algorithms in non-clairvoyant, clairvoyant and learning-augmented online settings, where item durations (virtual machine lifetimes) are unknown, known and predicted, respectively. Besides the algorithms taken from the literature, we also develop several new algorithms or enhancements. Empirical experimentation is carried out with real-world datasets of Microsoft Azure. The insights from the experimental results are discussed to explore the structures of algorithms and promising design elements that work well in practice.

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [6] [LoPace: A Lossless Optimized Prompt Accurate Compression Engine for Large Language Model Applications](https://arxiv.org/abs/2602.13266)
*Aman Ulla*

Main category: cs.DB

TL;DR: LoPace是一个专门为LLM提示存储设计的无损压缩框架，通过Zstandard、BPE tokenization和混合方法实现平均72.2%的空间节省，同时保持100%无损重建。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在自然语言处理中应用广泛，但在生产环境中高效存储和管理提示仍然具有挑战性。现有方法在压缩效率和存储管理方面存在不足，需要专门针对LLM提示的压缩解决方案。

Method: LoPace采用三种压缩方法：1) Zstandard基础压缩；2) Byte-Pair Encoding (BPE) tokenization结合二进制打包；3) 混合方法结合前两种技术。框架在386个不同类型的提示（代码片段、markdown文档、结构化内容）上进行测试。

Result: 平均节省72.2%存储空间，实现100%无损重建。混合方法表现最佳，平均压缩比4.89倍（范围1.22-19.09倍），压缩速度3.3-10.7 MB/s。内存占用小（平均0.35 MB），具有良好的可扩展性。

Conclusion: LoPace是一个生产就绪的提示压缩框架，能够显著减少存储需求，同时保持无损重建能力，适用于大规模数据库和实时LLM应用。

Abstract: Large Language Models (LLMs) have changed the way natural language processing works, but it is still hard to store and manage prompts efficiently in production environments. This paper presents LoPace (Lossless Optimized Prompt Accurate Compression Engine), a novel compression framework designed specifically for prompt storage in LLM applications. LoPace uses three different ways to compress data: Zstandard-based compression, Byte-Pair Encoding (BPE) tokenization with binary packing, and a hybrid method that combines the two. We show that LoPace saves an average of 72.2\% of space while still allowing for 100\% lossless reconstruction by testing it on 386 different prompts, such as code snippets, markdown documentation, and structured content. The hybrid method always works better than each technique on its own. It gets mean compression ratios of 4.89x (range: 1.22--19.09x) and speeds of 3.3--10.7 MB/s. Our findings show that LoPace is ready for production, with a small memory footprint (0.35 MB on average) and great scalability for big databases and real-time LLM apps.

</details>


### [7] [MergePipe: A Budget-Aware Parameter Management System for Scalable LLM Merging](https://arxiv.org/abs/2602.13273)
*Yuanyi Wang,Yanggan Gu,Zihao Wang,Kunxi Li,Yifan Yang,Zhaoyi Yan,Congkai Xie,Jianmin Wu,Hongxia Yang*

Main category: cs.DB

TL;DR: MergePipe：首个将LLM合并视为数据管理与执行问题的参数管理系统，通过成本感知规划和流式执行引擎，显著降低I/O开销并提升合并效率


<details>
  <summary>Details</summary>
Motivation: 随着专家模型数量增加，现有LLM合并方法将参数视为非结构化文件并以无状态、一次性方式执行，导致磁盘I/O过高、参数扫描冗余和可扩展性差

Method: 1) 引入基于目录的参数、合并计划和执行谱系抽象；2) 成本感知规划器显式建模专家参数I/O并强制执行用户指定的I/O预算；3) 流式执行引擎在事务保证下物化合并模型

Result: 实验显示MergePipe将总I/O减少高达一个数量级，端到端加速高达11倍（墙钟时间减少高达90%），优于最先进的LLM合并流水线

Conclusion: MergePipe通过将专家参数访问预算化，缓解了朴素流水线的O(K) I/O增长，实现了可预测的扩展行为，为大规模LLM合并提供了高效解决方案

Abstract: Large language model (LLM) merging has become a key technique in modern LLM development pipelines, enabling the integration of multiple task- or domain-specific expert models without retraining. However, as the number of experts grows, existing merging implementations treat model parameters as unstructured files and execute merges in a stateless, one-shot manner, leading to excessive disk I/O, redundant parameter scans, and poor scalability.
  In this paper, we present \textbf{MergePipe}, a parameter management system for scalable LLM merging. MergePipe is the first system that treats LLM merging as a data management and execution problem, and introduces a catalog-driven abstraction over model parameters, merge plans, and execution lineage. At its core, MergePipe employs a cost-aware planner that explicitly models expert parameter I/O and enforces user-specified I/O budgets, followed by a streaming execution engine that materializes merged models under transactional guarantees. Our key insight is that while base model reads and output writes are unavoidable, expert parameter reads dominate merge cost and constitute the primary optimization target. By making expert access budget-aware throughout planning and execution, MergePipe mitigates the $O(K)$ I/O growth of naive pipelines and achieves predictable scaling behavior. Experiments show that MergePipe reduces total I/O by up to an order of magnitude and delivers up to $11\times$ end-to-end speedups (up to 90\% wall-time reduction) over state-of-the-art LLM merging pipelines.

</details>


### [8] [Arming Data Agents with Tribal Knowledge](https://arxiv.org/abs/2602.13521)
*Shubham Agarwal,Asim Biswal,Sepanta Zeighami,Alvin Cheung,Joseph Gonzalez,Aditya G. Parameswaran*

Main category: cs.DB

TL;DR: Tk-Boost是一个增强NL2SQL代理的框架，通过积累"部落知识"来纠正代理在查询数据库时的误解，从而提高SQL生成准确性


<details>
  <summary>Details</summary>
Motivation: 现有的NL2SQL代理在面对大规模真实数据库时容易出错，因为它们缺乏对底层数据的正确理解，并形成对数据的误解。之前的方法只是简单重述数据库内容，而没有解决代理的误解问题

Method: Tk-Boost首先让NL2SQL代理回答一些查询，通过分析其在数据库上的错误来识别代理的误解，然后生成"部落知识"来纠正这些误解。这些知识被索引并附带适用条件，当回答新查询时，使用这些知识为代理提供反馈

Result: 在BIRD和Spider 2.0基准测试中，Tk-Boost将各种NL2SQL代理的准确性提高了最多16.9%（Spider 2.0）和13.7%（BIRD）

Conclusion: Tk-Boost通过积累和利用"部落知识"有效纠正NL2SQL代理的误解，显著提高了自然语言到SQL翻译的准确性，为增强现有NL2SQL代理提供了一种有效的即插即用框架

Abstract: Natural language to SQL (NL2SQL) translation enables non-expert users to query relational databases through natural language. Recently, NL2SQL agents, powered by the reasoning capabilities of Large Language Models (LLMs), have significantly advanced NL2SQL translation. Nonetheless, NL2SQL agents still make mistakes when faced with large-scale real-world databases because they lack knowledge of how to correctly leverage the underlying data (e.g., knowledge about the intent of each column) and form misconceptions about the data when querying it, leading to errors. Prior work has studied generating facts about the database to provide more context to NL2SQL agents, but such approaches simply restate database contents without addressing the agent's misconceptions. In this paper, we propose Tk-Boost, a bolt-on framework for augmenting any NL2SQL agent with tribal knowledge: knowledge that corrects the agent's misconceptions in querying the database accumulated through experience using the database. To accumulate experience, Tk-Boost first asks the NL2SQL agent to answer a few queries on the database, identifies the agent's misconceptions by analyzing its mistakes on the database, and generates tribal knowledge to address them. To enable accurate retrieval, Tk-Boost indexes this knowledge with applicability conditions that specify the query features for which the knowledge is useful. When answering new queries, Tk-Boost uses this knowledge to provide feedback to the NL2SQL agent, resolving the agent's misconceptions during SQL generation, and thus improving the agent's accuracy. Extensive experiments across the BIRD and Spider 2.0 benchmarks with various NL2SQL agents shows Tk-Boost improves NL2SQL agents accuracy by up to 16.9% on Spider 2.0 and 13.7% on BIRD

</details>


### [9] [DTBench: A Synthetic Benchmark for Document-to-Table Extraction](https://arxiv.org/abs/2602.13812)
*Yuxiang Guo,Zhuoran Du,Nan Tang,Kezheng Tang,Congcong Ge,Yunjun Gao*

Main category: cs.DB

TL;DR: DTBench：一个基于多智能体合成工作流的文档转表格能力评估基准，采用反向Table2Doc范式生成文档，覆盖5大类13小类能力，用于系统评估LLM在文档转表格任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有文档转表格（Doc2Table）提取基准既没有明确区分也没有全面覆盖所需的各种能力，且人工标注成本高、难以扩展。需要构建一个能力感知的基准来系统评估LLM在生成精确结构化表格方面的表现。

Method: 采用反向Table2Doc范式，设计多智能体合成工作流，从真实表格生成文档。提出两级能力分类法（5大类13小类），构建DTBench合成基准。

Result: 评估多个主流LLM在DTBench上的表现，发现模型之间存在显著性能差距，在推理、忠实性和冲突解决方面存在持续挑战。

Conclusion: DTBench为数据生成和评估提供了全面的测试平台，促进了文档转表格提取的未来研究。基准已公开可用。

Abstract: Document-to-table (Doc2Table) extraction derives structured tables from unstructured documents under a target schema, enabling reliable and verifiable SQL-based data analytics. Although large language models (LLMs) have shown promise in flexible information extraction, their ability to produce precisely structured tables remains insufficiently understood, particularly for indirect extraction that requires complex capabilities such as reasoning and conflict resolution. Existing benchmarks neither explicitly distinguish nor comprehensively cover the diverse capabilities required in Doc2Table extraction.We argue that a capability-aware benchmark is essential for systematic evaluation. However, constructing such benchmarks using human-annotated document-table pairs is costly, difficult to scale, and limited in capability coverage. To address this, we adopt a reverse Table2Doc paradigm and design a multi-agent synthesis workflow to generate documents from ground-truth tables. Based on this approach, we present DTBench, a synthetic benchmark that adopts a proposed two-level taxonomy of Doc2Table capabilities, covering 5 major categories and 13 subcategories. We evaluate several mainstream LLMs on DTBench, and demonstrate substantial performance gaps across models, as well as persistent challenges in reasoning, faithfulness, and conflict resolution. DTBench provides a comprehensive testbed for data generation and evaluation, facilitating future research on Doc2Table extraction. The benchmark is publicly available at https://github.com/ZJU-DAILY/DTBench.

</details>


### [10] [TabTracer: Monte Carlo Tree Search for Complex Table Reasoning with Large Language Models](https://arxiv.org/abs/2602.14089)
*Zhizhao Luo,Zhaojing Luo,Meihui Zhang,Rui Mao*

Main category: cs.DB

TL;DR: TabTracer是一个用于表格推理的智能体框架，通过状态跟踪、验证和回滚机制，结合蒙特卡洛树搜索，在提高准确率的同时大幅降低token消耗。


<details>
  <summary>Details</summary>
Motivation: 现有表格推理方法存在两个主要问题：1）基于提示的方法缺乏步骤级验证；2）基于智能体的方法验证有限、回溯不足、存在组合冗余导致token成本高。需要一种既能保证推理准确性又能降低计算成本的新方法。

Method: TabTracer框架包含三个核心组件：1）步骤级验证机制，通过类型化操作和轻量级数值/格式检查；2）执行反馈蒙特卡洛树搜索，维护候选表格状态树，使用反向传播的反思分数指导选择和回滚；3）预算感知剪枝、去重和状态哈希，通过单调性门控减少冗余。

Result: 在TabFact、WikiTQ和CRT数据集上的综合评估显示，TabTracer比最先进的基线方法在准确率上提升了高达6.7%，同时将token消耗降低了59-84%。

Conclusion: TabTracer通过协调多步骤工具调用、显式状态跟踪和智能搜索策略，在表格推理任务中实现了准确性提升和成本降低的双重优势，为LLM在表格推理领域的应用提供了有效解决方案。

Abstract: Large language models (LLMs) have emerged as powerful tools for natural language table reasoning, where there are two main categories of methods. Prompt-based approaches rely on language-only inference or one-pass program generation without step-level verification. Agent-based approaches use tools in a closed loop, but verification is often local and backtracking is limited, allowing errors to propagate and increasing cost. Moreover, they rely on chain- or beam-style trajectories that are typically combinatorially redundant, leading to high token costs. In this paper, we propose TabTracer, an agentic framework that coordinates multi-step tool calls over intermediate table states, with explicit state tracking for verification and rollback. First, it enforces step-level verification with typed operations and lightweight numeric and format checks to provide reliable rewards and suppress hallucinations. Second, execution-feedback Monte Carlo Tree Search maintains a search tree of candidate table states and uses backpropagated reflection scores to guide UCB1 selection and rollback via versioned snapshots. Third, it reduces redundancy with budget-aware pruning, deduplication, and state hashing with a monotonicity gate to cut token cost. Comprehensive evaluation on TabFact, WikiTQ, and CRT datasets shows that TabTracer outperforms state-of-the-art baselines by up to 6.7% in accuracy while reducing token consumption by 59--84%.

</details>


### [11] [Towards a Hybrid Quantum-Classical Computing Framework for Database Optimization Problems in Real Time Setup](https://arxiv.org/abs/2602.14263)
*Hanwen Liu,Ibrahim Sabek*

Main category: cs.DB

TL;DR: 提出首个实时量子增强数据库系统愿景，通过两种可扩展性策略解决大规模数据库优化问题，相比经典查询优化器实现14倍性能提升，并优于黑盒量子求解器。


<details>
  <summary>Details</summary>
Motivation: 现有量子计算方法将数据库优化问题（如连接顺序、索引选择）直接提交给黑盒量子求解器，缺乏对求解过程的细粒度控制，无法平衡精度与效率，限制了在实时数据库场景中的灵活性和处理大规模问题的能力。

Method: 提出实时量子增强数据库系统愿景，开发两种互补的可扩展性策略来处理超出硬件限制的大规模挑战、过度复杂性和过大尺寸问题。将方法集成到数据库查询优化器中作为初步原型。

Result: 在真实世界工作负载上评估，相比经典查询优化器实现高达14倍的性能提升。在效率和解决方案质量上都优于黑盒量子求解器。

Conclusion: 提出的实时量子增强数据库系统能够透明解决数据库优化问题，通过可扩展性策略有效处理大规模挑战，在性能和解决方案质量上均优于现有方法，为量子计算在数据库优化中的应用提供了新方向。

Abstract: Quantum computing has shown promise for solving complex optimization problems in databases, such as join ordering and index selection. Prior work often submits formulated problems directly to black-box quantum or quantum-inspired solvers with the expectation of directly obtaining a good final solution. Due to the black-box nature of these solvers, users cannot perform fine-grained control over the solving procedure to balance the accuracy and efficiency, which in turn limits flexibility in real-time settings where most database problems arise. Moreover, it leads to limited potential for handling large-scale database optimization problems. In this paper, we propose a vision for the first real-time quantum-augmented database system, enabling transparent solutions for database optimization problems. We develop two complementary scalability strategies to address large-scale challenges, overcomplexity, and oversizing that exceed hardware limits. We integrate our approach with a database query optimizer as a preliminary prototype, evaluating on real-world workload, achieving up to 14x improvement over the classical query optimizer. We also achieve both better efficiency and solution quality than a black-box quantum solver.

</details>


### [12] [Qute: Towards Quantum-Native Database](https://arxiv.org/abs/2602.14699)
*Muzhi Chen,Xuanhe Zhou,Wei Zhou,Bangrui Xu,Surui Tang,Guoliang Li,Bingsheng He,Yeye He,Yitong Song,Fan Wu*

Main category: cs.DB

TL;DR: Qute是一个将量子计算作为一等执行选项的量子数据库系统，通过编译扩展SQL到量子电路、混合优化器、选择性量子索引和保真度存储来克服当前量子比特限制。


<details>
  <summary>Details</summary>
Motivation: 现有方法要么在经典机器上运行量子算法，要么为量子模拟适配现有数据库，缺乏真正将量子计算作为数据库执行选项的系统。量子计算在特定任务上具有潜在优势，但受限于当前量子比特约束。

Method: 1) 将扩展SQL编译为门高效的量子电路；2) 使用混合优化器动态选择量子或经典执行计划；3) 引入选择性量子索引；4) 设计保真度存储以缓解量子比特限制。

Result: 在真实量子处理器(origin_wukong)上部署Qute，证明其在规模上优于经典基线。发布了开源原型：https://github.com/weAIDB/Qute。

Conclusion: Qute展示了量子计算作为数据库执行选项的可行性，提出了三阶段演进路线图，为量子原生数据库的发展奠定了基础。

Abstract: This paper envisions a quantum database (Qute) that treats quantum computation as a first-class execution option. Unlike prior simulation-based methods that either run quantum algorithms on classical machines or adapt existing databases for quantum simulation, Qute instead (i) compiles an extended form of SQL into gate-efficient quantum circuits, (ii) employs a hybrid optimizer to dynamically select between quantum and classical execution plans, (iii) introduces selective quantum indexing, and (iv) designs fidelity-preserving storage to mitigate current qubit constraints. We also present a three-stage evolution roadmap toward quantum-native database. Finally, by deploying Qute on a real quantum processor (origin_wukong), we show that it outperforms a classical baseline at scale, and we release an open-source prototype at https://github.com/weAIDB/Qute.

</details>


### [13] [A Unified Mathematical Framework for Distributed Data Fabrics: Categorical Hypergraph Models](https://arxiv.org/abs/2602.14708)
*T. Shaska,I. Kotsireas*

Main category: cs.DB

TL;DR: 提出一个基于超图的数学框架来统一分布式数据管理，通过范畴论和模张量范畴建模数据关系，证明关键任务的NP难性并提供可扩展解决方案。


<details>
  <summary>Details</summary>
Motivation: 当前分布式数据架构缺乏严格的数学基础，依赖临时架构导致一致性、数据溯源和可扩展性问题，需要统一的数学框架来解决这些挑战。

Method: 使用超图结构F=(D,M,G,T,P,A)建模数据织物，在分布式系统Σ=(N,C)上表示数据集、元数据、转换等元素。采用范畴论方法，将数据集作为对象、转换作为态射，并将超图嵌入模张量范畴，利用编织幺半结构捕获关系对称性。

Result: 证明了模式匹配和动态分区等关键任务的NP难性，提出了谱方法和基于对称性的对齐方案作为可扩展解决方案。框架在CAP和CAL定理下确保一致性、完整性和因果性。

Conclusion: 该数学框架为分布式数据织物提供了理论基础，通过超图、范畴论和几何类比统一异构数据管理，解决了现有架构在一致性、可扩展性和故障容忍方面的局限性。

Abstract: Current distributed data fabrics lack a rigorous mathematical foundation, often relying on ad-hoc architectures that struggle with consistency, lineage, and scale. We propose a mathematical framework for data fabrics, unifying heterogeneous data management in distributed systems through a hypergraph-based structure \( \mathcal{F} = (D, M, G, T, P, A) \). Datasets, metadata, transformations, policies, and analytics are modeled over a distributed system \( Σ= (N, C) \), with multi-way relationships encoded in a hypergraph \( G = (V, E) \). A categorical approach, with datasets as objects and transformations as morphisms, supports operations like data integration and federated learning. The hypergraph is embedded into a modular tensor category, capturing relational symmetries via braided monoidal structures, with geometric analogies to Hurwitz spaces enriching the algebraic modeling. We prove the NP-hardness of critical tasks, such as schema matching and dynamic partitioning, and propose spectral methods and symmetry-based alignments for scalable solutions. The framework ensures consistency, completeness, and causality under CAP and CAL theorems, leveraging sparse incidence matrices and braiding actions for fault-tolerant operations.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [14] [A Survey of Code Review Benchmarks and Evaluation Practices in Pre-LLM and LLM Era](https://arxiv.org/abs/2602.13377)
*Taufiqul Islam Khan,Shaowei Wang,Haoxiang Zhang,Tse-Hsun Chen*

Main category: cs.SE

TL;DR: 该论文对2015-2025年间代码审查基准测试进行了全面调查，分析了99篇研究论文，提出了五领域18细粒度任务的分类法，揭示了向端到端生成式同行评审的转变趋势，并指出了当前基准测试的局限性。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在代码审查领域的应用日益增多，现有基准测试分散且设计差异大，缺乏对评估能力的系统理解，阻碍了该领域的进一步发展。

Method: 系统调查了99篇研究论文（58篇前LLM时代，41篇LLM时代），提取关键元数据（数据集、评估指标、数据源、目标任务），并基于分析提出了多层分类法。

Result: 研究发现代码审查研究向端到端生成式同行评审明显转变，多语言覆盖增加，独立变更理解任务减少；提出了包含5个领域和18个细粒度任务的分类法；识别了当前基准测试的局限性。

Conclusion: 该调查为开发更现实、全面的LLM代码审查基准测试提供了结构化基础，并指出了未来方向：更广泛的任务覆盖、动态运行时评估和分类法指导的细粒度评估。

Abstract: Code review is a critical practice in modern software engineering, helping developers detect defects early, improve code quality, and facilitate knowledge sharing. With the rapid advancement of large language models (LLMs), a growing body of work has explored automated support for code review. However, progress in this area is hindered by the lack of a systematic understanding of existing benchmarks and evaluation practices. Current code review datasets are scattered, vary widely in design, and provide limited insight into what review capabilities are actually being assessed. In this paper, we present a comprehensive survey of code review benchmarks spanning both the Pre-LLM and LLM eras (2015--2025). We analyze 99 research papers (58 Pre-LLM era and 41 LLM era) and extract key metadata, including datasets, evaluation metrics, data sources, and target tasks. Based on this analysis, we propose a multi-level taxonomy that organizes code review research into five domains and 18 fine-grained tasks. Our study reveals a clear shift toward end-to-end generative peer review, increasing multilingual coverage, and a decline in standalone change understanding tasks. We further identify limitations of current benchmarks and outline future directions, including broader task coverage, dynamic runtime evaluation, and taxonomy-guided fine-grained assessment. This survey provides a structured foundation for developing more realistic and comprehensive benchmarks for LLM-based code review.

</details>


### [15] [InEx-Bug: A Human Annotated Dataset of Intrinsic and Extrinsic Bugs in the NPM Ecosystem](https://arxiv.org/abs/2602.13400)
*Tanner Wright,Adams Chen,Gema Rodríguez-Pérez*

Main category: cs.SE

TL;DR: 论文提出了InEx-Bug数据集，对NPM仓库的GitHub问题进行分类（内部缺陷、外部依赖/环境问题、非缺陷、未知），并分析了不同类型缺陷的解决时间和行为模式差异。


<details>
  <summary>Details</summary>
Motivation: 现有缺陷数据集无法区分问题来源是项目内部还是外部依赖/环境因素，这影响了软件维护和生态系统稳定性的研究。

Method: 构建了包含103个NPM仓库中377个GitHub问题的手动标注数据集，将问题分类为内部缺陷、外部依赖/环境问题、非缺陷或未知，并收集了时间性和行为元数据。

Result: 内部缺陷解决更快（中位数8.9天 vs 10.2天）、关闭率更高（92% vs 78%）、更常需要代码修改（57% vs 28%）；外部缺陷重开率更高（12% vs 4%）且复发延迟更长（157天 vs 87天）。

Conclusion: InEx-Bug数据集为深入研究NPM生态系统中的内部和外部缺陷提供了基础，揭示了不同类型缺陷的解决模式差异。

Abstract: Understanding the causes of software defects is essential for reliable software maintenance and ecosystem stability. However, existing bug datasets do not distinguish between issues originating within a project from those caused by external dependencies or environmental factors. In this paper we present InEx-Bug, a manually annotated dataset of 377 GitHub issues from 103 NPM repositories, categorizing issues as Intrinsic (internal defect), Extrinsic (dependency/environment issue), Not-a-Bug, or Unknown. Beyond labels, the dataset includes rich temporal and behavioral metadata such as maintainer participation, code changes, and reopening patterns. Analyses show Intrinsic bugs resolve faster (median 8.9 vs 10.2 days), are close more often (92% vs 78%), and require code changes more frequently (57% vs 28%) compared to Extrinsic bugs. While Extrinsic bugs exhibit higher reopen rates (12% vs 4%) and delayed recurrence (median 157 vs 87 days). The dataset provides a foundation for further studying Intrinsic and Extrinsic defects in the NPM ecosystem.

</details>


### [16] [Execution-State-Aware LLM Reasoning for Automated Proof-of-Vulnerability Generation](https://arxiv.org/abs/2602.13574)
*Haoyu Li,Xijia Che,Yanhao Wang,Xiaojing Liao,Luyi Xing*

Main category: cs.SE

TL;DR: DrillAgent：一个基于LLM的智能体框架，通过迭代假设-验证-精炼过程生成漏洞证明，结合语义推理与程序执行反馈，显著提升C/C++漏洞的PoV生成能力。


<details>
  <summary>Details</summary>
Motivation: 现有PoV生成方法存在局限性：定向模糊测试难以满足复杂语义约束，而基于LLM的方法缺乏具体执行行为的grounding，导致无法生成精确的漏洞证明。

Method: DrillAgent将PoV生成重构为迭代的假设-验证-精炼过程，结合LLM语义推理与具体程序状态反馈，通过分析目标代码、观察执行行为，将低级执行轨迹转换为源码级约束。

Result: 在SEC-bench真实世界C/C++漏洞基准测试中，DrillAgent在固定预算约束下显著优于现有LLM智能体基线，解决了比最佳基线多52.8%的CVE任务。

Conclusion: DrillAgent证明了执行状态感知推理对于复杂软件系统中可靠PoV生成的必要性，为自动化漏洞验证提供了有效解决方案。

Abstract: Proof-of-Vulnerability (PoV) generation is a critical task in software security, serving as a cornerstone for vulnerability validation, false positive reduction, and patch verification. While directed fuzzing effectively drives path exploration, satisfying complex semantic constraints remains a persistent bottleneck in automated exploit generation. Large Language Models (LLMs) offer a promising alternative with their semantic reasoning capabilities; however, existing LLM-based approaches lack sufficient grounding in concrete execution behavior, limiting their ability to generate precise PoVs.
  In this paper, we present DrillAgent, an agentic framework that reformulates PoV generation as an iterative hypothesis-verification-refinement process. To bridge the gap between static reasoning and dynamic execution, DrillAgent synergizes LLM-based semantic inference with feedback from concrete program states. The agent analyzes the target code to hypothesize inputs, observes execution behavior, and employs a novel mechanism to translate low-level execution traces into source-level constraints. This closed-loop design enables the agent to incrementally align its input generation with the precise requirements of the vulnerability. We evaluate DrillAgent on SEC-bench, a large-scale benchmark of real-world C/C++ vulnerabilities. Experimental results show that DrillAgent substantially outperforms state-of-the-art LLM agent baselines under fixed budget constraints, solving up to 52.8% more CVE tasks than the best-performing baseline. These results highlight the necessity of execution-state-aware reasoning for reliable PoV generation in complex software systems.

</details>


### [17] [From What to How: Bridging User Requirements with Software Development Using Large Language Models](https://arxiv.org/abs/2602.13611)
*Xiao He,Ru Chen,Jialun Cao*

Main category: cs.SE

TL;DR: DesBench是一个评估大语言模型在软件设计方面能力的基准测试，包含三个任务：设计感知代码生成、面向对象建模和验收测试用例设计。评估发现LLMs在软件设计方面仍面临显著挑战。


<details>
  <summary>Details</summary>
Motivation: 当前LLM基准测试主要关注代码实现，忽略了同样重要的软件设计方面。本研究旨在探究两个关键问题：(1) LLMs能否处理软件设计？(2) LLMs能否按照特定设计编写代码？

Method: 提出DesBench基准测试，包含30个手工创建的Java项目，涵盖需求文档、设计模型、实现和验收测试。评估了7个最先进的LLM（包括DeepSeek R1、Qwen2.5和GPT模型）在三个软件设计相关任务上的表现。

Result: LLMs在软件设计方面面临显著挑战：1) 代码生成中，仅提供高层设计或无设计时难以生成正确实现；2) 面向对象建模中，能准确识别对象和类，但在定义操作和类间关系方面有困难；3) 从功能需求生成的验收测试用例在代码覆盖率质量上可与人工编写的相媲美。

Conclusion: LLMs目前在软件设计管理方面存在局限性，需要进一步研究适合LLM开发的新设计方法学和语言。

Abstract: Recently, large language models (LLMs) are extensively utilized to enhance development efficiency, leading to numerous benchmarks for evaluating their performance. However, these benchmarks predominantly focus on implementation, overlooking the equally critical aspect of software design. This gap raises two pivotal questions: (1) Can LLMs handle software design? (2) Can LLMs write code following the specific designs? To investigate these questions, this paper proposes DesBench, a design-aware benchmark for evaluating LLMs on three software design-related tasks: design-aware code generation, object-oriented modeling, and the design of acceptance test cases. DesBench comprises 30 manually crafted Java projects that include requirement documents, design models, implementations, and acceptance tests, amounting to a total of 30 design models, 194 Java classes, and 737 test cases. We evaluated seven state-of-the-art LLMs, including three DeepSeek R1, two Qwen2.5, and two GPT models, using DesBench. The results reveal that LLMs remain significantly challenged by the intricacies of software design: (1) For code generation, LLMs struggle to produce correct implementations when provided with only high-level or no designs. (2) In object-oriented modeling, while LLMs can accurately identify objects and classes, they face challenges in defining operations and inter-class relationships. (3) Acceptance test cases generated by LLMs from functional requirements achieve code coverage quality comparable to those written by humans. Our research highlights the current limitations of LLMs in managing software design and calls for further investigation into new design methodologies and languages suitable for LLM-based development.

</details>


### [18] [VeriSBOM: Secure and Verifiable SBOM Sharing Via Zero-Knowledge Proofs](https://arxiv.org/abs/2602.13682)
*Gianpietro Castiglione,Shahriar Ebrahimi,Narges Khakpour*

Main category: cs.SE

TL;DR: VeriSBOM是一个基于零知识证明的可验证、选择性披露的软件物料清单框架，能够在保护敏感信息的同时提供密码学可验证性。


<details>
  <summary>Details</summary>
Motivation: 传统SBOM包含敏感信息（专有依赖、未修补漏洞、架构策略等），完全披露会带来技术和商业风险，破坏公司知识产权。需要一种既能验证软件属性又能保护隐私的解决方案。

Method: 使用零知识证明技术，结合可扩展向量承诺方案和折叠式证明聚合，生成简洁的零知识证明。第三方可以验证特定声明（如依赖真实性、无漏洞依赖、许可证合规性）而无需看到完整SBOM。

Result: 实现了VeriSBOM系统，分析了其安全性，并在真实包注册表上评估性能。结果显示该方法支持可扩展、隐私保护且可验证的SBOM共享和验证。

Conclusion: VeriSBOM提供了一个无需信任发布者的框架，通过密码学承诺和零知识证明，在保护敏感信息的同时实现软件依赖和安全属性的可验证性，解决了SBOM披露中的隐私与验证矛盾。

Abstract: A Software Bill of Materials (SBOM) is a key component for the transparency of software supply chain; it is a structured inventory of the components, dependencies, and associated metadata of a software artifact. However, an SBOM often contain sensitive information that organizations are unwilling to disclose in full to anyone, for two main concerns: technological risks deriving from exposing proprietary dependencies or unpatched vulnerabilities, and business risks, deriving from exposing architectural strategies. Therefore, delivering a plaintext SBOM may result in the disruption of the intellectual property of a company. To address this, we present VeriSBOM, a trustless, selectively disclosed SBOM framework that provides cryptographic verifiability of SBOMs using zero-knowledge proofs. Within VeriSBOM, third parties can validate specific statements about a delivered software. Respectively, VeriSBOM allows independent third parties to verify if a software contains authentic dependencies distributed by official package managers and that the same dependencies satisfy rigorous policy constraints such as the absence of vulnerable dependencies or the adherence with specific licenses models. VeriSBOM leverages a scalable vector commitment scheme together with folding-based proof aggregation to produce succinct zero-knowledge proofs that attest to security and compliance properties while preserving confidentiality. Crucially, the verification process requires no trust in the SBOM publisher beyond the soundness of the underlying primitives, and third parties can independently check proofs against the public cryptographic commitments. We implement VeriSBOM, analyze its security, and evaluate its performance on real-world package registries. The results show that our method enables scalable, privacy-preserving, and verifiable SBOM sharing and validation.

</details>


### [19] [ARC: Compiling Hundreds of Requirement Scenarios into A Runnable Web System](https://arxiv.org/abs/2602.13723)
*Weiyu Kong,Yun Lin,Xiwen Teoh,Duc-Minh Nguyen,Ruofei Ren,Jiaxin Chang,Haoxu Hu,Haoyu Chen*

Main category: cs.SE

TL;DR: ARC是一种基于多模态DSL文档的智能需求编译技术，能够自动生成可运行的Web系统，包括UI、API、数据库设计和测试套件，相比现有方法通过50.6%更多的GUI测试。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在代码生成方面存在局限性，当面对包含数百个场景的多模态文档时，性能显著下降，经常产生错误实现或遗漏约束。需要一种能够从复杂需求文档直接生成可运行系统的更可靠方法。

Method: 提出Agentic Requirement Compilation (ARC)技术，采用双向测试驱动的智能代理循环：自上而下的架构阶段将需求分解为可验证接口，然后自下而上的实现阶段让代理生成满足测试的代码。保持需求、设计和代码之间的严格可追溯性，支持智能资产重用。

Result: 从50-200个多模态场景的文档中生成了6个可运行的Web系统。相比最先进的基线方法，ARC生成的系统平均通过50.6%更多的GUI测试。用户研究显示，21名新手用户平均5.6小时就能为复杂系统（如1万行票务预订系统）编写DSL文档。

Conclusion: ARC能够有效将非平凡的需求规范转化为可维护、可运行的软件，证明了需求编译方法的可行性和实用性。

Abstract: Large Language Models (LLMs) have improved programming efficiency, but their performance degrades significantly as requirements scale; when faced with multi-modal documents containing hundreds of scenarios, LLMs often produce incorrect implementations or omit constraints. We propose Agentic Requirement Compilation (ARC), a technique that moves beyond simple code generation to requirement compilation, enabling the creation of runnable web systems directly from multi-modal DSL documents. ARC generates not only source code but also modular designs for UI, API, and database layers, enriched test suites (unit, modular, and integration), and detailed traceability for software maintenance. Our approach employs a bidirectional test-driven agentic loop: a top-down architecture phase decomposes requirements into verifiable interfaces, followed by a bottom-up implementation phase where agents generate code to satisfy those tests. ARC maintains strict traceability across requirements, design, and code to facilitate intelligent asset reuse. We evaluated ARC by generating six runnable web systems from documents spanning 50-200 multi-modal scenarios. Compared to state-of-the-art baselines, ARC-generated systems pass 50.6% more GUI tests on average. A user study with 21 participants showed that novice users can successfully write DSL documents for complex systems, such as a 10K-line ticket-booking system, in an average of 5.6 hours. These results demonstrate that ARC effectively transforms non-trivial requirement specifications into maintainable, runnable software.

</details>


### [20] [Impacts of Generative AI on Agile Teams' Productivity: A Multi-Case Longitudinal Study](https://arxiv.org/abs/2602.13766)
*Rafael Tomaz,Paloma Guenes,Allysson Allex Araújo,Maria Teresa Baldassarre,Marcos Kalinowski*

Main category: cs.SE

TL;DR: 对敏捷软件团队进行13个月纵向研究，发现GenAI工具显著提升团队绩效和幸福感，开发活动量持平但价值密度增加，验证了SPACE等多维框架的必要性


<details>
  <summary>Details</summary>
Motivation: 当前关于GenAI工具（如GitHub Copilot和GPT）对软件工程影响的研究多为短期个体实验，缺乏对工业敏捷环境中团队层面持续影响的深入理解。本研究旨在填补这一空白，通过纵向评估揭示GenAI在真实工作环境中的实际效果。

Method: 采用多案例纵向研究方法，在一家大型技术咨询公司的3个敏捷团队中进行约13个月的研究。通过收集和比较历史（采用前）和研究（采用后）冲刺阶段的定量遥测数据（Jira、SonarQube、Git）和定性调查数据，应用多维SPACE框架评估开发人员生产力。

Result: GenAI工具显著提高了团队绩效和幸福感。关键发现是：在开发活动量保持平稳的同时，绩效和感知效率急剧提升。这表明GenAI增加了开发工作的价值密度，而非工作量。这一发现验证了SPACE等多维框架的必要性，仅测量活动量的研究无法捕捉这种细微影响。

Conclusion: GenAI工具能够实质性改善敏捷软件团队的绩效和幸福感，其核心价值在于提升工作的价值密度而非增加工作量。研究强调了采用多维评估框架（如SPACE）的重要性，以全面捕捉GenAI在真实工业环境中的复杂影响，避免仅关注活动量的片面评估。

Abstract: Context: Generative Artificial Intelligence (GenAI) tools, such as GitHub Copilot and GPT tools, represent a paradigm shift in software engineering. While their impact is clear, most studies are short-term, focused on individual experiments. The sustained, team-level effects on productivity within industrial agile environments remain largely uncharacterized. Goal: This study aims to provide a longitudinal evaluation of GenAI's impact on agile software teams. We characterize its effect on developers' productivity by applying the multi-dimensional SPACE framework. Method: We conducted a multi-case longitudinal study involving 3 agile teams at a large technology consulting firm for around 13 months. We collected and compared quantitative telemetry (Jira, SonarQube, Git) and qualitative survey data from historical (pre-adoption) and research (post-adoption) sprints. Conclusion: GenAI tools can significantly improve team performance and well-being. Our key finding is a sharp increase in Performance and perceived Efficiency concurrent with flat developer Activity. This suggests GenAI increases the value density of development work, not its volume. This finding validates the necessity of multi-dimensional frameworks like SPACE to capture the true, nuanced impact of GenAI in situ, which would be invisible to studies measuring Activity alone.

</details>


### [21] [Impostor Phenomenon as Human Debt: A Challenge to the Future of Software Engineering](https://arxiv.org/abs/2602.13767)
*Paloma Guenes,Rafael Tomaz,Maria Teresa Baldassarre,Alexander Serebrenik*

Main category: cs.SE

TL;DR: 将冒名顶替综合征视为一种"人类债务"，类似于技术债务，并提出通过文化重构、透明度和盟友关系来解决这一问题。


<details>
  <summary>Details</summary>
Motivation: 冒名顶替综合征在软件工程领域普遍存在，但通常只被视为个人内部问题。本文认为这实际上是一种系统性问题，需要从组织和社会技术生态系统层面来解决。

Method: 采用立场论文的形式，将冒名顶替综合征概念化为"人类债务"，并与ICSE2026关于软件工程未来的预调查结果进行关联分析。提出文化重构、透明度和盟友关系作为解决方案。

Result: 识别出人类债务在软件工程领域的不平等分布，对代表性不足的工程师和研究人员影响更重。提出了组织层面的干预措施，强调领导者和机构需要解决环境因素。

Conclusion: 冒名顶替综合征不应仅被视为个人问题，而应作为系统性的人类债务来处理。通过文化重构和积极的盟友关系，可以创建一个更包容、可持续的软件工程生态系统。

Abstract: The Impostor Phenomenon (IP) impacts a significant portion of the Software Engineering workforce, yet it is often viewed primarily through an internal individual lens. In this position paper, we propose framing the prevalence of IP as a form of Human Debt and discuss the relation with the ICSE2026 Pre Survey on the Future of Software Engineering results. Similar to technical debt, which arises when short-term goals are prioritized over long-term structural integrity, Human Debt accumulates due to gaps in psychological safety and inclusive support within socio-technical ecosystems. We observe that this debt is not distributed equally, it weighs heavier on underrepresented engineers and researchers, who face compounded challenges within traditional hierarchical structures and academic environments. We propose cultural refactoring, transparency and active maintenance through allyship, suggesting that leaders and institutions must address the environmental factors that exacerbate these feelings, ensuring a sustainable ecosystem for all professionals.

</details>


### [22] [A Quasi-Experimental Evaluation of Coaching to Mitigate the Impostor Phenomenon in Early-Career Software Engineers](https://arxiv.org/abs/2602.13774)
*Paloma Guenes,Joan Leite,Rafael Tomaz,Allysson Allex Araujo,Jean Natividade,Maria Teresa Baldassarre,Marcos Kalinowski*

Main category: cs.SE

TL;DR: 该研究通过准实验设计，考察结构化团体辅导对早期软件工程师冒名顶替现象的影响，发现辅导仅带来轻微改善，而团队协作等环境因素可能更具影响力。


<details>
  <summary>Details</summary>
Motivation: 软件工程领域普遍存在冒名顶替现象，但相关干预措施（如辅导）的实证研究不足。本研究旨在探索结构化团体辅导对早期职业软件工程师冒名顶替感的实际影响。

Method: 采用准实验设计，20名参与者分为两个项目团队，使用等待列表对照设计。实验组接受三次辅导干预，对照组在观察期后接受干预。使用Clance冒名顶替量表（CIPS）评估IP，同时测量幸福感、生活满意度和情感状态。

Result: 辅导仅导致CIPS分数轻微下降，而对照组在观察期也有改善，表明环境和时间因素可能比正式干预更具影响力。

Conclusion: 辅导可能有助于提升对IP的反思和意识，但团队协作和项目工作等环境因素同样重要。本研究为理解SE环境中结构化IP干预提供了实证基础。

Abstract: Context: The Impostor Phenomenon (IP), the persistent belief of being a fraud despite evident competence, is common in Software Engineering (SE), where high expectations for expertise and innovation prevail. Although coaching and similar interventions are proposed to mitigate IP, empirical evidence in SE remains underexplored.
  Objective: This study examines the impact of a structured group coaching intervention on reducing IP feelings among early-career software engineers.
  Method: We conducted a quasi-experiment with 20 participants distributed across two project teams using a wait-list control design, complemented by non-participant observation. The treatment group received a three-session coaching intervention, while the control group received it after an observation phase. IP was assessed using the Clance Impostor Phenomenon Scale (CIPS), alongside evaluated measures of well-being (WHO-5), life satisfaction (SWLS), and affect (PANAS).
  Results: The coaching resulted in modest reductions in CIPS scores, whereas the control group also improved during the observation phase, suggesting that contextual and temporal factors may have exerted a stronger influence than the formal intervention.
  Conclusion: These results suggest that coaching may support reflection and awareness related to IP, yet other contextual aspects of team collaboration and project work might also contribute to these changes. This study offers a novel empirical step toward understanding how structured IP interventions operate within SE environments.

</details>


### [23] [Constructive Patterns for Human-Centered Tech Hiring](https://arxiv.org/abs/2602.13845)
*Allysson Allex Araújo,Gabriel Vasconcelos,Marvin Wyrich,Maria Teresa Baldassarre,Paloma Guenes,Marcos Kalinowski*

Main category: cs.SE

TL;DR: 研究发现22种构建性模式，帮助科技公司改善早期职业软件工程师的在线招聘体验，超越传统问题诊断，提供具体改进方案。


<details>
  <summary>Details</summary>
Motivation: 在线招聘过程通常是早期职业软件工程师与科技行业的首次接触，但许多候选人认为这些过程不透明、低效甚至令人沮丧。虽然先前研究广泛记录了在线科技招聘中的缺陷和偏见，但对于创造积极候选人体验的实践知之甚少。

Method: 基于申请人归因反应理论，对22名早期职业软件工程师进行半结构化访谈，收集了超过470个在线招聘体验的描述，通过主题分析识别积极实践模式。

Result: 识别出22种构建性模式，包括：全面透明的职位广告、具体且有发展性的反馈、人性化且尊重的互动、将过程视为双向选择等积极实践。

Conclusion: 研究将科技招聘讨论从诊断功能障碍扩展到设计以人为本、以成长为导向的候选人体验，为组织提供具体、经验基础的资源来更有效地吸引和支持早期职业软件工程师。

Abstract: [Context] Online Recruitment and Selection (R&S) processes are often the first point of contact between early-career software engineers and the tech industry. Yet many candidates experience these processes as opaque, inefficient, or even discouraging. While prior research has extensively documented the flaws and biases in online tech hiring, little is known about the practices that create positive candidate experiences. [Objective & Method] This paper explores such practices, referred to as Constructive Patterns (CPs), from the perspective of early-career software engineers. Guided by Applicant Attribution-Reaction Theory, we conducted 22 semi-structured interviews in which participants collectively described over 470 online R&S experiences. [Results] Through thematic analysis, we identified 22 CPs that reflect positive practices such as comprehensive and transparent job advertisements (CP01), specific and developmental feedback (CP03), humanized and respectful interaction (CP06), and framing the process as a two-way street (CP18). [Conclusion] Our findings extend the conversation on tech hiring beyond diagnosing dysfunctions toward designing for human-centered and growth-oriented candidate experiences. The resulting catalog of CPs provides a concrete and empirically grounded resource for organizations seeking to attract and support early-career software engineers more effectively.

</details>


### [24] [Evaluating LLM-Generated ACSL Annotations for Formal Verification](https://arxiv.org/abs/2602.13851)
*Arshad Beg,Diarmuid O'Donoghue,Rosemary Monahan*

Main category: cs.SE

TL;DR: 该论文对五种ACSL规范自动生成系统（包括基于规则的脚本、Frama-C RTE插件和三个大语言模型）在506个C程序上的生成与验证能力进行了实证评估。


<details>
  <summary>Details</summary>
Motivation: 为C程序生成准确且可验证的形式化规范对于构建可验证、可靠的软件系统至关重要，但目前自动生成真实C程序ACSL规范仍面临挑战。需要实证评估形式化分析工具在无需人工或学习辅助的情况下自动生成和验证ACSL规范的能力。

Method: 在最近发布的506个C程序数据集上进行受控研究，将原本用于交互式、开发者驱动工作流的数据集重新用于自动化评估。比较五种ACSL生成系统：基于规则的Python脚本、Frama-C的RTE插件，以及三个大语言模型（DeepSeek-V3.2、GPT-5.2和OLMo 3.1 32B Instruct）。所有生成的规范在相同条件下使用Frama-C WP插件配合多个SMT求解器进行验证。

Result: 研究结果为自动ACSL生成的能力和局限性提供了新的实证证据，补充了先前基于调查的工作。通过直接比较注释质量、求解器敏感性和证明稳定性，揭示了不同生成系统的性能差异。

Conclusion: 该研究系统评估了自动ACSL规范生成工具的现状，为形式化验证社区提供了重要的基准数据，有助于理解当前自动化工具在形式化规范生成方面的实际能力。

Abstract: Formal specifications are crucial for building verifiable and dependable software systems, yet generating accurate and verifiable specifications for real-world C programs remains challenging. This paper empirically evaluates the extent to which formal-analysis tools can automatically generate and verify ACSL specifications without human or learning-based assistance. We conduct a controlled study on a recently released dataset of 506 C programs, repurposing it from interactive, developer-driven workflows to an automated evaluation setting. Five ACSL generation systems are compared: a rule-based Python script, Frama-C's RTE plugin, and three large language models--DeepSeek-V3.2, GPT-5.2, and OLMo 3.1 32B Instruct. All generated specifications are verified under identical conditions using the Frama-C WP plugin powered by multiple SMT solvers, allowing a direct comparison of annotation quality, solver sensitivity, and proof stability. Our results provide new empirical evidence on the capabilities and limitations of automated ACSL generation, complementing prior survey-based work.

</details>


### [25] [CodeGlance: Understanding Code Reasoning Challenges in LLMs through Multi-Dimensional Feature Analysis](https://arxiv.org/abs/2602.13962)
*Yunkun Wang,Xuanhe Zhang,Junxiao Han,Chen Zhi,Shuiguang Deng*

Main category: cs.SE

TL;DR: CodeGlance是一个多维基准测试，用于评估LLM在三种真实场景下的代码推理能力：内在逻辑推理、API交互推理和未知函数推理，揭示了未知函数推理对较小模型的显著挑战。


<details>
  <summary>Details</summary>
Motivation: 现有代码推理研究主要关注孤立代码片段，忽略了涉及外部API交互和未知函数的真实场景复杂性，这阻碍了理解LLM在不同编程上下文中的真正挑战。

Method: 创建CodeGlance基准测试，包含三个真实场景：内在逻辑推理、API交互推理、未知函数推理。系统评估7个最先进的LLM，分析代码复杂性特征（执行跟踪长度、API调用次数、控制流复杂性），并研究增强策略（CoT、文档检索、代码搜索）的效果。

Result: 未知函数推理对较小模型构成显著挑战，Qwen2.5-3b在未知函数上仅达到6.0%准确率，而在熟悉API上达到37.5%。代码复杂性特征（执行跟踪长度、API调用次数、控制流复杂性）显著影响推理难度。增强策略的效果因挑战源于逻辑复杂性还是知识差距而异。

Conclusion: 研究结果为开发更强大的代码推理系统和在实际软件开发中部署基于LLM的编程助手提供了可操作的指导，强调了考虑真实场景复杂性的重要性。

Abstract: In modern software development, developers frequently need to understand code behavior at a glance -- whether reviewing pull requests, debugging issues, or navigating unfamiliar codebases. This ability to reason about dynamic program behavior is fundamental to effective software engineering and increasingly supported by Large Language Models (LLMs). However, existing studies on code reasoning focus primarily on isolated code snippets, overlooking the complexity of real-world scenarios involving external API interactions and unfamiliar functions. This gap hinders our understanding of what truly makes code reasoning challenging for LLMs across diverse programming contexts.
  We present CodeGlance, a multi-dimensional benchmark investigating code reasoning challenges across three realistic scenarios: intrinsic logic reasoning, API interaction reasoning, and unseen function reasoning. Through systematic evaluation of 7 state-of-the-art LLMs, we reveal that unseen function reasoning poses significant challenges especially for smaller models, with Qwen2.5-3b achieving only 6.0\% accuracy on unseen functions compared to 37.5\% on familiar APIs. We identify critical code complexity features -- including execution trace length, API invocation count, and control flow complexity -- that significantly impact code reasoning difficulty across scenarios. We further investigate how common augmentation strategies, including CoT, document retrieval, and code search, can improve reasoning performance, finding that their effectiveness varies substantially depending on whether challenges stem from logical complexity or knowledge gaps. These findings provide actionable guidance for developing more capable code reasoning systems and deploying LLM-based programming assistants in real-world software development.

</details>


### [26] [ATTest: Agent-Driven Tensor Testing for Deep Learning Library Modules](https://arxiv.org/abs/2602.13987)
*Zhengyu Zhan,Ye Shang,Jiawei Liu,Chunrong Fang,Quanjun Zhang,Zhenyu Chen*

Main category: cs.SE

TL;DR: ATTest是一个基于智能体驱动的张量测试框架，用于深度学习库的模块级单元测试生成，通过七阶段流水线解决传统方法的语义盲区和LLM的上下文限制问题。


<details>
  <summary>Details</summary>
Motivation: 深度学习库的单元测试面临复杂数值语义和隐式张量约束的挑战。传统基于搜索的软件测试存在语义盲区，难以满足高维张量约束，而大语言模型在处理跨文件上下文和不稳定代码修改方面存在困难。

Method: ATTest采用智能体驱动的七阶段流水线，包括约束提取和迭代的"生成-验证-修复"循环，以保持测试稳定性并缓解上下文窗口饱和问题。

Result: 在PyTorch和TensorFlow上的评估显示，ATTest显著优于PynguinML等最先进基线，平均分支覆盖率分别达到55.60%和54.77%。

Conclusion: 智能体驱动的工作流程能够弥合数值库中的语义差距，同时确保可审计的测试合成，为深度学习库测试提供了有效解决方案。

Abstract: The unit testing of Deep Learning (DL) libraries is challenging due to complex numerical semantics and implicit tensor constraints. Traditional Search-Based Software Testing (SBST) often suffers from semantic blindness, failing to satisfy the constraints of high-dimensional tensors, whereas Large Language Models (LLMs) struggle with cross-file context and unstable code modifications. This paper proposes ATTest, an agent-driven tensor testing framework for module-level unit test generation. ATTest orchestrates a seven-stage pipeline, which encompasses constraint extraction and an iterative "generation-validation-repair" loop, to maintain testing stability and mitigate context-window saturation. An evaluation on PyTorch and TensorFlow demonstrates that ATTest significantly outperforms state-of-the-art baselines such as PynguinML, achieving an average branch coverage of 55.60% and 54.77%, respectively. The results illustrate how agent-driven workflows bridge the semantic gap in numerical libraries while ensuring auditable test synthesis. Source code: https://github.com/iSEngLab/ATTest.git

</details>


### [27] [Every Maintenance Has Its Exemplar: The Future of Software Maintenance through Migration](https://arxiv.org/abs/2602.14046)
*Zirui Chen,Xing Hu,Xin Xia,Xiaohu Yang*

Main category: cs.SE

TL;DR: 该论文首次系统性地提出了基于迁移的软件维护研究议程，将迁移维护生命周期划分为四个关键阶段，并分析了各阶段的挑战，旨在推动自动化软件维护的发展。


<details>
  <summary>Details</summary>
Motivation: 软件维护是软件生命周期中的关键阶段，但人工维护劳动密集、耗时且易出错，迫切需要自动化。基于迁移的方法通过从其他系统转移知识、工件或解决方案，在API演进适配、软件测试和补丁迁移等任务中展现出强大潜力，是推进自动化维护的重要研究方向。

Method: 提出首个系统性的基于迁移的软件维护研究议程，将迁移维护生命周期划分为四个关键阶段：1)识别可通过迁移解决的维护任务；2)为目标项目选择合适的迁移源；3)跨系统匹配相关数据并适应目标上下文；4)验证迁移的正确性。同时分析各阶段可能出现的挑战。

Result: 建立了基于迁移的软件维护的系统框架，明确了迁移维护的完整生命周期和关键挑战，为后续研究提供了清晰的路线图。

Conclusion: 基于迁移的软件维护是推进自动化维护的有价值研究方向，本文提出的系统性研究议程旨在鼓励社区更深入地探索迁移方法，解决关键挑战以推动自动化软件维护的进步。

Abstract: Maintenance is a critical stage in the software lifecycle, ensuring that post-release systems remain reliable, efficient, and adaptable. However, manual software maintenance is labor-intensive, time-consuming, and error-prone, which highlights the urgent need for automation. Learning from maintenance activities conducted on other software systems offers an effective way to improve efficiency. In particular, recent research has demonstrated that migration-based approaches transfer knowledge, artifacts, or solutions from one system to another and show strong potential in tasks such as API evolution adaptation, software testing, and migrating patches for fault correction. This makes migration-based maintenance a valuable research direction for advancing automated maintenance.
  This paper takes a step further by presenting the first systematic research agenda on migration-based approaches to software maintenance. We characterize the migration-based maintenance lifecycle through four key stages: \ding{182} identifying a maintenance task that can be addressed through migration, \ding{183} selecting suitable migration sources for the target project,\ding{184} matching relevant data across systems and adapting the migrated data to the target context, and \ding{185} validating the correctness of the migration. We also analyze the challenges that may arise at each stage. Our goal is to encourage the community to explore migration-based approaches more thoroughly and to tackle the key challenges that must be solved to advance automated software maintenance.

</details>


### [28] [LongCLI-Bench: A Preliminary Benchmark and Study for Long-horizon Agentic Programming in Command-Line Interfaces](https://arxiv.org/abs/2602.14337)
*Yukang Feng,Jianwen Sun,Zelai Yang,Jiaxin Ai,Chuanhao Li,Zizhen Li,Fanrui Zhang,Kang He,Rui Ma,Jifan Lin,Jie Sun,Yang Xiao,Sizhuo Zhou,Wenxiao Wu,Yiming Liu,Pengfei Liu,Yu Qiao,Shenglin Zhang,Kaipeng Zhang*

Main category: cs.SE

TL;DR: LongCLI-Bench：一个评估AI编程代理长时程任务能力的基准，包含20个高质量长时程任务，采用双集测试协议，结果显示最先进代理的通过率低于20%


<details>
  <summary>Details</summary>
Motivation: 现有AI编程代理基准存在三个主要问题：任务时程短、GitHub数据污染、缺乏细粒度评估指标，无法有效评估真实软件工程所需的长时程规划和执行能力

Method: 从1000多个计算机科学作业和真实工作流中精选20个高质量长时程任务，涵盖四个工程类别：从零开始、功能添加、错误修复和重构。提出双集测试协议，测量需求满足度（失败到通过）和回归避免（通过到通过），并包含步骤级评分以精确定位执行失败

Result: 最先进的代理在LongCLI-Bench中的通过率低于20%。步骤级分析显示大多数任务在完成度低于30%时停滞，关键失败常发生在早期阶段。自我纠正仅带来边际改进，而通过计划注入和交互指导的人机协作能显著提高性能

Conclusion: 未来研究必须强调协同人机工作流的开发，同时提升代理的规划和执行能力，以克服长时程任务性能的关键挑战

Abstract: Recent advances in AI-assisted programming have empowered agents to execute complex workflows via command-line interfaces, however, existing benchmarks are limited by short task horizons, data contamination from GitHub scraping, and a lack of fine-grained evaluation metrics, fail to rigorously evaluate the long-horizon planning and execution capabilities essential for realistic software engineering. To address these gaps, we introduce LongCLI-Bench, a comprehensive benchmark designed to evaluate agentic capabilities across long-horizon, realistic tasks. We curated 20 high-quality, long-horizon tasks from over 1,000 computer science assignments and real-world workflows, covering four engineering categories: from scratch, feature addition, bug fixing, and refactoring. We propose a dual-set testing protocol for LongCLI-Bench, which measures requirement fulfillment (fail-to-pass) and regression avoidance (pass-to-pass), and incorporates step-level scoring to pinpoint execution failures. Extensive experiments reveal that even state-of-the-art agents achieve pass rates below 20% in LongCLI-Bench. Step-level analysis further indicates that the majority of tasks stall at less than 30% completion, highlighting that critical failures often occur in the early stages. Although self-correction offers marginal gains, human-agent collaboration through plan injection and interactive guidance yields significantly higher improvements. These results highlight that future research must emphasize the development of synergistic human-agent workflows alongside advances in agents' planning and execution capabilities to overcome key challenges in long-horizon task performance.

</details>


### [29] [An Empirical Study of the Evolution of GitHub Actions Workflows](https://arxiv.org/abs/2602.14572)
*Pooya Rostami Mazrae,Alexandre Decan,Tom Mens,Mairieli Wessel*

Main category: cs.SE

TL;DR: 对GitHub Actions工作流变更的混合方法分析，涵盖49K+仓库的267K+变更历史和3.4M+工作流文件版本，发现工作流变更频繁但规模小，主要涉及任务配置，未发现LLM工具对工作流维护的显著影响。


<details>
  <summary>Details</summary>
Motivation: GitHub Actions作为GitHub集成的CI/CD工具，在协作软件开发中自动化测试、构建、质量检查等任务。了解工作流的变更模式和频率对于改进工具支持和工作流维护至关重要。

Method: 采用混合方法分析：1) 对439个修改的工作流文件进行初步定性分析，识别出7种概念变更类型；2) 对2019年11月至2025年8月期间49K+ GitHub仓库的267K+工作流变更历史和3.4M+工作流文件版本进行定量分析。

Result: 仓库中位数为3个工作流文件，7.3%的工作流文件每周变更；变更规模小，约四分之三只包含单一变更；大多数变更涉及工作流作业中的任务配置和任务规范；未发现LLM编码工具或其他重大技术变革对工作流创建和维护频率的明确影响。

Conclusion: 研究结果强调需要改进工具来支持细粒度维护任务，包括更广泛采用依赖管理和基于AI的支持，以确保和维持工作流的安全性和质量。

Abstract: CI/CD practices play a significant role during collaborative software development by automating time-consuming and repetitive tasks such as testing, building, quality checking, dependency and security management. GitHub Actions, the CI/CD tool integrated into GitHub, allows repository maintainers to automate development workflows. We conducted a mixed methods analysis of GitHub Actions workflow changes over time. Through a preliminary qualitative analysis of 439 modified workflow files we identified seven types of conceptual changes to workflows. Next, we performed a quantitative analysis over 49K+ GitHub repositories totaling 267K+ workflow change histories and 3.4M+ workflow file versions from November 2019 to August 2025. This analysis revealed that repositories contain a median of three workflow files, and 7.3% of all workflow files are being changed every week. The changes made to workflows tend to be small, with about three-quarters containing only a single change. The large majority of the observed changes have to do with task configuration and task specification in workflow jobs. We did not find any conclusive evidence of the effect of LLM coding tools or other major technological changes on workflow creation and workflow maintenance frequency. Our findings highlight the need for improved tooling to support fine-grained maintenance tasks, such as a broader adoption of dependency management and AI-based support for ensuring and sustaining workflow security and quality.

</details>


### [30] [Automated Classification of Source Code Changes Based on Metrics Clustering in the Software Development Process](https://arxiv.org/abs/2602.14591)
*Evgenii Kniazev*

Main category: cs.SE

TL;DR: 提出一种基于聚类分析的自劢化源代码变更分类方法，通过k-means算法对11种代码变更指标进行聚类，再由专家将聚类结果映射到预定义的变更类别中。


<details>
  <summary>Details</summary>
Motivation: 在软件开发过程中，手动审查代码变更耗时且效率低下。需要一种自动化方法来减少代码变更审查所需的时间，同时保持分类的准确性。

Method: 采用两阶段方法：首先使用k-means算法和余弦相似度度量对11种源代码变更指标（包括代码行数、圈复杂度、文件数量、接口变更和结构变更等）进行聚类分析；然后由专家将聚类结果映射到预定义的变更类别中。

Result: 在5个软件系统（包括Subversion和NHibernate两个开源项目）上验证，分类纯度达到P_C = 0.75 ± 0.05，熵为E_C = 0.37 ± 0.06（显著性水平0.05），自动化分布步骤显著减少了代码变更审查时间。

Conclusion: 该方法通过自动化聚类和专家映射相结合的方式，有效减少了代码变更审查时间，同时保持了较好的分类质量，为软件开发过程中的变更管理提供了实用工具。

Abstract: This paper presents an automated method for classifying source code changes during the software development process based on clustering of change metrics. The method consists of two steps: clustering of metric vectors computed for each code change, followed by expert mapping of the resulting clusters to predefined change classes. The distribution of changes into clusters is performed automatically, while the mapping of clusters to classes is carried out by an expert. Automation of the distribution step substantially reduces the time required for code change review. The k-means algorithm with a cosine similarity measure between metric vectors is used for clustering. Eleven source code metrics are employed, covering lines of code, cyclomatic complexity, file counts, interface changes, and structural changes. The method was validated on five software systems, including two open-source projects (Subversion and NHibernate), and demonstrated classification purity of P_C = 0.75 +/- 0.05 and entropy of E_C = 0.37 +/- 0.06 at a significance level of 0.05.

</details>


### [31] [Consistent or Sensitive? Automated Code Revision Tools Against Semantics-Preserving Perturbations](https://arxiv.org/abs/2602.14595)
*Shirin Pirouzkhah,Souhaila Serbout,Alberto Bacchelli*

Main category: cs.SE

TL;DR: 本文研究自动代码修订工具的"一致性"问题，发现即使面对语义等价的代码变体，现有工具也会产生不一致的修订，正确率下降高达45.3%，且缺乏有效缓解策略。


<details>
  <summary>Details</summary>
Motivation: 自动代码修订工具在实际应用中需要处理表达相同问题的相似代码变体，这种"一致性"能力对其实用性至关重要。然而，现有工具的随机性可能导致对语义等价代码产生不同的修订结果，影响其可靠性。

Method: 设计了9种语义保持扰动类型，应用于2032个真实GitHub项目的Java方法，生成超过10K个扰动变体。使用这些变体评估5种最先进的基于Transformer的ACR工具的一致性表现。

Result: ACR工具在面对语义等价代码时，生成正确修订的能力下降高达45.3%。扰动越接近目标区域，工具越可能失败。尝试的注意力引导启发式方法仅带来边际改进。

Conclusion: 现有ACR工具在一致性方面存在严重缺陷，缺乏有效的缓解策略，这成为一个开放的研究问题。工具对代码变体的敏感性限制了其实际应用价值。

Abstract: Automated Code Revision (ACR) tools aim to reduce manual effort by automatically generating code revisions based on reviewer feedback. While ACR tools have shown promising performance on historical data, their real-world utility depends on their ability to handle similar code variants expressing the same issue - a property we define as consistency. However, the probabilistic nature of ACR tools often compromises consistency, which may lead to divergent revisions even for semantically equivalent code variants. In this paper, we investigate the extent to which ACR tools maintain consistency when presented with semantically equivalent code variants. To do so, we first designed nine types of semantics-preserving perturbations (SPP) and applied them to 2032 Java methods from real-world GitHub projects, generating over 10K perturbed variants for evaluation. Then we used these perturbations to evaluate the consistency of five state-of-the-art transformer-based ACR tools. We found that the ACR tools' ability to generate correct revisions can drop by up to 45.3%, when presented with semantically equivalent code. The closer the perturbation is to this targeted region, the more likely an ACR tool is to fail to generate the correct revision. We explored potential mitigation strategies that modify the input representation, but found that these attention-guiding heuristics yielded only marginal improvements, thus leaving the solution to this problem as an open research question.

</details>


### [32] [The Value of Effective Pull Request Description](https://arxiv.org/abs/2602.14611)
*Shirin Pirouzkhah,Pavlína Wurzel Gonçalves,Alberto Bacchelli*

Main category: cs.SE

TL;DR: 该研究通过混合方法实证分析GitHub PR描述，发现开发者重视PR描述但不同元素作用不同：目的和代码解释有助于保存变更理据和历史，而明确反馈类型最能预测变更接受和评审参与度。


<details>
  <summary>Details</summary>
Motivation: 在基于拉取请求的开发模式中，PR描述的作用尚未得到系统研究。虽然代码贡献通过PR提交并接受评审，但PR描述的具体价值和影响缺乏实证证据，需要填补这一研究空白。

Method: 采用混合方法：1) 灰色文献回顾提取PR描述写作指南，建立包含8个推荐元素的分类法；2) 分析156个项目、5种编程语言的80K个GitHub PR，评估元素与评审结果的关系；3) 调查64名开发者对元素重要性的认知；4) 分析提交时因素对PR描述及其元素的影响。

Result: 开发者认为PR描述重要但元素作用各异：目的和代码解释元素被开发者重视用于保存变更理据和历史；明确反馈类型最能预测变更接受和评审参与度；PR描述在成熟项目和复杂变更中更常见，表明其在实际有用时被使用而非形式主义。

Conclusion: PR描述在代码评审中具有实际价值，不同元素服务于不同目的。开发者应特别重视明确反馈类型以提高变更接受率，同时使用目的和代码解释元素来记录变更历史。PR描述的使用模式表明其在实际需要时被采用，而非机械遵循规范。

Abstract: In the pull-based development model, code contributions are submitted as pull requests (PRs) to undergo reviews and approval by other developers with the goal of being merged into the code base. A PR can be supported by a description, whose role has not yet been systematically investigated. To fill in this gap, we conducted a mixed-methods empirical study of PR descriptions. We conducted a grey literature review of guidelines on writing PR descriptions and derived a taxonomy of eight recommended elements. Using this taxonomy, we analyzed 80K GitHub PRs across 156 projects and five programming languages to assess associations between these elements and code review outcomes (e.g., merge decision, latency, first response time, review comments, and review iteration cycles). To complement these results, we surveyed 64 developers about the perceived importance of each element. Finally, we analyzed which submission-time factors predict whether PRs include a description and which elements they contain. We found that developers view PR descriptions as important, but their elements matter differently: purpose and code explanations are valued by developers for preserving the rationale and history of changes, while stating the desired feedback type best predicts change acceptance and reviewer engagement. PR descriptions are also more common in mature projects and complex changes, suggesting they are written when most useful rather than as a formality.

</details>


### [33] [Configuring Agentic AI Coding Tools: An Exploratory Study](https://arxiv.org/abs/2602.14690)
*Matthias Galster,Seyedmoein Mohsenimofidi,Jai Lal Lulla,Muhammad Auwal Abubakar,Christoph Treude,Sebastian Baltes*

Main category: cs.SE

TL;DR: 对5种AI编程工具配置机制的系统分析，基于2926个GitHub仓库的实证研究，揭示了配置模式、采用深度和工具文化差异


<details>
  <summary>Details</summary>
Motivation: 随着AI编程工具从对话式内容生成向自主能力发展，开发者通过版本控制的仓库级配置文件来配置这些工具。目前缺乏对这些配置机制的系统性分析和实证研究，需要了解实际采用情况和配置模式。

Method: 1. 识别8种配置机制；2. 对2926个GitHub仓库进行实证研究，分析配置采用情况；3. 深入分析三种跨工具通用机制：Context Files、Skills和Subagents；4. 比较不同工具（Claude Code、GitHub Copilot、Cursor、Gemini、Codex）的配置文化差异。

Result: 1. Context Files主导配置格局，常为仓库唯一机制，AGENTS.md成为跨工具互操作标准；2. 高级机制（Skills和Subagents）采用浅层：多数仓库仅定义1-2个工件，Skills主要依赖静态指令而非可执行工作流；3. 不同工具形成独特配置文化，Claude Code用户使用最广泛的机制范围。

Conclusion: 研究为纵向和实验研究建立了实证基线，以了解随着AI编程工具成熟，配置策略如何演变并影响代理性能。当前配置仍处于早期阶段，高级功能采用有限，但已出现跨工具标准和差异化使用模式。

Abstract: Agentic AI coding tools with autonomous capabilities beyond conversational content generation increasingly automate repetitive and time-consuming software development tasks. Developers can configure these tools through versioned repository-level artifacts such as Markdown and JSON files. In this paper, we present a systematic analysis of configuration mechanisms for agentic AI coding tools, covering Claude Code, GitHub Copilot, Cursor, Gemini, and Codex. We identify eight configuration mechanisms and, in an empirical study of 2,926 GitHub repositories, examine whether and how they are adopted. We then explore Context Files, Skills, and Subagents, that is, three mechanisms available across tools, in more detail. Our findings reveal three trends. First, Context Files dominate the configuration landscape and are often the sole mechanism in a repository, with AGENTS$.$md emerging as an interoperable standard across tools. Second, advanced mechanisms such as Skills and Subagents are only shallowly adopted: most repositories define only one or two artifacts, and Skills predominantly rely on static instructions rather than executable workflows. Third, distinct configuration cultures are forming around different tools, with Claude Code users employing the broadest range of mechanisms. These findings establish an empirical baseline for longitudinal and experimental research on how configuration strategies evolve and affect agent performance as agentic AI coding tools mature.

</details>


### [34] [Model Context Protocol (MCP) Tool Descriptions Are Smelly! Towards Improving AI Agent Efficiency with Augmented MCP Tool Descriptions](https://arxiv.org/abs/2602.14878)
*Mohammed Mehedi Hasan,Hao Li,Gopi Krishnan Rajbahadur,Bram Adams,Ahmed E. Hassan*

Main category: cs.SE

TL;DR: 对856个MCP工具进行首次大规模实证研究，发现97.1%的工具描述存在缺陷，改进描述可提升任务成功率但增加执行步骤，存在性能与成本的权衡。


<details>
  <summary>Details</summary>
Motivation: MCP中工具描述的质量直接影响基于基础模型的代理选择合适工具和传递正确参数的能力，但描述缺陷的普遍性和影响尚不清楚。

Method: 从文献中识别工具描述的六个组件，开发评分标准，基于此形式化工具描述缺陷，使用基于基础模型的扫描器分析856个工具，并进行描述增强实验。

Result: 97.1%的工具描述至少存在一个缺陷，56%未能清晰说明目的；增强描述使任务成功率中位数提升5.85个百分点，但执行步骤增加67.46%，16.67%的情况性能下降。

Conclusion: 工具描述质量对代理性能有显著影响，但存在性能与成本的权衡；紧凑的组件组合变体可在保持行为可靠性的同时减少不必要的token开销，实现更高效的上下文窗口使用。

Abstract: The Model Context Protocol (MCP) standardizes how Foundation Model (FM)-based agents interact with external systems by invoking tools. However, to understand a tool's purpose and features, FMs rely on natural-language tool descriptions, making these descriptions a critical component in guiding FMs to select the optimal tool for a given (sub)task and to pass the right arguments to the tool. While defects or smells in these descriptions can misguide FM-based agents, their prevalence and consequences in the MCP ecosystem remain unclear.
  To address this, we conduct the first large-scale empirical study of 856 tools spread across 103 MCP servers, assessing their description quality and their impact on agent performance. We identify six components of tool descriptions from the literature, develop a scoring rubric utilizing these components, then formalize tool description smells based on this rubric. By operationalizing this rubric through an FM-based scanner, we find that 97.1% of the analyzed tool descriptions contain at least one smell, with 56% failing to state their purpose clearly. While augmenting these descriptions for all components improves task success rates by a median of 5.85 percentage points and improves partial goal completion by 15.12%, it also increases the number of execution steps by 67.46% and regresses performance in 16.67% of cases. These findings highlight a trade-off between agent performance and cost, as well as the context sensitivity of the performance gain. Furthermore, component ablations show that compact variants of different component combinations often preserve behavioral reliability while reducing unnecessary token overhead, enabling more efficient use of the FM context window and lower execution costs.

</details>
