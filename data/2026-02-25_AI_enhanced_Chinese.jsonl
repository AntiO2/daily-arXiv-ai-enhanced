{"id": "2602.20341", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2602.20341", "abs": "https://arxiv.org/abs/2602.20341", "authors": ["Ignacio Amores-Sesar", "Mirza Ahad Baig", "Seth Gilbert", "Ray Neiheiser", "Michelle X. Yeo"], "title": "The Tragedy of Chain Commons", "comment": null, "summary": "Byzantine Fault Tolerant (BFT) consensus forms the foundation of many modern blockchains striving for both high throughput and low latency. A growing bottleneck is transaction execution and validation on the critical path of consensus, which has led to modular decoupled designs that separate ordering from execution: Consensus orders only metadata, while transactions are executed and validated concurrently. While this approach improves performance, it can leave invalid transactions in the ledger, increasing storage costs and enabling new forms of strategic behavior. We present the first systematic study of this setting, providing a formal framework to reason about the interaction between consensus and execution. Using this framework, we show that the decoupled design enables a previously unidentified attack, which we term gaslighting. We prove a fundamental trade-off between resilience to this attack and resource capacity utilization, where both are impossible to achieve deterministically in the decoupled model. To address this trade-off, we discuss an intermediate model for leader-based protocols that is robust to gaslighting attacks while achieving high throughput and low latency.", "AI": {"tldr": "\u8bba\u6587\u7cfb\u7edf\u7814\u7a76\u4e86BFT\u5171\u8bc6\u4e2d\u89e3\u8026\u8bbe\u8ba1\uff08\u6392\u5e8f\u4e0e\u6267\u884c\u5206\u79bb\uff09\u7684\u5b89\u5168\u9690\u60a3\uff0c\u53d1\u73b0\u4e86\u65b0\u7684gaslighting\u653b\u51fb\uff0c\u8bc1\u660e\u4e86\u653b\u51fb\u62b5\u6297\u6027\u4e0e\u8d44\u6e90\u5229\u7528\u7387\u4e4b\u95f4\u7684\u6839\u672c\u6027\u6743\u8861\uff0c\u5e76\u63d0\u51fa\u4e86\u4e2d\u95f4\u6a21\u578b\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u73b0\u4ee3\u533a\u5757\u94fe\u8ffd\u6c42\u9ad8\u541e\u5410\u91cf\u548c\u4f4e\u5ef6\u8fdf\uff0c\u4f46\u4ea4\u6613\u6267\u884c\u548c\u9a8c\u8bc1\u6210\u4e3a\u5171\u8bc6\u5173\u952e\u8def\u5f84\u7684\u74f6\u9888\u3002\u89e3\u8026\u8bbe\u8ba1\uff08\u5c06\u6392\u5e8f\u4e0e\u6267\u884c\u5206\u79bb\uff09\u867d\u7136\u63d0\u5347\u4e86\u6027\u80fd\uff0c\u4f46\u53ef\u80fd\u5bfc\u81f4\u65e0\u6548\u4ea4\u6613\u7559\u5728\u8d26\u672c\u4e2d\uff0c\u589e\u52a0\u5b58\u50a8\u6210\u672c\u5e76\u5f15\u53d1\u65b0\u7684\u6218\u7565\u884c\u4e3a\u98ce\u9669\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u5f62\u5f0f\u5316\u6846\u67b6\u6765\u5206\u6790\u5171\u8bc6\u4e0e\u6267\u884c\u4e4b\u95f4\u7684\u4ea4\u4e92\u5173\u7cfb\uff0c\u4f7f\u7528\u8be5\u6846\u67b6\u8bc1\u660e\u4e86\u5728\u89e3\u8026\u6a21\u578b\u4e2d\u5b58\u5728\u4e00\u79cd\u65b0\u7684gaslighting\u653b\u51fb\uff0c\u5e76\u8bc1\u660e\u4e86\u653b\u51fb\u62b5\u6297\u6027\u4e0e\u8d44\u6e90\u5bb9\u91cf\u5229\u7528\u7387\u4e4b\u95f4\u7684\u6839\u672c\u6027\u6743\u8861\u3002\u9488\u5bf9\u57fa\u4e8e\u9886\u5bfc\u8005\u7684\u534f\u8bae\uff0c\u8ba8\u8bba\u4e86\u4e00\u79cd\u4e2d\u95f4\u6a21\u578b\u3002", "result": "\u53d1\u73b0\u4e86\u4e4b\u524d\u672a\u88ab\u8bc6\u522b\u7684gaslighting\u653b\u51fb\uff0c\u8bc1\u660e\u4e86\u5728\u89e3\u8026\u6a21\u578b\u4e2d\u786e\u5b9a\u6027\u5730\u540c\u65f6\u5b9e\u73b0\u653b\u51fb\u62b5\u6297\u6027\u548c\u9ad8\u8d44\u6e90\u5229\u7528\u7387\u662f\u4e0d\u53ef\u80fd\u7684\u3002\u63d0\u51fa\u7684\u4e2d\u95f4\u6a21\u578b\u80fd\u591f\u5728\u62b5\u6297gaslighting\u653b\u51fb\u7684\u540c\u65f6\u5b9e\u73b0\u9ad8\u541e\u5410\u91cf\u548c\u4f4e\u5ef6\u8fdf\u3002", "conclusion": "\u89e3\u8026\u8bbe\u8ba1\u867d\u7136\u63d0\u5347\u4e86\u6027\u80fd\uff0c\u4f46\u5f15\u5165\u4e86\u65b0\u7684\u5b89\u5168\u98ce\u9669\u3002\u9700\u8981\u5728\u5b89\u5168\u6027\u548c\u6548\u7387\u4e4b\u95f4\u505a\u51fa\u6743\u8861\uff0c\u63d0\u51fa\u7684\u4e2d\u95f4\u6a21\u578b\u4e3a\u89e3\u51b3\u8fd9\u4e00\u6743\u8861\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2602.20444", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2602.20444", "abs": "https://arxiv.org/abs/2602.20444", "authors": ["Paul Borrill"], "title": "Circumventing the FLP Impossibility Result with Open Atomic Ethernet", "comment": "12 pages, 3 figures, 1 table", "summary": "The Fischer--Lynch--Paterson (FLP) impossibility result is widely regarded as one of the most fundamental negative results in distributed computing: no deterministic protocol can guarantee consensus in an asynchronous system with even one faulty process. For forty years, the field has treated this as an immovable constraint, designing around it with randomized protocols, failure detectors, and weakened consistency models. This essay argues that FLP is not a law of physics but a theorem about a particular system model -- and that Open Atomic Ethernet (OAE) circumvents it by rejecting the asynchronous model at its foundation. We introduce the term bisynchronous to describe OAE's key property: bounded-time bilateral resolution in which both parties reach common knowledge of outcome at every round boundary -- a strictly stronger guarantee than synchrony alone. By constructing a bisynchronous, swap-based protocol at Layer 2, OAE sidesteps the load-bearing assumptions of FLP's asynchronous model, achieving deterministic atomic coordination without violating any impossibility result.", "AI": {"tldr": "\u672c\u6587\u8ba4\u4e3aFLP\u4e0d\u53ef\u80fd\u6027\u5b9a\u7406\u4e0d\u662f\u7269\u7406\u5b9a\u5f8b\uff0c\u800c\u662f\u7279\u5b9a\u7cfb\u7edf\u6a21\u578b\u7684\u5b9a\u7406\uff0c\u5e76\u63d0\u51faOpen Atomic Ethernet\u901a\u8fc7\u62d2\u7edd\u5f02\u6b65\u6a21\u578b\u57fa\u7840\u6765\u89c4\u907fFLP\u9650\u5236\u3002", "motivation": "FLP\u4e0d\u53ef\u80fd\u6027\u7ed3\u679c\u88ab\u8ba4\u4e3a\u662f\u5206\u5e03\u5f0f\u8ba1\u7b97\u4e2d\u6700\u57fa\u672c\u7684\u8d1f\u9762\u7ed3\u679c\u4e4b\u4e00\uff0c\u56db\u5341\u5e74\u6765\u8be5\u9886\u57df\u4e00\u76f4\u5c06\u5176\u89c6\u4e3a\u4e0d\u53ef\u79fb\u52a8\u7684\u7ea6\u675f\u3002\u672c\u6587\u65e8\u5728\u6311\u6218\u8fd9\u4e00\u4f20\u7edf\u89c2\u70b9\uff0c\u5c55\u793a\u5982\u4f55\u901a\u8fc7\u4e0d\u540c\u7684\u7cfb\u7edf\u6a21\u578b\u8bbe\u8ba1\u6765\u89c4\u907fFLP\u9650\u5236\u3002", "method": "\u63d0\u51fa\"\u53cc\u540c\u6b65\"\u6982\u5ff5\u6765\u63cf\u8ff0OAE\u7684\u5173\u952e\u7279\u6027\uff1a\u6bcf\u8f6e\u8fb9\u754c\u4e0a\u53cc\u65b9\u90fd\u80fd\u8fbe\u6210\u7ed3\u679c\u5171\u8bc6\u7684\u6709\u754c\u65f6\u95f4\u53cc\u8fb9\u51b3\u8bae\u3002\u901a\u8fc7\u5728\u7b2c\u4e8c\u5c42\u6784\u5efa\u57fa\u4e8e\u4ea4\u6362\u7684\u53cc\u540c\u6b65\u534f\u8bae\uff0cOAE\u7ed5\u8fc7\u4e86FLP\u5f02\u6b65\u6a21\u578b\u7684\u8d1f\u8f7d\u5047\u8bbe\u3002", "result": "OAE\u901a\u8fc7\u62d2\u7edd\u5f02\u6b65\u6a21\u578b\u7684\u57fa\u7840\u5047\u8bbe\uff0c\u5b9e\u73b0\u4e86\u786e\u5b9a\u6027\u539f\u5b50\u534f\u8c03\uff0c\u800c\u6ca1\u6709\u8fdd\u53cd\u4efb\u4f55\u4e0d\u53ef\u80fd\u6027\u7ed3\u679c\uff0c\u4ece\u800c\u89c4\u907f\u4e86FLP\u9650\u5236\u3002", "conclusion": "FLP\u4e0d\u53ef\u80fd\u6027\u5b9a\u7406\u4e0d\u662f\u5206\u5e03\u5f0f\u8ba1\u7b97\u7684\u7edd\u5bf9\u7ea6\u675f\uff0c\u800c\u662f\u7279\u5b9a\u6a21\u578b\u4e0b\u7684\u5b9a\u7406\u3002\u901a\u8fc7\u91c7\u7528\u53cc\u540c\u6b65\u6a21\u578b\u548c\u9002\u5f53\u7684\u534f\u8bae\u8bbe\u8ba1\uff0c\u53ef\u4ee5\u5728\u5b9e\u9645\u7cfb\u7edf\u4e2d\u5b9e\u73b0\u786e\u5b9a\u6027\u5171\u8bc6\uff0c\u8fd9\u4e3a\u5206\u5e03\u5f0f\u7cfb\u7edf\u8bbe\u8ba1\u5f00\u8f9f\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2602.20450", "categories": ["cs.DC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.20450", "abs": "https://arxiv.org/abs/2602.20450", "authors": ["Nihal Balivada", "Shrey Gupta", "Shashank Shreedhar Bhatt", "Suyash Gupta"], "title": "Heterogeneity-Aware Client Selection Methodology For Efficient Federated Learning", "comment": null, "summary": "Federated Learning (FL) enables a distributed client-server architecture where multiple clients collaboratively train a global Machine Learning (ML) model without sharing sensitive local data. However, FL often results in lower accuracy than traditional ML algorithms due to statistical heterogeneity across clients. Prior works attempt to address this by using model updates, such as loss and bias, from client models to select participants that can improve the global model's accuracy. However, these updates neither accurately represent a client's heterogeneity nor are their selection methods deterministic. We mitigate these limitations by introducing Terraform, a novel client selection methodology that uses gradient updates and a deterministic selection algorithm to select heterogeneous clients for retraining. This bi-pronged approach allows Terraform to achieve up to 47 percent higher accuracy over prior works. We further demonstrate its efficiency through comprehensive ablation studies and training time analyses, providing strong justification for the robustness of Terraform.", "AI": {"tldr": "Terraform\u662f\u4e00\u79cd\u65b0\u9896\u7684\u8054\u90a6\u5b66\u4e60\u5ba2\u6237\u7aef\u9009\u62e9\u65b9\u6cd5\uff0c\u901a\u8fc7\u68af\u5ea6\u66f4\u65b0\u548c\u786e\u5b9a\u6027\u9009\u62e9\u7b97\u6cd5\u9009\u62e9\u5f02\u6784\u5ba2\u6237\u7aef\u8fdb\u884c\u91cd\u8bad\u7ec3\uff0c\u76f8\u6bd4\u5148\u524d\u5de5\u4f5c\u51c6\u786e\u7387\u63d0\u5347\u9ad8\u8fbe47%", "motivation": "\u8054\u90a6\u5b66\u4e60\u5728\u5206\u5e03\u5f0f\u5ba2\u6237\u7aef-\u670d\u52a1\u5668\u67b6\u6784\u4e2d\u8bad\u7ec3\u5168\u5c40\u6a21\u578b\u65f6\uff0c\u7531\u4e8e\u5ba2\u6237\u7aef\u95f4\u7684\u7edf\u8ba1\u5f02\u6784\u6027\uff0c\u901a\u5e38\u5bfc\u81f4\u51c6\u786e\u7387\u4f4e\u4e8e\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u3002\u73b0\u6709\u65b9\u6cd5\u4f7f\u7528\u6a21\u578b\u66f4\u65b0\uff08\u5982\u635f\u5931\u548c\u504f\u5dee\uff09\u9009\u62e9\u5ba2\u6237\u7aef\uff0c\u4f46\u8fd9\u4e9b\u66f4\u65b0\u4e0d\u80fd\u51c6\u786e\u8868\u793a\u5ba2\u6237\u7aef\u7684\u5f02\u6784\u6027\uff0c\u4e14\u9009\u62e9\u65b9\u6cd5\u7f3a\u4e4f\u786e\u5b9a\u6027\u3002", "method": "Terraform\u91c7\u7528\u53cc\u7ba1\u9f50\u4e0b\u7684\u65b9\u6cd5\uff1a1\uff09\u4f7f\u7528\u68af\u5ea6\u66f4\u65b0\u800c\u975e\u4f20\u7edf\u635f\u5931\u548c\u504f\u5dee\u6765\u8868\u5f81\u5ba2\u6237\u7aef\u5f02\u6784\u6027\uff1b2\uff09\u91c7\u7528\u786e\u5b9a\u6027\u9009\u62e9\u7b97\u6cd5\u9009\u62e9\u5f02\u6784\u5ba2\u6237\u7aef\u8fdb\u884c\u91cd\u8bad\u7ec3\u3002", "result": "Terraform\u76f8\u6bd4\u5148\u524d\u5de5\u4f5c\u5b9e\u73b0\u4e86\u9ad8\u8fbe47%\u7684\u51c6\u786e\u7387\u63d0\u5347\u3002\u901a\u8fc7\u5168\u9762\u7684\u6d88\u878d\u7814\u7a76\u548c\u8bad\u7ec3\u65f6\u95f4\u5206\u6790\uff0c\u8bc1\u660e\u4e86\u5176\u6548\u7387\u548c\u9c81\u68d2\u6027\u3002", "conclusion": "Terraform\u901a\u8fc7\u68af\u5ea6\u66f4\u65b0\u548c\u786e\u5b9a\u6027\u9009\u62e9\u7b97\u6cd5\u7684\u7ed3\u5408\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u8054\u90a6\u5b66\u4e60\u4e2d\u7edf\u8ba1\u5f02\u6784\u6027\u5bfc\u81f4\u7684\u51c6\u786e\u7387\u4e0b\u964d\u95ee\u9898\uff0c\u4e3a\u8054\u90a6\u5b66\u4e60\u5ba2\u6237\u7aef\u9009\u62e9\u63d0\u4f9b\u4e86\u66f4\u9c81\u68d2\u7684\u65b9\u6cd5\u3002"}}
{"id": "2602.20561", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2602.20561", "abs": "https://arxiv.org/abs/2602.20561", "authors": ["Sana Taghipour Anvar", "David Kaeli"], "title": "A Granularity Characterization of Task Scheduling Effectiveness", "comment": null, "summary": "Task-based runtime systems provide flexible load balancing and portability for parallel scientific applications, but their strong scaling is highly sensitive to task granularity. As parallelism increases, scheduling overhead may transition from negligible to dominant, leading to rapid drops in performance for some algorithms, while remaining negligible for others. Although such effects are widely observed empirically, there is a general lack of understanding how algorithmic structure impacts whether dynamic scheduling is always beneficial. In this work, we introduce a granularity characterization framework that directly links scheduling overhead growth to task-graph dependency topology. We show that dependency structure, rather than problem size alone, governs how overhead scales with parallelism. Based on this observation, we characterize execution behavior using a simple granularity measure that indicates when scheduling overhead can be amortized by parallel computation and when scheduling overhead dominates performance. Through experimental evaluation on representative parallel workloads with diverse dependency patterns, we demonstrate that the proposed characterization explains both gradual and abrupt strong-scaling breakdowns observed in practice. We further show that overhead models derived from dependency topology accurately predict strong-scaling limits and enable a practical runtime decision rule for selecting dynamic or static execution without requiring exhaustive strong-scaling studies or extensive offline tuning.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u4efb\u52a1\u7c92\u5ea6\u5206\u6790\u6846\u67b6\uff0c\u901a\u8fc7\u4efb\u52a1\u56fe\u4f9d\u8d56\u62d3\u6251\u7ed3\u6784\u6765\u9884\u6d4b\u8c03\u5ea6\u5f00\u9500\u589e\u957f\uff0c\u4ece\u800c\u89e3\u91ca\u52a8\u6001\u8c03\u5ea6\u5728\u5f3a\u6269\u5c55\u4e2d\u7684\u6027\u80fd\u5d29\u6e83\u73b0\u8c61\u3002", "motivation": "\u57fa\u4e8e\u4efb\u52a1\u7684\u8fd0\u884c\u65f6\u7cfb\u7edf\u4e3a\u5e76\u884c\u79d1\u5b66\u5e94\u7528\u63d0\u4f9b\u4e86\u7075\u6d3b\u7684\u8d1f\u8f7d\u5e73\u8861\u548c\u53ef\u79fb\u690d\u6027\uff0c\u4f46\u5176\u5f3a\u6269\u5c55\u6027\u80fd\u5bf9\u4efb\u52a1\u7c92\u5ea6\u9ad8\u5ea6\u654f\u611f\u3002\u968f\u7740\u5e76\u884c\u5ea6\u589e\u52a0\uff0c\u8c03\u5ea6\u5f00\u9500\u53ef\u80fd\u4ece\u53ef\u5ffd\u7565\u53d8\u4e3a\u4e3b\u5bfc\uff0c\u5bfc\u81f4\u67d0\u4e9b\u7b97\u6cd5\u6027\u80fd\u6025\u5267\u4e0b\u964d\u3002\u867d\u7136\u8fd9\u79cd\u73b0\u8c61\u5728\u7ecf\u9a8c\u4e0a\u88ab\u5e7f\u6cdb\u89c2\u5bdf\u5230\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u7b97\u6cd5\u7ed3\u6784\u5982\u4f55\u5f71\u54cd\u52a8\u6001\u8c03\u5ea6\u6548\u76ca\u7684\u7cfb\u7edf\u7406\u89e3\u3002", "method": "\u5f15\u5165\u4e86\u4e00\u4e2a\u7c92\u5ea6\u8868\u5f81\u6846\u67b6\uff0c\u5c06\u8c03\u5ea6\u5f00\u9500\u589e\u957f\u76f4\u63a5\u4e0e\u4efb\u52a1\u56fe\u4f9d\u8d56\u62d3\u6251\u7ed3\u6784\u8054\u7cfb\u8d77\u6765\u3002\u57fa\u4e8e\u4f9d\u8d56\u7ed3\u6784\u800c\u975e\u95ee\u9898\u89c4\u6a21\u5355\u72ec\u51b3\u5b9a\u5f00\u9500\u968f\u5e76\u884c\u5ea6\u6269\u5c55\u7684\u89c2\u5bdf\uff0c\u4f7f\u7528\u7b80\u5355\u7684\u7c92\u5ea6\u5ea6\u91cf\u6765\u8868\u5f81\u6267\u884c\u884c\u4e3a\uff0c\u6307\u793a\u8c03\u5ea6\u5f00\u9500\u4f55\u65f6\u80fd\u88ab\u5e76\u884c\u8ba1\u7b97\u5206\u644a\uff0c\u4f55\u65f6\u4f1a\u4e3b\u5bfc\u6027\u80fd\u3002", "result": "\u901a\u8fc7\u5177\u6709\u4e0d\u540c\u4f9d\u8d56\u6a21\u5f0f\u7684\u4ee3\u8868\u6027\u5e76\u884c\u5de5\u4f5c\u8d1f\u8f7d\u7684\u5b9e\u9a8c\u8bc4\u4f30\uff0c\u8bc1\u660e\u6240\u63d0\u51fa\u7684\u8868\u5f81\u80fd\u591f\u89e3\u91ca\u5b9e\u8df5\u4e2d\u89c2\u5bdf\u5230\u7684\u6e10\u8fdb\u548c\u7a81\u53d8\u7684\u5f3a\u6269\u5c55\u5d29\u6e83\u3002\u8fdb\u4e00\u6b65\u8868\u660e\uff0c\u4ece\u4f9d\u8d56\u62d3\u6251\u5bfc\u51fa\u7684\u5f00\u9500\u6a21\u578b\u80fd\u591f\u51c6\u786e\u9884\u6d4b\u5f3a\u6269\u5c55\u6781\u9650\uff0c\u5e76\u5b9e\u73b0\u5b9e\u7528\u7684\u8fd0\u884c\u65f6\u51b3\u7b56\u89c4\u5219\uff0c\u7528\u4e8e\u9009\u62e9\u52a8\u6001\u6216\u9759\u6001\u6267\u884c\uff0c\u65e0\u9700\u8fdb\u884c\u8be6\u5c3d\u7684\u5f3a\u6269\u5c55\u7814\u7a76\u6216\u5927\u91cf\u79bb\u7ebf\u8c03\u4f18\u3002", "conclusion": "\u4efb\u52a1\u4f9d\u8d56\u62d3\u6251\u7ed3\u6784\u800c\u975e\u95ee\u9898\u89c4\u6a21\u5355\u72ec\u51b3\u5b9a\u4e86\u8c03\u5ea6\u5f00\u9500\u7684\u6269\u5c55\u884c\u4e3a\u3002\u63d0\u51fa\u7684\u6846\u67b6\u4e3a\u7406\u89e3\u52a8\u6001\u8c03\u5ea6\u5728\u5f3a\u6269\u5c55\u4e2d\u7684\u6027\u80fd\u9650\u5236\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\uff0c\u5e76\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u8fd0\u884c\u65f6\u51b3\u7b56\u673a\u5236\uff0c\u80fd\u591f\u6839\u636e\u4efb\u52a1\u56fe\u7ed3\u6784\u9884\u6d4b\u4f55\u65f6\u52a8\u6001\u8c03\u5ea6\u6709\u76ca\u3001\u4f55\u65f6\u9759\u6001\u8c03\u5ea6\u66f4\u4f18\u3002"}}
{"id": "2602.20748", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2602.20748", "abs": "https://arxiv.org/abs/2602.20748", "authors": ["Sungwoo Park", "Seohyeon Kim", "Min-Soo Kim"], "title": "cuRPQ: A High-Performance GPU-Based Framework for Processing Regular and Conjunctive Regular Path Queries", "comment": "Accepted at SIGMOD 2026. 16 pages, 18 figures", "summary": "Regular path queries (RPQs) are fundamental for path-constrained reachability analysis, and more complex variants such as conjunctive regular path queries (CRPQs) are increasingly used in graph analytics. Evaluating these queries is computationally expensive, but to the best of our knowledge, no prior work has explored GPU acceleration. In this paper, we propose cuRPQ, a high-performance GPU-optimized framework for processing RPQs and CRPQs. cuRPQ addresses the key GPU challenges through a novel traversal algorithm, an efficient visited-set management scheme, and a concurrent exploration-materialization strategy. Extensive experiments show that cuRPQ outperforms state-of-the-art methods by orders of magnitude, without out-of-memory errors.", "AI": {"tldr": "cuRPQ\uff1a\u9996\u4e2aGPU\u52a0\u901f\u7684\u6b63\u5219\u8def\u5f84\u67e5\u8be2\u5904\u7406\u6846\u67b6\uff0c\u6027\u80fd\u63d0\u5347\u6570\u4e2a\u6570\u91cf\u7ea7", "motivation": "\u6b63\u5219\u8def\u5f84\u67e5\u8be2\uff08RPQ\uff09\u53ca\u5176\u53d8\u4f53\uff08\u5982CRPQ\uff09\u5728\u56fe\u5206\u6790\u4e2d\u65e5\u76ca\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u8ba1\u7b97\u5f00\u9500\u5927\uff0c\u4e14\u6ca1\u6709GPU\u52a0\u901f\u65b9\u6848", "method": "\u63d0\u51facuRPQ\u6846\u67b6\uff0c\u5305\u542b\u65b0\u578b\u904d\u5386\u7b97\u6cd5\u3001\u9ad8\u6548\u8bbf\u95ee\u96c6\u7ba1\u7406\u65b9\u6848\u548c\u5e76\u53d1\u63a2\u7d22-\u7269\u5316\u7b56\u7565\uff0c\u4e13\u95e8\u9488\u5bf9GPU\u4f18\u5316", "result": "\u5b9e\u9a8c\u8868\u660ecuRPQ\u6027\u80fd\u6bd4\u73b0\u6709\u6700\u4f18\u65b9\u6cd5\u9ad8\u51fa\u6570\u4e2a\u6570\u91cf\u7ea7\uff0c\u4e14\u4e0d\u4f1a\u51fa\u73b0\u5185\u5b58\u6ea2\u51fa\u9519\u8bef", "conclusion": "cuRPQ\u662f\u9996\u4e2a\u6210\u529f\u5b9e\u73b0GPU\u52a0\u901f\u7684\u6b63\u5219\u8def\u5f84\u67e5\u8be2\u5904\u7406\u6846\u67b6\uff0c\u663e\u8457\u63d0\u5347\u4e86\u67e5\u8be2\u6027\u80fd"}}
{"id": "2602.20206", "categories": ["cs.SE", "cs.AI", "cs.CY", "cs.ET", "cs.MA"], "pdf": "https://arxiv.org/pdf/2602.20206", "abs": "https://arxiv.org/abs/2602.20206", "authors": ["Sreecharan Sankaranarayanan"], "title": "Mitigating \"Epistemic Debt\" in Generative AI-Scaffolded Novice Programming using Metacognitive Scripts", "comment": null, "summary": "The democratization of Large Language Models (LLMs) has given rise to ``Vibe Coding,\" a workflow where novice programmers prioritize semantic intent over syntactic implementation. While this lowers barriers to entry, we hypothesize that without pedagogical guardrails, it is fundamentally misaligned with cognitive skill acquisition. Drawing on the distinction between Cognitive Offloading and Cognitive Outsourcing, we argue that unrestricted AI encourages novices to outsource the Intrinsic Cognitive Load required for schema formation, rather than merely offloading Extraneous Load. This accumulation of ``Epistemic Debt\" creates ``Fragile Experts\" whose high functional utility masks critically low corrective competence.\n  To quantify and mitigate this debt, we conducted a between-subjects experiment (N=78) using a custom Cursor IDE plugin backed by Claude 3.5 Sonnet. Participants represented \"AI-Native\" learners across three conditions: Manual (Control), Unrestricted AI (Outsourcing), and Scaffolded AI (Offloading). The Scaffolded condition utilized a novel ``Explanation Gate,\" leveraging a real-time LLM-as-a-Judge framework to enforce a ``Teach-Back\" protocol before generated code could be integrated.\n  Results reveal a ``Collapse of Competence\": while Unrestricted AI users matched the productivity of the Scaffolded group (p < .001 vs. Manual), they suffered a 77% failure rate in a subsequent AI-Blackout maintenance task, compared to only 39% in the Scaffolded group. Qualitative analysis suggests that successful vibe coders naturally engage in self-scaffolding, treating the AI as a consultant rather than a contractor. We discuss the implications for the maintainability of AI-generated software and propose that future learning systems must enforce Metacognitive Friction to prevent the mass production of unmaintainable code.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86AI\u7f16\u7a0b\u5bf9\u65b0\u624b\u5b66\u4e60\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u65e0\u9650\u5236\u4f7f\u7528AI\u4f1a\u5bfc\u81f4\"\u80fd\u529b\u5d29\u6e83\" - \u867d\u7136\u8868\u9762\u751f\u4ea7\u529b\u9ad8\uff0c\u4f46\u5b9e\u9645\u7ef4\u62a4\u80fd\u529b\u6781\u5dee\uff0c\u800c\u901a\u8fc7\"\u89e3\u91ca\u95e8\"\u7684\u811a\u624b\u67b6\u5f0fAI\u8f85\u52a9\u80fd\u663e\u8457\u6539\u5584\u5b66\u4e60\u6548\u679c\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u7684\u666e\u53ca\uff0c\u51fa\u73b0\u4e86\"\u6c1b\u56f4\u7f16\u7a0b\"\u73b0\u8c61\uff0c\u65b0\u624b\u7a0b\u5e8f\u5458\u66f4\u5173\u6ce8\u8bed\u4e49\u610f\u56fe\u800c\u975e\u8bed\u6cd5\u5b9e\u73b0\u3002\u7814\u7a76\u8005\u62c5\u5fc3\u5982\u679c\u6ca1\u6709\u6559\u5b66\u62a4\u680f\uff0c\u8fd9\u79cd\u6a21\u5f0f\u4f1a\u4e0e\u8ba4\u77e5\u6280\u80fd\u83b7\u53d6\u6839\u672c\u6027\u9519\u914d\uff0c\u5bfc\u81f4\u65b0\u624b\u5916\u5305\u4e86\u5f62\u6210\u56fe\u5f0f\u6240\u9700\u7684\u5185\u5728\u8ba4\u77e5\u8d1f\u8377\uff0c\u800c\u975e\u4ec5\u4ec5\u5378\u8f7d\u5916\u5728\u8d1f\u8377\uff0c\u4ece\u800c\u79ef\u7d2f\"\u8ba4\u77e5\u503a\u52a1\"\uff0c\u4ea7\u751f\"\u8106\u5f31\u4e13\u5bb6\"\u3002", "method": "\u91c7\u7528\u88ab\u8bd5\u95f4\u5b9e\u9a8c\u8bbe\u8ba1(N=78)\uff0c\u4f7f\u7528\u57fa\u4e8eClaude 3.5 Sonnet\u7684Cursor IDE\u63d2\u4ef6\u3002\u53c2\u4e0e\u8005\u5206\u4e3a\u4e09\u7ec4\uff1a\u624b\u52a8\u63a7\u5236\u7ec4\u3001\u65e0\u9650\u5236AI\u7ec4\uff08\u5916\u5305\u6a21\u5f0f\uff09\u3001\u811a\u624b\u67b6AI\u7ec4\uff08\u5378\u8f7d\u6a21\u5f0f\uff09\u3002\u811a\u624b\u67b6\u7ec4\u91c7\u7528\u65b0\u9896\u7684\"\u89e3\u91ca\u95e8\"\u673a\u5236\uff0c\u5229\u7528\u5b9e\u65f6LLM-as-a-Judge\u6846\u67b6\uff0c\u5728\u751f\u6210\u4ee3\u7801\u96c6\u6210\u524d\u5f3a\u5236\u6267\u884c\"\u6559\u56de\"\u534f\u8bae\u3002", "result": "\u7ed3\u679c\u663e\u793a\"\u80fd\u529b\u5d29\u6e83\"\u73b0\u8c61\uff1a\u65e0\u9650\u5236AI\u7528\u6237\u7684\u751f\u4ea7\u529b\u4e0e\u811a\u624b\u67b6\u7ec4\u76f8\u5f53(p<.001 vs.\u624b\u52a8\u7ec4)\uff0c\u4f46\u5728\u540e\u7eedAI\u9ed1\u5c4f\u7ef4\u62a4\u4efb\u52a1\u4e2d\u5931\u8d25\u7387\u9ad8\u8fbe77%\uff0c\u800c\u811a\u624b\u67b6\u7ec4\u4ec5\u4e3a39%\u3002\u8d28\u6027\u5206\u6790\u8868\u660e\uff0c\u6210\u529f\u7684\u6c1b\u56f4\u7f16\u7801\u8005\u4f1a\u81ea\u7136\u8fdb\u884c\u81ea\u6211\u811a\u624b\u67b6\uff0c\u5c06AI\u89c6\u4e3a\u987e\u95ee\u800c\u975e\u627f\u5305\u5546\u3002", "conclusion": "\u7814\u7a76\u5f3a\u8c03\u672a\u6765\u5b66\u4e60\u7cfb\u7edf\u5fc5\u987b\u5f3a\u5236\u6267\u884c\u5143\u8ba4\u77e5\u6469\u64e6\uff0c\u4ee5\u9632\u6b62\u5927\u89c4\u6a21\u4ea7\u751f\u4e0d\u53ef\u7ef4\u62a4\u7684\u4ee3\u7801\u3002\u6210\u529f\u7684AI\u8f85\u52a9\u7f16\u7a0b\u9700\u8981\u5c06AI\u4f5c\u4e3a\u8ba4\u77e5\u5378\u8f7d\u5de5\u5177\u800c\u975e\u8ba4\u77e5\u5916\u5305\u5de5\u5177\uff0c\u901a\u8fc7\u6559\u5b66\u6027\u5e72\u9884\u786e\u4fdd\u5b66\u4e60\u8005\u771f\u6b63\u7406\u89e3\u4ee3\u7801\u903b\u8f91\u3002"}}
{"id": "2602.20656", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2602.20656", "abs": "https://arxiv.org/abs/2602.20656", "authors": ["Guanbin Xu", "ZhenGuo Xu", "Yuzhe Li", "Youhui Bai", "Ping Gong", "Chaoyi Ruan", "Cheng Li"], "title": "Lagom: Unleashing the Power of Communication and Computation Overlapping for Distributed LLM Training", "comment": "6 pages, 8 figures", "summary": "Overlapping communication with computation is crucial for distributed large-model training, yet optimizing it - especially when computation becomes the bottleneck-remains challenging. We present Lagom, a system that co-tunes communication parameters to balance resource usage between computation and communication. By introducing a unified cost model and a priority-based search algorithm, Lagom reduces optimization complexity from exponential to linear. Evaluations on high- and low-bandwidth GPU clusters show that Lagom achieves 1.07-1.33x and 1.03-1.27x speedup over NCCL and AutoCCL across diverse models and parallelizations.", "AI": {"tldr": "Lagom\u7cfb\u7edf\u901a\u8fc7\u534f\u540c\u8c03\u4f18\u901a\u4fe1\u53c2\u6570\u6765\u5e73\u8861\u8ba1\u7b97\u4e0e\u901a\u4fe1\u8d44\u6e90\u4f7f\u7528\uff0c\u5728\u8ba1\u7b97\u6210\u4e3a\u74f6\u9888\u65f6\u4f18\u5316\u5206\u5e03\u5f0f\u5927\u6a21\u578b\u8bad\u7ec3\u4e2d\u7684\u901a\u4fe1\u8ba1\u7b97\u91cd\u53e0\uff0c\u5c06\u4f18\u5316\u590d\u6742\u5ea6\u4ece\u6307\u6570\u7ea7\u964d\u81f3\u7ebf\u6027\u7ea7\u3002", "motivation": "\u5728\u5206\u5e03\u5f0f\u5927\u6a21\u578b\u8bad\u7ec3\u4e2d\uff0c\u91cd\u53e0\u901a\u4fe1\u4e0e\u8ba1\u7b97\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5f53\u8ba1\u7b97\u6210\u4e3a\u74f6\u9888\u65f6\uff0c\u4f18\u5316\u8fd9\u79cd\u91cd\u53e0\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\u3002\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u5728\u8ba1\u7b97\u53d7\u9650\u60c5\u51b5\u4e0b\u6709\u6548\u5e73\u8861\u8ba1\u7b97\u4e0e\u901a\u4fe1\u8d44\u6e90\u3002", "method": "\u63d0\u51faLagom\u7cfb\u7edf\uff0c\u901a\u8fc7\u534f\u540c\u8c03\u4f18\u901a\u4fe1\u53c2\u6570\u6765\u5e73\u8861\u8ba1\u7b97\u4e0e\u901a\u4fe1\u8d44\u6e90\u4f7f\u7528\u3002\u5f15\u5165\u7edf\u4e00\u6210\u672c\u6a21\u578b\u548c\u57fa\u4e8e\u4f18\u5148\u7ea7\u7684\u641c\u7d22\u7b97\u6cd5\uff0c\u5c06\u4f18\u5316\u590d\u6742\u5ea6\u4ece\u6307\u6570\u7ea7\u964d\u81f3\u7ebf\u6027\u7ea7\u3002", "result": "\u5728\u9ad8\u5e26\u5bbd\u548c\u4f4e\u5e26\u5bbdGPU\u96c6\u7fa4\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\uff0cLagom\u5728\u591a\u79cd\u6a21\u578b\u548c\u5e76\u884c\u5316\u7b56\u7565\u4e0b\uff0c\u76f8\u6bd4NCCL\u548cAutoCCL\u5206\u522b\u5b9e\u73b0\u4e861.07-1.33\u500d\u548c1.03-1.27\u500d\u7684\u52a0\u901f\u3002", "conclusion": "Lagom\u901a\u8fc7\u534f\u540c\u8c03\u4f18\u901a\u4fe1\u53c2\u6570\u6709\u6548\u89e3\u51b3\u4e86\u8ba1\u7b97\u6210\u4e3a\u74f6\u9888\u65f6\u7684\u901a\u4fe1\u8ba1\u7b97\u91cd\u53e0\u4f18\u5316\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5206\u5e03\u5f0f\u5927\u6a21\u578b\u8bad\u7ec3\u6548\u7387\u3002"}}
{"id": "2602.20952", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2602.20952", "abs": "https://arxiv.org/abs/2602.20952", "authors": ["Zhen Lv", "Cong Cao", "Hongwei Huo", "Jiangtao Cui", "Yanguo Peng", "Hui Li", "Yingfan Liu"], "title": "RISK: Efficiently processing rich spatial-keyword queries on encrypted geo-textual data", "comment": "15 pages, 10 figures, IEEE ICDE", "summary": "Symmetric searchable encryption (SSE) for geo-textual data has attracted significant attention. However, existing schemes rely on task-specific, incompatible indices for isolated specific secure queries (e.g., range or k-nearest neighbor spatial-keyword queries), limiting practicality due to prohibitive multi-index overhead. To address this, we propose RISK, a model for rich spatial-keyword queries on encrypted geo-textual data. In a textual-first-then-spatial manner, RISK is built on a novel k-nearest neighbor quadtree (kQ-tree) that embeds representative and regional nearest neighbors, with the kQ-tree further encrypted using standard cryptographic tools (e.g., keyed hash functions and symmetric encryption). Overall, RISK seamlessly supports both secure range and k-nearest neighbor queries, is provably secure under IND-CKA2 model, and extensible to multi-party scenarios and dynamic updates. Experiments on three real-world and one synthetic datasets show that RISK outperforms state-of-the-art methods by at least 0.5 and 4 orders of magnitude in response time for 1% range queries and 10-nearest neighbor queries, respectively.", "AI": {"tldr": "RISK\uff1a\u4e00\u79cd\u652f\u6301\u4e30\u5bcc\u7a7a\u95f4-\u6587\u672c\u67e5\u8be2\u7684\u52a0\u5bc6\u5730\u7406\u6587\u672c\u6570\u636e\u6a21\u578b\uff0c\u57fa\u4e8ek\u6700\u8fd1\u90bb\u56db\u53c9\u6811\u6784\u5efa\uff0c\u540c\u65f6\u652f\u6301\u5b89\u5168\u8303\u56f4\u67e5\u8be2\u548ck\u6700\u8fd1\u90bb\u67e5\u8be2\uff0c\u6027\u80fd\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u5bf9\u79f0\u53ef\u641c\u7d22\u52a0\u5bc6\u65b9\u6848\u9488\u5bf9\u5730\u7406\u6587\u672c\u6570\u636e\u4f7f\u7528\u4efb\u52a1\u7279\u5b9a\u3001\u4e0d\u517c\u5bb9\u7684\u7d22\u5f15\u6765\u5904\u7406\u5b64\u7acb\u7684\u5b89\u5168\u67e5\u8be2\uff08\u5982\u8303\u56f4\u67e5\u8be2\u6216k\u6700\u8fd1\u90bb\u67e5\u8be2\uff09\uff0c\u5bfc\u81f4\u591a\u7d22\u5f15\u5f00\u9500\u8fc7\u5927\uff0c\u9650\u5236\u4e86\u5b9e\u9645\u5e94\u7528\u3002", "method": "\u63d0\u51faRISK\u6a21\u578b\uff0c\u91c7\u7528\"\u5148\u6587\u672c\u540e\u7a7a\u95f4\"\u7684\u65b9\u5f0f\uff0c\u57fa\u4e8e\u65b0\u9896\u7684k\u6700\u8fd1\u90bb\u56db\u53c9\u6811\uff08kQ-tree\uff09\u6784\u5efa\uff0c\u8be5\u6811\u5d4c\u5165\u4e86\u4ee3\u8868\u6027\u548c\u533a\u57df\u6700\u8fd1\u90bb\u4fe1\u606f\uff0c\u5e76\u4f7f\u7528\u6807\u51c6\u5bc6\u7801\u5b66\u5de5\u5177\uff08\u5982\u5bc6\u94a5\u54c8\u5e0c\u51fd\u6570\u548c\u5bf9\u79f0\u52a0\u5bc6\uff09\u5bf9kQ-tree\u8fdb\u884c\u52a0\u5bc6\u3002", "result": "\u5728\u4e09\u4e2a\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u548c\u4e00\u4e2a\u5408\u6210\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cRISK\u57281%\u8303\u56f4\u67e5\u8be2\u548c10\u6700\u8fd1\u90bb\u67e5\u8be2\u7684\u54cd\u5e94\u65f6\u95f4\u4e0a\u5206\u522b\u6bd4\u73b0\u6709\u6700\u4f18\u65b9\u6cd5\u81f3\u5c11\u5feb0.5\u548c4\u4e2a\u6570\u91cf\u7ea7\uff0c\u540c\u65f6\u5728IND-CKA2\u6a21\u578b\u4e0b\u53ef\u8bc1\u660e\u5b89\u5168\uff0c\u5e76\u53ef\u6269\u5c55\u5230\u591a\u65b9\u573a\u666f\u548c\u52a8\u6001\u66f4\u65b0\u3002", "conclusion": "RISK\u6210\u529f\u89e3\u51b3\u4e86\u73b0\u6709\u5730\u7406\u6587\u672c\u6570\u636e\u5bf9\u79f0\u53ef\u641c\u7d22\u52a0\u5bc6\u65b9\u6848\u4e2d\u591a\u7d22\u5f15\u5f00\u9500\u8fc7\u5927\u7684\u95ee\u9898\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u7edf\u4e00\u3001\u9ad8\u6548\u4e14\u5b89\u5168\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u652f\u6301\u4e30\u5bcc\u7684\u7a7a\u95f4-\u6587\u672c\u67e5\u8be2\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2602.20213", "categories": ["cs.SE", "cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2602.20213", "abs": "https://arxiv.org/abs/2602.20213", "authors": ["Jingwei Shi", "Xinxiang Yin", "Jing Huang", "Jinman Zhao", "Shengyu Tao"], "title": "CodeHacker: Automated Test Case Generation for Detecting Vulnerabilities in Competitive Programming Solutions", "comment": null, "summary": "The evaluation of Large Language Models (LLMs) for code generation relies heavily on the quality and robustness of test cases. However, existing benchmarks often lack coverage for subtle corner cases, allowing incorrect solutions to pass. To bridge this gap, we propose CodeHacker, an automated agent framework dedicated to generating targeted adversarial test cases that expose latent vulnerabilities in program submissions. Mimicking the hack mechanism in competitive programming, CodeHacker employs a multi-strategy approach, including stress testing, anti-hash attacks, and logic-specific targeting to break specific code submissions. To ensure the validity and reliability of these attacks, we introduce a Calibration Phase, where the agent iteratively refines its own Validator and Checker via self-generated adversarial probes before evaluating contestant code.Experiments demonstrate that CodeHacker significantly improves the True Negative Rate (TNR) of existing datasets, effectively filtering out incorrect solutions that were previously accepted. Furthermore, generated adversarial cases prove to be superior training data, boosting the performance of RL-trained models on benchmarks like LiveCodeBench.", "AI": {"tldr": "CodeHacker\u662f\u4e00\u4e2a\u81ea\u52a8\u5316\u4ee3\u7406\u6846\u67b6\uff0c\u4e13\u95e8\u751f\u6210\u9488\u5bf9\u6027\u5bf9\u6297\u6d4b\u8bd5\u7528\u4f8b\u6765\u66b4\u9732\u7a0b\u5e8f\u63d0\u4ea4\u4e2d\u7684\u6f5c\u5728\u6f0f\u6d1e\uff0c\u901a\u8fc7\u591a\u7b56\u7565\u653b\u51fb\u548c\u6821\u51c6\u9636\u6bb5\u63d0\u9ad8\u4ee3\u7801\u751f\u6210\u8bc4\u4f30\u7684\u53ef\u9760\u6027\u3002", "motivation": "\u73b0\u6709\u4ee3\u7801\u751f\u6210\u57fa\u51c6\u6d4b\u8bd5\u7f3a\u4e4f\u5bf9\u7ec6\u5fae\u8fb9\u754c\u60c5\u51b5\u7684\u8986\u76d6\uff0c\u5bfc\u81f4\u9519\u8bef\u89e3\u51b3\u65b9\u6848\u4e5f\u80fd\u901a\u8fc7\u6d4b\u8bd5\u3002\u9700\u8981\u66f4\u5f3a\u5927\u7684\u6d4b\u8bd5\u7528\u4f8b\u6765\u66b4\u9732LLM\u4ee3\u7801\u751f\u6210\u4e2d\u7684\u6f5c\u5728\u6f0f\u6d1e\u3002", "method": "\u91c7\u7528\u591a\u7b56\u7565\u65b9\u6cd5\uff08\u538b\u529b\u6d4b\u8bd5\u3001\u53cd\u54c8\u5e0c\u653b\u51fb\u3001\u903b\u8f91\u7279\u5b9a\u76ee\u6807\u653b\u51fb\uff09\uff0c\u6a21\u62df\u7ade\u8d5b\u7f16\u7a0b\u4e2d\u7684\u9ed1\u5ba2\u673a\u5236\u3002\u5f15\u5165\u6821\u51c6\u9636\u6bb5\uff0c\u901a\u8fc7\u81ea\u751f\u6210\u7684\u5bf9\u6297\u63a2\u9488\u8fed\u4ee3\u4f18\u5316\u9a8c\u8bc1\u5668\u548c\u68c0\u67e5\u5668\u3002", "result": "CodeHacker\u663e\u8457\u63d0\u9ad8\u4e86\u73b0\u6709\u6570\u636e\u96c6\u7684\u771f\u8d1f\u7387\uff0c\u6709\u6548\u8fc7\u6ee4\u6389\u4e4b\u524d\u88ab\u63a5\u53d7\u7684\u9519\u8bef\u89e3\u51b3\u65b9\u6848\u3002\u751f\u6210\u7684\u5bf9\u6297\u6848\u4f8b\u4f5c\u4e3a\u8bad\u7ec3\u6570\u636e\u80fd\u63d0\u5347RL\u8bad\u7ec3\u6a21\u578b\u5728LiveCodeBench\u7b49\u57fa\u51c6\u4e0a\u7684\u6027\u80fd\u3002", "conclusion": "CodeHacker\u6846\u67b6\u901a\u8fc7\u81ea\u52a8\u5316\u751f\u6210\u9488\u5bf9\u6027\u5bf9\u6297\u6d4b\u8bd5\u7528\u4f8b\uff0c\u63d0\u9ad8\u4e86\u4ee3\u7801\u751f\u6210\u8bc4\u4f30\u7684\u9c81\u68d2\u6027\uff0c\u540c\u65f6\u751f\u6210\u7684\u5bf9\u6297\u6570\u636e\u8fd8\u80fd\u7528\u4e8e\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002"}}
{"id": "2602.20887", "categories": ["cs.DC", "cs.CG"], "pdf": "https://arxiv.org/pdf/2602.20887", "abs": "https://arxiv.org/abs/2602.20887", "authors": ["David Knapp", "Johannes Albrecht Holke", "Thomas Spenke", "Carsten Burstedde"], "title": "A Morton-Type Space-Filling Curve for Pyramid Subdivision and Hybrid Adaptive Mesh Refinement", "comment": null, "summary": "The forest-of-refinement-trees approach allows for dynamic adaptive mesh refinement (AMR) at negligible cost. While originally developed for quadrilateral and hexahedral elements, previous work established the theory and algorithms for unstructured meshes of simplicial and prismatic elements. To harness the full potential of tree-based AMR for three-dimensional mixed-element meshes, this paper introduces the pyramid as a new functional element type; its primary purpose is to connect tetrahedral and hexahedral elements without hanging edges.We present a well-defined space-filling curve (SFC) for the pyramid and detail how the unique challenges on the element and forest level associated with the pyramidal refinement are resolved. We propose the necessary functional design and generalize the fundamental global parallel algorithms for refinement, coarsening, partitioning, and face ghost exchange to fully support this new element. Our demonstrations confirm the efficiency and scalability of this complete, hybrid-element dynamic AMR framework.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5c06\u91d1\u5b57\u5854\u5143\u7d20\u4f5c\u4e3a\u65b0\u7684\u529f\u80fd\u5143\u7d20\u7c7b\u578b\uff0c\u7528\u4e8e\u8fde\u63a5\u4e09\u7ef4\u6df7\u5408\u5143\u7d20\u7f51\u683c\u4e2d\u7684\u56db\u9762\u4f53\u548c\u516d\u9762\u4f53\u5143\u7d20\uff0c\u5b9e\u73b0\u4e86\u5b8c\u6574\u7684\u6df7\u5408\u5143\u7d20\u52a8\u6001\u81ea\u9002\u5e94\u7f51\u683c\u7ec6\u5316\u6846\u67b6\u3002", "motivation": "\u4e3a\u4e86\u5145\u5206\u53d1\u6325\u57fa\u4e8e\u6811\u7684\u81ea\u9002\u5e94\u7f51\u683c\u7ec6\u5316\u5728\u4e09\u7ef4\u6df7\u5408\u5143\u7d20\u7f51\u683c\u4e2d\u7684\u6f5c\u529b\uff0c\u9700\u8981\u89e3\u51b3\u56db\u9762\u4f53\u548c\u516d\u9762\u4f53\u5143\u7d20\u4e4b\u95f4\u7684\u8fde\u63a5\u95ee\u9898\uff0c\u907f\u514d\u60ac\u6302\u8fb9\u3002", "method": "\u5f15\u5165\u91d1\u5b57\u5854\u5143\u7d20\u4f5c\u4e3a\u65b0\u7684\u529f\u80fd\u5143\u7d20\u7c7b\u578b\uff1b\u63d0\u51fa\u5b9a\u4e49\u826f\u597d\u7684\u7a7a\u95f4\u586b\u5145\u66f2\u7ebf\uff1b\u89e3\u51b3\u5143\u7d20\u548c\u68ee\u6797\u7ea7\u522b\u7684\u91d1\u5b57\u5854\u7ec6\u5316\u6311\u6218\uff1b\u8bbe\u8ba1\u5fc5\u8981\u7684\u529f\u80fd\u5e76\u6cdb\u5316\u5168\u5c40\u5e76\u884c\u7b97\u6cd5\u3002", "result": "\u6f14\u793a\u8bc1\u5b9e\u4e86\u8fd9\u79cd\u5b8c\u6574\u7684\u6df7\u5408\u5143\u7d20\u52a8\u6001\u81ea\u9002\u5e94\u7f51\u683c\u7ec6\u5316\u6846\u67b6\u7684\u6548\u7387\u548c\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "\u91d1\u5b57\u5854\u5143\u7d20\u7684\u5f15\u5165\u4f7f\u5f97\u4e09\u7ef4\u6df7\u5408\u5143\u7d20\u7f51\u683c\u80fd\u591f\u5b9e\u73b0\u9ad8\u6548\u7684\u52a8\u6001\u81ea\u9002\u5e94\u7f51\u683c\u7ec6\u5316\uff0c\u4e3a\u590d\u6742\u51e0\u4f55\u7684\u6a21\u62df\u63d0\u4f9b\u4e86\u66f4\u7075\u6d3b\u7684\u7f51\u683c\u5904\u7406\u80fd\u529b\u3002"}}
{"id": "2602.20284", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.20284", "abs": "https://arxiv.org/abs/2602.20284", "authors": ["Han Fu", "Andreas Ermedahl", "Sigrid Eldh", "Kristian Wiklund", "Philipp Haller", "Cyrille Artho"], "title": "PhantomRun: Auto Repair of Compilation Errors in Embedded Open Source Software", "comment": "13 pages, 5 figures, Mining Software Repositories 2026 (MSR 2026) , Rio de Janeiro, Brazil, 13-14 April 2026", "summary": "Continuous Integration (CI) pipelines for embedded software sometimes fail during compilation, consuming significant developer time for debugging. We study four major open-source embedded system projects, spanning over 4000 build failures from the project's CI runs. We find that hardware dependencies account for the majority of compilation failures, followed by syntax errors and build-script issues. Most repairs need relatively small changes, making automated repair potentially suitable as long as the diverse setups and lack of test data can be handled.\n  In this paper, we present PhantomRun, an automated framework that leverages large language models (LLMs) to generate and validate fixes for CI compilation failures. The framework addresses the challenge of diverse build infrastructures and tool chains across embedded system projects by providing an adaptation layer for GitHub Actions and GitLab CI and four different build systems. PhantomRun utilizes build logs, source code, historical fixes, and compiler error messages to synthesize fixes using LLMs. Our evaluations show that PhantomRun successfully repairs up to 45% of CI compilation failures across the targeted projects, demonstrating the viability of LLM-based repairs for embedded-system CI pipelines.", "AI": {"tldr": "PhantomRun\u662f\u4e00\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u81ea\u52a8\u5316\u6846\u67b6\uff0c\u7528\u4e8e\u4fee\u590d\u5d4c\u5165\u5f0f\u7cfb\u7edfCI\u7f16\u8bd1\u5931\u8d25\u95ee\u9898\uff0c\u6210\u529f\u4fee\u590d\u7387\u53ef\u8fbe45%\u3002", "motivation": "\u5d4c\u5165\u5f0f\u8f6f\u4ef6\u7684\u6301\u7eed\u96c6\u6210\uff08CI\uff09\u7ba1\u9053\u5728\u7f16\u8bd1\u65f6\u7ecf\u5e38\u5931\u8d25\uff0c\u6d88\u8017\u5927\u91cf\u5f00\u53d1\u4eba\u5458\u8c03\u8bd5\u65f6\u95f4\u3002\u7814\u7a76\u53d1\u73b0\u786c\u4ef6\u4f9d\u8d56\u662f\u7f16\u8bd1\u5931\u8d25\u7684\u4e3b\u8981\u539f\u56e0\uff0c\u5176\u6b21\u662f\u8bed\u6cd5\u9519\u8bef\u548c\u6784\u5efa\u811a\u672c\u95ee\u9898\u3002", "method": "PhantomRun\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u751f\u6210\u548c\u9a8c\u8bc1CI\u7f16\u8bd1\u5931\u8d25\u7684\u4fee\u590d\u65b9\u6848\u3002\u6846\u67b6\u901a\u8fc7\u4e3aGitHub Actions\u548cGitLab CI\u4ee5\u53ca\u56db\u79cd\u4e0d\u540c\u6784\u5efa\u7cfb\u7edf\u63d0\u4f9b\u9002\u914d\u5c42\uff0c\u89e3\u51b3\u5d4c\u5165\u5f0f\u7cfb\u7edf\u9879\u76ee\u4e2d\u591a\u6837\u5316\u7684\u6784\u5efa\u57fa\u7840\u8bbe\u65bd\u548c\u5de5\u5177\u94fe\u6311\u6218\u3002\u5229\u7528\u6784\u5efa\u65e5\u5fd7\u3001\u6e90\u4ee3\u7801\u3001\u5386\u53f2\u4fee\u590d\u8bb0\u5f55\u548c\u7f16\u8bd1\u5668\u9519\u8bef\u6d88\u606f\u6765\u5408\u6210\u4fee\u590d\u65b9\u6848\u3002", "result": "\u8bc4\u4f30\u663e\u793aPhantomRun\u5728\u76ee\u6807\u9879\u76ee\u4e2d\u6210\u529f\u4fee\u590d\u4e86\u9ad8\u8fbe45%\u7684CI\u7f16\u8bd1\u5931\u8d25\uff0c\u8bc1\u660e\u4e86\u57fa\u4e8eLLM\u7684\u4fee\u590d\u5728\u5d4c\u5165\u5f0f\u7cfb\u7edfCI\u7ba1\u9053\u4e2d\u7684\u53ef\u884c\u6027\u3002", "conclusion": "\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u81ea\u52a8\u5316\u4fee\u590d\u6846\u67b6\u80fd\u591f\u6709\u6548\u5904\u7406\u5d4c\u5165\u5f0f\u7cfb\u7edfCI\u7f16\u8bd1\u5931\u8d25\u95ee\u9898\uff0c\u5927\u591a\u6570\u4fee\u590d\u53ea\u9700\u8981\u76f8\u5bf9\u8f83\u5c0f\u7684\u6539\u52a8\uff0c\u81ea\u52a8\u5316\u4fee\u590d\u5177\u6709\u6f5c\u529b\uff0c\u524d\u63d0\u662f\u80fd\u591f\u5904\u7406\u591a\u6837\u5316\u7684\u8bbe\u7f6e\u548c\u7f3a\u4e4f\u6d4b\u8bd5\u6570\u636e\u7684\u95ee\u9898\u3002"}}
{"id": "2602.21022", "categories": ["cs.DC", "cs.CC"], "pdf": "https://arxiv.org/pdf/2602.21022", "abs": "https://arxiv.org/abs/2602.21022", "authors": ["Antonio Cruciani", "Avinandan Das", "Massimo Equi", "Henrik Lievonen", "Diep Luong-Le", "Augusto Modanese", "Jukka Suomela"], "title": "Is a LOCAL algorithm computable?", "comment": "33 pages, 1 figure", "summary": "Common definitions of the \"standard\" LOCAL model tend to be sloppy and even self-contradictory on one point: do the nodes update their state using an arbitrary function or a computable function? So far, this distinction has been safe to neglect, since problems where it matters seem contrived and quite different from e.g. typical local graph problems studied in this context.\n  We show that this question matters even for locally checkable labeling problems (LCLs), perhaps the most widely studied family of problems in the context of the LOCAL model. Furthermore, we show that assumptions about computability are directly connected to another aspect already recognized as highly relevant: whether we have any knowledge of $n$, the size of the graph. Concretely, we show that there is an LCL problem $\u03a0$ with the following properties:\n  1. $\u03a0$ can be solved in $O(\\log n)$ rounds if the \\textsf{LOCAL} model is uncomputable.\n  2. $\u03a0$ can be solved in $O(\\log n)$ rounds in the computable model if we know any upper bound on $n$.\n  3. $\u03a0$ requires $\u03a9(\\sqrt{n})$ rounds in the computable model if we do not know anything about $n$.\n  We also show that the connection between computability and knowledge of $n$ holds in general: for any LCL problem $\u03a0$, if you have any bound on $n$, then $\u03a0$ has the same round complexity in the computable and uncomputable models.", "AI": {"tldr": "\u672c\u6587\u63ed\u793aLOCAL\u6a21\u578b\u4e2d\u8282\u70b9\u72b6\u6001\u66f4\u65b0\u51fd\u6570\u662f\u5426\u53ef\u8ba1\u7b97\u8fd9\u4e00\u88ab\u5ffd\u89c6\u7684\u533a\u522b\uff0c\u5bf9\u5c40\u90e8\u53ef\u68c0\u67e5\u6807\u8bb0\u95ee\u9898\uff08LCL\uff09\u6709\u91cd\u8981\u5f71\u54cd\uff0c\u5e76\u4e0e\u5bf9\u56fe\u89c4\u6a21n\u7684\u8ba4\u77e5\u76f4\u63a5\u76f8\u5173\u3002", "motivation": "LOCAL\u6a21\u578b\u4e2d\u5173\u4e8e\u8282\u70b9\u72b6\u6001\u66f4\u65b0\u51fd\u6570\u662f\u5426\u53ef\u8ba1\u7b97\u7684\u73b0\u6709\u5b9a\u4e49\u6a21\u7cca\u4e14\u81ea\u76f8\u77db\u76fe\uff0c\u8fd9\u4e00\u533a\u522b\u901a\u5e38\u88ab\u5ffd\u7565\u3002\u672c\u6587\u65e8\u5728\u8bc1\u660e\u8fd9\u4e00\u533a\u522b\u5bf9LCL\u95ee\u9898\u6709\u5b9e\u9645\u5f71\u54cd\uff0c\u5e76\u4e0e\u5bf9\u56fe\u89c4\u6a21n\u7684\u8ba4\u77e5\u5bc6\u5207\u76f8\u5173\u3002", "method": "\u901a\u8fc7\u6784\u9020\u4e00\u4e2a\u5177\u4f53\u7684LCL\u95ee\u9898\u03a0\uff0c\u5c55\u793a\u5176\u5728\u4e09\u79cd\u4e0d\u540c\u6761\u4ef6\u4e0b\u7684\u590d\u6742\u5ea6\u5dee\u5f02\uff1a1) \u4e0d\u53ef\u8ba1\u7b97\u6a21\u578b\uff1b2) \u5df2\u77e5n\u4e0a\u754c\u7684\u53ef\u8ba1\u7b97\u6a21\u578b\uff1b3) \u672a\u77e5n\u7684\u53ef\u8ba1\u7b97\u6a21\u578b\u3002\u5e76\u8bc1\u660e\u8fd9\u4e00\u8054\u7cfb\u5bf9\u4e00\u822cLCL\u95ee\u9898\u6210\u7acb\u3002", "result": "\u5b58\u5728LCL\u95ee\u9898\u03a0\uff1a\u5728\u4e0d\u53ef\u8ba1\u7b97\u6a21\u578b\u4e2dO(log n)\u8f6e\u53ef\u89e3\uff1b\u5df2\u77e5n\u4e0a\u754c\u7684\u53ef\u8ba1\u7b97\u6a21\u578b\u4e2dO(log n)\u8f6e\u53ef\u89e3\uff1b\u672a\u77e5n\u7684\u53ef\u8ba1\u7b97\u6a21\u578b\u4e2d\u9700\u8981\u03a9(\u221an)\u8f6e\u3002\u4e14\u5bf9\u4efb\u610fLCL\u95ee\u9898\uff0c\u82e5\u6709n\u7684\u4e0a\u754c\uff0c\u5219\u5176\u5728\u53ef\u8ba1\u7b97\u548c\u4e0d\u53ef\u8ba1\u7b97\u6a21\u578b\u4e2d\u7684\u8f6e\u590d\u6742\u5ea6\u76f8\u540c\u3002", "conclusion": "LOCAL\u6a21\u578b\u4e2d\u8282\u70b9\u72b6\u6001\u66f4\u65b0\u51fd\u6570\u7684\u53ef\u8ba1\u7b97\u6027\u5047\u8bbe\u5bf9LCL\u95ee\u9898\u590d\u6742\u5ea6\u6709\u5b9e\u8d28\u6027\u5f71\u54cd\uff0c\u4e14\u4e0e\u5bf9\u56fe\u89c4\u6a21n\u7684\u8ba4\u77e5\u76f4\u63a5\u76f8\u5173\u3002\u8fd9\u4e00\u53d1\u73b0\u6311\u6218\u4e86\u8be5\u533a\u522b\u53ef\u5b89\u5168\u5ffd\u7565\u7684\u4f20\u7edf\u89c2\u70b9\u3002"}}
{"id": "2602.20292", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.20292", "abs": "https://arxiv.org/abs/2602.20292", "authors": ["Sebastian Lobentanzer"], "title": "Quantifying the Expectation-Realisation Gap for Agentic AI Systems", "comment": "9 pages, no figures", "summary": "Agentic AI systems are deployed with expectations of substantial productivity gains, yet rigorous empirical evidence reveals systematic discrepancies between pre-deployment expectations and post-deployment outcomes. We review controlled trials and independent validations across software engineering, clinical documentation, and clinical decision support to quantify this expectation-realisation gap. In software development, experienced developers expected a 24% speedup from AI tools but were slowed by 19% -- a 43 percentage-point calibration error. In clinical documentation, vendor claims of multi-minute time savings contrast with measured reductions of less than one minute per note, and one widely deployed tool showed no statistically significant effect. In clinical decision support, externally validated performance falls substantially below developer-reported metrics. These shortfalls are driven by workflow integration friction, verification burden, measurement construct mismatches, and systematic heterogeneity in treatment effects. The evidence motivates structured planning frameworks that require explicit, quantified benefit expectations with human oversight costs factored in.", "AI": {"tldr": "AI\u5de5\u5177\u7684\u5b9e\u9645\u751f\u4ea7\u529b\u63d0\u5347\u8fdc\u4f4e\u4e8e\u9884\u671f\uff0c\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u5f00\u53d1\u8005\u9884\u671f24%\u52a0\u901f\u4f46\u5b9e\u9645\u88ab\u62d6\u616219%\uff0c\u4e34\u5e8a\u6587\u6863\u5de5\u5177\u58f0\u79f0\u8282\u7701\u6570\u5206\u949f\u4f46\u5b9e\u9645\u4e0d\u52301\u5206\u949f\uff0c\u4e34\u5e8a\u51b3\u7b56\u652f\u6301\u5de5\u5177\u5916\u90e8\u9a8c\u8bc1\u6027\u80fd\u8fdc\u4f4e\u4e8e\u5f00\u53d1\u8005\u62a5\u544a\u6307\u6807", "motivation": "\u63ed\u793aAI\u7cfb\u7edf\u90e8\u7f72\u4e2d\u671f\u671b\u4e0e\u73b0\u5b9e\u4e4b\u95f4\u7684\u7cfb\u7edf\u6027\u5dee\u8ddd\uff0c\u91cf\u5316\u8fd9\u79cd\u671f\u671b-\u5b9e\u73b0\u5dee\u8ddd\uff0c\u4e3a\u66f4\u73b0\u5b9e\u7684AI\u5de5\u5177\u8bc4\u4f30\u548c\u90e8\u7f72\u63d0\u4f9b\u4f9d\u636e", "method": "\u56de\u987e\u8f6f\u4ef6\u5de5\u7a0b\u3001\u4e34\u5e8a\u6587\u6863\u548c\u4e34\u5e8a\u51b3\u7b56\u652f\u6301\u9886\u57df\u7684\u5bf9\u7167\u8bd5\u9a8c\u548c\u72ec\u7acb\u9a8c\u8bc1\u7814\u7a76\uff0c\u91cf\u5316\u671f\u671b\u4e0e\u5b9e\u73b0\u4e4b\u95f4\u7684\u5dee\u8ddd", "result": "\u8f6f\u4ef6\u5de5\u7a0b\uff1a\u5f00\u53d1\u8005\u9884\u671f24%\u52a0\u901f\u4f46\u5b9e\u9645\u88ab\u62d6\u616219%\uff0843\u4e2a\u767e\u5206\u70b9\u6821\u51c6\u8bef\u5dee\uff09\uff1b\u4e34\u5e8a\u6587\u6863\uff1a\u5382\u5546\u58f0\u79f0\u8282\u7701\u6570\u5206\u949f\u4f46\u5b9e\u9645\u4e0d\u52301\u5206\u949f\uff0c\u4e00\u4e2a\u5e7f\u6cdb\u90e8\u7f72\u5de5\u5177\u65e0\u7edf\u8ba1\u663e\u8457\u6548\u679c\uff1b\u4e34\u5e8a\u51b3\u7b56\u652f\u6301\uff1a\u5916\u90e8\u9a8c\u8bc1\u6027\u80fd\u663e\u8457\u4f4e\u4e8e\u5f00\u53d1\u8005\u62a5\u544a\u6307\u6807", "conclusion": "\u671f\u671b-\u5b9e\u73b0\u5dee\u8ddd\u7531\u5de5\u4f5c\u6d41\u96c6\u6210\u6469\u64e6\u3001\u9a8c\u8bc1\u8d1f\u62c5\u3001\u6d4b\u91cf\u6784\u9020\u4e0d\u5339\u914d\u548c\u7cfb\u7edf\u5f02\u8d28\u6027\u9a71\u52a8\uff0c\u9700\u8981\u7ed3\u6784\u5316\u89c4\u5212\u6846\u67b6\uff0c\u8981\u6c42\u660e\u786e\u7684\u91cf\u5316\u6548\u76ca\u9884\u671f\u5e76\u8003\u8651\u4eba\u7c7b\u76d1\u7763\u6210\u672c"}}
{"id": "2602.21140", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2602.21140", "abs": "https://arxiv.org/abs/2602.21140", "authors": ["Haley Li", "Xinglu Wang", "Cong Feng", "Chunxu Zuo", "Yanan Wang", "Hei Lo", "Yufei Cui", "Bingji Wang", "Duo Cui", "Shuming Jing", "Yizhou Shan", "Ying Xiong", "Jiannan Wang", "Yong Zhang", "Zhenan Fan"], "title": "ReviveMoE: Fast Recovery for Hardware Failures in Large-Scale MoE LLM Inference Deployments", "comment": "21 pages, 6 figures", "summary": "As LLM deployments scale over more hardware, the probability of a single failure in a system increases significantly, and cloud operators must consider robust countermeasures to handle these inevitable failures. A common recovery approach is to simply restart the LLM serving instance; however, this is costly in model-as-a-service (MaaS) inference settings, where reloading model weights and recompiling computation graphs can introduce significant delays to incoming requests. We propose ReviveMoE, a method for rapid failure recovery in large-scale LLM deployments without restarting the serving instance. ReviveMoE is designed to support both the traditional LLM architecture, which collocates MoE and attention on the same hardware, and the disaggregated architectures, which separate MoE from attention. Integrated into Huawei Cloud's MaaS, ReviveMoE is built on top of Huawei's xDeepServe serving platform and the XCCL communications library.", "AI": {"tldr": "ReviveMoE\uff1a\u4e00\u79cd\u65e0\u9700\u91cd\u542f\u670d\u52a1\u5b9e\u4f8b\u5373\u53ef\u5b9e\u73b0\u5927\u89c4\u6a21LLM\u90e8\u7f72\u5feb\u901f\u6545\u969c\u6062\u590d\u7684\u65b9\u6cd5", "motivation": "\u968f\u7740LLM\u90e8\u7f72\u6269\u5c55\u5230\u66f4\u591a\u786c\u4ef6\uff0c\u7cfb\u7edf\u5355\u70b9\u6545\u969c\u6982\u7387\u663e\u8457\u589e\u52a0\uff0c\u4e91\u8fd0\u8425\u5546\u9700\u8981\u5904\u7406\u8fd9\u4e9b\u4e0d\u53ef\u907f\u514d\u7684\u6545\u969c\u3002\u4f20\u7edf\u7684\u91cd\u542fLLM\u670d\u52a1\u5b9e\u4f8b\u65b9\u6cd5\u5728\u6a21\u578b\u5373\u670d\u52a1\u63a8\u7406\u573a\u666f\u4e2d\u6210\u672c\u9ad8\u6602\uff0c\u56e0\u4e3a\u91cd\u65b0\u52a0\u8f7d\u6a21\u578b\u6743\u91cd\u548c\u91cd\u65b0\u7f16\u8bd1\u8ba1\u7b97\u56fe\u4f1a\u7ed9\u4f20\u5165\u8bf7\u6c42\u5e26\u6765\u663e\u8457\u5ef6\u8fdf\u3002", "method": "ReviveMoE\u65b9\u6cd5\u652f\u6301\u4f20\u7edfLLM\u67b6\u6784\uff08MoE\u548c\u6ce8\u610f\u529b\u673a\u5236\u5728\u540c\u4e00\u786c\u4ef6\u4e0a\uff09\u548c\u5206\u79bb\u5f0f\u67b6\u6784\uff08MoE\u4e0e\u6ce8\u610f\u529b\u673a\u5236\u5206\u79bb\uff09\u3002\u8be5\u65b9\u6cd5\u57fa\u4e8e\u534e\u4e3a\u7684xDeepServe\u670d\u52a1\u5e73\u53f0\u548cXCCL\u901a\u4fe1\u5e93\u6784\u5efa\uff0c\u5e76\u96c6\u6210\u5230\u534e\u4e3a\u4e91MaaS\u4e2d\u3002", "result": "ReviveMoE\u5b9e\u73b0\u4e86\u5927\u89c4\u6a21LLM\u90e8\u7f72\u7684\u5feb\u901f\u6545\u969c\u6062\u590d\uff0c\u907f\u514d\u4e86\u670d\u52a1\u5b9e\u4f8b\u91cd\u542f\u5e26\u6765\u7684\u5ef6\u8fdf\u95ee\u9898\u3002", "conclusion": "ReviveMoE\u4e3a\u4e91\u8fd0\u8425\u5546\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u6545\u969c\u6062\u590d\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u5728\u4e0d\u4e2d\u65ad\u670d\u52a1\u7684\u60c5\u51b5\u4e0b\u5904\u7406LLM\u90e8\u7f72\u4e2d\u7684\u786c\u4ef6\u6545\u969c\uff0c\u63d0\u9ad8\u4e86\u7cfb\u7edf\u7684\u53ef\u9760\u6027\u548c\u53ef\u7528\u6027\u3002"}}
{"id": "2602.20334", "categories": ["cs.SE", "cs.RO"], "pdf": "https://arxiv.org/pdf/2602.20334", "abs": "https://arxiv.org/abs/2602.20334", "authors": ["Chengjie Lu", "Jiahui Wu", "Shaukat Ali", "Malaika Din Hashmi", "Sebastian Mathias Thomle Mason", "Francois Picard", "Mikkel Labori Olsen", "Thomas Peyrucain"], "title": "UAMTERS: Uncertainty-Aware Mutation Analysis for DL-enabled Robotic Software", "comment": "23 pages, 6 figures, 7 tables", "summary": "Self-adaptive robots adjust their behaviors in response to unpredictable environmental changes. These robots often incorporate deep learning (DL) components into their software to support functionality such as perception, decision-making, and control, enhancing autonomy and self-adaptability. However, the inherent uncertainty of DL-enabled software makes it challenging to ensure its dependability in dynamic environments. Consequently, test generation techniques have been developed to test robot software, and classical mutation analysis injects faults into the software to assess the test suite's effectiveness in detecting the resulting failures. However, there is a lack of mutation analysis techniques to assess the effectiveness under the uncertainty inherent to DL-enabled software. To this end, we propose UAMTERS, an uncertainty-aware mutation analysis framework that introduces uncertainty-aware mutation operators to explicitly inject stochastic uncertainty into DL-enabled robotic software, simulating uncertainty in its behavior. We further propose mutation score metrics to quantify a test suite's ability to detect failures under varying levels of uncertainty. We evaluate UAMTERS across three robotic case studies, demonstrating that UAMTERS more effectively distinguishes test suite quality and captures uncertainty-induced failures in DL-enabled software.", "AI": {"tldr": "\u63d0\u51faUAMTERS\u6846\u67b6\uff0c\u9488\u5bf9DL\u8d4b\u80fd\u673a\u5668\u4eba\u8f6f\u4ef6\u7684\u4e0d\u786e\u5b9a\u6027\u8fdb\u884c\u53d8\u5f02\u5206\u6790\uff0c\u901a\u8fc7\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u7684\u53d8\u5f02\u7b97\u5b50\u548c\u8bc4\u5206\u6307\u6807\u8bc4\u4f30\u6d4b\u8bd5\u5957\u4ef6\u5728\u4e0d\u786e\u5b9a\u6027\u73af\u5883\u4e0b\u7684\u6709\u6548\u6027\u3002", "motivation": "\u81ea\u9002\u5e94\u673a\u5668\u4eba\u5e38\u96c6\u6210\u6df1\u5ea6\u5b66\u4e60\u7ec4\u4ef6\u4ee5\u589e\u5f3a\u81ea\u4e3b\u6027\uff0c\u4f46DL\u8f6f\u4ef6\u56fa\u6709\u7684\u4e0d\u786e\u5b9a\u6027\u4f7f\u5176\u5728\u52a8\u6001\u73af\u5883\u4e2d\u7684\u53ef\u9760\u6027\u96be\u4ee5\u4fdd\u8bc1\u3002\u73b0\u6709\u6d4b\u8bd5\u751f\u6210\u6280\u672f\u548c\u4f20\u7edf\u53d8\u5f02\u5206\u6790\u7f3a\u4e4f\u9488\u5bf9DL\u8f6f\u4ef6\u4e0d\u786e\u5b9a\u6027\u7684\u8bc4\u4f30\u65b9\u6cd5\u3002", "method": "\u63d0\u51faUAMTERS\u6846\u67b6\uff1a1\uff09\u8bbe\u8ba1\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u53d8\u5f02\u7b97\u5b50\uff0c\u663e\u5f0f\u6ce8\u5165\u968f\u673a\u4e0d\u786e\u5b9a\u6027\u5230DL\u8d4b\u80fd\u673a\u5668\u4eba\u8f6f\u4ef6\u4e2d\uff1b2\uff09\u63d0\u51fa\u53d8\u5f02\u8bc4\u5206\u6307\u6807\uff0c\u91cf\u5316\u6d4b\u8bd5\u5957\u4ef6\u5728\u4e0d\u540c\u4e0d\u786e\u5b9a\u6027\u6c34\u5e73\u4e0b\u68c0\u6d4b\u6545\u969c\u7684\u80fd\u529b\u3002", "result": "\u5728\u4e09\u4e2a\u673a\u5668\u4eba\u6848\u4f8b\u7814\u7a76\u4e2d\u8bc4\u4f30UAMTERS\uff0c\u8bc1\u660e\u5176\u80fd\u66f4\u6709\u6548\u5730\u533a\u5206\u6d4b\u8bd5\u5957\u4ef6\u8d28\u91cf\uff0c\u5e76\u6355\u6349DL\u8f6f\u4ef6\u4e2d\u7531\u4e0d\u786e\u5b9a\u6027\u5f15\u53d1\u7684\u6545\u969c\u3002", "conclusion": "UAMTERS\u586b\u8865\u4e86\u9488\u5bf9DL\u8d4b\u80fd\u673a\u5668\u4eba\u8f6f\u4ef6\u4e0d\u786e\u5b9a\u6027\u8fdb\u884c\u53d8\u5f02\u5206\u6790\u7684\u6280\u672f\u7a7a\u767d\uff0c\u4e3a\u8bc4\u4f30\u6d4b\u8bd5\u5957\u4ef6\u5728\u4e0d\u786e\u5b9a\u6027\u73af\u5883\u4e0b\u7684\u6709\u6548\u6027\u63d0\u4f9b\u4e86\u7cfb\u7edf\u5316\u6846\u67b6\u3002"}}
{"id": "2602.21144", "categories": ["cs.DC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.21144", "abs": "https://arxiv.org/abs/2602.21144", "authors": ["Anurag Dutt", "Nimit Shah", "Hazem Masarani", "Anshul Gandhi"], "title": "Scaling State-Space Models on Multiple GPUs with Tensor Parallelism", "comment": "Submitted to 46th IEEE International Conference on Distributed Computing Systems (ICDCS 2026)", "summary": "Selective state space models (SSMs) have rapidly become a compelling backbone for large language models, especially for long-context workloads. Yet in deployment, their inference performance is often bounded by the memory capacity, bandwidth, and latency limits of a single GPU, making multi-GPU execution increasingly necessary. Although tensor parallelism (TP) is widely used to scale Transformer inference, applying it to selective SSM blocks is non-trivial because the SSM mixer couples large projections with a sequence-wise recurrent state update and local mixing whose efficiency depends on preserving locality and avoiding synchronization in the critical path.\n  This paper presents a communication-efficient TP design for selective SSM inference that addresses three practical engineering challenges: enabling TTFT improvements via an SSM state cache across prefill and decode, partitioning the mixer's packed parameter tensor so that recurrent updates remain local while minimizing communication, and reducing TP aggregation overhead with quantized AllReduce. We evaluate on three representative SSM-based LLMs spanning pure-SSM and hybrid architectures - Mamba, Falcon-Mamba, and Zamba - on NVIDIA A6000 and A100 clusters. Our experiments show substantial throughput gains from tensor-parallel SSM inference, improving batch-request throughput by ~1.6-2.1x on 2 GPUs and ~2.6-4.0x on 4 GPUs for Mamba, with the largest benefits at long context lengths, and achieving a further ~10-18% throughput improvement from quantized all-reduce by lowering synchronization bandwidth overhead.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u9009\u62e9\u6027\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\uff08SSM\uff09\u7684\u9ad8\u6548\u5f20\u91cf\u5e76\u884c\u63a8\u7406\u8bbe\u8ba1\uff0c\u89e3\u51b3\u4e86\u591aGPU\u90e8\u7f72\u4e2d\u7684\u901a\u4fe1\u74f6\u9888\uff0c\u663e\u8457\u63d0\u5347\u4e86\u63a8\u7406\u541e\u5410\u91cf\u3002", "motivation": "\u9009\u62e9\u6027\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\u5df2\u6210\u4e3a\u5927\u8bed\u8a00\u6a21\u578b\u7684\u91cd\u8981\u67b6\u6784\uff0c\u4f46\u5176\u63a8\u7406\u6027\u80fd\u53d7\u9650\u4e8e\u5355GPU\u7684\u5185\u5b58\u548c\u5e26\u5bbd\u3002\u867d\u7136\u5f20\u91cf\u5e76\u884c\u5728Transformer\u4e2d\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u5e94\u7528\u4e8e\u9009\u62e9\u6027SSM\u5757\u5b58\u5728\u6311\u6218\uff0c\u56e0\u4e3aSSM\u6df7\u5408\u5668\u5c06\u5927\u6295\u5f71\u4e0e\u5e8f\u5217\u7ea7\u5faa\u73af\u72b6\u6001\u66f4\u65b0\u548c\u5c40\u90e8\u6df7\u5408\u8026\u5408\uff0c\u5176\u6548\u7387\u4f9d\u8d56\u4e8e\u4fdd\u6301\u5c40\u90e8\u6027\u548c\u907f\u514d\u5173\u952e\u8def\u5f84\u4e2d\u7684\u540c\u6b65\u3002", "method": "\u63d0\u51fa\u901a\u4fe1\u9ad8\u6548\u7684\u5f20\u91cf\u5e76\u884c\u8bbe\u8ba1\uff0c\u89e3\u51b3\u4e09\u4e2a\u5de5\u7a0b\u6311\u6218\uff1a1) \u901a\u8fc7SSM\u72b6\u6001\u7f13\u5b58\u5b9e\u73b0\u9884\u586b\u5145\u548c\u89e3\u7801\u9636\u6bb5\u7684TTFT\u6539\u8fdb\uff1b2) \u5bf9\u6df7\u5408\u5668\u7684\u6253\u5305\u53c2\u6570\u5f20\u91cf\u8fdb\u884c\u5206\u533a\uff0c\u4f7f\u5faa\u73af\u66f4\u65b0\u4fdd\u6301\u5c40\u90e8\u6027\u540c\u65f6\u6700\u5c0f\u5316\u901a\u4fe1\uff1b3) \u4f7f\u7528\u91cf\u5316AllReduce\u964d\u4f4eTP\u805a\u5408\u5f00\u9500\u3002", "result": "\u5728Mamba\u3001Falcon-Mamba\u548cZamba\u4e09\u79cdSSM\u67b6\u6784\u4e0a\u8bc4\u4f30\uff0c2GPU\u65f6\u541e\u5410\u91cf\u63d0\u53471.6-2.1\u500d\uff0c4GPU\u65f6\u63d0\u53472.6-4.0\u500d\uff0c\u957f\u4e0a\u4e0b\u6587\u573a\u666f\u6536\u76ca\u6700\u5927\u3002\u91cf\u5316AllReduce\u8fdb\u4e00\u6b65\u5e26\u676510-18%\u7684\u541e\u5410\u91cf\u63d0\u5347\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u9009\u62e9\u6027\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u591aGPU\u5f20\u91cf\u5e76\u884c\u63a8\u7406\u89e3\u51b3\u65b9\u6848\uff0c\u663e\u8457\u63d0\u5347\u4e86\u90e8\u7f72\u6548\u7387\u548c\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728\u957f\u4e0a\u4e0b\u6587\u5de5\u4f5c\u8d1f\u8f7d\u4e2d\u3002"}}
{"id": "2602.20478", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.20478", "abs": "https://arxiv.org/abs/2602.20478", "authors": ["Aristidis Vasilopoulos"], "title": "Codified Context: Infrastructure for AI Agents in a Complex Codebase", "comment": "9 pages, 4 figures, companion repository: https://github.com/arisvas4/codified-context-infrastructure, code DOI: 10.5281/zenodo.18746623", "summary": "LLM-based agentic coding assistants lack persistent memory: they lose coherence across sessions, forget project conventions, and repeat known mistakes. Recent studies characterize how developers configure agents through manifest files, but an open challenge remains how to scale such configurations for large, multi-agent projects. This paper presents a three-component codified context infrastructure developed during construction of a 108,000-line C# distributed system: (1) a hot-memory constitution encoding conventions, retrieval hooks, and orchestration protocols; (2) 19 specialized domain-expert agents; and (3) a cold-memory knowledge base of 34 on-demand specification documents. Quantitative metrics on infrastructure growth and interaction patterns across 283 development sessions are reported alongside four observational case studies illustrating how codified context propagates across sessions to prevent failures and maintain consistency. The framework is published as an open-source companion repository.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u4e09\u7ec4\u4ef6\u7f16\u7801\u4e0a\u4e0b\u6587\u57fa\u7840\u8bbe\u65bd\uff0c\u89e3\u51b3LLM\u4ee3\u7406\u52a9\u624b\u5728\u591a\u4ee3\u7406\u9879\u76ee\u4e2d\u7f3a\u4e4f\u6301\u4e45\u8bb0\u5fc6\u7684\u95ee\u9898\uff0c\u5305\u542b\u70ed\u8bb0\u5fc6\u5baa\u6cd5\u300119\u4e2a\u4e13\u4e1a\u4ee3\u7406\u548c\u51b7\u8bb0\u5fc6\u77e5\u8bc6\u5e93\u3002", "motivation": "LLM\u4ee3\u7406\u52a9\u624b\u7f3a\u4e4f\u6301\u4e45\u8bb0\u5fc6\uff0c\u5bfc\u81f4\u8de8\u4f1a\u8bdd\u4e00\u81f4\u6027\u5dee\u3001\u5fd8\u8bb0\u9879\u76ee\u7ea6\u5b9a\u3001\u91cd\u590d\u5df2\u77e5\u9519\u8bef\u3002\u73b0\u6709\u914d\u7f6e\u65b9\u6cd5\u96be\u4ee5\u6269\u5c55\u5230\u5927\u578b\u591a\u4ee3\u7406\u9879\u76ee\u3002", "method": "\u5f00\u53d1\u4e09\u7ec4\u4ef6\u57fa\u7840\u8bbe\u65bd\uff1a1)\u70ed\u8bb0\u5fc6\u5baa\u6cd5\uff08\u7f16\u7801\u7ea6\u5b9a\u3001\u68c0\u7d22\u94a9\u5b50\u548c\u7f16\u6392\u534f\u8bae\uff09\uff1b2)19\u4e2a\u4e13\u4e1a\u9886\u57df\u4e13\u5bb6\u4ee3\u7406\uff1b3)\u51b7\u8bb0\u5fc6\u77e5\u8bc6\u5e93\uff0834\u4e2a\u6309\u9700\u89c4\u8303\u6587\u6863\uff09\u3002\u5728108,000\u884cC#\u5206\u5e03\u5f0f\u7cfb\u7edf\u4e2d\u6784\u5efa\u3002", "result": "\u62a5\u544a\u4e86283\u4e2a\u5f00\u53d1\u4f1a\u8bdd\u4e2d\u7684\u57fa\u7840\u8bbe\u65bd\u589e\u957f\u548c\u4ea4\u4e92\u6a21\u5f0f\u7684\u5b9a\u91cf\u6307\u6807\uff0c\u4ee5\u53ca\u56db\u4e2a\u89c2\u5bdf\u6027\u6848\u4f8b\u7814\u7a76\uff0c\u5c55\u793a\u4e86\u7f16\u7801\u4e0a\u4e0b\u6587\u5982\u4f55\u8de8\u4f1a\u8bdd\u4f20\u64ad\u4ee5\u9632\u6b62\u6545\u969c\u548c\u4fdd\u6301\u4e00\u81f4\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u7f16\u7801\u4e0a\u4e0b\u6587\u6846\u67b6\u89e3\u51b3\u4e86LLM\u4ee3\u7406\u5728\u591a\u4ee3\u7406\u9879\u76ee\u4e2d\u7684\u6301\u4e45\u8bb0\u5fc6\u95ee\u9898\uff0c\u5df2\u4f5c\u4e3a\u5f00\u6e90\u914d\u5957\u4ed3\u5e93\u53d1\u5e03\uff0c\u80fd\u591f\u6709\u6548\u9632\u6b62\u6545\u969c\u5e76\u4fdd\u6301\u9879\u76ee\u4e00\u81f4\u6027\u3002"}}
{"id": "2602.21182", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2602.21182", "abs": "https://arxiv.org/abs/2602.21182", "authors": ["Paul Borrill"], "title": "Circumventing the CAP Theorem with Open Atomic Ethernet", "comment": "23 pages, 14 figures", "summary": "The CAP theorem is routinely treated as a systems law: under network partition, a replicated service must sacrifice either consistency or availability. The theorem is correct within its standard asynchronous network model, but operational practice depends on where partition-like phenomena become observable and on how lower layers discard or preserve semantic information about message fate. This paper argues that Open Atomic Ethernet (OAE) shifts the engineering regime in which CAP tradeoffs become application-visible by (i) replacing fire-and-forget link semantics with bounded-time bilateral reconciliation of endpoint state -- the property we call bisynchrony -- and (ii) avoiding Clos funnel points via an octavalent mesh in which each node can act as the root of a locally repaired spanning tree. The result is not the elimination of hard graph cuts, but a drastic reduction in the frequency and duration of application-visible \"soft partitions\" by detecting and healing dominant fabric faults within hundreds of nanoseconds. We connect this view to Brewer's original CAP framing, the formalization by Gilbert and Lynch, the CAL theorem of Lee et al., which replaces binary partition tolerance with a quantitative measure of apparent latency, and Abadi's PACELC extension.", "AI": {"tldr": "\u8be5\u8bba\u6587\u8ba4\u4e3aOpen Atomic Ethernet\u901a\u8fc7\u5f15\u5165\u53cc\u5411\u540c\u6b65\u548c\u516b\u4ef7\u7f51\u72b6\u62d3\u6251\uff0c\u5927\u5e45\u51cf\u5c11\u4e86\u5e94\u7528\u53ef\u89c1\u7684\"\u8f6f\u5206\u533a\"\u9891\u7387\u548c\u6301\u7eed\u65f6\u95f4\uff0c\u6539\u53d8\u4e86CAP\u6743\u8861\u7684\u5de5\u7a0b\u5b9e\u73b0\u65b9\u5f0f\u3002", "motivation": "CAP\u5b9a\u7406\u901a\u5e38\u88ab\u89c6\u4e3a\u7cfb\u7edf\u5b9a\u5f8b\uff0c\u4f46\u5728\u5b9e\u9645\u5de5\u7a0b\u5b9e\u8df5\u4e2d\uff0c\u5206\u533a\u73b0\u8c61\u7684\u53ef\u89c2\u6d4b\u6027\u4ee5\u53ca\u5e95\u5c42\u7f51\u7edc\u5982\u4f55\u5904\u7406\u6d88\u606f\u8bed\u4e49\u4fe1\u606f\u81f3\u5173\u91cd\u8981\u3002\u8bba\u6587\u65e8\u5728\u63a2\u8ba8\u5982\u4f55\u901a\u8fc7\u6539\u53d8\u7f51\u7edc\u67b6\u6784\u6765\u6539\u53d8CAP\u6743\u8861\u5728\u5e94\u7528\u5c42\u9762\u7684\u53ef\u89c1\u6027\u3002", "method": "\u63d0\u51faOpen Atomic Ethernet\u67b6\u6784\uff0c\u5b83\u901a\u8fc7\u4e24\u4e2a\u5173\u952e\u6280\u672f\uff1a(1) \u7528\u6709\u754c\u65f6\u95f4\u7684\u53cc\u5411\u7aef\u70b9\u72b6\u6001\u534f\u8c03\uff08\u79f0\u4e3a\u53cc\u5411\u540c\u6b65\uff09\u66ff\u4ee3\u4f20\u7edf\u7684\"\u53d1\u9001\u5373\u5fd8\"\u94fe\u8def\u8bed\u4e49\uff1b(2) \u91c7\u7528\u516b\u4ef7\u7f51\u72b6\u62d3\u6251\u907f\u514dClos\u6c47\u805a\u70b9\uff0c\u6bcf\u4e2a\u8282\u70b9\u90fd\u53ef\u4ee5\u4f5c\u4e3a\u672c\u5730\u4fee\u590d\u751f\u6210\u6811\u7684\u6839\u8282\u70b9\u3002", "result": "\u8be5\u67b6\u6784\u4e0d\u80fd\u5b8c\u5168\u6d88\u9664\u786c\u56fe\u5206\u5272\uff0c\u4f46\u80fd\u5c06\u5e94\u7528\u53ef\u89c1\u7684\"\u8f6f\u5206\u533a\"\u9891\u7387\u548c\u6301\u7eed\u65f6\u95f4\u5927\u5e45\u51cf\u5c11\uff0c\u80fd\u591f\u5728\u6570\u767e\u7eb3\u79d2\u5185\u68c0\u6d4b\u548c\u4fee\u590d\u4e3b\u8981\u7f51\u7edc\u6545\u969c\u3002", "conclusion": "Open Atomic Ethernet\u6539\u53d8\u4e86CAP\u6743\u8861\u7684\u5de5\u7a0b\u5b9e\u73b0\u65b9\u5f0f\uff0c\u901a\u8fc7\u964d\u4f4e\u8f6f\u5206\u533a\u7684\u53ef\u89c1\u6027\uff0c\u4e3a\u5206\u5e03\u5f0f\u7cfb\u7edf\u63d0\u4f9b\u4e86\u66f4\u597d\u7684\u64cd\u4f5c\u5b9e\u8df5\u3002\u8bba\u6587\u5c06\u8fd9\u4e00\u89c2\u70b9\u4e0eBrewer\u7684\u539f\u59cbCAP\u6846\u67b6\u3001Gilbert\u548cLynch\u7684\u5f62\u5f0f\u5316\u3001Lee\u7b49\u4eba\u7684CAL\u5b9a\u7406\u4ee5\u53caAbadi\u7684PACELC\u6269\u5c55\u8054\u7cfb\u8d77\u6765\u3002"}}
{"id": "2602.20598", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.20598", "abs": "https://arxiv.org/abs/2602.20598", "authors": ["Shoma Ansai", "Masaki Waga"], "title": "A Case Study on Runtime Verification of a Continuous Deployment Process", "comment": "Presented at the Runtime Verification Case-Studies Workshop 2025 (RVCase'25), with no formal proceedings", "summary": "We report our experience in applying runtime monitoring to a FluxCD-based continuous deployment (CD) process. Our target system consists of GitHub Actions, GitHub Container Registry (GHCR), FluxCD, and an application running on Kubernetes. We monitored its logs using SyMon. In our setting, we regard a deployment update as detected when FluxCD's polling log resolves the latest image tag. Through the case study, we found that FluxCD did not always detect a new image within five minutes after it was pushed to GHCR, whereas it always did so within ten minutes in the collected logs. Moreover, our results show that SyMon is fast enough for near-real-time monitoring in our setting.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5e94\u7528\u8fd0\u884c\u65f6\u76d1\u63a7\u5230\u57fa\u4e8eFluxCD\u7684\u6301\u7eed\u90e8\u7f72\u6d41\u7a0b\uff0c\u53d1\u73b0FluxCD\u5728\u955c\u50cf\u63a8\u9001\u5230GHCR\u540e5\u5206\u949f\u5185\u4e0d\u4e00\u5b9a\u80fd\u68c0\u6d4b\u5230\u65b0\u955c\u50cf\uff0c\u4f46\u572810\u5206\u949f\u5185\u603b\u80fd\u68c0\u6d4b\u5230\uff0c\u540c\u65f6\u9a8c\u8bc1\u4e86SyMon\u76d1\u63a7\u5de5\u5177\u5728\u8fd1\u5b9e\u65f6\u76d1\u63a7\u4e2d\u7684\u9002\u7528\u6027\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u8fd0\u884c\u65f6\u76d1\u63a7\u5728FluxCD\u6301\u7eed\u90e8\u7f72\u6d41\u7a0b\u4e2d\u7684\u5e94\u7528\u6548\u679c\uff0c\u7279\u522b\u662f\u76d1\u63a7\u90e8\u7f72\u66f4\u65b0\u7684\u68c0\u6d4b\u5ef6\u8fdf\u548c\u76d1\u63a7\u5de5\u5177\u7684\u6027\u80fd\u8868\u73b0\u3002", "method": "\u4f7f\u7528SyMon\u76d1\u63a7\u5de5\u5177\u5bf9\u7531GitHub Actions\u3001GitHub Container Registry\u3001FluxCD\u548cKubernetes\u5e94\u7528\u7ec4\u6210\u7684\u7cfb\u7edf\u8fdb\u884c\u65e5\u5fd7\u76d1\u63a7\uff0c\u5c06FluxCD\u8f6e\u8be2\u65e5\u5fd7\u89e3\u6790\u6700\u65b0\u955c\u50cf\u6807\u7b7e\u89c6\u4e3a\u90e8\u7f72\u66f4\u65b0\u68c0\u6d4b\u3002", "result": "\u7814\u7a76\u53d1\u73b0FluxCD\u5728\u955c\u50cf\u63a8\u9001\u5230GHCR\u540e5\u5206\u949f\u5185\u4e0d\u4e00\u5b9a\u80fd\u68c0\u6d4b\u5230\u65b0\u955c\u50cf\uff0c\u4f46\u5728\u6536\u96c6\u7684\u65e5\u5fd7\u4e2d10\u5206\u949f\u5185\u603b\u80fd\u68c0\u6d4b\u5230\uff1b\u540c\u65f6SyMon\u76d1\u63a7\u5de5\u5177\u5728\u8fd1\u5b9e\u65f6\u76d1\u63a7\u4e2d\u901f\u5ea6\u8db3\u591f\u5feb\u3002", "conclusion": "\u8fd0\u884c\u65f6\u76d1\u63a7\u5728FluxCD\u6301\u7eed\u90e8\u7f72\u6d41\u7a0b\u4e2d\u53ef\u884c\uff0cSyMon\u9002\u5408\u8fd1\u5b9e\u65f6\u76d1\u63a7\uff0c\u4f46\u9700\u8981\u6ce8\u610fFluxCD\u68c0\u6d4b\u65b0\u955c\u50cf\u53ef\u80fd\u5b58\u57285-10\u5206\u949f\u7684\u5ef6\u8fdf\u3002"}}
{"id": "2602.20610", "categories": ["cs.SE", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.20610", "abs": "https://arxiv.org/abs/2602.20610", "authors": ["Cuong Chi Le", "Minh V. T Pham", "Tung Vu Duy", "Cuong Duc Van", "Huy N. Phan", "Hoang N. Phan", "Tien N. Nguyen"], "title": "SpecMind: Cognitively Inspired, Interactive Multi-Turn Framework for Postcondition Inference", "comment": null, "summary": "Specifications are vital for ensuring program correctness, yet writing them manually remains challenging and time-intensive. Recent large language model (LLM)-based methods have shown successes in generating specifications such as postconditions, but existing single-pass prompting often yields inaccurate results. In this paper, we present SpecMind, a novel framework for postcondition generation that treats LLMs as interactive and exploratory reasoners rather than one-shot generators. SpecMind employs feedback-driven multi-turn prompting approaches, enabling the model to iteratively refine candidate postconditions by incorporating implicit and explicit correctness feedback, while autonomously deciding when to stop. This process fosters deeper code comprehension and improves alignment with true program behavior via exploratory attempts. Our empirical evaluation shows that SpecMind significantly outperforms state-of-the-art approaches in both accuracy and completeness of generated postconditions.", "AI": {"tldr": "SpecMind\u662f\u4e00\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u53cd\u9988\u9a71\u52a8\u7684\u591a\u8f6e\u63d0\u793a\u65b9\u6cd5\u8fed\u4ee3\u751f\u6210\u548c\u4f18\u5316\u7a0b\u5e8f\u540e\u7f6e\u6761\u4ef6\uff0c\u76f8\u6bd4\u5355\u6b21\u63d0\u793a\u65b9\u6cd5\u5728\u51c6\u786e\u6027\u548c\u5b8c\u6574\u6027\u4e0a\u663e\u8457\u63d0\u5347\u3002", "motivation": "\u89c4\u8303\u5bf9\u4e8e\u786e\u4fdd\u7a0b\u5e8f\u6b63\u786e\u6027\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u624b\u52a8\u7f16\u5199\u89c4\u8303\u65e2\u56f0\u96be\u53c8\u8017\u65f6\u3002\u73b0\u6709\u7684\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5355\u6b21\u63d0\u793a\u65b9\u6cd5\u751f\u6210\u7684\u540e\u7f6e\u6761\u4ef6\u5f80\u5f80\u4e0d\u51c6\u786e\uff0c\u9700\u8981\u66f4\u6709\u6548\u7684\u65b9\u6cd5\u6765\u751f\u6210\u9ad8\u8d28\u91cf\u7684\u89c4\u8303\u3002", "method": "SpecMind\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u89c6\u4e3a\u4ea4\u4e92\u5f0f\u548c\u63a2\u7d22\u6027\u63a8\u7406\u5668\u800c\u975e\u5355\u6b21\u751f\u6210\u5668\u3002\u91c7\u7528\u53cd\u9988\u9a71\u52a8\u7684\u591a\u8f6e\u63d0\u793a\u65b9\u6cd5\uff0c\u901a\u8fc7\u9690\u5f0f\u548c\u663e\u5f0f\u6b63\u786e\u6027\u53cd\u9988\u8fed\u4ee3\u4f18\u5316\u5019\u9009\u540e\u7f6e\u6761\u4ef6\uff0c\u5e76\u81ea\u4e3b\u51b3\u5b9a\u4f55\u65f6\u505c\u6b62\u3002\u8fd9\u79cd\u65b9\u6cd5\u4fc3\u8fdb\u66f4\u6df1\u5165\u7684\u4ee3\u7801\u7406\u89e3\uff0c\u901a\u8fc7\u63a2\u7d22\u6027\u5c1d\u8bd5\u66f4\u597d\u5730\u5bf9\u9f50\u771f\u5b9e\u7a0b\u5e8f\u884c\u4e3a\u3002", "result": "\u5b9e\u8bc1\u8bc4\u4f30\u8868\u660e\uff0cSpecMind\u5728\u751f\u6210\u540e\u7f6e\u6761\u4ef6\u7684\u51c6\u786e\u6027\u548c\u5b8c\u6574\u6027\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\u3002", "conclusion": "SpecMind\u901a\u8fc7\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u4ea4\u4e92\u5f0f\u63a8\u7406\u5668\uff0c\u91c7\u7528\u53cd\u9988\u9a71\u52a8\u7684\u8fed\u4ee3\u65b9\u6cd5\uff0c\u6709\u6548\u63d0\u5347\u4e86\u7a0b\u5e8f\u540e\u7f6e\u6761\u4ef6\u751f\u6210\u7684\u8d28\u91cf\uff0c\u4e3a\u89e3\u51b3\u89c4\u8303\u7f16\u5199\u96be\u9898\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2602.20644", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.20644", "abs": "https://arxiv.org/abs/2602.20644", "authors": ["Fida Khandaker Safa", "Yupeng Jiang", "Xi Zheng"], "title": "An LLM-driven Scenario Generation Pipeline Using an Extended Scenic DSL for Autonomous Driving Safety Validation", "comment": null, "summary": "Real-world crash reports, which combine textual summaries and sketches, are valuable for scenario-based testing of autonomous driving systems (ADS). However, current methods cannot effectively translate this multimodal data into precise, executable simulation scenarios, hindering the scalability of ADS safety validation. In this work, we propose a scalable and verifiable pipeline that uses a large language model (GPT-4o mini) and a probabilistic intermediate representation (an Extended Scenic domain-specific language) to automatically extract semantic scenario configurations from crash reports and generate corresponding simulation-ready scenarios. Unlike earlier approaches such as ScenicNL and LCTGen (which generate scenarios directly from text) or TARGET (which uses deterministic mappings from traffic rules), our method introduces an intermediate Scenic DSL layer to separate high-level semantic understanding from low-level scenario rendering, reducing errors and capturing real-world variability. We evaluated the pipeline on cases from the NHTSA CIREN database. The results show high accuracy in knowledge extraction: 100% correctness for environmental and road network attributes, and 97% and 98% for oracle and actor trajectories, respectively, compared to human-derived ground truth. We executed the generated scenarios in the CARLA simulator using the Autoware driving stack, and they consistently triggered the intended traffic-rule violations (such as opposite-lane crossing and red-light running) across 2,000 scenario variations. These findings demonstrate that the proposed pipeline provides a legally grounded, scalable, and verifiable approach to ADS safety validation.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u53ef\u6269\u5c55\u3001\u53ef\u9a8c\u8bc1\u7684\u6d41\u6c34\u7ebf\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u548c\u6982\u7387\u6027\u4e2d\u95f4\u8868\u793a\uff0c\u4ece\u771f\u5b9e\u4e8b\u6545\u62a5\u544a\u4e2d\u81ea\u52a8\u63d0\u53d6\u8bed\u4e49\u573a\u666f\u914d\u7f6e\u5e76\u751f\u6210\u6a21\u62df\u5c31\u7eea\u573a\u666f\uff0c\u7528\u4e8e\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u5b89\u5168\u9a8c\u8bc1\u3002", "motivation": "\u5f53\u524d\u65b9\u6cd5\u65e0\u6cd5\u6709\u6548\u5c06\u5305\u542b\u6587\u672c\u6458\u8981\u548c\u8349\u56fe\u7684\u591a\u6a21\u6001\u4e8b\u6545\u62a5\u544a\u8f6c\u5316\u4e3a\u7cbe\u786e\u3001\u53ef\u6267\u884c\u7684\u6a21\u62df\u573a\u666f\uff0c\u9650\u5236\u4e86\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u5b89\u5168\u9a8c\u8bc1\u7684\u53ef\u6269\u5c55\u6027\u3002", "method": "\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff08GPT-4o mini\uff09\u548c\u6982\u7387\u6027\u4e2d\u95f4\u8868\u793a\uff08\u6269\u5c55\u7684Scenic\u9886\u57df\u7279\u5b9a\u8bed\u8a00\uff09\uff0c\u901a\u8fc7\u4e2d\u95f4Scenic DSL\u5c42\u5206\u79bb\u9ad8\u5c42\u8bed\u4e49\u7406\u89e3\u548c\u4f4e\u5c42\u573a\u666f\u6e32\u67d3\uff0c\u4ece\u4e8b\u6545\u62a5\u544a\u4e2d\u63d0\u53d6\u8bed\u4e49\u573a\u666f\u914d\u7f6e\u5e76\u751f\u6210\u6a21\u62df\u573a\u666f\u3002", "result": "\u5728NHTSA CIREN\u6570\u636e\u5e93\u6848\u4f8b\u8bc4\u4f30\u4e2d\uff0c\u77e5\u8bc6\u63d0\u53d6\u51c6\u786e\u7387\u9ad8\uff1a\u73af\u5883\u548c\u9053\u8def\u7f51\u7edc\u5c5e\u6027100%\u6b63\u786e\uff0c\u8f68\u8ff9\u63d0\u53d6\u5206\u522b\u4e3a97%\u548c98%\u3002\u5728CARLA\u6a21\u62df\u5668\u4e2d\u6267\u884c\u751f\u6210\u7684\u573a\u666f\uff0c\u57282000\u4e2a\u573a\u666f\u53d8\u4f53\u4e2d\u4e00\u81f4\u89e6\u53d1\u4e86\u9884\u671f\u7684\u4ea4\u901a\u89c4\u5219\u8fdd\u89c4\u3002", "conclusion": "\u8be5\u6d41\u6c34\u7ebf\u4e3a\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u5b89\u5168\u9a8c\u8bc1\u63d0\u4f9b\u4e86\u6cd5\u5f8b\u4f9d\u636e\u5145\u5206\u3001\u53ef\u6269\u5c55\u4e14\u53ef\u9a8c\u8bc1\u7684\u65b9\u6cd5\uff0c\u80fd\u591f\u6709\u6548\u5229\u7528\u771f\u5b9e\u4e8b\u6545\u62a5\u544a\u751f\u6210\u9ad8\u8d28\u91cf\u7684\u6a21\u62df\u6d4b\u8bd5\u573a\u666f\u3002"}}
{"id": "2602.20684", "categories": ["cs.SE", "cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2602.20684", "abs": "https://arxiv.org/abs/2602.20684", "authors": ["Christopher Koch", "Joshua Andreas Wellbrock"], "title": "Agile V: A Compliance-Ready Framework for AI-Augmented Engineering -- From Concept to Audit-Ready Delivery", "comment": "9 pages, 2 figures", "summary": "Current AI-assisted engineering workflows lack a built-in mechanism to maintain task-level verification and regulatory traceability at machine-speed delivery. Agile V addresses this gap by embedding independent verification and audit artifact generation into each task cycle. The framework merges Agile iteration with V-Model verification into a continuous Infinity Loop, deploying specialized AI agents for requirements, design, build, test, and compliance, governed by mandatory human approval gates. We evaluate three hypotheses: (H1) audit-ready artifacts emerge as a by-product of development, (H2) 100% requirement-level verification is achievable with independent test generation, and (H3) verified increments can be delivered with single-digit human interactions per cycle. A feasibility case study on a Hardware-in-the-Loop system (about 500 LOC, 8 requirements, 54 tests) supports all three hypotheses: audit-ready documentation was generated automatically (H1), 100% requirement-level pass rate was achieved (H2), and only 6 prompts per cycle were required (H3), yielding an estimated 10-50x cost reduction versus a COCOMO II baseline (sensitivity range from pessimistic to optimistic assumptions). We invite independent replication to validate generalizability.", "AI": {"tldr": "Agile V\u6846\u67b6\u5c06\u654f\u6377\u8fed\u4ee3\u4e0eV\u6a21\u578b\u9a8c\u8bc1\u7ed3\u5408\u4e3a\u65e0\u9650\u5faa\u73af\uff0c\u901a\u8fc7AI\u4ee3\u7406\u81ea\u52a8\u751f\u6210\u5ba1\u8ba1\u5c31\u7eea\u6587\u6863\uff0c\u5b9e\u73b0100%\u9700\u6c42\u7ea7\u9a8c\u8bc1\uff0c\u6bcf\u4e2a\u5468\u671f\u4ec5\u97006\u6b21\u4eba\u5de5\u4ea4\u4e92\uff0c\u4f30\u8ba1\u6210\u672c\u964d\u4f4e10-50\u500d\u3002", "motivation": "\u5f53\u524dAI\u8f85\u52a9\u5de5\u7a0b\u5de5\u4f5c\u6d41\u7f3a\u4e4f\u5185\u7f6e\u673a\u5236\u6765\u5728\u673a\u5668\u901f\u5ea6\u4ea4\u4ed8\u65f6\u7ef4\u62a4\u4efb\u52a1\u7ea7\u9a8c\u8bc1\u548c\u76d1\u7ba1\u53ef\u8ffd\u6eaf\u6027\uff0c\u9700\u8981\u89e3\u51b3\u9a8c\u8bc1\u4e0e\u5ba1\u8ba1\u6587\u6863\u81ea\u52a8\u751f\u6210\u7684\u95ee\u9898\u3002", "method": "Agile V\u6846\u67b6\u5c06\u654f\u6377\u8fed\u4ee3\u4e0eV\u6a21\u578b\u9a8c\u8bc1\u5408\u5e76\u4e3a\u8fde\u7eed\u65e0\u9650\u5faa\u73af\uff0c\u90e8\u7f72\u4e13\u95e8\u7684AI\u4ee3\u7406\u5904\u7406\u9700\u6c42\u3001\u8bbe\u8ba1\u3001\u6784\u5efa\u3001\u6d4b\u8bd5\u548c\u5408\u89c4\uff0c\u7531\u5f3a\u5236\u6027\u4eba\u5de5\u5ba1\u6279\u95e8\u63a7\u5236\u3002", "result": "\u786c\u4ef6\u5728\u73af\u7cfb\u7edf\u6848\u4f8b\u7814\u7a76\uff08\u7ea6500\u884c\u4ee3\u7801\uff0c8\u4e2a\u9700\u6c42\uff0c54\u4e2a\u6d4b\u8bd5\uff09\u652f\u6301\u6240\u6709\u4e09\u4e2a\u5047\u8bbe\uff1a\u81ea\u52a8\u751f\u6210\u5ba1\u8ba1\u5c31\u7eea\u6587\u6863\uff0c\u5b9e\u73b0100%\u9700\u6c42\u7ea7\u901a\u8fc7\u7387\uff0c\u6bcf\u4e2a\u5468\u671f\u4ec5\u97006\u6b21\u63d0\u793a\uff0c\u4f30\u8ba1\u6210\u672c\u6bd4COCOMO II\u57fa\u51c6\u964d\u4f4e10-50\u500d\u3002", "conclusion": "Agile V\u6846\u67b6\u901a\u8fc7\u5728\u5f00\u53d1\u8fc7\u7a0b\u4e2d\u5d4c\u5165\u72ec\u7acb\u9a8c\u8bc1\u548c\u5ba1\u8ba1\u5de5\u4ef6\u751f\u6210\uff0c\u5b9e\u73b0\u4e86\u673a\u5668\u901f\u5ea6\u4ea4\u4ed8\u4e0b\u7684\u4efb\u52a1\u7ea7\u9a8c\u8bc1\u548c\u76d1\u7ba1\u53ef\u8ffd\u6eaf\u6027\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u6210\u672c\u5e76\u63d0\u9ad8\u4e86\u6548\u7387\u3002"}}
{"id": "2602.20717", "categories": ["cs.SE", "cs.CR"], "pdf": "https://arxiv.org/pdf/2602.20717", "abs": "https://arxiv.org/abs/2602.20717", "authors": ["Xiting Liu", "Yuetong Liu", "Yitong Zhang", "Jia Li", "Shi-Min Hu"], "title": "PackMonitor: Enabling Zero Package Hallucinations Through Decoding-Time Monitoring", "comment": null, "summary": "As Large Language Models (LLMs) are increasingly integrated into software development workflows, their trustworthiness has become a critical concern. However, in dependency recommendation scenarios, the reliability of LLMs is undermined by widespread package hallucinations, where models often recommend hallucinated packages. Recent studies have proposed a range of approaches to mitigate this issue. Nevertheless, existing approaches typically merely reduce hallucination rates rather than eliminate them, leaving persistent software security risks.\n  In this work, we argue that package hallucinations are theoretically preventable based on the key insight that package validity is decidable through finite and enumerable authoritative package lists. Building on this, we propose PackMonitor, the first approach capable of fundamentally eliminating package hallucinations by continuously monitoring the model's decoding process and intervening when necessary. To implement this in practice, PackMonitor addresses three key challenges: (1) determining when to trigger intervention via a Context-Aware Parser that continuously monitors model outputs and selectively activates intervening only during installation command generation; (2) resolving how to intervene by employing a Package-Name Intervenor that strictly limits the decoding space to an authoritative package list; and (3) ensuring monitoring efficiency through a DFA-Caching Mechanism that enables scalability to millions of packages with negligible overhead. Extensive experiments on five widely used LLMs demonstrate that PackMonitor is a training-free, plug-and-play solution that consistently reduces package hallucination rates to zero while maintaining low-latency inference and preserving original model capabilities.", "AI": {"tldr": "PackMonitor\u662f\u9996\u4e2a\u80fd\u4ece\u6839\u672c\u4e0a\u6d88\u9664LLM\u5728\u4f9d\u8d56\u63a8\u8350\u4e2d\u5305\u5e7b\u89c9\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u76d1\u63a7\u89e3\u7801\u8fc7\u7a0b\u5e76\u9650\u5236\u8f93\u51fa\u5230\u6743\u5a01\u5305\u5217\u8868\uff0c\u5c06\u5e7b\u89c9\u7387\u964d\u81f3\u96f6\u3002", "motivation": "LLM\u5728\u8f6f\u4ef6\u4f9d\u8d56\u63a8\u8350\u4e2d\u5b58\u5728\u4e25\u91cd\u7684\u5305\u5e7b\u89c9\u95ee\u9898\uff0c\u73b0\u6709\u65b9\u6cd5\u53ea\u80fd\u964d\u4f4e\u4f46\u4e0d\u80fd\u6d88\u9664\u5e7b\u89c9\uff0c\u5bfc\u81f4\u6301\u7eed\u7684\u8f6f\u4ef6\u5b89\u5168\u98ce\u9669\u3002\u4f5c\u8005\u8ba4\u4e3a\u5305\u5e7b\u89c9\u5728\u7406\u8bba\u4e0a\u662f\u53ef\u9884\u9632\u7684\uff0c\u56e0\u4e3a\u5305\u6709\u6548\u6027\u53ef\u901a\u8fc7\u6709\u9650\u4e14\u53ef\u679a\u4e3e\u7684\u6743\u5a01\u5305\u5217\u8868\u6765\u5224\u5b9a\u3002", "method": "PackMonitor\u901a\u8fc7\u4e09\u4e2a\u5173\u952e\u6280\u672f\u5b9e\u73b0\uff1a1) \u4e0a\u4e0b\u6587\u611f\u77e5\u89e3\u6790\u5668\uff0c\u6301\u7eed\u76d1\u63a7\u6a21\u578b\u8f93\u51fa\u5e76\u4ec5\u5728\u5b89\u88c5\u547d\u4ee4\u751f\u6210\u65f6\u89e6\u53d1\u5e72\u9884\uff1b2) \u5305\u540d\u5e72\u9884\u5668\uff0c\u4e25\u683c\u9650\u5236\u89e3\u7801\u7a7a\u95f4\u5230\u6743\u5a01\u5305\u5217\u8868\uff1b3) DFA\u7f13\u5b58\u673a\u5236\uff0c\u652f\u6301\u6269\u5c55\u5230\u6570\u767e\u4e07\u4e2a\u5305\u4e14\u5f00\u9500\u53ef\u5ffd\u7565\u3002", "result": "\u5728\u4e94\u4e2a\u5e7f\u6cdb\u4f7f\u7528\u7684LLM\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cPackMonitor\u4f5c\u4e3a\u514d\u8bad\u7ec3\u3001\u5373\u63d2\u5373\u7528\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u6301\u7eed\u5c06\u5305\u5e7b\u89c9\u7387\u964d\u81f3\u96f6\uff0c\u540c\u65f6\u4fdd\u6301\u4f4e\u5ef6\u8fdf\u63a8\u7406\u5e76\u4fdd\u7559\u539f\u59cb\u6a21\u578b\u80fd\u529b\u3002", "conclusion": "PackMonitor\u9996\u6b21\u5b9e\u73b0\u4e86\u4ece\u6839\u672c\u4e0a\u6d88\u9664LLM\u5305\u5e7b\u89c9\u7684\u76ee\u6807\uff0c\u901a\u8fc7\u7406\u8bba\u53ef\u9884\u9632\u6027\u7684\u6d1e\u5bdf\u548c\u5b9e\u7528\u7684\u76d1\u63a7\u5e72\u9884\u673a\u5236\uff0c\u4e3aLLM\u5728\u8f6f\u4ef6\u4f9d\u8d56\u63a8\u8350\u4e2d\u7684\u53ef\u4fe1\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u9760\u4fdd\u969c\u3002"}}
{"id": "2602.20799", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.20799", "abs": "https://arxiv.org/abs/2602.20799", "authors": ["Guangsheng Ou", "Qiming Zhang", "Sirong Chen", "Anji Li", "Dong Xu", "Tiancheng Luo", "Dekun Dai", "Cuiyun Gao", "Long Wang", "Jun Zhou", "Mingwei Liu", "Zibin Zheng"], "title": "Unseen-Codebases-Domain Data Synthesis and Training Based on Code Graphs", "comment": null, "summary": "In the context of newly release software frameworks, large language models (LLMs) often exhibit poor performance and a high rate of hallucination, as they are not exposed to such environments during training. Although inference-time augmentation techniques such as retrieval-augmented generation (RAG) can partially mitigate hallucinations, knowledge injection through prompting alone is insufficient to enable models to fully understand the intrinsic relationships among different components of a codebase, or to reason about the correct compositions and apply. Although explicit knowledge injection can be achieved through post-training, compared with public code domains, unseen codebases typically provide only source code and lack large volumes of high-quality, usage-oriented code that can be directly leveraged as training data. Consequently, existing data synthesis approaches are insufficient to adequately capture unseen codebases usage scenarios when restricted to source code alone. To address these challenges, we propose UCD-Training, a two-stage training framework for reasoning-aware data synthesis grounded in a code graph constructed from unseen codebases. UCD-Training first parses the source code to build a code graph, then conducts dependency-preserving continued pretraining (CPT) using file-level dependency data, followed by graph-grounded supervised fine-tuning (SFT) on three types of synthesized data augmented with explicit reasoning traces: (1) single-hop relation reasoning data, (2) compositional API reasoning data, and (3) codebase utilization data. We further introduce a new benchmark, UnseenCodeBench, for code generation on unseen codebases and conduct comprehensive experiments across multiple codebases.", "AI": {"tldr": "\u63d0\u51faUCD-Training\u6846\u67b6\uff0c\u901a\u8fc7\u4ee3\u7801\u56fe\u6784\u5efa\u548c\u4e24\u9636\u6bb5\u8bad\u7ec3\uff08\u4f9d\u8d56\u4fdd\u6301\u7684\u6301\u7eed\u9884\u8bad\u7ec3+\u56fe\u57fa\u76d1\u7763\u5fae\u8c03\uff09\u6765\u89e3\u51b3LLM\u5728\u672a\u89c1\u4ee3\u7801\u5e93\u4e0a\u7684\u6027\u80fd\u4e0d\u4f73\u548c\u5e7b\u89c9\u95ee\u9898\uff0c\u5e76\u5f15\u5165UnseenCodeBench\u57fa\u51c6\u8fdb\u884c\u8bc4\u4f30\u3002", "motivation": "LLM\u5728\u65b0\u53d1\u5e03\u7684\u8f6f\u4ef6\u6846\u67b6\u4e0a\u8868\u73b0\u4e0d\u4f73\u4e14\u6613\u4ea7\u751f\u5e7b\u89c9\uff0c\u56e0\u4e3a\u8bad\u7ec3\u65f6\u672a\u63a5\u89e6\u8fd9\u4e9b\u73af\u5883\u3002\u73b0\u6709\u65b9\u6cd5\u5982RAG\u53ea\u80fd\u90e8\u5206\u7f13\u89e3\uff0c\u4ec5\u901a\u8fc7\u63d0\u793a\u6ce8\u5165\u77e5\u8bc6\u4e0d\u8db3\u4ee5\u8ba9\u6a21\u578b\u7406\u89e3\u4ee3\u7801\u5e93\u7ec4\u4ef6\u95f4\u5185\u5728\u5173\u7cfb\u5e76\u8fdb\u884c\u6b63\u786e\u7ec4\u5408\u63a8\u7406\u3002\u672a\u89c1\u4ee3\u7801\u5e93\u901a\u5e38\u53ea\u6709\u6e90\u4ee3\u7801\uff0c\u7f3a\u4e4f\u9ad8\u8d28\u91cf\u4f7f\u7528\u5bfc\u5411\u7684\u8bad\u7ec3\u6570\u636e\uff0c\u73b0\u6709\u6570\u636e\u5408\u6210\u65b9\u6cd5\u96be\u4ee5\u6355\u6349\u4f7f\u7528\u573a\u666f\u3002", "method": "UCD-Training\u4e24\u9636\u6bb5\u8bad\u7ec3\u6846\u67b6\uff1a1) \u89e3\u6790\u6e90\u4ee3\u7801\u6784\u5efa\u4ee3\u7801\u56fe\uff1b2) \u4f9d\u8d56\u4fdd\u6301\u7684\u6301\u7eed\u9884\u8bad\u7ec3(CPT)\u4f7f\u7528\u6587\u4ef6\u7ea7\u4f9d\u8d56\u6570\u636e\uff1b3) \u56fe\u57fa\u76d1\u7763\u5fae\u8c03(SFT)\u5728\u4e09\u79cd\u5408\u6210\u6570\u636e\u4e0a\uff1a\u5355\u8df3\u5173\u7cfb\u63a8\u7406\u6570\u636e\u3001\u7ec4\u5408API\u63a8\u7406\u6570\u636e\u3001\u4ee3\u7801\u5e93\u5229\u7528\u6570\u636e\uff0c\u5747\u589e\u5f3a\u4e86\u663e\u5f0f\u63a8\u7406\u8f68\u8ff9\u3002", "result": "\u5728\u591a\u4e2a\u4ee3\u7801\u5e93\u4e0a\u8fdb\u884c\u4e86\u7efc\u5408\u5b9e\u9a8c\uff0c\u5e76\u5f15\u5165\u4e86\u65b0\u7684\u57fa\u51c6UnseenCodeBench\u7528\u4e8e\u672a\u89c1\u4ee3\u7801\u5e93\u7684\u4ee3\u7801\u751f\u6210\u8bc4\u4f30\u3002", "conclusion": "UCD-Training\u901a\u8fc7\u4ee3\u7801\u56fe\u6784\u5efa\u548c\u4e24\u9636\u6bb5\u8bad\u7ec3\uff0c\u6709\u6548\u89e3\u51b3\u4e86LLM\u5728\u672a\u89c1\u4ee3\u7801\u5e93\u4e0a\u7684\u7406\u89e3\u548c\u63a8\u7406\u95ee\u9898\uff0c\u4e3a\u4ee3\u7801\u751f\u6210\u4efb\u52a1\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u548c\u8bc4\u4f30\u57fa\u51c6\u3002"}}
{"id": "2602.20979", "categories": ["cs.SE", "cs.AI", "cs.PL"], "pdf": "https://arxiv.org/pdf/2602.20979", "abs": "https://arxiv.org/abs/2602.20979", "authors": ["Mark Marron"], "title": "Toward an Agentic Infused Software Ecosystem", "comment": null, "summary": "Fully leveraging the capabilities of AI agents in software development requires a rethinking of the software ecosystem itself. To this end, this paper outlines the creation of an Agentic Infused Software Ecosystem (AISE), that rests on three pillars. The first, of course, is the AI agents themselves, which in the past 5 years have moved from simple code completion and toward sophisticated independent development tasks, a trend which will only continue. The second pillar is the programming language and APIs (or tools) that these agents use to accomplish tasks, and increasingly, serve as the communication substrate that humans and AI agents interact and collaborate through. The final pillar is the runtime environment and ecosystem that agents operate within, and which provide the capabilities that programmatic agents use to interface with (and effect actions in) the external world. To realize the vision of AISE, all three pillars must be advanced in a holistic manner, and critically, in a manner that is synergistic for AI agents as they exist today, those that will exist in the future, and for the human developers that work alongside them.", "AI": {"tldr": "\u63d0\u51faAgentic Infused Software Ecosystem (AISE)\u6846\u67b6\uff0c\u5305\u542bAI\u4ee3\u7406\u3001\u7f16\u7a0b\u8bed\u8a00/API\u3001\u8fd0\u884c\u65f6\u73af\u5883\u4e09\u5927\u652f\u67f1\uff0c\u65e8\u5728\u6784\u5efa\u534f\u540c\u53d1\u5c55\u7684\u8f6f\u4ef6\u751f\u6001\u7cfb\u7edf\u3002", "motivation": "\u4e3a\u4e86\u5145\u5206\u53d1\u6325AI\u4ee3\u7406\u5728\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u7684\u6f5c\u529b\uff0c\u9700\u8981\u91cd\u65b0\u601d\u8003\u8f6f\u4ef6\u751f\u6001\u7cfb\u7edf\u672c\u8eab\uff0c\u6784\u5efa\u4e00\u4e2a\u80fd\u591f\u652f\u6301AI\u4ee3\u7406\u4e0e\u4eba\u7c7b\u5f00\u53d1\u8005\u534f\u540c\u5de5\u4f5c\u7684\u65b0\u67b6\u6784\u3002", "method": "\u63d0\u51faAISE\u6846\u67b6\uff0c\u57fa\u4e8e\u4e09\u5927\u652f\u67f1\uff1a1) AI\u4ee3\u7406\u672c\u8eab\uff1b2) \u7f16\u7a0b\u8bed\u8a00\u548cAPI\u4f5c\u4e3a\u4ee3\u7406\u5b8c\u6210\u4efb\u52a1\u548c\u4e0e\u4eba\u7c7b\u4ea4\u4e92\u7684\u901a\u4fe1\u57fa\u7840\uff1b3) \u8fd0\u884c\u65f6\u73af\u5883\u548c\u751f\u6001\u7cfb\u7edf\uff0c\u63d0\u4f9b\u4ee3\u7406\u4e0e\u5916\u90e8\u4e16\u754c\u4ea4\u4e92\u7684\u80fd\u529b\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u5168\u9762\u7684AISE\u6846\u67b6\u6982\u5ff5\uff0c\u4e3a\u672a\u6765AI\u4ee3\u7406\u9a71\u52a8\u7684\u8f6f\u4ef6\u5f00\u53d1\u751f\u6001\u7cfb\u7edf\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u548c\u67b6\u6784\u65b9\u5411\u3002", "conclusion": "\u8981\u5b9e\u73b0AISE\u613f\u666f\uff0c\u4e09\u5927\u652f\u67f1\u5fc5\u987b\u534f\u540c\u53d1\u5c55\uff0c\u65e2\u8981\u6ee1\u8db3\u5f53\u524d\u548c\u672a\u6765AI\u4ee3\u7406\u7684\u9700\u6c42\uff0c\u4e5f\u8981\u652f\u6301\u4eba\u7c7b\u5f00\u53d1\u8005\u7684\u5de5\u4f5c\uff0c\u6784\u5efa\u4e00\u4e2a\u771f\u6b63\u534f\u540c\u7684\u8f6f\u4ef6\u751f\u6001\u7cfb\u7edf\u3002"}}
{"id": "2602.21026", "categories": ["cs.SE", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2602.21026", "abs": "https://arxiv.org/abs/2602.21026", "authors": ["David Heddle"], "title": "A Modular Multi-Document Framework for Scientific Visualization and Simulation in Java", "comment": "10 pages, 5 figures. Includes optional 3D extension module and integrated plotting subsystem. Source code available on GitHub", "summary": "This paper presents the design and implementation of a modular multi-document interface (MDI) framework for scientific visualization and simulation in the Java Virtual Machine (JVM) ecosystem. The framework emphasizes architectural separation between visualization layers, simulation engines, and optional hardware-accelerated 3D rendering. 3D functionality is isolated into a separate module to prevent unnecessary dependency coupling in 2D-only applications. We describe the core abstractions, threading model, simulation integration strategy, and dependency isolation approach. A case study involving a real-time 3D gas expansion simulation integrated with synchronized 2D entropy plotting demonstrates architectural cohesion. The framework is publicly available via Maven Central and targets long-lived scientific and engineering desktop applications.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u7528\u4e8eJVM\u751f\u6001\u7cfb\u7edf\u7684\u6a21\u5757\u5316\u591a\u6587\u6863\u754c\u9762\u6846\u67b6\uff0c\u4e13\u6ce8\u4e8e\u79d1\u5b66\u53ef\u89c6\u5316\u548c\u6a21\u62df\uff0c\u901a\u8fc7\u67b6\u6784\u5206\u79bb\u5b9e\u73b0\u53ef\u89c6\u5316\u5c42\u3001\u6a21\u62df\u5f15\u64ce\u548c\u786c\u4ef6\u52a0\u901f3D\u6e32\u67d3\u7684\u89e3\u8026\u3002", "motivation": "\u4e3a\u79d1\u5b66\u548c\u5de5\u7a0b\u684c\u9762\u5e94\u7528\u63d0\u4f9b\u957f\u671f\u53ef\u7ef4\u62a4\u7684\u6846\u67b6\uff0c\u89e3\u51b3\u4f20\u7edf\u53ef\u89c6\u5316\u7cfb\u7edf\u4e2d\u4f9d\u8d56\u8026\u5408\u95ee\u9898\uff0c\u7279\u522b\u662f\u907f\u514d2D\u5e94\u7528\u5f3a\u5236\u4f9d\u8d563D\u529f\u80fd\u3002", "method": "\u91c7\u7528\u6a21\u5757\u5316\u8bbe\u8ba1\uff0c\u5c063D\u529f\u80fd\u9694\u79bb\u4e3a\u72ec\u7acb\u6a21\u5757\uff0c\u5b9a\u4e49\u6838\u5fc3\u62bd\u8c61\u3001\u7ebf\u7a0b\u6a21\u578b\u3001\u6a21\u62df\u96c6\u6210\u7b56\u7565\u548c\u4f9d\u8d56\u9694\u79bb\u65b9\u6cd5\uff0c\u901a\u8fc7Maven Central\u63d0\u4f9b\u516c\u5f00\u8bbf\u95ee\u3002", "result": "\u6210\u529f\u5b9e\u73b0\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u6846\u67b6\uff0c\u901a\u8fc7\u6c14\u4f53\u81a8\u80c0\u6a21\u62df\u6848\u4f8b\u5c55\u793a\u4e86\u67b6\u6784\u5185\u805a\u6027\uff0c\u652f\u6301\u5b9e\u65f63D\u6a21\u62df\u4e0e\u540c\u6b652D\u71b5\u56fe\u7ed8\u5236\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3aJVM\u751f\u6001\u7cfb\u7edf\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u79d1\u5b66\u53ef\u89c6\u5316\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u6a21\u5757\u5316\u8bbe\u8ba1\u5b9e\u73b0\u4e86\u826f\u597d\u7684\u67b6\u6784\u5206\u79bb\uff0c\u9002\u7528\u4e8e\u957f\u671f\u8fd0\u884c\u7684\u79d1\u7814\u548c\u5de5\u7a0b\u5e94\u7528\u3002"}}
{"id": "2602.21037", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.21037", "abs": "https://arxiv.org/abs/2602.21037", "authors": ["Bruno Guindani", "Matteo Camilli", "Livia Lestingi", "Marcello M. Bersani"], "title": "Automated Detection and Mitigation of Dependability Failures in Healthcare Scenarios through Digital Twins", "comment": "Submitted to IEEE Transactions on Reliability", "summary": "Medical Cyber-Physical Systems (CPSs) integrating Patients, Devices, and healthcare personnel (Physicians) form safety-critical PDP triads whose dependability is challenged by system heterogeneity and uncertainty in human and physiological behavior. While existing clinical decision support systems support clinical practice, there remains a need for proactive, reliability-oriented methodologies capable of identifying and mitigating failure scenarios before patient safety is compromised. This paper presents M-GENGAR, a methodology based on a closed-loop Digital Twin (DT) paradigm for dependability assurance of medical CPSs. The approach combines Stochastic Hybrid Automata modeling, data-driven learning of patient dynamics, and Statistical Model Checking with an offline critical scenario detection phase that integrates model-space exploration and diversity analysis to systematically identify and classify scenarios violating expert-defined dependability requirements. M-GENGAR also supports the automated synthesis of mitigation strategies, enabling runtime feedback and control within the DT loop. We evaluate M-GENGAR on a representative use case study involving a pulmonary ventilator. Results show that, in 87.5% of the evaluated scenarios, strategies synthesized through formal game-theoretic analysis stabilize patient vital metrics at least as effectively as human decision-making, while maintaining relevant metrics 20% closer to nominal healthy values on average.", "AI": {"tldr": "M-GENGAR\uff1a\u57fa\u4e8e\u6570\u5b57\u5b6a\u751f\u7684\u533b\u7597CPS\u53ef\u9760\u6027\u4fdd\u969c\u65b9\u6cd5\uff0c\u901a\u8fc7\u5f62\u5f0f\u5316\u5efa\u6a21\u3001\u573a\u666f\u68c0\u6d4b\u548c\u7f13\u89e3\u7b56\u7565\u5408\u6210\uff0c\u5728\u547c\u5438\u673a\u6848\u4f8b\u4e2d87.5%\u7684\u573a\u666f\u4e0b\u8868\u73b0\u4f18\u4e8e\u4eba\u7c7b\u51b3\u7b56\u3002", "motivation": "\u533b\u7597CPS\uff08\u60a3\u8005-\u8bbe\u5907-\u533b\u751f\u4e09\u5143\u7ec4\uff09\u5b58\u5728\u7cfb\u7edf\u5f02\u6784\u6027\u548c\u4eba\u673a\u884c\u4e3a\u4e0d\u786e\u5b9a\u6027\uff0c\u73b0\u6709\u4e34\u5e8a\u51b3\u7b56\u652f\u6301\u7cfb\u7edf\u7f3a\u4e4f\u4e3b\u52a8\u53ef\u9760\u6027\u4fdd\u969c\u65b9\u6cd5\uff0c\u9700\u8981\u5728\u60a3\u8005\u5b89\u5168\u53d7\u635f\u524d\u8bc6\u522b\u548c\u7f13\u89e3\u6545\u969c\u573a\u666f\u3002", "method": "\u57fa\u4e8e\u95ed\u73af\u6570\u5b57\u5b6a\u751f\u8303\u5f0f\uff0c\u7ed3\u5408\u968f\u673a\u6df7\u5408\u81ea\u52a8\u673a\u5efa\u6a21\u3001\u6570\u636e\u9a71\u52a8\u7684\u60a3\u8005\u52a8\u6001\u5b66\u4e60\u3001\u7edf\u8ba1\u6a21\u578b\u68c0\u67e5\uff0c\u901a\u8fc7\u79bb\u7ebf\u5173\u952e\u573a\u666f\u68c0\u6d4b\uff08\u6a21\u578b\u7a7a\u95f4\u63a2\u7d22\u548c\u591a\u6837\u6027\u5206\u6790\uff09\u8bc6\u522b\u8fdd\u53cd\u53ef\u9760\u6027\u8981\u6c42\u7684\u573a\u666f\uff0c\u5e76\u81ea\u52a8\u5408\u6210\u7f13\u89e3\u7b56\u7565\u3002", "result": "\u5728\u547c\u5438\u673a\u7528\u4f8b\u8bc4\u4f30\u4e2d\uff0c87.5%\u7684\u573a\u666f\u4e0b\uff0c\u901a\u8fc7\u5f62\u5f0f\u5316\u535a\u5f08\u8bba\u5206\u6790\u5408\u6210\u7684\u7b56\u7565\u5728\u7a33\u5b9a\u60a3\u8005\u751f\u547d\u4f53\u5f81\u65b9\u9762\u81f3\u5c11\u4e0e\u4eba\u7c7b\u51b3\u7b56\u540c\u7b49\u6709\u6548\uff0c\u4e14\u76f8\u5173\u6307\u6807\u5e73\u5747\u6bd4\u6b63\u5e38\u5065\u5eb7\u503c\u63a5\u8fd120%\u3002", "conclusion": "M-GENGAR\u4e3a\u533b\u7597CPS\u63d0\u4f9b\u4e86\u4e00\u79cd\u4e3b\u52a8\u7684\u53ef\u9760\u6027\u4fdd\u969c\u65b9\u6cd5\uff0c\u80fd\u591f\u7cfb\u7edf\u8bc6\u522b\u5173\u952e\u6545\u969c\u573a\u666f\u5e76\u81ea\u52a8\u5408\u6210\u6709\u6548\u7684\u7f13\u89e3\u7b56\u7565\uff0c\u5728\u547c\u5438\u673a\u6848\u4f8b\u4e2d\u9a8c\u8bc1\u4e86\u5176\u4f18\u4e8e\u4eba\u7c7b\u51b3\u7b56\u7684\u6f5c\u529b\u3002"}}
{"id": "2602.21074", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.21074", "abs": "https://arxiv.org/abs/2602.21074", "authors": ["Ana D\u00edaz-Mu\u00f1oz", "Jos\u00e9 A. Cruz-Lemus", "Mois\u00e9s Rodr\u00edguez", "Maria Teresa Baldassarre", "Mario Piattini"], "title": "Validation of an analyzability model for quantum software: a family of experiments", "comment": "42 pages, 5 figures, 12 tables. This is the Author Accepted Manuscript (AAM) of the article published in Empirical Software Engineering (2026). The final published version is available at https://doi.org/10.1007/s10664-026-10825-3", "summary": "The analyzability of hybrid software, which integrates both classical and quantum components, is a key factor in ensuring its maintainability and industrial adoption. This article presents the empirical validation, through a family of experiments, of the quantum component of a previously proposed hybrid software analyzability model based on the ISO/IEC 25010 standard. The experimental series consists of four studies involving participants with diverse profiles in both academic and professional settings. In these experiments, the model's ability to effectively measure the analyzability of quantum algorithms is assessed, and the relationship between the analyzability levels computed by the model and the participant's perceptions of the complexity of these algorithms is examined. The results indicate that the proposed model effectively distinguishes between quantum software components with varying levels of analyzability and aligns with human perception, reinforcing its validity in quantum computing.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7\u7cfb\u5217\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u57fa\u4e8eISO/IEC 25010\u6807\u51c6\u7684\u6df7\u5408\u8f6f\u4ef6\u53ef\u5206\u6790\u6027\u6a21\u578b\u4e2d\u91cf\u5b50\u7ec4\u4ef6\u90e8\u5206\u7684\u6709\u6548\u6027\uff0c\u8bc1\u660e\u8be5\u6a21\u578b\u80fd\u6709\u6548\u533a\u5206\u4e0d\u540c\u53ef\u5206\u6790\u6027\u6c34\u5e73\u7684\u91cf\u5b50\u7b97\u6cd5\uff0c\u5e76\u4e0e\u4eba\u7c7b\u611f\u77e5\u4e00\u81f4\u3002", "motivation": "\u6df7\u5408\u8f6f\u4ef6\uff08\u7ed3\u5408\u7ecf\u5178\u548c\u91cf\u5b50\u7ec4\u4ef6\uff09\u7684\u53ef\u5206\u6790\u6027\u662f\u5176\u53ef\u7ef4\u62a4\u6027\u548c\u5de5\u4e1a\u5e94\u7528\u7684\u5173\u952e\u56e0\u7d20\u3002\u9700\u8981\u9a8c\u8bc1\u5148\u524d\u63d0\u51fa\u7684\u57fa\u4e8eISO/IEC 25010\u6807\u51c6\u7684\u6df7\u5408\u8f6f\u4ef6\u53ef\u5206\u6790\u6027\u6a21\u578b\u4e2d\u91cf\u5b50\u7ec4\u4ef6\u7684\u6709\u6548\u6027\u3002", "method": "\u91c7\u7528\u7cfb\u5217\u5b9e\u9a8c\u65b9\u6cd5\uff0c\u5305\u542b\u56db\u9879\u7814\u7a76\uff0c\u6d89\u53ca\u5b66\u672f\u548c\u4e13\u4e1a\u73af\u5883\u4e2d\u4e0d\u540c\u80cc\u666f\u7684\u53c2\u4e0e\u8005\u3002\u8bc4\u4f30\u6a21\u578b\u6d4b\u91cf\u91cf\u5b50\u7b97\u6cd5\u53ef\u5206\u6790\u6027\u7684\u80fd\u529b\uff0c\u5e76\u68c0\u9a8c\u6a21\u578b\u8ba1\u7b97\u7684\u53ef\u5206\u6790\u6027\u6c34\u5e73\u4e0e\u53c2\u4e0e\u8005\u5bf9\u7b97\u6cd5\u590d\u6742\u6027\u611f\u77e5\u4e4b\u95f4\u7684\u5173\u7cfb\u3002", "result": "\u7ed3\u679c\u8868\u660e\uff0c\u63d0\u51fa\u7684\u6a21\u578b\u80fd\u6709\u6548\u533a\u5206\u5177\u6709\u4e0d\u540c\u53ef\u5206\u6790\u6027\u6c34\u5e73\u7684\u91cf\u5b50\u8f6f\u4ef6\u7ec4\u4ef6\uff0c\u5e76\u4e14\u4e0e\u4eba\u7c7b\u611f\u77e5\u4fdd\u6301\u4e00\u81f4\uff0c\u589e\u5f3a\u4e86\u5176\u5728\u91cf\u5b50\u8ba1\u7b97\u9886\u57df\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u901a\u8fc7\u5b9e\u8bc1\u9a8c\u8bc1\u4e86\u6df7\u5408\u8f6f\u4ef6\u53ef\u5206\u6790\u6027\u6a21\u578b\u4e2d\u91cf\u5b50\u7ec4\u4ef6\u7684\u6709\u6548\u6027\uff0c\u4e3a\u91cf\u5b50\u8f6f\u4ef6\u5de5\u7a0b\u63d0\u4f9b\u4e86\u53ef\u9760\u7684\u5206\u6790\u5de5\u5177\uff0c\u6709\u52a9\u4e8e\u4fc3\u8fdb\u91cf\u5b50\u8f6f\u4ef6\u7684\u5de5\u4e1a\u5e94\u7528\u3002"}}
