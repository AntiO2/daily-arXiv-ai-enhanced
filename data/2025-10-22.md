<div id=toc></div>

# Table of Contents

- [cs.SE](#cs.SE) [Total: 33]
- [cs.DB](#cs.DB) [Total: 1]
- [cs.DC](#cs.DC) [Total: 8]


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [1] [AI Exchange Platforms](https://arxiv.org/abs/2510.17839)
*Johannes Schneider,Rene Abraham*

Main category: cs.SE

TL;DR: 该论文提出了一个AI模型交换平台的分类框架，分析了平台的关键维度和特征，揭示了研究机构与组织之间的互动模式，为从业者和学者提供了理解AI交换平台挑战与机遇的基础。


<details>
  <summary>Details</summary>
Motivation: 随着基础模型的兴起，AI模型交换平台对组织效能和适应性变得至关重要，但目前缺乏对这些平台进行系统分类和理解的综合框架。

Method: 开发了一个分类法来系统化地分类AI交换平台，考察关键维度和特征，并分析公共研究机构与组织之间的互动模式。

Result: 识别了平台利用同行评审进行质量控制的关键特征，以及提供在线测试、部署和模型定制化机制的功能，揭示了不同利益相关者之间的协作模式。

Conclusion: 该分类法为理解AI模型交换平台提供了结构化方法，为从业者提供了实践指导，为学者提供了进一步研究的基础，并强调了平台设计中适应性和创新的重要性。

Abstract: The rapid integration of Artificial Intelligence (AI) into organizational
technology frameworks has transformed how organizations engage with AI-driven
models, influencing both operational performance and strategic innovation. With
the advent of foundation models, the importance of structured platforms for AI
model exchange has become paramount for organizational efficacy and
adaptability. However, a comprehensive framework to categorize and understand
these platforms remains underexplored. To address this gap, our taxonomy
provides a structured approach to categorize AI exchange platforms, examining
key dimensions and characteristics, as well as revealing interesting
interaction patterns between public research institutions and organizations:
Some platforms leverage peer review as a mechanism for quality control, and
provide mechanisms for online testing, deploying, and customization of models.
Our paper is beneficial to practitioners seeking to understand challenges and
opportunities that arise from AI exchange platforms. For academics, the
taxonomy serves as a foundation for further research into the evolution,
impact, and best practices associated with AI model sharing and utilization in
different contexts. Additionally, our study provides insights into the evolving
role of AI in various industries, highlighting the importance of adaptability
and innovation in platform design. This paper serves as a critical resource for
understanding the dynamic interplay between technology, business models, and
user engagement in the rapidly growing domain of AI model exchanges pointing
also towards possible future evolution.

</details>


### [2] [Vibe Coding: Toward an AI-Native Paradigm for Semantic and Intent-Driven Programming](https://arxiv.org/abs/2510.17842)
*Vinay Bamil*

Main category: cs.SE

TL;DR: 本文介绍了vibe coding这一新兴的AI原生编程范式，开发者通过指定高级功能意图和定性描述来生成软件，并提出了参考架构和实现方案。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型的发展，开发者可以通过与AI系统对话而非直接编写代码来生成软件，这催生了新的编程范式需求。

Method: 提出了vibe coding的定义和参考架构，包括意图解析器、语义嵌入引擎、智能代码生成器和交互反馈循环，并描述了假设实现方案。

Result: 与声明式、函数式和基于提示的编程进行了比较，分析了其对软件工程、人机协作和负责任AI实践的影响，并讨论了生产率的提升和民主化效应。

Conclusion: 识别了对齐、可复现性、偏见、可解释性、可维护性和安全性等关键挑战，并概述了未来研究方向和开放性问题。

Abstract: Recent advances in large language models have enabled developers to generate
software by conversing with artificial intelligence systems rather than writing
code directly. This paper introduces vibe coding, an emerging AI-native
programming paradigm in which a developer specifies high-level functional
intent along with qualitative descriptors of the desired "vibe" (tone, style,
or emotional resonance). An intelligent agent then transforms those
specifications into executable software. We formalize the definition of vibe
coding and propose a reference architecture that includes an intent parser, a
semantic embedding engine, an agentic code generator, and an interactive
feedback loop. A hypothetical implementation is described. We compare vibe
coding with declarative, functional, and prompt-based programming, and we
discuss its implications for software engineering, human-AI collaboration, and
responsible AI practice. Finally, we examine reported productivity gains and
democratizing effects, review recent studies that highlight vulnerabilities and
potential slowdowns, identify key challenges such as alignment,
reproducibility, bias, explainability, maintainability, and security, and
outline future directions and open research questions.

</details>


### [3] [Smart Contracts Formal Verification: A Systematic Literature Review](https://arxiv.org/abs/2510.17865)
*Rene Davila,Everardo Barcenas,Rocio Aldeco-Perez*

Main category: cs.SE

TL;DR: 本文对智能合约的形式化验证方法进行了综述研究，并提出了一种基于描述逻辑的替代性形式化验证方法。


<details>
  <summary>Details</summary>
Motivation: 智能合约作为在区块链平台上运行的自动执行合约，经常在其操作或规范中存在显著错误，这促使我们研究相关的形式化验证方法。

Method: 通过审查各种来源发表的相关工作，详细分析规范、验证工具和相关实验，然后提出基于描述逻辑的形式化验证替代方案。

Result: 对现有智能合约形式化验证方法的系统综述，识别了当前方法的局限性。

Conclusion: 基于描述逻辑的形式化验证方法为智能合约验证提供了有前景的替代方案，能够更好地处理合约规范和操作中的错误。

Abstract: Formal verification entails testing software to ensure it operates as
specified. Smart contracts are self-executing contracts with the terms of the
agreement directly written into lines of code. They run on blockchain platforms
and automatically enforce and execute the terms of an agreement when meeting
predefined conditions. However, Smart Contracts, as software models, often
contain notable errors in their operation or specifications. This observation
prompts us to conduct a focused study examining related works published across
various sources. These publications detail specifications, verification tools,
and relevant experiments. Subsequently, this survey proposes an alternative
formal verification based on description logic.

</details>


### [4] [UniCode: A Framework for Generating High Quality Competitive Coding Problems](https://arxiv.org/abs/2510.17868)
*Xinyue Zheng,Haowei Lin,Shaofei Cai,Zilong Zheng,Yitao Liang*

Main category: cs.SE

TL;DR: UniCode是一个自动生成高质量算法问题和抗污染测试用例的框架，通过LLM使用三种策略多样化问题生成，并采用压力驱动的测试用例合成管道确保可靠性。


<details>
  <summary>Details</summary>
Motivation: 解决传统编程基准测试依赖静态人工编写问题导致的数据污染和可扩展性限制问题。

Method: 利用LLM通过单问题扩展、同类型融合和跨类型融合三种策略多样化问题生成；采用压力驱动测试用例合成管道，结合小规模输入的暴力基础验证和大规模输入的共识验证机制。

Result: 构建了包含492个问题的基准测试，评估19个最先进LLM，其中表现最好的o4-mini模型仅达到70.3%的通过率。

Conclusion: UniCode提供了一个可扩展且可靠的解决方案，用于在编程领域生成动态评估数据集。

Abstract: The reliance of competitive coding benchmarks on static, human-authored
problems creates significant challenges, including data contamination and
limited scalability. To address these issues, we introduce UniCode, a novel
framework that automatically generates high-quality algorithmic problems
alongside robust, contamination-resistant test cases. Inspired by biological
evolution that creates better and diverse offspring, our framework leverages
Large Language Models (LLMs) to systematically diversify problems through three
strategies: single problem extension, same-type fusion, and cross-type fusion.
A key innovation is our stress-driven test case synthesis pipeline, which
generates reliable test suites without requiring a canonical ground-truth
solution. This pipeline combines brute-force grounding for small-scale inputs
with a consensus-based validation mechanism for large-scale inputs to ensure
high correctness and coverage. We demonstrate effectiveness of our framework by
curating a benchmark of 492 problems and evaluating 19 state-of-the-art LLMs.
The results reveal that UniCode is highly challenging and discriminative, with
the top-performing model, o4-mini, achieving a pass rate of only 70.3%. Our
framework provides a scalable and reliable solution for generating dynamic
evaluation datasets in coding domain.

</details>


### [5] [Repairing Tool Calls Using Post-tool Execution Reflection and RAG](https://arxiv.org/abs/2510.17874)
*Jason Tsay,Zidane Wright,Gaodan Fang,Kiran Kate,Saurabh Jha,Yara Rizk*

Main category: cs.SE

TL;DR: 开发了一个后工具执行反思组件，结合LLM反思和领域特定的RAG，使用工具文档和故障排除文档来修复kubectl命令执行中的语义错误。


<details>
  <summary>Details</summary>
Motivation: 代理系统调用工具时经常因各种语法和语义原因失败，一些语义错误只能在分析工具响应后才能识别和解决。

Method: 结合LLM反思和领域特定的检索增强生成(RAG)，使用kubectl工具文档和故障排除文档来修复命令错误。

Result: RAG反思修复了kubectl命令，使执行成功率提高55%，正确回答用户查询的可能性平均提高36%。故障排除文档比官方文档平均提高10%的成功率。

Conclusion: 结合LLM反思和领域特定RAG的方法能有效修复工具调用中的语义错误，显著提高命令执行成功率和问题解决准确性。

Abstract: Agentic systems interact with external systems by calling tools such as
Python functions, REST API endpoints, or command line tools such as kubectl in
Kubernetes. These tool calls often fail for various syntactic and semantic
reasons. Some less obvious semantic errors can only be identified and resolved
after analyzing the tool's response. To repair these errors, we develop a
post-tool execution reflection component that combines large language model
(LLM)-based reflection with domain-specific retrieval-augmented generation
(RAG) using documents describing both the specific tool being called and
troubleshooting documents related to the tool. For this paper, we focus on the
use case of the kubectl command line tool to manage Kubernetes, a platform for
orchestrating cluster applications. Through a larger empirical study and a
smaller manual evaluation, we find that our RAG-based reflection will repair
kubectl commands such that they are both more likely to successfully execute
(pass rate) for 55% of our models evaluated and 36% more likely to correctly
answer the user query on average. We find that troubleshooting documents
improve pass rate compared to official documentation by an average of 10%.

</details>


### [6] [TritonRL: Training LLMs to Think and Code Triton Without Cheating](https://arxiv.org/abs/2510.17891)
*Jiin Woo,Shaowei Zhu,Allen Nie,Zhen Jia,Yida Wang,Youngsuk Park*

Main category: cs.SE

TL;DR: TritonRL是一个专门用于Triton内核生成的领域专用大语言模型，通过监督微调和强化学习训练框架，能够生成高质量的可替代现有模块的Triton内核。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型的快速发展，对自动化高性能系统内核的需求成为加速开发和部署的关键推动因素。Triton内核生成面临数据稀缺和评估标准不完整等独特挑战，容易受到奖励攻击。

Method: 通过监督微调在精选数据集上蒸馏Triton特定知识，然后通过强化学习改进代码质量，使用稳健可验证的奖励和分层奖励分配，通过细粒度验证和分层奖励分解指导推理轨迹和代码标记。

Result: 在KernelBench上的实验表明，TritonRL在正确性和加速方面达到了最先进水平，超越了所有其他Triton专用模型。

Conclusion: 该研究证明了基于强化学习的训练范式的有效性，能够生成真正可替代现有模块的高质量Triton内核。

Abstract: With the rapid evolution of large language models (LLMs), the demand for
automated, high-performance system kernels has emerged as a key enabler for
accelerating development and deployment. We introduce TritonRL, a
domain-specialized LLM for Triton kernel generation, trained with a novel
training framework that enables robust and automated kernel synthesis. Unlike
general-purpose programming languages, Triton kernel generation faces unique
challenges due to data scarcity and incomplete evaluation criteria, vulnerable
to reward hacking. Our approach addresses these challenges end-to-end by
distilling Triton-specific knowledge through supervised fine-tuning on curated
datasets, and further improving code quality via reinforcement learning (RL)
with robust, verifiable rewards and hierarchical reward assignment. Our RL
framework robustly detects reward hacking and guides both reasoning traces and
code tokens through fine-grained verification and hierarchical reward
decomposition, enabling the model to generate high-quality Triton kernels that
can truly replace existing modules. With robust and fine-grained evaluation,
our experiments on KernelBench demonstrate that TritonRL achieves
state-of-the-art correctness and speedup, surpassing all other Triton-specific
models and underscoring the effectiveness of our RL-based training paradigm.

</details>


### [7] [A Systematic Literature Review of the Use of GenAI Assistants for Code Comprehension: Implications for Computing Education Research and Practice](https://arxiv.org/abs/2510.17894)
*Yunhan Qiao,Md Istiak Hossain Shihab,Christopher Hundhausen*

Main category: cs.SE

TL;DR: 这篇论文通过系统文献综述分析了2022-2024年间31项研究，探讨了GenAI在代码理解中的应用，发现虽然GenAI工具有潜力，但常产生不准确或模糊的解释，且新手程序员难以设计有效提示。


<details>
  <summary>Details</summary>
Motivation: 随着程序员越来越多地依赖GenAI助手开发代码解决方案，理解GenAI生成的代码变得至关重要，同时GenAI工具也被用于提供代码解释。在计算教育中，GenAI为学习者理解程序带来了新的挑战和机遇。

Method: 采用系统文献综述方法，对2022-2024年间发表的31项研究进行分析，分类基于GenAI的方法和工具，识别研究方法，并总结其有效性的实证评估。

Result: 研究发现GenAI助手经常产生不准确或不清楚的解释，新手程序员在制作有效提示方面存在困难，这阻碍了他们利用GenAI辅助代码理解的能力。

Conclusion: 研究结果为计算教育工作者提供了基于证据的指导，以使用GenAI促进代码理解，并确定了未来研究的方向。

Abstract: The ability to comprehend code has long been recognized as an essential skill
in software engineering. As programmers lean more heavily on generative
artificial intelligence (GenAI) assistants to develop code solutions, it is
becoming increasingly important for programmers to comprehend GenAI solutions
so that they can verify their appropriateness and properly integrate them into
existing code. At the same time, GenAI tools are increasingly being enlisted to
provide programmers with tailored explanations of code written both by GenAI
and humans. Thus, in computing education, GenAI presents new challenges and
opportunities for learners who are trying to comprehend computer programs. To
provide computing educators with evidence-based guidance on the use of GenAI to
facilitate code comprehension and to identify directions for future research,
we present a systematic literature review (SLR) of state-of-the-art approaches
and tools that leverage GenAI to enhance code comprehension. Our SLR focuses on
31 studies published between 2022 and 2024. Despite their potential, GenAI
assistants often yield inaccurate or unclear explanations, and novice
programmers frequently struggle to craft effective prompts, thereby impeding
their ability to leverage GenAI to aid code comprehension. Our review
classifies GenAI-based approaches and tools, identifies methods used to study
them, and summarizes the empirical evaluations of their effectiveness. We
consider the implications of our findings for computing education research and
practice, and identify directions for future research.

</details>


### [8] [SpecAgent: A Speculative Retrieval and Forecasting Agent for Code Completion](https://arxiv.org/abs/2510.17925)
*George Ma,Anurag Koul,Qi Chen,Yawen Wu,Sachit Kuhar,Yu Yu,Aritra Sengupta,Varun Kumar,Murali Krishna Ramanathan*

Main category: cs.SE

TL;DR: SpecAgent通过索引时异步探索仓库文件构建推测性上下文，在降低推理延迟的同时提升代码生成质量，相比基线方法获得9-11%的绝对性能提升。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在真实软件仓库中表现不佳，因为项目特定API和跨文件依赖关系至关重要。检索增强方法在推理时注入仓库上下文，但低延迟预算会影响检索质量或用户体验。

Method: SpecAgent在索引时主动探索仓库文件，构建推测性上下文来预测每个文件中的未来编辑。这种索引时异步性允许充分计算上下文，掩盖延迟，推测性上下文提升代码生成质量。

Result: 实验显示SpecAgent相比最佳基线方法获得9-11%的绝对性能提升（48-58%相对提升），同时显著降低推理延迟。

Conclusion: SpecAgent通过索引时异步构建推测性上下文的方法，有效解决了代码生成中的延迟和质量权衡问题，并在无泄漏基准上验证了其优越性能。

Abstract: Large Language Models (LLMs) excel at code-related tasks but often struggle
in realistic software repositories, where project-specific APIs and cross-file
dependencies are crucial. Retrieval-augmented methods mitigate this by
injecting repository context at inference time. The low inference-time latency
budget affects either retrieval quality or the added latency adversely impacts
user experience. We address this limitation with SpecAgent, an agent that
improves both latency and code-generation quality by proactively exploring
repository files during indexing and constructing speculative context that
anticipates future edits in each file. This indexing-time asynchrony allows
thorough context computation, masking latency, and the speculative nature of
the context improves code-generation quality. Additionally, we identify the
problem of future context leakage in existing benchmarks, which can inflate
reported performance. To address this, we construct a synthetic, leakage-free
benchmark that enables a more realistic evaluation of our agent against
baselines. Experiments show that SpecAgent consistently achieves absolute gains
of 9-11% (48-58% relative) compared to the best-performing baselines, while
significantly reducing inference latency.

</details>


### [9] [From Charts to Code: A Hierarchical Benchmark for Multimodal Models](https://arxiv.org/abs/2510.17932)
*Jiahao Tang,Henry Hengyuan Zhao,Lijian Wu,Yifei Tao,Dongxing Mao,Yang Wan,Jingru Tan,Min Zeng,Min Li,Alex Jinpeng Wang*

Main category: cs.SE

TL;DR: Chart2Code是一个新的多模态模型评估基准，专注于图表理解和代码生成能力，包含三个难度递增的任务级别和2023个任务，评估25个最先进模型。


<details>
  <summary>Details</summary>
Motivation: 从用户驱动角度设计，捕捉真实世界场景，系统性地增加任务难度，填补现有基准在图表到代码转换评估方面的空白。

Method: 构建包含三个层次的任务：图表复制、图表编辑和长表格到图表生成，涵盖22种图表类型，使用多级评估指标评估代码正确性和视觉保真度。

Result: 实验结果显示，即使是当前最先进的GPT-5模型在编辑任务上的平均得分也仅为0.57（基于代码）和0.22（基于图表质量），表明该基准具有挑战性。

Conclusion: Chart2Code基准将推动多模态推理的发展，促进更鲁棒和通用的多模态模型的开发。

Abstract: We introduce Chart2Code, a new benchmark for evaluating the chart
understanding and code generation capabilities of large multimodal models
(LMMs). Chart2Code is explicitly designed from a user-driven perspective,
capturing diverse real-world scenarios and progressively increasing task
difficulty. It consists of three levels: Level 1 (Chart Reproduction)
reproduces charts from a reference figure and user query; Level 2 (Chart
Editing) involves complex modifications such as changing chart types or adding
elements; and Level 3 (Long-Table to Chart Generation) requires models to
transform long, information-dense tables into faithful charts following user
instructions. To our knowledge, this is the first hierarchical benchmark that
reflects practical chart2code usage while systematically scaling task
complexity. In total, Chart2Code contains 2,023 tasks across 22 chart types,
paired with multi-level evaluation metrics that assess both code correctness
and the visual fidelity of rendered charts. We benchmark 25 state-of-the-art
(SoTA) LMMs, including both proprietary and the latest open-source models such
as GPT-5, Qwen2.5-VL, InternVL3/3.5, MiMo-VL, and Seed-1.6-VL. Experimental
results demonstrate that even the SoTA model GPT-5 averages only 0.57 on
code-based evaluation and 0.22 on chart-quality assessment across the editing
tasks, underscoring the difficulty of Chart2Code. We anticipate this benchmark
will drive advances in multimodal reasoning and foster the development of more
robust and general-purpose LMMs. Our code and data are available on Chart2Code.

</details>


### [10] [JunoBench: A Benchmark Dataset of Crashes in Python Machine Learning Jupyter Notebooks](https://arxiv.org/abs/2510.18013)
*Yiran Wang,José Antonio Hernández López,Ulf Nilsson,Dániel Varró*

Main category: cs.SE

TL;DR: JunoBench是首个针对Python机器学习笔记本中真实崩溃的基准数据集，包含111个来自Kaggle笔记本的经过整理且可复现的崩溃案例，每个案例都配有可验证的修复方案，涵盖主流ML库和笔记本特有的执行顺序问题。


<details>
  <summary>Details</summary>
Motivation: 机器学习笔记本（如Jupyter）广泛用于原型开发，但缺乏专门针对ML代码的调试工具，主要原因是缺乏相关基准数据集。

Method: 从公开Kaggle笔记本中收集真实崩溃案例，进行整理和验证，为每个崩溃提供可复现的修复方案，并构建统一的执行环境以确保可复现性。

Result: 创建了包含111个崩溃案例的JunoBench数据集，涵盖TensorFlow/Keras、PyTorch、Scikit-learn、Pandas、NumPy等主流ML库，以及笔记本特有的执行顺序问题。

Conclusion: JunoBench通过提供真实的崩溃案例及其解决方案，为基于笔记本的交互式ML开发中的错误检测、定位和修复提供了有力支持。

Abstract: Jupyter notebooks are widely used for machine learning (ML) prototyping. Yet
few debugging tools are designed for ML code in notebooks, potentially due to
the lack of benchmarks. We introduce JunoBench, the first benchmark dataset of
real-world crashes in Python-based ML notebooks. JunoBench has 111 curated and
reproducible crashes from public Kaggle notebooks, each paired with a
verifiable fix, ranging over popular ML libraries, including TensorFlow/Keras,
PyTorch, Scikit-learn, Pandas, and NumPy, as well as notebook-specific
out-of-order execution issue. To support reproducibility and ease of use,
JunoBench offers a unified execution environment where crashes and fixes can be
reliably reproduced. By providing realistic crashes and their resolutions,
JunoBench facilitates bug detection, localization, and repair tailored to the
interactive and iterative nature of notebook-based ML development.

</details>


### [11] [DIP-AI: A Discovery Framework for AI Innovation Projects](https://arxiv.org/abs/2510.18017)
*Mariana Crisostomo Martins,Lucas Elias Cardoso Rocha,Lucas Cordeiro Romao,Taciana Novo Kudo,Marcos Kalinowski,Renato de Freitas Bulcao-Neto*

Main category: cs.SE

TL;DR: 提出了DIP-AI框架，专门用于指导AI创新项目的早期探索阶段，帮助发现问题和需求，旨在提高交付质量和利益相关者满意度。


<details>
  <summary>Details</summary>
Motivation: 随着AI系统的发展，需求工程活动在数据密集型范式下面临挑战，特别是在问题发现方面缺乏支持。

Method: 基于文献综述，结合ISO 12207、5338和设计思维元素，提出了DIP-AI发现框架，并在产业-学术合作的AI创新项目案例研究中进行了评估。

Result: 评估结果表明DIP-AI具有相关性和实用性，特别是在促进AI项目问题发现方面表现良好。

Conclusion: DIP-AI框架为AI问题发现提供了有效支持，对学术界和产业界都有重要贡献。

Abstract: Despite the increasing development of Artificial Intelligence (AI) systems,
Requirements Engineering (RE) activities face challenges in this new
data-intensive paradigm. We identified a lack of support for problem discovery
within AI innovation projects. To address this, we propose and evaluate DIP-AI,
a discovery framework tailored to guide early-stage exploration in such
initiatives. Based on a literature review, our solution proposal combines
elements of ISO 12207, 5338, and Design Thinking to support the discovery of AI
innovation projects, aiming at promoting higher quality deliveries and
stakeholder satisfaction. We evaluated DIP-AI in an industry-academia
collaboration (IAC) case study of an AI innovation project, in which
participants applied DIP-AI to the discovery phase in practice and provided
their perceptions about the approach's problem discovery capability,
acceptance, and suggestions. The results indicate that DIP-AI is relevant and
useful, particularly in facilitating problem discovery in AI projects. This
research contributes to academia by sharing DIP-AI as a framework for AI
problem discovery. For industry, we discuss the use of this framework in a real
IAC program that develops AI innovation projects.

</details>


### [12] [A Benchmark Dataset And LLMs Comparison For NFR Classification With Explainable AI](https://arxiv.org/abs/2510.18096)
*Esrat Ebtida Sakib,MD Ahnaf Akib,Md Muktadir Mazumder,Maliha Noushin Raida,Md. Mohsinul Kabir*

Main category: cs.SE

TL;DR: 该论文通过增强现有NFR数据集，使用多种大型语言模型对非功能性需求进行分类比较，其中Gemma-2和Phi-3表现最佳。


<details>
  <summary>Details</summary>
Motivation: 手动识别非功能性需求耗时且易错，需要自动化解决方案，而构建高质量数据集是实现自动化的前提。

Method: 从项目章程和开源软件文档收集NFR数据，使用RoBERTa、CodeBERT、Gemma-2、Phi-3、Mistral-8B和Llama-3.1-8B等LLM进行分类，并比较其性能。

Result: Gemma-2表现最佳（精确率0.87，召回率0.89，F1分数0.88），Phi-3紧随其后（精确率0.85，召回率0.87，F1分数0.86）。

Conclusion: 通过改进上下文基础，增强了模型对技术方面和用户需求的理解，Gemma-2和Phi-3在NFR分类任务中表现优异。

Abstract: Non-Functional Requirements (NFRs) play a critical role in determining the
overall quality and user satisfaction of software systems. Accurately
identifying and classifying NFRs is essential to ensure that software meets
performance, usability, and reliability expectations. However, manual
identification of NFRs from documentation is time-consuming and prone to
errors, necessitating automated solutions. Before implementing any automated
solution, a robust and comprehensive dataset is essential. To build such a
dataset, we collected NFRs from various Project Charters and Open Source
Software Documentation. This enhanced the technical depth and usability of an
already existing NFR dataset. We categorized NFRs into sub-classes and
identified needs using widely used Large Language Models to facilitate
automation. After classifying the NFRs, we compared the classification results
of the selected LLMs: RoBERTa, CodeBERT, Gemma-2, Phi-3, Mistral-8B, and
Llama-3.1-8B using various evaluation metrics, including precision, recall,
F1-score, and lime scores. Among these models, Gemma-2 achieved the best
results with a precision of 0.87, recall of 0.89, and F1-score of 0.88,
alongside a lime hit score of 78 out of 80. Phi-3 closely followed with a
precision of 0.85, recall of 0.87, F1-score of 0.86, and the highest lime hit
score of 79. By improving the contextual foundation, this integration enhanced
the model's comprehension of technical aspects and user requirements.

</details>


### [13] [BlueCodeAgent: A Blue Teaming Agent Enabled by Automated Red Teaming for CodeGen AI](https://arxiv.org/abs/2510.18131)
*Chengquan Guo,Yuzhou Nie,Chulin Xie,Zinan Lin,Wenbo Guo,Bo Li*

Main category: cs.SE

TL;DR: BlueCodeAgent是一个端到端的蓝队代理，通过自动化红队生成多样化风险实例，结合宪法和代码分析进行多层次防御，在代码相关安全任务中显著提升检测性能。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型越来越多地用于代码生成，安全风险担忧日益增长。目前研究主要集中在红队测试上，而蓝队防御方面进展有限，需要有效的语义理解来区分安全与不安全代码。

Method: 提出BlueCodeAgent框架，集成红队和蓝队：红队生成多样化风险实例，蓝队代理利用这些实例通过宪法和代码分析检测已知和未知风险场景，并集成动态分析减少误报。

Result: 在三个代表性代码相关任务（偏见指令检测、恶意指令检测、漏洞代码检测）中，BlueCodeAgent相比基础模型和基于安全提示的防御方法取得显著提升，在三个任务的四个数据集上平均F1分数提高12.7%。

Conclusion: 红队测试通过持续识别新漏洞来增强蓝队防御性能，BlueCodeAgent能够总结可操作的宪法来增强上下文感知的风险检测能力。

Abstract: As large language models (LLMs) are increasingly used for code generation,
concerns over the security risks have grown substantially. Early research has
primarily focused on red teaming, which aims to uncover and evaluate
vulnerabilities and risks of CodeGen models. However, progress on the blue
teaming side remains limited, as developing defense requires effective semantic
understanding to differentiate the unsafe from the safe. To fill in this gap,
we propose BlueCodeAgent, an end-to-end blue teaming agent enabled by automated
red teaming. Our framework integrates both sides: red teaming generates diverse
risky instances, while the blue teaming agent leverages these to detect
previously seen and unseen risk scenarios through constitution and code
analysis with agentic integration for multi-level defense. Our evaluation
across three representative code-related tasks--bias instruction detection,
malicious instruction detection, and vulnerable code detection--shows that
BlueCodeAgent achieves significant gains over the base models and safety
prompt-based defenses. In particular, for vulnerable code detection tasks,
BlueCodeAgent integrates dynamic analysis to effectively reduce false
positives, a challenging problem as base models tend to be over-conservative,
misclassifying safe code as unsafe. Overall, BlueCodeAgent achieves an average
12.7\% F1 score improvement across four datasets in three tasks, attributed to
its ability to summarize actionable constitutions that enhance context-aware
risk detection. We demonstrate that the red teaming benefits the blue teaming
by continuously identifying new vulnerabilities to enhance defense performance.

</details>


### [14] [When Old Meets New: Evaluating the Impact of Regression Tests on SWE Issue Resolution](https://arxiv.org/abs/2510.18270)
*Yang Chen,Toufique Ahmed,Reyhaneh Jabbarvand,Martin Hirzel*

Main category: cs.SE

TL;DR: TestPrune是一种自动化技术，通过利用问题跟踪报告和战略性地重用回归测试来进行bug复现和补丁验证，能够显著提高问题复现率和解决率。


<details>
  <summary>Details</summary>
Motivation: 现实项目中的测试套件虽然庞大且覆盖率高，但仍无法检测所有bug。回归测试除了确保功能保留外，还可用于调试当前版本，特别是增强新报告问题的复现测试生成和验证补丁不回归现有功能。

Method: TestPrune能够自动将回归测试套件最小化为小型、高度相关的测试子集，可集成到任何基于代理的bug修复流程中，正交提升整体性能。

Result: 在Otter框架中，TestPrune使问题复现率相对提高6.2%-9.0%；在Agentless框架中，问题解决率相对提高9.4%-12.9%。使用成本极低，每个SWE-Bench实例仅需$0.02-$0.05。

Conclusion: TestPrune通过智能重用回归测试，有效提升了bug修复流程的性能，且成本效益显著，特别适用于LLM驱动的调试环境。

Abstract: Test suites in real-world projects are often large and achieve high code
coverage, yet they remain insufficient for detecting all bugs. The abundance of
unresolved issues in open-source project trackers highlights this gap. While
regression tests are typically designed to ensure past functionality is
preserved in the new version, they can also serve a complementary purpose:
debugging the current version. Specifically, regression tests can (1) enhance
the generation of reproduction tests for newly reported issues, and (2)
validate that patches do not regress existing functionality. We present
TestPrune, a fully automated technique that leverages issue tracker reports and
strategically reuses regression tests for both bug reproduction and patch
validation.
  A key contribution of TestPrune is its ability to automatically minimize the
regression suite to a small, highly relevant subset of tests. Due to the
predominance of LLM-based debugging techniques, this minimization is essential
as large test suites exceed context limits, introduce noise, and inflate
inference costs. TestPrune can be plugged into any agentic bug repair pipeline
and orthogonally improve overall performance. As a proof of concept, we show
that TestPrune leads to a 6.2%-9.0% relative increase in issue reproduction
rate within the Otter framework and a 9.4% - 12.9% relative increase in issue
resolution rate within the Agentless framework on SWE-Bench Lite and SWE-Bench
Verified benchmarks, capturing fixes that were correctly produced by agents but
not submitted as final patches. Compared to the benefits, the cost overhead of
using TestPrune is minimal, i.e., \$0.02 and \$0.05 per SWE-Bench instance,
using GPT-4o and Claude-3.7-Sonnet models, respectively.

</details>


### [15] [Ensuring Robustness in ML-enabled Software Systems: A User Survey](https://arxiv.org/abs/2510.18292)
*Hala Abdelkader,Mohamed Abdelrazek,Priya Rani,Rajesh Vasa,Jean-Guy Schneider*

Main category: cs.SE

TL;DR: 提出ML-On-Rails协议，一个统一框架来增强生产环境中ML系统的鲁棒性和可信度，包含OOD检测、对抗攻击检测、输入验证和可解释性等安全措施。


<details>
  <summary>Details</summary>
Motivation: 传统软件工程方法无法应对ML组件的特殊挑战，如静默故障、分布外数据和对抗攻击，需要专门框架来确保ML系统的鲁棒性。

Method: 开发ML-On-Rails协议，集成多种安全措施，使用HTTP状态码进行模型-软件通信，并通过从业者调查验证方法有效性。

Result: 调查揭示了当前ML系统的主要鲁棒性问题，表明标准化协议如ML-On-Rails可以显著改善系统鲁棒性。

Conclusion: 需要为ML系统工程师提供更多支持和资源，未来将继续完善该协议以提升其在实际应用中的有效性。

Abstract: Ensuring robustness in ML-enabled software systems requires addressing
critical challenges, such as silent failures, out-of-distribution (OOD) data,
and adversarial attacks. Traditional software engineering practices, which rely
on predefined logic, are insufficient for ML components that depend on data and
probabilistic decision-making. To address these challenges, we propose the
ML-On-Rails protocol, a unified framework designed to enhance the robustness
and trustworthiness of ML-enabled systems in production. This protocol
integrates key safeguards such as OOD detection, adversarial attack detection,
input validation, and explainability. It also includes a model-to-software
communication framework using HTTP status codes to enhance transparency in
reporting model outcomes and errors. To align our approach with real-world
challenges, we conducted a practitioner survey, which revealed major robustness
issues, gaps in current solutions, and highlighted how a standardised protocol
such as ML-On-Rails can improve system robustness. Our findings highlight the
need for more support and resources for engineers working with ML systems.
Finally, we outline future directions for refining the proposed protocol,
leveraging insights from the survey and real-world applications to continually
enhance its effectiveness.

</details>


### [16] [InspectCoder: Dynamic Analysis-Enabled Self Repair through interactive LLM-Debugger Collaboration](https://arxiv.org/abs/2510.18327)
*Yunkun Wang,Yue Zhang,Guochang Li,Chen Zhi,Binhua Li,Fei Huang,Yongbin Li,Shuiguang Deng*

Main category: cs.SE

TL;DR: InspectCoder是首个基于LLM的代理式程序修复系统，通过交互式调试器控制实现动态分析，显著提升代码修复准确率和效率。


<details>
  <summary>Details</summary>
Motivation: 现有LLM自我修复方法主要依赖静态语义分析或表面执行日志，缺乏深入运行时行为分析，无法有效诊断复杂逻辑错误的根本原因。

Method: 采用双代理框架，通过交互式调试器控制实现战略性断点设置、目标状态检查和增量运行时实验，将LLM调试从盲目试错转变为系统性根本原因诊断。

Result: 在两个挑战性自修复基准测试中，修复准确率相对最强基线提升5.10%-60.37%，bug修复效率提升1.67x-2.24x。

Conclusion: LLM驱动的动态分析在自动化软件工程中具有巨大潜力，交互式LLM-调试器系统为程序修复提供了新的有效途径。

Abstract: Large Language Models (LLMs) frequently generate buggy code with complex
logic errors that are challenging to diagnose. While existing LLM-based
self-repair approaches conduct intensive static semantic analysis or reply on
superficial execution logs, they miss the in-depth runtime behaviors that often
expose bug root causes-lacking the interactive dynamic analysis capabilities
that make human debugging effective. We present InspectCoder, the first agentic
program repair system that empowers LLMs to actively conduct dynamic analysis
via interactive debugger control. Our dual-agent framework enables strategic
breakpoint placement, targeted state inspection, and incremental runtime
experimentation within stateful debugger sessions. Unlike existing methods that
follow fixed log collection procedures, InspectCoder adaptively inspects and
perturbs relevant intermediate states at runtime, and leverages immediate
process rewards from debugger feedback to guide multi-step reasoning,
transforming LLM debugging paradigm from blind trial-and-error into systematic
root cause diagnosis. We conduct comprehensive experiments on two challenging
self-repair benchmarks: BigCodeBench-R and LiveCodeBench-R. InspectCoder
achieves 5.10%-60.37% relative improvements in repair accuracy over the
strongest baseline, while delivering 1.67x-2.24x superior bug-fix efficiency
respectively. We also contribute InspectWare, an open-source middleware that
abstracts debugger complexities and maintains stateful debugging sessions
across mainstream Python testing frameworks. Our work provides actionable
insight into the interactive LLM-debugger systems, demonstrating the
significant potential of LLM-driven dynamic analysis for automated software
engineering.

</details>


### [17] [Human to Document, AI to Code: Three Case Studies of Comparing GenAI for Notebook Competitions](https://arxiv.org/abs/2510.18430)
*Tasha Settewong,Youmei Fan,Raula Gaikovina Kula,Kenichi Matsumoto*

Main category: cs.SE

TL;DR: 本研究通过三个案例研究分析了人类编写与GenAI生成的计算笔记本在代码和文档特征上的差异，发现人类笔记本在结构多样性和创新性方面表现更好，而GenAI在代码质量方面更优。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI技术的出现，在竞争环境中区分人类编写与GenAI生成笔记本的特征变得越来越重要，特别是在数据科学领域。

Method: 通过分析25个代码和文档特征，比较了人类编写的Kaggle获奖笔记本与GenAI生成笔记本的差异。

Result: 金牌得主主要通过更长更详细的文档来区分；GenAI笔记本代码质量更高，但人类笔记本在结构多样性、复杂性和创新性方面表现更好。

Conclusion: 本研究为探索如何最大化人类与AI在笔记本中的协作潜力奠定了基础，提出了四个进一步研究议程。

Abstract: Computational notebooks have become the preferred tool of choice for data
scientists and practitioners to perform analyses and share results. Notebooks
uniquely combine scripts with documentation. With the emergence of generative
AI (GenAI) technologies, it is increasingly important, especially in
competitive settings, to distinguish the characteristics of human-written
versus GenAI.
  In this study, we present three case studies to explore potential strengths
of both humans and GenAI through the coding and documenting activities in
notebooks. We first characterize differences between 25 code and documentation
features in human-written, medal-winning Kaggle notebooks. We find that gold
medalists are primarily distinguished by longer and more detailed
documentation. Second, we analyze the distinctions between human-written and
GenAI notebooks. Our results show that while GenAI notebooks tend to achieve
higher code quality (as measured by metrics like code smells and technical
debt), human-written notebooks display greater structural diversity,
complexity, and innovative approaches to problem-solving. Based on these
results, we envision the work as groundwork that highlight four agendas to
further investigate how GenAI could be utilized in notebooks that maximizes the
potential collaboration between human and AI.

</details>


### [18] [Real-World Usability of Vulnerability Proof-of-Concepts: A Comprehensive Study](https://arxiv.org/abs/2510.18448)
*Wenjing Dang,Kaixuan Li,Sen Chen,Zhenwei Zhuo,Lyuye Zhang,Zheli Liu*

Main category: cs.SE

TL;DR: 该论文首次对真实环境中的漏洞概念验证(PoC)进行了大规模研究，评估了PoC报告的可用性、完整性和可复现性，揭示了78.9%的CVE漏洞缺乏可用PoC，现有PoC报告缺失约30%关键组件，并提出了改进策略。


<details>
  <summary>Details</summary>
Motivation: 概念验证对验证漏洞存在、减少误报和展示安全威胁严重性至关重要，但PoC研究远落后于漏洞数据研究，主要挑战包括PoC分散在不同平台、写作风格多样以及复现困难。

Method: 1) 从13个平台收集470,921个PoC及其报告；2) 提出结合模式匹配和微调BERT-NER模型的组件提取方法，从PoC报告中提取9个关键组件；3) 招募8名参与者手动复现150个采样漏洞，分析PoC可复现性及影响因素。

Result: 研究发现78.9%的CVE漏洞缺乏可用PoC，现有PoC报告通常缺失约30%理解漏洞和复现所需的关键组件，并识别了使用可用PoC报告复现漏洞失败的各种原因。

Conclusion: 最后提出了利益相关者可采取的行动策略，以增强漏洞PoC在加强软件安全方面的整体可用性。

Abstract: The Proof-of-Concept (PoC) for a vulnerability is crucial in validating its
existence, mitigating false positives, and illustrating the severity of the
security threat it poses. However, research on PoCs significantly lags behind
studies focusing on vulnerability data. This discrepancy can be directly
attributed to several challenges, including the dispersion of real-world PoCs
across multiple platforms, the diversity in writing styles, and the difficulty
associated with PoC reproduction. To fill this gap, we conduct the first
large-scale study on PoCs in the wild, assessing their report availability,
completeness, reproducibility. Specifically, 1) to investigate PoC reports
availability for CVE vulnerability, we collected an extensive dataset of
470,921 PoCs and their reports from 13 platforms, representing the broadest
collection of publicly available PoCs to date. 2) To assess the completeness of
PoC report at a fine-grained level, we proposed a component extraction method,
which combines pattern-matching techniques with a fine-tuned BERT-NER model to
extract 9 key components from PoC reports. 3) To evaluate the effectiveness of
PoCs, we recruited 8 participants to manually reproduce 150 sampled
vulnerabilities with 32 vulnerability types based on PoC reports, enabling an
in-depth analysis of PoC reproducibility and the factors influencing it. Our
findings reveal that 78.9% of CVE vulnerabilities lack available PoCs, and
existing PoC reports typically miss about 30% of the essential components
required for effective vulnerability understanding and reproduction, with
various reasons identified for the failure to reproduce vulnerabilities using
available PoC reports. Finally, we proposed actionable strategies for
stakeholders to enhance the overall usability of vulnerability PoCs in
strengthening software security.

</details>


### [19] [Large Language Models in Thematic Analysis: Prompt Engineering, Evaluation, and Guidelines for Qualitative Software Engineering Research](https://arxiv.org/abs/2510.18456)
*Cristina Martinez Montes,Robert Feldt,Cristina Miguel Martos,Sofia Ouhbi,Shweta Premanandan,Daniel Graziotin*

Main category: cs.SE

TL;DR: 本研究开发了一种将大语言模型整合到主题分析中的可重复方法，通过系统评估发现LLM生成的代码在61%的情况下优于人工代码，但也存在数据碎片化、遗漏潜在解释等局限性。


<details>
  <summary>Details</summary>
Motivation: 随着AI发展，大语言模型开始进入质性研究流程，但缺乏将其整合到主题分析等成熟方法中的可重复方法，且现有研究缺乏对LLM生成质性输出的系统性质量评估。

Method: 设计并迭代优化了Braun和Clarke反思性主题分析第2-5阶段的提示词，使用15个软件工程师福祉访谈数据，通过四位专家评估员对多个LLM输出与有经验研究者生成的代码和主题进行盲评。

Result: 评估者在61%的情况下更偏好LLM生成的代码，认为其分析价值更高，但也发现LLM存在不必要的数据碎片化、遗漏潜在解释、主题边界不清等问题。

Conclusion: 提出了整合优化提示词与评估框架的可重复方法，提供了在软件工程数据中LLM与人工生成代码和主题的实证比较，并制定了在保持方法严谨性的前提下将LLM整合到质性分析的指南。

Abstract: As artificial intelligence advances, large language models (LLMs) are
entering qualitative research workflows, yet no reproducible methods exist for
integrating them into established approaches like thematic analysis (TA), one
of the most common qualitative methods in software engineering research.
Moreover, existing studies lack systematic evaluation of LLM-generated
qualitative outputs against established quality criteria. We designed and
iteratively refined prompts for Phases 2-5 of Braun and Clarke's reflexive TA,
then tested outputs from multiple LLMs against codes and themes produced by
experienced researchers. Using 15 interviews on software engineers' well-being,
we conducted blind evaluations with four expert evaluators who applied rubrics
derived directly from Braun and Clarke's quality criteria. Evaluators preferred
LLM-generated codes 61% of the time, finding them analytically useful for
answering the research question. However, evaluators also identified
limitations: LLMs fragmented data unnecessarily, missed latent interpretations,
and sometimes produced themes with unclear boundaries. Our contributions are
threefold. First, a reproducible approach integrating refined, documented
prompts with an evaluation framework to operationalize Braun and Clarke's
reflexive TA. Second, an empirical comparison of LLM- and human-generated codes
and themes in software engineering data. Third, guidelines for integrating LLMs
into qualitative analysis while preserving methodological rigour, clarifying
when and how LLMs can assist effectively and when human interpretation remains
essential.

</details>


### [20] [CodeRL+: Improving Code Generation via Reinforcement with Execution Semantics Alignment](https://arxiv.org/abs/2510.18471)
*Xue Jiang,Yihong Dong,Mengyang Liu,Hongyi Deng,Tian Wang,Yongding Tao,Rongyu Cao,Binhua Li,Zhi Jin,Wenpin Jiao,Fei Huang,Yongbin Li,Ge Li*

Main category: cs.SE

TL;DR: CodeRL+是一种新的强化学习方法，通过整合执行语义对齐来改进代码生成，相比仅依赖测试用例结果的RLVR方法，能更有效地学习代码的执行语义。


<details>
  <summary>Details</summary>
Motivation: 现有LLM在代码生成时存在语义鸿沟，仅依赖测试用例的二元通过/失败信号效率低下，难以处理代码中的细微逻辑错误。

Method: 提出CodeRL+方法，通过推断变量级执行轨迹来提供执行语义的直接学习信号，可直接利用现有策略rollouts，并能与各种RL算法无缝集成。

Result: CodeRL+在pass@1上实现4.6%的相对提升，在代码推理和测试输出生成任务上分别获得15.5%和4.4%的准确率提升，且适用于不同RL算法和LLM。

Conclusion: CodeRL+有效加强了代码文本表示与底层执行语义之间的对齐，为代码生成提供了更有效的训练方法。

Abstract: While Large Language Models (LLMs) excel at code generation by learning from
vast code corpora, a fundamental semantic gap remains between their training on
textual patterns and the goal of functional correctness, which is governed by
formal execution semantics. Reinforcement Learning with Verifiable Rewards
(RLVR) approaches attempt to bridge this gap using outcome rewards from
executing test cases. However, solely relying on binary pass/fail signals is
inefficient for establishing a well-aligned connection between the textual
representation of code and its execution semantics, especially for subtle
logical errors within the code. In this paper, we propose CodeRL+, a novel
approach that integrates execution semantics alignment into the RLVR training
pipeline for code generation. CodeRL+ enables the model to infer variable-level
execution trajectory, providing a direct learning signal of execution
semantics. CodeRL+ can construct execution semantics alignment directly using
existing on-policy rollouts and integrates seamlessly with various RL
algorithms. Extensive experiments demonstrate that CodeRL+ outperforms
post-training baselines (including RLVR and Distillation), achieving a 4.6%
average relative improvement in pass@1. CodeRL+ generalizes effectively to
other coding tasks, yielding 15.5% and 4.4% higher accuracy on code-reasoning
and test-output-generation benchmarks, respectively. CodeRL+ shows strong
applicability across diverse RL algorithms and LLMs. Furthermore, probe
analyses provide compelling evidence that CodeRL+ strengthens the alignment
between code's textual representations and its underlying execution semantics.

</details>


### [21] [VAPU: System for Autonomous Legacy Code Modernization](https://arxiv.org/abs/2510.18509)
*Valtteri Ala-Salmi,Zeeshan Rasheed,Abdul Malik Sami,Muhammad Waseem,Kai-Kristian Kemell,Jussi Rasku,Mika Saari,Pekka Abrahamsson*

Main category: cs.SE

TL;DR: 提出基于LLM的多代理系统VAPU，用于自主更新遗留应用程序代码，相比零样本和单样本学习，在低温度设置下能实现相似错误数但更高需求满足率，Python文件更新成功率提升达22.5%。


<details>
  <summary>Details</summary>
Motivation: 遗留应用程序包含过时组件，带来兼容性、安全性和可靠性风险，但高资源成本使企业不愿更新。需要成本效益高的自主更新解决方案。

Method: 设计名为VAPU的多代理系统，模拟软件开发团队不同角色，分阶段更新代码文件。扩展评估从单LLM到五个LLM，测试温度参数0-1设置，使用20个开源Python项目。

Result: 在低温度设置下，VAPU与ZSL/OSL提示相比错误数相似但需求满足率更高，Python文件更新需求成功率提升达22.5%。

Conclusion: 基于LLM的多代理系统是自主更新遗留应用程序组件的有效解决方案。

Abstract: In this study, we present a solution for the modernization of legacy
applications, an area of code generation where LLM-based multi-agent systems
are proving essential for complex multi-phased tasks. Legacy applications often
contain deprecated components that create compatibility, security, and
reliability risks, but high resource costs make companies hesitate to update.
We take a step forward to integrate an LLM-based multi-agent system as part of
a legacy web application update to provide a cost-effective solution to update
legacy applications autonomously. We propose a multi-agent system named a
Verifying Agent Pipeline Updater (VAPU), which is designed to update code files
in phases while simulating different roles in a software development team. In
our previous study, we evaluated the system for legacy version updates by using
six legacy web application view files by resulting errors and accomplished
requirements. This study extends the previous evaluation of a multi-agent
pipeline system by extending the evaluation of VAPU from a single LLM to five
LLMs and using the temperature parameter in both 0 to 1 settings. Additionally,
we tested the system with 20 open-source Python GitHub projects. The results of
the evaluation were compared to Zero-Shot Learning (ZSL) and One-Shot Learning
(OSL) prompts. The extended evaluation of VAPU showed that particularly in a
low-temperature VAPU can get similar level of error count compared to the
ZSL/OSL prompts but with a higher level of fulfilled requirements, depending on
the LLM. VAPU showed up to 22.5% increase in the succeeding Python file update
requirements compared to ZSL/OSL prompts. The study indicates that an LLM-based
multi-agent system is a capable solution to update components of a legacy
application autonomously.

</details>


### [22] [Mining Service Behavior for Stateful Service Emulation](https://arxiv.org/abs/2510.18519)
*Md Arafat Hossain,Jun Han,Muhammad Ashad Kabir,Steve Versteeg,Jean-Guy Schneider,Jiaojiao Jiang*

Main category: cs.SE

TL;DR: 提出了一种考虑服务状态的服务建模方法，通过分析交互消息间的上下文依赖关系和数据值关系，提高状态化服务响应生成的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有服务虚拟化方法大多忽略服务状态，导致服务仿真准确性不足，特别是在处理状态化服务时测试环境真实性降低。

Method: 从服务交互中推导服务模型，通过揭示交互消息间的上下文依赖关系和分析消息数据值之间的关系来考虑服务状态。

Result: 使用状态化和无状态服务的交互轨迹进行评估，结果显示在服务响应生成方面相比现有方法在准确性和效率上有显著提升。

Conclusion: 考虑服务状态的服务建模方法能够有效提高服务虚拟化的准确性和测试环境的真实性。

Abstract: Enterprise software systems are increasingly integrating with diverse
services to meet expanding business demands. Testing these highly
interconnected systems presents a challenge due to the need for access to the
connected services. Service virtualization has emerged as a widely used
technique to derive service models from recorded interactions, for service
response generation during system testing. Various methods have been proposed
to emulate actual service behavior based on these interactions, but most fail
to account for the service's state, which reduces the accuracy of service
emulation and the realism of the testing environment, especially when dealing
with stateful services. This paper proposes an approach to deriving service
models from service interactions, which enhance the accuracy of response
generation by considering service state. This is achieved by uncovering
contextual dependencies among interaction messages and analyzing the
relationships between message data values. The approach is evaluated using
interaction traces collected from both stateful and stateless services, and the
results reveal notable enhancements in accuracy and efficiency over existing
approaches in service response generation.

</details>


### [23] [Demonstrators for Industrial Cyber-Physical System Research: A Requirements Hierarchy Driven by Software-Intensive Design](https://arxiv.org/abs/2510.18534)
*Uraz Odyurt,Richard Loendersloot,Tiedo Tinga*

Main category: cs.SE

TL;DR: 提出了一个演示器需求细化框架，通过定义5个层次化的演示级别来评估目标演示的可行性，进行现实调整，并帮助描述需求。


<details>
  <summary>Details</summary>
Motivation: 研究项目中演示器覆盖范围的不确定性导致目标与可实现的演示结果之间存在不匹配，阻碍项目进展。TRL量表作为松散描述符无法解决这一问题。

Method: 定义5个层次化的演示级别，明确与期望（如工作包交互）和项目工业用例相关联。在软件密集型系统和工业信息物理系统领域应用该框架。

Result: 在两个研究项目中进行了应用验证（一个在早期阶段，一个在最终阶段），显示了该框架的有效性。

Conclusion: 该演示器需求细化框架能够帮助评估演示可行性、进行现实调整，并有效描述需求，尽管完整的验证需要4-5年的项目周期。

Abstract: One of the challenges apparent in the organisation of research projects is
the uncertainties around the subject of demonstrators. A precise and detailed
elicitation of the coverage for project demonstrators is often an afterthought
and not sufficiently detailed during proposal writing. This practice leads to
continuous confusion and a mismatch between targeted and achievable
demonstration of results, hindering progress. The reliance on the TRL scale as
a loose descriptor does not help either. We propose a demonstrator requirements
elaboration framework aiming to evaluate the feasibility of targeted
demonstrations, making realistic adjustments, and assist in describing
requirements. In doing so, we define 5 hierarchical levels of demonstration,
clearly connected to expectations, e.g., work package interaction, and also
connected to the project's industrial use-cases. The considered application
scope in this paper is the domain of software-intensive systems and industrial
cyber-physical systems. A complete validation is not accessible, as it would
require application of our framework at the start of a project and observing
the results at the end, taking 4-5 years. Nonetheless, we have applied it to
two research projects from our portfolio, one at the early and another at the
final stages, revealing its effectiveness.

</details>


### [24] [When Abstraction Breaks Physics: Rethinking Modular Design in Quantum Software](https://arxiv.org/abs/2510.18557)
*Jianjun Zhao*

Main category: cs.SE

TL;DR: 量子软件工程中的抽象机制存在根本冲突：语法有效的抽象可能违反量子计算的物理约束。本文识别了三种失败案例，提出了物理安全抽象的设计原则和研究方向。


<details>
  <summary>Details</summary>
Motivation: 经典软件工程的抽象原则（模块化、可重用性、可扩展性）在量子程序中面临挑战，因为量子语义（幺正性、纠缠、不可克隆定理、测量的破坏性）与经典抽象机制存在冲突。

Method: 识别了三种抽象破坏量子语义的失败案例，提出了物理安全抽象机制的设计原则，包括量子特定类型系统、效果注释和基于契约的模块设计。

Result: 展示了经典抽象机制在量子计算中的局限性，提出了确保量子语义完整性的抽象设计框架。

Conclusion: 需要基于量子语义重新思考量子软件工程中的抽象机制，考虑工程可扩展性，为量子编程语言和工具的开发提供理论基础。

Abstract: Abstraction is a fundamental principle in classical software engineering,
which enables modularity, reusability, and scalability. However, quantum
programs adhere to fundamentally different semantics, such as unitarity,
entanglement, the no-cloning theorem, and the destructive nature of
measurement, which introduce challenges to the safe use of classical
abstraction mechanisms. This paper identifies a fundamental conflict in quantum
software engineering: abstraction practices that are syntactically valid may
violate the physical constraints of quantum computation. We present three
classes of failure cases where naive abstraction breaks quantum semantics and
propose a set of design principles for physically sound abstraction mechanisms.
We further propose research directions, including quantum-specific type
systems, effect annotations, and contract-based module design. Our goal is to
initiate a systematic rethinking of abstraction in quantum software
engineering, based on quantum semantics and considering engineering
scalability.

</details>


### [25] [WebDevJudge: Evaluating (M)LLMs as Critiques for Web Development Quality](https://arxiv.org/abs/2510.18560)
*Chunyang Li,Yilun Zheng,Xinting Huang,Tianqing Fang,Jiahao Xu,Yangqiu Song,Lihui Chen,Han Hu*

Main category: cs.SE

TL;DR: WebDevJudge是一个用于评估LLM作为评判者在网页开发任务中性能的系统基准，揭示了LLM评判者与人类专家之间存在显著差距。


<details>
  <summary>Details</summary>
Motivation: LLM作为评判者范式在定义明确的任务中表现良好，但在动态环境和复杂交互的开放式任务中的可靠性尚未探索。

Method: 构建WebDevJudge基准，包含基于静态观察的非交互式评估和动态网页环境的连续交互式评估，使用结构化且基于查询的评分标准标注人类偏好标签。

Result: 实验发现LLM评判者与人类专家存在显著差距，主要源于模型在识别功能等价性、验证任务可行性以及减少偏见方面的根本局限性。

Conclusion: WebDevJudge对LLM作为评判者范式提出了重大挑战，为未来开发更可靠的复杂场景自动化评估器提供了指导。

Abstract: The paradigm of LLM-as-a-judge is emerging as a scalable and efficient
alternative to human evaluation, demonstrating strong performance on
well-defined tasks. However, its reliability in open-ended tasks with dynamic
environments and complex interactions remains unexplored. To bridge the gap, we
introduce WebDevJudge, a systematic benchmark for assessing LLM-as-a-judge
performance in web development, with support for both non-interactive
evaluation based on static observations and continuous interactive evaluation
with a dynamic web environment. WebDevJudge comprises human preference labels
over paired web implementations, annotated with structured and query-grounded
rubrics to ensure high-quality ground truth. Using this benchmark, we
comprehensively evaluate various evaluators, including LLMs, MLLMs, and agentic
workflows. We systematically investigate the impact of different paradigms and
guidance mechanisms. Our experiments reveal a significant gap between LLM
judges and human experts. In-depth analysis indicates this gap stems from
fundamental model limitations, including failures in recognizing functional
equivalence, verifying task feasibility, and mitigating bias. Overall,
WebDevJudge presents a significant challenge to LLM-as-a-judge, offering
insights to guide future research toward developing more reliable and capable
automated evaluators for complicated scenarios. Code and data are available at
https://github.com/lcy2723/WebDevJudge.

</details>


### [26] [A Structured Evaluation Framework for Low-Code Platform Selection: A Multi-Criteria Decision Model for Enterprise Digital Transformation](https://arxiv.org/abs/2510.18590)
*Antonio Lamanna*

Main category: cs.SE

TL;DR: 提出了一个基于五个关键标准的低代码开发平台综合评估框架，包含加权评分模型，帮助企业根据特定需求定量评估和比较不同平台。


<details>
  <summary>Details</summary>
Motivation: 低代码开发平台的快速普及产生了对系统化评估方法的需求，以帮助企业做出明智的平台选择决策，填补营销驱动比较与严谨评估方法之间的差距。

Method: 基于五个关键标准（业务流程编排、UI/UX定制、集成与互操作性、治理与安全、AI增强自动化）构建评估框架，采用加权评分模型进行定量评估。

Result: 在企业环境中进行实证验证，证明这种结构化方法能显著改善决策结果，降低平台锁定或选择不当解决方案的风险。

Conclusion: 该框架为组织提供了系统化的低代码平台评估方法，支持基于特定需求和战略优先级的定量比较，有助于优化平台选择决策。

Abstract: The rapid adoption of Low-Code Development Platforms (LCDPs) has created a
critical need for systematic evaluation methodologies that enable organizations
to make informed platform selection decisions. This paper presents a
comprehensive evaluation framework based on five key criteria: Business Process
Orchestration, UI/UX Customization, Integration and Interoperability,
Governance and Security, and AI-Enhanced Automation. We propose a weighted
scoring model that allows organizations to quantitatively assess and compare
different low-code platforms based on their specific requirements and strategic
priorities. The framework addresses the gap between marketing-driven platform
comparisons and rigorous, context-specific evaluation methodologies. Through
empirical validation in enterprise environments, we demonstrate how this
structured approach can significantly improve decision-making outcomes and
reduce the risk of platform lock-in or inadequate solution selection.

</details>


### [27] [CUARewardBench: A Benchmark for Evaluating Reward Models on Computer-using Agent](https://arxiv.org/abs/2510.18596)
*Haojia Lin,Xiaoyu Tan,Yulei Qin,Zihan Xu,Yuchen Shi,Zongyi Li,Gang Li,Shaofei Cai,Siqi Cai,Chaoyou Fu,Ke Li,Xing Sun*

Main category: cs.SE

TL;DR: 提出了CUARewardBench，这是首个用于评估计算机使用代理（CUA）奖励模型的基准，包含轨迹级和步骤级评估，并通过Unanimous Prompt Ensemble方法显著提升了奖励模型的可靠性。


<details>
  <summary>Details</summary>
Motivation: 当前基于脚本的验证器在评估CUA时存在可扩展性差和无法提供逐步评估的问题，而奖励模型作为替代方案的潜力尚未充分探索。

Method: 构建了包含10个软件类别和7种代理架构的多样化数据集，设计了专家标注协议，并提出了Unanimous Prompt Ensemble（UPE）集成方法，通过严格的一致投票和策略性提示模板配置来提升模型性能。

Result: UPE方法在结果奖励模型（ORM）上达到89.8%精确度和93.3%负预测值，在过程奖励模型（PRM）上达到81.7%精确度和85.1%负预测值，显著优于单一视觉语言模型和传统集成方法。

Conclusion: 该研究揭示了当前CUA奖励模型的关键局限性，证明了通用视觉语言模型在奖励评估中优于专门的CUA模型，并通过UPE方法显著提升了奖励模型的可靠性。

Abstract: Computer-using agents (CUAs) enable task completion through natural
interaction with operating systems and software interfaces. While script-based
verifiers are widely adopted for evaluation, they suffer from limited
scalability and inability to provide step-wise assessment. Reward models offer
promising alternatives, but their effectiveness on CUA evaluation remains
largely underexplored. To address this gap, we present CUARewardBench,
comprising four key contributions: (1) First-ever Comprehensive CUA Reward
Benchmark: We introduce the first benchmark for evaluating both outcome reward
models (ORM) and process reward models (PRM) on CUA tasks, enabling systematic
assessment across trajectory-level and step-level evaluation. (2) Diverse,
Practical and Reliable Dataset: CUARewardBench encompasses trajectories from 10
software categories and 7 agent architectures with varying performance levels
(25.9%-50.8% success rates). All trajectories are expertly annotated through
carefully designed protocols, with rigorous quality control to ensure
reliability and practical applicability. (3) Comprehensive Analysis and
Insights: Through extensive experiments across 7 vision-language models and 3
prompt templates, we reveal critical limitations of current CUA RMs, including
insufficient visual reasoning capabilities, knowledge deficiencies, and the
superiority of general VLMs over specialized CUA models for reward evaluation.
(4) Unanimous Prompt Ensemble (UPE): Based on the insights from our
comprehensive analysis, we propose UPE, a novel ensemble method that
significantly enhances reward model reliability through strict unanimous voting
and strategic prompt-template configurations. UPE achieves 89.8% precision and
93.3% NPV for ORM, and 81.7% precision and 85.1% NPV for PRM, substantially
outperforming single VLMs and traditional ensemble approaches.

</details>


### [28] [An overview of the use of alternative funding and contracting approaches relevant for agile software development: A systematic review of real-life experiences](https://arxiv.org/abs/2510.18711)
*Bertha Ngereja,Magne Jørgensen*

Main category: cs.SE

TL;DR: 这篇综述研究了敏捷软件开发中替代性合同与资金方法，识别了4种替代资金方法和4种替代合同方法，分析了采用这些方法的动机、收益和挑战。


<details>
  <summary>Details</summary>
Motivation: 传统资金和合同方法过于刚性，与敏捷原则冲突，阻碍客户-承包商协作，限制盈利能力，因此需要寻找更灵活的替代方法。

Method: 在SCOPUS、Web of Science和Google Scholar中进行了系统文献综述，识别了38篇相关实证研究，涵盖私人和公共部门背景。

Result: 识别了4种替代资金方法和4种替代合同方法。采用这些方法的好处包括提高客户满意度、降低承包商风险、更高效的资源利用。挑战包括文化结构障碍、范围蔓延风险、需要额外时间和资源投入。

Conclusion: 组织应采用混合方法平衡灵活性和控制，逐步过渡到完全灵活的方法，组织背景在选择合适方法时至关重要。

Abstract: Agile software development emphasizes flexibility and iterative processes,
which may conflict with the more linear, rigid, and time-consuming traditional
funding and contracting approaches. This review synthesizes real-life
experiences of using alternative (non-traditional) contracting and funding
approaches. The focus is on identifying approaches that align better with agile
principles and understanding the motivations, benefits, and challenges these
alternatives present. A systematic literature review was conducted in SCOPUS,
Web of Science, and Google Scholar, where we identified 38 relevant
peer-reviewed empirical studies from private and public sector contexts. Four
alternative funding and four alternative contracting approaches were
identified. Organizations were motivated to adopt these alternative approaches
because traditional approaches often proved too rigid, conflicted with agile
principles, hindered effective client-contractor collaboration, and limited
profitability. The benefits of these alternatives included higher client
satisfaction, reduced contractor risk, and more efficient resource utilization.
Adopting alternative funding and contracting approaches may promote flexibility
and efficiency in agile projects but also presents cultural and structural
challenges, increases the risk of scope creep and analysis paralysis, and
requires additional effort in terms of time and resources. The context of the
organization matters highly in selecting a suitable approach, such as the
organizational readiness in terms of its leaders, people, and systems. Thus,
instead of wholly adopting alternative approaches and introducing changes
abruptly, organizations may benefit from starting with hybrid approaches that
balance flexibility and control and progressively transition to fully flexible
approaches tailored to their needs

</details>


### [29] [Causally Perturbed Fairness Testing](https://arxiv.org/abs/2510.18719)
*Chengwen Du,Tao Chen*

Main category: cs.SE

TL;DR: CausalFT是一个基于因果推理的公平性测试框架，通过提取与敏感特征因果相关的非敏感特征来指导测试样本生成，显著提升现有测试生成器的公平性缺陷检测能力。


<details>
  <summary>Details</summary>
Motivation: 现有公平性测试方法主要关注测试样本生成器的设计，而忽略了数据特征的知识，这些知识可以帮助指导扰动过程，从而限制了它们的潜力。

Method: 通过因果推理提取与敏感特征最直接因果相关的非敏感特征，并将这种因果关系注入到扰动过程中，指导测试样本生成器。

Result: 在1296个测试案例中，CausalFT能在93%的情况下显著提升任意基础生成器的公平性缺陷检测能力，且额外运行时间开销可接受。与基于相关性的方法相比，在64%的情况下表现更好且更高效。

Conclusion: CausalFT作为一个高层框架，能够有效提升公平性测试的效果，并增强模型的偏差抵抗能力。

Abstract: To mitigate unfair and unethical discrimination over sensitive features
(e.g., gender, age, or race), fairness testing plays an integral role in
engineering systems that leverage AI models to handle tabular data. A key
challenge therein is how to effectively reveal fairness bugs under an
intractable sample size using perturbation. Much current work has been focusing
on designing the test sample generators, ignoring the valuable knowledge about
data characteristics that can help guide the perturbation and hence limiting
their full potential. In this paper, we seek to bridge such a gap by proposing
a generic framework of causally perturbed fairness testing, dubbed CausalFT.
Through causal inference, the key idea of CausalFT is to extract the most
directly and causally relevant non-sensitive feature to its sensitive
counterpart, which can jointly influence the prediction of the label. Such a
causal relationship is then seamlessly injected into the perturbation to guide
a test sample generator. Unlike existing generator-level work, CausalFT serves
as a higher-level framework that can be paired with diverse base generators.
Extensive experiments on 1296 cases confirm that CausalFT can considerably
improve arbitrary base generators in revealing fairness bugs over 93% of the
cases with acceptable extra runtime overhead. Compared with a state-of-the-art
approach that ranks the non-sensitive features solely based on correlation,
CausalFT performs significantly better on 64% cases while being much more
efficient. Further, CausalFT can better improve bias resilience in nearly all
cases.

</details>


### [30] [ShaRE your Data! Characterizing Datasets for LLM-based Requirements Engineering](https://arxiv.org/abs/2510.18787)
*Quim Motger,Carlota Catot,Xavier Franch*

Main category: cs.SE

TL;DR: 本文对LLM在需求工程中使用的数据集进行了系统性映射研究，识别了62个公开数据集，发现数据集碎片化、表征不足的问题，并提出了分类框架和公共目录。


<details>
  <summary>Details</summary>
Motivation: 需求工程领域存在数据稀缺问题，现有的LLM4RE数据集分散且缺乏系统表征，限制了数据集的复用和比较。

Method: 通过系统性映射研究，识别和分析LLM4RE研究中使用的数据集，按工件类型、粒度、RE阶段、任务、领域和语言等描述符进行分类。

Result: 从43项主要研究中识别出62个公开数据集，发现存在研究空白：需求获取任务覆盖有限、管理活动数据集稀缺、多语言可用性不足。

Conclusion: 本研究提供了数据集目录和结构化表征方案，支持LLM4RE研究中的数据选择、比较和复用，未来将扩展至灰色文献并与开放数据集库集成。

Abstract: [Context] Large Language Models (LLMs) rely on domain-specific datasets to
achieve robust performance across training and inference stages. However, in
Requirements Engineering (RE), data scarcity remains a persistent limitation
reported in surveys and mapping studies. [Question/Problem] Although there are
multiple datasets supporting LLM-based RE tasks (LLM4RE), they are fragmented
and poorly characterized, limiting reuse and comparability. This research
addresses the limited visibility and characterization of datasets used in
LLM4RE. We investigate which public datasets are employed, how they can be
systematically characterized, and which RE tasks and dataset descriptors remain
under-represented. [Ideas/Results] To address this, we conduct a systematic
mapping study to identify and analyse datasets used in LLM4RE research. A total
of 62 publicly available datasets are referenced across 43 primary studies.
Each dataset is characterized along descriptors such as artifact type,
granularity, RE stage, task, domain, and language. Preliminary findings show
multiple research gaps, including limited coverage for elicitation tasks,
scarce datasets for management activities beyond traceability, and limited
multilingual availability. [Contribution] This research preview offers a public
catalogue and structured characterization scheme to support dataset selection,
comparison, and reuse in LLM4RE research. Future work will extend the scope to
grey literature, as well as integration with open dataset and benchmark
repositories.

</details>


### [31] [FeClustRE: Hierarchical Clustering and Semantic Tagging of App Features from User Reviews](https://arxiv.org/abs/2510.18799)
*Max Tiessler,Quim Motger*

Main category: cs.SE

TL;DR: FeClustRE是一个从移动应用评论中提取特征并生成层次化分类的框架，结合了语法解析、LLM增强、自动调优的层次聚类和语义标注，解决了现有方法在特征提取和结构化方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以将嘈杂、模糊的用户反馈转化为可解释的见解，语法方法缺乏语义深度，而LLM方法往往遗漏细粒度特征或无法进行连贯的结构化组织，导致特征提取结果缺乏结构化、有意义的表示。

Method: FeClustRE整合了混合特征提取、自动调优的层次聚类和基于LLM的语义标注。它结合语法解析与LLM增强，将特征组织成簇，并自动生成有意义的分类标签。

Result: 在公共基准测试中评估了提取正确性，在生成式AI助手应用评论样本研究中评估了聚类质量、语义连贯性和可解释性。

Conclusion: FeClustRE提供了一个混合特征提取和分类生成的框架，具有自动调优机制和全面的评估方法，开源实现可复现，连接了用户反馈和特征理解，支持对当前和新兴需求的深入洞察。

Abstract: [Context and motivation.] Extracting features from mobile app reviews is
increasingly important for multiple requirements engineering (RE) tasks.
However, existing methods struggle to turn noisy, ambiguous feedback into
interpretable insights. [Question/problem.] Syntactic approaches lack semantic
depth, while large language models (LLMs) often miss fine-grained features or
fail to structure them coherently. In addition, existing methods output flat
lists of features without semantic organization, limiting interpretation and
comparability. Consequently, current feature extraction approaches do not
provide structured, meaningful representations of app features. As a result,
practitioners face fragmented information that hinder requirement analysis,
prioritization, and cross-app comparison, among other use cases. [Principal
ideas/results.] In this context, we propose FeClustRE, a framework integrating
hybrid feature extraction, hierarchical clustering with auto-tuning and
LLM-based semantic labelling. FeClustRE combines syntactic parsing with LLM
enrichment, organizes features into clusters, and automatically generates
meaningful taxonomy labels. We evaluate FeClustRE on public benchmarks for
extraction correctness and on a sample study of generative AI assistant app
reviews for clustering quality, semantic coherence, and interpretability.
[Contribution.] Overall, FeClustRE delivers (1) a hybrid framework for feature
extraction and taxonomy generation, (2) an auto-tuning mechanism with a
comprehensive evaluation methodology, and (3) open-source and replicable
implementation. These contributions bridge user feedback and feature
understanding, enabling deeper insights into current and emerging requirements.

</details>


### [32] [Streamlining Acceptance Test Generation for Mobile Applications Through Large Language Models: An Industrial Case Study](https://arxiv.org/abs/2510.18861)
*Pedro Luís Fonseca,Bruno Lima,João Pascoal Faria*

Main category: cs.SE

TL;DR: AToMIC是一个自动化框架，使用专用大语言模型从需求文档和代码变更中自动生成Gherkin场景、页面对象和可执行的UI测试脚本，显著提升了移动应用验收测试的效率。


<details>
  <summary>Details</summary>
Motivation: 移动应用验收测试在现代软件开发中仍是瓶颈，特别是在使用Flutter等跨平台框架时。虽然开发者越来越依赖自动化测试工具，但创建和维护验收测试工件仍需大量人工工作。

Method: 引入AToMIC框架，利用专用大语言模型直接从需求（JIRA工单）和近期代码变更生成Gherkin场景、页面对象和可执行的UI测试脚本。

Result: 在宝马MyBMW应用中测试，覆盖13个真实问题，在170+屏幕的代码库中，AToMIC在标准硬件上每功能不到5分钟生成可执行测试工件。生成的工件质量高：93.3%的Gherkin场景在生成时语法正确，78.8%的页面对象无需手动编辑即可运行，100%生成的UI测试成功执行。

Conclusion: AToMIC是一个可扩展、实用的解决方案，能够简化工业移动项目中验收测试的创建和维护，所有实践者都报告了时间节省（通常每个功能节省一个完整开发日）并对采用该方法有强烈信心。

Abstract: Mobile acceptance testing remains a bottleneck in modern software
development, particularly for cross-platform mobile development using
frameworks like Flutter. While developers increasingly rely on automated
testing tools, creating and maintaining acceptance test artifacts still demands
significant manual effort. To help tackle this issue, we introduce AToMIC, an
automated framework leveraging specialized Large Language Models to generate
Gherkin scenarios, Page Objects, and executable UI test scripts directly from
requirements (JIRA tickets) and recent code changes. Applied to BMW's MyBMW
app, covering 13 real-world issues in a 170+ screen codebase, AToMIC produced
executable test artifacts in under five minutes per feature on standard
hardware. The generated artifacts were of high quality: 93.3% of Gherkin
scenarios were syntactically correct upon generation, 78.8% of PageObjects ran
without manual edits, and 100% of generated UI tests executed successfully. In
a survey, all practitioners reported time savings (often a full developer-day
per feature) and strong confidence in adopting the approach. These results
confirm AToMIC as a scalable, practical solution for streamlining acceptance
test creation and maintenance in industrial mobile projects.

</details>


### [33] [EffiReasonTrans: RL-Optimized Reasoning for Code Translation](https://arxiv.org/abs/2510.18863)
*Yanlin Wang,Rongyi Ou,Yanli Wang,Mingwei Liu,Jiachi Chen,Ensheng Shi,Xilin Liu,Yuchi Ma,Zibin Zheng*

Main category: cs.SE

TL;DR: EffiReasonTrans是一个代码翻译训练框架，通过构建推理增强数据集和两阶段训练策略，在提升翻译准确性的同时平衡推理延迟。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型在代码翻译中准确性提升与推理延迟增加之间的矛盾，满足实际开发工作流中需要人工检查的需求。

Method: 1) 使用更强的语言模型DeepSeek-R1构建推理增强数据集；2) 采用两阶段训练：监督微调+强化学习；3) 自动化语法和功能检查确保数据质量。

Result: 在6个翻译对上，翻译准确性显著提升（最高+49.2% CA和+27.8% CodeBLEU），生成token数量减少（最高-19.3%），推理延迟降低（最高-29.0%）。

Conclusion: EffiReasonTrans框架有效平衡了代码翻译的准确性和效率，在基于代理的框架中也表现出改进的翻译准确性。

Abstract: Code translation is a crucial task in software development and maintenance.
While recent advancements in large language models (LLMs) have improved
automated code translation accuracy, these gains often come at the cost of
increased inference latency, hindering real-world development workflows that
involve human-in-the-loop inspection. To address this trade-off, we propose
EffiReasonTrans, a training framework designed to improve translation accuracy
while balancing inference latency. We first construct a high-quality
reasoning-augmented dataset by prompting a stronger language model,
DeepSeek-R1, to generate intermediate reasoning and target translations. Each
(source code, reasoning, target code) triplet undergoes automated syntax and
functionality checks to ensure reliability. Based on this dataset, we employ a
two-stage training strategy: supervised fine-tuning on reasoning-augmented
samples, followed by reinforcement learning to further enhance accuracy and
balance inference latency. We evaluate EffiReasonTrans on six translation
pairs. Experimental results show that it consistently improves translation
accuracy (up to +49.2% CA and +27.8% CodeBLEU compared to the base model) while
reducing the number of generated tokens (up to -19.3%) and lowering inference
latency in most cases (up to -29.0%). Ablation studies further confirm the
complementary benefits of the two-stage training framework. Additionally,
EffiReasonTrans demonstrates improved translation accuracy when integrated into
agent-based frameworks. Our code and data are available at
https://github.com/DeepSoftwareAnalytics/EffiReasonTrans.

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [34] [DynaQuery: A Self-Adapting Framework for Querying Structured and Multimodal Data](https://arxiv.org/abs/2510.18029)
*Aymane Hassini*

Main category: cs.DB

TL;DR: DynaQuery是一个统一的、自适应的框架，通过Schema Introspection and Linking Engine (SILE)解决LLM在混合数据库自然语言查询中的结构化和非结构化数据联合推理挑战，相比传统RAG方法显著提高了查询可靠性。


<details>
  <summary>Details</summary>
Motivation: 解决LLM在复杂混合数据库自然语言查询中面临的挑战：需要同时推理结构化多关系模式与链接的非结构化资产语义内容。

Method: 提出DynaQuery框架，其核心是Schema Introspection and Linking Engine (SILE)，将模式链接提升为查询规划的一等公民阶段，采用结构感知架构。

Result: 相比非结构化RAG范式，SILE设计显著更鲁棒，几乎消除了SCHEMA_HALLUCINATION等灾难性上下文故障；在复杂基准测试中验证了从纯模式感知到整体语义感知的泛化原则。

Conclusion: 研究为开发鲁棒、自适应且可预测一致的自然语言数据库接口提供了经过验证的架构基础。

Abstract: The rise of Large Language Models (LLMs) has accelerated the long-standing
goal of enabling natural language querying over complex, hybrid databases. Yet,
this ambition exposes a dual challenge: reasoning jointly over structured,
multi-relational schemas and the semantic content of linked unstructured
assets. To overcome this, we present DynaQuery - a unified, self-adapting
framework that serves as a practical blueprint for next-generation "Unbound
Databases." At the heart of DynaQuery lies the Schema Introspection and Linking
Engine (SILE), a novel systems primitive that elevates schema linking to a
first-class query planning phase. We conduct a rigorous, multi-benchmark
empirical evaluation of this structure-aware architecture against the prevalent
unstructured Retrieval-Augmented Generation (RAG) paradigm. Our results
demonstrate that the unstructured retrieval paradigm is architecturally
susceptible to catastrophic contextual failures, such as SCHEMA_HALLUCINATION,
leading to unreliable query generation. In contrast, our SILE-based design
establishes a substantially more robust foundation, nearly eliminating this
failure mode. Moreover, end-to-end validation on a complex, newly curated
benchmark uncovers a key generalization principle: the transition from pure
schema-awareness to holistic semantics-awareness. Taken together, our findings
provide a validated architectural basis for developing natural language
database interfaces that are robust, adaptable, and predictably consistent.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [35] [Deploying Atmospheric and Oceanic AI Models on Chinese Hardware and Framework: Migration Strategies, Performance Optimization and Analysis](https://arxiv.org/abs/2510.17852)
*Yuze Sun,Wentao Luo,Yanfei Xiang,Jiancheng Pan,Jiahao Li,Quan Zhang,Xiaomeng Huang*

Main category: cs.DC

TL;DR: 该论文提出了一个将大气和海洋AI模型从PyTorch迁移到MindSpore并针对中国芯片优化的框架，旨在减少对GPU的依赖，提升硬件独立性。


<details>
  <summary>Details</summary>
Motivation: 当前AI气候和天气研究模型（如FourCastNet和AI-GOMS）严重依赖GPU，限制了硬件独立性，特别是对中国国产硬件和框架的支持不足。

Method: 开发了一个迁移框架，专注于软硬件适配、内存优化和并行化，将模型从PyTorch迁移到MindSpore并针对中国芯片进行优化。

Result: 实验结果表明，迁移和优化过程保持了模型的原始精度，同时显著降低了系统依赖性，并利用中国芯片提高了运行效率。

Conclusion: 这项工作为在大气和海洋AI模型开发中利用中国国产芯片和框架提供了有价值的见解和实践指导，为实现更大的技术独立性提供了途径。

Abstract: With the growing role of artificial intelligence in climate and weather
research, efficient model training and inference are in high demand. Current
models like FourCastNet and AI-GOMS depend heavily on GPUs, limiting hardware
independence, especially for Chinese domestic hardware and frameworks. To
address this issue, we present a framework for migrating large-scale
atmospheric and oceanic models from PyTorch to MindSpore and optimizing for
Chinese chips, and evaluating their performance against GPUs. The framework
focuses on software-hardware adaptation, memory optimization, and parallelism.
Furthermore, the model's performance is evaluated across multiple metrics,
including training speed, inference speed, model accuracy, and energy
efficiency, with comparisons against GPU-based implementations. Experimental
results demonstrate that the migration and optimization process preserves the
models' original accuracy while significantly reducing system dependencies and
improving operational efficiency by leveraging Chinese chips as a viable
alternative for scientific computing. This work provides valuable insights and
practical guidance for leveraging Chinese domestic chips and frameworks in
atmospheric and oceanic AI model development, offering a pathway toward greater
technological independence.

</details>


### [36] [Efficient Multi-Worker Selection based Distributed Swarm Learning via Analog Aggregation](https://arxiv.org/abs/2510.18152)
*Zhuoyu Yao,Yue Wang,Songyang Zhang,Yingshu Li,Zhipeng Cai,Zhi Tian*

Main category: cs.DC

TL;DR: 本文提出了一种用于分布式群学习(DSL)的空中模拟聚合方法DSL-OTA，通过多工作者选择策略和空中聚合提高通信效率、实现有效协作并确保隐私保护。


<details>
  <summary>Details</summary>
Motivation: 分布式学习系统中，有限的传输资源和复杂通信环境阻碍了边缘设备间的高效协作，特别是在大规模网络中。需要解决通信效率和隐私保护问题。

Method: 提出DSL-OTA方法，结合多工作者选择策略和空中模拟聚合，使标准DSL从单一最佳工作者贡献变得更加联邦化，同时保护聚合过程免受数据泄露风险。

Result: 理论分析验证了DSL-OTA在快速收敛率和低通信成本方面的优势。仿真结果显示，在均匀和非均匀数据集设置下，DSL-OTA优于现有方法，实现了更好的学习性能。

Conclusion: DSL-OTA方法有效解决了分布式学习中的通信效率和隐私保护问题，在理论和实践中都表现出优越性能。

Abstract: Recent advances in distributed learning systems have introduced effective
solutions for implementing collaborative artificial intelligence techniques in
wireless communication networks. Federated learning approaches provide a
model-aggregation mechanism among edge devices to achieve collaborative
training, while ensuring data security, communication efficiency, and sharing
computational overheads. On the other hand, limited transmission resources and
complex communication environments remain significant bottlenecks to the
efficient collaborations among edge devices, particularly within large-scale
networks. To address such issues, this paper proposes an over-the-air (OTA)
analog aggregation method designed for the distributed swarm learning (DSL),
termed DSL-OTA, aiming to enhance communication efficiency, enable effective
cooperation, and ensure privacy preserving. Incorporating multi-worker
selection strategy with over-the-air aggregation not only makes the standard
DSL based on single best worker contributing to global model update to become
more federated, but also secures the aggregation from potential risks of data
leakage. Our theoretical analyses verify the advantages of the proposed DSL-OTA
algorithm in terms of fast convergence rate and low communication costs.
Simulation results reveal that our DSL-OTA outperforms the other existing
methods by achieving better learning performance under both homogeneous and
heterogeneous dataset settings.

</details>


### [37] [A Distributed Framework for Causal Modeling of Performance Variability in GPU Traces](https://arxiv.org/abs/2510.18300)
*Ankur Lahiry,Ayush Pokharel,Banooqa Banday,Seth Ockerman,Amal Gueroudji,Mohammad Zaeed,Tanzima Z. Islam,Line Pouchard*

Main category: cs.DC

TL;DR: 提出了一个端到端的并行性能分析框架，用于高效处理多个大规模GPU跟踪数据，通过并行处理和因果图方法显著提升可扩展性。


<details>
  <summary>Details</summary>
Motivation: 大规模GPU跟踪数据对于识别异构高性能计算架构中的性能瓶颈至关重要，但单个跟踪数据的庞大体积和复杂性使得性能分析计算成本高昂且耗时。

Method: 采用端到端并行性能分析框架，对跟踪数据进行分区和并发处理，并运用因果图方法和并行协调图表来揭示执行流中的性能变异性和依赖关系。

Result: 实验结果显示在可扩展性方面实现了67%的提升，证明了该流水线在独立分析多个跟踪数据方面的有效性。

Conclusion: 该并行性能分析框架能够高效处理大规模GPU跟踪数据，显著提升分析效率，为异构HPC架构的性能优化提供了有效工具。

Abstract: Large-scale GPU traces play a critical role in identifying performance
bottlenecks within heterogeneous High-Performance Computing (HPC)
architectures. However, the sheer volume and complexity of a single trace of
data make performance analysis both computationally expensive and
time-consuming. To address this challenge, we present an end-to-end parallel
performance analysis framework designed to handle multiple large-scale GPU
traces efficiently. Our proposed framework partitions and processes trace data
concurrently and employs causal graph methods and parallel coordinating chart
to expose performance variability and dependencies across execution flows.
Experimental results demonstrate a 67% improvement in terms of scalability,
highlighting the effectiveness of our pipeline for analyzing multiple traces
independently.

</details>


### [38] [SLICE: SLO-Driven Scheduling for LLM Inference on Edge Computing Devices](https://arxiv.org/abs/2510.18544)
*Pan Zhou,Yiming Lei,Ling Liu,Xiaoqiong Xu,Ying Cai,Daji Ergu,Hongfang Yu,Yueyue Dai*

Main category: cs.DC

TL;DR: SLICE是一种针对边缘计算场景的创新调度解决方案，通过结合效用最大化请求调度算法和动态迭代生成速率控制机制，显著提高了LLM推理服务的SLO达成率。


<details>
  <summary>Details</summary>
Motivation: 现有调度服务系统仍以最大化输出token吞吐量为唯一优化目标，无法充分应对SLO要求的多样性，导致端到端延迟或TPOT相关SLO的违规率持续居高。

Method: 结合效用最大化请求调度算法与生成速率的动态迭代控制机制

Result: 相比最先进解决方案Orca和FastServe，SLICE实现了高达35倍的SLO达成率提升和3.4倍的任务完成时间优势

Conclusion: SLICE能够有效满足边缘设备对LLM服务的差异化SLO要求，显著改善推理服务的性能表现

Abstract: Large Language Models (LLMs), as the foundational architecture for
next-generation interactive AI applications, not only power intelligent
dialogue systems but also drive the evolution of embodied intelligence on edge
devices, including humanoid robots, smart vehicles, and other scenarios. The
applications running on these edge devices impose differentiated Service Level
Objectives (SLO) requirements on LLM services, specifically manifested as
distinct constraints on Time to First Token (TTFT) and Time Per Output Token
(TPOT) as well as end-to-end latency. Notably, edge devices typically handle
real-time tasks that are extremely sensitive to latency, such as machine
control and navigation planning. However, existing scheduling service systems
still prioritize maximizing output token throughput as the sole optimization
objective, failing to adequately address the diversity of SLO requirements.
This ultimately results in persistently high violation rates for end-to-end
latency or TPOT related SLOs.
  This paper proposes SLICE, an innovative scheduling solution designed for
edge computing scenarios with differentiated SLO requirements. By combining a
utility-maximizing request scheduling algorithm with a dynamic iterative
control mechanism for generation rates, SLICE significantly improves LLM
inference service SLO attainment. Experimental results demonstrate that
compared to state-of-the-art solutions Orca and FastServe, SLICE achieves up to
35x higher SLO attainment and 3.4x advantage in task completion time than the
other two solutions.

</details>


### [39] [Tokencake: A KV-Cache-centric Serving Framework for LLM-based Multi-Agent Applications](https://arxiv.org/abs/2510.18586)
*Zhuohang Bian,Feiyang Wu,Teng Ma,Youwei Zhuo*

Main category: cs.DC

TL;DR: Tokencake是一个针对多智能体应用的KV缓存优化框架，通过空间调度和时间调度解决缓存争用和GPU内存利用率低的问题。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在多智能体应用中面临KV缓存的性能挑战：空间争用导致关键智能体缓存被驱逐，时间利用率低导致等待外部函数调用的智能体缓存闲置。

Method: 采用智能体感知设计，空间调度器使用动态内存分区保护关键智能体，时间调度器使用主动卸载和预测性上传机制在函数调用停滞期间重新利用GPU内存。

Result: 在代表性多智能体基准测试中，相比vLLM，Tokencake能将端到端延迟降低超过47.06%，GPU内存有效利用率提升高达16.9%。

Conclusion: Tokencake通过协同优化调度和内存管理，有效解决了多智能体应用中KV缓存的性能瓶颈问题。

Abstract: Large Language Models (LLMs) are increasingly deployed in complex multi-agent
applications that use external function calls. This workload creates severe
performance challenges for the KV Cache: space contention leads to the eviction
of critical agents' caches and time underutilization leaves the cache of agents
stalled on long-running tool calls idling in GPU memory. We present Tokencake,
a KV-Cache-centric serving framework that co-optimizes scheduling and memory
management with an agent-aware design. Tokencake's Space Scheduler uses dynamic
memory partitioning to shield critical agents from contention, while its Time
Scheduler employs a proactive offload and predictive upload mechanism to
repurpose GPU memory during function call stalls. Our evaluation on
representative multi-agent benchmarks shows that Tokencake can reduce
end-to-end latency by over 47.06%, improve effective GPU memory utilization by
up to 16.9% compared to vLLM.

</details>


### [40] [Distributed Interactive Proofs for Planarity with Log-Star Communication](https://arxiv.org/abs/2510.18592)
*Yuval Gil,Merav Parter*

Main category: cs.DC

TL;DR: 本文提出了新的通信高效的分布式交互证明协议用于平面性验证，实现了O(log* n)轮交互和O(1)证明大小的嵌入式平面性验证。


<details>
  <summary>Details</summary>
Motivation: 分布式交互证明(DIP)由Kol等人引入，旨在通过集中式证明者与分布式验证者之间的高效通信来验证图的性质，目标是减少交互轮次和证明大小。

Method: 设计了多轮交互协议，对于嵌入式平面性和一般平面性验证，分别实现了O(log* n)轮交互和O(1)或O(⌈log Δ/log* n⌉)的证明大小，并可推广到任意1≤r≤log* n轮次。

Result: 实现了嵌入式平面性的O(log* n)轮DIP协议，证明大小为O(1)；一般平面性的证明大小为O(⌈log Δ/log* n⌉)。协议可灵活调整轮次与证明大小的权衡。

Conclusion: 该工作显著改进了平面性验证的分布式交互证明效率，为图性质验证提供了更高效的通信协议框架。

Abstract: We provide new communication-efficient distributed interactive proofs for
planarity. The notion of a \emph{distributed interactive proof (DIP)} was
introduced by Kol, Oshman, and Saxena (PODC 2018). In a DIP, the \emph{prover}
is a single centralized entity whose goal is to prove a certain claim regarding
an input graph $G$. To do so, the prover communicates with a distributed
\emph{verifier} that operates concurrently on all $n$ nodes of $G$. A DIP is
measured by the amount of prover-verifier communication it requires. Namely,
the goal is to design a DIP with a small number of interaction rounds and a
small \emph{proof size}, i.e., a small amount of communication per round. Our
main result is an $O(\log ^{*}n)$-round DIP protocol for embedded planarity and
planarity with a proof size of $O(1)$ and $O(\lceil\log \Delta/\log
^{*}n\rceil)$, respectively. In fact, this result can be generalized as
follows. For any $1\leq r\leq \log^{*}n$, there exists an $O(r)$-round protocol
for embedded planarity and planarity with a proof size of $O(\log ^{(r)}n)$ and
$O(\log ^{(r)}n+\log \Delta /r)$, respectively.

</details>


### [41] [Towards an Optimized Benchmarking Platform for CI/CD Pipelines](https://arxiv.org/abs/2510.18640)
*Nils Japke,Sebastian Koch,Helmut Lukasczyk,David Bermbach*

Main category: cs.DC

TL;DR: 性能基准测试优化在CI/CD系统中的实际应用面临三大挑战：优化策略的可组合性、自动化评估以及实际应用复杂性，需要研究解决以提升性能回归检测的实用性。


<details>
  <summary>Details</summary>
Motivation: 大规模软件系统中的性能回归会导致严重的资源效率问题，但频繁的基准测试在CI/CD流水线中面临资源密集和时间消耗的挑战，现有优化技术缺乏实际集成方案。

Method: 识别了三个核心挑战：基准测试优化策略的可组合性、基准测试结果的自动化评估、以及在实际CI/CD系统中应用这些策略的可用性和复杂性。提出了一个概念性的云基准测试框架来处理这些挑战。

Result: 提出了一个概念框架，但尚未实现具体系统。主要贡献是明确了阻碍基准测试优化技术广泛采用的关键问题领域。

Conclusion: 基准测试优化领域在关键方面仍未被充分探索，需要进一步研究来解决已识别的挑战，使CI/CD系统中的性能回归检测更加实用和有效。

Abstract: Performance regressions in large-scale software systems can lead to
substantial resource inefficiencies, making their early detection critical.
Frequent benchmarking is essential for identifying these regressions and
maintaining service-level agreements (SLAs). Performance benchmarks, however,
are resource-intensive and time-consuming, which is a major challenge for
integration into Continuous Integration / Continuous Deployment (CI/CD)
pipelines. Although numerous benchmark optimization techniques have been
proposed to accelerate benchmark execution, there is currently no practical
system that integrates these optimizations seamlessly into real-world CI/CD
pipelines. In this vision paper, we argue that the field of benchmark
optimization remains under-explored in key areas that hinder its broader
adoption. We identify three central challenges to enabling frequent and
efficient benchmarking: (a) the composability of benchmark optimization
strategies, (b) automated evaluation of benchmarking results, and (c) the
usability and complexity of applying these strategies as part of CI/CD systems
in practice. We also introduce a conceptual cloud-based benchmarking framework
handling these challenges transparently. By presenting these open problems, we
aim to stimulate research toward making performance regression detection in
CI/CD systems more practical and effective.

</details>


### [42] [PCMS: Parallel Coupler For Multimodel Simulations](https://arxiv.org/abs/2510.18838)
*Jacob S. Merson,Cameron W. Smith,Mark S. Shephard,Fuad Hasan,Abhiyan Paudel,Angel Castillo-Crooke,Joyal Mathew,Mohammad Elahi*

Main category: cs.DC

TL;DR: PCMS是一个新的GPU加速通用耦合框架，用于在超级计算机上耦合模拟代码，支持五维分布式控制和场映射方法，在Frontier超级计算机的2080个GPU上展示了85%的弱扩展效率。


<details>
  <summary>Details</summary>
Motivation: 开发一个能够在领导级超级计算机上高效耦合不同模拟代码的通用框架，以支持复杂的多物理场模拟需求。

Method: PCMS框架包括分布式控制和场映射方法，支持多达五维的耦合，能够利用离散化和场信息来适应物理约束，并通过GPU加速提高性能。

Result: 成功演示了XGC与DEGAS2的耦合，以及GNET与GTC的五维分布函数耦合，在Frontier的2080个GPU上实现了85%的弱扩展效率。

Conclusion: PCMS是一个高效、可扩展的耦合框架，能够支持复杂的多模型模拟，在领导级超级计算机上表现出良好的性能。

Abstract: This paper presents the Parallel Coupler for Multimodel Simulations (PCMS), a
new GPU accelerated generalized coupling framework for coupling simulation
codes on leadership class supercomputers. PCMS includes distributed control and
field mapping methods for up to five dimensions. For field mapping PCMS can
utilize discretization and field information to accommodate physics
constraints. PCMS is demonstrated with a coupling of the gyrokinetic
microturbulence code XGC with a Monte Carlo neutral transport code DEGAS2 and
with a 5D distribution function coupling of an energetic particle transport
code (GNET) to a gyrokinetic microturbulence code (GTC). Weak scaling is also
demonstrated on up to 2,080 GPUs of Frontier with a weak scaling efficiency of
85%.

</details>
