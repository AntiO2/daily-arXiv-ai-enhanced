{"id": "2601.04432", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2601.04432", "abs": "https://arxiv.org/abs/2601.04432", "authors": ["Harshavardhan Kamarthi", "Harshil Shah", "Henry Milner", "Sayan Sinha", "Yan Li", "B. Aditya Prakash", "Vyas Sekar"], "title": "AHA: Scalable Alternative History Analysis for Operational Timeseries Applications", "comment": "To Appear at KDD 2026", "summary": "Many operational systems collect high-dimensional timeseries data about users/systems on key performance metrics. For instance, ISPs, content distribution networks, and video delivery services collect quality of experience metrics for user sessions associated with metadata (e.g., location, device, ISP). Over such historical data, operators and data analysts often need to run retrospective analysis; e.g., analyze anomaly detection algorithms, experiment with different configurations for alerts, evaluate new algorithms, and so on. We refer to this class of workloads as alternative history analysis for operational datasets. We show that in such settings, traditional data processing solutions (e.g., data warehouses, sampling, sketching, big-data systems) either pose high operational costs or do not guarantee accurate replay. We design and implement a system, called AHA (Alternative History Analytics), that overcomes both challenges to provide cost efficiency and fidelity for high-dimensional data. The design of AHA is based on analytical and empirical insights about such workloads: 1) the decomposability of underlying statistics; 2) sparsity in terms of active number of subpopulations over attribute-value combinations; and 3) efficiency structure of aggregation operations in modern analytics databases. Using multiple real-world datasets and as well as case-studies on production pipelines at a large video analytics company, we show that AHA provides 100% accuracy for a broad range of downstream tasks and up to 85x lower total cost of ownership (i.e., compute + storage) compared to conventional methods.", "AI": {"tldr": "AHA\u7cfb\u7edf\u4e3a\u9ad8\u7ef4\u65f6\u5e8f\u6570\u636e\u7684\u66ff\u4ee3\u5386\u53f2\u5206\u6790\u63d0\u4f9b\u6210\u672c\u6548\u76ca\u548c\u4fdd\u771f\u5ea6\u4fdd\u8bc1\uff0c\u76f8\u6bd4\u4f20\u7edf\u65b9\u6cd5\u964d\u4f4e85\u500d\u603b\u62e5\u6709\u6210\u672c", "motivation": "\u8fd0\u8425\u5546\u548c\u5206\u6790\u5e08\u9700\u8981\u5bf9\u9ad8\u7ef4\u65f6\u5e8f\u6570\u636e\u8fdb\u884c\u56de\u987e\u6027\u5206\u6790\uff08\u5982\u5f02\u5e38\u68c0\u6d4b\u3001\u7b97\u6cd5\u8bc4\u4f30\u7b49\uff09\uff0c\u4f46\u4f20\u7edf\u6570\u636e\u5904\u7406\u65b9\u6848\u8981\u4e48\u8fd0\u8425\u6210\u672c\u9ad8\uff0c\u8981\u4e48\u65e0\u6cd5\u4fdd\u8bc1\u51c6\u786e\u91cd\u653e", "method": "\u8bbe\u8ba1AHA\u7cfb\u7edf\uff0c\u57fa\u4e8e\u4e09\u4e2a\u5173\u952e\u6d1e\u5bdf\uff1a1)\u5e95\u5c42\u7edf\u8ba1\u7684\u53ef\u5206\u89e3\u6027\uff1b2)\u5c5e\u6027\u503c\u7ec4\u5408\u4e2d\u5b50\u7fa4\u4f53\u6d3b\u8dc3\u5ea6\u7684\u7a00\u758f\u6027\uff1b3)\u73b0\u4ee3\u5206\u6790\u6570\u636e\u5e93\u4e2d\u805a\u5408\u64cd\u4f5c\u7684\u9ad8\u6548\u7ed3\u6784", "result": "\u5728\u591a\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u548c\u751f\u4ea7\u7ba1\u9053\u6848\u4f8b\u7814\u7a76\u4e2d\uff0cAHA\u4e3a\u5e7f\u6cdb\u7684\u4e0b\u6e38\u4efb\u52a1\u63d0\u4f9b100%\u51c6\u786e\u5ea6\uff0c\u76f8\u6bd4\u4f20\u7edf\u65b9\u6cd5\u603b\u62e5\u6709\u6210\u672c\uff08\u8ba1\u7b97+\u5b58\u50a8\uff09\u964d\u4f4e\u9ad8\u8fbe85\u500d", "conclusion": "AHA\u7cfb\u7edf\u6210\u529f\u89e3\u51b3\u4e86\u9ad8\u7ef4\u65f6\u5e8f\u6570\u636e\u66ff\u4ee3\u5386\u53f2\u5206\u6790\u4e2d\u7684\u6210\u672c\u6548\u7387\u548c\u4fdd\u771f\u5ea6\u6311\u6218\uff0c\u4e3a\u8fd0\u8425\u5546\u63d0\u4f9b\u7ecf\u6d4e\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848"}}
{"id": "2601.04722", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2601.04722", "abs": "https://arxiv.org/abs/2601.04722", "authors": ["Chrysanthi Kosyfaki", "Ruiyuan Zhang", "Nikos Mamoulis", "Xiaofang Zhou"], "title": "Does Provenance Interact?", "comment": null, "summary": "Data provenance (the process of determining the origin and derivation of data outputs) has applications across multiple domains including explaining database query results and auditing scientific workflows. Despite decades of research, provenance tracing remains challenging due to computational costs and storage overhead. In streaming systems such as Apache Flink, provenance graphs can grow super-linearly with data volume, posing significant scalability challenges. Temporal provenance is a promising direction, attaching timestamps to provenance information, enabling time-focused queries without maintaining complete historical records. However, existing temporal provenance methods primarily focus on system-level debugging, leaving a gap in data management applications. This paper proposes an agenda that uses Temporal Interaction Networks (TINs) to represent temporal provenance efficiently. We demonstrate TINs' applicability across streaming systems, transportation networks, and financial networks. We classify data into discrete and liquid types, define five temporal provenance query types, and propose a state-based indexing approach. Our vision outlines research directions toward making temporal provenance a practical tool for large-scale dataflows.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4f7f\u7528\u65f6\u95f4\u4ea4\u4e92\u7f51\u7edc(TINs)\u9ad8\u6548\u8868\u793a\u65f6\u95f4\u6eaf\u6e90\u4fe1\u606f\uff0c\u89e3\u51b3\u6d41\u5f0f\u7cfb\u7edf\u4e2d\u6eaf\u6e90\u56fe\u968f\u6570\u636e\u91cf\u8d85\u7ebf\u6027\u589e\u957f\u7684\u53ef\u6269\u5c55\u6027\u95ee\u9898\uff0c\u4e3a\u5927\u89c4\u6a21\u6570\u636e\u6d41\u63d0\u4f9b\u5b9e\u7528\u5de5\u5177\u3002", "motivation": "\u6570\u636e\u6eaf\u6e90\u5728\u6570\u636e\u5e93\u67e5\u8be2\u89e3\u91ca\u548c\u79d1\u5b66\u5de5\u4f5c\u6d41\u5ba1\u8ba1\u7b49\u591a\u4e2a\u9886\u57df\u6709\u91cd\u8981\u5e94\u7528\uff0c\u4f46\u4f20\u7edf\u6eaf\u6e90\u65b9\u6cd5\u9762\u4e34\u8ba1\u7b97\u6210\u672c\u548c\u5b58\u50a8\u5f00\u9500\u7684\u6311\u6218\u3002\u5728\u6d41\u5f0f\u7cfb\u7edf\u4e2d\uff0c\u6eaf\u6e90\u56fe\u968f\u6570\u636e\u91cf\u8d85\u7ebf\u6027\u589e\u957f\uff0c\u5b58\u5728\u663e\u8457\u7684\u53ef\u6269\u5c55\u6027\u95ee\u9898\u3002\u73b0\u6709\u65f6\u95f4\u6eaf\u6e90\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u7cfb\u7edf\u7ea7\u8c03\u8bd5\uff0c\u5728\u6570\u636e\u7ba1\u7406\u5e94\u7528\u65b9\u9762\u5b58\u5728\u7a7a\u767d\u3002", "method": "\u63d0\u51fa\u4f7f\u7528\u65f6\u95f4\u4ea4\u4e92\u7f51\u7edc(TINs)\u8868\u793a\u65f6\u95f4\u6eaf\u6e90\u4fe1\u606f\uff0c\u5c06\u6570\u636e\u5206\u4e3a\u79bb\u6563\u578b\u548c\u6d41\u52a8\u578b\u4e24\u7c7b\uff0c\u5b9a\u4e49\u4e94\u79cd\u65f6\u95f4\u6eaf\u6e90\u67e5\u8be2\u7c7b\u578b\uff0c\u5e76\u63d0\u51fa\u57fa\u4e8e\u72b6\u6001\u7684\u7d22\u5f15\u65b9\u6cd5\u3002\u8be5\u65b9\u6cd5\u9002\u7528\u4e8e\u6d41\u5f0f\u7cfb\u7edf\u3001\u4ea4\u901a\u7f51\u7edc\u548c\u91d1\u878d\u7f51\u7edc\u7b49\u591a\u79cd\u573a\u666f\u3002", "result": "\u5c55\u793a\u4e86TINs\u5728\u591a\u4e2a\u9886\u57df\u7684\u9002\u7528\u6027\uff0c\u63d0\u51fa\u4e86\u7cfb\u7edf\u5316\u7684\u65f6\u95f4\u6eaf\u6e90\u6846\u67b6\uff0c\u5305\u62ec\u6570\u636e\u5206\u7c7b\u3001\u67e5\u8be2\u7c7b\u578b\u5b9a\u4e49\u548c\u7d22\u5f15\u65b9\u6cd5\uff0c\u4e3a\u5927\u89c4\u6a21\u6570\u636e\u6d41\u7684\u65f6\u95f4\u6eaf\u6e90\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7814\u7a76\u8bae\u7a0b\uff0c\u65e8\u5728\u901a\u8fc7\u65f6\u95f4\u4ea4\u4e92\u7f51\u7edc\u4f7f\u65f6\u95f4\u6eaf\u6e90\u6210\u4e3a\u5927\u89c4\u6a21\u6570\u636e\u6d41\u7684\u5b9e\u7528\u5de5\u5177\uff0c\u5e76\u89c4\u5212\u4e86\u672a\u6765\u7684\u7814\u7a76\u65b9\u5411\uff0c\u4e3a\u89e3\u51b3\u6eaf\u6e90\u53ef\u6269\u5c55\u6027\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2601.04757", "categories": ["cs.DB", "cs.LO"], "pdf": "https://arxiv.org/pdf/2601.04757", "abs": "https://arxiv.org/abs/2601.04757", "authors": ["Cristian Riveros", "Benjamin Scheidt", "Nicole Schweikardt"], "title": "Structural Indexing of Relational Databases for the Evaluation of Free-Connex Acyclic Conjunctive Queries", "comment": "This paper supersedes the preprint arXiv:2405.12358 by the same authors that only considered the special case of binary schemas", "summary": "We present an index structure to boost the evaluation of free-connex acyclic conjunctive queries (fc-ACQs) over relational databases. The main ingredient of the index associated with a given database $D$ is an auxiliary database $D_{col}$. Our main result states that for any fc-ACQ $Q$ over $D$, we can count the number of answers of $Q$ or enumerate them with constant delay after a preprocessing phase that takes time linear in the size of $D_{col}$.\n  Unlike previous indexing methods based on values or order (e.g., B+ trees), our index is based on structural symmetries among tuples in a database, and the size of $D_{col}$ is related to the number of colors assigned to $D$ by Scheidt and Schweikardt's \"relational color refinement\" (2025). In the particular case of graphs, this coincides with the minimal size of an equitable partition of the graph. For example, the size of $D_{col}$ is logarithmic in the case of binary trees and constant for regular graphs. Even in the worst-case that $D$ has no structural symmetries among tuples at all, the size of $D_{col}$ is still linear in the size of $D$.\n  Given that the size of $D_{col}$ is bounded by the size of $D$ and can be much smaller (even constant for some families of databases), our index is the first foundational result on indexing internal structural symmetries of a database to evaluate all fc-ACQs with performance potentially strictly smaller than the database size.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u6570\u636e\u5e93\u7ed3\u6784\u5bf9\u79f0\u6027\u7684\u7d22\u5f15\u65b9\u6cd5\uff0c\u7528\u4e8e\u9ad8\u6548\u8bc4\u4f30\u81ea\u7531\u8fde\u63a5\u65e0\u73af\u8fde\u63a5\u67e5\u8be2\uff0c\u9884\u5904\u7406\u65f6\u95f4\u4e0e\u8f85\u52a9\u6570\u636e\u5e93\u5927\u5c0f\u7ebf\u6027\u76f8\u5173\uff0c\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\u8f85\u52a9\u6570\u636e\u5e93\u5927\u5c0f\u53ef\u8fdc\u5c0f\u4e8e\u539f\u6570\u636e\u5e93\u3002", "motivation": "\u73b0\u6709\u7d22\u5f15\u65b9\u6cd5\u4e3b\u8981\u57fa\u4e8e\u503c\u6216\u987a\u5e8f\uff08\u5982B+\u6811\uff09\uff0c\u7f3a\u4e4f\u5229\u7528\u6570\u636e\u5e93\u5185\u90e8\u7ed3\u6784\u5bf9\u79f0\u6027\u7684\u7d22\u5f15\u6280\u672f\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u5229\u7528\u6570\u636e\u5e93\u7ed3\u6784\u5bf9\u79f0\u6027\u6765\u9ad8\u6548\u8bc4\u4f30\u81ea\u7531\u8fde\u63a5\u65e0\u73af\u8fde\u63a5\u67e5\u8be2\u7684\u65b9\u6cd5\u3002", "method": "\u6784\u5efa\u57fa\u4e8e\u7ed3\u6784\u5bf9\u79f0\u6027\u7684\u7d22\u5f15\u7ed3\u6784\uff0c\u6838\u5fc3\u662f\u521b\u5efa\u8f85\u52a9\u6570\u636e\u5e93D_col\uff0c\u8be5\u6570\u636e\u5e93\u7684\u5927\u5c0f\u4e0eScheidt\u548cSchweikardt\u7684\"\u5173\u7cfb\u989c\u8272\u7ec6\u5316\"\u7b97\u6cd5\u5206\u914d\u7684\u989c\u8272\u6570\u91cf\u76f8\u5173\u3002\u5229\u7528\u6570\u636e\u5e93\u5143\u7ec4\u95f4\u7684\u7ed3\u6784\u5bf9\u79f0\u6027\u6765\u52a0\u901f\u67e5\u8be2\u5904\u7406\u3002", "result": "\u5bf9\u4e8e\u4efb\u4f55\u81ea\u7531\u8fde\u63a5\u65e0\u73af\u8fde\u63a5\u67e5\u8be2\uff0c\u53ef\u4ee5\u5728\u4e0eD_col\u5927\u5c0f\u7ebf\u6027\u76f8\u5173\u7684\u9884\u5904\u7406\u65f6\u95f4\u540e\uff0c\u4ee5\u5e38\u6570\u5ef6\u8fdf\u8ba1\u6570\u6216\u679a\u4e3e\u67e5\u8be2\u7ed3\u679c\u3002D_col\u5927\u5c0f\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\u53ef\u8fdc\u5c0f\u4e8e\u539f\u6570\u636e\u5e93\uff08\u5982\u4e8c\u53c9\u6811\u4e2d\u5bf9\u6570\u5927\u5c0f\uff0c\u6b63\u5219\u56fe\u4e2d\u5e38\u6570\u5927\u5c0f\uff09\u3002", "conclusion": "\u8fd9\u662f\u9996\u4e2a\u57fa\u4e8e\u6570\u636e\u5e93\u5185\u90e8\u7ed3\u6784\u5bf9\u79f0\u6027\u7684\u7d22\u5f15\u57fa\u7840\u6027\u6210\u679c\uff0c\u80fd\u591f\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\u5b9e\u73b0\u6bd4\u6570\u636e\u5e93\u5927\u5c0f\u66f4\u4f18\u7684\u67e5\u8be2\u6027\u80fd\uff0c\u4e3a\u5229\u7528\u7ed3\u6784\u5bf9\u79f0\u6027\u4f18\u5316\u67e5\u8be2\u8bc4\u4f30\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2601.04820", "categories": ["cs.DB", "cs.SI"], "pdf": "https://arxiv.org/pdf/2601.04820", "abs": "https://arxiv.org/abs/2601.04820", "authors": ["Chotanansub Sophaken", "Thanadej Rattanakornphan", "Piyanon Charoenpoonpanich", "Thanapol Phungtua-eng", "Chainarong Amornbunchornvej"], "title": "LGTD: Local-Global Trend Decomposition for Season-Length-Free Time Series Analysis", "comment": "First draft", "summary": "Time series decomposition into trend, seasonal structure, and residual components is a core primitive for downstream analytics such as anomaly detection, change-point detection, and forecasting. However, most existing seasonal-trend decomposition methods rely on user-specified or estimated season lengths and implicitly assume stable periodic structure. These assumptions limit robustness and deployability in large, heterogeneous collections where recurring patterns may drift, appear intermittently, or exist at multiple time scales.\n  We propose LGTD (Local-Global Trend Decomposition), a season-length-free decomposition framework that represents a time series as the sum of a smooth global trend, adaptive local trends whose recurrence induces implicit (emergent) seasonal structure, and a residual component. Rather than explicitly modeling seasonality through a fixed or estimated period, LGTD treats seasonal structure as an emergent property arising from repeated local trend regimes. Concretely, LGTD first estimates a global trend capturing long-term evolution, then applies AutoTrend, an adaptive error-driven local linear trend inference module, to segment the detrended signal into short-lived piecewise-linear regimes. Residuals are obtained after removing both global and local trends.\n  By eliminating manual season-length specification, LGTD supports automated, low-touch deployment across time series with irregular, drifting, or weakly periodic structure. We analyze computational complexity and show that LGTD scales linearly with series length under mild conditions. Experiments on synthetic benchmarks demonstrate robust and balanced decomposition performance across fixed, transitive, and variable season-length settings, especially where period-based methods degrade.", "AI": {"tldr": "LGTD\u662f\u4e00\u79cd\u65e0\u9700\u6307\u5b9a\u5b63\u8282\u957f\u5ea6\u7684\u65f6\u5e8f\u5206\u89e3\u65b9\u6cd5\uff0c\u901a\u8fc7\u5168\u5c40\u8d8b\u52bf\u548c\u81ea\u9002\u5e94\u5c40\u90e8\u8d8b\u52bf\u6765\u9690\u5f0f\u6355\u6349\u5b63\u8282\u6027\u7ed3\u6784\uff0c\u9002\u7528\u4e8e\u4e0d\u89c4\u5219\u3001\u6f02\u79fb\u6216\u5f31\u5468\u671f\u6027\u7684\u65f6\u95f4\u5e8f\u5217\u3002", "motivation": "\u73b0\u6709\u5b63\u8282\u8d8b\u52bf\u5206\u89e3\u65b9\u6cd5\u9700\u8981\u7528\u6237\u6307\u5b9a\u6216\u4f30\u8ba1\u5b63\u8282\u957f\u5ea6\uff0c\u5e76\u5047\u8bbe\u7a33\u5b9a\u7684\u5468\u671f\u7ed3\u6784\uff0c\u8fd9\u9650\u5236\u4e86\u5728\u5927\u578b\u5f02\u6784\u96c6\u5408\u4e2d\u7684\u9c81\u68d2\u6027\u548c\u53ef\u90e8\u7f72\u6027\uff0c\u56e0\u4e3a\u5b9e\u9645\u6570\u636e\u4e2d\u7684\u91cd\u590d\u6a21\u5f0f\u53ef\u80fd\u5b58\u5728\u6f02\u79fb\u3001\u95f4\u6b47\u51fa\u73b0\u6216\u591a\u65f6\u95f4\u5c3a\u5ea6\u3002", "method": "LGTD\u5c06\u65f6\u95f4\u5e8f\u5217\u5206\u89e3\u4e3a\u5e73\u6ed1\u5168\u5c40\u8d8b\u52bf\u3001\u81ea\u9002\u5e94\u5c40\u90e8\u8d8b\u52bf\uff08\u5176\u91cd\u590d\u51fa\u73b0\u4ea7\u751f\u9690\u5f0f\u5b63\u8282\u6027\u7ed3\u6784\uff09\u548c\u6b8b\u5dee\u5206\u91cf\u3002\u9996\u5148\u4f30\u8ba1\u6355\u83b7\u957f\u671f\u6f14\u5316\u7684\u5168\u5c40\u8d8b\u52bf\uff0c\u7136\u540e\u4f7f\u7528AutoTrend\uff08\u81ea\u9002\u5e94\u8bef\u5dee\u9a71\u52a8\u7684\u5c40\u90e8\u7ebf\u6027\u8d8b\u52bf\u63a8\u65ad\u6a21\u5757\uff09\u5c06\u53bb\u8d8b\u52bf\u4fe1\u53f7\u5206\u5272\u4e3a\u77ed\u671f\u5206\u6bb5\u7ebf\u6027\u533a\u95f4\u3002", "result": "LGTD\u5728\u56fa\u5b9a\u3001\u8fc7\u6e21\u548c\u53ef\u53d8\u5b63\u8282\u957f\u5ea6\u8bbe\u7f6e\u7684\u5408\u6210\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u7a33\u5065\u548c\u5e73\u8861\u7684\u5206\u89e3\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728\u57fa\u4e8e\u5468\u671f\u7684\u65b9\u6cd5\u6027\u80fd\u4e0b\u964d\u7684\u60c5\u51b5\u4e0b\u3002\u8be5\u65b9\u6cd5\u8ba1\u7b97\u590d\u6742\u5ea6\u4e0e\u5e8f\u5217\u957f\u5ea6\u5448\u7ebf\u6027\u5173\u7cfb\u3002", "conclusion": "LGTD\u901a\u8fc7\u6d88\u9664\u624b\u52a8\u6307\u5b9a\u5b63\u8282\u957f\u5ea6\u7684\u9700\u6c42\uff0c\u652f\u6301\u5728\u5177\u6709\u4e0d\u89c4\u5219\u3001\u6f02\u79fb\u6216\u5f31\u5468\u671f\u6027\u7ed3\u6784\u7684\u65f6\u95f4\u5e8f\u5217\u4e0a\u5b9e\u73b0\u81ea\u52a8\u5316\u3001\u4f4e\u63a5\u89e6\u90e8\u7f72\uff0c\u4e3a\u4e0b\u6e38\u5206\u6790\u63d0\u4f9b\u4e86\u66f4\u9c81\u68d2\u7684\u5206\u89e3\u57fa\u7840\u3002"}}
{"id": "2601.04252", "categories": ["cs.SE", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.04252", "abs": "https://arxiv.org/abs/2601.04252", "authors": ["Daoan Zhang", "Shuo Zhang", "Zijian Jin", "Jiebo Luo", "Shengyu Fu", "Elsie Nallipogu"], "title": "Sphinx: Benchmarking and Modeling for LLM-Driven Pull Request Review", "comment": null, "summary": "Pull request (PR) review is essential for ensuring software quality, yet automating this task remains challenging due to noisy supervision, limited contextual understanding, and inadequate evaluation metrics. We present Sphinx, a unified framework for LLM-based PR review that addresses these limitations through three key components: (1) a structured data generation pipeline that produces context-rich, semantically grounded review comments by comparing pseudo-modified and merged code; (2) a checklist-based evaluation benchmark that assesses review quality based on structured coverage of actionable verification points, moving beyond surface-level metrics like BLEU; and (3) Checklist Reward Policy Optimization (CRPO), a novel training paradigm that uses rule-based, interpretable rewards to align model behavior with real-world review practices. Extensive experiments show that models trained with Sphinx achieve state-of-the-art performance on review completeness and precision, outperforming both proprietary and open-source baselines by up to 40\\% in checklist coverage. Together, Sphinx enables the development of PR review models that are not only fluent but also context-aware, technically precise, and practically deployable in real-world development workflows. The data will be released after review.", "AI": {"tldr": "SPHINX\u662f\u4e00\u4e2a\u57fa\u4e8eLLM\u7684PR\u4ee3\u7801\u5ba1\u67e5\u7edf\u4e00\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u6570\u636e\u751f\u6210\u3001\u6e05\u5355\u5f0f\u8bc4\u4f30\u57fa\u51c6\u548c\u6e05\u5355\u5956\u52b1\u7b56\u7565\u4f18\u5316\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u81ea\u52a8\u5316\u4ee3\u7801\u5ba1\u67e5\u7684\u4e09\u5927\u6311\u6218\uff0c\u5728\u5ba1\u67e5\u5b8c\u6574\u6027\u548c\u7cbe\u786e\u6027\u4e0a\u8fbe\u5230SOTA\u6027\u80fd\u3002", "motivation": "\u81ea\u52a8\u5316PR\u4ee3\u7801\u5ba1\u67e5\u9762\u4e34\u4e09\u5927\u6311\u6218\uff1a\u566a\u58f0\u76d1\u7763\u3001\u6709\u9650\u7684\u4e0a\u4e0b\u6587\u7406\u89e3\u3001\u4e0d\u5145\u5206\u7684\u8bc4\u4f30\u6307\u6807\u3002\u73b0\u6709\u65b9\u6cd5\u65e0\u6cd5\u6709\u6548\u5904\u7406\u8fd9\u4e9b\u9650\u5236\uff0c\u9700\u8981\u66f4\u7cfb\u7edf\u5316\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "SPHINX\u5305\u542b\u4e09\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1a1) \u7ed3\u6784\u5316\u6570\u636e\u751f\u6210\u7ba1\u9053\uff0c\u901a\u8fc7\u6bd4\u8f83\u4f2a\u4fee\u6539\u4ee3\u7801\u548c\u5408\u5e76\u4ee3\u7801\u751f\u6210\u4e0a\u4e0b\u6587\u4e30\u5bcc\u7684\u5ba1\u67e5\u8bc4\u8bba\uff1b2) \u57fa\u4e8e\u6e05\u5355\u7684\u8bc4\u4f30\u57fa\u51c6\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u53ef\u64cd\u4f5c\u9a8c\u8bc1\u70b9\u8bc4\u4f30\u5ba1\u67e5\u8d28\u91cf\uff1b3) \u6e05\u5355\u5956\u52b1\u7b56\u7565\u4f18\u5316(CRPO)\uff0c\u4f7f\u7528\u57fa\u4e8e\u89c4\u5219\u7684\u3001\u53ef\u89e3\u91ca\u7684\u5956\u52b1\u6765\u5bf9\u9f50\u6a21\u578b\u884c\u4e3a\u4e0e\u5b9e\u9645\u5ba1\u67e5\u5b9e\u8df5\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u4f7f\u7528SPHINX\u8bad\u7ec3\u7684\u6a21\u578b\u5728\u5ba1\u67e5\u5b8c\u6574\u6027\u548c\u7cbe\u786e\u6027\u4e0a\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u5728\u6e05\u5355\u8986\u76d6\u7387\u4e0a\u6bd4\u4e13\u6709\u548c\u5f00\u6e90\u57fa\u7ebf\u9ad8\u51fa40%\u3002\u6a21\u578b\u4e0d\u4ec5\u6d41\u7545\uff0c\u800c\u4e14\u5177\u6709\u4e0a\u4e0b\u6587\u611f\u77e5\u80fd\u529b\u3001\u6280\u672f\u7cbe\u786e\u6027\uff0c\u5e76\u80fd\u5b9e\u9645\u90e8\u7f72\u5230\u5f00\u53d1\u5de5\u4f5c\u6d41\u4e2d\u3002", "conclusion": "SPHINX\u6846\u67b6\u80fd\u591f\u5f00\u53d1\u51fa\u65e2\u6d41\u7545\u53c8\u5177\u6709\u4e0a\u4e0b\u6587\u611f\u77e5\u80fd\u529b\u3001\u6280\u672f\u7cbe\u786e\u6027\u4e14\u53ef\u5b9e\u9645\u90e8\u7f72\u7684PR\u5ba1\u67e5\u6a21\u578b\uff0c\u89e3\u51b3\u4e86\u81ea\u52a8\u5316\u4ee3\u7801\u5ba1\u67e5\u7684\u5173\u952e\u6311\u6218\uff0c\u6570\u636e\u5c06\u5728\u5ba1\u67e5\u540e\u53d1\u5e03\u3002"}}
{"id": "2601.04327", "categories": ["cs.DC", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.04327", "abs": "https://arxiv.org/abs/2601.04327", "authors": ["Erel Kaplan", "Tomer Bitan", "Lian Ghrayeb", "Le Chen", "Tom Yotam", "Niranjan Hasabnis", "Gal Oren"], "title": "ParaCodex: A Profiling-Guided Autonomous Coding Agent for Reliable Parallel Code Generation and Translation", "comment": null, "summary": "Parallel programming is central to HPC and AI, but producing code that is correct and fast remains challenging, especially for OpenMP GPU offload, where data movement and tuning dominate. Autonomous coding agents can compile, test, and profile on target hardware, but outputs are brittle without domain scaffolding.\n  We present ParaCodex, an HPC-engineer workflow that turns a Codex-based agent into an autonomous OpenMP GPU offload system using staged hotspot analysis, explicit data planning, correctness gating, and profiling-guided refinement. We evaluate translation from serial CPU kernels to OpenMP GPU offload kernels on HeCBench, Rodinia, and NAS. After excluding five kernels, ParaCodex succeeded on all 31 valid kernels. The generated kernels improved GPU time over reference OpenMP implementations in 25/31 cases, achieving geometric-mean speedups of 3x on HeCBench and 5x on Rodinia, and outperforming a zero-shot Codex baseline on all suites. We also evaluate CUDA to OpenMP offload translation on ParEval, where ParaCodex maintains high compilation and validation rates in code-only and end-to-end settings.", "AI": {"tldr": "ParaCodex\u662f\u4e00\u4e2a\u57fa\u4e8eCodex\u7684\u81ea\u4e3b\u7f16\u7801\u7cfb\u7edf\uff0c\u7528\u4e8e\u5c06\u4e32\u884cCPU\u5185\u6838\u8f6c\u6362\u4e3aOpenMP GPU\u5378\u8f7d\u5185\u6838\uff0c\u901a\u8fc7\u70ed\u70b9\u5206\u6790\u3001\u6570\u636e\u89c4\u5212\u3001\u6b63\u786e\u6027\u68c0\u67e5\u548c\u6027\u80fd\u4f18\u5316\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5b9e\u73b0\u663e\u8457\u52a0\u901f\u3002", "motivation": "\u5e76\u884c\u7f16\u7a0b\u5bf9HPC\u548cAI\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u7f16\u5199\u6b63\u786e\u4e14\u9ad8\u6548\u7684\u4ee3\u7801\uff08\u7279\u522b\u662fOpenMP GPU\u5378\u8f7d\uff09\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\u3002\u73b0\u6709\u81ea\u4e3b\u7f16\u7801\u4ee3\u7406\u8f93\u51fa\u8106\u5f31\uff0c\u7f3a\u4e4f\u9886\u57df\u7279\u5b9a\u7684\u652f\u6491\u6846\u67b6\u3002", "method": "\u63d0\u51faParaCodex\u5de5\u4f5c\u6d41\uff0c\u5c06\u57fa\u4e8eCodex\u7684\u4ee3\u7406\u8f6c\u53d8\u4e3a\u81ea\u4e3bOpenMP GPU\u5378\u8f7d\u7cfb\u7edf\uff0c\u91c7\u7528\u5206\u9636\u6bb5\u70ed\u70b9\u5206\u6790\u3001\u663e\u5f0f\u6570\u636e\u89c4\u5212\u3001\u6b63\u786e\u6027\u95e8\u63a7\u548c\u6027\u80fd\u5206\u6790\u5f15\u5bfc\u7684\u4f18\u5316\u65b9\u6cd5\u3002", "result": "\u5728HeCBench\u3001Rodinia\u548cNAS\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cParaCodex\u6210\u529f\u5904\u740631\u4e2a\u6709\u6548\u5185\u6838\u4e2d\u768431\u4e2a\uff0c\u572825/31\u60c5\u51b5\u4e0b\u4f18\u4e8e\u53c2\u8003OpenMP\u5b9e\u73b0\uff0c\u51e0\u4f55\u5e73\u5747\u52a0\u901f\u6bd4\u5728HeCBench\u4e0a\u8fbe\u52303\u500d\uff0cRodinia\u4e0a\u8fbe\u52305\u500d\uff0c\u5728\u6240\u6709\u6d4b\u8bd5\u5957\u4ef6\u4e0a\u90fd\u4f18\u4e8e\u96f6\u6837\u672cCodex\u57fa\u7ebf\u3002", "conclusion": "ParaCodex\u5c55\u793a\u4e86\u81ea\u4e3b\u7f16\u7801\u4ee3\u7406\u5728HPC\u9886\u57df\u7684\u6f5c\u529b\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u5de5\u4f5c\u6d41\u548c\u9886\u57df\u7279\u5b9a\u4f18\u5316\uff0c\u80fd\u591f\u6709\u6548\u751f\u6210\u9ad8\u6027\u80fd\u7684OpenMP GPU\u5378\u8f7d\u4ee3\u7801\uff0c\u663e\u8457\u63d0\u5347\u5f00\u53d1\u6548\u7387\u3002"}}
{"id": "2601.04868", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2601.04868", "abs": "https://arxiv.org/abs/2601.04868", "authors": ["Meghyn Bienvenu", "Diego Figueira", "Pierre Lafourcade"], "title": "Responsibility Measures for Conjunctive Queries with Negation", "comment": "Full version of ICDT'26 paper", "summary": "We contribute to the recent line of work on responsibility measures that quantify the contributions of database facts to obtaining a query result. In contrast to existing work which has almost exclusively focused on monotone queries, here we explore how to define responsibility measures for unions of conjunctive queries with negated atoms (UCQ${}^\\lnot$). Starting from the question of what constitutes a reasonable notion of explanation or relevance for queries with negated atoms, we propose two approaches, one assigning scores to (positive) database facts and the other also considering negated facts. Our approaches, which are orthogonal to the previously studied score of Reshef et al., can be used to lift previously studied scores for monotone queries, known as drastic Shapley and weighted sums of minimal supports (WSMS), to UCQ$^\\lnot$. We investigate the data and combined complexity of the resulting measures, notably showing that the WSMS measures are tractable in data complexity for all UCQ${}^\\lnot$ queries and further establishing tractability in combined complexity for suitable classes of conjunctive queries with negation.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4e3a\u5177\u6709\u5426\u5b9a\u539f\u5b50\u7684\u8054\u5408\u5408\u53d6\u67e5\u8be2(UCQ\u00ac)\u63d0\u51fa\u4e86\u4e24\u79cd\u8d23\u4efb\u5ea6\u91cf\u65b9\u6cd5\uff0c\u5c06\u5355\u8c03\u67e5\u8be2\u7684\u8d23\u4efb\u5ea6\u91cf\u6269\u5c55\u5230\u975e\u5355\u8c03\u67e5\u8be2\uff0c\u5e76\u5206\u6790\u4e86\u8ba1\u7b97\u590d\u6742\u5ea6\u3002", "motivation": "\u73b0\u6709\u8d23\u4efb\u5ea6\u91cf\u7814\u7a76\u51e0\u4e4e\u5b8c\u5168\u96c6\u4e2d\u5728\u5355\u8c03\u67e5\u8be2\u4e0a\uff0c\u4f46\u5b9e\u9645\u5e94\u7528\u4e2d\u9700\u8981\u5904\u7406\u5305\u542b\u5426\u5b9a\u539f\u5b50\u7684\u67e5\u8be2\u3002\u9700\u8981\u4e3aUCQ\u00ac\u5b9a\u4e49\u5408\u7406\u7684\u8d23\u4efb\u5ea6\u91cf\u6765\u89e3\u91ca\u67e5\u8be2\u7ed3\u679c\u4e2d\u6570\u636e\u5e93\u4e8b\u5b9e\u7684\u8d21\u732e\u3002", "method": "\u63d0\u51fa\u4e24\u79cd\u65b9\u6cd5\uff1a1) \u4ec5\u7ed9\u6b63\u6570\u636e\u5e93\u4e8b\u5b9e\u5206\u914d\u5206\u6570\uff1b2) \u540c\u65f6\u8003\u8651\u6b63\u4e8b\u5b9e\u548c\u5426\u5b9a\u4e8b\u5b9e\u3002\u8fd9\u4e9b\u65b9\u6cd5\u5c06\u5355\u8c03\u67e5\u8be2\u7684drastic Shapley\u548cWSMS\u5ea6\u91cf\u6269\u5c55\u5230UCQ\u00ac\uff0c\u5e76\u7814\u7a76\u5176\u6570\u636e\u590d\u6742\u5ea6\u548c\u7ec4\u5408\u590d\u6742\u5ea6\u3002", "result": "\u8bc1\u660e\u4e86WSMS\u5ea6\u91cf\u5bf9\u6240\u6709UCQ\u00ac\u67e5\u8be2\u5728\u6570\u636e\u590d\u6742\u5ea6\u4e0a\u662f\u53ef\u5904\u7406\u7684\uff0c\u5e76\u4e3a\u5408\u9002\u7684\u5e26\u5426\u5b9a\u5408\u53d6\u67e5\u8be2\u7c7b\u5728\u7ec4\u5408\u590d\u6742\u5ea6\u4e0a\u5efa\u7acb\u4e86\u53ef\u5904\u7406\u6027\u3002", "conclusion": "\u6210\u529f\u5c06\u8d23\u4efb\u5ea6\u91cf\u4ece\u5355\u8c03\u67e5\u8be2\u6269\u5c55\u5230\u5305\u542b\u5426\u5b9a\u539f\u5b50\u7684\u67e5\u8be2\uff0c\u63d0\u4f9b\u4e86\u4e24\u79cd\u5408\u7406\u7684\u89e3\u91ca\u65b9\u6cd5\uff0c\u5e76\u8bc1\u660e\u4e86\u67d0\u4e9b\u5ea6\u91cf\u5728\u8ba1\u7b97\u4e0a\u7684\u53ef\u884c\u6027\uff0c\u4e3a\u975e\u5355\u8c03\u67e5\u8be2\u7684\u89e3\u91ca\u6027\u5206\u6790\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2601.04293", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.04293", "abs": "https://arxiv.org/abs/2601.04293", "authors": ["Nathan Shaw", "Sanjeetha Pennada", "Robert M Hierons", "Donghwan Shin"], "title": "A Systematic Mapping Study on the Debugging of Autonomous Driving Systems", "comment": "33 pages, 7 figures", "summary": "As Autonomous Driving Systems (ADS) progress towards commercial deployment, there is an increasing focus on ensuring their safety and reliability. While considerable research has been conducted on testing methods for detecting faults in ADS, very little attention has been paid to debugging in ADS. Debugging is an essential process that follows test failures to localise and repair the faults in the systems to maintain their safety and reliability. This Systematic Mapping Study (SMS) aims to provide a detailed overview of the current landscape of ADS debugging, highlighting existing approaches and identifying gaps in research. The study also proposes directions for future work and standards for problem definition and terminology in the field. Our findings reveal various methods for ADS debugging and highlight the current fragmented yet promising landscape.", "AI": {"tldr": "\u8fd9\u7bc7\u7cfb\u7edf\u6620\u5c04\u7814\u7a76\u7efc\u8ff0\u4e86\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u8c03\u8bd5\u7684\u73b0\u72b6\uff0c\u53d1\u73b0\u8be5\u9886\u57df\u7814\u7a76\u5206\u6563\u4f46\u524d\u666f\u5e7f\u9614\uff0c\u63d0\u51fa\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\u4e0e\u672f\u8bed\u6807\u51c6\u5316\u5efa\u8bae\u3002", "motivation": "\u968f\u7740\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u5411\u5546\u4e1a\u5316\u90e8\u7f72\u53d1\u5c55\uff0c\u786e\u4fdd\u5176\u5b89\u5168\u53ef\u9760\u6027\u65e5\u76ca\u91cd\u8981\u3002\u867d\u7136\u5df2\u6709\u5927\u91cf\u6d4b\u8bd5\u65b9\u6cd5\u7814\u7a76\u7528\u4e8e\u68c0\u6d4b\u6545\u969c\uff0c\u4f46\u8c03\u8bd5\u8fc7\u7a0b\uff08\u5b9a\u4f4d\u548c\u4fee\u590d\u6545\u969c\uff09\u5374\u5f88\u5c11\u53d7\u5230\u5173\u6ce8\uff0c\u800c\u8c03\u8bd5\u5bf9\u4e8e\u7ef4\u6301\u7cfb\u7edf\u5b89\u5168\u53ef\u9760\u6027\u81f3\u5173\u91cd\u8981\u3002", "method": "\u91c7\u7528\u7cfb\u7edf\u6620\u5c04\u7814\u7a76\u65b9\u6cd5\uff0c\u5bf9\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u8c03\u8bd5\u9886\u57df\u7684\u73b0\u6709\u7814\u7a76\u8fdb\u884c\u5168\u9762\u68b3\u7406\u548c\u5206\u6790\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u8c03\u8bd5\u5b58\u5728\u591a\u79cd\u65b9\u6cd5\uff0c\u5f53\u524d\u7814\u7a76\u683c\u5c40\u5448\u73b0\u5206\u6563\u4f46\u524d\u666f\u5e7f\u9614\u7684\u7279\u70b9\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u8c03\u8bd5\u7684\u73b0\u72b6\uff0c\u63d0\u51fa\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\uff0c\u5e76\u5efa\u8bae\u5efa\u7acb\u95ee\u9898\u5b9a\u4e49\u548c\u672f\u8bed\u6807\u51c6\u5316\u6846\u67b6\u3002"}}
{"id": "2601.04349", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2601.04349", "abs": "https://arxiv.org/abs/2601.04349", "authors": ["Xaver Stiensmeier", "Alexander Kanitz", "Jan Kr\u00fcger", "Santiago Insua", "Adri\u00e1n Ro\u0161inec", "Vikt\u00f3ria Spi\u0161\u00e1kov\u00e1", "Luk\u00e1\u0161 Hejtm\u00e1nek", "David Yuan", "Gavin Farrell", "Jonathan Tedds", "Juha T\u00f6rnroos", "Harald Wagener", "Alex Sczyrba", "Nils Hoffmann", "Matej Antol"], "title": "Hybrid Cloud Architectures for Research Computing: Applications and Use Cases", "comment": null, "summary": "Scientific research increasingly depends on robust and scalable IT infrastructures to support complex computational workflows. With the proliferation of services provided by research infrastructures, NRENs, and commercial cloud providers, researchers must navigate a fragmented ecosystem of computing environments, balancing performance, cost, scalability, and accessibility. Hybrid cloud architectures offer a compelling solution by integrating multiple computing environments to enhance flexibility, resource efficiency, and access to specialised hardware.\n  This paper provides a comprehensive overview of hybrid cloud deployment models, focusing on grid and cloud platforms (OpenPBS, SLURM, OpenStack, Kubernetes) and workflow management tools (Nextflow, Snakemake, CWL). We explore strategies for federated computing, multi-cloud orchestration, and workload scheduling, addressing key challenges such as interoperability, data security, reproducibility, and network performance. Drawing on implementations from life sciences, as coordinated by the ELIXIR Compute Platform and their integration into a wider EOSC context, we propose a roadmap for accelerating hybrid cloud adoption in research computing, emphasising governance frameworks and technical solutions that can drive sustainable and scalable infrastructure development.", "AI": {"tldr": "\u672c\u6587\u5168\u9762\u7efc\u8ff0\u4e86\u6df7\u5408\u4e91\u90e8\u7f72\u6a21\u578b\uff0c\u91cd\u70b9\u5173\u6ce8\u7f51\u683c\u4e0e\u4e91\u5e73\u53f0\uff08OpenPBS\u3001SLURM\u3001OpenStack\u3001Kubernetes\uff09\u548c\u5de5\u4f5c\u6d41\u7ba1\u7406\u5de5\u5177\uff08Nextflow\u3001Snakemake\u3001CWL\uff09\uff0c\u63a2\u8ba8\u4e86\u8054\u90a6\u8ba1\u7b97\u3001\u591a\u4e91\u7f16\u6392\u548c\u8d1f\u8f7d\u8c03\u5ea6\u7b56\u7565\uff0c\u5e76\u57fa\u4e8e\u751f\u547d\u79d1\u5b66\u9886\u57df\u7684\u5b9e\u65bd\u6848\u4f8b\u63d0\u51fa\u4e86\u52a0\u901f\u7814\u7a76\u8ba1\u7b97\u4e2d\u6df7\u5408\u4e91\u91c7\u7528\u7684\u8def\u7ebf\u56fe\u3002", "motivation": "\u79d1\u5b66\u7814\u7a76\u65e5\u76ca\u4f9d\u8d56\u7a33\u5065\u4e14\u53ef\u6269\u5c55\u7684IT\u57fa\u7840\u8bbe\u65bd\u6765\u652f\u6301\u590d\u6742\u8ba1\u7b97\u5de5\u4f5c\u6d41\u3002\u968f\u7740\u7814\u7a76\u57fa\u7840\u8bbe\u65bd\u3001NREN\u548c\u5546\u4e1a\u4e91\u63d0\u4f9b\u5546\u63d0\u4f9b\u7684\u670d\u52a1\u6fc0\u589e\uff0c\u7814\u7a76\u4eba\u5458\u5fc5\u987b\u5728\u4e00\u4e2a\u788e\u7247\u5316\u7684\u8ba1\u7b97\u73af\u5883\u751f\u6001\u7cfb\u7edf\u4e2d\u5bfc\u822a\uff0c\u5e73\u8861\u6027\u80fd\u3001\u6210\u672c\u3001\u53ef\u6269\u5c55\u6027\u548c\u53ef\u8bbf\u95ee\u6027\u3002\u6df7\u5408\u4e91\u67b6\u6784\u901a\u8fc7\u96c6\u6210\u591a\u4e2a\u8ba1\u7b97\u73af\u5883\u6765\u589e\u5f3a\u7075\u6d3b\u6027\u3001\u8d44\u6e90\u6548\u7387\u548c\u4e13\u7528\u786c\u4ef6\u8bbf\u95ee\uff0c\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u5438\u5f15\u529b\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u672c\u6587\u91c7\u7528\u7efc\u8ff0\u5206\u6790\u65b9\u6cd5\uff0c\u5168\u9762\u6982\u8ff0\u6df7\u5408\u4e91\u90e8\u7f72\u6a21\u578b\uff0c\u91cd\u70b9\u5173\u6ce8\u7f51\u683c\u548c\u4e91\u5e73\u53f0\uff08\u5305\u62ecOpenPBS\u3001SLURM\u3001OpenStack\u3001Kubernetes\uff09\u4ee5\u53ca\u5de5\u4f5c\u6d41\u7ba1\u7406\u5de5\u5177\uff08Nextflow\u3001Snakemake\u3001CWL\uff09\u3002\u63a2\u7d22\u8054\u90a6\u8ba1\u7b97\u3001\u591a\u4e91\u7f16\u6392\u548c\u8d1f\u8f7d\u8c03\u5ea6\u7b56\u7565\uff0c\u89e3\u51b3\u4e92\u64cd\u4f5c\u6027\u3001\u6570\u636e\u5b89\u5168\u3001\u53ef\u91cd\u590d\u6027\u548c\u7f51\u7edc\u6027\u80fd\u7b49\u5173\u952e\u6311\u6218\u3002\u57fa\u4e8eELIXIR\u8ba1\u7b97\u5e73\u53f0\u534f\u8c03\u7684\u751f\u547d\u79d1\u5b66\u9886\u57df\u5b9e\u65bd\u6848\u4f8b\u53ca\u5176\u5728\u66f4\u5e7f\u6cdbEOSC\u80cc\u666f\u4e0b\u7684\u96c6\u6210\u3002", "result": "\u901a\u8fc7\u5206\u6790\u73b0\u6709\u6df7\u5408\u4e91\u90e8\u7f72\u6a21\u578b\u548c\u6280\u672f\u5de5\u5177\uff0c\u8bc6\u522b\u4e86\u7814\u7a76\u8ba1\u7b97\u4e2d\u7684\u5173\u952e\u6311\u6218\u548c\u89e3\u51b3\u65b9\u6848\u3002\u57fa\u4e8eELIXIR\u8ba1\u7b97\u5e73\u53f0\u7684\u5b9e\u9645\u5b9e\u65bd\u7ecf\u9a8c\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u52a0\u901f\u6df7\u5408\u4e91\u5728\u7814\u7a76\u8ba1\u7b97\u4e2d\u91c7\u7528\u7684\u8def\u7ebf\u56fe\uff0c\u5f3a\u8c03\u6cbb\u7406\u6846\u67b6\u548c\u6280\u672f\u89e3\u51b3\u65b9\u6848\uff0c\u4ee5\u63a8\u52a8\u53ef\u6301\u7eed\u548c\u53ef\u6269\u5c55\u7684\u57fa\u7840\u8bbe\u65bd\u53d1\u5c55\u3002", "conclusion": "\u6df7\u5408\u4e91\u67b6\u6784\u4e3a\u7814\u7a76\u8ba1\u7b97\u63d0\u4f9b\u4e86\u7075\u6d3b\u3001\u9ad8\u6548\u548c\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002\u901a\u8fc7\u9002\u5f53\u7684\u6cbb\u7406\u6846\u67b6\u548c\u6280\u672f\u96c6\u6210\uff0c\u53ef\u4ee5\u514b\u670d\u4e92\u64cd\u4f5c\u6027\u3001\u6570\u636e\u5b89\u5168\u548c\u6027\u80fd\u7b49\u6311\u6218\u3002ELIXIR\u8ba1\u7b97\u5e73\u53f0\u5728\u751f\u547d\u79d1\u5b66\u9886\u57df\u7684\u6210\u529f\u5b9e\u65bd\u4e3a\u5176\u4ed6\u5b66\u79d1\u63d0\u4f9b\u4e86\u53ef\u501f\u9274\u7684\u6a21\u5f0f\uff0c\u52a0\u901f\u6df7\u5408\u4e91\u5728\u7814\u7a76\u8ba1\u7b97\u4e2d\u7684\u5e7f\u6cdb\u91c7\u7528\uff0c\u4fc3\u8fdb\u79d1\u5b66\u7814\u7a76\u7684\u521b\u65b0\u548c\u53d1\u5c55\u3002"}}
{"id": "2601.05108", "categories": ["cs.DB", "cs.LO"], "pdf": "https://arxiv.org/pdf/2601.05108", "abs": "https://arxiv.org/abs/2601.05108", "authors": ["Philipp Hanisch", "Markus Kr\u00f6tzsch"], "title": "Rule Rewriting Revisited: A Fresh Look at Static Filtering for Datalog and ASP", "comment": "Technical report of our ICDT'26 paper", "summary": "Static filtering is a data-independent optimisation method for Datalog, which generalises algebraic query rewriting techniques from relational databases. In spite of its early discovery by Kifer and Lozinskii in 1986, the method has been overlooked in recent research and system development, and special cases are being rediscovered independently. We therefore recall the original approach, using updated terminology and more general filter predicates that capture features of modern systems, and we show how to extend its applicability to answer set programming (ASP). The outcome is strictly more general but also more complex than the classical approach: double exponential in general and single exponential even for predicates of bounded arity. As a solution, we propose tractable approximations of the algorithm that can still yield much improved logic programs in typical cases, e.g., it can improve the performance of rule systems over real-world data in the order of magnitude.", "AI": {"tldr": "\u9759\u6001\u8fc7\u6ee4\u662fDatalog\u7684\u6570\u636e\u65e0\u5173\u4f18\u5316\u65b9\u6cd5\uff0c\u63a8\u5e7f\u4e86\u5173\u7cfb\u6570\u636e\u5e93\u7684\u4ee3\u6570\u67e5\u8be2\u91cd\u5199\u6280\u672f\u3002\u672c\u6587\u56de\u987e\u5e76\u66f4\u65b0\u4e86\u8be5\u65b9\u6cd5\uff0c\u6269\u5c55\u5230ASP\uff0c\u63d0\u51fa\u53ef\u5904\u7406\u7684\u8fd1\u4f3c\u7b97\u6cd5\u4ee5\u663e\u8457\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u5c3d\u7ba1Kifer\u548cLozinskii\u57281986\u5e74\u5c31\u63d0\u51fa\u4e86\u9759\u6001\u8fc7\u6ee4\u65b9\u6cd5\uff0c\u4f46\u8be5\u65b9\u6cd5\u5728\u8fd1\u671f\u7814\u7a76\u548c\u7cfb\u7edf\u5f00\u53d1\u4e2d\u88ab\u5ffd\u89c6\uff0c\u5176\u7279\u4f8b\u88ab\u72ec\u7acb\u91cd\u65b0\u53d1\u73b0\u3002\u56e0\u6b64\u9700\u8981\u56de\u987e\u539f\u59cb\u65b9\u6cd5\uff0c\u4f7f\u7528\u73b0\u4ee3\u672f\u8bed\u548c\u66f4\u901a\u7528\u7684\u8fc7\u6ee4\u5668\u8c13\u8bcd\uff0c\u5e76\u5c06\u5176\u6269\u5c55\u5230\u7b54\u6848\u96c6\u7f16\u7a0b\uff08ASP\uff09\u3002", "method": "\u4f7f\u7528\u66f4\u65b0\u672f\u8bed\u548c\u66f4\u901a\u7528\u7684\u8fc7\u6ee4\u5668\u8c13\u8bcd\u6765\u91cd\u65b0\u8868\u8ff0\u539f\u59cb\u9759\u6001\u8fc7\u6ee4\u65b9\u6cd5\uff0c\u5c06\u5176\u6269\u5c55\u5230ASP\u3002\u63d0\u51fa\u53ef\u5904\u7406\u7684\u8fd1\u4f3c\u7b97\u6cd5\uff0c\u5305\u62ec\u4e00\u822c\u60c5\u51b5\u4e0b\u7684\u53cc\u6307\u6570\u590d\u6742\u5ea6\u548c\u6709\u754c\u5143\u6570\u8c13\u8bcd\u7684\u5355\u6307\u6570\u590d\u6742\u5ea6\u8fd1\u4f3c\u3002", "result": "\u6269\u5c55\u540e\u7684\u65b9\u6cd5\u6bd4\u7ecf\u5178\u65b9\u6cd5\u66f4\u901a\u7528\u4f46\u4e5f\u66f4\u590d\u6742\u3002\u63d0\u51fa\u7684\u53ef\u5904\u7406\u8fd1\u4f3c\u7b97\u6cd5\u5728\u5178\u578b\u60c5\u51b5\u4e0b\u4ecd\u80fd\u663e\u8457\u6539\u8fdb\u903b\u8f91\u7a0b\u5e8f\uff0c\u4f8b\u5982\u5728\u771f\u5b9e\u4e16\u754c\u6570\u636e\u4e0a\u53ef\u5c06\u89c4\u5219\u7cfb\u7edf\u6027\u80fd\u63d0\u5347\u4e00\u4e2a\u6570\u91cf\u7ea7\u3002", "conclusion": "\u9759\u6001\u8fc7\u6ee4\u4f5c\u4e3aDatalog\u7684\u6570\u636e\u65e0\u5173\u4f18\u5316\u65b9\u6cd5\u503c\u5f97\u91cd\u65b0\u5173\u6ce8\uff0c\u901a\u8fc7\u73b0\u4ee3\u672f\u8bed\u66f4\u65b0\u548c\u6269\u5c55\u5230ASP\uff0c\u914d\u5408\u53ef\u5904\u7406\u8fd1\u4f3c\u7b97\u6cd5\uff0c\u80fd\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u663e\u8457\u63d0\u5347\u6027\u80fd\u3002"}}
{"id": "2601.04526", "categories": ["cs.SE", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.04526", "abs": "https://arxiv.org/abs/2601.04526", "authors": ["Zhao Tian"], "title": "Advancing Language Models for Code-related Tasks", "comment": "Accepted by ICSE 2026 (DS)", "summary": "Recent advances in language models (LMs) have driven significant progress in various software engineering tasks. However, existing LMs still struggle with complex programming scenarios due to limitations in data quality, model architecture, and reasoning capability. This research systematically addresses these challenges through three complementary directions: (1) improving code data quality with a code difference-guided adversarial augmentation technique (CODA) and a code denoising technique (CodeDenoise); (2) enhancing model architecture via syntax-guided code LMs (LEAM and LEAM++); and (3) advancing model reasoning with a prompting technique (muFiX) and an agent-based technique (Specine). These techniques aim to promote the practical adoption of LMs in software development and further advance intelligent software engineering.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7\u4e09\u4e2a\u4e92\u8865\u65b9\u5411\u7cfb\u7edf\u89e3\u51b3\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u7f16\u7a0b\u573a\u666f\u4e2d\u7684\u9650\u5236\uff1a\u6539\u8fdb\u4ee3\u7801\u6570\u636e\u8d28\u91cf\u3001\u589e\u5f3a\u6a21\u578b\u67b6\u6784\u3001\u63d0\u5347\u6a21\u578b\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u7f16\u7a0b\u573a\u666f\u4e2d\u4ecd\u5b58\u5728\u56f0\u96be\uff0c\u4e3b\u8981\u53d7\u9650\u4e8e\u6570\u636e\u8d28\u91cf\u3001\u6a21\u578b\u67b6\u6784\u548c\u63a8\u7406\u80fd\u529b\u3002\u9700\u8981\u7cfb\u7edf\u6027\u5730\u89e3\u51b3\u8fd9\u4e9b\u6311\u6218\uff0c\u4ee5\u4fc3\u8fdb\u8bed\u8a00\u6a21\u578b\u5728\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u7684\u5b9e\u9645\u5e94\u7528\u3002", "method": "\u91c7\u7528\u4e09\u4e2a\u4e92\u8865\u65b9\u5411\uff1a1) \u901a\u8fc7\u4ee3\u7801\u5dee\u5f02\u5f15\u5bfc\u7684\u5bf9\u6297\u589e\u5f3a\u6280\u672f(CODA)\u548c\u4ee3\u7801\u53bb\u566a\u6280\u672f(CodeDenoise)\u6539\u8fdb\u4ee3\u7801\u6570\u636e\u8d28\u91cf\uff1b2) \u901a\u8fc7\u8bed\u6cd5\u5f15\u5bfc\u7684\u4ee3\u7801\u8bed\u8a00\u6a21\u578b(LEAM\u548cLEAM++)\u589e\u5f3a\u6a21\u578b\u67b6\u6784\uff1b3) \u901a\u8fc7\u63d0\u793a\u6280\u672f(muFiX)\u548c\u57fa\u4e8e\u4ee3\u7406\u7684\u6280\u672f(Specine)\u63d0\u5347\u6a21\u578b\u63a8\u7406\u80fd\u529b\u3002", "result": "\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u7cfb\u5217\u521b\u65b0\u6280\u672f\uff0c\u5305\u62ec\u6570\u636e\u589e\u5f3a\u3001\u6a21\u578b\u67b6\u6784\u4f18\u5316\u548c\u63a8\u7406\u65b9\u6cd5\u6539\u8fdb\uff0c\u65e8\u5728\u63d0\u5347\u8bed\u8a00\u6a21\u578b\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\u3002", "conclusion": "\u8be5\u7814\u7a76\u901a\u8fc7\u7cfb\u7edf\u6027\u7684\u591a\u65b9\u5411\u65b9\u6cd5\uff0c\u6709\u671b\u4fc3\u8fdb\u8bed\u8a00\u6a21\u578b\u5728\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u7684\u5b9e\u9645\u5e94\u7528\uff0c\u5e76\u8fdb\u4e00\u6b65\u63a8\u52a8\u667a\u80fd\u8f6f\u4ef6\u5de5\u7a0b\u7684\u53d1\u5c55\u3002"}}
{"id": "2601.04523", "categories": ["cs.DC", "cs.PL"], "pdf": "https://arxiv.org/pdf/2601.04523", "abs": "https://arxiv.org/abs/2601.04523", "authors": ["Ajay Singh", "Nikos Metaxakis", "Panagiota Fatourou"], "title": "Sharded Elimination and Combining for Highly-Efficient Concurrent Stacks", "comment": "extended version of paper in PPoPP 2026", "summary": "We present a new blocking linearizable stack implementation which utilizes sharding and fetch&increment to achieve significantly better performance than all existing concurrent stacks. The proposed implementation is based on a novel elimination mechanism and a new combining approach that are efficiently blended to gain high performance. Our implementation results in enhanced parallelism and low contention when accessing the shared stack. Experiments show that the proposed stack implementation outperforms all existing concurrent stacks by up to 2X in most workloads. It is particularly efficient in systems supporting a large number of threads and in high contention scenarios.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u5206\u7247\u548cfetch&increment\u7684\u65b0\u578b\u963b\u585e\u7ebf\u6027\u5316\u6808\u5b9e\u73b0\uff0c\u6027\u80fd\u6bd4\u73b0\u6709\u5e76\u53d1\u6808\u63d0\u5347\u9ad8\u8fbe2\u500d", "motivation": "\u73b0\u6709\u5e76\u53d1\u6808\u5728\u9ad8\u5e76\u53d1\u573a\u666f\u4e0b\u6027\u80fd\u4e0d\u8db3\uff0c\u9700\u8981\u8bbe\u8ba1\u4e00\u79cd\u80fd\u591f\u51cf\u5c11\u4e89\u7528\u3001\u63d0\u9ad8\u5e76\u884c\u6027\u7684\u65b0\u5b9e\u73b0", "method": "\u7ed3\u5408\u5206\u7247\u6280\u672f\u3001fetch&increment\u64cd\u4f5c\u3001\u65b0\u9896\u7684\u6d88\u9664\u673a\u5236\u548c\u7ec4\u5408\u65b9\u6cd5\uff0c\u6709\u6548\u6df7\u5408\u8fd9\u4e9b\u6280\u672f\u4ee5\u5b9e\u73b0\u9ad8\u6027\u80fd", "result": "\u5728\u5927\u591a\u6570\u5de5\u4f5c\u8d1f\u8f7d\u4e0b\u6027\u80fd\u6bd4\u73b0\u6709\u5e76\u53d1\u6808\u63d0\u5347\u9ad8\u8fbe2\u500d\uff0c\u7279\u522b\u5728\u5927\u89c4\u6a21\u7ebf\u7a0b\u7cfb\u7edf\u548c\u9ad8\u4e89\u7528\u573a\u666f\u4e0b\u8868\u73b0\u4f18\u5f02", "conclusion": "\u63d0\u51fa\u7684\u6808\u5b9e\u73b0\u901a\u8fc7\u521b\u65b0\u7684\u6d88\u9664\u673a\u5236\u548c\u7ec4\u5408\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u5e76\u53d1\u6808\u7684\u6027\u80fd\u548c\u53ef\u6269\u5c55\u6027"}}
{"id": "2601.04540", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.04540", "abs": "https://arxiv.org/abs/2601.04540", "authors": ["Tanghaoran Zhang", "Xinjun Mao", "Shangwen Wang", "Yuxin Zhao", "Yao Lu", "Jin Zhang", "Zhang Zhang", "Kang Yang", "Yue Yu"], "title": "AdaptEval: A Benchmark for Evaluating Large Language Models on Code Snippet Adaptation", "comment": "13 pages, 7 figures, Accepted by ASE 2025", "summary": "Recent advancements in large language models (LLMs) have automated various software engineering tasks, with benchmarks emerging to evaluate their capabilities. However, for adaptation, a critical activity during code reuse, there is no benchmark to assess LLMs' performance, leaving their practical utility in this area unclear. To fill this gap, we propose AdaptEval, a benchmark designed to evaluate LLMs on code snippet adaptation. Unlike existing benchmarks, AdaptEval incorporates the following three distinctive features: First, Practical Context. Tasks in AdaptEval are derived from developers' practices, preserving rich contextual information from Stack Overflow and GitHub communities. Second, Multi-granularity Annotation. Each task is annotated with requirements at both task and adaptation levels, supporting the evaluation of LLMs across diverse adaptation scenarios. Third, Fine-grained Evaluation. AdaptEval includes a two-tier testing framework combining adaptation-level and function-level tests, which enables evaluating LLMs' performance across various individual adaptations. Based on AdaptEval, we conduct the first empirical study to evaluate six instruction-tuned LLMs and especially three reasoning LLMs on code snippet adaptation. Experimental results demonstrate that AdaptEval enables the assessment of LLMs' adaptation capabilities from various perspectives. It also provides critical insights into their current limitations, particularly their struggle to follow explicit instructions. We hope AdaptEval can facilitate further investigation and enhancement of LLMs' capabilities in code snippet adaptation, supporting their real-world applications.", "AI": {"tldr": "\u63d0\u51fa\u4e86AdaptEval\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u4e8e\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4ee3\u7801\u7247\u6bb5\u9002\u5e94\u4efb\u52a1\u4e0a\u7684\u80fd\u529b\uff0c\u586b\u8865\u4e86\u8be5\u9886\u57df\u8bc4\u4f30\u7a7a\u767d\u3002", "motivation": "\u867d\u7136\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4efb\u52a1\u4e2d\u5e94\u7528\u5e7f\u6cdb\uff0c\u4f46\u5728\u4ee3\u7801\u91cd\u7528\u4e2d\u7684\u5173\u952e\u6d3b\u52a8\u2014\u2014\u4ee3\u7801\u9002\u5e94\u65b9\u9762\uff0c\u7f3a\u4e4f\u4e13\u95e8\u7684\u8bc4\u4f30\u57fa\u51c6\uff0c\u5bfc\u81f4\u5176\u5b9e\u9645\u6548\u7528\u4e0d\u660e\u786e\u3002", "method": "AdaptEval\u57fa\u51c6\u5177\u6709\u4e09\u4e2a\u7279\u70b9\uff1a1) \u57fa\u4e8eStack Overflow\u548cGitHub\u5f00\u53d1\u8005\u5b9e\u8df5\u7684\u5b9e\u9645\u4e0a\u4e0b\u6587\uff1b2) \u4efb\u52a1\u7ea7\u548c\u9002\u5e94\u7ea7\u7684\u591a\u7c92\u5ea6\u6807\u6ce8\uff1b3) \u5305\u542b\u9002\u5e94\u7ea7\u548c\u51fd\u6570\u7ea7\u6d4b\u8bd5\u7684\u4e24\u5c42\u8bc4\u4f30\u6846\u67b6\u3002", "result": "\u8bc4\u4f30\u4e866\u4e2a\u6307\u4ee4\u8c03\u4f18LLM\u548c3\u4e2a\u63a8\u7406LLM\uff0c\u53d1\u73b0AdaptEval\u80fd\u4ece\u591a\u89d2\u5ea6\u8bc4\u4f30\u6a21\u578b\u9002\u5e94\u80fd\u529b\uff0c\u5e76\u63ed\u793a\u5176\u5f53\u524d\u5c40\u9650\u6027\uff0c\u7279\u522b\u662f\u96be\u4ee5\u9075\u5faa\u660e\u786e\u6307\u4ee4\u7684\u95ee\u9898\u3002", "conclusion": "AdaptEval\u586b\u8865\u4e86\u4ee3\u7801\u9002\u5e94\u8bc4\u4f30\u7684\u7a7a\u767d\uff0c\u4e3aLLM\u5728\u8be5\u9886\u57df\u7684\u80fd\u529b\u7814\u7a76\u548c\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u91cd\u8981\u652f\u6301\u3002"}}
{"id": "2601.04659", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2601.04659", "abs": "https://arxiv.org/abs/2601.04659", "authors": ["Gijun Park"], "title": "Quantifying Autoscaler Vulnerabilities: An Empirical Study of Resource Misallocation Induced by Cloud Infrastructure Faults", "comment": null, "summary": "Resource autoscaling mechanisms in cloud environments depend on accurate performance metrics to make optimal provisioning decisions. When infrastructure faults including hardware malfunctions, network disruptions, and software anomalies corrupt these metrics, autoscalers may systematically over- or under-provision resources, resulting in elevated operational expenses or degraded service reliability. This paper conducts controlled simulation experiments to measure how four prevalent fault categories affect both vertical and horizontal autoscaling behaviors across multiple instance configurations and service level objective (SLO) thresholds. Experimental findings demonstrate that storage-related faults generate the largest cost overhead, adding up to $258 monthly under horizontal scaling policies, whereas routing anomalies consistently bias autoscalers toward insufficient resource allocation. The sensitivity to fault-induced metric distortions differs markedly between scaling strategies: horizontal autoscaling exhibits greater susceptibility to transient anomalies, particularly near threshold boundaries. These empirically-grounded insights offer actionable recommendations for designing fault-tolerant autoscaling policies that distinguish genuine workload fluctuations from failure artifacts.", "AI": {"tldr": "\u7814\u7a76\u901a\u8fc7\u6a21\u62df\u5b9e\u9a8c\u5206\u6790\u56db\u79cd\u5e38\u89c1\u57fa\u7840\u8bbe\u65bd\u6545\u969c\u5bf9\u4e91\u8d44\u6e90\u81ea\u52a8\u6269\u7f29\u5bb9\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u5b58\u50a8\u6545\u969c\u5bfc\u81f4\u6700\u9ad8\u6210\u672c\u5f00\u9500\uff0c\u8def\u7531\u6545\u969c\u5bfc\u81f4\u8d44\u6e90\u5206\u914d\u4e0d\u8db3\uff0c\u6c34\u5e73\u6269\u7f29\u5bf9\u77ac\u65f6\u6545\u969c\u66f4\u654f\u611f\u3002", "motivation": "\u4e91\u73af\u5883\u4e2d\u8d44\u6e90\u81ea\u52a8\u6269\u7f29\u673a\u5236\u4f9d\u8d56\u51c6\u786e\u7684\u6027\u80fd\u6307\u6807\u505a\u51fa\u6700\u4f18\u8d44\u6e90\u914d\u7f6e\u51b3\u7b56\u3002\u5f53\u786c\u4ef6\u6545\u969c\u3001\u7f51\u7edc\u4e2d\u65ad\u3001\u8f6f\u4ef6\u5f02\u5e38\u7b49\u57fa\u7840\u8bbe\u65bd\u6545\u969c\u7834\u574f\u8fd9\u4e9b\u6307\u6807\u65f6\uff0c\u81ea\u52a8\u6269\u7f29\u5668\u53ef\u80fd\u7cfb\u7edf\u6027\u5730\u8fc7\u5ea6\u6216\u4e0d\u8db3\u914d\u7f6e\u8d44\u6e90\uff0c\u5bfc\u81f4\u8fd0\u8425\u6210\u672c\u589e\u52a0\u6216\u670d\u52a1\u53ef\u9760\u6027\u4e0b\u964d\u3002", "method": "\u901a\u8fc7\u53d7\u63a7\u6a21\u62df\u5b9e\u9a8c\uff0c\u6d4b\u91cf\u56db\u79cd\u5e38\u89c1\u6545\u969c\u7c7b\u522b\u5bf9\u5782\u76f4\u548c\u6c34\u5e73\u81ea\u52a8\u6269\u7f29\u884c\u4e3a\u7684\u5f71\u54cd\uff0c\u6db5\u76d6\u591a\u79cd\u5b9e\u4f8b\u914d\u7f6e\u548c\u670d\u52a1\u6c34\u5e73\u76ee\u6807(SLO)\u9608\u503c\u3002", "result": "\u5b58\u50a8\u76f8\u5173\u6545\u969c\u4ea7\u751f\u6700\u5927\u7684\u6210\u672c\u5f00\u9500\uff0c\u5728\u6c34\u5e73\u6269\u7f29\u7b56\u7565\u4e0b\u6bcf\u6708\u589e\u52a0\u9ad8\u8fbe258\u7f8e\u5143\uff1b\u8def\u7531\u5f02\u5e38\u6301\u7eed\u5bfc\u81f4\u81ea\u52a8\u6269\u7f29\u5668\u504f\u5411\u8d44\u6e90\u5206\u914d\u4e0d\u8db3\uff1b\u6c34\u5e73\u6269\u7f29\u5bf9\u6545\u969c\u5f15\u8d77\u7684\u6307\u6807\u5931\u771f\u66f4\u654f\u611f\uff0c\u7279\u522b\u662f\u5728\u9608\u503c\u8fb9\u754c\u9644\u8fd1\u3002", "conclusion": "\u57fa\u4e8e\u5b9e\u8bc1\u7684\u6d1e\u5bdf\u4e3a\u8bbe\u8ba1\u5bb9\u9519\u81ea\u52a8\u6269\u7f29\u7b56\u7565\u63d0\u4f9b\u4e86\u53ef\u64cd\u4f5c\u5efa\u8bae\uff0c\u5e2e\u52a9\u533a\u5206\u771f\u5b9e\u5de5\u4f5c\u8d1f\u8f7d\u6ce2\u52a8\u4e0e\u6545\u969c\u4f2a\u5f71\uff0c\u63d0\u9ad8\u4e91\u8d44\u6e90\u7ba1\u7406\u7684\u9c81\u68d2\u6027\u3002"}}
{"id": "2601.04556", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.04556", "abs": "https://arxiv.org/abs/2601.04556", "authors": ["Bo Yu", "Lei Zhao"], "title": "4D-ARE: Bridging the Attribution Gap in LLM Agent Requirements Engineering", "comment": "39 pages, 11 tables", "summary": "We deployed an LLM agent with ReAct reasoning and full data access. It executed flawlessly, yet when asked \"Why is completion rate 80%?\", it returned metrics instead of causal explanation. The agent knew how to reason but we had not specified what to reason about. This reflects a gap: runtime reasoning frameworks (ReAct, Chain-of-Thought) have transformed LLM agents, but design-time specification--determining what domain knowledge agents need--remains under-explored. We propose 4D-ARE (4-Dimensional Attribution-Driven Agent Requirements Engineering), a preliminary methodology for specifying attribution-driven agents. The core insight: decision-makers seek attribution, not answers. Attribution concerns organize into four dimensions (Results -> Process -> Support -> Long-term), motivated by Pearl's causal hierarchy. The framework operationalizes through five layers producing artifacts that compile directly to system prompts. We demonstrate the methodology through an industrial pilot deployment in financial services. 4D-ARE addresses what agents should reason about, complementing runtime frameworks that address how. We hypothesize systematic specification amplifies the power of these foundational advances. This paper presents a methodological proposal with preliminary industrial validation; rigorous empirical evaluation is planned for future work.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa4D-ARE\u65b9\u6cd5\uff0c\u7528\u4e8e\u5728AI\u4ee3\u7406\u8bbe\u8ba1\u9636\u6bb5\u7cfb\u7edf\u5316\u5730\u6307\u5b9a\u9700\u8981\u63a8\u7406\u7684\u5185\u5bb9\uff0c\u5f25\u8865\u73b0\u6709\u8fd0\u884c\u65f6\u63a8\u7406\u6846\u67b6\u7684\u4e0d\u8db3\u3002", "motivation": "\u73b0\u6709LLM\u4ee3\u7406\u8fd0\u884c\u65f6\u63a8\u7406\u6846\u67b6\uff08\u5982ReAct\u3001Chain-of-Thought\uff09\u5173\u6ce8\"\u5982\u4f55\u63a8\u7406\"\uff0c\u4f46\u7f3a\u4e4f\u5bf9\"\u63a8\u7406\u4ec0\u4e48\"\u7684\u8bbe\u8ba1\u65f6\u89c4\u8303\u3002\u4f5c\u8005\u53d1\u73b0\u5373\u4f7f\u4ee3\u7406\u80fd\u5b8c\u7f8e\u6267\u884c\u4efb\u52a1\uff0c\u5f53\u88ab\u95ee\u53ca\"\u4e3a\u4ec0\u4e48\u5b8c\u6210\u7387\u662f80%\"\u65f6\uff0c\u5b83\u53ea\u8fd4\u56de\u6307\u6807\u800c\u975e\u56e0\u679c\u89e3\u91ca\uff0c\u8fd9\u53cd\u6620\u4e86\u4ee3\u7406\u9700\u8981\u660e\u786e\u7684\u9886\u57df\u77e5\u8bc6\u89c4\u8303\u3002", "method": "\u63d0\u51fa4D-ARE\uff08\u56db\u7ef4\u5f52\u56e0\u9a71\u52a8\u4ee3\u7406\u9700\u6c42\u5de5\u7a0b\uff09\u65b9\u6cd5\uff0c\u6838\u5fc3\u6d1e\u5bdf\u662f\u51b3\u7b56\u8005\u9700\u8981\u5f52\u56e0\u800c\u975e\u7b80\u5355\u7b54\u6848\u3002\u5f52\u56e0\u95ee\u9898\u7ec4\u7ec7\u6210\u56db\u4e2a\u7ef4\u5ea6\uff08\u7ed3\u679c\u2192\u8fc7\u7a0b\u2192\u652f\u6301\u2192\u957f\u671f\uff09\uff0c\u57fa\u4e8ePearl\u56e0\u679c\u5c42\u6b21\u7406\u8bba\u3002\u6846\u67b6\u901a\u8fc7\u4e94\u5c42\u64cd\u4f5c\u5316\uff0c\u4ea7\u751f\u53ef\u76f4\u63a5\u7f16\u8bd1\u4e3a\u7cfb\u7edf\u63d0\u793a\u7684\u5de5\u4ef6\u3002", "result": "\u5728\u91d1\u878d\u670d\u52a1\u884c\u4e1a\u8fdb\u884c\u4e86\u8bd5\u70b9\u90e8\u7f72\uff0c\u5c55\u793a\u4e86\u8be5\u65b9\u6cd5\u7684\u53ef\u884c\u6027\u30024D-ARE\u89e3\u51b3\u4e86\u4ee3\u7406\u5e94\u8be5\u63a8\u7406\u4ec0\u4e48\u7684\u95ee\u9898\uff0c\u8865\u5145\u4e86\u73b0\u6709\u8fd0\u884c\u65f6\u6846\u67b6\u5bf9\u5982\u4f55\u63a8\u7406\u7684\u5173\u6ce8\u3002", "conclusion": "\u7cfb\u7edf\u5316\u7684\u89c4\u8303\u8bbe\u8ba1\u80fd\u653e\u5927\u57fa\u7840\u6280\u672f\u8fdb\u6b65\u7684\u529b\u91cf\u3002\u672c\u6587\u63d0\u51fa\u4e86\u65b9\u6cd5\u8bba\u5efa\u8bae\u548c\u521d\u6b65\u5de5\u4e1a\u9a8c\u8bc1\uff0c\u4e25\u683c\u7684\u5b9e\u8bc1\u8bc4\u4f30\u8ba1\u5212\u5728\u672a\u6765\u5de5\u4f5c\u4e2d\u8fdb\u884c\u3002"}}
{"id": "2601.04750", "categories": ["cs.DC", "cs.NI"], "pdf": "https://arxiv.org/pdf/2601.04750", "abs": "https://arxiv.org/abs/2601.04750", "authors": ["Krishna Chaitanya Sunkara"], "title": "Cognitive Infrastructure: A Unified DCIM Framework for AI Data Centers", "comment": "71 pages, 10 figures, 5 tables, 9 chapters including cases study. Published independently under Creative Commons BY 4.0. Includes comprehensive technical diagrams, quantitative models, JSON schema specifications, and production deployment validation.This is comprehensive manuscript synthesizing original research and systems engineering practices in AI Scale data center infrastructure management", "summary": "This work presents DCIM 3.0, a unified framework integrating semantic reasoning, predictive analytics, autonomous orchestration, and unified connectivity for next-generation AI data center management. The framework addresses critical challenges in infrastructure automation, sustainability, and digital-twin design through knowledge graph-based intelligence, thermal modeling, and the Unified Device Connectivity Protocol (UDCP).Keywords-Data Center Infrastructure Management, DCIM, AI Data Centers, Knowledge Graphs, Digital Twin, Thermal Management, Infrastructure Automation, Sustainability, GPU Computing, Data Center", "AI": {"tldr": "DCIM 3.0\u662f\u4e00\u4e2a\u7edf\u4e00\u6846\u67b6\uff0c\u96c6\u6210\u4e86\u8bed\u4e49\u63a8\u7406\u3001\u9884\u6d4b\u5206\u6790\u3001\u81ea\u4e3b\u7f16\u6392\u548c\u7edf\u4e00\u8fde\u63a5\uff0c\u7528\u4e8e\u4e0b\u4e00\u4ee3AI\u6570\u636e\u4e2d\u5fc3\u7ba1\u7406", "motivation": "\u89e3\u51b3\u57fa\u7840\u8bbe\u65bd\u81ea\u52a8\u5316\u3001\u53ef\u6301\u7eed\u6027\u548c\u6570\u5b57\u5b6a\u751f\u8bbe\u8ba1\u4e2d\u7684\u5173\u952e\u6311\u6218\uff0c\u7279\u522b\u662f\u5728AI\u6570\u636e\u4e2d\u5fc3\u73af\u5883\u4e2d", "method": "\u901a\u8fc7\u77e5\u8bc6\u56fe\u8c31\u667a\u80fd\u3001\u70ed\u5efa\u6a21\u548c\u7edf\u4e00\u8bbe\u5907\u8fde\u63a5\u534f\u8bae(UDCP)\u6784\u5efa\u7edf\u4e00\u7ba1\u7406\u6846\u67b6", "result": "\u63d0\u51fa\u4e86DCIM 3.0\u6846\u67b6\uff0c\u96c6\u6210\u4e86\u8bed\u4e49\u63a8\u7406\u3001\u9884\u6d4b\u5206\u6790\u3001\u81ea\u4e3b\u7f16\u6392\u548c\u7edf\u4e00\u8fde\u63a5\u529f\u80fd", "conclusion": "DCIM 3.0\u4e3a\u4e0b\u4e00\u4ee3AI\u6570\u636e\u4e2d\u5fc3\u7ba1\u7406\u63d0\u4f9b\u4e86\u5168\u9762\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u89e3\u51b3\u4e86\u57fa\u7840\u8bbe\u65bd\u81ea\u52a8\u5316\u3001\u53ef\u6301\u7eed\u6027\u548c\u6570\u5b57\u5b6a\u751f\u8bbe\u8ba1\u7684\u5173\u952e\u95ee\u9898"}}
{"id": "2601.04689", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.04689", "abs": "https://arxiv.org/abs/2601.04689", "authors": ["Charaka Geethal Kapugama"], "title": "Extending Delta Debugging Minimization for Spectrum-Based Fault Localization", "comment": "Accepted to 2026 IEEE 16th Annual Computing and Communication Workshop and Conference (CCWC)", "summary": "This paper introduces DDMIN-LOC, a technique that combines Delta Debugging Minimization (DDMIN) with Spectrum-Based Fault Localization (SBFL). It can be applied to programs taking string inputs, even when only a single failure-inducing input is available. DDMIN is an algorithm that systematically explores the minimal failure-inducing input that exposes a bug, given an initial failing input. However, it does not provide information about the faulty statements responsible for the failure. DDMIN-LOC addresses this limitation by collecting the passing and failing inputs generated during the DDMIN process and computing suspiciousness scores for program statements and predicates using SBFL algorithms. These scores are then combined to rank statements according to their likelihood of being faulty. DDMIN-LOC requires only one failing input of the buggy program, although it can be applied only to programs that take string inputs. DDMIN-LOC was evaluated on 136 programs selected from the QuixBugs and Codeflaws benchmarks using the SBFL algorithms Tarantula, Ochiai, GenProg, Jaccard and DStar. Experimental results show that DDMIN-LOC performs best with Jaccard: in most subjects, fewer than 20% executable lines need to be examined to locate the faulty statements. Moreover, in most subjects, faulty statements are ranked within the top 3 positions in all the generated test suites derived from different failing inputs.", "AI": {"tldr": "DDMIN-LOC\u7ed3\u5408Delta Debugging Minimization\uff08DDMIN\uff09\u548c\u57fa\u4e8e\u9891\u8c31\u7684\u6545\u969c\u5b9a\u4f4d\uff08SBFL\uff09\uff0c\u4ec5\u9700\u5355\u4e2a\u5931\u8d25\u8f93\u5165\u5373\u53ef\u5b9a\u4f4d\u5b57\u7b26\u4e32\u8f93\u5165\u7a0b\u5e8f\u4e2d\u7684\u6545\u969c\u8bed\u53e5\u3002", "motivation": "DDMIN\u7b97\u6cd5\u80fd\u627e\u51fa\u6700\u5c0f\u5931\u8d25\u8bf1\u5bfc\u8f93\u5165\uff0c\u4f46\u65e0\u6cd5\u5b9a\u4f4d\u5177\u4f53\u6545\u969c\u8bed\u53e5\u3002\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u5728\u4ec5\u6709\u5355\u4e2a\u5931\u8d25\u8f93\u5165\u7684\u60c5\u51b5\u4e0b\uff0c\u65e2\u80fd\u6700\u5c0f\u5316\u8f93\u5165\u53c8\u80fd\u5b9a\u4f4d\u6545\u969c\u3002", "method": "\u7ed3\u5408DDMIN\u548cSBFL\uff1a1\uff09\u4f7f\u7528DDMIN\u751f\u6210\u901a\u8fc7\u548c\u5931\u8d25\u6d4b\u8bd5\u7528\u4f8b\uff1b2\uff09\u6536\u96c6\u8fd9\u4e9b\u6d4b\u8bd5\u7528\u4f8b\u7684\u6267\u884c\u9891\u8c31\uff1b3\uff09\u5e94\u7528SBFL\u7b97\u6cd5\uff08Tarantula\u3001Ochiai\u7b49\uff09\u8ba1\u7b97\u8bed\u53e5\u53ef\u7591\u5ea6\u5206\u6570\uff1b4\uff09\u7ed3\u5408\u5206\u6570\u5bf9\u8bed\u53e5\u8fdb\u884c\u6392\u540d\u3002", "result": "\u5728QuixBugs\u548cCodeflaws\u57fa\u51c6\u7684136\u4e2a\u7a0b\u5e8f\u4e0a\u8bc4\u4f30\uff0c\u4f7f\u7528Jaccard\u7b97\u6cd5\u6548\u679c\u6700\u4f73\uff1a\u5927\u591a\u6570\u60c5\u51b5\u4e0b\u53ea\u9700\u68c0\u67e5\u4e0d\u523020%\u7684\u53ef\u6267\u884c\u884c\u5373\u53ef\u5b9a\u4f4d\u6545\u969c\uff0c\u4e14\u6545\u969c\u8bed\u53e5\u5728\u6392\u540d\u4e2d\u901a\u5e38\u4f4d\u4e8e\u524d3\u4f4d\u3002", "conclusion": "DDMIN-LOC\u6709\u6548\u89e3\u51b3\u4e86DDMIN\u65e0\u6cd5\u5b9a\u4f4d\u6545\u969c\u8bed\u53e5\u7684\u95ee\u9898\uff0c\u4ec5\u9700\u5355\u4e2a\u5931\u8d25\u8f93\u5165\u5373\u53ef\u5728\u5b57\u7b26\u4e32\u8f93\u5165\u7a0b\u5e8f\u4e2d\u5b9e\u73b0\u9ad8\u6548\u6545\u969c\u5b9a\u4f4d\uff0c\u4e3a\u8c03\u8bd5\u63d0\u4f9b\u4e86\u5b9e\u7528\u5de5\u5177\u3002"}}
{"id": "2601.04813", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2601.04813", "abs": "https://arxiv.org/abs/2601.04813", "authors": ["Homayoun Maleki", "Nekane Sainz", "Jon Legarda"], "title": "Proof of Commitment: A Human-Centric Resource for Permissionless Consensus", "comment": null, "summary": "Permissionless consensus protocols require a scarce resource to regulate leader election and provide Sybil resistance. Existing paradigms such as Proof of Work and Proof of Stake instantiate this scarcity through parallelizable resources like computation or capital. Once acquired, these resources can be subdivided across many identities at negligible marginal cost, making linear Sybil cost fundamentally unattainable.\n  We introduce Proof of Commitment (PoCmt), a consensus primitive grounded in a non-parallelizable resource: real-time human engagement. Validators maintain a commitment state capturing cumulative human effort, protocol participation, and online availability. Engagement is enforced through a Human Challenge Oracle that issues identity-bound, time-sensitive challenges, limiting the number of challenges solvable within each human window.\n  Under this model, sustaining multiple active identities requires proportional human-time effort. We establish a cost-theoretic separation showing that protocols based on parallelizable resources admit zero marginal Sybil cost, whereas PoCmt enforces a strictly linear cost profile. Using a weighted-backbone analysis, we show that PoCmt achieves safety, liveness, and commitment-proportional fairness under partial synchrony.\n  Simulations complement the analysis by isolating human-time capacity as the sole adversarial bottleneck and validating the predicted commitment drift and fairness properties. These results position PoCmt as a new point in the consensus design space, grounding permissionless security in sustained human effort rather than computation or capital.", "AI": {"tldr": "PoCmt\u662f\u4e00\u79cd\u57fa\u4e8e\u4eba\u7c7b\u5b9e\u65f6\u53c2\u4e0e\u7684\u975e\u5e76\u884c\u5316\u8d44\u6e90\u7684\u65b0\u578b\u5171\u8bc6\u534f\u8bae\uff0c\u901a\u8fc7\u4eba\u7c7b\u6311\u6218\u673a\u5236\u786e\u4fddSybil\u653b\u51fb\u6210\u672c\u7ebf\u6027\u589e\u957f\uff0c\u76f8\u6bd4\u4f20\u7edfPoW/PoS\u5177\u6709\u66f4\u597d\u7684\u6297Sybil\u653b\u51fb\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u5171\u8bc6\u534f\u8bae\uff08\u5982PoW\u548cPoS\uff09\u4f7f\u7528\u53ef\u5e76\u884c\u5316\u8d44\u6e90\uff08\u8ba1\u7b97\u6216\u8d44\u672c\uff09\uff0c\u8fd9\u4e9b\u8d44\u6e90\u4e00\u65e6\u83b7\u5f97\u5c31\u53ef\u4ee5\u4ee5\u8fd1\u4e4e\u96f6\u8fb9\u9645\u6210\u672c\u5206\u914d\u7ed9\u591a\u4e2a\u8eab\u4efd\uff0c\u65e0\u6cd5\u5b9e\u73b0\u771f\u6b63\u7684\u7ebf\u6027Sybil\u6210\u672c\u3002\u9700\u8981\u4e00\u79cd\u57fa\u4e8e\u975e\u5e76\u884c\u5316\u8d44\u6e90\u7684\u5171\u8bc6\u673a\u5236\u6765\u4ece\u6839\u672c\u4e0a\u89e3\u51b3Sybil\u653b\u51fb\u95ee\u9898\u3002", "method": "\u63d0\u51faProof of Commitment (PoCmt)\u534f\u8bae\uff0c\u57fa\u4e8e\u4eba\u7c7b\u5b9e\u65f6\u53c2\u4e0e\u8fd9\u4e00\u975e\u5e76\u884c\u5316\u8d44\u6e90\u3002\u901a\u8fc7\u4eba\u7c7b\u6311\u6218\u9884\u8a00\u673a\uff08Human Challenge Oracle\uff09\u53d1\u5e03\u8eab\u4efd\u7ed1\u5b9a\u3001\u65f6\u95f4\u654f\u611f\u7684\u6311\u6218\uff0c\u9650\u5236\u6bcf\u4e2a\u65f6\u95f4\u7a97\u53e3\u5185\u53ef\u89e3\u51b3\u7684\u6311\u6218\u6570\u91cf\u3002\u9a8c\u8bc1\u8005\u7ef4\u62a4\u627f\u8bfa\u72b6\u6001\uff0c\u8bb0\u5f55\u7d2f\u8ba1\u4eba\u7c7b\u52aa\u529b\u3001\u534f\u8bae\u53c2\u4e0e\u548c\u5728\u7ebf\u53ef\u7528\u6027\u3002", "result": "\u7406\u8bba\u5206\u6790\u8868\u660e\uff0c\u57fa\u4e8e\u53ef\u5e76\u884c\u5316\u8d44\u6e90\u7684\u534f\u8bae\u5141\u8bb8\u96f6\u8fb9\u9645Sybil\u6210\u672c\uff0c\u800cPoCmt\u5f3a\u5236\u6267\u884c\u4e25\u683c\u7ebf\u6027\u6210\u672c\u66f2\u7ebf\u3002\u901a\u8fc7\u52a0\u6743\u9aa8\u5e72\u5206\u6790\u8bc1\u660ePoCmt\u5728\u90e8\u5206\u540c\u6b65\u6761\u4ef6\u4e0b\u5b9e\u73b0\u5b89\u5168\u6027\u3001\u6d3b\u6027\u548c\u627f\u8bfa\u6bd4\u4f8b\u516c\u5e73\u6027\u3002\u6a21\u62df\u9a8c\u8bc1\u4e86\u4eba\u7c7b\u65f6\u95f4\u5bb9\u91cf\u4f5c\u4e3a\u552f\u4e00\u5bf9\u6297\u74f6\u9888\u7684\u6709\u6548\u6027\u3002", "conclusion": "PoCmt\u4e3a\u5171\u8bc6\u8bbe\u8ba1\u7a7a\u95f4\u63d0\u4f9b\u4e86\u4e00\u4e2a\u65b0\u65b9\u5411\uff0c\u5c06\u65e0\u8bb8\u53ef\u5b89\u5168\u6027\u5efa\u7acb\u5728\u6301\u7eed\u7684\u4eba\u7c7b\u52aa\u529b\u800c\u975e\u8ba1\u7b97\u6216\u8d44\u672c\u4e0a\uff0c\u4ece\u6839\u672c\u4e0a\u89e3\u51b3\u4e86Sybil\u653b\u51fb\u7684\u8fb9\u9645\u6210\u672c\u95ee\u9898\u3002"}}
{"id": "2601.04841", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.04841", "abs": "https://arxiv.org/abs/2601.04841", "authors": ["Jefferson Seide Moll\u00e9ri", "Sami Hyrynsalmi", "Antti Hakkala", "Kai K. Kimppa", "Jouni Smed"], "title": "A Longitudinal Analysis of Gamification in Untappd: Ethical Reflections on a Social Drinking Application", "comment": null, "summary": "This paper presents a longitudinal ethical analysis of Untappd, a social drinking application that gamifies beer consumption through badges, streaks, and social sharing. Building on an exploratory study conducted in 2020, we revisit the platform in 2025 to examine how its gamification features and ethical framings have evolved. Drawing on traditional ethical theory and practical frameworks for Software Engineering, we analyze five categories of badges and their implications for user autonomy and well-being. Our findings show that, despite small adjustments and superficial disclaimers, many of the original ethical issues remain. We argue for continuous ethical reflection built embedded into software lifecycles to prevent the normalization of risky behaviors through design.", "AI": {"tldr": "\u5bf9\u793e\u4ea4\u996e\u9152\u5e94\u7528Untappd\u7684\u7eb5\u5411\u4f26\u7406\u5206\u6790\uff0c\u53d1\u73b0\u5c3d\u7ba1\u5e73\u53f0\u6709\u6240\u8c03\u6574\uff0c\u4f46\u539f\u6709\u7684\u4f26\u7406\u95ee\u9898\u4f9d\u7136\u5b58\u5728\uff0c\u547c\u5401\u5c06\u4f26\u7406\u53cd\u601d\u5d4c\u5165\u8f6f\u4ef6\u751f\u547d\u5468\u671f", "motivation": "\u7814\u7a76Untappd\u8fd9\u7c7b\u901a\u8fc7\u5fbd\u7ae0\u3001\u8fde\u7eed\u8bb0\u5f55\u548c\u793e\u4ea4\u5206\u4eab\u6765\u6e38\u620f\u5316\u996e\u9152\u884c\u4e3a\u7684\u5e94\u7528\uff0c\u5206\u6790\u5176\u8bbe\u8ba1\u7279\u5f81\u5982\u4f55\u5f71\u54cd\u7528\u6237\u81ea\u4e3b\u6027\u548c\u798f\u7949\uff0c\u4ee5\u53ca\u5e73\u53f0\u4f26\u7406\u6846\u67b6\u7684\u6f14\u53d8", "method": "\u91c7\u7528\u7eb5\u5411\u7814\u7a76\u65b9\u6cd5\uff0c\u57fa\u4e8e2020\u5e74\u7684\u63a2\u7d22\u6027\u7814\u7a76\uff0c\u57282025\u5e74\u91cd\u65b0\u5ba1\u89c6\u5e73\u53f0\uff1b\u7ed3\u5408\u4f20\u7edf\u4f26\u7406\u7406\u8bba\u548c\u8f6f\u4ef6\u5de5\u7a0b\u5b9e\u8df5\u6846\u67b6\uff0c\u5206\u6790\u4e94\u7c7b\u5fbd\u7ae0\u53ca\u5176\u5bf9\u7528\u6237\u7684\u5f71\u54cd", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u5c3d\u7ba1\u5e73\u53f0\u8fdb\u884c\u4e86\u5c0f\u5e45\u8c03\u6574\u548c\u8868\u9762\u514d\u8d23\u58f0\u660e\uff0c\u4f46\u539f\u6709\u7684\u8bb8\u591a\u4f26\u7406\u95ee\u9898\u4ecd\u7136\u5b58\u5728\uff1b\u6e38\u620f\u5316\u8bbe\u8ba1\u53ef\u80fd\u4f7f\u5371\u9669\u884c\u4e3a\u6b63\u5e38\u5316", "conclusion": "\u9700\u8981\u5728\u8f6f\u4ef6\u751f\u547d\u5468\u671f\u4e2d\u5d4c\u5165\u6301\u7eed\u7684\u4f26\u7406\u53cd\u601d\uff0c\u4ee5\u9632\u6b62\u901a\u8fc7\u8bbe\u8ba1\u4f7f\u5371\u9669\u884c\u4e3a\u6b63\u5e38\u5316\uff1b\u8f6f\u4ef6\u5f00\u53d1\u8005\u5e94\u627f\u62c5\u66f4\u591a\u4f26\u7406\u8d23\u4efb"}}
{"id": "2601.04904", "categories": ["cs.DC", "cs.PF"], "pdf": "https://arxiv.org/pdf/2601.04904", "abs": "https://arxiv.org/abs/2601.04904", "authors": ["Vincent Maillou", "Matthias Bollhofer", "Olaf Schenk", "Alexandros Nikolaos Ziogas", "Mathieu Luisier"], "title": "Parallel Quadratic Selected Inversion in Quantum Transport Simulation", "comment": "12 pages, 9 figures", "summary": "Driven by Moore's Law, the dimensions of transistors have been pushed down to the nanometer scale. Advanced quantum transport (QT) solvers are required to accurately simulate such nano-devices. The non-equilibrium Green's function (NEGF) formalism lends itself optimally to these tasks, but it is computationally very intensive, involving the selected inversion (SI) of matrices and the selected solution of quadratic matrix (SQ) equations. Existing algorithms to tackle these numerical problems are ideally suited to GPU acceleration, e.g., the so-called recursive Green's function (RGF) technique, but they are typically sequential, require block-tridiagonal (BT) matrices as inputs, and their implementation has been so far restricted to shared memory parallelism, thus limiting the achievable device sizes. To address these shortcomings, we introduce distributed methods that build on RGF and enable parallel selected inversion and selected solution of the quadratic matrix equation. We further extend them to handle BT matrices with arrowhead, which allows for the investigation of multi-terminal transistor structures. We evaluate the performance of our approach on a real dataset from the QT simulation of a nano-ribbon transistor and compare it with the sparse direct package PARDISO. When scaling to 16 GPUs, our fused SI and SQ solver is 5.2x faster than the SI module of PARDISO applied to a device 16x shorter. These results highlight the potential of our method to accelerate NEGF-based nano-device simulations.", "AI": {"tldr": "\u63d0\u51fa\u5206\u5e03\u5f0f\u9012\u5f52\u683c\u6797\u51fd\u6570\u65b9\u6cd5\uff0c\u7528\u4e8e\u52a0\u901f\u7eb3\u7c73\u5668\u4ef6\u91cf\u5b50\u8f93\u8fd0\u6a21\u62df\u4e2d\u7684\u9009\u62e9\u9006\u77e9\u9635\u548c\u9009\u62e9\u4e8c\u6b21\u77e9\u9635\u65b9\u7a0b\u6c42\u89e3\uff0c\u652f\u6301\u591a\u7ec8\u7aef\u6676\u4f53\u7ba1\u7ed3\u6784\uff0c\u572816\u4e2aGPU\u4e0a\u6bd4PARDISO\u5feb5.2\u500d\u3002", "motivation": "\u968f\u7740\u6676\u4f53\u7ba1\u5c3a\u5bf8\u7f29\u5c0f\u5230\u7eb3\u7c73\u5c3a\u5ea6\uff0c\u9700\u8981\u7cbe\u786e\u7684\u91cf\u5b50\u8f93\u8fd0\u6a21\u62df\u3002\u975e\u5e73\u8861\u683c\u6797\u51fd\u6570(NEGF)\u65b9\u6cd5\u662f\u7406\u60f3\u9009\u62e9\uff0c\u4f46\u8ba1\u7b97\u91cf\u5927\uff0c\u6d89\u53ca\u9009\u62e9\u9006\u77e9\u9635\u548c\u9009\u62e9\u4e8c\u6b21\u77e9\u9635\u65b9\u7a0b\u6c42\u89e3\u3002\u73b0\u6709\u7b97\u6cd5\u5982\u9012\u5f52\u683c\u6797\u51fd\u6570(RGF)\u9002\u5408GPU\u52a0\u901f\uff0c\u4f46\u901a\u5e38\u662f\u987a\u5e8f\u6267\u884c\u3001\u9700\u8981\u5757\u4e09\u5bf9\u89d2\u77e9\u9635\u8f93\u5165\uff0c\u4e14\u4ec5\u9650\u4e8e\u5171\u4eab\u5185\u5b58\u5e76\u884c\uff0c\u9650\u5236\u4e86\u53ef\u6a21\u62df\u7684\u5668\u4ef6\u5c3a\u5bf8\u3002", "method": "\u63d0\u51fa\u5206\u5e03\u5f0f\u65b9\u6cd5\uff0c\u57fa\u4e8eRGF\u5b9e\u73b0\u5e76\u884c\u9009\u62e9\u9006\u77e9\u9635\u548c\u9009\u62e9\u4e8c\u6b21\u77e9\u9635\u65b9\u7a0b\u6c42\u89e3\u3002\u6269\u5c55\u65b9\u6cd5\u5904\u7406\u5e26\u7bad\u5934\u7ed3\u6784\u7684\u5757\u4e09\u5bf9\u89d2\u77e9\u9635\uff0c\u652f\u6301\u591a\u7ec8\u7aef\u6676\u4f53\u7ba1\u7ed3\u6784\u3002\u5728\u771f\u5b9e\u7eb3\u7c73\u5e26\u6676\u4f53\u7ba1\u91cf\u5b50\u8f93\u8fd0\u6a21\u62df\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\u6027\u80fd\u3002", "result": "\u572816\u4e2aGPU\u4e0a\uff0c\u878d\u5408\u7684\u9009\u62e9\u9006\u77e9\u9635\u548c\u9009\u62e9\u4e8c\u6b21\u77e9\u9635\u65b9\u7a0b\u6c42\u89e3\u5668\u6bd4PARDISO\u7684\u9009\u62e9\u9006\u77e9\u9635\u6a21\u5757\u5feb5.2\u500d\uff08\u5e94\u7528\u4e8e16\u500d\u77ed\u7684\u5668\u4ef6\uff09\u3002\u5c55\u793a\u4e86\u65b9\u6cd5\u5728\u52a0\u901fNEGF\u57fa\u7eb3\u7c73\u5668\u4ef6\u6a21\u62df\u65b9\u9762\u7684\u6f5c\u529b\u3002", "conclusion": "\u63d0\u51fa\u7684\u5206\u5e03\u5f0f\u65b9\u6cd5\u89e3\u51b3\u4e86\u73b0\u6709RGF\u6280\u672f\u7684\u5c40\u9650\u6027\uff0c\u652f\u6301\u5927\u89c4\u6a21\u5e76\u884c\u8ba1\u7b97\u548c\u591a\u7ec8\u7aef\u7ed3\u6784\uff0c\u663e\u8457\u52a0\u901f\u4e86\u7eb3\u7c73\u5668\u4ef6\u91cf\u5b50\u8f93\u8fd0\u6a21\u62df\uff0c\u4e3a\u66f4\u5927\u5c3a\u5bf8\u5668\u4ef6\u7684\u7cbe\u786e\u6a21\u62df\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\u3002"}}
{"id": "2601.04886", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.04886", "abs": "https://arxiv.org/abs/2601.04886", "authors": ["Jingzhi Gong", "Giovanni Pinna", "Yixin Bian", "Jie M. Zhang"], "title": "Analyzing Message-Code Inconsistency in AI Coding Agent-Authored Pull Requests", "comment": null, "summary": "Pull request (PR) descriptions generated by AI coding agents are the primary channel for communicating code changes to human reviewers. However, the alignment between these messages and the actual changes remains unexplored, raising concerns about the trustworthiness of AI agents. To fill this gap, we analyzed 23,247 agentic PRs across five agents using PR message-code inconsistency (PR-MCI). We contributed 974 manually annotated PRs, found 406 PRs (1.7%) exhibited high PR-MCI, and identified eight PR-MCI types, revealing that descriptions claiming unimplemented changes was the most common issue (45.4%). Statistical tests confirmed that high-MCI PRs had 51.7% lower acceptance rates (28.3% vs. 80.0%) and took 3.5x longer to merge (55.8 vs. 16.0 hours). Our findings suggest that unreliable PR descriptions undermine trust in AI agents, highlighting the need for PR-MCI verification mechanisms and improved PR generation to enable trustworthy human-AI collaboration.", "AI": {"tldr": "\u7814\u7a76\u5206\u6790\u4e86AI\u4ee3\u7801\u52a9\u624b\u751f\u6210\u7684PR\u63cf\u8ff0\u4e0e\u5b9e\u9645\u4ee3\u7801\u53d8\u66f4\u4e4b\u95f4\u7684\u4e0d\u4e00\u81f4\u6027\uff0c\u53d1\u73b01.7%\u7684PR\u5b58\u5728\u4e25\u91cd\u4e0d\u4e00\u81f4\u95ee\u9898\uff0c\u5bfc\u81f4\u63a5\u53d7\u7387\u964d\u4f4e51.7%\uff0c\u5408\u5e76\u65f6\u95f4\u5ef6\u957f3.5\u500d\u3002", "motivation": "AI\u7f16\u7801\u4ee3\u7406\u751f\u6210\u7684PR\u63cf\u8ff0\u662f\u5411\u4eba\u7c7b\u8bc4\u5ba1\u8005\u4f20\u8fbe\u4ee3\u7801\u53d8\u66f4\u7684\u4e3b\u8981\u6e20\u9053\uff0c\u4f46\u8fd9\u4e9b\u63cf\u8ff0\u4e0e\u5b9e\u9645\u53d8\u66f4\u4e4b\u95f4\u7684\u5bf9\u9f50\u7a0b\u5ea6\u5c1a\u672a\u88ab\u63a2\u7d22\uff0c\u5f15\u53d1\u4e86\u4eba\u4eec\u5bf9AI\u4ee3\u7406\u53ef\u4fe1\u5ea6\u7684\u62c5\u5fe7\u3002", "method": "\u4f7f\u7528PR\u6d88\u606f-\u4ee3\u7801\u4e0d\u4e00\u81f4\u6027\uff08PR-MCI\uff09\u65b9\u6cd5\u5206\u6790\u4e86\u4e94\u4e2aAI\u4ee3\u7406\u768423,247\u4e2aPR\uff0c\u8d21\u732e\u4e86974\u4e2a\u624b\u52a8\u6807\u6ce8\u7684PR\uff0c\u8bc6\u522b\u4e86\u516b\u79cdPR-MCI\u7c7b\u578b\u3002", "result": "\u53d1\u73b0406\u4e2aPR\uff081.7%\uff09\u8868\u73b0\u51fa\u9ad8PR-MCI\uff0c\u5176\u4e2d\u58f0\u79f0\u672a\u5b9e\u73b0\u53d8\u66f4\u7684\u63cf\u8ff0\u662f\u6700\u5e38\u89c1\u95ee\u9898\uff0845.4%\uff09\u3002\u9ad8MCI\u7684PR\u63a5\u53d7\u7387\u964d\u4f4e51.7%\uff0828.3% vs 80.0%\uff09\uff0c\u5408\u5e76\u65f6\u95f4\u5ef6\u957f3.5\u500d\uff0855.8 vs 16.0\u5c0f\u65f6\uff09\u3002", "conclusion": "\u4e0d\u53ef\u9760\u7684PR\u63cf\u8ff0\u4f1a\u524a\u5f31\u5bf9AI\u4ee3\u7406\u7684\u4fe1\u4efb\uff0c\u9700\u8981\u5efa\u7acbPR-MCI\u9a8c\u8bc1\u673a\u5236\u548c\u6539\u8fdbPR\u751f\u6210\u65b9\u6cd5\uff0c\u4ee5\u5b9e\u73b0\u53ef\u4fe1\u8d56\u7684\u4eba\u673a\u534f\u4f5c\u3002"}}
{"id": "2601.04930", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2601.04930", "abs": "https://arxiv.org/abs/2601.04930", "authors": ["Antonella Del Pozzo", "Achille Desreumaux", "Mathieu Gestin", "Alexandre Rapetti", "Sara Tucci-Piergiovanni"], "title": "Asynchronous Secure Federated Learning with Byzantine aggregators", "comment": null, "summary": "Privacy-preserving federated averaging is a central approach for protecting client privacy in federated learning. In this paper, we study this problem in an asynchronous communications setting with malicious aggregators. We propose a new solution to provide federated averaging in this model while protecting the client's data privacy through secure aggregation and differential privacy. Our solution maintains the same performance as the state of the art across all metrics. The main contributions of this paper are threefold. First, unlike existing single- or multi-server solutions, we consider malicious aggregation servers that may manipulate the model to leak clients' data or halt computation. To tolerate this threat, we replicate the aggregators, allowing a fraction of them to be corrupted. Second, we propose a new privacy preservation protocol for protocols in asynchronous communication models with Byzantine aggregators. In this protocol, clients mask their values and add Gaussian noise to their models. In contrast with previous works, we use the replicated servers to unmask the models, while ensuring the liveness of training even if aggregators misbehave. Third, the asynchronous communication model introduces new challenges not present in existing approaches. In such a setting, faster clients may contribute more frequently, potentially reducing their privacy and biasing the training. To address this, we introduce an inclusion mechanism that ensures uniform client participation and balanced privacy budgets. Interestingly, the solution presented in this paper does not rely on agreement between aggregators. Thus, we circumvent the known impossibility of consensus in asynchronous settings where processes might crash. Additionally, this feature increases availability, as a consensus-based algorithm only progresses in periods of low latency.", "AI": {"tldr": "\u63d0\u51fa\u5f02\u6b65\u901a\u4fe1\u73af\u5883\u4e0b\u9488\u5bf9\u6076\u610f\u805a\u5408\u5668\u7684\u8054\u90a6\u5e73\u5747\u9690\u79c1\u4fdd\u62a4\u65b9\u6848\uff0c\u7ed3\u5408\u5b89\u5168\u805a\u5408\u4e0e\u5dee\u5206\u9690\u79c1\uff0c\u901a\u8fc7\u590d\u5236\u805a\u5408\u5668\u5bb9\u5fcd\u62dc\u5360\u5ead\u6545\u969c\uff0c\u65e0\u9700\u5171\u8bc6\u534f\u8bae", "motivation": "\u73b0\u6709\u8054\u90a6\u5b66\u4e60\u9690\u79c1\u4fdd\u62a4\u65b9\u6848\u4e3b\u8981\u9488\u5bf9\u540c\u6b65\u901a\u4fe1\u548c\u8bda\u5b9e\u805a\u5408\u5668\uff0c\u7f3a\u4e4f\u5bf9\u5f02\u6b65\u901a\u4fe1\u73af\u5883\u4e0b\u6076\u610f\u805a\u5408\u5668\u7684\u6709\u6548\u9632\u62a4\uff0c\u4e14\u5f02\u6b65\u901a\u4fe1\u4f1a\u5e26\u6765\u5ba2\u6237\u7aef\u53c2\u4e0e\u4e0d\u5747\u548c\u9690\u79c1\u9884\u7b97\u5931\u8861\u95ee\u9898", "method": "1) \u590d\u5236\u805a\u5408\u5668\u5bb9\u5fcd\u62dc\u5360\u5ead\u6545\u969c\uff1b2) \u5ba2\u6237\u7aef\u4f7f\u7528\u63a9\u7801\u548c\u9ad8\u65af\u566a\u58f0\u4fdd\u62a4\u6a21\u578b\u66f4\u65b0\uff1b3) \u5f15\u5165\u5305\u542b\u673a\u5236\u786e\u4fdd\u5ba2\u6237\u7aef\u5747\u5300\u53c2\u4e0e\uff1b4) \u5229\u7528\u590d\u5236\u670d\u52a1\u5668\u89e3\u63a9\u7801\u6a21\u578b\uff0c\u65e0\u9700\u805a\u5408\u5668\u95f4\u5171\u8bc6", "result": "\u65b9\u6848\u5728\u6240\u6709\u6307\u6807\u4e0a\u8fbe\u5230\u4e0e\u73b0\u6709\u6700\u4f73\u65b9\u6848\u76f8\u540c\u7684\u6027\u80fd\uff0c\u80fd\u591f\u5bb9\u5fcd\u6076\u610f\u805a\u5408\u5668\u64cd\u7eb5\uff0c\u5728\u5f02\u6b65\u73af\u5883\u4e0b\u4fdd\u6301\u8bad\u7ec3\u6d3b\u6027\uff0c\u540c\u65f6\u786e\u4fdd\u5ba2\u6237\u7aef\u9690\u79c1\u4fdd\u62a4\u548c\u53c2\u4e0e\u5747\u8861", "conclusion": "\u8be5\u5de5\u4f5c\u9996\u6b21\u5728\u5f02\u6b65\u901a\u4fe1\u6a21\u578b\u4e0b\u89e3\u51b3\u4e86\u6076\u610f\u805a\u5408\u5668\u7684\u8054\u90a6\u5b66\u4e60\u9690\u79c1\u4fdd\u62a4\u95ee\u9898\uff0c\u901a\u8fc7\u521b\u65b0\u7684\u67b6\u6784\u8bbe\u8ba1\u7ed5\u8fc7\u4e86\u5f02\u6b65\u73af\u5883\u4e0b\u7684\u5171\u8bc6\u4e0d\u53ef\u80fd\u6027\uff0c\u63d0\u9ad8\u4e86\u7cfb\u7edf\u53ef\u7528\u6027"}}
{"id": "2601.04922", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.04922", "abs": "https://arxiv.org/abs/2601.04922", "authors": ["Th\u00e9o Boivin", "Joeffrey Legaux"], "title": "AVX / NEON Intrinsic Functions: When Should They Be Used?", "comment": null, "summary": "A cross-configuration benchmark is proposed to explore the capacities and limitations of AVX / NEON intrinsic functions in a generic context of development project, when a vectorisation strategy is required to optimise the code. The main aim is to guide developers to choose when using intrinsic functions, depending on the OS, architecture and/or available compiler. Intrinsic functions were observed highly efficient in conditional branching, with intrinsic version execution time reaching around 5% of plain code execution time. However, intrinsic functions were observed as unnecessary in many cases, as the compilers already well auto-vectorise the code.", "AI": {"tldr": "\u63d0\u51fa\u8de8\u914d\u7f6e\u57fa\u51c6\u6d4b\u8bd5\uff0c\u8bc4\u4f30AVX/NEON\u5185\u8054\u51fd\u6570\u5728\u901a\u7528\u5f00\u53d1\u9879\u76ee\u4e2d\u7684\u80fd\u529b\u4e0e\u9650\u5236\uff0c\u6307\u5bfc\u5f00\u53d1\u8005\u6839\u636eOS\u3001\u67b6\u6784\u548c\u7f16\u8bd1\u5668\u9009\u62e9\u662f\u5426\u4f7f\u7528\u5185\u8054\u51fd\u6570\u8fdb\u884c\u5411\u91cf\u5316\u4f18\u5316\u3002", "motivation": "\u5728\u9700\u8981\u5411\u91cf\u5316\u7b56\u7565\u4f18\u5316\u4ee3\u7801\u7684\u901a\u7528\u5f00\u53d1\u9879\u76ee\u4e2d\uff0c\u63a2\u7d22AVX/NEON\u5185\u8054\u51fd\u6570\u7684\u80fd\u529b\u4e0e\u9650\u5236\uff0c\u4e3a\u5f00\u53d1\u8005\u63d0\u4f9b\u4f55\u65f6\u4f7f\u7528\u5185\u8054\u51fd\u6570\u7684\u6307\u5bfc\uff0c\u5e2e\u52a9\u5176\u6839\u636e\u64cd\u4f5c\u7cfb\u7edf\u3001\u67b6\u6784\u548c\u53ef\u7528\u7f16\u8bd1\u5668\u505a\u51fa\u660e\u667a\u9009\u62e9\u3002", "method": "\u63d0\u51fa\u8de8\u914d\u7f6e\u57fa\u51c6\u6d4b\u8bd5\u65b9\u6cd5\uff0c\u5728\u4e0d\u540c\u64cd\u4f5c\u7cfb\u7edf\u3001\u67b6\u6784\u548c\u7f16\u8bd1\u5668\u73af\u5883\u4e0b\uff0c\u5bf9\u6bd4\u5206\u6790\u4f7f\u7528\u5185\u8054\u51fd\u6570\u4e0e\u666e\u901a\u4ee3\u7801\u7684\u6027\u80fd\u8868\u73b0\uff0c\u7279\u522b\u5173\u6ce8\u6761\u4ef6\u5206\u652f\u7b49\u5173\u952e\u573a\u666f\u3002", "result": "\u5185\u8054\u51fd\u6570\u5728\u6761\u4ef6\u5206\u652f\u5904\u7406\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u6267\u884c\u65f6\u95f4\u4ec5\u4e3a\u666e\u901a\u4ee3\u7801\u76845%\u5de6\u53f3\uff1b\u4f46\u5728\u8bb8\u591a\u60c5\u51b5\u4e0b\uff0c\u7f16\u8bd1\u5668\u5df2\u80fd\u5f88\u597d\u5730\u81ea\u52a8\u5411\u91cf\u5316\u4ee3\u7801\uff0c\u4f7f\u5f97\u5185\u8054\u51fd\u6570\u53d8\u5f97\u4e0d\u5fc5\u8981\u3002", "conclusion": "\u5185\u8054\u51fd\u6570\u5728\u7279\u5b9a\u573a\u666f\uff08\u5982\u6761\u4ef6\u5206\u652f\uff09\u4e2d\u975e\u5e38\u9ad8\u6548\uff0c\u4f46\u5f00\u53d1\u8005\u5e94\u8c28\u614e\u8bc4\u4f30\u4f7f\u7528\u573a\u666f\uff0c\u56e0\u4e3a\u73b0\u4ee3\u7f16\u8bd1\u5668\u5df2\u5177\u5907\u826f\u597d\u7684\u81ea\u52a8\u5411\u91cf\u5316\u80fd\u529b\uff0c\u76f2\u76ee\u4f7f\u7528\u5185\u8054\u51fd\u6570\u53ef\u80fd\u4e0d\u5fc5\u8981\u3002"}}
{"id": "2601.05109", "categories": ["cs.DC", "cs.MA"], "pdf": "https://arxiv.org/pdf/2601.05109", "abs": "https://arxiv.org/abs/2601.05109", "authors": ["Marco Laju", "Donghyun Son", "Saurabh Agarwal", "Nitin Kedia", "Myungjin Lee", "Jayanth Srinivasa", "Aditya Akella"], "title": "Nalar: An agent serving framework", "comment": null, "summary": "LLM-driven agentic applications increasingly automate complex, multi-step tasks, but serving them efficiently remains challenging due to heterogeneous components, dynamic and model-driven control flow, long-running state, and unpredictable latencies. Nalar is a ground-up agent-serving framework that cleanly separates workflow specification from execution while providing the runtime visibility and control needed for robust performance. Nalar preserves full Python expressiveness, using lightweight auto-generated stubs that turn agent and tool invocations into futures carrying dependency and context metadata. A managed state layer decouples logical state from physical placement, enabling safe reuse, migration, and consistent retry behavior. A two-level control architecture combines global policy computation with local event-driven enforcement to support adaptive routing, scheduling, and resource management across evolving workflows. Together, these mechanisms allow Nalar to deliver scalable, efficient, and policy-driven serving of heterogeneous agentic applications without burdening developers with orchestration logic. Across three agentic workloads, Nalar cuts tail latency by 34--74\\%, achieves up to $2.9\\times$ speedups, sustains 80 RPS where baselines fail, and scales to 130K futures with sub-500 ms control overhead.", "AI": {"tldr": "Nalar\u662f\u4e00\u4e2a\u4e13\u95e8\u4e3aLLM\u9a71\u52a8\u7684\u667a\u80fd\u4f53\u5e94\u7528\u8bbe\u8ba1\u7684\u670d\u52a1\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u79bb\u5de5\u4f5c\u6d41\u89c4\u8303\u4e0e\u6267\u884c\u3001\u63d0\u4f9b\u8fd0\u884c\u65f6\u53ef\u89c1\u6027\u548c\u63a7\u5236\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u7684\u667a\u80fd\u4f53\u5e94\u7528\u670d\u52a1\u3002", "motivation": "\u5f53\u524dLLM\u9a71\u52a8\u7684\u667a\u80fd\u4f53\u5e94\u7528\u9762\u4e34\u591a\u7ec4\u4ef6\u5f02\u6784\u6027\u3001\u52a8\u6001\u63a7\u5236\u6d41\u3001\u957f\u8fd0\u884c\u72b6\u6001\u548c\u4e0d\u53ef\u9884\u6d4b\u5ef6\u8fdf\u7b49\u6311\u6218\uff0c\u9700\u8981\u4e13\u95e8\u7684\u670d\u52a1\u6846\u67b6\u6765\u9ad8\u6548\u5904\u7406\u8fd9\u4e9b\u590d\u6742\u4efb\u52a1\u3002", "method": "1. \u4f7f\u7528\u8f7b\u91cf\u7ea7\u81ea\u52a8\u751f\u6210\u7684\u5b58\u6839\u5c06\u667a\u80fd\u4f53\u548c\u5de5\u5177\u8c03\u7528\u8f6c\u6362\u4e3a\u643a\u5e26\u4f9d\u8d56\u548c\u4e0a\u4e0b\u6587\u5143\u6570\u636e\u7684futures\uff1b2. \u7ba1\u7406\u72b6\u6001\u5c42\u89e3\u8026\u903b\u8f91\u72b6\u6001\u4e0e\u7269\u7406\u653e\u7f6e\uff1b3. \u4e24\u7ea7\u63a7\u5236\u67b6\u6784\u7ed3\u5408\u5168\u5c40\u7b56\u7565\u8ba1\u7b97\u4e0e\u672c\u5730\u4e8b\u4ef6\u9a71\u52a8\u6267\u884c\u3002", "result": "\u5728\u4e09\u4e2a\u667a\u80fd\u4f53\u5de5\u4f5c\u8d1f\u8f7d\u4e0a\uff0cNalar\u5c06\u5c3e\u90e8\u5ef6\u8fdf\u964d\u4f4e\u4e8634-74%\uff0c\u5b9e\u73b0\u4e86\u6700\u9ad82.9\u500d\u7684\u52a0\u901f\uff0c\u5728\u57fa\u7ebf\u5931\u8d25\u65f6\u4ecd\u80fd\u7ef4\u630180 RPS\uff0c\u5e76\u80fd\u6269\u5c55\u523013\u4e07\u4e2afutures\u4e14\u63a7\u5236\u5f00\u9500\u4f4e\u4e8e500\u6beb\u79d2\u3002", "conclusion": "Nalar\u901a\u8fc7\u5176\u521b\u65b0\u7684\u67b6\u6784\u8bbe\u8ba1\uff0c\u80fd\u591f\u5728\u4e0d\u589e\u52a0\u5f00\u53d1\u8005\u7f16\u6392\u903b\u8f91\u8d1f\u62c5\u7684\u60c5\u51b5\u4e0b\uff0c\u4e3a\u5f02\u6784\u667a\u80fd\u4f53\u5e94\u7528\u63d0\u4f9b\u53ef\u6269\u5c55\u3001\u9ad8\u6548\u4e14\u7b56\u7565\u9a71\u52a8\u7684\u670d\u52a1\u3002"}}
