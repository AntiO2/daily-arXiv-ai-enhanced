{"id": "2511.16947", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2511.16947", "abs": "https://arxiv.org/abs/2511.16947", "authors": ["Chenqi Zhao", "Wenfei Wu", "Linhai Song", "Yuchen Xu"], "title": "MicroMoE: Fine-Grained Load Balancing for Mixture-of-Experts with Token Scheduling", "comment": "19 pages", "summary": "Mixture-of-Experts (MoE) has emerged as a promising approach to scale up deep learning models due to its significant reduction in computational resources. However, the dynamic nature of MoE leads to load imbalance among experts, severely impacting training efficiency. While previous research has attempted to address the load balancing challenge, existing solutions either compromise model accuracy or introduce additional system overhead. As a result, they fail to achieve fine-grained load balancing, which is crucial to optimizing training efficiency.\n  We propose MicroEP, a novel parallelization strategy to achieve fine-grained load balancing in MoE systems. MicroEP is capable of achieving optimal load balancing in every micro-batch through efficient token scheduling across GPUs. Furthermore, we propose MicroMoE, an efficient distributed MoE training system with MicroEP's load balancing capabilities. Our experimental results demonstrate that MicroMoE improves the end-to-end training throughput by up to 47.6% compared with the state-of-the-art system, and almost consistently achieves optimal load balance among GPUs.", "AI": {"tldr": "MicroEP\u662f\u4e00\u79cd\u65b0\u9896\u7684\u5e76\u884c\u5316\u7b56\u7565\uff0c\u901a\u8fc7\u8de8GPU\u7684\u9ad8\u6548token\u8c03\u5ea6\u5b9e\u73b0MoE\u7cfb\u7edf\u4e2d\u7ec6\u7c92\u5ea6\u7684\u8d1f\u8f7d\u5747\u8861\u3002MicroMoE\u7cfb\u7edf\u57fa\u4e8e\u6b64\u7b56\u7565\uff0c\u76f8\u6bd4\u6700\u5148\u8fdb\u7cfb\u7edf\u53ef\u5c06\u7aef\u5230\u7aef\u8bad\u7ec3\u541e\u5410\u91cf\u63d0\u5347\u9ad8\u8fbe47.6%\u3002", "motivation": "MoE\u65b9\u6cd5\u5728\u6269\u5c55\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u65b9\u9762\u5f88\u6709\u524d\u666f\uff0c\u4f46\u5176\u52a8\u6001\u7279\u6027\u5bfc\u81f4\u4e13\u5bb6\u95f4\u8d1f\u8f7d\u4e0d\u5747\u8861\uff0c\u4e25\u91cd\u5f71\u54cd\u8bad\u7ec3\u6548\u7387\u3002\u73b0\u6709\u89e3\u51b3\u65b9\u6848\u8981\u4e48\u727a\u7272\u6a21\u578b\u7cbe\u5ea6\uff0c\u8981\u4e48\u5f15\u5165\u989d\u5916\u7cfb\u7edf\u5f00\u9500\uff0c\u65e0\u6cd5\u5b9e\u73b0\u7ec6\u7c92\u5ea6\u8d1f\u8f7d\u5747\u8861\u3002", "method": "\u63d0\u51faMicroEP\u5e76\u884c\u5316\u7b56\u7565\uff0c\u901a\u8fc7\u8de8GPU\u7684\u9ad8\u6548token\u8c03\u5ea6\u5728\u6bcf\u4e2a\u5fae\u6279\u6b21\u4e2d\u5b9e\u73b0\u6700\u4f18\u8d1f\u8f7d\u5747\u8861\u3002\u57fa\u4e8e\u6b64\u6784\u5efa\u4e86MicroMoE\u5206\u5e03\u5f0fMoE\u8bad\u7ec3\u7cfb\u7edf\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cMicroMoE\u76f8\u6bd4\u6700\u5148\u8fdb\u7cfb\u7edf\u53ef\u5c06\u7aef\u5230\u7aef\u8bad\u7ec3\u541e\u5410\u91cf\u63d0\u5347\u9ad8\u8fbe47.6%\uff0c\u5e76\u4e14\u51e0\u4e4e\u59cb\u7ec8\u5728GPU\u95f4\u5b9e\u73b0\u6700\u4f18\u8d1f\u8f7d\u5747\u8861\u3002", "conclusion": "MicroEP\u7b56\u7565\u548cMicroMoE\u7cfb\u7edf\u6709\u6548\u89e3\u51b3\u4e86MoE\u8bad\u7ec3\u4e2d\u7684\u8d1f\u8f7d\u4e0d\u5747\u8861\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8bad\u7ec3\u6548\u7387\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u6a21\u578b\u7cbe\u5ea6\u3002"}}
{"id": "2511.17119", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2511.17119", "abs": "https://arxiv.org/abs/2511.17119", "authors": ["Gabriel Job Antunes Grabher", "Fumio Machida", "Thomas Ropars"], "title": "Modeling Anomaly Detection in Cloud Services: Analysis of the Properties that Impact Latency and Resource Consumption", "comment": null, "summary": "Detecting and resolving performance anomalies in Cloud services is crucial for maintaining desired performance objectives. Scaling actions triggered by an anomaly detector help achieve target latency at the cost of extra resource consumption. However, performance anomaly detectors make mistakes. This paper studies which characteristics of performance anomaly detection are important to optimize the trade-off between performance and cost. Using Stochastic Reward Nets, we model a Cloud service monitored by a performance anomaly detector. Using our model, we study the impact of detector characteristics, namely precision, recall and inspection frequency, on the average latency and resource consumption of the monitored service. Our results show that achieving a high precision and a high recall is not always necessary. If detection can be run frequently, a high precision is enough to obtain a good performance-to-cost trade-off, but if the detector is run infrequently, recall becomes the most important.", "AI": {"tldr": "\u7814\u7a76\u6027\u80fd\u5f02\u5e38\u68c0\u6d4b\u5668\u7684\u7279\u6027\u5982\u4f55\u4f18\u5316\u4e91\u670d\u52a1\u4e2d\u6027\u80fd\u4e0e\u6210\u672c\u7684\u6743\u8861\uff0c\u53d1\u73b0\u9ad8\u7cbe\u5ea6\u548c\u9ad8\u53ec\u56de\u7387\u5e76\u975e\u603b\u662f\u5fc5\u8981\uff0c\u68c0\u6d4b\u9891\u7387\u4f1a\u5f71\u54cd\u54ea\u4e2a\u7279\u6027\u66f4\u91cd\u8981\u3002", "motivation": "\u4e91\u670d\u52a1\u4e2d\u6027\u80fd\u5f02\u5e38\u68c0\u6d4b\u5bf9\u4e8e\u7ef4\u6301\u6027\u80fd\u76ee\u6807\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u68c0\u6d4b\u5668\u4f1a\u72af\u9519\uff0c\u9700\u8981\u7814\u7a76\u54ea\u4e9b\u68c0\u6d4b\u7279\u6027\u5bf9\u4f18\u5316\u6027\u80fd\u4e0e\u6210\u672c\u6743\u8861\u6700\u91cd\u8981\u3002", "method": "\u4f7f\u7528\u968f\u673a\u5956\u52b1\u7f51\u7edc\u5efa\u6a21\u7531\u6027\u80fd\u5f02\u5e38\u68c0\u6d4b\u5668\u76d1\u63a7\u7684\u4e91\u670d\u52a1\uff0c\u5206\u6790\u68c0\u6d4b\u5668\u7cbe\u5ea6\u3001\u53ec\u56de\u7387\u548c\u68c0\u67e5\u9891\u7387\u5bf9\u5e73\u5747\u5ef6\u8fdf\u548c\u8d44\u6e90\u6d88\u8017\u7684\u5f71\u54cd\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff1a\u5982\u679c\u68c0\u6d4b\u9891\u7e41\u8fd0\u884c\uff0c\u9ad8\u7cbe\u5ea6\u8db3\u4ee5\u83b7\u5f97\u826f\u597d\u7684\u6027\u80fd-\u6210\u672c\u6743\u8861\uff1b\u5982\u679c\u68c0\u6d4b\u8fd0\u884c\u4e0d\u9891\u7e41\uff0c\u53ec\u56de\u7387\u53d8\u5f97\u6700\u91cd\u8981\u3002\u9ad8\u7cbe\u5ea6\u548c\u9ad8\u53ec\u56de\u7387\u5e76\u975e\u603b\u662f\u5fc5\u8981\u3002", "conclusion": "\u6027\u80fd\u5f02\u5e38\u68c0\u6d4b\u5668\u7684\u4f18\u5316\u7b56\u7565\u5e94\u6839\u636e\u68c0\u6d4b\u9891\u7387\u8c03\u6574\uff1a\u9ad8\u9891\u68c0\u6d4b\u65f6\u4fa7\u91cd\u7cbe\u5ea6\uff0c\u4f4e\u9891\u68c0\u6d4b\u65f6\u4fa7\u91cd\u53ec\u56de\u7387\uff0c\u4ee5\u5b9e\u73b0\u6700\u4f73\u6027\u80fd-\u6210\u672c\u6743\u8861\u3002"}}
{"id": "2511.16700", "categories": ["cs.DB", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.16700", "abs": "https://arxiv.org/abs/2511.16700", "authors": ["Sedat Bin Vedat", "Enes Kutay Yarkan", "Meftun Akarsu", "Recep Kaan Karaman", "Arda Sar", "\u00c7a\u011fr\u0131 \u00c7elikbilek", "Sava\u015f Sayg\u0131l\u0131"], "title": "RAG-Driven Data Quality Governance for Enterprise ERP Systems", "comment": null, "summary": "Enterprise ERP systems managing hundreds of thousands of employee records face critical data quality challenges when human resources departments perform decentralized manual entry across multiple languages. We present an end-to-end pipeline combining automated data cleaning with LLM-driven SQL query generation, deployed on a production system managing 240,000 employee records over six months.\n  The system operates in two integrated stages: a multi-stage cleaning pipeline that performs translation normalization, spelling correction, and entity deduplication during periodic synchronization from Microsoft SQL Server to PostgreSQL; and a retrieval-augmented generation framework powered by GPT-4o that translates natural-language questions in Turkish, Russian, and English into validated SQL queries. The query engine employs LangChain orchestration, FAISS vector similarity search, and few-shot learning with 500+ validated examples.\n  Our evaluation demonstrates 92.5% query validity, 95.1% schema compliance, and 90.7\\% semantic accuracy on 2,847 production queries. The system reduces query turnaround time from 2.3 days to under 5 seconds while maintaining 99.2% uptime, with GPT-4o achieving 46% lower latency and 68% cost reduction versus GPT-3.5. This modular architecture provides a reproducible framework for AI-native enterprise data governance, demonstrating real-world viability at enterprise scale with 4.3/5.0 user satisfaction.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u7aef\u5230\u7aef\u7684\u4f01\u4e1aERP\u6570\u636e\u8d28\u91cf\u89e3\u51b3\u65b9\u6848\uff0c\u7ed3\u5408\u81ea\u52a8\u5316\u6570\u636e\u6e05\u7406\u548cLLM\u9a71\u52a8\u7684SQL\u67e5\u8be2\u751f\u6210\uff0c\u5728\u7ba1\u740624\u4e07\u5458\u5de5\u8bb0\u5f55\u7684\u751f\u4ea7\u7cfb\u7edf\u4e2d\u90e8\u7f726\u4e2a\u6708\uff0c\u663e\u8457\u63d0\u5347\u67e5\u8be2\u6548\u7387\u548c\u51c6\u786e\u6027\u3002", "motivation": "\u4f01\u4e1aERP\u7cfb\u7edf\u9762\u4e34\u591a\u8bed\u8a00\u73af\u5883\u4e0b\u4eba\u529b\u8d44\u6e90\u90e8\u95e8\u5206\u6563\u624b\u52a8\u5f55\u5165\u5bfc\u81f4\u7684\u6570\u636e\u8d28\u91cf\u95ee\u9898\uff0c\u9700\u8981\u89e3\u51b3\u6570\u636e\u6e05\u7406\u548c\u81ea\u7136\u8bed\u8a00\u67e5\u8be2\u7684\u6311\u6218\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u96c6\u6210\u65b9\u6cd5\uff1a\u591a\u9636\u6bb5\u6e05\u7406\u7ba1\u9053\uff08\u7ffb\u8bd1\u6807\u51c6\u5316\u3001\u62fc\u5199\u7ea0\u6b63\u3001\u5b9e\u4f53\u53bb\u91cd\uff09\u548c\u57fa\u4e8eGPT-4o\u7684\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u6846\u67b6\uff0c\u652f\u6301\u571f\u8033\u5176\u8bed\u3001\u4fc4\u8bed\u548c\u82f1\u8bed\u7684\u81ea\u7136\u8bed\u8a00\u8f6cSQL\u67e5\u8be2\u3002", "result": "\u57282847\u4e2a\u751f\u4ea7\u67e5\u8be2\u4e2d\u8fbe\u523092.5%\u67e5\u8be2\u6709\u6548\u6027\u300195.1%\u6a21\u5f0f\u5408\u89c4\u6027\u548c90.7%\u8bed\u4e49\u51c6\u786e\u6027\uff0c\u67e5\u8be2\u5468\u8f6c\u65f6\u95f4\u4ece2.3\u5929\u7f29\u77ed\u81f35\u79d2\u5185\uff0cGPT-4o\u76f8\u6bd4GPT-3.5\u5ef6\u8fdf\u964d\u4f4e46%\u3001\u6210\u672c\u51cf\u5c1168%\u3002", "conclusion": "\u8be5\u6a21\u5757\u5316\u67b6\u6784\u4e3a\u4f01\u4e1aAI\u539f\u751f\u6570\u636e\u6cbb\u7406\u63d0\u4f9b\u4e86\u53ef\u590d\u73b0\u6846\u67b6\uff0c\u5728\u4f01\u4e1a\u89c4\u6a21\u4e0b\u5c55\u73b0\u5b9e\u9645\u53ef\u884c\u6027\uff0c\u7528\u6237\u6ee1\u610f\u5ea6\u8fbe4.3/5.0\u3002"}}
{"id": "2511.16707", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.16707", "abs": "https://arxiv.org/abs/2511.16707", "authors": ["Yuki Kataoka", "Ryuhei So", "Masahiro Banno", "Yasushi Tsujimoto", "Tomohiro Takayama", "Yosuke Yamagishi", "Takahiro Tsuge", "Norio Yamamoto", "Chiaki Suda", "Toshi A. Furukawa"], "title": "Large language models for automated PRISMA 2020 adherence checking", "comment": null, "summary": "Evaluating adherence to PRISMA 2020 guideline remains a burden in the peer review process. To address the lack of shareable benchmarks, we constructed a copyright-aware benchmark of 108 Creative Commons-licensed systematic reviews and evaluated ten large language models (LLMs) across five input formats. In a development cohort, supplying structured PRISMA 2020 checklists (Markdown, JSON, XML, or plain text) yielded 78.7-79.7% accuracy versus 45.21% for manuscript-only input (p less than 0.0001), with no differences between structured formats (p>0.9). Across models, accuracy ranged from 70.6-82.8% with distinct sensitivity-specificity trade-offs, replicated in an independent validation cohort. We then selected Qwen3-Max (a high-sensitivity open-weight model) and extended evaluation to the full dataset (n=120), achieving 95.1% sensitivity and 49.3% specificity. Structured checklist provision substantially improves LLM-based PRISMA assessment, though human expert verification remains essential before editorial decisions.", "AI": {"tldr": "\u6784\u5efa\u4e86\u4e00\u4e2a\u5305\u542b108\u7bc7CC\u8bb8\u53ef\u7cfb\u7edf\u8bc4\u4ef7\u7684\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u8bc4\u4f30\u4e8610\u4e2aLLM\u57285\u79cd\u8f93\u5165\u683c\u5f0f\u4e0b\u5bf9PRISMA 2020\u6307\u5357\u7684\u4f9d\u4ece\u6027\u8bc4\u4f30\u80fd\u529b\u3002\u63d0\u4f9b\u7ed3\u6784\u5316\u68c0\u67e5\u8868\u663e\u8457\u63d0\u9ad8\u4e86\u51c6\u786e\u6027\uff0c\u6700\u4f73\u6a21\u578bQwen3-Max\u5728\u5b8c\u6574\u6570\u636e\u96c6\u4e0a\u8fbe\u523095.1%\u7684\u654f\u611f\u6027\u548c49.3%\u7684\u7279\u5f02\u6027\u3002", "motivation": "\u89e3\u51b3\u540c\u884c\u8bc4\u5ba1\u8fc7\u7a0b\u4e2dPRISMA 2020\u6307\u5357\u4f9d\u4ece\u6027\u8bc4\u4f30\u7f3a\u4e4f\u53ef\u5171\u4eab\u57fa\u51c6\u7684\u95ee\u9898\uff0c\u4e3a\u81ea\u52a8\u5316\u8bc4\u4f30\u63d0\u4f9b\u53ef\u9760\u5de5\u5177\u3002", "method": "\u6784\u5efa\u7248\u6743\u611f\u77e5\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u8bc4\u4f3010\u4e2aLLM\u57285\u79cd\u8f93\u5165\u683c\u5f0f\u4e0b\u7684\u8868\u73b0\uff0c\u5305\u62ec\u5f00\u53d1\u961f\u5217\u548c\u72ec\u7acb\u9a8c\u8bc1\u961f\u5217\u7684\u5bf9\u6bd4\u5206\u6790\u3002", "result": "\u7ed3\u6784\u5316\u68c0\u67e5\u8868\u8f93\u5165\uff08Markdown\u3001JSON\u3001XML\u3001\u7eaf\u6587\u672c\uff09\u51c6\u786e\u7387\u8fbe78.7-79.7%\uff0c\u663e\u8457\u9ad8\u4e8e\u4ec5\u4f7f\u7528\u624b\u7a3f\u768445.21%\u3002\u4e0d\u540c\u6a21\u578b\u51c6\u786e\u7387\u572870.6-82.8%\u4e4b\u95f4\uff0cQwen3-Max\u5728\u5b8c\u6574\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u6700\u4f73\u3002", "conclusion": "\u63d0\u4f9b\u7ed3\u6784\u5316\u68c0\u67e5\u8868\u53ef\u663e\u8457\u6539\u5584\u57fa\u4e8eLLM\u7684PRISMA\u8bc4\u4f30\uff0c\u4f46\u5728\u7f16\u8f91\u51b3\u7b56\u524d\u4ecd\u9700\u4eba\u7c7b\u4e13\u5bb6\u9a8c\u8bc1\u3002"}}
{"id": "2511.16935", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2511.16935", "abs": "https://arxiv.org/abs/2511.16935", "authors": ["Sierra A. T. Moxon", "Harold Solbrig", "Nomi L. Harris", "Patrick Kalita", "Mark A. Miller", "Sujay Patil", "Kevin Schaper", "Chris Bizon", "J. Harry Caufield", "Silvano Cirujano Cuesta", "Corey Cox", "Frank Dekervel", "Damion M. Dooley", "William D. Duncan", "Tim Fliss", "Sarah Gehrke", "Adam S. L. Graefe", "Harshad Hegde", "AJ Ireland", "Julius O. B. Jacobsen", "Madan Krishnamurthy", "Carlo Kroll", "David Linke", "Ryan Ly", "Nicolas Matentzoglu", "James A. Overton", "Jonny L. Saunders", "Deepak R. Unni", "Gaurav Vaidya", "Wouter-Michiel A. M. Vierdag", "LinkML Community Contributors", "Oliver Ruebel", "Christopher G. Chute", "Matthew H. Brush", "Melissa A. Haendel", "Christopher J. Mungall"], "title": "LinkML: An Open Data Modeling Framework", "comment": null, "summary": "Scientific research relies on well-structured, standardized data; however, much of it is stored in formats such as free-text lab notebooks, non-standardized spreadsheets, or data repositories. This lack of structure challenges interoperability, making data integration, validation, and reuse difficult. LinkML (Linked Data Modeling Language) is an open framework that simplifies the process of authoring, validating, and sharing data. LinkML can describe a range of data structures, from flat, list-based models to complex, interrelated, and normalized models that utilize polymorphism and compound inheritance. It offers an approachable syntax that is not tied to any one technical architecture and can be integrated seamlessly with many existing frameworks. The LinkML syntax provides a standard way to describe schemas, classes, and relationships, allowing modelers to build well-defined, stable, and optionally ontology-aligned data structures. Once defined, LinkML schemas may be imported into other LinkML schemas. These key features make LinkML an accessible platform for interdisciplinary collaboration and a reliable way to define and share data semantics.\n  LinkML helps reduce heterogeneity, complexity, and the proliferation of single-use data models while simultaneously enabling compliance with FAIR data standards. LinkML has seen increasing adoption in various fields, including biology, chemistry, biomedicine, microbiome research, finance, electrical engineering, transportation, and commercial software development. In short, LinkML makes implicit models explicitly computable and allows data to be standardized at its origin. LinkML documentation and code are available at linkml.io.", "AI": {"tldr": "LinkML\u662f\u4e00\u4e2a\u5f00\u653e\u6846\u67b6\uff0c\u7528\u4e8e\u7b80\u5316\u6570\u636e\u7684\u521b\u5efa\u3001\u9a8c\u8bc1\u548c\u5171\u4eab\u8fc7\u7a0b\uff0c\u901a\u8fc7\u63d0\u4f9b\u6807\u51c6\u5316\u7684\u6570\u636e\u5efa\u6a21\u8bed\u8a00\u6765\u89e3\u51b3\u79d1\u5b66\u6570\u636e\u7f3a\u4e4f\u7ed3\u6784\u5316\u7684\u95ee\u9898\u3002", "motivation": "\u79d1\u5b66\u6570\u636e\u901a\u5e38\u5b58\u50a8\u5728\u975e\u7ed3\u6784\u5316\u683c\u5f0f\u4e2d\uff0c\u5982\u81ea\u7531\u6587\u672c\u5b9e\u9a8c\u5ba4\u7b14\u8bb0\u672c\u3001\u975e\u6807\u51c6\u5316\u7535\u5b50\u8868\u683c\u7b49\uff0c\u8fd9\u5bfc\u81f4\u6570\u636e\u4e92\u64cd\u4f5c\u6027\u5dee\uff0c\u96be\u4ee5\u96c6\u6210\u3001\u9a8c\u8bc1\u548c\u91cd\u7528\u3002", "method": "LinkML\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u8bbf\u95ee\u7684\u8bed\u6cd5\u6765\u63cf\u8ff0\u6a21\u5f0f\u3001\u7c7b\u548c\u5173\u7cfb\uff0c\u652f\u6301\u4ece\u7b80\u5355\u5217\u8868\u5230\u590d\u6742\u76f8\u4e92\u5173\u8054\u6a21\u578b\u7684\u591a\u79cd\u6570\u636e\u7ed3\u6784\uff0c\u5e76\u53ef\u4e0e\u73b0\u6709\u6846\u67b6\u65e0\u7f1d\u96c6\u6210\u3002", "result": "LinkML\u5df2\u5728\u751f\u7269\u5b66\u3001\u5316\u5b66\u3001\u751f\u7269\u533b\u5b66\u3001\u91d1\u878d\u7b49\u591a\u4e2a\u9886\u57df\u5f97\u5230\u5e94\u7528\uff0c\u5e2e\u52a9\u51cf\u5c11\u6570\u636e\u5f02\u6784\u6027\u548c\u590d\u6742\u6027\uff0c\u540c\u65f6\u652f\u6301FAIR\u6570\u636e\u6807\u51c6\u5408\u89c4\u3002", "conclusion": "LinkML\u4f7f\u9690\u5f0f\u6a21\u578b\u53d8\u5f97\u663e\u5f0f\u53ef\u8ba1\u7b97\uff0c\u5141\u8bb8\u5728\u6570\u636e\u6e90\u5934\u8fdb\u884c\u6807\u51c6\u5316\uff0c\u4e3a\u8de8\u5b66\u79d1\u5408\u4f5c\u63d0\u4f9b\u4e86\u53ef\u9760\u7684\u6570\u636e\u8bed\u4e49\u5b9a\u4e49\u548c\u5171\u4eab\u5e73\u53f0\u3002"}}
{"id": "2511.16708", "categories": ["cs.SE", "cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2511.16708", "abs": "https://arxiv.org/abs/2511.16708", "authors": ["Shreshth Rajan"], "title": "Multi-Agent Code Verification with Compound Vulnerability Detection", "comment": "18 pages, 3 figures, 9 tables", "summary": "LLMs generate buggy code: 29.6% of SWE-bench \"solved\" patches fail, 62% of BaxBench solutions have vulnerabilities, and existing tools only catch 65% of bugs with 35% false positives. We built CodeX-Verify, a multi-agent system that uses four specialized agents to detect different types of bugs. We prove mathematically that combining agents with different detection patterns finds more bugs than any single agent when the agents look for different problems, confirmed by measuring agent correlation of p = 0.05--0.25. We also show that multiple vulnerabilities in the same code create exponentially more risk than previously thought--SQL injection plus exposed credentials creates 15x more danger (risk 300 vs. 20) than traditional models predict. Testing on 99 code samples with verified labels shows our system catches 76.1% of bugs, matching the best existing method while running faster and without test execution. We tested 15 different agent combinations and found that using multiple agents improves accuracy by 39.7 percentage points (from 32.8% to 72.4%) compared to single agents, with gains of +14.9pp, +13.5pp, and +11.2pp for agents 2, 3, and 4. The best two-agent combination reaches 79.3% accuracy. Testing on 300 real patches from Claude Sonnet 4.5 runs in under 200ms per sample, making this practical for production use.", "AI": {"tldr": "CodeX-Verify\u662f\u4e00\u4e2a\u591a\u4ee3\u7406\u7cfb\u7edf\uff0c\u4e13\u95e8\u68c0\u6d4bLLM\u751f\u6210\u7684\u4ee3\u7801\u4e2d\u7684bug\uff0c\u80fd\u6355\u83b776.1%\u7684bug\uff0c\u6bd4\u5355\u4ee3\u7406\u7cfb\u7edf\u51c6\u786e\u7387\u63d0\u9ad839.7\u4e2a\u767e\u5206\u70b9\uff0c\u8fd0\u884c\u901f\u5ea6\u5feb\uff0c\u65e0\u9700\u6d4b\u8bd5\u6267\u884c\u3002", "motivation": "\u73b0\u6709\u5de5\u5177\u53ea\u80fd\u6355\u83b765%\u7684bug\u4e14\u5047\u9633\u6027\u7387\u8fbe35%\uff0c\u800cLLM\u751f\u6210\u7684\u4ee3\u7801\u4e2dbug\u7387\u5f88\u9ad8\uff08SWE-bench\u4e2d29.6%\u7684\u8865\u4e01\u5931\u8d25\uff0cBaxBench\u4e2d62%\u7684\u89e3\u51b3\u65b9\u6848\u6709\u6f0f\u6d1e\uff09\u3002", "method": "\u4f7f\u7528\u56db\u4e2a\u4e13\u95e8\u4ee3\u7406\u68c0\u6d4b\u4e0d\u540c\u7c7b\u578bbug\u7684\u591a\u4ee3\u7406\u7cfb\u7edf\uff0c\u6570\u5b66\u8bc1\u660e\u4e0d\u540c\u68c0\u6d4b\u6a21\u5f0f\u7684\u4ee3\u7406\u7ec4\u5408\u80fd\u53d1\u73b0\u66f4\u591abug\uff0c\u4ee3\u7406\u95f4\u76f8\u5173\u6027p=0.05-0.25\u3002", "result": "\u572899\u4e2a\u5e26\u9a8c\u8bc1\u6807\u7b7e\u7684\u4ee3\u7801\u6837\u672c\u4e0a\u6d4b\u8bd5\uff0c\u7cfb\u7edf\u6355\u83b776.1%\u7684bug\uff0c\u5339\u914d\u6700\u4f73\u73b0\u6709\u65b9\u6cd5\u4f46\u8fd0\u884c\u66f4\u5feb\uff1b\u591a\u4ee3\u7406\u6bd4\u5355\u4ee3\u7406\u51c6\u786e\u7387\u63d0\u9ad839.7\u4e2a\u767e\u5206\u70b9\uff08\u4ece32.8%\u523072.4%\uff09\uff1b\u6700\u4f73\u53cc\u4ee3\u7406\u7ec4\u5408\u8fbe\u523079.3%\u51c6\u786e\u7387\uff1b\u5728300\u4e2a\u771f\u5b9e\u8865\u4e01\u4e0a\u6d4b\u8bd5\uff0c\u6bcf\u4e2a\u6837\u672c\u8fd0\u884c\u65f6\u95f4<200ms\u3002", "conclusion": "\u591a\u4ee3\u7406\u7cfb\u7edf\u80fd\u6709\u6548\u68c0\u6d4bLLM\u751f\u6210\u7684\u4ee3\u7801bug\uff0c\u51c6\u786e\u7387\u9ad8\u4e14\u5b9e\u7528\uff0c\u540c\u65f6\u53d1\u73b0\u540c\u4e00\u4ee3\u7801\u4e2d\u7684\u591a\u4e2a\u6f0f\u6d1e\u4f1a\u5e26\u6765\u6307\u6570\u7ea7\u98ce\u9669\u589e\u52a0\uff08\u5982SQL\u6ce8\u5165\u52a0\u51ed\u8bc1\u6cc4\u9732\u98ce\u9669\u589e\u52a015\u500d\uff09\u3002"}}
{"id": "2511.17377", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2511.17377", "abs": "https://arxiv.org/abs/2511.17377", "authors": ["Huicong Xu", "Shuang Liu", "Xianyu Zhu", "Qiyu Zhuang", "Wei Lu", "Xiaoyong Du"], "title": "Anomaly Pattern-guided Transaction Bug Testing in Relational Databases", "comment": null, "summary": "Concurrent transaction processing is a fundamental capability of Relational Database Management Systems (RDBMSs), widely utilized in applications requiring high levels of parallel user interaction, such as banking systems, e-commerce platforms, and telecommunications infrastructure. Isolation levels offer a configurable mechanism to manage the interaction between concurrent transactions, enabling varying degrees of consistency and performance trade-offs. These isolation guarantees are supported by all major RDBMSs. However, testing transaction behavior under different isolation levels remains a significant challenge due to two primary reasons. First, automatically generating test transactions that can effectively expose bugs in transaction handling logic is non-trivial, as such bugs are typically triggered under specific transactional constraints. Second, detecting logic anomalies in transaction outcomes is difficult because the correct execution results are often unknown for randomly generated transactions. To address these challenges, we propose an anomaly pattern-guided testing approach for uncovering transaction bugs in RDBMSs. Our solution tackles the first challenge by introducing a test case generation technique guided by predefined anomaly patterns, which increases the likelihood of exposing transactional bugs. For the second challenge, we present a two-phase detection process, involving explicit error detection and implicit error detection, to identify bugs in transaction execution. We have implemented our approach in a tool, APTrans, and evaluated it on three widely-used RDBMSs: MySQL, MariaDB, and OceanBase. APTrans successfully identified 13 previously unknown transaction-related bugs, 11 of which have been confirmed by the respective development teams.", "AI": {"tldr": "\u63d0\u51fa\u4e86APTrans\u5de5\u5177\uff0c\u901a\u8fc7\u5f02\u5e38\u6a21\u5f0f\u5f15\u5bfc\u7684\u6d4b\u8bd5\u65b9\u6cd5\u6765\u53d1\u73b0RDBMS\u4e2d\u7684\u4e8b\u52a1bug\uff0c\u5728MySQL\u3001MariaDB\u548cOceanBase\u4e2d\u53d1\u73b0\u4e8613\u4e2a\u672a\u77e5\u4e8b\u52a1\u76f8\u5173bug\u3002", "motivation": "\u6d4b\u8bd5\u4e0d\u540c\u9694\u79bb\u7ea7\u522b\u4e0b\u7684\u4e8b\u52a1\u884c\u4e3a\u5177\u6709\u6311\u6218\u6027\uff1a\u81ea\u52a8\u751f\u6210\u80fd\u66b4\u9732\u4e8b\u52a1\u5904\u7406\u903b\u8f91bug\u7684\u6d4b\u8bd5\u4e8b\u52a1\u56f0\u96be\uff0c\u4e14\u68c0\u6d4b\u4e8b\u52a1\u7ed3\u679c\u4e2d\u7684\u903b\u8f91\u5f02\u5e38\u4e5f\u56f0\u96be\u3002", "method": "\u91c7\u7528\u5f02\u5e38\u6a21\u5f0f\u5f15\u5bfc\u7684\u6d4b\u8bd5\u65b9\u6cd5\uff0c\u5305\u62ec\u57fa\u4e8e\u9884\u5b9a\u4e49\u5f02\u5e38\u6a21\u5f0f\u7684\u6d4b\u8bd5\u7528\u4f8b\u751f\u6210\u6280\u672f\uff0c\u4ee5\u53ca\u5305\u542b\u663e\u5f0f\u548c\u9690\u5f0f\u9519\u8bef\u68c0\u6d4b\u7684\u4e24\u9636\u6bb5\u68c0\u6d4b\u8fc7\u7a0b\u3002", "result": "\u5728\u4e09\u4e2a\u4e3b\u6d41RDBMS\uff08MySQL\u3001MariaDB\u3001OceanBase\uff09\u4e2d\u6210\u529f\u8bc6\u522b\u4e8613\u4e2a\u4e4b\u524d\u672a\u77e5\u7684\u4e8b\u52a1\u76f8\u5173bug\uff0c\u5176\u4e2d11\u4e2a\u5df2\u88ab\u76f8\u5e94\u5f00\u53d1\u56e2\u961f\u786e\u8ba4\u3002", "conclusion": "APTrans\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u4e8b\u52a1\u6d4b\u8bd5\u4e2d\u7684\u6311\u6218\uff0c\u80fd\u591f\u53ef\u9760\u5730\u53d1\u73b0RDBMS\u4e2d\u7684\u4e8b\u52a1\u5904\u7406bug\u3002"}}
{"id": "2511.16858", "categories": ["cs.SE", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.16858", "abs": "https://arxiv.org/abs/2511.16858", "authors": ["Toufique Ahmed", "Jatin Ganhotra", "Avraham Shinnar", "Martin Hirzel"], "title": "Is the Cure Still Worse Than the Disease? Test Overfitting by LLMs in Automated Program Repair", "comment": null, "summary": "Automated program repair has been shown to be susceptible to generating repaired code that passes on seen tests but fails on a hold-out set of hidden tests. This problem, dubbed test overfitting, has been identified and studied before the rise of large language models. We experimentally study how much test overfitting is still a problem today, using repository-level SWE-bench tasks.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86\u5728\u5927\u578b\u8bed\u8a00\u6a21\u578b\u65f6\u4ee3\uff0c\u7a0b\u5e8f\u81ea\u52a8\u4fee\u590d\u4e2d\u7684\u6d4b\u8bd5\u8fc7\u62df\u5408\u95ee\u9898\u662f\u5426\u4ecd\u7136\u5b58\u5728\uff0c\u4f7f\u7528SWE-bench\u4ed3\u5e93\u7ea7\u4efb\u52a1\u8fdb\u884c\u5b9e\u9a8c\u5206\u6790\u3002", "motivation": "\u7a0b\u5e8f\u81ea\u52a8\u4fee\u590d\u6280\u672f\u5b58\u5728\u6d4b\u8bd5\u8fc7\u62df\u5408\u95ee\u9898\uff0c\u5373\u4fee\u590d\u540e\u7684\u4ee3\u7801\u5728\u53ef\u89c1\u6d4b\u8bd5\u4e0a\u901a\u8fc7\u4f46\u5728\u9690\u85cf\u6d4b\u8bd5\u96c6\u4e0a\u5931\u8d25\u3002\u867d\u7136\u8fd9\u4e2a\u95ee\u9898\u5728\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5174\u8d77\u524d\u5df2\u88ab\u7814\u7a76\uff0c\u4f46\u9700\u8981\u9a8c\u8bc1\u5728\u5f53\u524d\u6280\u672f\u80cc\u666f\u4e0b\u662f\u5426\u4ecd\u7136\u663e\u8457\u3002", "method": "\u4f7f\u7528SWE-bench\u4ed3\u5e93\u7ea7\u4efb\u52a1\u8fdb\u884c\u5b9e\u9a8c\u7814\u7a76\uff0c\u5206\u6790\u7a0b\u5e8f\u4fee\u590d\u4e2d\u7684\u6d4b\u8bd5\u8fc7\u62df\u5408\u73b0\u8c61\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u6d4b\u8bd5\u8fc7\u62df\u5408\u95ee\u9898\u5728\u5f53\u4eca\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u7a0b\u5e8f\u4fee\u590d\u4e2d\u4ecd\u7136\u5b58\u5728\u3002", "conclusion": "\u5373\u4f7f\u5728\u5927\u578b\u8bed\u8a00\u6a21\u578b\u65f6\u4ee3\uff0c\u7a0b\u5e8f\u81ea\u52a8\u4fee\u590d\u4e2d\u7684\u6d4b\u8bd5\u8fc7\u62df\u5408\u95ee\u9898\u4ecd\u9700\u5173\u6ce8\u548c\u89e3\u51b3\u3002"}}
{"id": "2511.16882", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.16882", "abs": "https://arxiv.org/abs/2511.16882", "authors": ["Tim Menzies", "Tao Chen", "Yulong Ye", "Kishan Kumar Ganguly", "Amirali Rayegan", "Srinath Srinivasan", "Andre Lustosa"], "title": "MOOT: a Repository of Many Multi-Objective Optimization Tasks", "comment": null, "summary": "Software engineers must make decisions that trade off competing goals (faster vs. cheaper, secure vs. usable, accurate vs. interpretable, etc.). Despite MSR's proven techniques for exploring such goals, researchers still struggle with these trade-offs. Similarly, industrial practitioners deliver sub-optimal products since they lack the tools needed to explore these trade-offs.\n  To enable more research in this important area, we introduce MOOT, a repository of multi-objective optimization tasks taken from recent SE research papers. MOOT's tasks cover software configuration, cloud tuning, project health, process modeling, hyperparameter optimization, and more. Located at github.com/timm/moot, MOOT's current 120+ tasks are freely available under an MIT license (and we invite community contributions). As shown here, this data enables dozens of novel research questions.", "AI": {"tldr": "MOOT\u662f\u4e00\u4e2a\u591a\u76ee\u6807\u4f18\u5316\u4efb\u52a1\u5e93\uff0c\u5305\u542b120+\u4e2a\u6765\u81ea\u8f6f\u4ef6\u5de5\u7a0b\u7814\u7a76\u8bba\u6587\u7684\u4efb\u52a1\uff0c\u6db5\u76d6\u8f6f\u4ef6\u914d\u7f6e\u3001\u4e91\u8c03\u4f18\u3001\u9879\u76ee\u5065\u5eb7\u7b49\u591a\u4e2a\u9886\u57df\uff0c\u65e8\u5728\u4fc3\u8fdb\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u591a\u76ee\u6807\u6743\u8861\u7684\u7814\u7a76\u3002", "motivation": "\u8f6f\u4ef6\u5de5\u7a0b\u5e08\u9700\u8981\u5728\u7ade\u4e89\u6027\u76ee\u6807\u4e4b\u95f4\u505a\u51fa\u6743\u8861\u51b3\u7b56\uff08\u5982\u901f\u5ea6vs\u6210\u672c\u3001\u5b89\u5168vs\u53ef\u7528\u6027\u7b49\uff09\uff0c\u4f46\u73b0\u6709\u7814\u7a76\u5de5\u5177\u4e0d\u8db3\uff0c\u5bfc\u81f4\u7814\u7a76\u4eba\u5458\u96be\u4ee5\u63a2\u7d22\u8fd9\u4e9b\u6743\u8861\uff0c\u5de5\u4e1a\u5b9e\u8df5\u8005\u4e5f\u65e0\u6cd5\u4f18\u5316\u4ea7\u54c1\u3002", "method": "\u6784\u5efaMOOT\u77e5\u8bc6\u5e93\uff0c\u6536\u96c6\u6765\u81ea\u8fd1\u671f\u8f6f\u4ef6\u5de5\u7a0b\u7814\u7a76\u8bba\u6587\u7684120\u591a\u4e2a\u591a\u76ee\u6807\u4f18\u5316\u4efb\u52a1\uff0c\u6db5\u76d6\u8f6f\u4ef6\u914d\u7f6e\u3001\u4e91\u8c03\u4f18\u3001\u9879\u76ee\u5065\u5eb7\u3001\u8fc7\u7a0b\u5efa\u6a21\u3001\u8d85\u53c2\u6570\u4f18\u5316\u7b49\u9886\u57df\uff0c\u5e76\u5728GitHub\u4e0a\u5f00\u6e90\u3002", "result": "MOOT\u63d0\u4f9b\u4e86120\u591a\u4e2a\u591a\u76ee\u6807\u4f18\u5316\u4efb\u52a1\uff0c\u8fd9\u4e9b\u6570\u636e\u80fd\u591f\u652f\u6301\u6570\u5341\u4e2a\u65b0\u7684\u7814\u7a76\u95ee\u9898\uff0c\u4e3a\u8f6f\u4ef6\u5de5\u7a0b\u6743\u8861\u7814\u7a76\u63d0\u4f9b\u4e86\u4e30\u5bcc\u7684\u6570\u636e\u57fa\u7840\u3002", "conclusion": "MOOT\u77e5\u8bc6\u5e93\u586b\u8865\u4e86\u8f6f\u4ef6\u5de5\u7a0b\u591a\u76ee\u6807\u4f18\u5316\u7814\u7a76\u7684\u6570\u636e\u7a7a\u767d\uff0c\u4e3a\u7814\u7a76\u8005\u548c\u5b9e\u8df5\u8005\u63d0\u4f9b\u4e86\u63a2\u7d22\u7ade\u4e89\u6027\u76ee\u6807\u6743\u8861\u7684\u5de5\u5177\uff0c\u6709\u671b\u63a8\u52a8\u8be5\u9886\u57df\u7684\u7814\u7a76\u8fdb\u5c55\u3002"}}
{"id": "2511.17027", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.17027", "abs": "https://arxiv.org/abs/2511.17027", "authors": ["Zhijie Chen", "Xiang Chen", "Ziming Li", "Jiacheng Xue", "Chaoyang Gao"], "title": "ReVul-CoT: Towards Effective Software Vulnerability Assessment with Retrieval-Augmented Generation and Chain-of-Thought Prompting", "comment": null, "summary": "Context: Software Vulnerability Assessment (SVA) plays a vital role in evaluating and ranking vulnerabilities in software systems to ensure their security and reliability. Objective: Although Large Language Models (LLMs) have recently shown remarkable potential in SVA, they still face two major limitations. First, most LLMs are trained on general-purpose corpora and thus lack domain-specific knowledge essential for effective SVA. Second, they tend to rely on shallow pattern matching instead of deep contextual reasoning, making it challenging to fully comprehend complex code semantics and their security implications. Method: To alleviate these limitations, we propose a novel framework ReVul-CoT that integrates Retrieval-Augmented Generation (RAG) with Chain-of-Thought (COT) prompting. In ReVul-CoT, the RAG module dynamically retrieves contextually relevant information from a constructed local knowledge base that consolidates vulnerability data from authoritative sources (such as NVD and CWE), along with corresponding code snippets and descriptive information. Building on DeepSeek-V3.1, CoT prompting guides the LLM to perform step-by-step reasoning over exploitability, impact scope, and related factors Results: We evaluate ReVul-CoT on a dataset of 12,070 vulnerabilities. Experimental results show that ReVul-CoT outperforms state-of-the-art SVA baselines by 16.50%-42.26% in terms of MCC, and outperforms the best baseline by 10.43%, 15.86%, and 16.50% in Accuracy, F1-score, and MCC, respectively. Our ablation studies further validate the contributions of considering dynamic retrieval, knowledge integration, and CoT-based reasoning. Conclusion: Our results demonstrate that combining RAG with CoT prompting significantly enhances LLM-based SVA and points out promising directions for future research.", "AI": {"tldr": "ReVul-CoT\u6846\u67b6\u7ed3\u5408\u68c0\u7d22\u589e\u5f3a\u751f\u6210(RAG)\u548c\u601d\u7ef4\u94fe(COT)\u63d0\u793a\uff0c\u901a\u8fc7\u52a8\u6001\u68c0\u7d22\u6f0f\u6d1e\u77e5\u8bc6\u5e93\u548c\u9010\u6b65\u63a8\u7406\uff0c\u663e\u8457\u63d0\u5347\u4e86\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8f6f\u4ef6\u6f0f\u6d1e\u8bc4\u4f30\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8f6f\u4ef6\u6f0f\u6d1e\u8bc4\u4f30\u4e2d\u5b58\u5728\u4e24\u4e2a\u4e3b\u8981\u5c40\u9650\uff1a\u7f3a\u4e4f\u9886\u57df\u4e13\u4e1a\u77e5\u8bc6\uff0c\u4ee5\u53ca\u4f9d\u8d56\u6d45\u5c42\u6a21\u5f0f\u5339\u914d\u800c\u975e\u6df1\u5ea6\u4e0a\u4e0b\u6587\u63a8\u7406\uff0c\u96be\u4ee5\u5145\u5206\u7406\u89e3\u590d\u6742\u4ee3\u7801\u8bed\u4e49\u53ca\u5176\u5b89\u5168\u5f71\u54cd\u3002", "method": "\u63d0\u51faReVul-CoT\u6846\u67b6\uff0c\u96c6\u6210RAG\u6a21\u5757\u4ece\u6784\u5efa\u7684\u672c\u5730\u77e5\u8bc6\u5e93\uff08\u5305\u542bNVD\u3001CWE\u7b49\u6743\u5a01\u6f0f\u6d1e\u6570\u636e\uff09\u52a8\u6001\u68c0\u7d22\u76f8\u5173\u4fe1\u606f\uff0c\u5e76\u57fa\u4e8eDeepSeek-V3.1\u4f7f\u7528COT\u63d0\u793a\u5f15\u5bfc\u6a21\u578b\u5bf9\u53ef\u5229\u7528\u6027\u3001\u5f71\u54cd\u8303\u56f4\u7b49\u8fdb\u884c\u9010\u6b65\u63a8\u7406\u3002", "result": "\u572812,070\u4e2a\u6f0f\u6d1e\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cReVul-CoT\u5728MCC\u6307\u6807\u4e0a\u6bd4\u6700\u5148\u8fdb\u57fa\u7ebf\u63d0\u534716.50%-42.26%\uff0c\u5728\u51c6\u786e\u7387\u3001F1\u5206\u6570\u548cMCC\u4e0a\u5206\u522b\u6bd4\u6700\u4f73\u57fa\u7ebf\u63d0\u534710.43%\u300115.86%\u548c16.50%\u3002\u6d88\u878d\u7814\u7a76\u9a8c\u8bc1\u4e86\u52a8\u6001\u68c0\u7d22\u3001\u77e5\u8bc6\u96c6\u6210\u548cCOT\u63a8\u7406\u7684\u8d21\u732e\u3002", "conclusion": "\u7ed3\u5408RAG\u4e0eCOT\u63d0\u793a\u80fd\u663e\u8457\u589e\u5f3a\u57fa\u4e8eLLM\u7684\u8f6f\u4ef6\u6f0f\u6d1e\u8bc4\u4f30\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u6307\u660e\u4e86\u6709\u524d\u666f\u7684\u65b9\u5411\u3002"}}
{"id": "2511.17131", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.17131", "abs": "https://arxiv.org/abs/2511.17131", "authors": ["Horia Cristescu", "Charles Park", "Trong Canh Nguyen", "Sergiu Talmacel", "Alexandru-Gabriel Ilie", "Stefan Adam"], "title": "UI-CUBE: Enterprise-Grade Computer Use Agent Benchmarking Beyond Task Accuracy to Operational Reliability", "comment": "18 pages, 8 figures, 5 tables. Benchmark comprising 226 tasks across two difficulty tiers. Code and benchmark available at https://github.com/UiPath/uipath_enterprise_benchmark", "summary": "While current Computer Use Agent (CUA) benchmarks measure task completion effectively, they provide limited assessment of enterprise deployment readiness, emphasizing functional correctness over the operational reliability required for production systems. We present UI-CUBE (UiPath Computer Use BEnchmark), a systematic benchmark comprising 226 tasks across two difficulty tiers designed to expose fundamental architectural limitations in current CUAs. Our evaluation covers simple UI interactions (136 tasks) and complex workflows including copy-paste tasks (50 tasks) and enterprise application scenarios (40 tasks), with systematic interface variation coverage, multi-resolution testing and automated validation of task success through the application state. Evaluation of five state-of-the-art models reveals a sharp capability cliff rather than gradual performance degradation. Simple UI interactions achieve 67-85% success rates (compared to 97.9% human performance), but complex workflows drop precipitously to 9-19%. Human evaluators with no prior application experience achieve only 61.2% on complex tasks despite near-perfect performance on simple tasks, establishing realistic performance ceilings. This discontinuous performance pattern -- where agents achieve 68-87% of human performance on simple tasks but only 15-32% on complex workflows -- indicates fundamental architectural limitations in memory management, hierarchical planning, and state coordination rather than incremental capability gaps addressable through better training or prompting. UI-CUBE functions as an enterprise-readiness diagnostic, revealing that while current CUAs can manipulate individual interface elements, they cannot yet function as reliable workflow automation tools. These findings provide architectural insights essential for developing production-ready CUAs capable of managing complex, multi-step enterprise processes.", "AI": {"tldr": "UI-CUBE\u662f\u4e00\u4e2a\u7cfb\u7edf\u6027\u7684\u8ba1\u7b97\u673a\u4f7f\u7528\u4ee3\u7406\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b226\u4e2a\u4efb\u52a1\uff0c\u65e8\u5728\u63ed\u793a\u5f53\u524dCUAs\u5728\u4f01\u4e1a\u90e8\u7f72\u51c6\u5907\u5ea6\u65b9\u9762\u7684\u57fa\u672c\u67b6\u6784\u9650\u5236\u3002\u8bc4\u4f30\u663e\u793aCUAs\u5728\u7b80\u5355UI\u4ea4\u4e92\u4e0a\u8868\u73b0\u5c1a\u53ef(67-85%)\uff0c\u4f46\u5728\u590d\u6742\u5de5\u4f5c\u6d41\u4e2d\u6027\u80fd\u6025\u5267\u4e0b\u964d\u81f39-19%\uff0c\u8868\u660e\u5b58\u5728\u6839\u672c\u6027\u7684\u67b6\u6784\u95ee\u9898\u3002", "motivation": "\u5f53\u524dCUA\u57fa\u51c6\u6d4b\u8bd5\u4e3b\u8981\u8861\u91cf\u4efb\u52a1\u5b8c\u6210\u5ea6\uff0c\u4f46\u5bf9\u4f01\u4e1a\u90e8\u7f72\u51c6\u5907\u5ea6\u8bc4\u4f30\u6709\u9650\uff0c\u8fc7\u4e8e\u5f3a\u8c03\u529f\u80fd\u6b63\u786e\u6027\u800c\u5ffd\u89c6\u4e86\u751f\u4ea7\u7cfb\u7edf\u6240\u9700\u7684\u64cd\u4f5c\u53ef\u9760\u6027\u3002\u9700\u8981\u5f00\u53d1\u80fd\u66b4\u9732CUAs\u57fa\u672c\u67b6\u6784\u9650\u5236\u7684\u7cfb\u7edf\u6027\u57fa\u51c6\u3002", "method": "UI-CUBE\u5305\u542b226\u4e2a\u4efb\u52a1\uff0c\u5206\u4e3a\u4e24\u4e2a\u96be\u5ea6\u5c42\u7ea7\uff1a\u7b80\u5355UI\u4ea4\u4e92(136\u4e2a\u4efb\u52a1)\u548c\u590d\u6742\u5de5\u4f5c\u6d41(90\u4e2a\u4efb\u52a1\uff0c\u5305\u62ec50\u4e2a\u590d\u5236\u7c98\u8d34\u4efb\u52a1\u548c40\u4e2a\u4f01\u4e1a\u5e94\u7528\u573a\u666f)\u3002\u91c7\u7528\u7cfb\u7edf\u754c\u9762\u53d8\u5316\u8986\u76d6\u3001\u591a\u5206\u8fa8\u7387\u6d4b\u8bd5\u548c\u901a\u8fc7\u5e94\u7528\u72b6\u6001\u81ea\u52a8\u9a8c\u8bc1\u4efb\u52a1\u6210\u529f\u7684\u65b9\u6cd5\u3002", "result": "\u8bc4\u4f30\u4e94\u4e2a\u6700\u5148\u8fdb\u6a21\u578b\u663e\u793a\u80fd\u529b\u60ac\u5d16\u800c\u975e\u6e10\u8fdb\u6027\u80fd\u4e0b\u964d\uff1a\u7b80\u5355UI\u4ea4\u4e92\u6210\u529f\u738767-85%(\u4eba\u7c7b97.9%)\uff0c\u590d\u6742\u5de5\u4f5c\u6d41\u6025\u5267\u4e0b\u964d\u81f39-19%\u3002\u4eba\u7c7b\u8bc4\u4f30\u8005\u5728\u590d\u6742\u4efb\u52a1\u4e0a\u4ec5\u8fbe61.2%\uff0c\u4e3aCUAs\u8bbe\u5b9a\u4e86\u73b0\u5b9e\u6027\u80fd\u4e0a\u9650\u3002", "conclusion": "\u5f53\u524dCUAs\u53ef\u4ee5\u64cd\u4f5c\u5355\u4e2a\u754c\u9762\u5143\u7d20\uff0c\u4f46\u8fd8\u4e0d\u80fd\u4f5c\u4e3a\u53ef\u9760\u7684\u5de5\u4f5c\u6d41\u81ea\u52a8\u5316\u5de5\u5177\u3002\u8fd9\u79cd\u4e0d\u8fde\u7eed\u6027\u80fd\u6a21\u5f0f\u8868\u660e\u5b58\u5728\u5185\u5b58\u7ba1\u7406\u3001\u5206\u5c42\u89c4\u5212\u548c\u72b6\u6001\u534f\u8c03\u65b9\u9762\u7684\u57fa\u672c\u67b6\u6784\u9650\u5236\uff0c\u800c\u975e\u53ef\u901a\u8fc7\u66f4\u597d\u8bad\u7ec3\u6216\u63d0\u793a\u89e3\u51b3\u7684\u589e\u91cf\u80fd\u529b\u5dee\u8ddd\u3002"}}
{"id": "2511.17262", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.17262", "abs": "https://arxiv.org/abs/2511.17262", "authors": ["Jinfeng Wen", "Yuehan Sun"], "title": "SlsReuse: LLM-Powered Serverless Function Reuse", "comment": null, "summary": "Serverless computing has rapidly emerged as a popular cloud computing paradigm. It enables developers to implement function-level tasks, i.e., serverless functions, without managing infrastructure. While reducing operational overhead, it poses challenges, especially for novice developers. Developing functions from scratch requires adapting to heterogeneous, platform-specific programming styles, making the process time-consuming and error-prone. Function reuse offers a promising solution to address these challenges. However, research on serverless computing lacks a dedicated approach for function recommendation. Existing techniques from traditional contexts remain insufficient due to the semantic gap between task descriptions and heterogeneous function implementations. Advances in large language models (LLMs), pre-trained on large-scale corpora, create opportunities to bridge this gap by aligning developer requirements with function semantics.\n  This paper presents SlsReuse, the first LLM-powered framework for serverless function reuse. Specifically, SlsReuse first constructs a reusable function repository serving as a foundational knowledge base. Then, it learns unified semantic-enhanced representations of heterogeneous functions through effective prompt engineering with few-shot prompting, capturing implicit code intent, target platforms, programming languages, and cloud services. Finally, given a natural language task query, SlsReuse performs intent-aware discovery combined with a multi-level pruning strategy and similarity matching. We evaluate SlsReuse on a curated dataset of 110 task queries. Built on ChatGPT-4o, one of the most representative LLMs, SlsReuse achieves Recall@10 of 91.20%, exceeding the state-of-the-art baseline by 24.53 percentage points.", "AI": {"tldr": "SlsReuse\u662f\u9996\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u670d\u52a1\u5668less\u51fd\u6570\u91cd\u7528\u6846\u67b6\uff0c\u901a\u8fc7\u6784\u5efa\u53ef\u91cd\u7528\u51fd\u6570\u5e93\u3001\u5b66\u4e60\u7edf\u4e00\u8bed\u4e49\u589e\u5f3a\u8868\u793a\uff0c\u5e76\u7ed3\u5408\u610f\u56fe\u611f\u77e5\u53d1\u73b0\u548c\u591a\u7ea7\u526a\u679d\u7b56\u7565\uff0c\u663e\u8457\u63d0\u5347\u4e86\u51fd\u6570\u63a8\u8350\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u670d\u52a1\u5668less\u8ba1\u7b97\u867d\u7136\u964d\u4f4e\u4e86\u8fd0\u7ef4\u5f00\u9500\uff0c\u4f46\u65b0\u624b\u5f00\u53d1\u8005\u9700\u8981\u9002\u5e94\u5e73\u53f0\u7279\u5b9a\u7684\u7f16\u7a0b\u98ce\u683c\uff0c\u4ece\u5934\u5f00\u53d1\u51fd\u6570\u8017\u65f6\u4e14\u6613\u9519\u3002\u51fd\u6570\u91cd\u7528\u662f\u89e3\u51b3\u8fd9\u4e9b\u6311\u6218\u7684\u6709\u6548\u65b9\u6cd5\uff0c\u4f46\u73b0\u6709\u6280\u672f\u7531\u4e8e\u4efb\u52a1\u63cf\u8ff0\u4e0e\u5f02\u6784\u51fd\u6570\u5b9e\u73b0\u4e4b\u95f4\u7684\u8bed\u4e49\u9e3f\u6c9f\u800c\u4e0d\u8db3\u3002", "method": "SlsReuse\u9996\u5148\u6784\u5efa\u53ef\u91cd\u7528\u51fd\u6570\u5e93\u4f5c\u4e3a\u77e5\u8bc6\u57fa\u7840\uff0c\u7136\u540e\u901a\u8fc7\u6709\u6548\u7684\u63d0\u793a\u5de5\u7a0b\u548c\u5c11\u6837\u672c\u63d0\u793a\u5b66\u4e60\u5f02\u6784\u51fd\u6570\u7684\u7edf\u4e00\u8bed\u4e49\u589e\u5f3a\u8868\u793a\uff0c\u6355\u83b7\u4ee3\u7801\u610f\u56fe\u3001\u76ee\u6807\u5e73\u53f0\u3001\u7f16\u7a0b\u8bed\u8a00\u548c\u4e91\u670d\u52a1\u3002\u6700\u540e\uff0c\u7ed9\u5b9a\u81ea\u7136\u8bed\u8a00\u4efb\u52a1\u67e5\u8be2\uff0c\u6267\u884c\u610f\u56fe\u611f\u77e5\u53d1\u73b0\u7ed3\u5408\u591a\u7ea7\u526a\u679d\u7b56\u7565\u548c\u76f8\u4f3c\u6027\u5339\u914d\u3002", "result": "\u5728110\u4e2a\u4efb\u52a1\u67e5\u8be2\u7684\u7cbe\u9009\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0c\u57fa\u4e8eChatGPT-4o\u7684SlsReuse\u5728Recall@10\u6307\u6807\u4e0a\u8fbe\u523091.20%\uff0c\u6bd4\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\u63d0\u9ad8\u4e8624.53\u4e2a\u767e\u5206\u70b9\u3002", "conclusion": "SlsReuse\u901a\u8fc7\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u6210\u529f\u5f25\u5408\u4e86\u5f00\u53d1\u8005\u9700\u6c42\u4e0e\u51fd\u6570\u8bed\u4e49\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u4e3a\u670d\u52a1\u5668less\u51fd\u6570\u91cd\u7528\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.17271", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.17271", "abs": "https://arxiv.org/abs/2511.17271", "authors": ["Sebastian B\u00f6hm", "Florian Sattler", "Norbert Siegmund", "Sven Apel"], "title": "Detecting Performance-Relevant Changes in Configurable Software Systems", "comment": null, "summary": "Performance is a volatile property of a software system and frequent performance profiling is required to keep the knowledge about a software system's performance behavior up to date. Repeating all performance measurements after every revision is a cost-intensive task, especially in the presence of configurability, where one has to measure multiple configurations to obtain a comprehensive picture. Configuration sampling is a common approach to control the measurement cost. However, it cannot guarantee completeness and might miss performance regressions, especially if they only affect few configurations. As an alternative to solve the cost reduction problem, we present ConfFLARE: ConfFLARE estimates whether a change potentially impacts performance by identifying data-flow interactions with performance-relevant code and extracts which software features participate in such interactions. Based on these features, we can select a subset of relevant configurations to focus performance profiling efforts on. In a study conducted on both, synthetic and real-world software systems, ConfFLARE correctly detects performance regressions in almost all cases and identifies relevant features in all but two cases, reducing the number of configurations to be tested on average by $79\\%$ for synthetic and by $70\\%$ for real-world regression scenarios saving hours of performance testing time.", "AI": {"tldr": "ConfFLARE\u901a\u8fc7\u8bc6\u522b\u4e0e\u6027\u80fd\u76f8\u5173\u4ee3\u7801\u7684\u6570\u636e\u6d41\u4ea4\u4e92\u6765\u68c0\u6d4b\u6027\u80fd\u56de\u5f52\uff0c\u5e76\u57fa\u4e8e\u76f8\u5173\u7279\u5f81\u9009\u62e9\u914d\u7f6e\u5b50\u96c6\u8fdb\u884c\u6027\u80fd\u5206\u6790\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u6d4b\u8bd5\u914d\u7f6e\u6570\u91cf\u3002", "motivation": "\u8f6f\u4ef6\u7cfb\u7edf\u7684\u6027\u80fd\u662f\u6613\u53d8\u7684\uff0c\u9700\u8981\u9891\u7e41\u7684\u6027\u80fd\u5206\u6790\u6765\u4fdd\u6301\u5bf9\u7cfb\u7edf\u6027\u80fd\u884c\u4e3a\u7684\u4e86\u89e3\u3002\u5728\u5b58\u5728\u53ef\u914d\u7f6e\u6027\u7684\u60c5\u51b5\u4e0b\uff0c\u5bf9\u6240\u6709\u914d\u7f6e\u8fdb\u884c\u6027\u80fd\u6d4b\u91cf\u6210\u672c\u9ad8\u6602\uff0c\u800c\u914d\u7f6e\u62bd\u6837\u65b9\u6cd5\u65e0\u6cd5\u4fdd\u8bc1\u5b8c\u6574\u6027\uff0c\u53ef\u80fd\u4f1a\u9057\u6f0f\u4ec5\u5f71\u54cd\u5c11\u6570\u914d\u7f6e\u7684\u6027\u80fd\u56de\u5f52\u3002", "method": "ConfFLARE\u901a\u8fc7\u8bc6\u522b\u4e0e\u6027\u80fd\u76f8\u5173\u4ee3\u7801\u7684\u6570\u636e\u6d41\u4ea4\u4e92\u6765\u4f30\u8ba1\u53d8\u66f4\u662f\u5426\u53ef\u80fd\u5f71\u54cd\u6027\u80fd\uff0c\u5e76\u63d0\u53d6\u53c2\u4e0e\u6b64\u7c7b\u4ea4\u4e92\u7684\u8f6f\u4ef6\u7279\u5f81\u3002\u57fa\u4e8e\u8fd9\u4e9b\u7279\u5f81\uff0c\u53ef\u4ee5\u9009\u62e9\u76f8\u5173\u914d\u7f6e\u5b50\u96c6\u6765\u96c6\u4e2d\u6027\u80fd\u5206\u6790\u5de5\u4f5c\u3002", "result": "\u5728\u5408\u6210\u548c\u771f\u5b9e\u4e16\u754c\u8f6f\u4ef6\u7cfb\u7edf\u7684\u7814\u7a76\u4e2d\uff0cConfFLARE\u5728\u51e0\u4e4e\u6240\u6709\u60c5\u51b5\u4e0b\u90fd\u80fd\u6b63\u786e\u68c0\u6d4b\u6027\u80fd\u56de\u5f52\uff0c\u5e76\u5728\u9664\u4e24\u4e2a\u6848\u4f8b\u5916\u7684\u6240\u6709\u60c5\u51b5\u4e0b\u8bc6\u522b\u51fa\u76f8\u5173\u7279\u5f81\uff0c\u5e73\u5747\u51cf\u5c1179%\uff08\u5408\u6210\uff09\u548c70%\uff08\u771f\u5b9e\u4e16\u754c\uff09\u7684\u6d4b\u8bd5\u914d\u7f6e\u6570\u91cf\uff0c\u8282\u7701\u4e86\u6570\u5c0f\u65f6\u7684\u6027\u80fd\u6d4b\u8bd5\u65f6\u95f4\u3002", "conclusion": "ConfFLARE\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u66ff\u4ee3\u65b9\u6cd5\u6765\u89e3\u51b3\u6027\u80fd\u6d4b\u8bd5\u6210\u672c\u95ee\u9898\uff0c\u901a\u8fc7\u667a\u80fd\u9009\u62e9\u76f8\u5173\u914d\u7f6e\u5b50\u96c6\uff0c\u5728\u4fdd\u8bc1\u68c0\u6d4b\u6027\u80fd\u56de\u5f52\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u4e86\u6d4b\u8bd5\u5de5\u4f5c\u91cf\u3002"}}
{"id": "2511.17303", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.17303", "abs": "https://arxiv.org/abs/2511.17303", "authors": ["Timmie M. R. Lagermann", "Kristina Sophia Carter", "Su Mei Gwen Ho", "Lu\u00eds Cruz", "Kerstin Eder", "Maja H. Kirkeby"], "title": "Framework Matters: Energy Efficiency of UI Automation Testing Frameworks", "comment": "10 pages, 6 figures, submitted to The 41st ACM/SIGAPP Symposium On Applied Computing (SAC2026)", "summary": "We examine per action energy consumption across four web user interface (UI) automation testing frameworks to determine whether consistent tendencies can guide energy-aware test design. Using a controlled client-server setup with external power metering, we repeat each UI action (refresh, click variants, checkbox, drag&drop, input-text, scroll) 35 times. Across each of the actions, energy costs vary by both framework and action. Puppeteer is the most efficient for left-click, right-click, double-click, checkbox, and input-text; Selenium is the most efficient for refresh and scroll; Nightwatch is generally the least energy efficient. The energy cost of performing the same action varied by up to a factor of six depending on the framework. This indicates that providing transparency of energy consumption for UI automation testing frameworks allows developers to make informed, energy-aware decisions when testing a specific UI action.", "AI": {"tldr": "\u7814\u7a76\u6bd4\u8f83\u4e86\u56db\u79cdWeb UI\u81ea\u52a8\u5316\u6d4b\u8bd5\u6846\u67b6\u7684\u80fd\u8017\u8868\u73b0\uff0c\u53d1\u73b0\u4e0d\u540c\u6846\u67b6\u6267\u884c\u76f8\u540cUI\u64cd\u4f5c\u7684\u80fd\u8017\u5dee\u5f02\u53ef\u8fbe6\u500d\uff0cPuppeteer\u5728\u591a\u6570\u64cd\u4f5c\u4e2d\u6700\u8282\u80fd\uff0cNightwatch\u6700\u8017\u80fd\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u786e\u5b9aUI\u81ea\u52a8\u5316\u6d4b\u8bd5\u6846\u67b6\u7684\u80fd\u8017\u7279\u6027\uff0c\u4e3a\u5f00\u53d1\u8005\u5728\u6d4b\u8bd5\u7279\u5b9aUI\u64cd\u4f5c\u65f6\u63d0\u4f9b\u80fd\u8017\u900f\u660e\u7684\u51b3\u7b56\u4f9d\u636e\u3002", "method": "\u5728\u53d7\u63a7\u7684\u5ba2\u6237\u7aef-\u670d\u52a1\u5668\u73af\u5883\u4e2d\u4f7f\u7528\u5916\u90e8\u529f\u7387\u6d4b\u91cf\uff0c\u5bf9\u6bcf\u79cdUI\u64cd\u4f5c\uff08\u5237\u65b0\u3001\u70b9\u51fb\u53d8\u4f53\u3001\u590d\u9009\u6846\u3001\u62d6\u653e\u3001\u6587\u672c\u8f93\u5165\u3001\u6eda\u52a8\uff09\u91cd\u590d\u6267\u884c35\u6b21\u3002", "result": "\u4e0d\u540c\u6846\u67b6\u548c\u64cd\u4f5c\u7684\u80fd\u8017\u5dee\u5f02\u663e\u8457\uff1aPuppeteer\u5728\u5de6\u51fb\u3001\u53f3\u51fb\u3001\u53cc\u51fb\u3001\u590d\u9009\u6846\u548c\u6587\u672c\u8f93\u5165\u64cd\u4f5c\u4e2d\u6700\u8282\u80fd\uff1bSelenium\u5728\u5237\u65b0\u548c\u6eda\u52a8\u64cd\u4f5c\u4e2d\u6700\u8282\u80fd\uff1bNightwatch\u901a\u5e38\u80fd\u8017\u6700\u9ad8\u3002\u76f8\u540c\u64cd\u4f5c\u5728\u4e0d\u540c\u6846\u67b6\u95f4\u7684\u80fd\u8017\u5dee\u5f02\u53ef\u8fbe6\u500d\u3002", "conclusion": "\u4e3aUI\u81ea\u52a8\u5316\u6d4b\u8bd5\u6846\u67b6\u63d0\u4f9b\u80fd\u8017\u900f\u660e\u5ea6\uff0c\u4f7f\u5f00\u53d1\u8005\u80fd\u591f\u9488\u5bf9\u7279\u5b9aUI\u64cd\u4f5c\u505a\u51fa\u660e\u667a\u7684\u8282\u80fd\u6d4b\u8bd5\u51b3\u7b56\u3002"}}
{"id": "2511.17330", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.17330", "abs": "https://arxiv.org/abs/2511.17330", "authors": ["Haoxin Tu", "Huan Zhao", "Yahui Song", "Mehtab Zafar", "Ruijie Meng", "Abhik Roychoudhury"], "title": "Agentic Program Verification", "comment": "21 pages, 8 figures", "summary": "Automatically generated code is gaining traction recently, owing to the prevalence of Large Language Models (LLMs). Further, the AlphaProof initiative has demonstrated the possibility of using AI for general mathematical reasoning. Reasoning about computer programs (software) can be accomplished via general mathematical reasoning; however, it tends to be more structured and richer in contexts. This forms an attractive proposition, since then AI agents can be used to reason about voluminous code that gets generated by AI.\n  In this work, we present a first LLM agent, AutoRocq, for conducting program verification. Unlike past works, which rely on extensive training of LLMs on proof examples, our agent learns on-the-fly and improves the proof via an iterative refinement loop. The iterative improvement of the proof is achieved by the proof agent communicating with the Rocq (formerly Coq) theorem prover to get additional context and feedback. The final result of the iteration is a proof derivation checked by the Rocq theorem prover. In this way, our proof construction involves autonomous collaboration between the proof agent and the theorem prover. This autonomy facilitates the search for proofs and decision-making in deciding on the structure of the proof tree.\n  Experimental evaluation on SV-COMP benchmarks and on Linux kernel modules shows promising efficacy in achieving automated program verification. As automation in code generation becomes more widespread, we posit that our proof agent can be potentially integrated with AI coding agents to achieve a generate and validate loop, thus moving closer to the vision of trusted automatic programming.", "AI": {"tldr": "AutoRocq\u662f\u9996\u4e2a\u7528\u4e8e\u7a0b\u5e8f\u9a8c\u8bc1\u7684LLM\u667a\u80fd\u4f53\uff0c\u901a\u8fc7\u8fed\u4ee3\u7cbe\u5316\u5faa\u73af\u4e0eRocq\u5b9a\u7406\u8bc1\u660e\u5668\u534f\u4f5c\uff0c\u5b9e\u73b0\u81ea\u4e3b\u7684\u7a0b\u5e8f\u9a8c\u8bc1\uff0c\u65e0\u9700\u5927\u91cf\u8bad\u7ec3\u6570\u636e\u3002", "motivation": "\u968f\u7740AI\u751f\u6210\u4ee3\u7801\u7684\u666e\u53ca\uff0c\u9700\u8981AI\u667a\u80fd\u4f53\u6765\u9a8c\u8bc1\u5927\u91cf\u751f\u6210\u7684\u4ee3\u7801\u3002\u7a0b\u5e8f\u9a8c\u8bc1\u6bd4\u4e00\u822c\u6570\u5b66\u63a8\u7406\u66f4\u5177\u7ed3\u6784\u6027\u548c\u4e0a\u4e0b\u6587\u4e30\u5bcc\u6027\uff0c\u56e0\u6b64\u5f00\u53d1\u80fd\u591f\u81ea\u4e3b\u8fdb\u884c\u7a0b\u5e8f\u9a8c\u8bc1\u7684AI\u667a\u80fd\u4f53\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002", "method": "\u91c7\u7528LLM\u667a\u80fd\u4f53\u4e0eRocq\u5b9a\u7406\u8bc1\u660e\u5668\u534f\u4f5c\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u8fed\u4ee3\u7cbe\u5316\u5faa\u73af\u5b66\u4e60\u5e76\u6539\u8fdb\u8bc1\u660e\u3002\u667a\u80fd\u4f53\u4ece\u5b9a\u7406\u8bc1\u660e\u5668\u83b7\u53d6\u4e0a\u4e0b\u6587\u548c\u53cd\u9988\uff0c\u81ea\u4e3b\u6784\u5efa\u8bc1\u660e\u6811\u7ed3\u6784\u3002", "result": "\u5728SV-COMP\u57fa\u51c6\u6d4b\u8bd5\u548cLinux\u5185\u6838\u6a21\u5757\u4e0a\u7684\u5b9e\u9a8c\u8bc4\u4f30\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u5728\u5b9e\u73b0\u81ea\u52a8\u5316\u7a0b\u5e8f\u9a8c\u8bc1\u65b9\u9762\u5177\u6709\u826f\u597d\u6548\u679c\u3002", "conclusion": "AutoRocq\u9a8c\u8bc1\u667a\u80fd\u4f53\u53ef\u4ee5\u4e0eAI\u4ee3\u7801\u751f\u6210\u667a\u80fd\u4f53\u96c6\u6210\uff0c\u5b9e\u73b0\u751f\u6210-\u9a8c\u8bc1\u5faa\u73af\uff0c\u63a8\u52a8\u53ef\u4fe1\u81ea\u52a8\u7f16\u7a0b\u613f\u666f\u7684\u5b9e\u73b0\u3002"}}
{"id": "2511.17368", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.17368", "abs": "https://arxiv.org/abs/2511.17368", "authors": ["Eric L. Melin", "Ahmed Musa Awon", "Nasir U. Eisty", "Neil A. Ernst", "Shurui Zhou"], "title": "Exploring Scientific Debt: Harnessing AI for SATD Identification in Scientific Software", "comment": "11 pages, 2 figures, 6 tables", "summary": "Developers often leave behind clues in their code, admitting where it falls short, known as Self-Admitted Technical Debt (SATD). In the world of Scientific Software (SSW), where innovation moves fast and collaboration is key, such debt is not just common but deeply impactful. As research relies on accurate and reproducible results, accumulating SATD can threaten the very foundations of scientific discovery. Yet, despite its significance, the relationship between SATD and SSW remains largely unexplored, leaving a crucial gap in understanding how to manage SATD in this critical domain. This study explores SATD in SSW repositories, comparing SATD in scientific versus general-purpose open-source software and evaluating transformer-based models for SATD identification. We analyzed SATD in 27 scientific and general-purpose repositories across multiple domains and languages. We fine-tuned and compared 10 transformer-based models (100M-7B parameters) on 67,066 labeled code comments. SSW contains 9.25x more Scientific Debt and 4.93x more SATD than general-purpose software due to complex computations, domain constraints, and evolving research needs. Furthermore, our best model outperforms existing ones. This study uncovers how SATD in SSW differs from general software, revealing its impact on quality and scientific validity. By recognizing these challenges, developers and researchers can adopt smarter strategies to manage debt and safeguard the integrity of scientific discovery.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u7d22\u4e86\u79d1\u5b66\u8f6f\u4ef6\u4e2d\u7684\u81ea\u8ba4\u6280\u672f\u503a\u52a1\uff0c\u53d1\u73b0\u79d1\u5b66\u8f6f\u4ef6\u6bd4\u901a\u7528\u8f6f\u4ef6\u5305\u542b9.25\u500d\u7684\u79d1\u5b66\u503a\u52a1\u548c4.93\u500d\u7684SATD\uff0c\u5e76\u8bc4\u4f30\u4e86\u57fa\u4e8etransformer\u7684SATD\u8bc6\u522b\u6a21\u578b\u3002", "motivation": "\u79d1\u5b66\u8f6f\u4ef6\u4e2d\u7684\u6280\u672f\u503a\u52a1\u5bf9\u7814\u7a76\u7ed3\u679c\u7684\u51c6\u786e\u6027\u548c\u53ef\u91cd\u590d\u6027\u6784\u6210\u5a01\u80c1\uff0c\u4f46SATD\u4e0e\u79d1\u5b66\u8f6f\u4ef6\u4e4b\u95f4\u7684\u5173\u7cfb\u5c1a\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\u3002", "method": "\u5206\u6790\u4e8627\u4e2a\u79d1\u5b66\u548c\u901a\u7528\u8f6f\u4ef6\u4ed3\u5e93\uff0c\u572867,066\u4e2a\u6807\u6ce8\u4ee3\u7801\u6ce8\u91ca\u4e0a\u5fae\u8c03\u6bd4\u8f83\u4e8610\u4e2a\u57fa\u4e8etransformer\u7684\u6a21\u578b\uff08\u53c2\u6570\u8303\u56f41\u4ebf-70\u4ebf\uff09\u3002", "result": "\u79d1\u5b66\u8f6f\u4ef6\u5305\u542b\u663e\u8457\u66f4\u591a\u7684\u79d1\u5b66\u503a\u52a1\u548cSATD\uff0c\u6700\u4f73\u6a21\u578b\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86\u79d1\u5b66\u8f6f\u4ef6\u4e2dSATD\u7684\u7279\u6b8a\u6027\u53ca\u5176\u5bf9\u8d28\u91cf\u548c\u79d1\u5b66\u6709\u6548\u6027\u7684\u5f71\u54cd\uff0c\u4e3a\u5f00\u53d1\u8005\u548c\u7814\u7a76\u4eba\u5458\u63d0\u4f9b\u4e86\u7ba1\u7406\u6280\u672f\u503a\u52a1\u7684\u7b56\u7565\u3002"}}
{"id": "2511.17417", "categories": ["cs.SE", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.17417", "abs": "https://arxiv.org/abs/2511.17417", "authors": ["Soroush Javdan", "Pragash Krishnamoorthy", "Olga Baysal"], "title": "CREST: Improving Interpretability and Effectiveness of Troubleshooting at Ericsson through Criterion-Specific Trouble Report Retrieval", "comment": null, "summary": "The rapid evolution of the telecommunication industry necessitates efficient troubleshooting processes to maintain network reliability, software maintainability, and service quality. Trouble Reports (TRs), which document issues in Ericsson's production system, play a critical role in facilitating the timely resolution of software faults. However, the complexity and volume of TR data, along with the presence of diverse criteria that reflect different aspects of each fault, present challenges for retrieval systems. Building on prior work at Ericsson, which utilized a two-stage workflow, comprising Initial Retrieval (IR) and Re-Ranking (RR) stages, this study investigates different TR observation criteria and their impact on the performance of retrieval models. We propose \\textbf{CREST} (\\textbf{C}riteria-specific \\textbf{R}etrieval via \\textbf{E}nsemble of \\textbf{S}pecialized \\textbf{T}R models), a criterion-driven retrieval approach that leverages specialized models for different TR fields to improve both effectiveness and interpretability, thereby enabling quicker fault resolution and supporting software maintenance. CREST utilizes specialized models trained on specific TR criteria and aggregates their outputs to capture diverse and complementary signals. This approach leads to enhanced retrieval accuracy, better calibration of predicted scores, and improved interpretability by providing relevance scores for each criterion, helping users understand why specific TRs were retrieved. Using a subset of Ericsson's internal TRs, this research demonstrates that criterion-specific models significantly outperform a single model approach across key evaluation metrics. This highlights the importance of all targeted criteria used in this study for optimizing the performance of retrieval systems.", "AI": {"tldr": "CREST\u662f\u4e00\u4e2a\u57fa\u4e8e\u591a\u6807\u51c6\u96c6\u6210\u5b66\u4e60\u7684\u6545\u969c\u62a5\u544a\u68c0\u7d22\u7cfb\u7edf\uff0c\u901a\u8fc7\u4e3a\u4e0d\u540c\u6545\u969c\u6807\u51c6\u8bad\u7ec3\u4e13\u95e8\u6a21\u578b\u5e76\u96c6\u6210\u8f93\u51fa\uff0c\u663e\u8457\u63d0\u5347\u4e86\u68c0\u7d22\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u7535\u4fe1\u884c\u4e1a\u5feb\u901f\u53d1\u5c55\u9700\u8981\u9ad8\u6548\u7684\u6545\u969c\u6392\u9664\u6d41\u7a0b\uff0c\u4f46Ericsson\u751f\u4ea7\u7cfb\u7edf\u4e2d\u7684\u6545\u969c\u62a5\u544a\u6570\u636e\u590d\u6742\u4e14\u91cf\u5927\uff0c\u5305\u542b\u53cd\u6620\u6545\u969c\u4e0d\u540c\u65b9\u9762\u7684\u591a\u79cd\u6807\u51c6\uff0c\u7ed9\u68c0\u7d22\u7cfb\u7edf\u5e26\u6765\u6311\u6218\u3002", "method": "\u63d0\u51faCREST\u65b9\u6cd5\uff0c\u4e3a\u4e0d\u540c\u7684\u6545\u969c\u62a5\u544a\u6807\u51c6\u8bad\u7ec3\u4e13\u95e8\u6a21\u578b\uff0c\u7136\u540e\u96c6\u6210\u8fd9\u4e9b\u4e13\u95e8\u6a21\u578b\u7684\u8f93\u51fa\u6765\u6355\u83b7\u591a\u6837\u5316\u548c\u4e92\u8865\u7684\u4fe1\u53f7\uff0c\u4ece\u800c\u63d0\u9ad8\u68c0\u7d22\u6548\u679c\u548c\u53ef\u89e3\u91ca\u6027\u3002", "result": "\u5728Ericsson\u5185\u90e8\u6545\u969c\u62a5\u544a\u5b50\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u57fa\u4e8e\u6807\u51c6\u4e13\u95e8\u5316\u7684\u6a21\u578b\u5728\u5173\u952e\u8bc4\u4f30\u6307\u6807\u4e0a\u663e\u8457\u4f18\u4e8e\u5355\u4e00\u6a21\u578b\u65b9\u6cd5\u3002", "conclusion": "\u6240\u6709\u76ee\u6807\u6807\u51c6\u5bf9\u4e8e\u4f18\u5316\u68c0\u7d22\u7cfb\u7edf\u6027\u80fd\u90fd\u5f88\u91cd\u8981\uff0cCREST\u65b9\u6cd5\u901a\u8fc7\u63d0\u4f9b\u6bcf\u4e2a\u6807\u51c6\u7684\u76f8\u5173\u6027\u5206\u6570\uff0c\u5e2e\u52a9\u7528\u6237\u7406\u89e3\u7279\u5b9a\u6545\u969c\u62a5\u544a\u88ab\u68c0\u7d22\u7684\u539f\u56e0\uff0c\u652f\u6301\u66f4\u5feb\u7684\u6545\u969c\u89e3\u51b3\u548c\u8f6f\u4ef6\u7ef4\u62a4\u3002"}}
