<div id=toc></div>

# Table of Contents

- [cs.DC](#cs.DC) [Total: 6]
- [cs.DB](#cs.DB) [Total: 8]
- [cs.SE](#cs.SE) [Total: 10]


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [1] [Fantasy: Efficient Large-scale Vector Search on GPU Clusters with GPUDirect Async](https://arxiv.org/abs/2512.02278)
*Yi Liu,Chen Qian*

Main category: cs.DC

TL;DR: Fantasy是一个用于大规模向量相似性搜索的GPU集群系统，通过GPUDirect Async实现计算与网络通信的流水线化，解决了单GPU内存不足和CPU-GPU架构中数据传输瓶颈的问题。


<details>
  <summary>Details</summary>
Motivation: 随着AI应用（如大语言模型）中向量数量的快速增长，图索引大小迅速超过单个GPU的内存容量。现有的CPU-GPU架构虽然能存储更多向量，但数据传输步骤会阻塞GPU计算，导致性能瓶颈。

Method: 提出Fantasy系统，在GPU集群中使用GPUDirect Async技术，将向量搜索与数据传输进行流水线化处理，重叠计算与网络通信，从而消除数据传输的阻塞。

Result: 显著提高了大规模图索引的搜索吞吐量，并支持更大的查询批处理大小，解决了单GPU内存限制和CPU-GPU架构中的数据传输瓶颈问题。

Conclusion: Fantasy通过GPU集群中的流水线化设计，有效解决了大规模向量相似性搜索中的内存限制和性能瓶颈问题，为AI应用提供了高效的大规模向量搜索解决方案。

Abstract: Vector similarity search has become a critical component in AI-driven applications such as large language models (LLMs). To achieve high recall and low latency, GPUs are utilized to exploit massive parallelism for faster query processing. However, as the number of vectors continues to grow, the graph size quickly exceeds the memory capacity of a single GPU, making it infeasible to store and process the entire index on a single GPU. Recent work uses CPU-GPU architectures to keep vectors in CPU memory or SSDs, but the loading step stalls GPU computation. We present Fantasy, an efficient system that pipelines vector search and data transfer in a GPU cluster with GPUDirect Async. Fantasy overlaps computation and network communication to significantly improve search throughput for large graphs and deliver large query batch sizes.

</details>


### [2] [DOLMA: A Data Object Level Memory Disaggregation Framework for HPC Applications](https://arxiv.org/abs/2512.02300)
*Haoyu Zheng,Shouwei Gao,Jie Ren,Wenqian Dong*

Main category: cs.DC

TL;DR: DOLMA是一个面向HPC应用的数据对象级内存解聚合框架，通过智能识别和卸载数据对象到远程内存，在平均减少63%本地内存使用的同时，将性能下降控制在16%以内。


<details>
  <summary>Details</summary>
Motivation: 内存解聚合技术有望扩展HPC系统的内存容量并提高利用率，但访问远程内存的性能开销对计算密集型HPC应用构成重大挑战，这些应用的执行时间对数据局部性高度敏感。

Method: DOLMA框架智能识别并将数据对象卸载到远程内存，提供定量分析来确定合适的本地内存大小。利用HPC应用中典型可预测的内存访问模式，通过双缓冲区设计实现远程内存预取。通过仔细平衡本地和远程内存使用，并维护多线程并发性。

Result: 在八个HPC工作负载和计算内核的评估中，DOLMA将性能下降限制在16%以内，同时将本地内存使用量平均减少高达63%。

Conclusion: DOLMA为HPC领域利用解聚合内存提供了一个灵活高效的解决方案，同时对应用性能的影响最小。

Abstract: Memory disaggregation is promising to scale memory capacity and improves utilization in HPC systems. However, the performance overhead of accessing remote memory poses a significant chal- lenge, particularly for compute-intensive HPC applications where execution times are highly sensitive to data locality. In this work, we present DOLMA, a Data Object Level M emory dis Aggregation framework designed for HPC applications. DOLMA intelligently identifies and offloads data objects to remote memory, while pro- viding quantitative analysis to decide a suitable local memory size. Furthermore, DOLMA leverages the predictable memory access patterns typical in HPC applications and enables remote memory prefetch via a dual-buffer design. By carefully balancing local and remote memory usage and maintaining multi-thread concurrency, DOLMA provides a flexible and efficient solution for leveraging dis- aggregated memory in HPC domains while minimally compromis- ing application performance. Evaluating with eight HPC workloads and computational kernels, DOLMA limits performance degrada- tion to less than 16% while reducing local memory usage by up to 63%, on average.

</details>


### [3] [Solutions for Distributed Memory Access Mechanism on HPC Clusters](https://arxiv.org/abs/2512.02546)
*Jan Meizner,Maciej Malawski*

Main category: cs.DC

TL;DR: 论文评估了分布式系统中基于两个HPC集群的远程内存访问机制，比较了基于共享存储和MPI（通过Infiniband和Slingshot）的解决方案与本地内存访问的性能，发现基于MPI的远程访问性能与本地内存访问相似


<details>
  <summary>Details</summary>
Motivation: 研究分布式系统中远程内存访问机制的性能，特别是在HPC集群环境下，为医疗等应用场景提供高效的数据访问解决方案

Method: 在两个不同的HPC集群上，比较了基于共享存储的解决方案和基于MPI（通过Infiniband和Slingshot网络）的远程内存访问机制，并与本地内存访问进行性能对比

Result: 研究发现基于MPI的远程内存访问性能与本地内存访问相似，特别是在Infiniband和Slingshot网络支持下，远程访问性能接近本地访问水平

Conclusion: 基于MPI的远程内存访问机制在分布式系统中具有实用价值，特别适用于医疗等需要高效数据访问的应用场景，能够提供接近本地内存访问的性能

Abstract: Paper presents and evaluates various mechanisms for remote access to memory in distributed systems based on two distinct HPC clusters. We are comparing solutions based on the shared storage and MPI (over Infiniband and Slingshot) to the local memory access. This paper also mentions medical use-cases that would mostly benefit from the described solution. We have found out that results for remote access esp. backed by MPI are similar to local memory access.

</details>


### [4] [Offloading Artificial Intelligence Workloads across the Computing Continuum by means of Active Storage Systems](https://arxiv.org/abs/2512.02646)
*Alex Barceló,Sebastián A. Cajas Ordoñez,Jaydeep Samanta,Andrés L. Suárez-Cetrulo,Romila Ghosh,Ricardo Simón Carbajo,Anna Queralt*

Main category: cs.DC

TL;DR: 本文提出了一种基于主动存储的计算连续体软件架构，用于优化AI工作负载分布，通过将计算嵌入存储架构减少数据传输开销，提高内存效率和训练速度。


<details>
  <summary>Details</summary>
Motivation: AI工作负载需求增长，传统云架构难以处理AI驱动数据的体量和速度，在存储、计算和数据移动方面存在效率问题。现有框架缺乏计算连续体所需的灵活性和适应性，无法应对设备异构性和快速变化的算法模型。

Method: 提出一种软件架构，将AI工作负载无缝分布到计算连续体中，使用主流Python库和active storage平台dataClay实现。通过将计算嵌入存储架构，减少数据传输开销。

Result: 实验评估显示，通过主动存储卸载工作负载显著提高了内存效率和训练速度，同时保持准确性。在不同设备上展示了内存消耗、存储需求、训练时间和执行效率的权衡。

Conclusion: 主动存储有潜力革新AI工作负载管理，使分布式AI部署更具可扩展性和资源效率，同时为领域专家和应用开发者提供极低入门门槛。

Abstract: The increasing demand for artificial intelligence (AI) workloads across diverse computing environments has driven the need for more efficient data management strategies. Traditional cloud-based architectures struggle to handle the sheer volume and velocity of AI-driven data, leading to inefficiencies in storage, computation, and data movement. This paper explores the integration of active storage systems within the computing continuum to optimize AI workload distribution.
  By embedding computation directly into storage architectures, active storage is able to reduce data transfer overhead, enhancing performance and improving resource utilization. Other existing frameworks and architectures offer mechanisms to distribute certain AI processes across distributed environments; however, they lack the flexibility and adaptability that the continuum requires, both regarding the heterogeneity of devices and the rapid-changing algorithms and models being used by domain experts and researchers.
  This article proposes a software architecture aimed at seamlessly distributing AI workloads across the computing continuum, and presents its implementation using mainstream Python libraries and dataClay, an active storage platform. The evaluation shows the benefits and trade-offs regarding memory consumption, storage requirements, training times, and execution efficiency across different devices. Experimental results demonstrate that the process of offloading workloads through active storage significantly improves memory efficiency and training speeds while maintaining accuracy. Our findings highlight the potential of active storage to revolutionize AI workload management, making distributed AI deployments more scalable and resource-efficient with a very low entry barrier for domain experts and application developers.

</details>


### [5] [Distributed and Autonomic Minimum Spanning Trees](https://arxiv.org/abs/2512.02683)
*Luiz A. Rodrigues,Elias P. Duarte,Luciana Arantes*

Main category: cs.DC

TL;DR: 提出一种自洽算法，使分布式系统中的n个进程能够构建和维护连接自身的生成树，每个节点的入度和树深度最多为log₂n，支持动态创建和透明重构，并基于此提出两种广播算法。


<details>
  <summary>Details</summary>
Motivation: 传统的一对多广播策略在分布式系统中不可扩展，会给发送者带来沉重负载。需要一种能够自动构建和维护生成树的算法，以支持可扩展的广播通信。

Method: 使用VCube虚拟拓扑作为故障检测器，构建和维护一个生成树，其中进程作为树的顶点。算法确保每个顶点的入度和树深度最多为log₂n，当所有进程正常时，每个进程的度恰好为log₂n。支持从任意源进程动态创建生成树，并在进程故障或恢复时透明重构。

Result: 算法能够容忍最多n-1个进程故障，正确进程仍通过可扩展的生成树保持连接。基于该算法提出了两种广播算法：尽力而为广播和可靠广播。仿真结果包括与其他替代方案的比较。

Conclusion: 该自洽生成树算法为分布式系统提供了可扩展的广播通信解决方案，通过VCube虚拟拓扑支持动态重构和故障容忍，为广播通信提供了高效的基础设施。

Abstract: The most common strategy for enabling a process in a distributed system to broadcast a message is one-to-all communication. However, this approach is not scalable, as it places a heavy load on the sender. This work presents an autonomic algorithm that enables the $n$ processes in a distributed system to build and maintain a spanning tree connecting themselves. In this context, processes are the vertices of the spanning tree. By definition, a spanning tree connects all processes without forming cycles. The proposed algorithm ensures that every vertex in the spanning tree has both an in-degree and the tree depth of at most $log_2 n$. When all processes are correct, the degree of each process is exactly $log_2 n$. A spanning tree is dynamically created from any source process and is transparently reconstructed as processes fail or recover. Up to $n-1$ processes can fail, and the correct processes remain connected through a scalable, functioning spanning tree. To build and maintain the tree, processes use the VCube virtual topology, which also serves as a failure detector. Two broadcast algorithms based on the autonomic spanning tree algorithm are presented: one for best-effort broadcast and one for reliable broadcast. Simulation results are provided, including comparisons with other alternatives.

</details>


### [6] [Designing FAIR Workflows at OLCF: Building Scalable and Reusable Ecosystems for HPC Science](https://arxiv.org/abs/2512.02818)
*Sean R. Wilkinson,Patrick Widener,Sarp Oral,Rafael Ferreira da Silva*

Main category: cs.DC

TL;DR: HPC中心应发挥更积极作用，通过组件化FAIR方法促进跨学科研究，借鉴EOSC-Life架构但专注于使单个工作流组件可发现、可重用。


<details>
  <summary>Details</summary>
Motivation: HPC用户常因系统差异而开发与特定中心紧密耦合的数字制品，导致重复劳动。现有FAIR实践多局限于特定学科领域，形成孤岛，限制了跨学科协作。

Method: 借鉴欧洲开放科学云(EOSC) EOSC-Life FAIR工作流协作架构，提出针对HPC需求的模型，强调使单个工作流组件而非整个工作流符合FAIR原则。

Result: 提出组件化FAIR方法，能更好支持HPC用户多样化需求，最大化其工作的长期价值，促进跨学科研究协作。

Conclusion: HPC中心应设计支持研究者更有效发现、共享和重用计算组件的基础设施，通过组件化FAIR生态系统推动跨学科科学进步。

Abstract: High Performance Computing (HPC) centers provide advanced infrastructure that enables scientific research at extreme scale. These centers operate with hardware configurations, software environments, and security requirements that differ substantially from most users' local systems. As a result, users often develop customized digital artifacts that are tightly coupled to a given HPC center. This practice can lead to significant duplication of effort as multiple users independently create similar solutions to common problems. The FAIR Principles offer a framework to address these challenges. Initially designed to improve data stewardship, the FAIR approach has since been extended to encompass software, workflows, models, and infrastructure. By encouraging the use of rich metadata and community standards, FAIR practices aim to make digital artifacts easier to share and reuse, both within and across scientific domains. Many FAIR initiatives have emerged within individual research communities, often aligned by discipline (e.g. bioinformatics, earth sciences). These communities have made progress in adopting FAIR practices, but their domain-specific nature can lead to silos that limit broader collaboration. Thus, we propose that HPC centers play a more active role in fostering FAIR ecosystems that support research across multiple disciplines. This requires designing infrastructure that enables researchers to discover, share, and reuse computational components more effectively. Here, we build on the architecture of the European Open Science Cloud (EOSC) EOSC-Life FAIR Workflows Collaboratory to propose a model tailored to the needs of HPC. Rather than focusing on entire workflows, we emphasize the importance of making individual workflow components FAIR. This component-based approach better supports the diverse and evolving needs of HPC users while maximizing the long-term value of their work.

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [7] [FCDB (Functorial-Categorical Database): A Compositional Framework for Information Preservation and Anti-Commutativity Reduction](https://arxiv.org/abs/2512.02021)
*Jun Kawasaki*

Main category: cs.DB

TL;DR: FCDb提出了一种基于函子范畴的分层数据库架构，通过完全保留投影族实现信息不丢失，将正确性与信息保留解耦，核心内核在所有权边界处处理非交换性。


<details>
  <summary>Details</summary>
Motivation: 传统数据库架构通过丢弃信息来确保局部一致性，导致正确性与信息丢失相纠缠。作者希望建立一个既能保证正确性又能完全保留信息的数据库模型。

Method: 将数据操作建模为分层函子范畴中的态射，建立完全保留投影族（CPF），涵盖内容不变性、能力和所有权三个维度，并支持可选的观测投影（B+树、时间历史、图结构）。识别最小内核F_core = Own o Cap o CAS，在伴随提升和纤维结构下保持信息。

Result: 该框架在范畴极限下使操作对可交换，同时保持所有权完整性和能力约束。通过投影解释连接到信息几何学，支持在不丢弃语义、时间或关系熵的情况下进行经验验证。

Conclusion: FCDb提供了一种新的数据库范式，将正确性与信息保留解耦，通过范畴方法处理非交换性，为信息完整性和操作一致性提供了理论基础。

Abstract: Conventional database architectures often secure local consistency by discarding information, entangling correctness with loss. We introduce the Functorial-Categorical Database (FCDb), which models data operations as morphisms in a layered functor category and establishes a Complete Preserving Family (CPF) of projections spanning content invariance (CAS), capability, and ownership, with optional observational projections for local order (B+Tree), temporal history (append-only/LSM), and adjacency (Graph). We identify a minimal kernel (F_core = Own o Cap o CAS) that preserves information and collapses non-commutativity to the ethical grant/revoke boundary. Under adjoint lifts and a fibred structure, operational pairs commute in the categorical limit while ownership integrity and capability constraints are maintained. The framework connects to information geometry via projection interpretations and supports empirical validation without discarding semantic, temporal, or relational entropy.

</details>


### [8] [Trinity: Disaggregating Vector Search from Prefill-Decode Disaggregation in LLM Serving](https://arxiv.org/abs/2512.02281)
*Yi Liu,Chen Qian*

Main category: cs.DB

TL;DR: Trinity是一个将向量检索整合到PD解耦LLM服务中的框架，通过专用GPU池和智能调度优化检索任务处理


<details>
  <summary>Details</summary>
Motivation: 当前检索任务与模型推理过程纠缠在一起，如异构RAG请求和提示答案缓存，增加了尾部延迟。需要研究如何在PD解耦架构中协调向量检索，同时不违反各种检索工作负载的SLO

Method: Trinity框架将所有检索整合到单个共享的向量搜索GPU池中，与PD解耦的LLM服务协同工作。包括：(1) PD解耦中GPU向量搜索服务的新架构；(2) 向量搜索的连续批处理，充分利用GPU处理异构查询；(3) 阶段感知调度，在解码和预填充任务之间抢占向量搜索请求

Result: 论文提出了Trinity框架，但摘要中没有具体实验结果数据

Conclusion: Trinity提供了一个实用的框架，将向量检索整合到PD解耦的LLM服务中，通过专用GPU池和智能调度优化检索任务处理

Abstract: Prefill and decode (PD) disaggregation separates prompt prefill and token-by-token decode stages into distinct GPU pools and has become the dominant architecture for large-scale LLM serving in industry. Also, retrieval tasks via vector search remains entangled with the model inference process, like heterogeneous RAG requests and prompt answer caches, inflating tail latency. We are motivated to investigate how vector search should be orchestrated along with PD disaggregation with a dedicated deployment architecture without violating SLOs in various retrieval workloads. We present Trinity, a practical framework that consolidates all retrieval into a single, shared vector-search GPU pool and make it work with PD disaggregated LLM serving in match. Trinity introduces (1) a novel architecture for deploying GPU-based vector search service in PD disaggregation. (2) Continuous batching for vector search that make full used of GPUs under heterogeneous queries; (3) Stage-aware scheduling that preempts vector search requests between both decode and prefill tasks.

</details>


### [9] [Multi-Objective Agentic Rewrites for Unstructured Data Processing](https://arxiv.org/abs/2512.02289)
*Lindsey Linxi Wei,Shreya Shankar,Sepanta Zeighami,Yeounoh Chung,Fatma Ozcan,Aditya G. Parameswaran*

Main category: cs.DB

TL;DR: MOAR是一个为DocETL系统设计的多目标优化器，通过扩展重写指令和全局搜索算法，在保持高精度的同时显著降低LLM处理成本。


<details>
  <summary>Details</summary>
Motivation: DocETL系统虽然通过语义操作符简化了LLM数据处理流程，但仅优化精度而忽略成本。实际应用中，复杂的操作符和数据会导致LLM结果不准确且成本高昂，需要同时优化精度和成本。

Method: 1. 扩展重写指令：新增两类成本优化指令，将原有三类指令扩展至30多个；2. 全局搜索算法：考虑操作符间的相互影响，采用多臂赌博机框架在无限重写空间中优先探索有潜力的管道重写方案。

Result: 在六个工作负载测试中，MOAR比次优优化器ABACUS精度提高27%，同时以55%的成本达到其最佳精度水平，实现了精度和成本的双重优化。

Conclusion: MOAR成功解决了DocETL系统仅优化精度的问题，通过扩展指令集和创新的全局搜索算法，在LLM数据处理中实现了精度和成本的多目标优化，具有实际应用价值。

Abstract: One year ago, we open-sourced DocETL, a declarative system for LLM-powered data processing that, as of November 2025, has 3.2K GitHub stars and users across domains (e.g., journalism, law, medicine, policy, finance, and urban planning). In DocETL, users build pipelines by composing operators described in natural language, also known as semantic operators, with an LLM executing each operator's logic. However, due to complexity in the operator or the data it operates on, LLMs often give inaccurate results. To address this challenge, DocETL introduced rewrite directives, or abstract rules that guide LLM agents in rewriting pipelines by decomposing operators or data. For example, decomposing a single filter("is this email sent from an executive and discussing fraud?") into the conjunction of two separate semantic filters may improve accuracy. However, DocETL only optimizes for accuracy, not cost. How do we optimize for both?
  We present MOAR (Multi-Objective Agentic Rewrites), a new optimizer for DocETL. To target cost optimization, we introduce two new categories of directives and extend all three existing categories with new ones, bringing the total to over 30 directives -- more than doubling what DocETL originally had. Moreover, since operators can interact with each other unpredictably due to LLM behavior, optimizing operators or sub-pipelines individually can yield suboptimal overall plans. Recognizing this, we design a new global search algorithm that explores rewrites in the context of entire pipelines. Since the space of rewrites is infinite -- pipelines can be rewritten in many ways, and each rewritten pipeline can itself be rewritten -- our algorithm adapts a multi-armed bandit framework to prioritize which pipelines to rewrite. Across six workloads, MOAR achieves 27% higher accuracy than ABACUS, the next-best optimizer, while matching its best accuracy at 55% of its cost.

</details>


### [10] [QJoin: Transformation-aware Joinable Data Discovery Using Reinforcement Learning](https://arxiv.org/abs/2512.02444)
*Ning Wang,Sainyam Galhotra*

Main category: cs.DB

TL;DR: QJoin：基于强化学习的框架，通过学习跨连接任务的重用转换策略，解决异构数据仓库中的连接发现问题，相比传统方法在准确性和效率上都有显著提升。


<details>
  <summary>Details</summary>
Motivation: 在大型异构数据仓库中，发现哪些表可以连接以及通过什么转换进行连接是数据集成和数据发现的核心挑战。传统连接发现方法主要设计用于等值连接，假设连接键完全或近似匹配，在开放或联邦设置中，当标识符格式不一致、嵌入或跨多列拆分时，这些技术会失效。

Method: 引入QJoin强化学习框架，训练智能体在唯一性感知奖励下工作，平衡相似性与键的独特性，探索简洁、高价值的转换链。为加速新连接，引入两种重用机制：(i) 智能体迁移，从预训练智能体初始化新策略；(ii) 转换重用，为相似列集群缓存成功的操作符序列。

Result: 在AutoJoin Web基准测试（31个表对）中，QJoin平均F1分数达到91.0%。在NYC+Chicago开放数据集的19,990个连接任务中，QJoin通过重用机制将运行时间减少了高达7.4%（13,747秒）。

Conclusion: 转换学习和重用可以使连接发现既更准确又更高效，QJoin框架在异构数据环境中表现出色，解决了传统方法在复杂数据格式下的局限性。

Abstract: Discovering which tables in large, heterogeneous repositories can be joined and by what transformations is a central challenge in data integration and data discovery. Traditional join discovery methods are largely designed for equi-joins, which assume that join keys match exactly or nearly so. These techniques, while efficient in clean, well-normalized databases, fail in open or federated settings where identifiers are inconsistently formatted, embedded, or split across multiple columns. Approximate or fuzzy joins alleviate minor string variations but cannot capture systematic transformations. We introduce QJoin, a reinforcement-learning framework that learns and reuses transformation strategies across join tasks. QJoin trains an agent under a uniqueness-aware reward that balances similarity with key distinctiveness, enabling it to explore concise, high-value transformation chains. To accelerate new joins, we introduce two reuse mechanisms: (i) agent transfer, which initializes new policies from pretrained agents, and (ii) transformation reuse, which caches successful operator sequences for similar column clusters. On the AutoJoin Web benchmark (31 table pairs), QJoin achieves an average F1-score of 91.0%. For 19,990 join tasks in NYC+Chicago open datasets, Qjoin reduces runtime by up to 7.4% (13,747 s) by using reusing. These results demonstrate that transformation learning and reuse can make join discovery both more accurate and more efficient.

</details>


### [11] [A Datalake for Data-driven Social Science Research](https://arxiv.org/abs/2512.02463)
*Puneet Arya,Ojas Sahasrabudhe,Adwaiya Srivastav,Partha Pratim Das,Maya Ramanath*

Main category: cs.DB

TL;DR: 为社会科学研究设计的专用数据湖基础设施，解决技术门槛、数据格式不一致和可靠数据集获取困难等问题


<details>
  <summary>Details</summary>
Motivation: 社会科学研究日益需要数据驱动的洞察，但研究人员面临技术专业知识缺乏、数据格式不一致、可靠数据集获取有限等障碍，特别是非政府组织、学生和基层组织难以应用先进数据科学实践

Method: 开发专门为跨学科社会科学研究定制的数据湖基础设施，支持多种数据类型的摄取和集成，自动进行来源和版本跟踪，实施基于角色的访问控制，并内置可视化和分析工具

Result: 通过治理、健康和教育等实际用例展示了该数据湖的实用性，详细演示了收入、教育和婴儿死亡率关系分析的案例，证明平台能简化研究流程同时保持透明度和可重复性

Conclusion: 此类基础设施可以民主化先进数据科学实践的访问，特别是对非政府组织、学生和基层组织，平台计划继续发展以支持机器学习管道、移动访问和公民数据反馈机制

Abstract: Social science research increasingly demands data-driven insights, yet researchers often face barriers such as lack of technical expertise, inconsistent data formats, and limited access to reliable datasets.Social science research increasingly demands data-driven insights, yet researchers often face barriers such as lack of technical expertise, inconsistent data formats, and limited access to reliable datasets. In this paper, we present a Datalake infrastructure tailored to the needs of interdisciplinary social science research. Our system supports ingestion and integration of diverse data types, automatic provenance and version tracking, role-based access control, and built-in tools for visualization and analysis. We demonstrate the utility of our Datalake using real-world use cases spanning governance, health, and education. A detailed walkthrough of one such use case -- analyzing the relationship between income, education, and infant mortality -- shows how our platform streamlines the research process while maintaining transparency and reproducibility. We argue that such infrastructure can democratize access to advanced data science practices, especially for NGOs, students, and grassroots organizations. The Datalake continues to evolve with plans to support ML pipelines, mobile access, and citizen data feedback mechanisms.

</details>


### [12] [Stress-Testing Causal Claims via Cardinality Repairs](https://arxiv.org/abs/2512.02491)
*Yarden Gabbay,Haoquan Guan,Shaull Almagor,El Kindi Rezig,Brit Youngmann,Babak Salimi*

Main category: cs.DB

TL;DR: SubCure框架通过基数修复进行因果分析鲁棒性审计，识别少量数据子集（元组或子群体）的移除如何显著改变因果结论，揭示传统方法无法检测的脆弱性。


<details>
  <summary>Details</summary>
Motivation: 观察数据中的因果分析支撑着医疗、公共政策和经济等高风险决策，但这些结论可能出奇地脆弱：即使是轻微的数据错误（重复记录或录入错误）也可能极大地改变因果关系。这引发了一个基本问题：因果主张对数据的小规模、针对性修改有多鲁棒？解决这个问题对于确保实证发现的可信性、可解释性和可复现性至关重要。

Method: 提出SubCure框架，通过基数修复进行鲁棒性审计。给定因果查询和用户指定的效应估计目标范围，SubCure识别少量元组或子群体，其移除能将估计值调整到期望范围。该框架在元组级和模式级删除设置下形式化该问题，证明两者都是NP完全问题。为扩展到大型数据集，开发了结合机器学习遗忘技术的高效算法，无需从头重新训练即可增量更新因果估计。

Result: 在四个真实世界数据集上进行评估，涵盖不同应用领域。在每个案例中，SubCure都发现了紧凑、高影响力的子集，其移除显著改变了因果结论，揭示了传统方法无法检测的脆弱性。结果表明基数修复是压力测试因果分析和防范基于普通数据缺陷的误导性主张的强大通用工具。

Conclusion: 基数修复是压力测试因果分析和防范基于普通数据缺陷的误导性主张的强大通用工具。SubCure框架不仅量化了因果结论的敏感性，还精确定位了驱动这些结论的具体数据区域，为因果分析的鲁棒性审计提供了系统方法。

Abstract: Causal analyses derived from observational data underpin high-stakes decisions in domains such as healthcare, public policy, and economics. Yet such conclusions can be surprisingly fragile: even minor data errors - duplicate records, or entry mistakes - may drastically alter causal relationships. This raises a fundamental question: how robust is a causal claim to small, targeted modifications in the data? Addressing this question is essential for ensuring the reliability, interpretability, and reproducibility of empirical findings. We introduce SubCure, a framework for robustness auditing via cardinality repairs. Given a causal query and a user-specified target range for the estimated effect, SubCure identifies a small set of tuples or subpopulations whose removal shifts the estimate into the desired range. This process not only quantifies the sensitivity of causal conclusions but also pinpoints the specific regions of the data that drive those conclusions. We formalize this problem under both tuple- and pattern-level deletion settings and show both are NP-complete. To scale to large datasets, we develop efficient algorithms that incorporate machine unlearning techniques to incrementally update causal estimates without retraining from scratch. We evaluate SubCure across four real-world datasets covering diverse application domains. In each case, it uncovers compact, high-impact subsets whose removal significantly shifts the causal conclusions, revealing vulnerabilities that traditional methods fail to detect. Our results demonstrate that cardinality repair is a powerful and general-purpose tool for stress-testing causal analyses and guarding against misleading claims rooted in ordinary data imperfections.

</details>


### [13] [PystachIO: Efficient Distributed GPU Query Processing with PyTorch over Fast Networks & Fast Storage](https://arxiv.org/abs/2512.02862)
*Jigao Luo,Nils Boeschen,Muhammad El-Hindi,Carsten Binnig*

Main category: cs.DB

TL;DR: PystachIO：基于PyTorch的分布式OLAP引擎，通过优化GPU、网络和存储I/O的重叠，实现存储驻留大规模OLAP工作负载的高效处理


<details>
  <summary>Details</summary>
Motivation: 现代数据中心采用GPU为中心的HPC架构，Tensor计算运行时（如PyTorch）已证明能加速分析工作负载，但现有研究主要关注数据能放入GPU内存的情况。需要系统研究如何支持大规模、存储驻留的OLAP工作负载的分布式查询处理。

Method: 提出PystachIO，一个基于PyTorch的分布式OLAP引擎，结合快速网络和存储I/O，通过关键优化最大化GPU、网络和存储的利用率，解决计算与数据移动之间重叠不足的问题。

Result: 评估显示，相比现有的分布式GPU查询处理方法，PystachIO实现了高达3倍的端到端加速。

Conclusion: PystachIO成功展示了Tensor计算运行时可以有效支持大规模、存储驻留的OLAP工作负载的分布式查询处理，通过优化I/O与计算的重叠显著提升性能。

Abstract: The AI hardware boom has led modern data centers to adopt HPC-style architectures centered on distributed, GPU-centric computation. Large GPU clusters interconnected by fast RDMA networks and backed by high-bandwidth NVMe storage enable scalable computation and rapid access to storage-resident data. Tensor computation runtimes (TCRs), such as PyTorch, originally designed for AI workloads, have recently been shown to accelerate analytical workloads. However, prior work has primarily considered settings where the data fits in aggregated GPU memory. In this paper, we systematically study how TCRs can support scalable, distributed query processing for large-scale, storage-resident OLAP workloads. Although TCRs provide abstractions for network and storage I/O, naive use often underutilizes GPU and I/O bandwidth due to insufficient overlap between computation and data movement. As a core contribution, we present PystachIO, a PyTorch-based distributed OLAP engine that combines fast network and storage I/O with key optimizations to maximize GPU, network, and storage utilization. Our evaluation shows up to 3x end-to-end speedups over existing distributed GPU-based query processing approaches.

</details>


### [14] [From Administrative Chaos to Analytical Cohorts: A Three-Stage Normalisation Pipeline for Longitudinal University Administrative Records](https://arxiv.org/abs/2512.02936)
*H. R. Paz*

Main category: cs.DB

TL;DR: 提出三階段正規化流程處理大學行政數據，解決原始不一致數據問題，保留100%學生數據，實現完全地理編碼，並識別結構性缺失數據模式。


<details>
  <summary>Details</summary>
Motivation: 大學行政記錄在數據驅動決策中日益重要，但原始不一致數據的正規化過程常被忽視，特別是在拉丁美洲高等教育環境中，存在重複標識符、地理信息不一致和學校類型分類問題。

Method: 三階段正規化流程：N1 CENSAL（人口統計數據統一）、N1b IDENTITY RESOLUTION（重複標識符合併）、N1c GEO and SECONDARY-SCHOOL NORMALISATION（地理編碼和學校類型分類），並使用卡方檢驗和邏輯回歸進行法證分析。

Result: 保留100%學生數據，實現完全地理編碼，56.6%人口獲得有效學校類型分類，43.4%被識別為結構性缺失。缺失模式與入學年代和地理因素高度相關，證實為歷史誘導的結構性機制。

Conclusion: 提供高等教育專用的透明可重現正規化流程，建立處理結構性缺失信息的框架（避免推測性插補），並指導定義分析一致的群組，支持學習分析和政策評估。

Abstract: The growing use of longitudinal university administrative records in data-driven decision-making often overlooks a critical layer: how raw, inconsistent data are normalised before modelling. This article presents a three-stage normalisation pipeline for a dataset of 24,133 engineering students at a Latin American public university, spanning four decades (1980-2019). The pipeline comprises: (i) N1 CENSAL, harmonising demographics into a single person-level layer; (ii) N1b IDENTITY RESOLUTION, consolidating duplicate identifiers into a canonical ID while preserving an audit trail; and (iii) N1c GEO and SECONDARY-SCHOOL NORMALISATION, which builds reference tables, classifies school types (state national, state provincial, private secular, private religious), and flags irrecoverable cases as DATA_MISSING. The pipeline preserves 100% of students, achieves full geocoding, and yields valid school types for 56.6% of the population. The remaining 43.4% are identified as structurally missing due to legacy enrolment practices rather than stochastic non-response. Forensic analysis (chi-square, logistic regression) shows missingness is highly predictable from entry decade and geography, confirming a structural, historically induced mechanism. The article contributes: (a) a transparent, reproducible normalisation pipeline tailored to higher education; (b) a framework for treating structurally missing information without speculative imputation; and (c) guidance on defining analytically coherent cohorts (full population vs. secondary-school-informed subcohorts) for downstream learning analytics and policy evaluation.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [15] [Bin2Vec: Interpretable and Auditable Multi-View Binary Analysis for Code Plagiarism Detection](https://arxiv.org/abs/2512.02197)
*Moussa Moussaoui,Tarik Houichime,Abdelalim Sadiq*

Main category: cs.SE

TL;DR: Bin2Vec是一个结合程序静态特征（函数、导入导出）和动态行为（指令、内存使用）的软件相似性分析框架，提供可解释的可视化视图和总体相似度评分。


<details>
  <summary>Details</summary>
Motivation: 现有软件相似性分析方法通常只关注单一类型信息（静态或动态），无法提供全面、可解释的程序比较结果。需要一种能结合多种信息源并提供人类可理解的相似性分析框架。

Method: Bin2Vec将程序的不同信息类型（内置函数、导入导出、指令、内存使用）表示为可单独检查的视图，通过易于阅读的图表可视化，然后整合为总体相似度评分。该框架作为二进制表示和机器学习技术之间的桥梁，生成机器学习模型可高效处理的特征表示。

Result: 在PuTTY和7-Zip的多个版本上进行测试，结果显示该方法能计算最优且可视化友好的软件表示。PuTTY版本显示更复杂的行为和内存活动，而7-Zip版本更关注性能相关模式。方法提供可靠且人类可解释的决策。

Conclusion: Bin2Vec提供可靠且可解释的软件相似性分析，其模块化和易扩展性使其适用于审计、软件来源验证、网络安全和逆向工程中的大规模程序筛查等任务。

Abstract: We introduce Bin2Vec, a new framework that helps compare software programs in a clear and explainable way. Instead of focusing only on one type of information, Bin2Vec combines what a program looks like (its built-in functions, imports, and exports) with how it behaves when it runs (its instructions and memory usage). This gives a more complete picture when deciding whether two programs are similar or not. Bin2Vec represents these different types of information as views that can be inspected separately using easy-to-read charts, and then brings them together into an overall similarity score. Bin2Vec acts as a bridge between binary representations and machine learning techniques by generating feature representations that can be efficiently processed by machine-learning models. We tested Bin2Vec on multiple versions of two well-known Windows programs, PuTTY and 7-Zip. The primary results strongly confirmed that our method compute an optimal and visualization-friendly representation of the analyzed software. For example, PuTTY versions showed more complex behavior and memory activity, while 7-Zip versions focused more on performance-related patterns. Overall, Bin2Vec provides decisions that are both reliable and explainable to humans. Because it is modular and easy to extend, it can be applied to tasks like auditing, verifying software origins, or quickly screening large numbers of programs in cybersecurity and reverse-engineering work.

</details>


### [16] [Towards autonomous normative multi-agent systems for Human-AI software engineering teams](https://arxiv.org/abs/2512.02329)
*Hoa Khanh Dam,Geeta Mahala,Rashina Hoda,Xi Zheng,Cristina Conati*

Main category: cs.SE

TL;DR: 论文提出了一种由AI驱动的软件工程新范式，其中基于大语言模型的自主智能体成为软件开发的核心驱动力，通过与人类和其他智能体协作，实现远超当前开发流程的速度、可靠性和适应性。


<details>
  <summary>Details</summary>
Motivation: 当前软件工程面临效率、可靠性和适应性方面的挑战，需要一种能够与人类协作、具备自主决策能力的AI驱动范式来变革软件开发过程。

Method: 引入基于大语言模型的软件工程智能体，赋予其信念、欲望、意图和记忆以实现类人推理能力，并通过道义模态（承诺、义务、禁止和许可）规范智能体间的协调与协作。

Result: 建立了一个可扩展、透明且可信赖的人机软件工程团队框架，使智能体能够与人类协作完成软件设计、实现、测试和部署等核心开发活动。

Conclusion: 该研究为未来人机协作的软件工程团队提供了理论基础和技术框架，有望实现软件开发过程的根本性变革，大幅提升开发效率和质量。

Abstract: This paper envisions a transformative paradigm in software engineering, where Artificial Intelligence, embodied in fully autonomous agents, becomes the primary driver of the core software development activities. We introduce a new class of software engineering agents, empowered by Large Language Models and equipped with beliefs, desires, intentions, and memory to enable human-like reasoning. These agents collaborate with humans and other agents to design, implement, test, and deploy software systems with a level of speed, reliability, and adaptability far beyond the current software development processes. Their coordination and collaboration are governed by norms expressed as deontic modalities - commitments, obligations, prohibitions and permissions - that regulate interactions and ensure regulatory compliance. These innovations establish a scalable, transparent and trustworthy framework for future Human-AI software engineering teams.

</details>


### [17] [Process-Centric Analysis of Agentic Software Systems](https://arxiv.org/abs/2512.02393)
*Shuyang Liu,Yang Chen,Rahul Krishna,Saurabh Sinha,Jatin Ganhotra,Reyhan Jabbarvand*

Main category: cs.SE

TL;DR: 论文提出Graphectory框架，将智能体系统的执行轨迹编码为图结构，以进行过程中心化的评估分析，超越传统结果导向的评估方法。


<details>
  <summary>Details</summary>
Motivation: 当前对智能体系统的评估过于结果导向，只关注最终成功或失败，忽略了智能体推理、规划、行动和策略演变的详细过程。需要一种系统方法来分析智能体工作流的执行轨迹。

Method: 提出Graphectory框架，将智能体系统的执行轨迹编码为包含时间和语义关系的图结构。使用该框架分析4000个轨迹，涉及SWE-agent和OpenHands两种智能体编程工作流，结合四种LLM骨干模型，解决SWE-bench Verified问题。

Result: 分析发现：(1) 使用更丰富提示或更强LLM的智能体表现出更复杂的Graphectory，反映更深入的探索、更广泛的上下文收集和更彻底的验证；(2) 问题解决策略随问题难度和底层LLM变化，已解决问题遵循连贯的定位-修补-验证步骤，未解决问题表现出混乱、重复或回溯行为；(3) 即使成功，智能体编程系统也常显示低效过程，导致不必要的冗长轨迹。

Conclusion: Graphectory提供了一种系统方法来分析智能体系统的执行过程，揭示了传统结果导向评估无法捕捉的洞察，有助于评估和优化智能体工作流的质量和效率。

Abstract: Agentic systems are modern software systems: they consist of orchestrated modules, expose interfaces, and are deployed in software pipelines. Unlike conventional programs, their execution (i.e., trajectories) is inherently stochastic and adaptive to the problem they are solving. Evaluation of such systems is often outcome-centric, judging their performance based on success or failure at the final step. This narrow focus overlooks detailed insights about such systems, failing to explain how agents reason, plan, act, or change their strategies over time. Inspired by the structured representation of conventional software systems as graphs, we introduce Graphectory to systematically encode the temporal and semantic relations in such software systems. Graphectory facilitates the design of process-centric metrics and analyses to assess the quality of agentic workflows independent of final success.
  Using Graphectory, we analyze 4000 trajectories of two dominant agentic programming workflows, namely SWE-agent and OpenHands, with a combination of four backbone Large Language Models (LLMs), attempting to resolve SWE-bench Verified issues. Our fully automated analyses reveal that: (1) agents using richer prompts or stronger LLMs exhibit more complex Graphectory, reflecting deeper exploration, broader context gathering, and more thorough validation before patch submission; (2) agents' problem-solving strategies vary with both problem difficulty and the underlying LLM -- for resolved issues, the strategies often follow coherent localization-patching-validation steps, while unresolved ones exhibit chaotic, repetitive, or backtracking behaviors; (3) even when successful, agentic programming systems often display inefficient processes, leading to unnecessarily prolonged trajectories.

</details>


### [18] [Feedback Loops and Code Perturbations in LLM-based Software Engineering: A Case Study on a C-to-Rust Translation System](https://arxiv.org/abs/2512.02567)
*Martin Weiss,Jesko Hecking-Harbusch,Jochen Quante,Matthias Woehrle*

Main category: cs.SE

TL;DR: 研究探讨了自动化C到Rust代码翻译系统中三个关键因素对质量的影响：自动反馈循环、大语言模型选择和代码扰动，发现反馈循环能显著缩小不同模型间的性能差异。


<details>
  <summary>Details</summary>
Motivation: 随着强生成式AI在软件工程任务中的广泛应用，工业实践需要更高可靠性的自动化方法。本研究关注影响代码翻译质量的三个关键因素：自动反馈循环、大语言模型选择和代码扰动的影响。

Method: 基于生成-检查模式构建自动化C到Rust翻译系统，LLM生成Rust代码后自动检查可编译性和行为等价性。对于失败检查，通过反馈循环重新提示LLM修复输出。通过改变三个变量（反馈循环、LLM选择、代码扰动）来评估系统成功率。

Result: 无反馈循环时，LLM选择对翻译成功率影响很大；但当系统使用反馈循环时，不同模型间的差异显著减小。代码扰动提供的多样性甚至能改善系统性能，同时观察到系统在代码扰动下的鲁棒性表现。

Conclusion: 自动反馈循环是提升代码翻译系统可靠性的关键因素，能有效缩小不同LLM间的性能差异。代码扰动不仅能增强系统鲁棒性，还能通过多样性提升性能。这些发现对工业实践中构建可靠的AI驱动代码翻译系统具有重要意义。

Abstract: The advent of strong generative AI has a considerable impact on various software engineering tasks such as code repair, test generation, or language translation. While tools like GitHub Copilot are already in widespread use in interactive settings, automated approaches require a higher level of reliability before being usable in industrial practice. In this paper, we focus on three aspects that directly influence the quality of the results: a) the effect of automated feedback loops, b) the choice of Large Language Model (LLM), and c) the influence of behavior-preserving code changes.
  We study the effect of these three variables on an automated C-to-Rust translation system. Code translation from C to Rust is an attractive use case in industry due to Rust's safety guarantees. The translation system is based on a generate-and-check pattern, in which Rust code generated by the LLM is automatically checked for compilability and behavioral equivalence with the original C code. For negative checking results, the LLM is re-prompted in a feedback loop to repair its output. These checks also allow us to evaluate and compare the respective success rates of the translation system when varying the three variables.
  Our results show that without feedback loops LLM selection has a large effect on translation success. However, when the translation system uses feedback loops the differences across models diminish. We observe this for the average performance of the system as well as its robustness under code perturbations. Finally, we also identify that diversity provided by code perturbations can even result in improved system performance.

</details>


### [19] [Empirical Assessment of the Perception of Software Product Line Engineering by an SME before Migrating its Code Base](https://arxiv.org/abs/2512.02707)
*Thomas Georges,Marianne Huchard,Mélanie König,Clémentine Nebut,Chouki Tibermacine*

Main category: cs.SE

TL;DR: 该研究通过与一家中小型企业合作，评估了将现有代码库迁移到软件产品线(SPL)的过程，通过访谈关键利益相关者分析迁移的益处、风险及变革阻力。


<details>
  <summary>Details</summary>
Motivation: 软件产品线工程虽然能带来显著效益，但迁移过程成本高昂且具有挑战性，会显著影响公司的开发流程和开发者实践。研究通过与一家决定进行SPL迁移的中小型企业合作，旨在深入了解现有开发流程、迁移的预期效益和风险。

Method: 采用定性研究方法，对参与软件开发的关键利益相关者进行深入访谈，评估公司当前的开发流程和实践，以及迁移的预期效益和风险。研究设计了专门的访谈方案，收集利益相关者对迁移的看法和可能的变革阻力。

Result: 研究发现所有参与者，无论其在开发过程中的角色如何，都识别出了与其自身活动相关的迁移益处。研究还表明，有效的风险缓解策略包括：在整个过程中保持利益相关者的知情和参与，尽可能保留良好实践，并积极让他们参与迁移过程以确保平稳过渡并最小化潜在挑战。

Conclusion: 软件产品线迁移的成功不仅取决于技术因素，更关键的是人员和组织因素。通过让利益相关者充分参与、保持良好实践并确保透明沟通，可以显著降低迁移风险并提高成功率。该研究为其他企业进行类似迁移提供了有价值的实践指导。

Abstract: Migrating a set of software variants into a software product line (SPL) is an expensive and potentially challenging endeavor. Indeed, SPL engineering can significantly impact a company's development process and often requires changes to established developer practices. The work presented in this paper stems from a collaboration with a Small and Medium-sized Enterprise (SME) that decided to migrate its existing code base into an SPL. In this study, we conducted an in-depth evaluation of the company's current development processes and practices, as well as the anticipated benefits and risks associated with the migration. Key stakeholders involved in software development participated in this evaluation to provide insight into their perceptions of the migration and their potential resistance to change. This paper describes the design of the interviews conducted with these stakeholders and presents an analysis of the results. Among the qualitative findings, we observed that all participants, regardless of their role in the development process, identified benefits of the migration relevant to their own activities. Furthermore, our results suggest that an effective risk mitigation strategy involves keeping stakeholders informed and engaged throughout the process, preserving as many good practices as possible, and actively involving them in the migration to ensure a smooth transition and minimize potential challenges.

</details>


### [20] [Integrative Analysis of Risk Management Methodologies in Data Science Projects](https://arxiv.org/abs/2512.02728)
*Sabrina Delmondes da Costa Feitosa*

Main category: cs.SE

TL;DR: 本文通过文献综述比较了数据科学项目中的风险管理方法，发现传统方法对新兴风险覆盖有限，而现代模型能整合伦理监督和持续监控，为开发平衡技术效率与负责任数据实践的混合框架提供理论支持。


<details>
  <summary>Details</summary>
Motivation: 数据科学项目失败率高，主要由于技术限制、组织局限和风险管理不足。现有挑战包括数据成熟度低、缺乏治理、技术与业务团队错位，以及缺乏解决伦理和社会技术风险的结构化机制。本研究旨在比较数据科学项目的主要风险管理方法，识别、分类和综合其异同与差距。

Method: 采用整合性文献综述方法，使用索引数据库和结构化协议进行文献筛选与内容分析。研究分析了广泛采用的风险管理标准（ISO 31000、PMBOK风险管理、NIST RMF）以及数据科学工作流特定框架（如CRISP DM和最近提出的DS EthiCo RMF）。

Result: 研究发现传统方法对新兴风险覆盖有限，而当代模型提出了能够整合伦理监督、治理和持续监控的多维结构。DS EthiCo RMF等框架将伦理和社会技术维度纳入项目生命周期。

Conclusion: 本研究为开发平衡技术效率、组织对齐和负责任数据实践的混合框架提供了理论支持，同时指出了可指导未来研究的研究空白。强调需要整合传统风险管理与新兴伦理维度的综合方法。

Abstract: Data science initiatives frequently exhibit high failure rates, driven by technical constraints, organizational limitations and insufficient risk management practices. Challenges such as low data maturity, lack of governance, misalignment between technical and business teams, and the absence of structured mechanisms to address ethical and sociotechnical risks have been widely identified in the literature. In this context, the purpose of this study is to conduct a comparative analysis of the main risk management methodologies applied to data science projects, aiming to identify, classify, and synthesize their similarities, differences and existing gaps. An integrative literature review was performed using indexed databases and a structured protocol for selection and content analysis. The study examines widely adopted risk management standards ISO 31000, PMBOK Risk Management and NIST RMF, as well as frameworks specific to data science workflows, such as CRISP DM and the recently proposed DS EthiCo RMF, which incorporates ethical and sociotechnical dimensions into the project life cycle. The findings reveal that traditional approaches provide limited coverage of emerging risks, whereas contemporary models propose multidimensional structures capable of integrating ethical oversight, governance and continuous monitoring. As a contribution, this work offers theoretical support for the development of hybrid frameworks that balance technical efficiency, organizational alignment and responsible data practices, while highlighting research gaps that can guide future investigations.

</details>


### [21] ["Can you feel the vibes?": An exploration of novice programmer engagement with vibe coding](https://arxiv.org/abs/2512.02750)
*Kiev Gama,Filipe Calegario,Victoria Jackson,Alexander Nolte,Luiz Augusto Morais,Vinicius Garcia*

Main category: cs.SE

TL;DR: 论文研究"氛围编程"在教育中的应用，通过巴西大学一日黑客松活动，探索新手程序员和混合经验团队如何利用自然语言提示进行软件开发，发现其能促进快速原型设计和跨学科协作，但也存在创意过早收敛、代码质量不均等问题。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI和AI辅助编码的兴起，"氛围编程"（通过自然语言提示而非直接编写代码来创建软件）有望民主化软件开发，但其教育意义尚未得到充分探索。本研究旨在调查新手程序员和混合经验团队如何参与氛围编程。

Method: 在巴西公立大学组织为期一日的教育黑客松活动，招募31名来自计算和非计算学科的本科生参与者，分为9个团队。通过观察、退出调查和半结构化访谈，研究创意过程、工具使用模式、协作动态和学习成果。

Result: 研究发现氛围编程能够实现快速原型设计和跨学科协作，参与者培养了提示工程技能并在时间限制内交付了功能演示。但也观察到创意过早收敛、代码质量不均需要返工、对核心软件工程实践参与有限等问题。团队采用了结合多种AI工具的复杂工作流程，人类判断在关键改进中仍然至关重要。

Conclusion: 氛围编程黑客松可以作为有价值的低风险学习环境，但需要配合明确的支架支持发散思维、批判性评估AI输出，以及对生产质量有现实期望。短期形式（9小时）对建立新手的信心有效，同时适应了时间有限的参与者。

Abstract: Emerging alongside generative AI and the broader trend of AI-assisted coding, the term "vibe coding" refers to creating software via natural language prompts rather than direct code authorship. This approach promises to democratize software development, but its educational implications remain underexplored. This paper reports on a one-day educational hackathon investigating how novice programmers and mixed-experience teams engage with vibe coding. We organized an inclusive event at a Brazilian public university with 31 undergraduate participants from computing and non-computing disciplines, divided into nine teams. Through observations, an exit survey, and semi-structured interviews, we examined creative processes, tool usage patterns, collaboration dynamics, and learning outcomes. Findings reveal that vibe coding enabled rapid prototyping and cross-disciplinary collaboration, with participants developing prompt engineering skills and delivering functional demonstrations within time constraints. However, we observed premature convergence in ideation, uneven code quality requiring rework, and limited engagement with core software engineering practices. Teams adopted sophisticated workflows combining multiple AI tools in pipeline configurations, with human judgment remaining essential for critical refinement. The short format (9 hours) proved effective for confidence-building among newcomers while accommodating participants with limited availability. We conclude that vibe coding hackathons can serve as valuable low-stakes learning environments when coupled with explicit scaffolds for divergent thinking, critical evaluation of AI outputs, and realistic expectations about production quality.

</details>


### [22] [Towards Observation Lakehouses: Living, Interactive Archives of Software Behavior](https://arxiv.org/abs/2512.02795)
*Marcus Kessel*

Main category: cs.SE

TL;DR: 提出观察数据湖屋架构，用于持续收集、存储和分析代码执行行为数据，支持行为感知的评估和训练


<details>
  <summary>Details</summary>
Motivation: 当前代码生成LLM主要基于静态代码训练，缺乏运行时行为数据，容易学习到有bug的代码。需要动态观察执行来获取真实功能，但现有方法缺乏持久化、演化和大规模交互分析能力

Method: 构建基于Apache Parquet + Iceberg + DuckDB的观察数据湖屋，采用高维追加式观察表存储所有执行记录（刺激、响应、上下文），通过SQL查询按需生成SRC切片视图

Result: 在509个问题的基准测试中，摄入了约860万行观察数据（<51MiB），在笔记本电脑上能在<100ms内重建SRM/SRC视图和聚类，证明无需分布式集群即可实现持续行为挖掘

Conclusion: 观察数据湖屋使行为真实数据成为一等公民，为行为感知的评估和训练提供了基础设施路径，相关代码和数据集已在GitHub开源

Abstract: Code-generating LLMs are trained largely on static artifacts (source, comments, specifications) and rarely on materializations of run-time behavior. As a result, they readily internalize buggy or mislabeled code. Since non-trivial semantic properties are undecidable in general, the only practical way to obtain ground-truth functionality is by dynamic observation of executions. In prior work, we addressed representation with Sequence Sheets, Stimulus-Response Matrices (SRMs), and Stimulus-Response Cubes (SRCs) to capture and compare behavior across tests, implementations, and contexts. These structures make observation data analyzable offline and reusable, but they do not by themselves provide persistence, evolution, or interactive analytics at scale. In this paper, therefore, we introduce observation lakehouses that operationalize continual SRCs: a tall, append-only observations table storing every actuation (stimulus, response, context) and SQL queries that materialize SRC slices on demand. Built on Apache Parquet + Iceberg + DuckDB, the lakehouse ingests data from controlled pipelines (LASSO) and CI pipelines (e.g., unit test executions), enabling n-version assessment, behavioral clustering, and consensus oracles without re-execution. On a 509-problem benchmark, we ingest $\approx$8.6M observation rows ($<$51MiB) and reconstruct SRM/SRC views and clusters in $<$100ms on a laptop, demonstrating that continual behavior mining is practical without a distributed cluster of machines. This makes behavioral ground truth first-class alongside other run-time data and provides an infrastructure path toward behavior-aware evaluation and training. The Observation Lakehouse, together with the accompanying dataset, is publicly available as an open-source project on GitHub: https://github.com/SoftwareObservatorium/observation-lakehouse

</details>


### [23] [Model-Based Diagnosis with Multiple Observations: A Unified Approach for C Software and Boolean Circuits](https://arxiv.org/abs/2512.02898)
*Pedro Orvalho,Marta Kwiatkowska,Mikoláš Janota,Vasco Manquinho*

Main category: cs.SE

TL;DR: CFaults 是一个基于模型诊断的多故障定位工具，通过将多个失败测试用例聚合到统一的MaxSAT公式中，保证诊断结果的一致性并生成子集最小化诊断。


<details>
  <summary>Details</summary>
Motivation: 现有基于公式的故障定位方法存在两个主要问题：1) 无法保证在所有失败测试中都能找到诊断结果；2) 可能产生非子集最小化的冗余诊断，特别是在多故障场景下。这些问题使得调试过程效率低下。

Method: CFaults 采用基于模型诊断方法，将多个失败测试用例聚合到一个统一的最大可满足性公式中。这种方法保证了诊断结果在所有观察中的一致性，并简化了故障定位过程。

Result: 在C程序基准测试集（TCAS和C-Pack-IPAs）上，CFaults比BugAssist、SNIPER和HSD等其他方法更快。在ISCAS85布尔电路基准测试中，虽然速度比HSD慢，但能在仅少6%的电路中定位故障，表现依然有竞争力。此外，CFaults只生成子集最小化的诊断，而其他方法会产生冗余诊断。

Conclusion: CFaults 是一个有效的多故障定位工具，能够保证诊断一致性并生成最小化诊断，在C软件和布尔电路故障定位中表现出色，特别是在处理多故障场景时具有优势。

Abstract: Debugging is one of the most time-consuming and expensive tasks in software development and circuit design. Several formula-based fault localisation (FBFL) methods have been proposed, but they fail to guarantee a set of diagnoses across all failing tests or may produce redundant diagnoses that are not subset-minimal, particularly for programs/circuits with multiple faults.
  This paper introduces CFaults, a novel fault localisation tool for C software and Boolean circuits with multiple faults. CFaults leverages Model-Based Diagnosis (MBD) with multiple observations and aggregates all failing test cases into a unified Maximum Satisfiability (MaxSAT) formula. Consequently, our method guarantees consistency across observations and simplifies the fault localisation procedure. Experimental results on three benchmark sets, two of C programs, TCAS and C-Pack-IPAs, and one of Boolean circuits, ISCAS85, show that CFaults is faster at localising faults in C software than other FBFL approaches such as BugAssist, SNIPER, and HSD. On the ISCAS85 benchmark, CFaults is generally slower than HSD; however, it localises faults in only 6% fewer circuits, demonstrating that it remains competitive in this domain. Furthermore, CFaults produces only subset-minimal diagnoses of faulty statements, whereas the other approaches tend to enumerate redundant diagnoses (e.g., BugAssist and SNIPER).

</details>


### [24] [The Evolutionary Ecology of Software: Constraints, Innovation, and the AI Disruption](https://arxiv.org/abs/2512.02953)
*Sergi Valverde,Blai Vidiella,Salva Duran-Nebreda*

Main category: cs.SE

TL;DR: 该研究从进化生态学视角分析软件的演化，探讨软件与创新之间的共生关系，特别关注AI驱动开发工具对软件生态系统多样性的影响。


<details>
  <summary>Details</summary>
Motivation: 研究动机是理解软件作为社会技术系统的复杂演化轨迹，探索约束、修补和频率依赖选择之间的相互作用如何驱动软件进化，以及AI工具如何改变软件创新生态。

Method: 采用基于主体的建模和案例研究相结合的方法，运用复杂网络分析和进化理论，研究编程语言的演化及其对开发者实践的影响。

Result: 研究发现技术制品与社会规范、文化动态和人类互动共同演化，AI驱动的开发工具虽然提供前所未有的信息获取途径，但也可能带来文化停滞风险，类似于过去软件生态系统的多样性衰退。

Conclusion: 理解AI介导的软件生产引入的进化压力对于预测文化变革模式、技术适应性和软件创新未来至关重要，需要关注AI工具对软件生态系统多样性的潜在负面影响。

Abstract: This chapter investigates the evolutionary ecology of software, focusing on the symbiotic relationship between software and innovation. An interplay between constraints, tinkering, and frequency-dependent selection drives the complex evolutionary trajectories of these socio-technological systems. Our approach integrates agent-based modeling and case studies, drawing on complex network analysis and evolutionary theory to explore how software evolves under the competing forces of novelty generation and imitation. By examining the evolution of programming languages and their impact on developer practices, we illustrate how technological artifacts co-evolve with and shape societal norms, cultural dynamics, and human interactions. This ecological perspective also informs our analysis of the emerging role of AI-driven development tools in software evolution. While large language models (LLMs) provide unprecedented access to information, their widespread adoption introduces new evolutionary pressures that may contribute to cultural stagnation, much like the decline of diversity in past software ecosystems. Understanding the evolutionary pressures introduced by AI-mediated software production is critical for anticipating broader patterns of cultural change, technological adaptation, and the future of software innovation.

</details>
