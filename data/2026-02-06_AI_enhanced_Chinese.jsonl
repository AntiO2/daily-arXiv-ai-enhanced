{"id": "2602.05017", "categories": ["cs.DC", "q-bio.CB"], "pdf": "https://arxiv.org/pdf/2602.05017", "abs": "https://arxiv.org/abs/2602.05017", "authors": ["Jose-Luis Estragues-Mu\u00f1oz", "Carlos Alvarez", "Arnau Montagud", "Daniel Jimenez-Gonzalez", "Alfonso Valencia"], "title": "A novel scalable high performance diffusion solver for multiscale cell simulations", "comment": "14 pages, 9 figures", "summary": "Agent-based cellular models simulate tissue evolution by capturing the behavior of individual cells, their interactions with neighboring cells, and their responses to the surrounding microenvironment. An important challenge in the field is scaling cellular resolution models to real-scale tumor simulations, which is critical for the development of digital twin models of diseases and requires the use of High-Performance Computing (HPC) since every time step involves trillions of operations. We hereby present a scalable HPC solution for the molecular diffusion modeling using an efficient implementation of state-of-the-art Finite Volume Method (FVM) frameworks. The paper systematically evaluates a novel scalable Biological Finite Volume Method (BioFVM) library and presents an extensive performance analysis of the available solutions. Results shows that our HPC proposal reach almost 200x speedup and up to 36% reduction in memory usage over the current state-of-the-art solutions, paving the way to efficiently compute the next generation of biological problems.", "AI": {"tldr": "\u63d0\u51fa\u53ef\u6269\u5c55\u7684HPC\u89e3\u51b3\u65b9\u6848BioFVM\u5e93\uff0c\u7528\u4e8e\u5206\u5b50\u6269\u6563\u5efa\u6a21\uff0c\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u5b9e\u73b0200\u500d\u52a0\u901f\u548c36%\u5185\u5b58\u51cf\u5c11", "motivation": "\u57fa\u4e8e\u4ee3\u7406\u7684\u7ec6\u80de\u6a21\u578b\u5728\u6a21\u62df\u7ec4\u7ec7\u6f14\u5316\u65f6\u9700\u8981\u5904\u7406\u4e2a\u4f53\u7ec6\u80de\u884c\u4e3a\u3001\u7ec6\u80de\u95f4\u76f8\u4e92\u4f5c\u7528\u548c\u5fae\u73af\u5883\u54cd\u5e94\u3002\u5173\u952e\u6311\u6218\u662f\u5c06\u7ec6\u80de\u5206\u8fa8\u7387\u6a21\u578b\u6269\u5c55\u5230\u771f\u5b9e\u89c4\u6a21\u7684\u80bf\u7624\u6a21\u62df\uff0c\u8fd9\u5bf9\u75be\u75c5\u6570\u5b57\u5b6a\u751f\u6a21\u578b\u5f00\u53d1\u81f3\u5173\u91cd\u8981\uff0c\u9700\u8981\u5229\u7528\u9ad8\u6027\u80fd\u8ba1\u7b97\u5904\u7406\u4e07\u4ebf\u7ea7\u64cd\u4f5c\u3002", "method": "\u63d0\u51fa\u53ef\u6269\u5c55\u7684HPC\u89e3\u51b3\u65b9\u6848\uff0c\u91c7\u7528\u9ad8\u6548\u5b9e\u73b0\u7684\u6700\u5148\u8fdb\u6709\u9650\u4f53\u79ef\u6cd5\u6846\u67b6\uff0c\u7cfb\u7edf\u8bc4\u4f30\u65b0\u578b\u53ef\u6269\u5c55\u751f\u7269\u6709\u9650\u4f53\u79ef\u6cd5\u5e93\uff0c\u5e76\u5bf9\u53ef\u7528\u89e3\u51b3\u65b9\u6848\u8fdb\u884c\u5e7f\u6cdb\u7684\u6027\u80fd\u5206\u6790\u3002", "result": "HPC\u65b9\u6848\u76f8\u6bd4\u5f53\u524d\u6700\u5148\u8fdb\u89e3\u51b3\u65b9\u6848\u5b9e\u73b0\u8fd1200\u500d\u52a0\u901f\u548c\u9ad8\u8fbe36%\u7684\u5185\u5b58\u4f7f\u7528\u51cf\u5c11\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e3a\u9ad8\u6548\u8ba1\u7b97\u4e0b\u4e00\u4ee3\u751f\u7269\u95ee\u9898\u94fa\u5e73\u4e86\u9053\u8def\u3002"}}
{"id": "2602.05131", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2602.05131", "abs": "https://arxiv.org/abs/2602.05131", "authors": ["Irene Bonati", "Silvina Caino-Lores", "Tain\u00e3 Coleman", "Sagar Dolas", "Sandro Fiore", "Venkatesh Kannan", "Marco Verdicchio", "Sean R. Wilkinson", "Rafael Ferreira da Silva"], "title": "Towards Advancing Research with Workflows: A perspective from the Workflows Community Summit -- Amsterdam, 2025", "comment": null, "summary": "Scientific workflows have become essential for orchestrating complex computational processes across distributed resources, managing large datasets, and ensuring reproducibility in modern research. The Workflows Community Summit 2025, held in Amsterdam on June 6th, 2025, convened international experts to examine emerging challenges and opportunities in this domain. Participants identified key barriers to workflow adoption, including tensions between system generality and domain-specific utility, concerns over long-term sustainability of workflow systems and services, insufficient recognition for those who develop and maintain reproducible workflows, and gaps in standardization, funding, training, and cross-disciplinary collaboration. To address these challenges, the summit proposed action lines spanning technology, policy, and community dimensions: shifting evaluation metrics from raw computational performance toward measuring genuine scientific impact; formalizing workflow patterns and community-driven benchmarks to improve transparency, reproducibility, and usability; cultivating a cohesive international workflows community that engages funding bodies and research stakeholders; and investing in human capital through dedicated workflow engineering roles, career pathways, and integration of workflow concepts into educational curricula and long-term training initiatives. This document presents the summit's findings, beginning with an overview of the current computing ecosystem and the rationale for workflow-centric approaches, followed by a discussion of identified challenges and recommended action lines for advancing scientific discovery through workflows.", "AI": {"tldr": "2025\u5e74\u79d1\u5b66\u5de5\u4f5c\u6d41\u793e\u533a\u5cf0\u4f1a\u8bc6\u522b\u4e86\u5de5\u4f5c\u6d41\u91c7\u7528\u7684\u5173\u952e\u969c\u788d\uff0c\u5e76\u63d0\u51fa\u4e86\u6280\u672f\u3001\u653f\u7b56\u548c\u793e\u533a\u5c42\u9762\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5f3a\u8c03\u4ece\u8ba1\u7b97\u6027\u80fd\u8bc4\u4f30\u8f6c\u5411\u79d1\u5b66\u5f71\u54cd\u8861\u91cf\uff0c\u5efa\u7acb\u6807\u51c6\u5316\u6a21\u5f0f\uff0c\u57f9\u517b\u56fd\u9645\u793e\u533a\uff0c\u4ee5\u53ca\u6295\u8d44\u4eba\u529b\u8d44\u672c\u3002", "motivation": "\u79d1\u5b66\u5de5\u4f5c\u6d41\u5728\u73b0\u4ee3\u7814\u7a76\u4e2d\u5bf9\u4e8e\u534f\u8c03\u5206\u5e03\u5f0f\u8ba1\u7b97\u3001\u7ba1\u7406\u5927\u6570\u636e\u548c\u786e\u4fdd\u53ef\u91cd\u590d\u6027\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u9762\u4e34\u91c7\u7528\u969c\u788d\u30022025\u5e74\u5de5\u4f5c\u6d41\u793e\u533a\u5cf0\u4f1a\u65e8\u5728\u53ec\u96c6\u56fd\u9645\u4e13\u5bb6\uff0c\u8bc6\u522b\u6311\u6218\u5e76\u5236\u5b9a\u89e3\u51b3\u65b9\u6848\uff0c\u4ee5\u63a8\u52a8\u5de5\u4f5c\u6d41\u5728\u79d1\u5b66\u53d1\u73b0\u4e2d\u7684\u5e94\u7528\u3002", "method": "\u901a\u8fc72025\u5e746\u67086\u65e5\u5728\u963f\u59c6\u65af\u7279\u4e39\u4e3e\u884c\u7684\u56fd\u9645\u5de5\u4f5c\u6d41\u793e\u533a\u5cf0\u4f1a\uff0c\u6c47\u96c6\u4e13\u5bb6\u8ba8\u8bba\uff0c\u8bc6\u522b\u5173\u952e\u6311\u6218\uff0c\u5e76\u63d0\u51fa\u8de8\u6280\u672f\u3001\u653f\u7b56\u548c\u793e\u533a\u7ef4\u5ea6\u7684\u884c\u52a8\u8def\u7ebf\u3002", "result": "\u8bc6\u522b\u4e86\u56db\u5927\u5173\u952e\u969c\u788d\uff1a\u7cfb\u7edf\u901a\u7528\u6027\u4e0e\u9886\u57df\u7279\u5b9a\u6027\u4e4b\u95f4\u7684\u5f20\u529b\u3001\u5de5\u4f5c\u6d41\u7cfb\u7edf\u957f\u671f\u53ef\u6301\u7eed\u6027\u95ee\u9898\u3001\u5de5\u4f5c\u6d41\u5f00\u53d1\u8005\u7f3a\u4e4f\u8ba4\u53ef\u3001\u6807\u51c6\u5316/\u8d44\u91d1/\u57f9\u8bad/\u8de8\u5b66\u79d1\u5408\u4f5c\u4e0d\u8db3\u3002\u63d0\u51fa\u4e86\u56db\u4e2a\u884c\u52a8\u8def\u7ebf\uff1a\u8bc4\u4f30\u6307\u6807\u8f6c\u5411\u79d1\u5b66\u5f71\u54cd\u3001\u5efa\u7acb\u6807\u51c6\u5316\u6a21\u5f0f\u548c\u57fa\u51c6\u3001\u57f9\u517b\u56fd\u9645\u793e\u533a\u3001\u6295\u8d44\u4eba\u529b\u8d44\u672c\u548c\u6559\u80b2\u3002", "conclusion": "\u79d1\u5b66\u5de5\u4f5c\u6d41\u9700\u8981\u7cfb\u7edf\u6027\u53d8\u9769\uff0c\u5305\u62ec\u8bc4\u4f30\u4f53\u7cfb\u8f6c\u578b\u3001\u6807\u51c6\u5316\u5efa\u8bbe\u3001\u793e\u533a\u53d1\u5c55\u548c\u4eba\u624d\u57f9\u517b\uff0c\u4ee5\u5145\u5206\u53d1\u6325\u5176\u5728\u63a8\u52a8\u79d1\u5b66\u53d1\u73b0\u4e2d\u7684\u6f5c\u529b\u3002\u5cf0\u4f1a\u63d0\u51fa\u7684\u591a\u7ef4\u5ea6\u884c\u52a8\u8def\u7ebf\u4e3a\u5de5\u4f5c\u6d41\u9886\u57df\u7684\u672a\u6765\u53d1\u5c55\u63d0\u4f9b\u4e86\u8def\u7ebf\u56fe\u3002"}}
{"id": "2602.05292", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2602.05292", "abs": "https://arxiv.org/abs/2602.05292", "authors": ["Haoyu Bai", "Muhammed Tawfiqul Islam", "Minxian Xu", "Rajkumar Buyya"], "title": "ORACL: Optimized Reasoning for Autoscaling via Chain of Thought with LLMs for Microservices", "comment": null, "summary": "Applications are moving away from monolithic designs to microservice and serverless architectures, where fleets of lightweight and independently deployable components run on public clouds. Autoscaling serves as the primary control mechanism for balancing resource utilization and quality of service, yet existing policies are either opaque learned models that require substantial per-deployment training or brittle hand-tuned rules that fail to generalize. We investigate whether large language models can act as universal few-shot resource allocators that adapt across rapidly evolving microservice deployments.\n  We propose ORACL, Optimized Reasoning for Autoscaling via Chain of Thought with LLMs for Microservices, a framework that leverages prior knowledge and chain-of-thought reasoning to diagnose performance regressions and recommend resource allocations. ORACL transforms runtime telemetry, including pods, replicas, CPU and memory usage, latency, service-level objectives, and fault signals, into semantic natural-language state descriptions and invokes an LLM to produce an interpretable intermediate reasoning trace. This reasoning identifies likely root causes, prunes the action space, and issues safe allocation decisions under policy constraints. Experiments on representative open-source microservice workloads show that ORACL improves root-cause identification accuracy by 15 percent, accelerates training by up to 24x, and improves quality of service by 6 percent in short-term scenarios, without deployment-specific retraining.", "AI": {"tldr": "ORACL\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u901a\u7528\u5c11\u6837\u672c\u8d44\u6e90\u5206\u914d\u5668\uff0c\u901a\u8fc7\u601d\u7ef4\u94fe\u63a8\u7406\u8bca\u65ad\u5fae\u670d\u52a1\u6027\u80fd\u95ee\u9898\u5e76\u63a8\u8350\u8d44\u6e90\u5206\u914d\uff0c\u65e0\u9700\u90e8\u7f72\u7279\u5b9a\u8bad\u7ec3\u5373\u53ef\u63d0\u5347\u6839\u56e0\u8bc6\u522b\u51c6\u786e\u738715%\u3001\u8bad\u7ec3\u52a0\u901f24\u500d\u3001\u670d\u52a1\u8d28\u91cf\u63d0\u53476%\u3002", "motivation": "\u968f\u7740\u5e94\u7528\u4ece\u5355\u4f53\u67b6\u6784\u8f6c\u5411\u5fae\u670d\u52a1\u548c\u65e0\u670d\u52a1\u5668\u67b6\u6784\uff0c\u73b0\u6709\u7684\u81ea\u52a8\u6269\u7f29\u5bb9\u7b56\u7565\u5b58\u5728\u5c40\u9650\u6027\uff1a\u57fa\u4e8e\u5b66\u4e60\u7684\u6a21\u578b\u9700\u8981\u5927\u91cf\u90e8\u7f72\u7279\u5b9a\u8bad\u7ec3\uff0c\u800c\u624b\u52a8\u8c03\u4f18\u7684\u89c4\u5219\u53c8\u8106\u5f31\u4e14\u96be\u4ee5\u6cdb\u5316\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u9002\u5e94\u5feb\u901f\u6f14\u8fdb\u7684\u5fae\u670d\u52a1\u90e8\u7f72\u7684\u901a\u7528\u8d44\u6e90\u5206\u914d\u65b9\u6848\u3002", "method": "\u63d0\u51faORACL\u6846\u67b6\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5148\u9a8c\u77e5\u8bc6\u548c\u601d\u7ef4\u94fe\u63a8\u7406\u80fd\u529b\u3002\u5c06\u8fd0\u884c\u65f6\u9065\u6d4b\u6570\u636e\uff08pods\u3001\u526f\u672c\u3001CPU/\u5185\u5b58\u4f7f\u7528\u7387\u3001\u5ef6\u8fdf\u3001SLO\u3001\u6545\u969c\u4fe1\u53f7\uff09\u8f6c\u6362\u4e3a\u8bed\u4e49\u81ea\u7136\u8bed\u8a00\u72b6\u6001\u63cf\u8ff0\uff0c\u8c03\u7528LLM\u751f\u6210\u53ef\u89e3\u91ca\u7684\u4e2d\u95f4\u63a8\u7406\u8f68\u8ff9\uff0c\u8bc6\u522b\u6839\u56e0\u3001\u526a\u679d\u52a8\u4f5c\u7a7a\u95f4\uff0c\u5e76\u5728\u7b56\u7565\u7ea6\u675f\u4e0b\u505a\u51fa\u5b89\u5168\u7684\u5206\u914d\u51b3\u7b56\u3002", "result": "\u5728\u4ee3\u8868\u6027\u5f00\u6e90\u5fae\u670d\u52a1\u5de5\u4f5c\u8d1f\u8f7d\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff1aORACL\u5c06\u6839\u56e0\u8bc6\u522b\u51c6\u786e\u7387\u63d0\u9ad815%\uff0c\u8bad\u7ec3\u901f\u5ea6\u63d0\u5347\u9ad8\u8fbe24\u500d\uff0c\u77ed\u671f\u573a\u666f\u4e0b\u670d\u52a1\u8d28\u91cf\u63d0\u53476%\uff0c\u4e14\u65e0\u9700\u90e8\u7f72\u7279\u5b9a\u7684\u91cd\u65b0\u8bad\u7ec3\u3002", "conclusion": "\u5927\u8bed\u8a00\u6a21\u578b\u53ef\u4ee5\u4f5c\u4e3a\u901a\u7528\u7684\u5c11\u6837\u672c\u8d44\u6e90\u5206\u914d\u5668\uff0c\u901a\u8fc7\u601d\u7ef4\u94fe\u63a8\u7406\u9002\u5e94\u5feb\u901f\u6f14\u8fdb\u7684\u5fae\u670d\u52a1\u90e8\u7f72\uff0c\u63d0\u4f9b\u6bd4\u73b0\u6709\u65b9\u6cd5\u66f4\u597d\u7684\u6027\u80fd\u8bca\u65ad\u548c\u8d44\u6e90\u5206\u914d\u80fd\u529b\uff0c\u540c\u65f6\u4fdd\u6301\u53ef\u89e3\u91ca\u6027\u548c\u6cdb\u5316\u6027\u3002"}}
{"id": "2602.05346", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2602.05346", "abs": "https://arxiv.org/abs/2602.05346", "authors": ["Shubham Mishra", "Jo\u00e3o Gon\u00e7alves", "Chawinphat Tankuranand", "Neil Giridharan", "Natacha Crooks", "Heidi Howard", "Chris Jensen"], "title": "Proteus: Append-Only Ledgers for (Mostly) Trusted Execution Environments", "comment": null, "summary": "Distributed ledgers are increasingly relied upon by industry to provide trustworthy accountability, strong integrity protection, and high availability for critical data without centralizing trust. Recently, distributed append-only logs are opting for a layered approach, combining crash-fault-tolerant (CFT) consensus with hardware-based Trusted Execution Environments (TEEs) for greater resiliency. Unfortunately, hardware TEEs can be subject to (rare) attacks, undermining the very guarantees that distributed ledgers are carefully designed to achieve. In response, we present Proteus, a new distributed consensus protocol that cautiously trusts the guarantees of TEEs. Proteus carefully embeds a Byzantine fault-tolerant (BFT) protocol inside of a CFT protocol with no additional messages. This is made possible through careful refactoring of both the CFT and BFT protocols such that their structure aligns. Proteus achieves performance in line with regular TEE-enabled consensus protocols, while guaranteeing integrity in the face of TEE platform compromises.", "AI": {"tldr": "Proteus\u662f\u4e00\u4e2a\u5206\u5e03\u5f0f\u5171\u8bc6\u534f\u8bae\uff0c\u901a\u8fc7\u5728CFT\u534f\u8bae\u4e2d\u5d4c\u5165BFT\u534f\u8bae\uff0c\u8c28\u614e\u4fe1\u4efbTEE\u786c\u4ef6\uff0c\u5728TEE\u53ef\u80fd\u88ab\u653b\u51fb\u7684\u60c5\u51b5\u4e0b\u4ecd\u80fd\u4fdd\u8bc1\u6570\u636e\u5b8c\u6574\u6027\u3002", "motivation": "\u5206\u5e03\u5f0f\u8d26\u672c\u4f9d\u8d56\u786c\u4ef6TEE\u63d0\u4f9b\u4fe1\u4efb\uff0c\u4f46TEE\u53ef\u80fd\u53d7\u5230\u653b\u51fb\uff0c\u8fd9\u4f1a\u7834\u574f\u5206\u5e03\u5f0f\u8d26\u672c\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u4fdd\u8bc1\u3002\u9700\u8981\u4e00\u79cd\u5728TEE\u53ef\u80fd\u88ab\u653b\u7834\u65f6\u4ecd\u80fd\u4fdd\u8bc1\u5b8c\u6574\u6027\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u901a\u8fc7\u7cbe\u5fc3\u91cd\u6784CFT\u548cBFT\u534f\u8bae\u4f7f\u5b83\u4eec\u7ed3\u6784\u5bf9\u9f50\uff0c\u5728CFT\u534f\u8bae\u4e2d\u5d4c\u5165BFT\u534f\u8bae\u800c\u4e0d\u589e\u52a0\u989d\u5916\u6d88\u606f\u3002\u8c28\u614e\u4fe1\u4efbTEE\u7684\u4fdd\u8bc1\uff0c\u5728TEE\u5e73\u53f0\u53ef\u80fd\u88ab\u653b\u7834\u65f6\u4ecd\u80fd\u4fdd\u8bc1\u5b8c\u6574\u6027\u3002", "result": "Proteus\u5728\u4fdd\u6301\u4e0e\u5e38\u89c4TEE\u589e\u5f3a\u5171\u8bc6\u534f\u8bae\u76f8\u5f53\u6027\u80fd\u7684\u540c\u65f6\uff0c\u80fd\u591f\u5728TEE\u5e73\u53f0\u88ab\u653b\u7834\u7684\u60c5\u51b5\u4e0b\u4fdd\u8bc1\u6570\u636e\u5b8c\u6574\u6027\u3002", "conclusion": "Proteus\u63d0\u4f9b\u4e86\u4e00\u79cd\u5e73\u8861\u7684\u65b9\u6cd5\uff0c\u65e2\u5229\u7528TEE\u7684\u6027\u80fd\u4f18\u52bf\uff0c\u53c8\u901a\u8fc7\u5d4c\u5165BFT\u534f\u8bae\u63d0\u4f9b\u989d\u5916\u7684\u5b89\u5168\u4fdd\u969c\uff0c\u5728\u786c\u4ef6TEE\u53ef\u80fd\u4e0d\u53ef\u9760\u7684\u60c5\u51b5\u4e0b\u4ecd\u80fd\u4fdd\u8bc1\u5206\u5e03\u5f0f\u8d26\u672c\u7684\u5b8c\u6574\u6027\u3002"}}
{"id": "2602.04926", "categories": ["cs.DB", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.04926", "abs": "https://arxiv.org/abs/2602.04926", "authors": ["Ning Wang", "Kuanyan Zhu", "Daniel Yuehwoon Yee", "Yitang Gao", "Shiying Huang", "Zirun Xu", "Sainyam Galhotra"], "title": "Pruning Minimal Reasoning Graphs for Efficient Retrieval-Augmented Generation", "comment": null, "summary": "Retrieval-augmented generation (RAG) is now standard for knowledge-intensive LLM tasks, but most systems still treat every query as fresh, repeatedly re-retrieving long passages and re-reasoning from scratch, inflating tokens, latency, and cost. We present AutoPrunedRetriever, a graph-style RAG system that persists the minimal reasoning subgraph built for earlier questions and incrementally extends it for later ones. AutoPrunedRetriever stores entities and relations in a compact, ID-indexed codebook and represents questions, facts, and answers as edge sequences, enabling retrieval and prompting over symbolic structure instead of raw text. To keep the graph compact, we apply a two-layer consolidation policy (fast ANN/KNN alias detection plus selective $k$-means once a memory threshold is reached) and prune low-value structure, while prompts retain only overlap representatives and genuinely new evidence. We instantiate two front ends: AutoPrunedRetriever-REBEL, which uses REBEL as a triplet parser, and AutoPrunedRetriever-llm, which swaps in an LLM extractor. On GraphRAG-Benchmark (Medical and Novel), both variants achieve state-of-the-art complex reasoning accuracy, improving over HippoRAG2 by roughly 9--11 points, and remain competitive on contextual summarize and generation. On our harder STEM and TV benchmarks, AutoPrunedRetriever again ranks first, while using up to two orders of magnitude fewer tokens than graph-heavy baselines, making it a practical substrate for long-running sessions, evolving corpora, and multi-agent pipelines.", "AI": {"tldr": "AutoPrunedRetriever\uff1a\u57fa\u4e8e\u56fe\u7ed3\u6784\u7684RAG\u7cfb\u7edf\uff0c\u901a\u8fc7\u6301\u4e45\u5316\u63a8\u7406\u5b50\u56fe\u5e76\u589e\u91cf\u6269\u5c55\uff0c\u51cf\u5c11\u91cd\u590d\u68c0\u7d22\u548c\u63a8\u7406\uff0c\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u6210\u672c", "motivation": "\u4f20\u7edfRAG\u7cfb\u7edf\u5bf9\u6bcf\u4e2a\u67e5\u8be2\u90fd\u91cd\u65b0\u68c0\u7d22\u957f\u6bb5\u843d\u5e76\u4ece\u5934\u63a8\u7406\uff0c\u5bfc\u81f4token\u4f7f\u7528\u3001\u5ef6\u8fdf\u548c\u6210\u672c\u589e\u52a0\u3002\u9700\u8981\u4e00\u79cd\u80fd\u6301\u4e45\u5316\u63a8\u7406\u7ed3\u6784\u5e76\u589e\u91cf\u66f4\u65b0\u7684\u7cfb\u7edf\u6765\u63d0\u9ad8\u6548\u7387\u3002", "method": "\u63d0\u51fa\u56fe\u5f0fRAG\u7cfb\u7edf\uff0c\u5c06\u5b9e\u4f53\u548c\u5173\u7cfb\u5b58\u50a8\u5728\u7d27\u51d1\u7684ID\u7d22\u5f15\u7801\u672c\u4e2d\uff0c\u5c06\u95ee\u9898\u3001\u4e8b\u5b9e\u548c\u7b54\u6848\u8868\u793a\u4e3a\u8fb9\u5e8f\u5217\u3002\u91c7\u7528\u4e24\u5c42\u5408\u5e76\u7b56\u7565\uff08\u5feb\u901fANN/KNN\u522b\u540d\u68c0\u6d4b+\u9009\u62e9\u6027k-means\uff09\u4fdd\u6301\u56fe\u7d27\u51d1\uff0c\u5e76\u4fee\u526a\u4f4e\u4ef7\u503c\u7ed3\u6784\u3002", "result": "\u5728GraphRAG-Benchmark\uff08\u533b\u5b66\u548c\u5c0f\u8bf4\uff09\u4e0a\uff0c\u4e24\u4e2a\u53d8\u4f53\u90fd\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u590d\u6742\u63a8\u7406\u51c6\u786e\u7387\uff0c\u6bd4HippoRAG2\u63d0\u9ad8\u4e86\u7ea69-11\u4e2a\u767e\u5206\u70b9\u3002\u5728STEM\u548cTV\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4e5f\u6392\u540d\u7b2c\u4e00\uff0c\u540c\u65f6\u4f7f\u7528\u7684token\u6bd4\u57fa\u4e8e\u56fe\u7684\u57fa\u7ebf\u5c11\u4e24\u4e2a\u6570\u91cf\u7ea7\u3002", "conclusion": "AutoPrunedRetriever\u901a\u8fc7\u6301\u4e45\u5316\u548c\u589e\u91cf\u6269\u5c55\u63a8\u7406\u5b50\u56fe\uff0c\u663e\u8457\u63d0\u9ad8\u4e86RAG\u7cfb\u7edf\u7684\u6548\u7387\u548c\u6027\u80fd\uff0c\u4e3a\u957f\u671f\u8fd0\u884c\u4f1a\u8bdd\u3001\u6f14\u5316\u8bed\u6599\u5e93\u548c\u591a\u667a\u80fd\u4f53\u7ba1\u9053\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u57fa\u7840\u3002"}}
{"id": "2602.04910", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.04910", "abs": "https://arxiv.org/abs/2602.04910", "authors": ["Nongyu Di", "Tianyu Chen", "Shan Lu", "Shuai Lu", "Yeyun Gong", "Peng Cheng", "Jacob R. Lorch", "Yuan Yao", "Xiaoxing Ma"], "title": "Reducing the Costs of Proof Synthesis on Rust Systems by Scaling Up a Seed Training Set", "comment": null, "summary": "Large Language Models (LLMs) are widely used for code generation. However, the correctness of code generated by LLMs remains a concern. A potential remedy to this concern is to have LLMs generate formal correctness proofs along with such code. However, compared with code generation, code-proof generation requires much higher reasoning capability and has much less existing data to learn from. In this paper, we present VeruSyn, a data synthesis pipeline for Verus, a state-of-the-art verification tool for system software written in Rust. Through self-synthesis and tutorial-based synthesis, VeruSyn achieves much larger scale and Verus-feature coverage than previous data-synthesis techniques designed for Verus; VeruSyn also supplements its dataset with long-chain-of-thought (CoT) data through agent trajectory synthesis. With VeruSyn, we synthesize the largest set of Verus verified programs: 6.9 million Rust programs, each with a formal specification and a proof that it meets that specification. This dataset lets us create a fine-tuned Qwen2.5-Coder-32B-Instruct model with appealing cost-proof tradeoff compared with state-of-the-art commercial models like Claude Sonnet 4.5. It also significantly outperforms models like o4-mini and previously proposed research models.", "AI": {"tldr": "VeruSyn\u662f\u4e00\u4e2a\u7528\u4e8eVerus\uff08Rust\u7cfb\u7edf\u8f6f\u4ef6\u9a8c\u8bc1\u5de5\u5177\uff09\u7684\u6570\u636e\u5408\u6210\u7ba1\u9053\uff0c\u901a\u8fc7\u81ea\u5408\u6210\u548c\u6559\u7a0b\u5408\u6210\u751f\u6210\u4e86690\u4e07\u4e2a\u5e26\u6709\u5f62\u5f0f\u89c4\u8303\u548c\u8bc1\u660e\u7684Rust\u7a0b\u5e8f\uff0c\u7528\u4e8e\u8bad\u7ec3\u4ee3\u7801\u8bc1\u660e\u751f\u6210\u6a21\u578b\u3002", "motivation": "LLM\u751f\u6210\u7684\u4ee3\u7801\u6b63\u786e\u6027\u5b58\u5728\u95ee\u9898\uff0c\u9700\u8981\u5f62\u5f0f\u5316\u8bc1\u660e\u6765\u4fdd\u8bc1\u3002\u4f46\u4ee3\u7801\u8bc1\u660e\u751f\u6210\u6bd4\u4ee3\u7801\u751f\u6210\u9700\u8981\u66f4\u5f3a\u7684\u63a8\u7406\u80fd\u529b\uff0c\u4e14\u73b0\u6709\u6570\u636e\u4e0d\u8db3\u3002Verus\u4f5c\u4e3aRust\u7cfb\u7edf\u8f6f\u4ef6\u7684\u9a8c\u8bc1\u5de5\u5177\uff0c\u7f3a\u4e4f\u5927\u89c4\u6a21\u8bad\u7ec3\u6570\u636e\u3002", "method": "VeruSyn\u91c7\u7528\u4e09\u79cd\u5408\u6210\u65b9\u6cd5\uff1a1) \u81ea\u5408\u6210\uff1a\u57fa\u4e8e\u73b0\u6709\u7a0b\u5e8f\u751f\u6210\u65b0\u7a0b\u5e8f\uff1b2) \u6559\u7a0b\u5408\u6210\uff1a\u4ece\u6559\u7a0b\u4e2d\u63d0\u53d6\u4ee3\u7801\u548c\u8bc1\u660e\uff1b3) \u4ee3\u7406\u8f68\u8ff9\u5408\u6210\uff1a\u751f\u6210\u957f\u94fe\u63a8\u7406\u6570\u636e\u3002\u6700\u7ec8\u5408\u6210690\u4e07\u4e2aVerus\u9a8c\u8bc1\u7a0b\u5e8f\u3002", "result": "\u521b\u5efa\u4e86\u6700\u5927\u7684Verus\u9a8c\u8bc1\u7a0b\u5e8f\u6570\u636e\u96c6\uff08690\u4e07\u4e2a\uff09\uff0c\u57fa\u4e8e\u6b64\u5fae\u8c03\u7684Qwen2.5-Coder-32B-Instruct\u6a21\u578b\u5728\u6210\u672c-\u8bc1\u660e\u6743\u8861\u4e0a\u4f18\u4e8eClaude Sonnet 4.5\u7b49\u5546\u4e1a\u6a21\u578b\uff0c\u663e\u8457\u8d85\u8d8ao4-mini\u548c\u5148\u524d\u7814\u7a76\u6a21\u578b\u3002", "conclusion": "VeruSyn\u901a\u8fc7\u5927\u89c4\u6a21\u6570\u636e\u5408\u6210\u89e3\u51b3\u4e86\u4ee3\u7801\u8bc1\u660e\u751f\u6210\u7684\u6570\u636e\u7a00\u7f3a\u95ee\u9898\uff0c\u8bad\u7ec3\u7684\u6a21\u578b\u5728\u4ee3\u7801\u8bc1\u660e\u751f\u6210\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u4e3aLLM\u751f\u6210\u53ef\u9a8c\u8bc1\u4ee3\u7801\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.05356", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2602.05356", "abs": "https://arxiv.org/abs/2602.05356", "authors": ["Andrew Lewis-Pye"], "title": "Reaching Univalency with Subquadratic Communication", "comment": null, "summary": "The Dolev-Reischuk lower bound establishes that any deterministic Byzantine Agreement (BA) protocol for $n$ processors tolerating $f$ faults requires $\u03a9(f^2+n)$ messages. But what exactly does this quadratic cost pay for? Even the minimal requirement that every correct processor \\emph{receive at least one message} already necessitates $\u03a9(f^2 + n)$ messages. This raises a fundamental question: is the Dolev-Reischuk bound about the difficulty of \\emph{reaching univalency} -- the point at which the protocol's outcome is determined -- or merely about \\emph{disseminating} the outcome to all processors afterward?\n  We resolve this question by showing that reaching univalency does \\emph{not} require quadratic communication. Specifically, we introduce $\u03b5$-BA, a relaxation allowing an $\u03b5$-fraction of correct processors to output incorrectly, and prove it can be solved deterministically with $O(n \\log n)$ communication complexity when $f < n(1/3 - \u03b5)$. Crucially, any $\u03b5$-BA protocol can serve as the first phase of a full BA protocol: after $\u03b5$-BA, a single all-to-all exchange and majority vote completes BA. Since the outcome is already determined after $\u03b5$-BA, this demonstrates that the quadratic cost in Dolev-Reischuk stems entirely from dissemination, rather than from reaching univalency. We also define Extractable BA for authenticated settings, capturing when processors collectively hold enough signed messages to determine the agreed value, and show it can be solved with communication complexity $O(f \\log f)$.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8Dolev-Reischuk\u4e0b\u754c\uff08\u03a9(f\u00b2+n)\u6d88\u606f\uff09\u7684\u672c\u8d28\uff0c\u8bc1\u660e\u8fbe\u5230\u5355\u503c\u6027\uff08univalency\uff09\u4e0d\u9700\u8981\u4e8c\u6b21\u901a\u4fe1\uff0c\u4e8c\u6b21\u6210\u672c\u4e3b\u8981\u6765\u81ea\u7ed3\u679c\u4f20\u64ad\u800c\u975e\u51b3\u7b56\u8fbe\u6210\u3002", "motivation": "\u7406\u89e3Dolev-Reischuk\u4e0b\u754c\u4e2d\u4e8c\u6b21\u901a\u4fe1\u6210\u672c\u7684\u6839\u672c\u539f\u56e0\uff1a\u662f\u8fbe\u6210\u5171\u8bc6\u51b3\u7b56\uff08\u5355\u503c\u6027\uff09\u9700\u8981\u4e8c\u6b21\u901a\u4fe1\uff0c\u8fd8\u662f\u4ec5\u4ec5\u5c06\u7ed3\u679c\u4f20\u64ad\u7ed9\u6240\u6709\u5904\u7406\u5668\u9700\u8981\u4e8c\u6b21\u901a\u4fe1\uff1f", "method": "\u63d0\u51fa\u03b5-BA\uff08\u5141\u8bb8\u03b5\u6bd4\u4f8b\u6b63\u786e\u5904\u7406\u5668\u8f93\u51fa\u9519\u8bef\uff09\uff0c\u8bc1\u660e\u5728f < n(1/3 - \u03b5)\u65f6\u53ef\u7528O(n log n)\u901a\u4fe1\u590d\u6742\u5ea6\u786e\u5b9a\u6027\u89e3\u51b3\u3002\u4efb\u4f55\u03b5-BA\u534f\u8bae\u53ef\u4f5c\u4e3a\u5b8c\u6574BA\u534f\u8bae\u7684\u7b2c\u4e00\u9636\u6bb5\uff0c\u7b2c\u4e8c\u9636\u6bb5\u53ea\u9700\u4e00\u6b21\u5168\u5bf9\u5168\u4ea4\u6362\u548c\u591a\u6570\u6295\u7968\u3002\u5728\u8ba4\u8bc1\u8bbe\u7f6e\u4e2d\u5b9a\u4e49Extractable BA\uff0c\u8bc1\u660e\u53ef\u7528O(f log f)\u901a\u4fe1\u89e3\u51b3\u3002", "result": "\u8fbe\u5230\u5355\u503c\u6027\u4e0d\u9700\u8981\u4e8c\u6b21\u901a\u4fe1\uff0c\u4e8c\u6b21\u6210\u672c\u5b8c\u5168\u6765\u81ea\u7ed3\u679c\u4f20\u64ad\u3002\u03b5-BA\u53ef\u5728O(n log n)\u901a\u4fe1\u5185\u89e3\u51b3\uff0cExtractable BA\u5728\u8ba4\u8bc1\u8bbe\u7f6e\u4e2d\u53ef\u5728O(f log f)\u901a\u4fe1\u5185\u89e3\u51b3\u3002", "conclusion": "Dolev-Reischuk\u4e0b\u754c\u7684\u4e8c\u6b21\u901a\u4fe1\u6210\u672c\u4e0d\u662f\u8fbe\u6210\u5171\u8bc6\u51b3\u7b56\uff08\u5355\u503c\u6027\uff09\u6240\u5fc5\u9700\uff0c\u800c\u662f\u5c06\u7ed3\u679c\u4f20\u64ad\u7ed9\u6240\u6709\u5904\u7406\u5668\u6240\u9700\u3002\u8fd9\u6f84\u6e05\u4e86\u62dc\u5360\u5ead\u534f\u8bae\u901a\u4fe1\u590d\u6742\u6027\u7684\u6839\u672c\u539f\u56e0\u3002"}}
{"id": "2602.05452", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2602.05452", "abs": "https://arxiv.org/abs/2602.05452", "authors": ["Alexandros Zeakis", "George Papadakis", "Dimitrios Skoutas", "Manolis Koubarakis"], "title": "DistillER: Knowledge Distillation in Entity Resolution with Large Language Models", "comment": null, "summary": "Recent advances in Entity Resolution (ER) have leveraged Large Language Models (LLMs), achieving strong performance but at the cost of substantial computational resources or high financial overhead. Existing LLM-based ER approaches operate either in unsupervised settings and rely on very large and costly models, or in supervised settings and require ground-truth annotations, leaving a critical gap between time efficiency and effectiveness. To make LLM-powered ER more practical, we investigate Knowledge Distillation (KD) as a means to transfer knowledge from large, effective models (Teachers) to smaller, more efficient models (Students) without requiring gold labels. We introduce DistillER, the first framework that systematically bridges this gap across three dimensions: (i) Data Selection, where we study strategies for identifying informative subsets of data; (ii) Knowledge Elicitation, where we compare single- and multi-teacher settings across LLMs and smaller language models (SLMs); and (iii) Distillation Algorithms, where we evaluate supervised fine-tuning and reinforcement learning approaches. Our experiments reveal that supervised fine-tuning of Students on noisy labels generated by LLM Teachers consistently outperforms alternative KD strategies, while also enabling high-quality explanation generation. Finally, we benchmark DistillER against established supervised and unsupervised ER methods based on LLMs and SLMs, demonstrating significant improvements in both effectiveness and efficiency.", "AI": {"tldr": "DistillER\u662f\u4e00\u4e2a\u77e5\u8bc6\u84b8\u998f\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u5927\u578bLLM\u6559\u5e08\u6a21\u578b\u7684\u77e5\u8bc6\u8f6c\u79fb\u5230\u5c0f\u578b\u5b66\u751f\u6a21\u578b\uff0c\u5728\u4e0d\u4f9d\u8d56\u9ec4\u91d1\u6807\u7b7e\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u9ad8\u6548\u4e14\u6709\u6548\u7684\u5b9e\u4f53\u89e3\u6790\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8eLLM\u7684\u5b9e\u4f53\u89e3\u6790\u65b9\u6cd5\u8981\u4e48\u4f9d\u8d56\u8ba1\u7b97\u6210\u672c\u9ad8\u6602\u7684\u5927\u578b\u6a21\u578b\uff0c\u8981\u4e48\u9700\u8981\u5e26\u6807\u6ce8\u7684\u8bad\u7ec3\u6570\u636e\uff0c\u5728\u65f6\u95f4\u6548\u7387\u548c\u6709\u6548\u6027\u4e4b\u95f4\u5b58\u5728\u5173\u952e\u5dee\u8ddd\u3002\u9700\u8981\u4e00\u79cd\u66f4\u5b9e\u7528\u7684\u65b9\u6cd5\u6765\u5b9e\u73b0LLM\u9a71\u52a8\u7684\u5b9e\u4f53\u89e3\u6790\u3002", "method": "\u63d0\u51faDistillER\u6846\u67b6\uff0c\u4ece\u4e09\u4e2a\u7ef4\u5ea6\u7cfb\u7edf\u89e3\u51b3\u77e5\u8bc6\u84b8\u998f\u95ee\u9898\uff1a1) \u6570\u636e\u9009\u62e9\u7b56\u7565\u8bc6\u522b\u4fe1\u606f\u4e30\u5bcc\u7684\u5b50\u96c6\uff1b2) \u77e5\u8bc6\u63d0\u53d6\uff0c\u6bd4\u8f83\u5355\u6559\u5e08\u548c\u591a\u6559\u5e08\u8bbe\u7f6e\uff1b3) \u84b8\u998f\u7b97\u6cd5\uff0c\u8bc4\u4f30\u76d1\u7763\u5fae\u8c03\u548c\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u5728LLM\u6559\u5e08\u751f\u6210\u7684\u566a\u58f0\u6807\u7b7e\u4e0a\u5bf9\u5b66\u751f\u6a21\u578b\u8fdb\u884c\u76d1\u7763\u5fae\u8c03\uff0c\u59cb\u7ec8\u4f18\u4e8e\u5176\u4ed6\u77e5\u8bc6\u84b8\u998f\u7b56\u7565\uff0c\u540c\u65f6\u8fd8\u80fd\u751f\u6210\u9ad8\u8d28\u91cf\u7684\u89e3\u91ca\u3002DistillER\u5728\u6548\u679c\u548c\u6548\u7387\u4e0a\u90fd\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u7684\u76d1\u7763\u548c\u975e\u76d1\u7763ER\u65b9\u6cd5\u3002", "conclusion": "\u77e5\u8bc6\u84b8\u998f\u662f\u4f7fLLM\u9a71\u52a8\u7684\u5b9e\u4f53\u89e3\u6790\u66f4\u5b9e\u7528\u7684\u6709\u6548\u65b9\u6cd5\uff0cDistillER\u6846\u67b6\u5728\u4e0d\u4f9d\u8d56\u9ec4\u91d1\u6807\u7b7e\u7684\u60c5\u51b5\u4e0b\uff0c\u6210\u529f\u5730\u5c06\u5927\u578b\u6709\u6548\u6a21\u578b\u7684\u77e5\u8bc6\u8f6c\u79fb\u5230\u5c0f\u578b\u9ad8\u6548\u6a21\u578b\u4e2d\u3002"}}
{"id": "2602.04935", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.04935", "abs": "https://arxiv.org/abs/2602.04935", "authors": ["Youjin Wang", "Run Zhou", "Rong Fu", "Shuaishuai Cao", "Hongwei Zeng", "Jiaxuan Lu", "Sicheng Fan", "Jiaqiao Zhao", "Liangming Pan"], "title": "ASA: Activation Steering for Tool-Calling Domain Adaptation", "comment": null, "summary": "For real-world deployment of general-purpose LLM agents, the core challenge is often not tool use itself, but efficient domain adaptation under rapidly evolving toolsets, APIs, and protocols. Repeated LoRA or SFT across domains incurs exponentially growing training and maintenance costs, while prompt or schema methods are brittle under distribution shift and complex interfaces. We propose \\textbf{Activation Steering Adapter (ASA}), a lightweight, inference-time, training-free mechanism that reads routing signals from intermediate activations and uses an ultra-light router to produce adaptive control strengths for precise domain alignment. Across multiple model scales and domains, ASA achieves LoRA-comparable adaptation with substantially lower overhead and strong cross-model transferability, making it ideally practical for robust, scalable, and efficient multi-domain tool ecosystems with frequent interface churn dynamics.", "AI": {"tldr": "ASA\u662f\u4e00\u79cd\u8f7b\u91cf\u7ea7\u3001\u65e0\u9700\u8bad\u7ec3\u7684\u63a8\u7406\u65f6\u9002\u914d\u673a\u5236\uff0c\u901a\u8fc7\u8bfb\u53d6\u4e2d\u95f4\u6fc0\u6d3b\u7684\u8def\u7531\u4fe1\u53f7\uff0c\u4f7f\u7528\u8d85\u8f7b\u91cf\u8def\u7531\u5668\u4ea7\u751f\u81ea\u9002\u5e94\u63a7\u5236\u5f3a\u5ea6\uff0c\u5b9e\u73b0\u7cbe\u786e\u9886\u57df\u5bf9\u9f50\uff0c\u5728\u591a\u9886\u57df\u5de5\u5177\u751f\u6001\u7cfb\u7edf\u4e2d\u5177\u6709\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u7684\u4f18\u52bf\u3002", "motivation": "\u901a\u7528LLM\u667a\u80fd\u4f53\u5728\u73b0\u5b9e\u90e8\u7f72\u4e2d\u7684\u6838\u5fc3\u6311\u6218\u4e0d\u662f\u5de5\u5177\u4f7f\u7528\u672c\u8eab\uff0c\u800c\u662f\u5728\u5feb\u901f\u6f14\u53d8\u7684\u5de5\u5177\u96c6\u3001API\u548c\u534f\u8bae\u4e0b\u7684\u9ad8\u6548\u9886\u57df\u9002\u5e94\u3002\u4f20\u7edf\u7684LoRA\u6216SFT\u65b9\u6cd5\u5728\u4e0d\u540c\u9886\u57df\u91cd\u590d\u8bad\u7ec3\u4f1a\u5bfc\u81f4\u8bad\u7ec3\u548c\u7ef4\u62a4\u6210\u672c\u6307\u6570\u7ea7\u589e\u957f\uff0c\u800c\u63d0\u793a\u6216\u6a21\u5f0f\u65b9\u6cd5\u5728\u5206\u5e03\u504f\u79fb\u548c\u590d\u6742\u63a5\u53e3\u4e0b\u8868\u73b0\u8106\u5f31\u3002", "method": "\u63d0\u51fa\u6fc0\u6d3b\u5bfc\u5411\u9002\u914d\u5668\uff08ASA\uff09\uff0c\u8fd9\u662f\u4e00\u79cd\u8f7b\u91cf\u7ea7\u3001\u63a8\u7406\u65f6\u3001\u65e0\u9700\u8bad\u7ec3\u7684\u673a\u5236\u3002\u5b83\u4ece\u4e2d\u95f4\u6fc0\u6d3b\u4e2d\u8bfb\u53d6\u8def\u7531\u4fe1\u53f7\uff0c\u4f7f\u7528\u8d85\u8f7b\u91cf\u8def\u7531\u5668\u4ea7\u751f\u81ea\u9002\u5e94\u63a7\u5236\u5f3a\u5ea6\uff0c\u5b9e\u73b0\u7cbe\u786e\u7684\u9886\u57df\u5bf9\u9f50\u3002", "result": "\u5728\u591a\u4e2a\u6a21\u578b\u89c4\u6a21\u548c\u9886\u57df\u4e0a\uff0cASA\u5b9e\u73b0\u4e86\u4e0eLoRA\u76f8\u5f53\u7684\u9002\u5e94\u6548\u679c\uff0c\u4f46\u5f00\u9500\u663e\u8457\u964d\u4f4e\uff0c\u5e76\u5177\u6709\u5f3a\u5927\u7684\u8de8\u6a21\u578b\u53ef\u8f6c\u79fb\u6027\u3002", "conclusion": "ASA\u975e\u5e38\u9002\u5408\u5177\u6709\u9891\u7e41\u63a5\u53e3\u53d8\u5316\u7684\u7a33\u5065\u3001\u53ef\u6269\u5c55\u548c\u9ad8\u6548\u7684\u591a\u9886\u57df\u5de5\u5177\u751f\u6001\u7cfb\u7edf\uff0c\u4e3aLLM\u667a\u80fd\u4f53\u7684\u5b9e\u9645\u90e8\u7f72\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.05754", "categories": ["cs.DC", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.05754", "abs": "https://arxiv.org/abs/2602.05754", "authors": ["Seonghye Cho", "Jaemin Han", "Hyunjin Kim", "Euisoo Jung", "Jae-Gil Lee"], "title": "TimelyFreeze: Adaptive Parameter Freezing Mechanism for Pipeline Parallelism", "comment": null, "summary": "Pipeline parallelism enables training models that exceed single-device memory, but practical throughput remains limited by pipeline bubbles. Although parameter freezing can improve training throughput by adaptively skipping backward computation, existing methods often over-freeze parameters, resulting in unnecessary accuracy degradation. To address this issue, we propose TimelyFreeze, which models the pipeline schedule as a directed acyclic graph and solves a linear program to compute optimal freeze ratios that minimize batch execution time under accuracy constraints. Experiments show that TimelyFreeze achieves up to 40% training throughput improvement on LLaMA-8B with comparable accuracy. Overall, it enables faster large-scale model training without compromising convergence and generalizes across diverse pipeline-parallel settings.", "AI": {"tldr": "TimelyFreeze\uff1a\u4e00\u79cd\u901a\u8fc7\u5efa\u6a21\u6d41\u6c34\u7ebf\u8c03\u5ea6\u4e3a\u6709\u5411\u65e0\u73af\u56fe\u5e76\u6c42\u89e3\u7ebf\u6027\u89c4\u5212\u95ee\u9898\u6765\u8ba1\u7b97\u6700\u4f18\u51bb\u7ed3\u6bd4\u4f8b\u7684\u65b9\u6cd5\uff0c\u5728\u4fdd\u8bc1\u7cbe\u5ea6\u7684\u524d\u63d0\u4e0b\u51cf\u5c11\u6d41\u6c34\u7ebf\u6c14\u6ce1\uff0c\u63d0\u5347\u8bad\u7ec3\u541e\u5410\u91cf", "motivation": "\u6d41\u6c34\u7ebf\u5e76\u884c\u867d\u7136\u80fd\u8bad\u7ec3\u8d85\u51fa\u5355\u8bbe\u5907\u5185\u5b58\u7684\u6a21\u578b\uff0c\u4f46\u5b9e\u9645\u541e\u5410\u91cf\u53d7\u9650\u4e8e\u6d41\u6c34\u7ebf\u6c14\u6ce1\u3002\u73b0\u6709\u7684\u53c2\u6570\u51bb\u7ed3\u65b9\u6cd5\u867d\u7136\u80fd\u901a\u8fc7\u81ea\u9002\u5e94\u8df3\u8fc7\u53cd\u5411\u8ba1\u7b97\u6765\u63d0\u9ad8\u8bad\u7ec3\u541e\u5410\u91cf\uff0c\u4f46\u5f80\u5f80\u8fc7\u5ea6\u51bb\u7ed3\u53c2\u6570\uff0c\u5bfc\u81f4\u4e0d\u5fc5\u8981\u7684\u7cbe\u5ea6\u4e0b\u964d\u3002", "method": "\u5c06\u6d41\u6c34\u7ebf\u8c03\u5ea6\u5efa\u6a21\u4e3a\u6709\u5411\u65e0\u73af\u56fe\uff0c\u901a\u8fc7\u6c42\u89e3\u7ebf\u6027\u89c4\u5212\u95ee\u9898\u8ba1\u7b97\u6700\u4f18\u51bb\u7ed3\u6bd4\u4f8b\uff0c\u5728\u7cbe\u5ea6\u7ea6\u675f\u4e0b\u6700\u5c0f\u5316\u6279\u6b21\u6267\u884c\u65f6\u95f4\u3002\u8be5\u65b9\u6cd5\u80fd\u81ea\u9002\u5e94\u5730\u786e\u5b9a\u54ea\u4e9b\u53c2\u6570\u5e94\u8be5\u51bb\u7ed3\uff0c\u907f\u514d\u8fc7\u5ea6\u51bb\u7ed3\u3002", "result": "\u5728LLaMA-8B\u6a21\u578b\u4e0a\u5b9e\u73b0\u4e86\u9ad8\u8fbe40%\u7684\u8bad\u7ec3\u541e\u5410\u91cf\u63d0\u5347\uff0c\u540c\u65f6\u4fdd\u6301\u53ef\u6bd4\u7684\u7cbe\u5ea6\u3002\u8be5\u65b9\u6cd5\u5728\u4e0d\u5f71\u54cd\u6536\u655b\u7684\u60c5\u51b5\u4e0b\u52a0\u901f\u5927\u89c4\u6a21\u6a21\u578b\u8bad\u7ec3\uff0c\u5e76\u80fd\u6cdb\u5316\u5230\u4e0d\u540c\u7684\u6d41\u6c34\u7ebf\u5e76\u884c\u8bbe\u7f6e\u3002", "conclusion": "TimelyFreeze\u901a\u8fc7\u4f18\u5316\u53c2\u6570\u51bb\u7ed3\u7b56\u7565\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u6d41\u6c34\u7ebf\u5e76\u884c\u4e2d\u7684\u6c14\u6ce1\u95ee\u9898\uff0c\u5728\u4fdd\u8bc1\u6a21\u578b\u7cbe\u5ea6\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u4e86\u8bad\u7ec3\u6548\u7387\uff0c\u4e3a\u5927\u89c4\u6a21\u6a21\u578b\u8bad\u7ec3\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.05503", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2602.05503", "abs": "https://arxiv.org/abs/2602.05503", "authors": ["Christopher Spinrath", "Angela Bonifati", "Rachid Echahed"], "title": "Repairing Property Graphs under PG-Constraints", "comment": "This paper, without the appendix, has been accepted for publication in Volume 19 of PVLDB", "summary": "Recent standardization efforts for graph databases lead to standard query languages like GQL and SQL/PGQ, and constraint languages like Property Graph Constraints (PG-Constraints). In this paper, we embark on the study of repairing property graphs under PG-Constraints. We identify a significant subset of PG-Constraints, encoding denial constraints and including recursion as a key feature, while still permitting automata-based structural analyses of errors. We present a comprehensive repair pipeline for these constraints to repair Property Graphs, involving changes in the graph topology and leading to node, edge and, optionally, label deletions. We investigate three algorithmic strategies for the repair procedure, based on Integer Linear Programming (ILP), a naive, and an LP-guided greedy algorithm. Our experiments on various real-world datasets reveal that repairing with label deletions can achieve a 59% reduction in deletions compared to node/edge deletions. Moreover, the LP-guided greedy algorithm offers a runtime advantage of up to 97% compared to the ILP strategy, while matching the same quality.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u5728PG-Constraints\u7ea6\u675f\u4e0b\u4fee\u590d\u5c5e\u6027\u56fe\uff0c\u63d0\u51fa\u5305\u542bILP\u3001\u6734\u7d20\u548cLP\u5f15\u5bfc\u8d2a\u5fc3\u7b97\u6cd5\u7684\u4fee\u590d\u6d41\u7a0b\uff0c\u5b9e\u9a8c\u663e\u793a\u6807\u7b7e\u5220\u9664\u6bd4\u8282\u70b9/\u8fb9\u5220\u9664\u51cf\u5c1159%\u5220\u9664\u91cf\uff0cLP\u5f15\u5bfc\u8d2a\u5fc3\u7b97\u6cd5\u6bd4ILP\u5feb97%\u4e14\u8d28\u91cf\u76f8\u5f53\u3002", "motivation": "\u968f\u7740GQL\u548cSQL/PGQ\u7b49\u56fe\u6570\u636e\u5e93\u6807\u51c6\u67e5\u8be2\u8bed\u8a00\u4ee5\u53caPG-Constraints\u7ea6\u675f\u8bed\u8a00\u7684\u51fa\u73b0\uff0c\u9700\u8981\u5728PG-Constraints\u7ea6\u675f\u4e0b\u4fee\u590d\u5c5e\u6027\u56fe\u7684\u95ee\u9898\u53d8\u5f97\u91cd\u8981\u3002\u73b0\u6709\u7814\u7a76\u7f3a\u4e4f\u5bf9\u8fd9\u7c7b\u7ea6\u675f\u4e0b\u56fe\u4fee\u590d\u7684\u7cfb\u7edf\u6027\u65b9\u6cd5\u3002", "method": "\u8bc6\u522bPG-Constraints\u7684\u91cd\u8981\u5b50\u96c6\uff08\u5305\u542b\u5426\u5b9a\u7ea6\u675f\u548c\u9012\u5f52\uff09\uff0c\u63d0\u51fa\u5b8c\u6574\u7684\u56fe\u4fee\u590d\u6d41\u7a0b\uff0c\u6d89\u53ca\u56fe\u62d3\u6251\u7ed3\u6784\u53d8\u66f4\u548c\u8282\u70b9\u3001\u8fb9\u3001\u6807\u7b7e\u5220\u9664\u3002\u5f00\u53d1\u4e09\u79cd\u4fee\u590d\u7b97\u6cd5\u7b56\u7565\uff1a\u6574\u6570\u7ebf\u6027\u89c4\u5212(ILP)\u3001\u6734\u7d20\u7b97\u6cd5\u3001LP\u5f15\u5bfc\u8d2a\u5fc3\u7b97\u6cd5\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff1a1) \u4f7f\u7528\u6807\u7b7e\u5220\u9664\u76f8\u6bd4\u8282\u70b9/\u8fb9\u5220\u9664\u53ef\u51cf\u5c1159%\u7684\u5220\u9664\u64cd\u4f5c\uff1b2) LP\u5f15\u5bfc\u8d2a\u5fc3\u7b97\u6cd5\u76f8\u6bd4ILP\u7b56\u7565\u8fd0\u884c\u65f6\u95f4\u51cf\u5c11\u9ad8\u8fbe97%\uff0c\u540c\u65f6\u4fdd\u6301\u76f8\u540c\u7684\u4fee\u590d\u8d28\u91cf\u3002", "conclusion": "\u8bba\u6587\u4e3aPG-Constraints\u7ea6\u675f\u4e0b\u7684\u5c5e\u6027\u56fe\u4fee\u590d\u63d0\u4f9b\u4e86\u7cfb\u7edf\u65b9\u6cd5\uff0cLP\u5f15\u5bfc\u8d2a\u5fc3\u7b97\u6cd5\u5728\u6548\u7387\u548c\u8d28\u91cf\u4e0a\u53d6\u5f97\u826f\u597d\u5e73\u8861\uff0c\u6807\u7b7e\u5220\u9664\u7b56\u7565\u663e\u8457\u51cf\u5c11\u4fee\u590d\u4ee3\u4ef7\uff0c\u5bf9\u56fe\u6570\u636e\u5e93\u7ea6\u675f\u7ef4\u62a4\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2602.04938", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.04938", "abs": "https://arxiv.org/abs/2602.04938", "authors": ["Lukas Radosky", "Ivan Polasek"], "title": "Large Language Models in Software Documentation and Modeling: A Literature Review and Findings", "comment": "This is a preprint of a paper that was presented at the IEEE 24th World Symposium on Applied Machine Intelligence and Informatics (SAMI 2026)", "summary": "Generative artificial intelligence attracts significant attention, especially with the introduction of large language models. Its capabilities are being exploited to solve various software engineering tasks. Thanks to their ability to understand natural language and generate natural language responses, large language models are great for processing various software documentation artifacts. At the same time, large language models excel at understanding structured languages, having the potential for working with software programs and models. We conduct a literature review on the usage of large language models for software engineering tasks related to documentation and modeling. We analyze articles from four major venues in the area, organize them per tasks they solve, and provide an overview of used prompt techniques, metrics, approaches to human-based evaluation, and major datasets.", "AI": {"tldr": "\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u8f6f\u4ef6\u5de5\u7a0b\u6587\u6863\u548c\u5efa\u6a21\u4efb\u52a1\u4e2d\u5e94\u7528\u7684\u6587\u732e\u7efc\u8ff0\uff0c\u5206\u6790\u76f8\u5173\u7814\u7a76\u3001\u4efb\u52a1\u5206\u7c7b\u3001\u63d0\u793a\u6280\u672f\u3001\u8bc4\u4f30\u65b9\u6cd5\u548c\u6570\u636e\u96c6", "motivation": "\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\u7279\u522b\u662f\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u8f6f\u4ef6\u5de5\u7a0b\u9886\u57df\u53d7\u5230\u5e7f\u6cdb\u5173\u6ce8\uff0c\u5b83\u4eec\u80fd\u591f\u7406\u89e3\u81ea\u7136\u8bed\u8a00\u548c\u7ed3\u6784\u5316\u8bed\u8a00\uff0c\u9002\u5408\u5904\u7406\u8f6f\u4ef6\u6587\u6863\u548c\u6a21\u578b\u3002\u9700\u8981\u7cfb\u7edf\u68b3\u7406LLM\u5728\u8f6f\u4ef6\u5de5\u7a0b\u6587\u6863\u548c\u5efa\u6a21\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\u73b0\u72b6\u3002", "method": "\u5bf9\u56db\u4e2a\u4e3b\u8981\u76f8\u5173\u9886\u57df\u7684\u6587\u732e\u8fdb\u884c\u7efc\u8ff0\uff0c\u6309\u4efb\u52a1\u7c7b\u578b\u7ec4\u7ec7\u6587\u7ae0\uff0c\u5206\u6790\u4f7f\u7528\u7684\u63d0\u793a\u6280\u672f\u3001\u8bc4\u4f30\u6307\u6807\u3001\u4eba\u5de5\u8bc4\u4f30\u65b9\u6cd5\u548c\u4e3b\u8981\u6570\u636e\u96c6\u3002", "result": "\u63d0\u4f9b\u4e86LLM\u5728\u8f6f\u4ef6\u5de5\u7a0b\u6587\u6863\u548c\u5efa\u6a21\u4efb\u52a1\u5e94\u7528\u7684\u7cfb\u7edf\u6027\u7efc\u8ff0\uff0c\u5305\u62ec\u4efb\u52a1\u5206\u7c7b\u6846\u67b6\u3001\u5e38\u7528\u6280\u672f\u65b9\u6cd5\u3001\u8bc4\u4f30\u4f53\u7cfb\u7b49\uff0c\u4e3a\u7814\u7a76\u8005\u63d0\u4f9b\u8be5\u9886\u57df\u7684\u5168\u9762\u6982\u89c8\u3002", "conclusion": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u8f6f\u4ef6\u5de5\u7a0b\u6587\u6863\u548c\u5efa\u6a21\u4efb\u52a1\u4e2d\u5177\u6709\u91cd\u8981\u5e94\u7528\u4ef7\u503c\uff0c\u672c\u6587\u7684\u7efc\u8ff0\u4e3a\u76f8\u5173\u7814\u7a76\u63d0\u4f9b\u4e86\u7cfb\u7edf\u6027\u7684\u53c2\u8003\u6846\u67b6\u548c\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2602.05948", "categories": ["cs.DC", "cs.DS", "cs.MA", "cs.RO"], "pdf": "https://arxiv.org/pdf/2602.05948", "abs": "https://arxiv.org/abs/2602.05948", "authors": ["Himani", "Supantha Pandit", "Gokarna Sharma"], "title": "Location-Aware Dispersion on Anonymous Graphs", "comment": "3 tables, 2 figures, 6 pseudo-codes", "summary": "The well-studied DISPERSION problem is a fundamental coordination problem in distributed robotics, where a set of mobile robots must relocate so that each occupies a distinct node of a network. DISPERSION assumes that a robot can settle at any node as long as no other robot settles on that node. In this work, we introduce LOCATION-AWARE DISPERSION, a novel generalization of DISPERSION that incorporates location awareness: Let $G = (V, E)$ be an anonymous, connected, undirected graph with $n = |V|$ nodes, each labeled with a color $\\sf{col}(v) \\in C = \\{c_1, \\dots, c_t\\}, t\\leq n$. A set $R = \\{r_1, \\dots, r_k\\}$ of $k \\leq n$ mobile robots is given, where each robot $r_i$ has an associated color $\\mathsf{col}(r_i) \\in C$. Initially placed arbitrarily on the graph, the goal is to relocate the robots so that each occupies a distinct node of the same color. When $|C|=1$, LOCATION-AWARE DISPERSION reduces to DISPERSION. There is a solution to DISPERSION in graphs with any $k\\leq n$ without knowing $k,n$.\n  Like DISPERSION, the goal is to solve LOCATION-AWARE DISPERSION minimizing both time and memory requirement at each agent. We develop several deterministic algorithms with guaranteed bounds on both time and memory requirement. We also give an impossibility and a lower bound for any deterministic algorithm for LOCATION-AWARE DISPERSION. To the best of our knowledge, the presented results collectively establish the algorithmic feasibility of LOCATION-AWARE DISPERSION in anonymous networks and also highlight the challenges on getting an efficient solution compared to the solutions for DISPERSION.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4f4d\u7f6e\u611f\u77e5\u5206\u6563\u95ee\u9898\uff0c\u8fd9\u662f\u7ecf\u5178\u5206\u6563\u95ee\u9898\u7684\u65b0\u63a8\u5e7f\uff0c\u8981\u6c42\u673a\u5668\u4eba\u6839\u636e\u989c\u8272\u5339\u914d\u79fb\u52a8\u5230\u5bf9\u5e94\u989c\u8272\u7684\u8282\u70b9\u4e0a\uff0c\u5e76\u8bbe\u8ba1\u4e86\u786e\u5b9a\u6027\u7b97\u6cd5\uff0c\u7ed9\u51fa\u4e86\u65f6\u95f4\u4e0e\u5185\u5b58\u7684\u754c\u9650\uff0c\u540c\u65f6\u8bc1\u660e\u4e86\u4e0d\u53ef\u80fd\u6027\u548c\u4e0b\u754c\u3002", "motivation": "\u7ecf\u5178\u5206\u6563\u95ee\u9898\u53ea\u8981\u6c42\u673a\u5668\u4eba\u5360\u636e\u4e0d\u540c\u8282\u70b9\uff0c\u4e0d\u8003\u8651\u8282\u70b9\u5c5e\u6027\u3002\u5b9e\u9645\u5e94\u7528\u4e2d\uff0c\u673a\u5668\u4eba\u53ef\u80fd\u9700\u8981\u79fb\u52a8\u5230\u7279\u5b9a\u7c7b\u578b\u7684\u8282\u70b9\uff08\u5982\u5145\u7535\u7ad9\u3001\u5de5\u4f5c\u7ad9\u7b49\uff09\u3002\u4f4d\u7f6e\u611f\u77e5\u5206\u6563\u95ee\u9898\u5f15\u5165\u4e86\u989c\u8272\u6807\u7b7e\uff0c\u8981\u6c42\u673a\u5668\u4eba\u79fb\u52a8\u5230\u4e0e\u5176\u989c\u8272\u5339\u914d\u7684\u8282\u70b9\uff0c\u8fd9\u66f4\u8d34\u8fd1\u5b9e\u9645\u673a\u5668\u4eba\u534f\u8c03\u9700\u6c42\u3002", "method": "\u63d0\u51fa\u4e86\u4f4d\u7f6e\u611f\u77e5\u5206\u6563\u95ee\u9898\u7684\u5f62\u5f0f\u5316\u5b9a\u4e49\uff0c\u5f00\u53d1\u4e86\u591a\u4e2a\u786e\u5b9a\u6027\u7b97\u6cd5\uff0c\u8fd9\u4e9b\u7b97\u6cd5\u4fdd\u8bc1\u5728\u533f\u540d\u3001\u8fde\u901a\u3001\u65e0\u5411\u56fe\u4e0a\u5de5\u4f5c\u3002\u7b97\u6cd5\u8bbe\u8ba1\u8003\u8651\u4e86\u65f6\u95f4\u590d\u6742\u5ea6\u548c\u5185\u5b58\u9700\u6c42\u7684\u6700\u5c0f\u5316\u3002\u540c\u65f6\u7ed9\u51fa\u4e86\u4e0d\u53ef\u80fd\u6027\u8bc1\u660e\u548c\u4efb\u610f\u786e\u5b9a\u6027\u7b97\u6cd5\u7684\u4e0b\u754c\u3002", "result": "\u8bc1\u660e\u4e86\u4f4d\u7f6e\u611f\u77e5\u5206\u6563\u95ee\u9898\u5728\u533f\u540d\u7f51\u7edc\u4e2d\u7684\u7b97\u6cd5\u53ef\u884c\u6027\uff0c\u7ed9\u51fa\u4e86\u5177\u6709\u65f6\u95f4\u4e0e\u5185\u5b58\u4fdd\u8bc1\u754c\u9650\u7684\u786e\u5b9a\u6027\u7b97\u6cd5\u3002\u5f53\u989c\u8272\u96c6\u5408\u5927\u5c0f\u4e3a1\u65f6\uff0c\u95ee\u9898\u9000\u5316\u4e3a\u7ecf\u5178\u5206\u6563\u95ee\u9898\u3002\u4e0e\u7ecf\u5178\u5206\u6563\u76f8\u6bd4\uff0c\u4f4d\u7f6e\u611f\u77e5\u5206\u6563\u5728\u6548\u7387\u4e0a\u9762\u4e34\u66f4\u5927\u6311\u6218\u3002", "conclusion": "\u4f4d\u7f6e\u611f\u77e5\u5206\u6563\u95ee\u9898\u662f\u5206\u6563\u95ee\u9898\u7684\u6709\u610f\u4e49\u63a8\u5e7f\uff0c\u5728\u533f\u540d\u7f51\u7edc\u4e2d\u7b97\u6cd5\u53ef\u884c\u4f46\u6bd4\u7ecf\u5178\u5206\u6563\u66f4\u5177\u6311\u6218\u6027\u3002\u8bba\u6587\u5efa\u7acb\u4e86\u8be5\u95ee\u9898\u7684\u7406\u8bba\u57fa\u7840\uff0c\u63d0\u4f9b\u4e86\u7b97\u6cd5\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u63ed\u793a\u4e86\u5176\u56fa\u6709\u7684\u590d\u6742\u6027\u9650\u5236\u3002"}}
{"id": "2602.05540", "categories": ["cs.DB", "cs.OS"], "pdf": "https://arxiv.org/pdf/2602.05540", "abs": "https://arxiv.org/abs/2602.05540", "authors": ["Felix Schuhknecht", "Nick Rassau"], "title": "Taking the Leap: Efficient and Reliable Fine-Grained NUMA Migration in User-space", "comment": null, "summary": "Modern multi-socket architectures offer a single virtual address space, but physically divide main-memory across multiple regions, where each region is attached to a CPU and its cores. While this simplifies the usage, developers must be aware of non-uniform memory access (NUMA), where an access by a thread running on a core-local NUMA region is significantly cheaper than an access from a core-remote region. Obviously, if query answering is parallelized across the cores of multiple regions, then the portion of the database on which the query is operating should be distributed across the same regions to ensure local accesses. As the present data placement might not fit this, migrating pages from one NUMA region to another can be performed to improve the situation. To do so, different options exist: One option is to rely on automatic NUMA balancing integrated in Linux, which is steered by the observed access patterns and frequency. Another option is to actively trigger migration via the system call move_pages(). Unfortunately, both variants have significant downsides in terms of their feature set and performance. As an alternative, we propose a new user-space migration method called page_leap() that can perform page migration asynchronously at a high performance by exploiting features of the virtual memory subsystem. The method is (a) actively triggered by the user, (b) ensures that all pages are eventually migrated, (c) handles concurrent writes correctly, (d) supports pooled memory, (e) adaptively adjusts its migration granularity based on the workload, and (f) supports both small pages and huge pages.", "AI": {"tldr": "\u63d0\u51fapage_leap()\u7528\u6237\u7a7a\u95f4\u9875\u9762\u8fc1\u79fb\u65b9\u6cd5\uff0c\u89e3\u51b3NUMA\u67b6\u6784\u4e0b\u5185\u5b58\u8bbf\u95ee\u6027\u80fd\u95ee\u9898\uff0c\u76f8\u6bd4\u73b0\u6709\u65b9\u6848\u5177\u6709\u66f4\u9ad8\u6027\u80fd\u548c\u66f4\u5b8c\u6574\u529f\u80fd", "motivation": "\u73b0\u4ee3\u591a\u63d2\u69fd\u67b6\u6784\u867d\u7136\u63d0\u4f9b\u5355\u4e00\u865a\u62df\u5730\u5740\u7a7a\u95f4\uff0c\u4f46\u7269\u7406\u5185\u5b58\u5206\u5e03\u5728\u591a\u4e2aNUMA\u533a\u57df\u3002\u5f53\u67e5\u8be2\u5e76\u884c\u5316\u8de8\u591a\u4e2a\u533a\u57df\u6838\u5fc3\u6267\u884c\u65f6\uff0c\u6570\u636e\u5e94\u5206\u5e03\u5728\u76f8\u540c\u533a\u57df\u4ee5\u786e\u4fdd\u672c\u5730\u8bbf\u95ee\u3002\u73b0\u6709\u8fc1\u79fb\u65b9\u6848\uff08Linux\u81ea\u52a8NUMA\u5e73\u8861\u548cmove_pages()\u7cfb\u7edf\u8c03\u7528\uff09\u5728\u529f\u80fd\u96c6\u548c\u6027\u80fd\u65b9\u9762\u5b58\u5728\u663e\u8457\u7f3a\u9677\u3002", "method": "\u63d0\u51fapage_leap()\u7528\u6237\u7a7a\u95f4\u8fc1\u79fb\u65b9\u6cd5\uff0c\u901a\u8fc7\u5229\u7528\u865a\u62df\u5185\u5b58\u5b50\u7cfb\u7edf\u7279\u6027\u5b9e\u73b0\u5f02\u6b65\u9ad8\u6027\u80fd\u9875\u9762\u8fc1\u79fb\u3002\u8be5\u65b9\u6cd5\u5177\u6709\u4ee5\u4e0b\u7279\u70b9\uff1a(a) \u7528\u6237\u4e3b\u52a8\u89e6\u53d1\uff0c(b) \u786e\u4fdd\u6240\u6709\u9875\u9762\u6700\u7ec8\u8fc1\u79fb\uff0c(c) \u6b63\u786e\u5904\u7406\u5e76\u53d1\u5199\u5165\uff0c(d) \u652f\u6301\u6c60\u5316\u5185\u5b58\uff0c(e) \u6839\u636e\u5de5\u4f5c\u8d1f\u8f7d\u81ea\u9002\u5e94\u8c03\u6574\u8fc1\u79fb\u7c92\u5ea6\uff0c(f) \u652f\u6301\u5c0f\u9875\u9762\u548c\u5927\u9875\u9762\u3002", "result": "\u8bba\u6587\u672a\u63d0\u4f9b\u5177\u4f53\u5b9e\u9a8c\u7ed3\u679c\uff0c\u4f46\u4ece\u65b9\u6cd5\u63cf\u8ff0\u6765\u770b\uff0cpage_leap()\u76f8\u6bd4\u73b0\u6709\u65b9\u6848\u5728\u529f\u80fd\u548c\u6027\u80fd\u65b9\u9762\u90fd\u6709\u663e\u8457\u6539\u8fdb\uff0c\u80fd\u591f\u66f4\u6709\u6548\u5730\u4f18\u5316NUMA\u67b6\u6784\u4e0b\u7684\u5185\u5b58\u8bbf\u95ee\u6027\u80fd\u3002", "conclusion": "page_leap()\u4f5c\u4e3a\u4e00\u79cd\u65b0\u7684\u7528\u6237\u7a7a\u95f4\u9875\u9762\u8fc1\u79fb\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86\u73b0\u6709NUMA\u9875\u9762\u8fc1\u79fb\u65b9\u6848\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u6570\u636e\u5e93\u7b49\u5e76\u884c\u5e94\u7528\u5728NUMA\u67b6\u6784\u4e0a\u5b9e\u73b0\u9ad8\u6548\u5185\u5b58\u8bbf\u95ee\u63d0\u4f9b\u4e86\u66f4\u597d\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.05042", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.05042", "abs": "https://arxiv.org/abs/2602.05042", "authors": ["Lucas Romao", "Luiz Xavier", "J\u00falia Cond\u00e9 Ara\u00fajo", "Marina Cond\u00e9 Ara\u00fajo", "Ariane Rodrigues", "Marcos Kalinowski"], "title": "Applying a Requirements-Focused Agile Management Approach for Machine Learning-Enabled Systems", "comment": "Accepted for publication at the 5th International Conference on AI Engineering - Software Engineering for AI (CAIN) 2026", "summary": "Machine Learning (ML)-enabled systems challenge traditional Requirements Engineering (RE) and agile management due to data dependence, experimentation, and uncertain model behavior. Existing RE and agile practices remain poorly integrated and insufficiently tailored to these characteristics. This paper reports on the practical experience of applying RefineML, a requirements-focused approach for the continuous and agile refinement of ML-enabled systems, which integrates ML-tailored specification and agile management approaches with best practices derived from a systematic mapping study. The application context concerns an industry-academia collaboration project between PUC-Rio and EXA, a Brazilian cybersecurity company. For evaluation purposes, we applied questionnaires assessing RefineML's suitability and overall acceptance and semi-structured interviews. We applied thematic analysis to the collected qualitative data. Regarding suitability and acceptance, the results of the questionnaires indicated high perceived usefulness and intention to use. Based on the interviews, stakeholders perceived RefineML as improving communication and facilitating early feasibility assessments, as well as enabling dual-track governance of ML and software work, allowing continuous refinement of the model while evolving the overall software project. However, some limitations remain, particularly related to difficulties in operationalizing ML concerns into agile requirements and in estimating ML effort.", "AI": {"tldr": "RefineML\u662f\u4e00\u4e2a\u9762\u5411\u9700\u6c42\u7684\u6301\u7eed\u654f\u6377\u65b9\u6cd5\uff0c\u7528\u4e8eML\u7cfb\u7edf\u5f00\u53d1\uff0c\u96c6\u6210\u4e86ML\u5b9a\u5236\u89c4\u8303\u548c\u654f\u6377\u7ba1\u7406\uff0c\u5728\u5de5\u4e1a-\u5b66\u672f\u5408\u4f5c\u9879\u76ee\u4e2d\u9a8c\u8bc1\u6709\u6548\u3002", "motivation": "\u673a\u5668\u5b66\u4e60\u7cfb\u7edf\u5bf9\u4f20\u7edf\u9700\u6c42\u5de5\u7a0b\u548c\u654f\u6377\u7ba1\u7406\u63d0\u51fa\u6311\u6218\uff0c\u5305\u62ec\u6570\u636e\u4f9d\u8d56\u6027\u3001\u5b9e\u9a8c\u6027\u548c\u6a21\u578b\u884c\u4e3a\u4e0d\u786e\u5b9a\u6027\u3002\u73b0\u6709\u65b9\u6cd5\u96c6\u6210\u4e0d\u8db3\u4e14\u672a\u9488\u5bf9ML\u7279\u6027\u5b9a\u5236\u3002", "method": "\u63d0\u51faRefineML\u65b9\u6cd5\uff0c\u96c6\u6210ML\u5b9a\u5236\u89c4\u8303\u3001\u654f\u6377\u7ba1\u7406\u65b9\u6cd5\u548c\u7cfb\u7edf\u6620\u5c04\u7814\u7a76\u7684\u6700\u4f73\u5b9e\u8df5\u3002\u901a\u8fc7\u4e0e\u5df4\u897f\u7f51\u7edc\u5b89\u5168\u516c\u53f8EXA\u7684\u5de5\u4e1a-\u5b66\u672f\u5408\u4f5c\u9879\u76ee\u8fdb\u884c\u5e94\u7528\u8bc4\u4f30\uff0c\u4f7f\u7528\u95ee\u5377\u8c03\u67e5\u548c\u534a\u7ed3\u6784\u5316\u8bbf\u8c08\u6536\u96c6\u6570\u636e\uff0c\u5e76\u8fdb\u884c\u4e3b\u9898\u5206\u6790\u3002", "result": "\u95ee\u5377\u8c03\u67e5\u663e\u793aRefineML\u5177\u6709\u9ad8\u611f\u77e5\u6709\u7528\u6027\u548c\u4f7f\u7528\u610f\u613f\u3002\u8bbf\u8c08\u8868\u660eRefineML\u80fd\u6539\u5584\u6c9f\u901a\u3001\u4fc3\u8fdb\u65e9\u671f\u53ef\u884c\u6027\u8bc4\u4f30\uff0c\u5e76\u5b9e\u73b0ML\u548c\u8f6f\u4ef6\u5de5\u4f5c\u7684\u53cc\u8f68\u6cbb\u7406\uff0c\u5141\u8bb8\u5728\u6f14\u8fdb\u8f6f\u4ef6\u9879\u76ee\u7684\u540c\u65f6\u6301\u7eed\u7cbe\u70bc\u6a21\u578b\u3002\u4f46\u4ecd\u5b58\u5728\u5c06ML\u5173\u6ce8\u70b9\u64cd\u4f5c\u5316\u4e3a\u654f\u6377\u9700\u6c42\u4ee5\u53ca\u4f30\u7b97ML\u5de5\u4f5c\u91cf\u7684\u56f0\u96be\u3002", "conclusion": "RefineML\u4e3aML\u7cfb\u7edf\u5f00\u53d1\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u9700\u6c42\u5bfc\u5411\u654f\u6377\u65b9\u6cd5\uff0c\u6539\u5584\u4e86\u56e2\u961f\u6c9f\u901a\u548c\u9879\u76ee\u6cbb\u7406\uff0c\u4f46\u9700\u8981\u8fdb\u4e00\u6b65\u89e3\u51b3ML\u9700\u6c42\u64cd\u4f5c\u5316\u548c\u5de5\u4f5c\u91cf\u4f30\u7b97\u7684\u6311\u6218\u3002"}}
{"id": "2602.05458", "categories": ["cs.SE", "cs.DC", "cs.PF", "eess.SY"], "pdf": "https://arxiv.org/pdf/2602.05458", "abs": "https://arxiv.org/abs/2602.05458", "authors": ["Anatoly A. Krasnovsky"], "title": "Emergence-as-Code for Self-Governing Reliable Systems", "comment": null, "summary": "SLO-as-code has made per-service} reliability declarative, but user experience is defined by journeys whose reliability is an emergent property of microservice topology, routing, redundancy, timeouts/fallbacks, shared failure domains, and tail amplification. As a result, journey objectives (e.g., \"checkout p99 < 400 ms\") are often maintained outside code and drift as the system evolves, forcing teams to either miss user expectations or over-provision and gate releases with ad-hoc heuristics. We propose Emergence-as-Code (EmaC), a vision for making journey reliability computable and governable via intent plus evidence. An EmaC spec declares journey intent (objective, control-flow operators, allowed actions) and binds it to atomic SLOs and telemetry. A runtime inference component consumes operational artifacts (e.g., tracing and traffic configuration) to synthesize a candidate journey model with provenance and confidence. From the last accepted model, the EmaC compiler/controller derives bounded journey SLOs and budgets under explicit correlation assumptions (optimistic independence vs. pessimistic shared fate), and emits control-plane artifacts (burn-rate alerts, rollout gates, action guards) that are reviewable in a Git workflow. An anonymized artifact repository provides a runnable example specification and generated outputs.", "AI": {"tldr": "\u63d0\u51faEmergence-as-Code (EmaC)\u6846\u67b6\uff0c\u4f7f\u5fae\u670d\u52a1\u65c5\u7a0b\u53ef\u9760\u6027\u53ef\u8ba1\u7b97\u548c\u53ef\u6cbb\u7406\uff0c\u901a\u8fc7\u610f\u56fe\u58f0\u660e\u548c\u8fd0\u884c\u65f6\u63a8\u7406\u6765\u7ba1\u7406\u7528\u6237\u65c5\u7a0b\u7684SLO", "motivation": "\u867d\u7136SLO-as-code\u4f7f\u5355\u4e2a\u670d\u52a1\u53ef\u9760\u6027\u53ef\u58f0\u660e\uff0c\u4f46\u7528\u6237\u65c5\u7a0b\u7684\u53ef\u9760\u6027\u662f\u5fae\u670d\u52a1\u62d3\u6251\u3001\u8def\u7531\u3001\u5197\u4f59\u3001\u8d85\u65f6/\u56de\u9000\u3001\u5171\u4eab\u6545\u969c\u57df\u548c\u5c3e\u90e8\u653e\u5927\u7684\u6d8c\u73b0\u5c5e\u6027\u3002\u65c5\u7a0b\u76ee\u6807\u901a\u5e38\u7ef4\u62a4\u5728\u4ee3\u7801\u4e4b\u5916\uff0c\u968f\u7740\u7cfb\u7edf\u6f14\u8fdb\u800c\u6f02\u79fb\uff0c\u5bfc\u81f4\u56e2\u961f\u8981\u4e48\u9519\u8fc7\u7528\u6237\u671f\u671b\uff0c\u8981\u4e48\u8fc7\u5ea6\u914d\u7f6e\u5e76\u4f7f\u7528\u4e34\u65f6\u542f\u53d1\u5f0f\u65b9\u6cd5\u63a7\u5236\u53d1\u5e03", "method": "\u63d0\u51faEmaC\u6846\u67b6\uff1a1) EmaC\u89c4\u8303\u58f0\u660e\u65c5\u7a0b\u610f\u56fe\uff08\u76ee\u6807\u3001\u63a7\u5236\u6d41\u64cd\u4f5c\u7b26\u3001\u5141\u8bb8\u7684\u64cd\u4f5c\uff09\u5e76\u7ed1\u5b9a\u5230\u539f\u5b50SLO\u548c\u9065\u6d4b\u6570\u636e\uff1b2) \u8fd0\u884c\u65f6\u63a8\u7406\u7ec4\u4ef6\u6d88\u8d39\u64cd\u4f5c\u5de5\u4ef6\uff08\u5982\u8ffd\u8e2a\u548c\u6d41\u91cf\u914d\u7f6e\uff09\u5408\u6210\u5177\u6709\u6765\u6e90\u548c\u7f6e\u4fe1\u5ea6\u7684\u5019\u9009\u65c5\u7a0b\u6a21\u578b\uff1b3) \u4ece\u6700\u540e\u63a5\u53d7\u7684\u6a21\u578b\u4e2d\uff0cEmaC\u7f16\u8bd1\u5668/\u63a7\u5236\u5668\u5728\u663e\u5f0f\u76f8\u5173\u6027\u5047\u8bbe\u4e0b\u63a8\u5bfc\u6709\u754c\u7684\u65c5\u7a0bSLO\u548c\u9884\u7b97\uff1b4) \u751f\u6210\u63a7\u5236\u5e73\u9762\u5de5\u4ef6\uff08\u71c3\u70e7\u7387\u8b66\u62a5\u3001\u53d1\u5e03\u95e8\u63a7\u3001\u64cd\u4f5c\u9632\u62a4\uff09", "result": "\u63d0\u4f9b\u533f\u540d\u5316\u5de5\u4ef6\u4ed3\u5e93\u5305\u542b\u53ef\u8fd0\u884c\u7684\u793a\u4f8b\u89c4\u8303\u548c\u751f\u6210\u8f93\u51fa\uff0c\u5c55\u793a\u4e86\u5982\u4f55\u4f7f\u65c5\u7a0b\u53ef\u9760\u6027\u53ef\u8ba1\u7b97\u548c\u53ef\u6cbb\u7406", "conclusion": "EmaC\u4e3a\u5fae\u670d\u52a1\u67b6\u6784\u4e2d\u7684\u65c5\u7a0b\u53ef\u9760\u6027\u7ba1\u7406\u63d0\u4f9b\u4e86\u7cfb\u7edf\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u610f\u56fe\u52a0\u8bc1\u636e\u7684\u65b9\u5f0f\u4f7f\u65c5\u7a0b\u53ef\u9760\u6027\u53ef\u8ba1\u7b97\u548c\u53ef\u6cbb\u7406\uff0c\u89e3\u51b3\u4e86SLO-as-code\u5728\u65c5\u7a0b\u5c42\u9762\u7684\u5c40\u9650\u6027"}}
{"id": "2602.05651", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2602.05651", "abs": "https://arxiv.org/abs/2602.05651", "authors": ["Nick Rassau", "Felix Schuhknecht"], "title": "One Size Does NOT Fit All: On the Importance of Physical Representations for Datalog Evaluation", "comment": null, "summary": "Datalog is an increasingly popular recursive query language that is declarative by design, meaning its programs must be translated by an engine into the actual physical execution plan. When generating this plan, a central decision is how to physically represent all involved relations, an aspect in which existing Datalog engines are surprisingly restrictive and often resort to one-size-fits-all solutions. The reason for this is that the typical execution plan of a Datalog program not only performs a single type of operation against the physical representations, but a mixture of operations, such as insertions, lookups, and containment-checks. Further, the relevance of each operation type highly depends on the workload characteristics, which range from familiar properties such as the size, multiplicity, and arity of the individual relations to very specific Datalog properties, such as the \"interweaving\" of rules when relations occur multiple times, and in particular the recursiveness of the query which might generate new tuples on the fly during evaluation. This indicates that a variety of physical representations, each with its own strengths and weaknesses, is required to meet the specific needs of different workload situations. To evaluate this, we conduct an in-depth experimental study of the interplay between potentially suitable physical representations and seven dimensions of workload characteristics that vary across actual Datalog programs, revealing which properties actually matter. Based on these insights, we design an automatic selection mechanism that utilizes a set of decision trees to identify suitable physical representations for a given workload.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86Datalog\u67e5\u8be2\u5f15\u64ce\u4e2d\u7269\u7406\u8868\u793a\u9009\u62e9\u7684\u95ee\u9898\uff0c\u901a\u8fc7\u5b9e\u9a8c\u5206\u6790\u5de5\u4f5c\u8d1f\u8f7d\u7279\u6027\u4e0e\u7269\u7406\u8868\u793a\u4e4b\u95f4\u7684\u76f8\u4e92\u4f5c\u7528\uff0c\u5e76\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u57fa\u4e8e\u51b3\u7b56\u6811\u7684\u81ea\u52a8\u9009\u62e9\u673a\u5236\u3002", "motivation": "\u73b0\u6709Datalog\u5f15\u64ce\u5728\u7269\u7406\u8868\u793a\u9009\u62e9\u4e0a\u8fc7\u4e8e\u9650\u5236\uff0c\u901a\u5e38\u91c7\u7528\u4e00\u5200\u5207\u7684\u89e3\u51b3\u65b9\u6848\u3002Datalog\u7a0b\u5e8f\u7684\u6267\u884c\u8ba1\u5212\u6d89\u53ca\u591a\u79cd\u64cd\u4f5c\u7c7b\u578b\uff08\u63d2\u5165\u3001\u67e5\u627e\u3001\u5305\u542b\u68c0\u67e5\uff09\uff0c\u4e14\u4e0d\u540c\u5de5\u4f5c\u8d1f\u8f7d\u7279\u6027\uff08\u5173\u7cfb\u5927\u5c0f\u3001\u591a\u91cd\u6027\u3001\u9012\u5f52\u6027\u7b49\uff09\u5bf9\u64cd\u4f5c\u9700\u6c42\u4e0d\u540c\uff0c\u9700\u8981\u591a\u6837\u5316\u7684\u7269\u7406\u8868\u793a\u6765\u6ee1\u8db3\u4e0d\u540c\u573a\u666f\u3002", "method": "1. \u6df1\u5165\u5b9e\u9a8c\u7814\u7a76\uff1a\u5206\u6790\u6f5c\u5728\u5408\u9002\u7684\u7269\u7406\u8868\u793a\u4e0e\u4e03\u4e2a\u5de5\u4f5c\u8d1f\u8f7d\u7279\u6027\u7ef4\u5ea6\u4e4b\u95f4\u7684\u76f8\u4e92\u4f5c\u7528\uff1b2. \u8bbe\u8ba1\u81ea\u52a8\u9009\u62e9\u673a\u5236\uff1a\u5229\u7528\u4e00\u7ec4\u51b3\u7b56\u6811\u6765\u8bc6\u522b\u9002\u5408\u7ed9\u5b9a\u5de5\u4f5c\u8d1f\u8f7d\u7684\u7269\u7406\u8868\u793a\u3002", "result": "\u5b9e\u9a8c\u63ed\u793a\u4e86\u54ea\u4e9b\u5de5\u4f5c\u8d1f\u8f7d\u7279\u6027\u771f\u6b63\u91cd\u8981\uff0c\u4e3a\u7269\u7406\u8868\u793a\u9009\u62e9\u63d0\u4f9b\u4e86\u5b9e\u8bc1\u4f9d\u636e\u3002\u57fa\u4e8e\u8fd9\u4e9b\u6d1e\u5bdf\u8bbe\u8ba1\u7684\u51b3\u7b56\u6811\u673a\u5236\u80fd\u591f\u81ea\u52a8\u4e3a\u7279\u5b9a\u5de5\u4f5c\u8d1f\u8f7d\u9009\u62e9\u6700\u4f18\u7684\u7269\u7406\u8868\u793a\u3002", "conclusion": "Datalog\u67e5\u8be2\u5f15\u64ce\u9700\u8981\u6839\u636e\u5177\u4f53\u5de5\u4f5c\u8d1f\u8f7d\u7279\u6027\u7075\u6d3b\u9009\u62e9\u7269\u7406\u8868\u793a\uff0c\u800c\u4e0d\u662f\u91c7\u7528\u4e00\u5200\u5207\u7684\u65b9\u6848\u3002\u901a\u8fc7\u5b9e\u9a8c\u5206\u6790\u548c\u51b3\u7b56\u6811\u673a\u5236\uff0c\u53ef\u4ee5\u5b9e\u73b0\u81ea\u52a8\u5316\u7684\u7269\u7406\u8868\u793a\u9009\u62e9\uff0c\u4ece\u800c\u4f18\u5316Datalog\u7a0b\u5e8f\u7684\u6267\u884c\u6027\u80fd\u3002"}}
{"id": "2602.05043", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.05043", "abs": "https://arxiv.org/abs/2602.05043", "authors": ["Grace A. Lewis", "Rachel Brower-Sinning", "Robert Edman", "Ipek Ozkaya", "Sebasti\u00e1n Echeverr\u00eda", "Alex Derr", "Collin Beaudoin", "Katherine R. Maffey"], "title": "Quality Model for Machine Learning Components", "comment": "A short version of this paper has been accepted to CAIN 2026, the 5th IEEE/ACM Conference on AI Engineering - Software Engineering for AI Systems", "summary": "Despite increased adoption and advances in machine learning (ML), there are studies showing that many ML prototypes do not reach the production stage and that testing is still largely limited to testing model properties, such as model performance, without considering requirements derived from the system it will be a part of, such as throughput, resource consumption, or robustness. This limited view of testing leads to failures in model integration, deployment, and operations. In traditional software development, quality models such as ISO 25010 provide a widely used structured framework to assess software quality, define quality requirements, and provide a common language for communication with stakeholders. A newer standard, ISO 25059, defines a more specific quality model for AI systems. However, a problem with this standard is that it combines system attributes with ML component attributes, which is not helpful for a model developer, as many system attributes cannot be assessed at the component level. In this paper, we present a quality model for ML components that serves as a guide for requirements elicitation and negotiation and provides a common vocabulary for ML component developers and system stakeholders to agree on and define system-derived requirements and focus their testing efforts accordingly. The quality model was validated through a survey in which the participants agreed with its relevance and value. The quality model has been successfully integrated into an open-source tool for ML component testing and evaluation demonstrating its practical application.", "AI": {"tldr": "\u63d0\u51fa\u9488\u5bf9\u673a\u5668\u5b66\u4e60\u7ec4\u4ef6\u7684\u8d28\u91cf\u6a21\u578b\uff0c\u5e2e\u52a9\u5f00\u53d1\u8005\u548c\u7cfb\u7edf\u5229\u76ca\u76f8\u5173\u8005\u5b9a\u4e49\u7cfb\u7edf\u7ea7\u9700\u6c42\u5e76\u6307\u5bfc\u6d4b\u8bd5\u5de5\u4f5c", "motivation": "\u5f53\u524d\u673a\u5668\u5b66\u4e60\u6d4b\u8bd5\u4e3b\u8981\u5173\u6ce8\u6a21\u578b\u6027\u80fd\u7b49\u5c5e\u6027\uff0c\u800c\u5ffd\u7565\u4e86\u7cfb\u7edf\u7ea7\u9700\u6c42\uff08\u5982\u541e\u5410\u91cf\u3001\u8d44\u6e90\u6d88\u8017\u3001\u9c81\u68d2\u6027\uff09\uff0c\u5bfc\u81f4\u6a21\u578b\u96c6\u6210\u3001\u90e8\u7f72\u548c\u8fd0\u7ef4\u5931\u8d25\u3002\u867d\u7136ISO 25059\u6807\u51c6\u5b9a\u4e49\u4e86AI\u7cfb\u7edf\u8d28\u91cf\u6a21\u578b\uff0c\u4f46\u5b83\u5c06\u7cfb\u7edf\u5c5e\u6027\u548cML\u7ec4\u4ef6\u5c5e\u6027\u6df7\u5728\u4e00\u8d77\uff0c\u5bf9\u7ec4\u4ef6\u5f00\u53d1\u8005\u4e0d\u5b9e\u7528\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u4e13\u95e8\u9488\u5bf9\u673a\u5668\u5b66\u4e60\u7ec4\u4ef6\u7684\u8d28\u91cf\u6a21\u578b\uff0c\u4f5c\u4e3a\u9700\u6c42\u83b7\u53d6\u548c\u534f\u5546\u7684\u6307\u5357\uff0c\u4e3aML\u7ec4\u4ef6\u5f00\u53d1\u8005\u548c\u7cfb\u7edf\u5229\u76ca\u76f8\u5173\u8005\u63d0\u4f9b\u5171\u540c\u8bcd\u6c47\u3002\u901a\u8fc7\u8c03\u67e5\u9a8c\u8bc1\u4e86\u8be5\u6a21\u578b\u7684\u76f8\u5173\u6027\u548c\u4ef7\u503c\uff0c\u5e76\u5c06\u5176\u96c6\u6210\u5230\u5f00\u6e90\u7684ML\u7ec4\u4ef6\u6d4b\u8bd5\u548c\u8bc4\u4f30\u5de5\u5177\u4e2d\u3002", "result": "\u53c2\u4e0e\u8005\u8ba4\u53ef\u8be5\u8d28\u91cf\u6a21\u578b\u7684\u76f8\u5173\u6027\u548c\u4ef7\u503c\u3002\u8be5\u6a21\u578b\u5df2\u6210\u529f\u96c6\u6210\u5230\u5f00\u6e90\u5de5\u5177\u4e2d\uff0c\u5c55\u793a\u4e86\u5176\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002", "conclusion": "\u63d0\u51fa\u7684\u673a\u5668\u5b66\u4e60\u7ec4\u4ef6\u8d28\u91cf\u6a21\u578b\u80fd\u591f\u6709\u6548\u5e2e\u52a9\u5f00\u53d1\u8005\u548c\u5229\u76ca\u76f8\u5173\u8005\u5b9a\u4e49\u7cfb\u7edf\u7ea7\u9700\u6c42\uff0c\u6307\u5bfc\u6d4b\u8bd5\u5de5\u4f5c\uff0c\u89e3\u51b3\u5f53\u524dML\u6d4b\u8bd5\u8fc7\u4e8e\u5c40\u9650\u7684\u95ee\u9898\u3002"}}
{"id": "2602.05486", "categories": ["cs.SE", "cs.AI", "cs.CR", "cs.DC"], "pdf": "https://arxiv.org/pdf/2602.05486", "abs": "https://arxiv.org/abs/2602.05486", "authors": ["Matteo Esposito", "Lodovica Marchesi", "Roberto Tonelli", "Valentina Lenarduzzi"], "title": "Sovereign-by-Design A Reference Architecture for AI and Blockchain Enabled Systems", "comment": null, "summary": "Digital sovereignty has emerged as a central concern for modern software-intensive systems, driven by the dominance of non-sovereign cloud infrastructures, the rapid adoption of Generative AI, and increasingly stringent regulatory requirements. While existing initiatives address governance, compliance, and security in isolation, they provide limited guidance on how sovereignty can be operationalized at the architectural level. In this paper, we argue that sovereignty must be treated as a first-class architectural property rather than a purely regulatory objective. We introduce a Sovereign Reference Architecture that integrates self-sovereign identity, blockchain-based trust and auditability, sovereign data governance, and Generative AI deployed under explicit architectural control. The architecture explicitly captures the dual role of Generative AI as both a source of governance risk and an enabler of compliance, accountability, and continuous assurance when properly constrained. By framing sovereignty as an architectural quality attribute, our work bridges regulatory intent and concrete system design, offering a coherent foundation for building auditable, evolvable, and jurisdiction-aware AI-enabled systems. The proposed reference architecture provides a principled starting point for future research and practice at the intersection of software architecture, Generative AI, and digital sovereignty.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u5c06\u6570\u5b57\u4e3b\u6743\u4f5c\u4e3a\u9996\u8981\u67b6\u6784\u5c5e\u6027\uff0c\u800c\u975e\u5355\u7eaf\u76d1\u7ba1\u76ee\u6807\uff0c\u5e76\u5f15\u5165\u4e00\u4e2a\u6574\u5408\u81ea\u4e3b\u6743\u8eab\u4efd\u3001\u533a\u5757\u94fe\u4fe1\u4efb\u3001\u4e3b\u6743\u6570\u636e\u6cbb\u7406\u548c\u53d7\u63a7\u751f\u6210\u5f0fAI\u7684\u53c2\u8003\u67b6\u6784\u3002", "motivation": "\u6570\u5b57\u4e3b\u6743\u5df2\u6210\u4e3a\u73b0\u4ee3\u8f6f\u4ef6\u5bc6\u96c6\u578b\u7cfb\u7edf\u7684\u6838\u5fc3\u5173\u5207\uff0c\u4e3b\u8981\u9a71\u52a8\u56e0\u7d20\u5305\u62ec\uff1a\u975e\u4e3b\u6743\u4e91\u57fa\u7840\u8bbe\u65bd\u7684\u4e3b\u5bfc\u5730\u4f4d\u3001\u751f\u6210\u5f0fAI\u7684\u5feb\u901f\u91c7\u7528\u3001\u4ee5\u53ca\u65e5\u76ca\u4e25\u683c\u7684\u76d1\u7ba1\u8981\u6c42\u3002\u73b0\u6709\u4e3e\u63aa\u5728\u6cbb\u7406\u3001\u5408\u89c4\u548c\u5b89\u5168\u6027\u65b9\u9762\u5404\u81ea\u4e3a\u653f\uff0c\u7f3a\u4e4f\u5728\u67b6\u6784\u5c42\u9762\u5b9e\u73b0\u4e3b\u6743\u7684\u5177\u4f53\u6307\u5bfc\u3002", "method": "\u63d0\u51fa\u5c06\u4e3b\u6743\u89c6\u4e3a\u9996\u8981\u67b6\u6784\u5c5e\u6027\uff0c\u5f15\u5165\u4e3b\u6743\u53c2\u8003\u67b6\u6784\uff0c\u8be5\u67b6\u6784\u6574\u5408\u4e86\u56db\u4e2a\u5173\u952e\u7ec4\u4ef6\uff1a\u81ea\u4e3b\u6743\u8eab\u4efd\u3001\u57fa\u4e8e\u533a\u5757\u94fe\u7684\u4fe1\u4efb\u4e0e\u53ef\u5ba1\u8ba1\u6027\u3001\u4e3b\u6743\u6570\u636e\u6cbb\u7406\u3001\u4ee5\u53ca\u5728\u660e\u786e\u67b6\u6784\u63a7\u5236\u4e0b\u90e8\u7f72\u7684\u751f\u6210\u5f0fAI\u3002", "result": "\u8be5\u67b6\u6784\u660e\u786e\u6355\u6349\u4e86\u751f\u6210\u5f0fAI\u7684\u53cc\u91cd\u89d2\u8272\uff1a\u65e2\u662f\u6cbb\u7406\u98ce\u9669\u7684\u6765\u6e90\uff0c\u53c8\u662f\u5408\u89c4\u6027\u3001\u95ee\u8d23\u5236\u548c\u6301\u7eed\u4fdd\u969c\u7684\u8d4b\u80fd\u8005\uff08\u5f53\u53d7\u5230\u9002\u5f53\u7ea6\u675f\u65f6\uff09\u3002\u901a\u8fc7\u5c06\u4e3b\u6743\u6784\u5efa\u4e3a\u67b6\u6784\u8d28\u91cf\u5c5e\u6027\uff0c\u5f25\u5408\u4e86\u76d1\u7ba1\u610f\u56fe\u4e0e\u5177\u4f53\u7cfb\u7edf\u8bbe\u8ba1\u4e4b\u95f4\u7684\u9e3f\u6c9f\u3002", "conclusion": "\u63d0\u51fa\u7684\u53c2\u8003\u67b6\u6784\u4e3a\u8f6f\u4ef6\u67b6\u6784\u3001\u751f\u6210\u5f0fAI\u548c\u6570\u5b57\u4e3b\u6743\u4ea4\u53c9\u9886\u57df\u7684\u672a\u6765\u7814\u7a76\u548c\u5b9e\u8df5\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u8d77\u70b9\uff0c\u4e3a\u6784\u5efa\u53ef\u5ba1\u8ba1\u3001\u53ef\u6f14\u8fdb\u548c\u5177\u5907\u53f8\u6cd5\u7ba1\u8f96\u610f\u8bc6\u7684AI\u8d4b\u80fd\u7cfb\u7edf\u5960\u5b9a\u4e86\u8fde\u8d2f\u57fa\u7840\u3002"}}
{"id": "2602.05674", "categories": ["cs.DB", "cs.CR"], "pdf": "https://arxiv.org/pdf/2602.05674", "abs": "https://arxiv.org/abs/2602.05674", "authors": ["Miguel Fuentes", "Brett Mullins", "Yingtai Xiao", "Daniel Kifer", "Cameron Musco", "Daniel Sheldon"], "title": "Fast Private Adaptive Query Answering for Large Data Domains", "comment": null, "summary": "Privately releasing marginals of a tabular dataset is a foundational problem in differential privacy. However, state-of-the-art mechanisms suffer from a computational bottleneck when marginal estimates are reconstructed from noisy measurements. Recently, residual queries were introduced and shown to lead to highly efficient reconstruction in the batch query answering setting. We introduce new techniques to integrate residual queries into state-of-the-art adaptive mechanisms such as AIM. Our contributions include a novel conceptual framework for residual queries using multi-dimensional arrays, lazy updating strategies, and adaptive optimization of the per-round privacy budget allocation. Together these contributions reduce error, improve speed, and simplify residual query operations. We integrate these innovations into a new mechanism (AIM+GReM), which improves AIM by using fast residual-based reconstruction instead of a graphical model approach. Our mechanism is orders of magnitude faster than the original framework and demonstrates competitive error and greatly improved scalability.", "AI": {"tldr": "\u63d0\u51faAIM+GReM\u673a\u5236\uff0c\u901a\u8fc7\u6b8b\u5dee\u67e5\u8be2\u548c\u4f18\u5316\u7b56\u7565\u6539\u8fdb\u5dee\u5206\u9690\u79c1\u4e0b\u7684\u8fb9\u9645\u5206\u5e03\u53d1\u5e03\uff0c\u663e\u8457\u63d0\u5347\u8ba1\u7b97\u6548\u7387", "motivation": "\u73b0\u6709\u5dee\u5206\u9690\u79c1\u8fb9\u9645\u53d1\u5e03\u673a\u5236\u5728\u4ece\u566a\u58f0\u6d4b\u91cf\u91cd\u5efa\u8fb9\u9645\u4f30\u8ba1\u65f6\u5b58\u5728\u8ba1\u7b97\u74f6\u9888\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848", "method": "\u63d0\u51fa\u57fa\u4e8e\u591a\u7ef4\u6570\u7ec4\u7684\u6b8b\u5dee\u67e5\u8be2\u6982\u5ff5\u6846\u67b6\u3001\u60f0\u6027\u66f4\u65b0\u7b56\u7565\u3001\u81ea\u9002\u5e94\u6bcf\u8f6e\u9690\u79c1\u9884\u7b97\u5206\u914d\uff0c\u5e76\u96c6\u6210\u5230AIM+GReM\u673a\u5236\u4e2d", "result": "AIM+GReM\u6bd4\u539f\u59cb\u6846\u67b6\u5feb\u51e0\u4e2a\u6570\u91cf\u7ea7\uff0c\u5177\u6709\u7ade\u4e89\u6027\u7684\u8bef\u5dee\u548c\u663e\u8457\u6539\u5584\u7684\u53ef\u6269\u5c55\u6027", "conclusion": "\u6b8b\u5dee\u67e5\u8be2\u4e0e\u81ea\u9002\u5e94\u673a\u5236\u7684\u6709\u6548\u96c6\u6210\u80fd\u591f\u5927\u5e45\u63d0\u5347\u5dee\u5206\u9690\u79c1\u8fb9\u9645\u53d1\u5e03\u7684\u8ba1\u7b97\u6548\u7387\u548c\u53ef\u6269\u5c55\u6027"}}
{"id": "2602.05122", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.05122", "abs": "https://arxiv.org/abs/2602.05122", "authors": ["Altino Alves", "Andre Hora"], "title": "TestMigrationsInPy: A Dataset of Test Migrations from Unittest to Pytest", "comment": "Published at MSR 2025", "summary": "Unittest and pytest are the most popular testing frameworks in Python. Overall, pytest provides some advantages, including simpler assertion, reuse of fixtures, and interoperability. Due to such benefits, multiple projects in the Python ecosystem have migrated from unittest to pytest. To facilitate the migration, pytest can also run unittest tests, thus, the migration can happen gradually over time. However, the migration can be time-consuming and take a long time to conclude. In this context, projects would benefit from automated solutions to support the migration process. In this paper, we propose TestMigrationsInPy, a dataset of test migrations from unittest to pytest. TestMigrationsInPy contains 923 real-world migrations performed by developers. Future research proposing novel solutions to migrate frameworks in Python can rely on TestMigrationsInPy as a ground truth. Moreover, as TestMigrationsInPy includes information about the migration type (e.g., changes in assertions or fixtures), our dataset enables novel solutions to be verified effectively, for instance, from simpler assertion migrations to more complex fixture migrations. TestMigrationsInPy is publicly available at: https://github.com/altinoalvesjunior/TestMigrationsInPy.", "AI": {"tldr": "TestMigrationsInPy\u662f\u4e00\u4e2a\u5305\u542b923\u4e2a\u771f\u5b9e\u4e16\u754cunittest\u5230pytest\u8fc1\u79fb\u7684\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u652f\u6301Python\u6d4b\u8bd5\u6846\u67b6\u8fc1\u79fb\u7684\u81ea\u52a8\u5316\u7814\u7a76\u3002", "motivation": "pytest\u76f8\u6bd4unittest\u6709\u8bf8\u591a\u4f18\u52bf\uff0c\u8bb8\u591aPython\u9879\u76ee\u6b63\u5728\u4eceunittest\u8fc1\u79fb\u5230pytest\uff0c\u4f46\u8fc1\u79fb\u8fc7\u7a0b\u8017\u65f6\u4e14\u590d\u6742\uff0c\u9700\u8981\u81ea\u52a8\u5316\u5de5\u5177\u652f\u6301\u3002", "method": "\u6536\u96c6\u4e86923\u4e2a\u771f\u5b9e\u5f00\u53d1\u8005\u7684\u6d4b\u8bd5\u8fc1\u79fb\u6848\u4f8b\uff0c\u6784\u5efa\u4e86\u5305\u542b\u8fc1\u79fb\u7c7b\u578b\u4fe1\u606f\uff08\u5982\u65ad\u8a00\u3001fixture\u7b49\uff09\u7684\u6570\u636e\u96c6\u3002", "result": "\u521b\u5efa\u4e86TestMigrationsInPy\u6570\u636e\u96c6\uff0c\u5305\u542b\u8be6\u7ec6\u7684\u8fc1\u79fb\u4fe1\u606f\uff0c\u53ef\u4f5c\u4e3a\u672a\u6765\u7814\u7a76\u7684\u57fa\u7840\u4e8b\u5b9e\u6570\u636e\u96c6\u3002", "conclusion": "TestMigrationsInPy\u4e3aPython\u6d4b\u8bd5\u6846\u67b6\u8fc1\u79fb\u7814\u7a76\u63d0\u4f9b\u4e86\u5b9d\u8d35\u8d44\u6e90\uff0c\u652f\u6301\u4ece\u7b80\u5355\u65ad\u8a00\u8fc1\u79fb\u5230\u590d\u6742fixture\u8fc1\u79fb\u7684\u9a8c\u8bc1\u3002"}}
{"id": "2602.05708", "categories": ["cs.DB", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.05708", "abs": "https://arxiv.org/abs/2602.05708", "authors": ["Chuangtao Ma", "Zeyu Zhang", "Arijit Khan", "Sebastian Schelter", "Paul Groth"], "title": "Cost-Efficient RAG for Entity Matching with LLMs: A Blocking-based Exploration", "comment": null, "summary": "Retrieval-augmented generation (RAG) enhances LLM reasoning in knowledge-intensive tasks, but existing RAG pipelines incur substantial retrieval and generation overhead when applied to large-scale entity matching. To address this limitation, we introduce CE-RAG4EM, a cost-efficient RAG architecture that reduces computation through blocking-based batch retrieval and generation. We also present a unified framework for analyzing and evaluating RAG systems for entity matching, focusing on blocking-aware optimizations and retrieval granularity. Extensive experiments suggest that CE-RAG4EM can achieve comparable or improved matching quality while substantially reducing end-to-end runtime relative to strong baselines. Our analysis further reveals that key configuration parameters introduce an inherent trade-off between performance and overhead, offering practical guidance for designing efficient and scalable RAG systems for entity matching and data integration.", "AI": {"tldr": "CE-RAG4EM\uff1a\u4e00\u79cd\u7528\u4e8e\u5b9e\u4f53\u5339\u914d\u7684\u6210\u672c\u9ad8\u6548RAG\u67b6\u6784\uff0c\u901a\u8fc7\u57fa\u4e8e\u5206\u5757\u7684\u6279\u91cf\u68c0\u7d22\u548c\u751f\u6210\u51cf\u5c11\u8ba1\u7b97\u5f00\u9500\uff0c\u5728\u4fdd\u6301\u5339\u914d\u8d28\u91cf\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u7aef\u5230\u7aef\u8fd0\u884c\u65f6\u95f4\u3002", "motivation": "\u73b0\u6709RAG\u7ba1\u9053\u5728\u5927\u89c4\u6a21\u5b9e\u4f53\u5339\u914d\u4e2d\u4ea7\u751f\u5927\u91cf\u68c0\u7d22\u548c\u751f\u6210\u5f00\u9500\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u6765\u5e73\u8861\u6027\u80fd\u4e0e\u8ba1\u7b97\u6210\u672c\u3002", "method": "\u63d0\u51faCE-RAG4EM\u67b6\u6784\uff0c\u91c7\u7528\u57fa\u4e8e\u5206\u5757\u7684\u6279\u91cf\u68c0\u7d22\u548c\u751f\u6210\u7b56\u7565\uff0c\u5e76\u5efa\u7acb\u7edf\u4e00\u7684RAG\u7cfb\u7edf\u5206\u6790\u8bc4\u4f30\u6846\u67b6\uff0c\u91cd\u70b9\u5173\u6ce8\u5206\u5757\u611f\u77e5\u4f18\u5316\u548c\u68c0\u7d22\u7c92\u5ea6\u3002", "result": "\u5b9e\u9a8c\u8868\u660eCE-RAG4EM\u5728\u4fdd\u6301\u6216\u63d0\u5347\u5339\u914d\u8d28\u91cf\u7684\u540c\u65f6\uff0c\u663e\u8457\u51cf\u5c11\u7aef\u5230\u7aef\u8fd0\u884c\u65f6\u95f4\u3002\u5206\u6790\u63ed\u793a\u5173\u952e\u914d\u7f6e\u53c2\u6570\u5728\u6027\u80fd\u548c\u5f00\u9500\u4e4b\u95f4\u5b58\u5728\u56fa\u6709\u6743\u8861\u3002", "conclusion": "CE-RAG4EM\u4e3a\u5b9e\u4f53\u5339\u914d\u548c\u6570\u636e\u96c6\u6210\u63d0\u4f9b\u4e86\u9ad8\u6548\u53ef\u6269\u5c55\u7684RAG\u7cfb\u7edf\u8bbe\u8ba1\u6307\u5bfc\uff0c\u901a\u8fc7\u4f18\u5316\u914d\u7f6e\u53c2\u6570\u5e73\u8861\u6027\u80fd\u4e0e\u8ba1\u7b97\u5f00\u9500\u3002"}}
{"id": "2602.05123", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.05123", "abs": "https://arxiv.org/abs/2602.05123", "authors": ["Andre Hora", "Gordon Fraser"], "title": "Exceptional Behaviors: How Frequently Are They Tested?", "comment": "Published at AST 2025", "summary": "Exceptions allow developers to handle error cases expected to occur infrequently. Ideally, good test suites should test both normal and exceptional behaviors to catch more bugs and avoid regressions. While current research analyzes exceptions that propagate to tests, it does not explore other exceptions that do not reach the tests. In this paper, we provide an empirical study to explore how frequently exceptional behaviors are tested in real-world systems. We consider both exceptions that propagate to tests and the ones that do not reach the tests. For this purpose, we run an instrumented version of test suites, monitor their execution, and collect information about the exceptions raised at runtime. We analyze the test suites of 25 Python systems, covering 5,372 executed methods, 17.9M calls, and 1.4M raised exceptions. We find that 21.4% of the executed methods do raise exceptions at runtime. In methods that raise exceptions, on the median, 1 in 10 calls exercise exceptional behaviors. Close to 80% of the methods that raise exceptions do so infrequently, but about 20% raise exceptions more frequently. Finally, we provide implications for researchers and practitioners. We suggest developing novel tools to support exercising exceptional behaviors and refactoring expensive try/except blocks. We also call attention to the fact that exception-raising behaviors are not necessarily \"abnormal\" or rare.", "AI": {"tldr": "\u5bf925\u4e2aPython\u7cfb\u7edf\u7684\u5b9e\u8bc1\u7814\u7a76\u53d1\u73b0\uff0c21.4%\u7684\u6267\u884c\u65b9\u6cd5\u4f1a\u5728\u8fd0\u884c\u65f6\u629b\u51fa\u5f02\u5e38\uff0c\u5176\u4e2d\u7ea620%\u7684\u65b9\u6cd5\u9891\u7e41\u629b\u51fa\u5f02\u5e38\uff0c\u6311\u6218\u4e86\u5f02\u5e38\u662f\"\u7f55\u89c1\"\u884c\u4e3a\u7684\u4f20\u7edf\u89c2\u5ff5\u3002", "motivation": "\u5f53\u524d\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u4f20\u64ad\u5230\u6d4b\u8bd5\u7684\u5f02\u5e38\uff0c\u4f46\u5ffd\u7565\u4e86\u672a\u5230\u8fbe\u6d4b\u8bd5\u7684\u5176\u4ed6\u5f02\u5e38\u3002\u9700\u8981\u5b9e\u8bc1\u7814\u7a76\u771f\u5b9e\u7cfb\u7edf\u4e2d\u5f02\u5e38\u884c\u4e3a\u7684\u6d4b\u8bd5\u9891\u7387\uff0c\u4ee5\u5168\u9762\u4e86\u89e3\u5f02\u5e38\u5904\u7406\u60c5\u51b5\u3002", "method": "\u8fd0\u884c25\u4e2aPython\u7cfb\u7edf\u7684\u6d4b\u8bd5\u5957\u4ef6\uff0c\u76d1\u63a7\u6267\u884c\u8fc7\u7a0b\uff0c\u6536\u96c6\u8fd0\u884c\u65f6\u629b\u51fa\u7684\u5f02\u5e38\u4fe1\u606f\u3002\u8986\u76d65,372\u4e2a\u6267\u884c\u65b9\u6cd5\u30011,790\u4e07\u6b21\u8c03\u7528\u548c140\u4e07\u6b21\u629b\u51fa\u7684\u5f02\u5e38\u3002", "result": "21.4%\u7684\u6267\u884c\u65b9\u6cd5\u4f1a\u5728\u8fd0\u884c\u65f6\u629b\u51fa\u5f02\u5e38\uff1b\u5728\u629b\u51fa\u5f02\u5e38\u7684\u65b9\u6cd5\u4e2d\uff0c\u4e2d\u4f4d\u6570\u663e\u793a\u6bcf10\u6b21\u8c03\u7528\u5c31\u67091\u6b21\u89e6\u53d1\u5f02\u5e38\u884c\u4e3a\uff1b\u7ea680%\u7684\u65b9\u6cd5\u5f88\u5c11\u629b\u51fa\u5f02\u5e38\uff0c\u4f46\u7ea620%\u7684\u65b9\u6cd5\u9891\u7e41\u629b\u51fa\u5f02\u5e38\u3002", "conclusion": "\u5f02\u5e38\u629b\u51fa\u884c\u4e3a\u4e0d\u4e00\u5b9a\u662f\"\u5f02\u5e38\"\u6216\u7f55\u89c1\u7684\u3002\u5efa\u8bae\u5f00\u53d1\u65b0\u5de5\u5177\u652f\u6301\u5f02\u5e38\u884c\u4e3a\u6d4b\u8bd5\u548c\u91cd\u6784\u6602\u8d35\u7684try/except\u5757\uff0c\u63d0\u9192\u7814\u7a76\u8005\u5173\u6ce8\u5f02\u5e38\u884c\u4e3a\u7684\u5b9e\u9645\u9891\u7387\u3002"}}
{"id": "2602.05928", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2602.05928", "abs": "https://arxiv.org/abs/2602.05928", "authors": ["Rick van der Heijden", "Nikolay Yakovets", "Thekla Hamm"], "title": "Even Faster Geosocial Reachability Queries", "comment": null, "summary": "Geosocial reachability queries (\\textsc{RangeReach}) determine whether a given vertex in a geosocial network can reach any spatial vertex within a query region. The state-of-the-art 3DReach method answers such queries by encoding graph reachability through interval labelling and indexing spatial vertices in a 3D R-tree. We present 2DReach, a simpler approach that avoids interval labelling entirely. Like 3DReach, 2DReach collapses strongly connected components (SCCs) into a DAG, but instead of computing interval labels, it directly stores a 2D R-tree per component over all reachable spatial vertices. A query then reduces to a single 2D R-tree lookup. We further propose compressed variants that reduce storage by excluding spatial sinks and sharing R-trees between components with identical reachable sets. Experiments on four real-world datasets show that 2DReach achieves faster index construction than 3DReach, with the compressed variant yielding the smallest index size among all methods. 2DReach delivers competitive or superior query performance with more stable response times across varying query parameters.", "AI": {"tldr": "2DReach\uff1a\u4e00\u79cd\u66f4\u7b80\u5355\u7684geosocial\u53ef\u8fbe\u6027\u67e5\u8be2\u65b9\u6cd5\uff0c\u75282D R-tree\u66ff\u4ee33DReach\u7684\u533a\u95f4\u6807\u7b7e\u548c3D R-tree\uff0c\u5b9e\u73b0\u66f4\u5feb\u7684\u7d22\u5f15\u6784\u5efa\u548c\u66f4\u7a33\u5b9a\u7684\u67e5\u8be2\u6027\u80fd\u3002", "motivation": "\u73b0\u67093DReach\u65b9\u6cd5\u4f7f\u7528\u533a\u95f4\u6807\u7b7e\u548c3D R-tree\u8fdb\u884cgeosocial\u53ef\u8fbe\u6027\u67e5\u8be2\uff0c\u65b9\u6cd5\u590d\u6742\u3002\u672c\u6587\u63d0\u51fa\u66f4\u7b80\u5355\u76842DReach\u65b9\u6cd5\uff0c\u907f\u514d\u533a\u95f4\u6807\u7b7e\u7684\u590d\u6742\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u6216\u63d0\u5347\u6027\u80fd\u3002", "method": "\u5c06\u5f3a\u8fde\u901a\u5206\u91cf\u538b\u7f29\u4e3aDAG\uff0c\u4e3a\u6bcf\u4e2a\u5206\u91cf\u76f4\u63a5\u5b58\u50a82D R-tree\u8986\u76d6\u6240\u6709\u53ef\u8fbe\u7a7a\u95f4\u9876\u70b9\u3002\u67e5\u8be2\u7b80\u5316\u4e3a\u5355\u6b212D R-tree\u67e5\u627e\u3002\u63d0\u51fa\u538b\u7f29\u53d8\u4f53\uff1a\u6392\u9664\u7a7a\u95f4\u6c47\u70b9\uff0c\u5728\u5177\u6709\u76f8\u540c\u53ef\u8fbe\u96c6\u7684\u5206\u91cf\u95f4\u5171\u4eabR-tree\u3002", "result": "\u5728\u56db\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u663e\u793a\uff1a2DReach\u6bd43DReach\u7d22\u5f15\u6784\u5efa\u66f4\u5feb\uff1b\u538b\u7f29\u53d8\u4f53\u5728\u6240\u6709\u65b9\u6cd5\u4e2d\u7d22\u5f15\u5c3a\u5bf8\u6700\u5c0f\uff1b\u67e5\u8be2\u6027\u80fd\u5177\u6709\u7ade\u4e89\u529b\u6216\u66f4\u4f18\uff0c\u4e14\u54cd\u5e94\u65f6\u95f4\u5728\u4e0d\u540c\u67e5\u8be2\u53c2\u6570\u4e0b\u66f4\u7a33\u5b9a\u3002", "conclusion": "2DReach\u901a\u8fc7\u907f\u514d\u533a\u95f4\u6807\u7b7e\u7684\u590d\u6742\u6027\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u66f4\u7b80\u5355\u6709\u6548\u7684geosocial\u53ef\u8fbe\u6027\u67e5\u8be2\u89e3\u51b3\u65b9\u6848\uff0c\u5728\u7d22\u5f15\u6784\u5efa\u901f\u5ea6\u3001\u5b58\u50a8\u6548\u7387\u548c\u67e5\u8be2\u6027\u80fd\u7a33\u5b9a\u6027\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002"}}
{"id": "2602.05157", "categories": ["cs.SE", "eess.SY"], "pdf": "https://arxiv.org/pdf/2602.05157", "abs": "https://arxiv.org/abs/2602.05157", "authors": ["Alireza Abbaspour", "Shabin Mahadevan", "Kilian Zwirglmaier", "Jeff Stafford"], "title": "The Necessity of a Holistic Safety Evaluation Framework for AI-Based Automation Features", "comment": null, "summary": "The intersection of Safety of Intended Functionality (SOTIF) and Functional Safety (FuSa) analysis of driving automation features has traditionally excluded Quality Management (QM) components from rigorous safety impact evaluations. While QM components are not typically classified as safety-relevant, recent developments in artificial intelligence (AI) integration reveal that such components can contribute to SOTIF-related hazardous risks. Compliance with emerging AI safety standards, such as ISO/PAS 8800, necessitates re-evaluating safety considerations for these components. This paper examines the necessity of conducting holistic safety analysis and risk assessment on AI components, emphasizing their potential to introduce hazards with the capacity to violate risk acceptance criteria when deployed in safety-critical driving systems, particularly in perception algorithms. Using case studies, we demonstrate how deficiencies in AI-driven perception systems can emerge even in QM-classified components, leading to unintended functional behaviors with critical safety implications. By bridging theoretical analysis with practical examples, this paper argues for the adoption of comprehensive FuSa, SOTIF, and AI standards-driven methodologies to identify and mitigate risks in AI components. The findings demonstrate the importance of revising existing safety frameworks to address the evolving challenges posed by AI, ensuring comprehensive safety assurance across all component classifications spanning multiple safety standards.", "AI": {"tldr": "QM\u7ec4\u4ef6\u4f20\u7edf\u4e0a\u88ab\u6392\u9664\u5728\u5b89\u5168\u5206\u6790\u4e4b\u5916\uff0c\u4f46AI\u96c6\u6210\u663e\u793a\u5b83\u4eec\u53ef\u80fd\u5f15\u53d1SOTIF\u76f8\u5173\u98ce\u9669\uff0c\u9700\u8981\u91cd\u65b0\u8bc4\u4f30\u5b89\u5168\u6846\u67b6", "motivation": "\u4f20\u7edf\u9a7e\u9a76\u81ea\u52a8\u5316\u529f\u80fd\u7684\u5b89\u5168\u5206\u6790\u5c06\u8d28\u91cf\u7ba1\u7406(QM)\u7ec4\u4ef6\u6392\u9664\u5728\u4e25\u683c\u7684\u5b89\u5168\u5f71\u54cd\u8bc4\u4f30\u4e4b\u5916\uff0c\u4f46\u968f\u7740AI\u96c6\u6210\u7684\u53d1\u5c55\uff0c\u8fd9\u4e9b\u975e\u5b89\u5168\u76f8\u5173\u7ec4\u4ef6\u53ef\u80fd\u5f15\u53d1SOTIF\u76f8\u5173\u5371\u9669\u98ce\u9669\uff0c\u9700\u8981\u91cd\u65b0\u8bc4\u4f30\u5b89\u5168\u8003\u91cf", "method": "\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u5206\u6790AI\u9a71\u52a8\u7684\u611f\u77e5\u7cfb\u7edf\u7f3a\u9677\uff0c\u5c55\u793a\u5373\u4f7f\u5728QM\u5206\u7c7b\u7684\u7ec4\u4ef6\u4e2d\u4e5f\u53ef\u80fd\u51fa\u73b0\u7f3a\u9677\uff0c\u5bfc\u81f4\u5177\u6709\u5173\u952e\u5b89\u5168\u5f71\u54cd\u7684\u610f\u5916\u529f\u80fd\u884c\u4e3a\uff1b\u91c7\u7528\u7efc\u5408\u7684FuSa\u3001SOTIF\u548cAI\u6807\u51c6\u9a71\u52a8\u65b9\u6cd5", "result": "\u7814\u7a76\u8868\u660eAI\u7ec4\u4ef6\u53ef\u80fd\u5f15\u5165\u8fdd\u53cd\u98ce\u9669\u63a5\u53d7\u6807\u51c6\u7684\u5371\u9669\uff0c\u7279\u522b\u662f\u5728\u611f\u77e5\u7b97\u6cd5\u4e2d\uff1bQM\u5206\u7c7b\u7684\u7ec4\u4ef6\u4e2d\u7684\u7f3a\u9677\u53ef\u80fd\u5bfc\u81f4\u5173\u952e\u5b89\u5168\u5f71\u54cd", "conclusion": "\u9700\u8981\u91c7\u7528\u5168\u9762\u7684\u5b89\u5168\u5206\u6790\u65b9\u6cd5\uff0c\u4fee\u8ba2\u73b0\u6709\u5b89\u5168\u6846\u67b6\u4ee5\u5e94\u5bf9AI\u5e26\u6765\u7684\u6311\u6218\uff0c\u786e\u4fdd\u8de8\u6240\u6709\u7ec4\u4ef6\u5206\u7c7b\u7684\u5168\u9762\u5b89\u5168\u4fdd\u8bc1\uff0c\u6db5\u76d6\u591a\u4e2a\u5b89\u5168\u6807\u51c6"}}
{"id": "2602.05944", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2602.05944", "abs": "https://arxiv.org/abs/2602.05944", "authors": ["Yichun Wang", "Kristina Irion", "Paul Groth", "Hazar Harmouch"], "title": "\"Detective Work We Shouldn't Have to Do\": Practitioner Challenges in Regulatory-Aligned Data Quality in Machine Learning Systems", "comment": null, "summary": "Ensuring data quality in machine learning (ML) systems has become increasingly complex as regulatory requirements expand. In the European Union (EU), frameworks such as the General Data Protection Regulation (GDPR) and the Artificial Intelligence Act (AI Act) articulate data quality requirements that closely parallel technical concerns in ML practice, while also extending to legal obligations related to accountability, risk management, and human rights protection. This paper presents a qualitative interview study with EU-based data practitioners working on ML systems in regulated contexts. Through semi-structured interviews, we investigate how practitioners interpret regulatory-aligned data quality, the challenges they encounter, and the supports they identify as necessary. Our findings reveal persistent gaps between legal principles and engineering workflows, fragmentation across data pipelines, limitations of existing tools, unclear responsibility boundaries between technical and legal teams, and a tendency toward reactive, audit-driven quality practices. We also identify practitioners' needs for compliance-aware tooling, clearer governance structures, and cultural shifts toward proactive data governance.", "AI": {"tldr": "\u8be5\u8bba\u6587\u901a\u8fc7\u8bbf\u8c08\u6b27\u76df\u6570\u636e\u4ece\u4e1a\u8005\uff0c\u7814\u7a76\u673a\u5668\u5b66\u4e60\u7cfb\u7edf\u4e2d\u76d1\u7ba1\u8981\u6c42\u4e0e\u6570\u636e\u8d28\u91cf\u5b9e\u8df5\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u53d1\u73b0\u6cd5\u5f8b\u539f\u5219\u4e0e\u5de5\u7a0b\u6d41\u7a0b\u8131\u8282\u3001\u5de5\u5177\u4e0d\u8db3\u3001\u8d23\u4efb\u4e0d\u6e05\u7b49\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u6539\u8fdb\u5efa\u8bae\u3002", "motivation": "\u968f\u7740\u6b27\u76dfGDPR\u548cAI\u6cd5\u6848\u7b49\u76d1\u7ba1\u6846\u67b6\u5bf9\u673a\u5668\u5b66\u4e60\u7cfb\u7edf\u6570\u636e\u8d28\u91cf\u63d0\u51fa\u8981\u6c42\uff0c\u9700\u8981\u4e86\u89e3\u6570\u636e\u4ece\u4e1a\u8005\u5982\u4f55\u5728\u5b9e\u9645\u5de5\u4f5c\u4e2d\u5e94\u5bf9\u8fd9\u4e9b\u76d1\u7ba1\u8981\u6c42\uff0c\u4ee5\u53ca\u76d1\u7ba1\u539f\u5219\u4e0e\u5de5\u7a0b\u5b9e\u8df5\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002", "method": "\u91c7\u7528\u5b9a\u6027\u8bbf\u8c08\u7814\u7a76\u65b9\u6cd5\uff0c\u5bf9\u6b27\u76df\u5730\u533a\u5728\u53d7\u76d1\u7ba1\u73af\u5883\u4e2d\u4ece\u4e8b\u673a\u5668\u5b66\u4e60\u7cfb\u7edf\u7684\u6570\u636e\u4ece\u4e1a\u8005\u8fdb\u884c\u534a\u7ed3\u6784\u5316\u8bbf\u8c08\uff0c\u63a2\u8ba8\u4ed6\u4eec\u5bf9\u76d1\u7ba1\u8981\u6c42\u4e0b\u6570\u636e\u8d28\u91cf\u7684\u7406\u89e3\u3001\u9762\u4e34\u7684\u6311\u6218\u548c\u6240\u9700\u652f\u6301\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff1a\u6cd5\u5f8b\u539f\u5219\u4e0e\u5de5\u7a0b\u6d41\u7a0b\u5b58\u5728\u6301\u7eed\u5dee\u8ddd\uff1b\u6570\u636e\u7ba1\u9053\u788e\u7247\u5316\uff1b\u73b0\u6709\u5de5\u5177\u5b58\u5728\u5c40\u9650\u6027\uff1b\u6280\u672f\u56e2\u961f\u4e0e\u6cd5\u5f8b\u56e2\u961f\u8d23\u4efb\u8fb9\u754c\u4e0d\u6e05\uff1b\u6570\u636e\u8d28\u91cf\u5b9e\u8df5\u503e\u5411\u4e8e\u88ab\u52a8\u3001\u5ba1\u8ba1\u9a71\u52a8\u7684\u65b9\u5f0f\u3002", "conclusion": "\u4ece\u4e1a\u8005\u9700\u8981\u5408\u89c4\u610f\u8bc6\u66f4\u5f3a\u7684\u5de5\u5177\u3001\u66f4\u6e05\u6670\u7684\u6cbb\u7406\u7ed3\u6784\uff0c\u4ee5\u53ca\u5411\u4e3b\u52a8\u6570\u636e\u6cbb\u7406\u7684\u6587\u5316\u8f6c\u53d8\uff0c\u4ee5\u5f25\u5408\u76d1\u7ba1\u8981\u6c42\u4e0e\u5de5\u7a0b\u5b9e\u8df5\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002"}}
{"id": "2602.05242", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.05242", "abs": "https://arxiv.org/abs/2602.05242", "authors": ["Chenhui Mao", "Yuanting Lei", "Zhixiang Wei", "Ming Liang", "Zhixiang Wang", "Jingxuan Xu", "Dajun Chen", "Wei Jiang", "Yong Li"], "title": "EGSS: Entropy-guided Stepwise Scaling for Reliable Software Engineering", "comment": null, "summary": "Agentic Test-Time Scaling (TTS) has delivered state-of-the-art (SOTA) performance on complex software engineering tasks such as code generation and bug fixing. However, its practical adoption remains limited due to significant computational overhead, primarily driven by two key challenges: (1) the high cost associated with deploying excessively large ensembles, and (2) the lack of a reliable mechanism for selecting the optimal candidate solution, ultimately constraining the performance gains that can be realized. To address these challenges, we propose Entropy-Guided Stepwise Scaling (EGSS), a novel TTS framework that dynamically balances efficiency and effectiveness through entropy-guided adaptive search and robust test-suite augmentation. Extensive experiments on SWE-Bench-Verified demonstrate that EGSS consistently boosts performance by 5-10% across all evaluated models. Specifically, it increases the resolved ratio of Kimi-K2-Intruct from 63.2% to 72.2%, and GLM-4.6 from 65.8% to 74.6%. Furthermore, when paired with GLM-4.6, EGSS achieves a new state-of-the-art among open-source large language models. In addition to these accuracy improvements, EGSS reduces inference-time token usage by over 28% compared to existing TTS methods, achieving simultaneous gains in both effectiveness and computational efficiency.", "AI": {"tldr": "EGSS\u6846\u67b6\u901a\u8fc7\u71b5\u5f15\u5bfc\u81ea\u9002\u5e94\u641c\u7d22\u548c\u6d4b\u8bd5\u5957\u4ef6\u589e\u5f3a\uff0c\u5728\u4fdd\u6301Agentic\u6d4b\u8bd5\u65f6\u6269\u5c55\u6027\u80fd\u4f18\u52bf\u7684\u540c\u65f6\uff0c\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u5f00\u9500\uff0c\u5b9e\u73b0\u6548\u7387\u4e0e\u6548\u679c\u7684\u6700\u4f73\u5e73\u8861\u3002", "motivation": "Agentic\u6d4b\u8bd5\u65f6\u6269\u5c55\u5728\u4ee3\u7801\u751f\u6210\u548cbug\u4fee\u590d\u7b49\u590d\u6742\u8f6f\u4ef6\u5de5\u7a0b\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5b9e\u9645\u5e94\u7528\u53d7\u9650\uff1a1) \u5927\u89c4\u6a21\u96c6\u6210\u90e8\u7f72\u6210\u672c\u8fc7\u9ad8\uff1b2) \u7f3a\u4e4f\u53ef\u9760\u7684\u6700\u4f18\u5019\u9009\u65b9\u6848\u9009\u62e9\u673a\u5236\uff0c\u9650\u5236\u4e86\u6027\u80fd\u63d0\u5347\u6f5c\u529b\u3002", "method": "\u63d0\u51fa\u71b5\u5f15\u5bfc\u9010\u6b65\u6269\u5c55\u6846\u67b6\uff0c\u901a\u8fc7\u71b5\u5f15\u5bfc\u7684\u81ea\u9002\u5e94\u641c\u7d22\u548c\u9c81\u68d2\u7684\u6d4b\u8bd5\u5957\u4ef6\u589e\u5f3a\uff0c\u52a8\u6001\u5e73\u8861\u6548\u7387\u4e0e\u6548\u679c\u3002", "result": "\u5728SWE-Bench-Verified\u4e0a\uff0cEGSS\u5c06\u6027\u80fd\u63d0\u53475-10%\uff0cKimi-K2-Intruct\u89e3\u51b3\u7387\u4ece63.2%\u63d0\u5347\u81f372.2%\uff0cGLM-4.6\u4ece65.8%\u63d0\u5347\u81f374.6%\u3002\u4e0eGLM-4.6\u7ed3\u5408\u8fbe\u5230\u5f00\u6e90\u5927\u6a21\u578bSOTA\uff0c\u540c\u65f6\u51cf\u5c1128%\u63a8\u7406\u65f6token\u4f7f\u7528\u3002", "conclusion": "EGSS\u6709\u6548\u89e3\u51b3\u4e86Agentic\u6d4b\u8bd5\u65f6\u6269\u5c55\u7684\u8ba1\u7b97\u6548\u7387\u95ee\u9898\uff0c\u5728\u4fdd\u6301\u6027\u80fd\u4f18\u52bf\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u5f00\u9500\uff0c\u4e3a\u5b9e\u9645\u90e8\u7f72\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2602.05270", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.05270", "abs": "https://arxiv.org/abs/2602.05270", "authors": ["Thanh Le-Cong", "Bach Le", "Toby Murray", "Michael Pradel", "Cristian Cadar"], "title": "PatchGuru: Patch Oracle Inference from Natural Language Artifacts with Large Language Models", "comment": null, "summary": "As software systems evolve, patches may unintentionally alter program behavior. Validating patches against their intended semantics is difficult due to incomplete regression tests and informal, non-executable natural language (NL) descriptions of patch intent. We present PatchGuru, the first automated technique that infers executable patch specifications from real-world pull requests (PRs). Given a PR, PatchGuru uses large language models (LLMs) to extract developer intent from NL artifacts and synthesizes patch oracles: under-approximate yet practical specifications expressed as runtime assertions in comparison programs that integrate pre- and post-patch versions. Patch oracles focus on patch-relevant behaviors, enable automated validation, and support cross-version properties. PatchGuru iteratively refines inferred oracles by comparing pre- and post-patch behaviors, identifies violations, filters inconsistencies via self-review, and generates bug reports. We evaluate PatchGuru on 400 recent PRs from four widely used open-source Python projects. PatchGuru reports 39 warnings with a precision of 0.62, yielding 24 confirmed true positives, including 12 previously unknown bugs, 11 of which were subsequently fixed by developers. Compared to the state-of-the-art technique Testora, PatchGuru detects 17 more bugs (24 vs. 7) while improving precision from 0.32 to 0.62. PatchGuru incurs an average cost of 8.9 minutes and USD 0.07 per PR. These results suggest that PatchGuru complements code review and regression testing by providing executable documentation and automated validation of patch intent.", "AI": {"tldr": "PatchGuru\uff1a\u9996\u4e2a\u4ece\u771f\u5b9ePR\u4e2d\u81ea\u52a8\u63a8\u65ad\u53ef\u6267\u884c\u8865\u4e01\u89c4\u8303\u7684\u6280\u672f\uff0c\u5229\u7528LLM\u4ece\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\u4e2d\u63d0\u53d6\u5f00\u53d1\u8005\u610f\u56fe\uff0c\u751f\u6210\u8865\u4e01\u9884\u8a00\uff08\u8fd0\u884c\u65f6\u65ad\u8a00\uff09\uff0c\u7528\u4e8e\u9a8c\u8bc1\u8865\u4e01\u884c\u4e3a\u5e76\u53d1\u73b0bug\u3002", "motivation": "\u8f6f\u4ef6\u7cfb\u7edf\u6f14\u5316\u4e2d\uff0c\u8865\u4e01\u53ef\u80fd\u65e0\u610f\u6539\u53d8\u7a0b\u5e8f\u884c\u4e3a\u3002\u7531\u4e8e\u56de\u5f52\u6d4b\u8bd5\u4e0d\u5b8c\u6574\u4e14\u8865\u4e01\u610f\u56fe\u63cf\u8ff0\u662f\u975e\u6b63\u5f0f\u7684\u81ea\u7136\u8bed\u8a00\uff0c\u9a8c\u8bc1\u8865\u4e01\u662f\u5426\u7b26\u5408\u9884\u671f\u8bed\u4e49\u5f88\u56f0\u96be\u3002", "method": "\u7ed9\u5b9aPR\uff0cPatchGuru\u4f7f\u7528LLM\u4ece\u81ea\u7136\u8bed\u8a00\u5de5\u4ef6\u4e2d\u63d0\u53d6\u5f00\u53d1\u8005\u610f\u56fe\uff0c\u5408\u6210\u8865\u4e01\u9884\u8a00\uff08\u6bd4\u8f83\u7a0b\u5e8f\u4e2d\u96c6\u6210\u524d\u540e\u7248\u672c\u7684\u8fd0\u884c\u65f6\u65ad\u8a00\uff09\u3002\u901a\u8fc7\u8fed\u4ee3\u7cbe\u70bc\u63a8\u65ad\u7684\u9884\u8a00\uff0c\u6bd4\u8f83\u524d\u540e\u7248\u672c\u884c\u4e3a\uff0c\u8bc6\u522b\u8fdd\u89c4\uff0c\u901a\u8fc7\u81ea\u5ba1\u8fc7\u6ee4\u4e0d\u4e00\u81f4\u6027\uff0c\u751f\u6210bug\u62a5\u544a\u3002", "result": "\u57284\u4e2a\u5e7f\u6cdb\u4f7f\u7528\u7684\u5f00\u6e90Python\u9879\u76ee\u7684400\u4e2a\u8fd1\u671fPR\u4e0a\u8bc4\u4f30\uff0cPatchGuru\u62a5\u544a39\u4e2a\u8b66\u544a\uff0c\u7cbe\u5ea60.62\uff0c\u4ea7\u751f24\u4e2a\u786e\u8ba4\u7684\u771f\u9633\u6027\uff08\u5305\u62ec12\u4e2a\u5148\u524d\u672a\u77e5\u7684bug\uff0c\u5176\u4e2d11\u4e2a\u88ab\u5f00\u53d1\u8005\u4fee\u590d\uff09\u3002\u76f8\u6bd4\u6700\u5148\u8fdb\u6280\u672fTestora\uff0c\u591a\u68c0\u6d4b17\u4e2abug\uff0824 vs 7\uff09\uff0c\u7cbe\u5ea6\u4ece0.32\u63d0\u5347\u52300.62\u3002\u6bcf\u4e2aPR\u5e73\u5747\u6210\u672c8.9\u5206\u949f\u548c0.07\u7f8e\u5143\u3002", "conclusion": "PatchGuru\u901a\u8fc7\u63d0\u4f9b\u53ef\u6267\u884c\u6587\u6863\u548c\u8865\u4e01\u610f\u56fe\u7684\u81ea\u52a8\u9a8c\u8bc1\uff0c\u8865\u5145\u4e86\u4ee3\u7801\u5ba1\u67e5\u548c\u56de\u5f52\u6d4b\u8bd5\u3002"}}
{"id": "2602.05312", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.05312", "abs": "https://arxiv.org/abs/2602.05312", "authors": ["Tatsuya Shirai", "Olivier Nourry", "Yutaro Kashiwa", "Kenji Fujiwara", "Hajimu Iida"], "title": "Does Programming Language Matter? An Empirical Study of Fuzzing Bug Detection", "comment": "Accepted to the 23rd International Conference on Mining Software Repositories (MSR 2026). 12 pages, 9 figures", "summary": "Fuzzing has become a popular technique for automatically detecting vulnerabilities and bugs by generating unexpected inputs. In recent years, the fuzzing process has been integrated into continuous integration workflows (i.e., continuous fuzzing), enabling short and frequent testing cycles. Despite its widespread adoption, prior research has not examined whether the effectiveness of continuous fuzzing varies across programming languages. This study conducts a large-scale cross-language analysis to examine how fuzzing bug characteristics and detection efficiency differ among languages. We analyze 61,444 fuzzing bugs and 999,248 builds from 559 OSS-Fuzz projects categorized by primary language. Our findings reveal that (i) C++ and Rust exhibit higher fuzzing bug detection frequencies, (ii) Rust and Python show low vulnerability ratios but tend to expose more critical vulnerabilities, (iii) crash types vary across languages and unreproducible bugs are more frequent in Go but rare in Rust, and (iv) Python attains higher patch coverage but suffers from longer time-to-detection. These results demonstrate that fuzzing behavior and effectiveness are strongly shaped by language design, providing insights for language-aware fuzzing strategies and tool development.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5bf961,444\u4e2a\u6a21\u7cca\u6d4b\u8bd5\u6f0f\u6d1e\u548c999,248\u6b21\u6784\u5efa\u8fdb\u884c\u5927\u89c4\u6a21\u8de8\u8bed\u8a00\u5206\u6790\uff0c\u53d1\u73b0\u6a21\u7cca\u6d4b\u8bd5\u6548\u679c\u56e0\u7f16\u7a0b\u8bed\u8a00\u800c\u5f02\uff1aC++\u548cRust\u68c0\u6d4b\u9891\u7387\u9ad8\uff0cRust\u548cPython\u6f0f\u6d1e\u6bd4\u4f8b\u4f4e\u4f46\u4e25\u91cd\u6027\u9ad8\uff0cGo\u4e2d\u4e0d\u53ef\u590d\u73b0\u6f0f\u6d1e\u591a\u800cRust\u4e2d\u5c11\uff0cPython\u8865\u4e01\u8986\u76d6\u7387\u9ad8\u4f46\u68c0\u6d4b\u65f6\u95f4\u957f\u3002", "motivation": "\u5c3d\u7ba1\u6a21\u7cca\u6d4b\u8bd5\u5df2\u5e7f\u6cdb\u5e94\u7528\u4e8e\u6301\u7eed\u96c6\u6210\u6d41\u7a0b\uff0c\u4f46\u5148\u524d\u7814\u7a76\u672a\u63a2\u8ba8\u4e0d\u540c\u7f16\u7a0b\u8bed\u8a00\u4e0b\u6301\u7eed\u6a21\u7cca\u6d4b\u8bd5\u7684\u6548\u679c\u5dee\u5f02\u3002\u672c\u7814\u7a76\u65e8\u5728\u5206\u6790\u6a21\u7cca\u6d4b\u8bd5\u6f0f\u6d1e\u7279\u5f81\u548c\u68c0\u6d4b\u6548\u7387\u5728\u4e0d\u540c\u8bed\u8a00\u95f4\u7684\u5dee\u5f02\u3002", "method": "\u5bf9559\u4e2aOSS-Fuzz\u9879\u76ee\u8fdb\u884c\u5927\u89c4\u6a21\u8de8\u8bed\u8a00\u5206\u6790\uff0c\u6db5\u76d661,444\u4e2a\u6a21\u7cca\u6d4b\u8bd5\u6f0f\u6d1e\u548c999,248\u6b21\u6784\u5efa\uff0c\u6309\u4e3b\u8981\u7f16\u7a0b\u8bed\u8a00\uff08C++\u3001Rust\u3001Python\u3001Go\u7b49\uff09\u5206\u7c7b\u7814\u7a76\u3002", "result": "1) C++\u548cRust\u7684\u6a21\u7cca\u6d4b\u8bd5\u6f0f\u6d1e\u68c0\u6d4b\u9891\u7387\u66f4\u9ad8\uff1b2) Rust\u548cPython\u7684\u6f0f\u6d1e\u6bd4\u4f8b\u8f83\u4f4e\u4f46\u503e\u5411\u4e8e\u66b4\u9732\u66f4\u4e25\u91cd\u7684\u5b89\u5168\u6f0f\u6d1e\uff1b3) \u5d29\u6e83\u7c7b\u578b\u56e0\u8bed\u8a00\u800c\u5f02\uff0cGo\u4e2d\u4e0d\u53ef\u590d\u73b0\u6f0f\u6d1e\u66f4\u5e38\u89c1\u800cRust\u4e2d\u7f55\u89c1\uff1b4) Python\u7684\u8865\u4e01\u8986\u76d6\u7387\u66f4\u9ad8\u4f46\u68c0\u6d4b\u65f6\u95f4\u66f4\u957f\u3002", "conclusion": "\u6a21\u7cca\u6d4b\u8bd5\u884c\u4e3a\u548c\u6548\u679c\u53d7\u8bed\u8a00\u8bbe\u8ba1\u5f71\u54cd\u663e\u8457\uff0c\u7814\u7a76\u7ed3\u679c\u4e3a\u8bed\u8a00\u611f\u77e5\u7684\u6a21\u7cca\u6d4b\u8bd5\u7b56\u7565\u548c\u5de5\u5177\u5f00\u53d1\u63d0\u4f9b\u4e86\u91cd\u8981\u89c1\u89e3\u3002"}}
{"id": "2602.05465", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.05465", "abs": "https://arxiv.org/abs/2602.05465", "authors": ["Alexander Berndt", "Vekil Bekmyradov", "Rainer Gemulla", "Marcus Kessel", "Thomas Bach", "Sebastian Baltes"], "title": "Can We Classify Flaky Tests Using Only Test Code? An LLM-Based Empirical Study", "comment": "10 pages, 3 figures, 7 tables, 33rd IEEE International Conference on Software Analysis, Evolution and Reengineering: Reproducibility Studies and Negative Results (SANER-RENE 2025)", "summary": "Flaky tests yield inconsistent results when they are repeatedly executed on the same code revision. They interfere with automated quality assurance of code changes and hinder efficient software testing. Previous work evaluated approaches to train machine learning models to classify flaky tests based on identifiers in the test code. However, the resulting classifiers have been shown to lack generalizability, hindering their applicability in practical environments. Recently, pre-trained Large Language Models (LLMs) have shown the capability to generalize across various tasks. Thus, they represent a promising approach to address the generalizability problem of previous approaches. In this study, we evaluated three LLMs (two general-purpose models, one code-specific model) using three prompting techniques on two benchmark datasets from prior studies on flaky test classification. Furthermore, we manually investigated 50 samples from the given datasets to determine whether classifying flaky tests based only on test code is feasible for humans. Our findings indicate that LLMs struggle to classify flaky tests given only the test code. The results of our best prompt-model combination were only marginally better than random guessing. In our manual analysis, we found that the test code does not necessarily contain sufficient information for a flakiness classification. Our findings motivate future work to evaluate LLMs for flakiness classification with additional context, for example, using retrieval-augmented generation or agentic AI.", "AI": {"tldr": "LLMs\u5728\u4ec5\u57fa\u4e8e\u6d4b\u8bd5\u4ee3\u7801\u7684\u60c5\u51b5\u4e0b\u96be\u4ee5\u6709\u6548\u5206\u7c7bflaky tests\uff0c\u6548\u679c\u4ec5\u7565\u4f18\u4e8e\u968f\u673a\u731c\u6d4b\uff0c\u56e0\u4e3a\u6d4b\u8bd5\u4ee3\u7801\u672c\u8eab\u53ef\u80fd\u4e0d\u5305\u542b\u8db3\u591f\u7684flakiness\u4fe1\u606f\u3002", "motivation": "Flaky tests\u4f1a\u5e72\u6270\u4ee3\u7801\u53d8\u66f4\u7684\u81ea\u52a8\u5316\u8d28\u91cf\u4fdd\u8bc1\u5e76\u963b\u788d\u9ad8\u6548\u8f6f\u4ef6\u6d4b\u8bd5\u3002\u5148\u524d\u57fa\u4e8e\u6d4b\u8bd5\u4ee3\u7801\u6807\u8bc6\u7b26\u8bad\u7ec3\u673a\u5668\u5b66\u4e60\u6a21\u578b\u7684\u65b9\u6cd5\u7f3a\u4e4f\u6cdb\u5316\u80fd\u529b\uff0c\u800c\u9884\u8bad\u7ec3LLMs\u5728\u8de8\u4efb\u52a1\u6cdb\u5316\u65b9\u9762\u8868\u73b0\u51fa\u6f5c\u529b\uff0c\u6709\u671b\u89e3\u51b3\u5148\u524d\u65b9\u6cd5\u7684\u6cdb\u5316\u95ee\u9898\u3002", "method": "\u8bc4\u4f30\u4e86\u4e09\u4e2aLLMs\uff08\u4e24\u4e2a\u901a\u7528\u6a21\u578b\uff0c\u4e00\u4e2a\u4ee3\u7801\u4e13\u7528\u6a21\u578b\uff09\uff0c\u4f7f\u7528\u4e09\u79cd\u63d0\u793a\u6280\u672f\uff0c\u5728\u4e24\u4e2aflaky test\u5206\u7c7b\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u6d4b\u8bd5\u3002\u540c\u65f6\u624b\u52a8\u8c03\u67e5\u4e8650\u4e2a\u6837\u672c\uff0c\u4ee5\u786e\u5b9a\u4ec5\u57fa\u4e8e\u6d4b\u8bd5\u4ee3\u7801\u5bf9\u4eba\u7c7b\u662f\u5426\u53ef\u884c\u3002", "result": "LLMs\u5728\u4ec5\u57fa\u4e8e\u6d4b\u8bd5\u4ee3\u7801\u7684\u60c5\u51b5\u4e0b\u96be\u4ee5\u6709\u6548\u5206\u7c7bflaky tests\uff0c\u6700\u4f73\u63d0\u793a-\u6a21\u578b\u7ec4\u5408\u7684\u7ed3\u679c\u4ec5\u7565\u4f18\u4e8e\u968f\u673a\u731c\u6d4b\u3002\u624b\u52a8\u5206\u6790\u53d1\u73b0\u6d4b\u8bd5\u4ee3\u7801\u4e0d\u4e00\u5b9a\u5305\u542b\u8db3\u591f\u7684flakiness\u5206\u7c7b\u4fe1\u606f\u3002", "conclusion": "\u4ec5\u57fa\u4e8e\u6d4b\u8bd5\u4ee3\u7801\u8fdb\u884cflakiness\u5206\u7c7b\u5b58\u5728\u5c40\u9650\u6027\uff0c\u672a\u6765\u5de5\u4f5c\u5e94\u8bc4\u4f30LLMs\u5728\u9644\u52a0\u4e0a\u4e0b\u6587\uff08\u5982\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u6216\u4ee3\u7406AI\uff09\u4e0b\u7684flakiness\u5206\u7c7b\u80fd\u529b\u3002"}}
{"id": "2602.05523", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.05523", "abs": "https://arxiv.org/abs/2602.05523", "authors": ["Shahin Honarvar", "Amber Gorzynski", "James Lee-Jones", "Harry Coppock", "Marek Rei", "Joseph Ryan", "Alastair F. Donaldson"], "title": "Capture the Flags: Family-Based Evaluation of Agentic LLMs via Semantics-Preserving Transformations", "comment": null, "summary": "Agentic large language models (LLMs) are increasingly evaluated on cybersecurity tasks using capture-the-flag (CTF) benchmarks. However, existing pointwise benchmarks have limited ability to shed light on the robustness and generalisation abilities of agents across alternative versions of the source code. We introduce CTF challenge families, whereby a single CTF is used as the basis for generating a family of semantically-equivalent challenges via semantics-preserving program transformations. This enables controlled evaluation of agent robustness to source code transformations while keeping the underlying exploit strategy fixed. We introduce a new tool, Evolve-CTF, that generates CTF families from Python challenges using a range of transformations. Using Evolve-CTF to derive families from Cybench and Intercode challenges, we evaluate 13 agentic LLM configurations with tool access. We find that models are remarkably robust to intrusive renaming and code insertion-based transformations, but that composed transformations and deeper obfuscation affect performance by requiring more sophisticated use of tools. We also find that enabling explicit reasoning has little effect on solution success rates across challenge families. Our work contributes a valuable technique and tool for future LLM evaluations, and a large dataset characterising the capabilities of current state-of-the-art models in this domain.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faCTF\u6311\u6218\u5bb6\u65cf\u6982\u5ff5\uff0c\u901a\u8fc7\u8bed\u4e49\u4fdd\u7559\u7684\u7a0b\u5e8f\u53d8\u6362\u751f\u6210\u7b49\u4ef7\u6311\u6218\uff0c\u7528\u4e8e\u8bc4\u4f30LLM\u4ee3\u7406\u5728\u7f51\u7edc\u5b89\u5168\u4efb\u52a1\u4e2d\u7684\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u80fd\u529b\uff0c\u5e76\u5f00\u53d1\u4e86Evolve-CTF\u5de5\u5177\u8fdb\u884c\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "motivation": "\u73b0\u6709CTF\u57fa\u51c6\u6d4b\u8bd5\u53ea\u80fd\u8fdb\u884c\u70b9\u72b6\u8bc4\u4f30\uff0c\u65e0\u6cd5\u6df1\u5165\u5206\u6790\u667a\u80fd\u4f53\u5728\u4e0d\u540c\u4ee3\u7801\u53d8\u4f53\u4e0a\u7684\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u80fd\u529b\uff0c\u9700\u8981\u66f4\u7cfb\u7edf\u7684\u65b9\u6cd5\u6765\u8bc4\u4f30LLM\u4ee3\u7406\u5728\u7f51\u7edc\u5b89\u5168\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002", "method": "\u63d0\u51faCTF\u6311\u6218\u5bb6\u65cf\u6982\u5ff5\uff0c\u4f7f\u7528\u8bed\u4e49\u4fdd\u7559\u7684\u7a0b\u5e8f\u53d8\u6362\u751f\u6210\u7b49\u4ef7\u6311\u6218\uff1b\u5f00\u53d1Evolve-CTF\u5de5\u5177\uff0c\u5bf9Python\u6311\u6218\u5e94\u7528\u591a\u79cd\u53d8\u6362\u751f\u6210\u5bb6\u65cf\uff1b\u5728Cybench\u548cIntercode\u6311\u6218\u4e0a\u8bc4\u4f3013\u79cdLLM\u4ee3\u7406\u914d\u7f6e\u3002", "result": "\u6a21\u578b\u5bf9\u91cd\u547d\u540d\u548c\u4ee3\u7801\u63d2\u5165\u53d8\u6362\u8868\u73b0\u51fa\u8f83\u5f3a\u9c81\u68d2\u6027\uff0c\u4f46\u7ec4\u5408\u53d8\u6362\u548c\u6df1\u5ea6\u6df7\u6dc6\u4f1a\u5f71\u54cd\u6027\u80fd\uff1b\u663e\u5f0f\u63a8\u7406\u5bf9\u6210\u529f\u7387\u5f71\u54cd\u6709\u9650\uff1b\u63d0\u4f9b\u4e86\u5927\u89c4\u6a21\u6570\u636e\u96c6\u548c\u8bc4\u4f30\u5de5\u5177\u3002", "conclusion": "CTF\u6311\u6218\u5bb6\u65cf\u4e3aLLM\u8bc4\u4f30\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u5de5\u5177\u548c\u65b9\u6cd5\uff0c\u63ed\u793a\u4e86\u5f53\u524d\u6700\u5148\u8fdb\u6a21\u578b\u5728\u7f51\u7edc\u5b89\u5168\u9886\u57df\u7684\u6027\u80fd\u7279\u70b9\u548c\u5c40\u9650\u6027\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u57fa\u51c6\u548c\u65b9\u5411\u3002"}}
{"id": "2602.05550", "categories": ["cs.SE", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.05550", "abs": "https://arxiv.org/abs/2602.05550", "authors": ["Yulong He", "Artem Ermakov", "Sergey Kovalchuk", "Artem Aliev", "Dmitry Shalymov"], "title": "ArkTS-CodeSearch: A Open-Source ArkTS Dataset for Code Retrieval", "comment": null, "summary": "ArkTS is a core programming language in the OpenHarmony ecosystem, yet research on ArkTS code intelligence is hindered by the lack of public datasets and evaluation benchmarks. This paper presents a large-scale ArkTS dataset constructed from open-source repositories, targeting code retrieval and code evaluation tasks. We design a single-search task, where natural language comments are used to retrieve corresponding ArkTS functions. ArkTS repositories are crawled from GitHub and Gitee, and comment-function pairs are extracted using tree-sitter-arkts, followed by cross-platform deduplication and statistical analysis of ArkTS function types. We further evaluate all existing open-source code embedding models on the single-search task and perform fine-tuning using both ArkTS and TypeScript training datasets, resulting in a high-performing model for ArkTS code understanding. This work establishes the first systematic benchmark for ArkTS code retrieval. Both the dataset and our fine-tuned model will be released publicly and are available at https://huggingface.co/hreyulog/embedinggemma_arkts and https://huggingface.co/datasets/hreyulog/arkts-code-docstring,establishing the first systematic benchmark for ArkTS code retrieval.", "AI": {"tldr": "\u672c\u6587\u6784\u5efa\u4e86\u9996\u4e2a\u5927\u89c4\u6a21ArkTS\u4ee3\u7801\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u4ee3\u7801\u68c0\u7d22\u548c\u8bc4\u4f30\u4efb\u52a1\uff0c\u5e76\u8bc4\u4f30\u4e86\u73b0\u6709\u5f00\u6e90\u4ee3\u7801\u5d4c\u5165\u6a21\u578b\uff0c\u901a\u8fc7\u5fae\u8c03\u5f97\u5230\u4e86\u9ad8\u6027\u80fd\u7684ArkTS\u4ee3\u7801\u7406\u89e3\u6a21\u578b\u3002", "motivation": "OpenHarmony\u751f\u6001\u7cfb\u7edf\u4e2d\u7684\u6838\u5fc3\u7f16\u7a0b\u8bed\u8a00ArkTS\u7f3a\u4e4f\u516c\u5f00\u6570\u636e\u96c6\u548c\u8bc4\u4f30\u57fa\u51c6\uff0c\u963b\u788d\u4e86ArkTS\u4ee3\u7801\u667a\u80fd\u7814\u7a76\u7684\u53d1\u5c55\u3002", "method": "\u4eceGitHub\u548cGitee\u722c\u53d6ArkTS\u4ed3\u5e93\uff0c\u4f7f\u7528tree-sitter-arkts\u63d0\u53d6\u6ce8\u91ca-\u51fd\u6570\u5bf9\uff0c\u8fdb\u884c\u8de8\u5e73\u53f0\u53bb\u91cd\u548c\u7edf\u8ba1\u5206\u6790\uff1b\u8bbe\u8ba1\u5355\u641c\u7d22\u4efb\u52a1\uff0c\u8bc4\u4f30\u73b0\u6709\u5f00\u6e90\u4ee3\u7801\u5d4c\u5165\u6a21\u578b\uff0c\u5e76\u4f7f\u7528ArkTS\u548cTypeScript\u8bad\u7ec3\u6570\u636e\u96c6\u8fdb\u884c\u5fae\u8c03\u3002", "result": "\u5efa\u7acb\u4e86\u9996\u4e2aArkTS\u4ee3\u7801\u68c0\u7d22\u7cfb\u7edf\u57fa\u51c6\uff0c\u53d1\u5e03\u4e86\u6570\u636e\u96c6\u548c\u5fae\u8c03\u6a21\u578b\uff0c\u4e3aArkTS\u4ee3\u7801\u667a\u80fd\u7814\u7a76\u63d0\u4f9b\u4e86\u57fa\u7840\u8d44\u6e90\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u586b\u8865\u4e86ArkTS\u4ee3\u7801\u667a\u80fd\u7814\u7a76\u7684\u7a7a\u767d\uff0c\u4e3a\u540e\u7eed\u7814\u7a76\u63d0\u4f9b\u4e86\u6570\u636e\u96c6\u3001\u57fa\u51c6\u548c\u9884\u8bad\u7ec3\u6a21\u578b\uff0c\u5c06\u4fc3\u8fdbOpenHarmony\u751f\u6001\u7cfb\u7edf\u7684\u53d1\u5c55\u3002"}}
{"id": "2602.05703", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.05703", "abs": "https://arxiv.org/abs/2602.05703", "authors": ["Tom\u00e1\u0161 Brablec", "Tom\u00e1\u0161 Dac\u00edk", "Tom\u00e1\u0161 Vojnar"], "title": "SEAL: Symbolic Execution with Separation Logic (Competition Contribution)", "comment": "4 pages, accepted to SV-COMP 2026", "summary": "SEAL is a static analyser for the verification of programs that manipulate unbounded linked data structures. It is based on separation logic to represent abstract memory states and, unlike other separation-logic-based approaches, it employs a general-purpose separation logic solver Astral for satisfiability and entailment checking, which itself is based on translation to SMT. This design results in a modular architecture intended to be easier to extend and to combine with reasoning in other theories. Although still a prototype, SEAL achieved competitive results in the LinkedLists base category and was one of only four analysers capable of verifying programs with unbounded lists. We believe that the tool's extensibility, combined with further development, can lead to significant improvements in future competitions.", "AI": {"tldr": "SEAL\u662f\u4e00\u4e2a\u57fa\u4e8e\u5206\u79bb\u903b\u8f91\u7684\u9759\u6001\u5206\u6790\u5de5\u5177\uff0c\u7528\u4e8e\u9a8c\u8bc1\u64cd\u4f5c\u65e0\u754c\u94fe\u8868\u6570\u636e\u7ed3\u6784\u7684\u7a0b\u5e8f\uff0c\u91c7\u7528\u6a21\u5757\u5316\u67b6\u6784\u548c\u901a\u7528\u5206\u79bb\u903b\u8f91\u6c42\u89e3\u5668Astral\uff0c\u5728\u94fe\u8868\u9a8c\u8bc1\u65b9\u9762\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u73b0\u6709\u7684\u5206\u79bb\u903b\u8f91\u65b9\u6cd5\u901a\u5e38\u7f3a\u4e4f\u6a21\u5757\u5316\u548c\u53ef\u6269\u5c55\u6027\uff0c\u96be\u4ee5\u4e0e\u5176\u4ed6\u7406\u8bba\u63a8\u7406\u7ed3\u5408\u3002SEAL\u65e8\u5728\u63d0\u4f9b\u4e00\u4e2a\u66f4\u6613\u6269\u5c55\u3001\u6a21\u5757\u5316\u7684\u9a8c\u8bc1\u6846\u67b6\uff0c\u4e13\u95e8\u9488\u5bf9\u65e0\u754c\u94fe\u8868\u6570\u636e\u7ed3\u6784\u7684\u7a0b\u5e8f\u9a8c\u8bc1\u3002", "method": "\u57fa\u4e8e\u5206\u79bb\u903b\u8f91\u8868\u793a\u62bd\u8c61\u5185\u5b58\u72b6\u6001\uff0c\u4f7f\u7528\u901a\u7528\u5206\u79bb\u903b\u8f91\u6c42\u89e3\u5668Astral\u8fdb\u884c\u53ef\u6ee1\u8db3\u6027\u548c\u8574\u542b\u68c0\u67e5\uff0cAstral\u672c\u8eab\u57fa\u4e8eSMT\u8f6c\u6362\u3002\u91c7\u7528\u6a21\u5757\u5316\u67b6\u6784\u8bbe\u8ba1\uff0c\u4fbf\u4e8e\u6269\u5c55\u548c\u4e0e\u5176\u4ed6\u7406\u8bba\u63a8\u7406\u7ed3\u5408\u3002", "result": "\u5728LinkedLists\u57fa\u7840\u7c7b\u522b\u4e2d\u53d6\u5f97\u7ade\u4e89\u6027\u7ed3\u679c\uff0c\u662f\u4ec5\u6709\u7684\u56db\u4e2a\u80fd\u591f\u9a8c\u8bc1\u65e0\u754c\u94fe\u8868\u7a0b\u5e8f\u7684\u5206\u6790\u5668\u4e4b\u4e00\u3002\u867d\u7136\u4ecd\u662f\u539f\u578b\uff0c\u4f46\u5c55\u793a\u4e86\u5176\u6709\u6548\u6027\u3002", "conclusion": "SEAL\u7684\u6a21\u5757\u5316\u67b6\u6784\u548c\u53ef\u6269\u5c55\u6027\u8bbe\u8ba1\uff0c\u7ed3\u5408\u8fdb\u4e00\u6b65\u5f00\u53d1\uff0c\u6709\u671b\u5728\u672a\u6765\u7ade\u8d5b\u4e2d\u53d6\u5f97\u663e\u8457\u6539\u8fdb\u3002\u8be5\u5de5\u5177\u4e3a\u5206\u79bb\u903b\u8f91\u9a8c\u8bc1\u63d0\u4f9b\u4e86\u66f4\u7075\u6d3b\u3001\u53ef\u6269\u5c55\u7684\u6846\u67b6\u3002"}}
{"id": "2602.05712", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.05712", "abs": "https://arxiv.org/abs/2602.05712", "authors": ["Lola Solovyeva", "Fernando Castor"], "title": "Towards Green AI: Decoding the Energy of LLM Inference in Software Development", "comment": null, "summary": "Context: AI-assisted tools are increasingly integrated into software development workflows, but their reliance on large language models (LLMs) introduces substantial computational and energy costs. Understanding and reducing the energy footprint of LLM inference is therefore essential for sustainable software development. Objective: In this study, we conduct a phase-level analysis of LLM inference energy consumption, distinguishing between the (1) prefill, where the model processes the input and builds internal representations, and (2) decoding, where output tokens are generated using the stored state. Method: We investigate six 6B-7B and four 3B-4B transformer-based models, evaluating them on code-centric benchmarks HumanEval for code generation and LongBench for code understanding. Results: Our findings show that, within both parameter groups, models exhibit distinct energy patterns across phases. Furthermore, we observed that increases in prefill cost amplify the energy cost per token during decoding, with amplifications ranging from 1.3% to 51.8% depending on the model. Lastly, three out of ten models demonstrate babbling behavior, adding excessive content to the output that unnecessarily inflates energy consumption. We implemented babbling suppression for code generation, achieving energy savings ranging from 44% to 89% without affecting generation accuracy. Conclusion: These findings show that prefill costs influence decoding, which dominates energy consumption, and that babbling suppression can yield up to 89% energy savings. Reducing inference energy therefore requires both mitigating babbling behavior and limiting impact of prefill on decoding.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5206\u6790\u4e86LLM\u63a8\u7406\u7684\u80fd\u8017\u6a21\u5f0f\uff0c\u53d1\u73b0\u9884\u586b\u5145\u9636\u6bb5\u6210\u672c\u4f1a\u5f71\u54cd\u89e3\u7801\u9636\u6bb5\u7684\u80fd\u8017\uff0c\u4e14\u67d0\u4e9b\u6a21\u578b\u5b58\u5728\"\u5e9f\u8bdd\"\u884c\u4e3a\u5bfc\u81f4\u80fd\u8017\u6d6a\u8d39\u3002\u901a\u8fc7\u6291\u5236\u5e9f\u8bdd\u884c\u4e3a\uff0c\u53ef\u5728\u4e0d\u5f71\u54cd\u51c6\u786e\u6027\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b044%-89%\u7684\u80fd\u8017\u8282\u7701\u3002", "motivation": "\u968f\u7740AI\u8f85\u52a9\u5de5\u5177\u5728\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5de5\u5177\u5e26\u6765\u4e86\u5de8\u5927\u7684\u8ba1\u7b97\u548c\u80fd\u6e90\u6210\u672c\u3002\u7406\u89e3\u5e76\u51cf\u5c11LLM\u63a8\u7406\u7684\u80fd\u6e90\u8db3\u8ff9\u5bf9\u4e8e\u53ef\u6301\u7eed\u8f6f\u4ef6\u5f00\u53d1\u81f3\u5173\u91cd\u8981\u3002", "method": "\u7814\u7a76\u5206\u6790\u4e866\u4e2a6B-7B\u53c2\u6570\u548c4\u4e2a3B-4B\u53c2\u6570\u7684transformer\u6a21\u578b\uff0c\u5728\u4ee3\u7801\u751f\u6210\uff08HumanEval\uff09\u548c\u4ee3\u7801\u7406\u89e3\uff08LongBench\uff09\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u8fdb\u884c\u8bc4\u4f30\u3002\u533a\u5206\u4e86\u9884\u586b\u5145\u9636\u6bb5\uff08\u5904\u7406\u8f93\u5165\uff09\u548c\u89e3\u7801\u9636\u6bb5\uff08\u751f\u6210\u8f93\u51fa\uff09\u7684\u80fd\u8017\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff1a1\uff09\u4e0d\u540c\u6a21\u578b\u5728\u80fd\u8017\u6a21\u5f0f\u4e0a\u5b58\u5728\u5dee\u5f02\uff1b2\uff09\u9884\u586b\u5145\u6210\u672c\u7684\u589e\u52a0\u4f1a\u653e\u5927\u89e3\u7801\u9636\u6bb5\u7684\u6bcftoken\u80fd\u8017\uff08\u653e\u59271.3%-51.8%\uff09\uff1b3\uff0910\u4e2a\u6a21\u578b\u4e2d\u67093\u4e2a\u8868\u73b0\u51fa\"\u5e9f\u8bdd\"\u884c\u4e3a\uff0c\u6dfb\u52a0\u4e0d\u5fc5\u8981\u5185\u5bb9\u589e\u52a0\u80fd\u8017\uff1b4\uff09\u901a\u8fc7\u6291\u5236\u5e9f\u8bdd\u884c\u4e3a\uff0c\u53ef\u5728\u4e0d\u5f71\u54cd\u51c6\u786e\u6027\u7684\u60c5\u51b5\u4e0b\u8282\u770144%-89%\u7684\u80fd\u8017\u3002", "conclusion": "\u9884\u586b\u5145\u6210\u672c\u4f1a\u5f71\u54cd\u89e3\u7801\u9636\u6bb5\u7684\u80fd\u8017\uff0c\u800c\u89e3\u7801\u9636\u6bb5\u4e3b\u5bfc\u6574\u4f53\u80fd\u8017\u3002\u6291\u5236\u5e9f\u8bdd\u884c\u4e3a\u53ef\u663e\u8457\u8282\u7701\u80fd\u6e90\uff08\u9ad8\u8fbe89%\uff09\u3002\u51cf\u5c11\u63a8\u7406\u80fd\u8017\u9700\u8981\u540c\u65f6\u6291\u5236\u5e9f\u8bdd\u884c\u4e3a\u5e76\u9650\u5236\u9884\u586b\u5145\u5bf9\u89e3\u7801\u7684\u5f71\u54cd\u3002"}}
{"id": "2602.05721", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.05721", "abs": "https://arxiv.org/abs/2602.05721", "authors": ["Bin Liu", "Yanjie Zhao", "Zhenpeng Chen", "Guoai Xu", "Haoyu Wang"], "title": "A Dual-Loop Agent Framework for Automated Vulnerability Reproduction", "comment": null, "summary": "Automated vulnerability reproduction from CVE descriptions requires generating executable Proof-of-Concept (PoC) exploits and validating them in target environments. This process is critical in software security research and practice, yet remains time-consuming and demands specialized expertise when performed manually. While LLM agents show promise for automating this task, existing approaches often conflate exploring attack directions with fixing implementation details, which leads to unproductive debugging loops when reproduction fails. To address this, we propose Cve2PoC, an LLM-based dual-loop agent framework following a plan-execute-evaluate paradigm. The Strategic Planner analyzes vulnerability semantics and target code to produce structured attack plans. The Tactical Executor generates PoC code and validates it through progressive verification. The Adaptive Refiner evaluates execution results and routes failures to different loops: the \\textit{Tactical Loop} for code-level refinement, while the \\textit{Strategic Loop} for attack strategy replanning. This dual-loop design enables the framework to escape ineffective debugging by matching remediation to failure type. Evaluation on two benchmarks covering 617 real-world vulnerabilities demonstrates that Cve2PoC achieves 82.9\\% and 54.3\\% reproduction success rates on SecBench.js and PatchEval, respectively, outperforming the best baseline by 11.3\\% and 20.4\\%. Human evaluation confirms that generated PoCs achieve comparable code quality to human-written exploits in readability and reusability.", "AI": {"tldr": "Cve2PoC\u662f\u4e00\u4e2a\u57fa\u4e8eLLM\u7684\u53cc\u5faa\u73af\u4ee3\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u6218\u7565\u89c4\u5212-\u6218\u672f\u6267\u884c-\u81ea\u9002\u5e94\u4f18\u5316\u7684\u8303\u5f0f\uff0c\u81ea\u52a8\u4eceCVE\u63cf\u8ff0\u751f\u6210\u53ef\u6267\u884c\u7684PoC\u6f0f\u6d1e\u5229\u7528\u4ee3\u7801\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u6f0f\u6d1e\u590d\u73b0\u6210\u529f\u7387\u3002", "motivation": "\u4eceCVE\u63cf\u8ff0\u81ea\u52a8\u590d\u73b0\u6f0f\u6d1e\u9700\u8981\u751f\u6210\u53ef\u6267\u884c\u7684PoC\u5229\u7528\u4ee3\u7801\u5e76\u5728\u76ee\u6807\u73af\u5883\u4e2d\u9a8c\u8bc1\uff0c\u8fd9\u4e00\u8fc7\u7a0b\u5728\u8f6f\u4ef6\u5b89\u5168\u7814\u7a76\u548c\u5b9e\u8df5\u4e2d\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u624b\u52a8\u64cd\u4f5c\u8017\u65f6\u4e14\u9700\u8981\u4e13\u4e1a\u77e5\u8bc6\u3002\u73b0\u6709LLM\u4ee3\u7406\u65b9\u6cd5\u5728\u63a2\u7d22\u653b\u51fb\u65b9\u5411\u548c\u4fee\u590d\u5b9e\u73b0\u7ec6\u8282\u65f6\u5e38\u5e38\u6df7\u6dc6\uff0c\u5bfc\u81f4\u590d\u73b0\u5931\u8d25\u65f6\u9677\u5165\u65e0\u6548\u7684\u8c03\u8bd5\u5faa\u73af\u3002", "method": "\u63d0\u51fa\u4e86Cve2PoC\u6846\u67b6\uff0c\u91c7\u7528\u8ba1\u5212-\u6267\u884c-\u8bc4\u4f30\u8303\u5f0f\uff0c\u5305\u542b\u4e09\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1a\u6218\u7565\u89c4\u5212\u5668\u5206\u6790\u6f0f\u6d1e\u8bed\u4e49\u548c\u76ee\u6807\u4ee3\u7801\u751f\u6210\u7ed3\u6784\u5316\u653b\u51fb\u8ba1\u5212\uff1b\u6218\u672f\u6267\u884c\u5668\u751f\u6210PoC\u4ee3\u7801\u5e76\u901a\u8fc7\u6e10\u8fdb\u9a8c\u8bc1\u8fdb\u884c\u6d4b\u8bd5\uff1b\u81ea\u9002\u5e94\u4f18\u5316\u5668\u8bc4\u4f30\u6267\u884c\u7ed3\u679c\u5e76\u5c06\u5931\u8d25\u8def\u7531\u5230\u4e0d\u540c\u5faa\u73af\uff1a\u6218\u672f\u5faa\u73af\u7528\u4e8e\u4ee3\u7801\u7ea7\u4f18\u5316\uff0c\u6218\u7565\u5faa\u73af\u7528\u4e8e\u653b\u51fb\u7b56\u7565\u91cd\u65b0\u89c4\u5212\u3002\u8fd9\u79cd\u53cc\u5faa\u73af\u8bbe\u8ba1\u4f7f\u6846\u67b6\u80fd\u591f\u6839\u636e\u5931\u8d25\u7c7b\u578b\u5339\u914d\u5408\u9002\u7684\u4fee\u590d\u65b9\u6848\uff0c\u907f\u514d\u65e0\u6548\u8c03\u8bd5\u3002", "result": "\u5728\u4e24\u4e2a\u5305\u542b617\u4e2a\u771f\u5b9e\u6f0f\u6d1e\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e0a\uff0cCve2PoC\u5728SecBench.js\u548cPatchEval\u4e0a\u5206\u522b\u8fbe\u5230\u4e8682.9%\u548c54.3%\u7684\u590d\u73b0\u6210\u529f\u7387\uff0c\u6bd4\u6700\u4f73\u57fa\u7ebf\u5206\u522b\u63d0\u9ad8\u4e8611.3%\u548c20.4%\u3002\u4eba\u5de5\u8bc4\u4f30\u786e\u8ba4\u751f\u6210\u7684PoC\u5728\u53ef\u8bfb\u6027\u548c\u53ef\u91cd\u7528\u6027\u65b9\u9762\u8fbe\u5230\u4e86\u4e0e\u4eba\u5de5\u7f16\u5199\u5229\u7528\u4ee3\u7801\u76f8\u5f53\u7684\u8d28\u91cf\u3002", "conclusion": "Cve2PoC\u901a\u8fc7\u6218\u7565-\u6218\u672f\u5206\u79bb\u7684\u53cc\u5faa\u73af\u8bbe\u8ba1\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709LLM\u4ee3\u7406\u5728\u6f0f\u6d1e\u590d\u73b0\u4e2d\u6df7\u6dc6\u653b\u51fb\u63a2\u7d22\u548c\u5b9e\u73b0\u7ec6\u8282\u7684\u95ee\u9898\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u81ea\u52a8\u5316\u6f0f\u6d1e\u590d\u73b0\u7684\u6210\u529f\u7387\u548c\u4ee3\u7801\u8d28\u91cf\uff0c\u4e3a\u8f6f\u4ef6\u5b89\u5168\u7814\u7a76\u548c\u5b9e\u8df5\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u81ea\u52a8\u5316\u5de5\u5177\u3002"}}
{"id": "2602.05739", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.05739", "abs": "https://arxiv.org/abs/2602.05739", "authors": ["Nazanin Siavash", "Armin Moin"], "title": "A Bayesian Optimization-Based AutoML Framework for Non-Intrusive Load Monitoring", "comment": null, "summary": "Non-Intrusive Load Monitoring (NILM), commonly known as energy disaggregation, aims to estimate the power consumption of individual appliances by analyzing a home's total electricity usage. This method provides a cost-effective alternative to installing dedicated smart meters for each appliance. In this paper, we introduce a novel framework that incorporates Automated Machine Learning (AutoML) into the NILM domain, utilizing Bayesian Optimization for automated model selection and hyperparameter tuning. This framework empowers domain practitioners to effectively apply machine learning techniques without requiring advanced expertise in data science or machine learning. To support further research and industry adoption, we present AutoML4NILM, a flexible and extensible open-source toolkit designed to streamline the deployment of AutoML solutions for energy disaggregation. Currently, this framework supports 11 algorithms, each with different hyperparameters; however, its flexible design allows for the extension of both the algorithms and their hyperparameters.", "AI": {"tldr": "\u63d0\u51faAutoML4NILM\u6846\u67b6\uff0c\u5c06\u81ea\u52a8\u673a\u5668\u5b66\u4e60\u5e94\u7528\u4e8e\u975e\u4fb5\u5165\u5f0f\u8d1f\u8377\u76d1\u6d4b\u9886\u57df\uff0c\u901a\u8fc7\u8d1d\u53f6\u65af\u4f18\u5316\u5b9e\u73b0\u81ea\u52a8\u6a21\u578b\u9009\u62e9\u548c\u8d85\u53c2\u6570\u8c03\u4f18\uff0c\u964d\u4f4e\u9886\u57df\u4e13\u5bb6\u5e94\u7528\u673a\u5668\u5b66\u4e60\u7684\u95e8\u69db\u3002", "motivation": "\u975e\u4fb5\u5165\u5f0f\u8d1f\u8377\u76d1\u6d4b\uff08NILM\uff09\u901a\u8fc7\u5206\u6790\u5bb6\u5ead\u603b\u7528\u7535\u91cf\u6765\u4f30\u8ba1\u5355\u4e2a\u7535\u5668\u529f\u8017\uff0c\u76f8\u6bd4\u4e3a\u6bcf\u4e2a\u7535\u5668\u5b89\u88c5\u4e13\u7528\u667a\u80fd\u7535\u8868\u66f4\u5177\u6210\u672c\u6548\u76ca\u3002\u7136\u800c\uff0c\u5e94\u7528\u673a\u5668\u5b66\u4e60\u6280\u672f\u9700\u8981\u6570\u636e\u79d1\u5b66\u4e13\u4e1a\u77e5\u8bc6\uff0c\u9650\u5236\u4e86\u9886\u57df\u4e13\u5bb6\u7684\u4f7f\u7528\u3002", "method": "\u63d0\u51fa\u5c06\u81ea\u52a8\u673a\u5668\u5b66\u4e60\uff08AutoML\uff09\u5f15\u5165NILM\u9886\u57df\u7684\u65b0\u6846\u67b6\uff0c\u5229\u7528\u8d1d\u53f6\u65af\u4f18\u5316\u8fdb\u884c\u81ea\u52a8\u6a21\u578b\u9009\u62e9\u548c\u8d85\u53c2\u6570\u8c03\u4f18\u3002\u5f00\u53d1\u4e86AutoML4NILM\u5f00\u6e90\u5de5\u5177\u5305\uff0c\u76ee\u524d\u652f\u630111\u79cd\u7b97\u6cd5\u53ca\u5176\u4e0d\u540c\u8d85\u53c2\u6570\uff0c\u4e14\u8bbe\u8ba1\u7075\u6d3b\u53ef\u6269\u5c55\u3002", "result": "\u5f00\u53d1\u4e86AutoML4NILM\u5de5\u5177\u5305\uff0c\u4e3aNILM\u9886\u57df\u63d0\u4f9b\u7075\u6d3b\u53ef\u6269\u5c55\u7684AutoML\u89e3\u51b3\u65b9\u6848\uff0c\u4f7f\u9886\u57df\u4ece\u4e1a\u8005\u65e0\u9700\u9ad8\u7ea7\u6570\u636e\u79d1\u5b66\u4e13\u4e1a\u77e5\u8bc6\u4e5f\u80fd\u6709\u6548\u5e94\u7528\u673a\u5668\u5b66\u4e60\u6280\u672f\u3002", "conclusion": "\u8be5\u6846\u67b6\u901a\u8fc7\u81ea\u52a8\u5316\u673a\u5668\u5b66\u4e60\u6d41\u7a0b\u964d\u4f4e\u4e86NILM\u9886\u57df\u5e94\u7528\u673a\u5668\u5b66\u4e60\u7684\u95e8\u69db\uff0c\u4fc3\u8fdb\u4e86\u7814\u7a76\u548c\u5de5\u4e1a\u5e94\u7528\uff0c\u5f00\u6e90\u5de5\u5177\u5305\u7684\u8bbe\u8ba1\u7075\u6d3b\u6027\u652f\u6301\u7b97\u6cd5\u548c\u8d85\u53c2\u6570\u7684\u8fdb\u4e00\u6b65\u6269\u5c55\u3002"}}
{"id": "2602.05759", "categories": ["cs.SE", "cs.CR"], "pdf": "https://arxiv.org/pdf/2602.05759", "abs": "https://arxiv.org/abs/2602.05759", "authors": ["Lei Zhang"], "title": "Toward Quantum-Safe Software Engineering: A Vision for Post-Quantum Cryptography Migration", "comment": "2 pages, 1 figure, accepted by 2026 IEEE/ACM 48th International Conference on Software Engineering (ICSE'26 Poster Track)", "summary": "The quantum threat to cybersecurity has accelerated the standardization of Post-Quantum Cryptography (PQC). Migrating legacy software to these quantum-safe algorithms is not a simple library swap, but a new software engineering challenge: existing vulnerability detection, refactoring, and testing tools are not designed for PQC's probabilistic behavior, side-channel sensitivity, and complex performance trade-offs. To address these challenges, this paper outlines a vision for a new class of tools and introduces the Automated Quantum-safe Adaptation (AQuA) framework, with a three-pillar agenda for PQC-aware detection, semantic refactoring, and hybrid verification, thereby motivating Quantum-Safe Software Engineering (QSSE) as a distinct research direction.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u91cf\u5b50\u5b89\u5168\u8f6f\u4ef6\u5de5\u7a0b(QSSE)\u65b0\u7814\u7a76\u65b9\u5411\uff0c\u4ecb\u7ecd\u81ea\u52a8\u5316\u91cf\u5b50\u5b89\u5168\u9002\u5e94(AQuA)\u6846\u67b6\uff0c\u5305\u542bPQC\u611f\u77e5\u68c0\u6d4b\u3001\u8bed\u4e49\u91cd\u6784\u548c\u6df7\u5408\u9a8c\u8bc1\u4e09\u5927\u652f\u67f1\uff0c\u4ee5\u5e94\u5bf9\u540e\u91cf\u5b50\u5bc6\u7801\u8fc1\u79fb\u7684\u8f6f\u4ef6\u5de5\u7a0b\u6311\u6218\u3002", "motivation": "\u91cf\u5b50\u8ba1\u7b97\u5bf9\u7f51\u7edc\u5b89\u5168\u7684\u5a01\u80c1\u52a0\u901f\u4e86\u540e\u91cf\u5b50\u5bc6\u7801(PQC)\u6807\u51c6\u5316\uff0c\u4f46\u5c06\u9057\u7559\u8f6f\u4ef6\u8fc1\u79fb\u5230\u91cf\u5b50\u5b89\u5168\u7b97\u6cd5\u5e76\u975e\u7b80\u5355\u7684\u5e93\u66ff\u6362\uff0c\u800c\u662f\u4e00\u4e2a\u65b0\u7684\u8f6f\u4ef6\u5de5\u7a0b\u6311\u6218\u3002\u73b0\u6709\u6f0f\u6d1e\u68c0\u6d4b\u3001\u91cd\u6784\u548c\u6d4b\u8bd5\u5de5\u5177\u65e0\u6cd5\u5904\u7406PQC\u7684\u6982\u7387\u884c\u4e3a\u3001\u4fa7\u4fe1\u9053\u654f\u611f\u6027\u548c\u590d\u6742\u6027\u80fd\u6743\u8861\u3002", "method": "\u63d0\u51fa\u81ea\u52a8\u5316\u91cf\u5b50\u5b89\u5168\u9002\u5e94(AQuA)\u6846\u67b6\uff0c\u5305\u542b\u4e09\u5927\u652f\u67f1\uff1a1) PQC\u611f\u77e5\u68c0\u6d4b\u5de5\u5177\uff0c2) \u8bed\u4e49\u91cd\u6784\u6280\u672f\uff0c3) \u6df7\u5408\u9a8c\u8bc1\u65b9\u6cd5\u3002\u8fd9\u4e9b\u5de5\u5177\u4e13\u95e8\u8bbe\u8ba1\u7528\u4e8e\u5904\u7406PQC\u7279\u6709\u7684\u6311\u6218\u3002", "result": "\u8bba\u6587\u63d0\u51fa\u4e86\u91cf\u5b50\u5b89\u5168\u8f6f\u4ef6\u5de5\u7a0b(QSSE)\u4f5c\u4e3a\u4e00\u4e2a\u72ec\u7acb\u7684\u7814\u7a76\u65b9\u5411\uff0c\u5e76\u6982\u8ff0\u4e86AQuA\u6846\u67b6\u7684\u613f\u666f\uff0c\u4e3a\u540e\u91cf\u5b50\u5bc6\u7801\u8fc1\u79fb\u63d0\u4f9b\u7cfb\u7edf\u5316\u7684\u8f6f\u4ef6\u5de5\u7a0b\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "\u9700\u8981\u4e13\u95e8\u9488\u5bf9\u540e\u91cf\u5b50\u5bc6\u7801\u7279\u6027\u7684\u65b0\u5de5\u5177\u548c\u65b9\u6cd5\uff0cAQuA\u6846\u67b6\u4e3a\u6b64\u63d0\u4f9b\u4e86\u7cfb\u7edf\u5316\u65b9\u6848\uff0c\u91cf\u5b50\u5b89\u5168\u8f6f\u4ef6\u5de5\u7a0b\u5e94\u6210\u4e3a\u4e00\u4e2a\u72ec\u7acb\u7684\u7814\u7a76\u9886\u57df\uff0c\u4ee5\u5e94\u5bf9\u91cf\u5b50\u65f6\u4ee3\u7684\u8f6f\u4ef6\u5b89\u5168\u6311\u6218\u3002"}}
{"id": "2602.05780", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.05780", "abs": "https://arxiv.org/abs/2602.05780", "authors": ["Ulrich Finkler", "Irene Manotas", "Wei Zhang", "Geert Janssen", "Octavian Popescu", "Shyam Ramji"], "title": "Automated Customization of LLMs for Enterprise Code Repositories Using Semantic Scopes", "comment": null, "summary": "Code completion (CC) is a task frequently used by developers when working in collaboration with LLM-based programming assistants. Despite the increased performance of LLMs on public benchmarks, out of the box LLMs still have a hard time generating code that aligns with a private code repository not previously seen by the model's training data. Customizing code LLMs to a private repository provides a way to improve the model performance. In this paper we present our approach for automated LLM customization based on semantic scopes in the code. We evaluate LLMs on real industry cases with two private enterprise code repositories with two customization strategies: Retrieval-Augmented Generation (RAG) and supervised Fine-Tuning (FT). Our mechanism for ingesting the repository's data and formulating the training data pairs with semantic scopes helps models to learn the underlying patterns specific to the repository, providing more precise code to developers and helping to boost their productivity. The code completions of moderately sized customized models can be significantly better than those of uncustomized models of much larger capacity. We also include an analysis of customization on two public benchmarks and present opportunities for future work.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u57fa\u4e8e\u4ee3\u7801\u8bed\u4e49\u8303\u56f4\u7684\u81ea\u52a8\u5316LLM\u5b9a\u5236\u65b9\u6cd5\uff0c\u901a\u8fc7RAG\u548c\u5fae\u8c03\u7b56\u7565\u63d0\u5347\u6a21\u578b\u5728\u79c1\u6709\u4ee3\u7801\u5e93\u4e0a\u7684\u4ee3\u7801\u8865\u5168\u6027\u80fd\uff0c\u5b9a\u5236\u540e\u4e2d\u7b49\u89c4\u6a21\u6a21\u578b\u8868\u73b0\u4f18\u4e8e\u672a\u5b9a\u5236\u7684\u5927\u89c4\u6a21\u6a21\u578b\u3002", "motivation": "\u5c3d\u7ba1LLM\u5728\u516c\u5f00\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u5904\u7406\u672a\u89c1\u8fc7\u8bad\u7ec3\u6570\u636e\u7684\u79c1\u6709\u4ee3\u7801\u5e93\u65f6\uff0c\u751f\u6210\u7684\u4ee3\u7801\u96be\u4ee5\u4e0e\u79c1\u6709\u4ee3\u7801\u5e93\u5bf9\u9f50\u3002\u5b9a\u5236\u5316\u4ee3\u7801LLM\u53ef\u4ee5\u63d0\u5347\u6a21\u578b\u5728\u7279\u5b9a\u79c1\u6709\u4ee3\u7801\u5e93\u4e0a\u7684\u6027\u80fd\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u4ee3\u7801\u8bed\u4e49\u8303\u56f4\u7684\u81ea\u52a8\u5316LLM\u5b9a\u5236\u65b9\u6cd5\uff0c\u901a\u8fc7\u8bed\u4e49\u8303\u56f4\u673a\u5236\u5904\u7406\u4ee3\u7801\u5e93\u6570\u636e\u5e76\u6784\u5efa\u8bad\u7ec3\u6570\u636e\u5bf9\u3002\u8bc4\u4f30\u4e24\u79cd\u5b9a\u5236\u7b56\u7565\uff1a\u68c0\u7d22\u589e\u5f3a\u751f\u6210(RAG)\u548c\u76d1\u7763\u5fae\u8c03(FT)\uff0c\u5728\u4e24\u4e2a\u79c1\u6709\u4f01\u4e1a\u4ee3\u7801\u5e93\u4e0a\u8fdb\u884c\u5b9e\u9a8c\u3002", "result": "\u5b9a\u5236\u540e\u7684\u4e2d\u7b49\u89c4\u6a21\u6a21\u578b\u5728\u4ee3\u7801\u8865\u5168\u4efb\u52a1\u4e0a\u8868\u73b0\u663e\u8457\u4f18\u4e8e\u672a\u5b9a\u5236\u7684\u5927\u89c4\u6a21\u6a21\u578b\u3002\u8bed\u4e49\u8303\u56f4\u673a\u5236\u5e2e\u52a9\u6a21\u578b\u5b66\u4e60\u7279\u5b9a\u4ee3\u7801\u5e93\u7684\u5e95\u5c42\u6a21\u5f0f\uff0c\u4e3a\u5f00\u53d1\u8005\u63d0\u4f9b\u66f4\u7cbe\u786e\u7684\u4ee3\u7801\u8865\u5168\uff0c\u63d0\u5347\u751f\u4ea7\u529b\u3002", "conclusion": "\u57fa\u4e8e\u8bed\u4e49\u8303\u56f4\u7684LLM\u5b9a\u5236\u65b9\u6cd5\u80fd\u6709\u6548\u63d0\u5347\u6a21\u578b\u5728\u79c1\u6709\u4ee3\u7801\u5e93\u4e0a\u7684\u4ee3\u7801\u8865\u5168\u6027\u80fd\uff0c\u5b9a\u5236\u5316\u6a21\u578b\u4f18\u4e8e\u672a\u5b9a\u5236\u7684\u5927\u89c4\u6a21\u6a21\u578b\u3002\u6587\u4e2d\u8fd8\u5305\u542b\u5bf9\u4e24\u4e2a\u516c\u5f00\u57fa\u51c6\u6d4b\u8bd5\u7684\u5206\u6790\uff0c\u5e76\u63d0\u51fa\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2602.05891", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.05891", "abs": "https://arxiv.org/abs/2602.05891", "authors": ["Shenyu Zheng", "Ximing Dong", "Xiaoshuang Liu", "Gustavo Oliva", "Chong Chun Yong", "Dayi Lin", "Boyuan Chen", "Shaowei Wang", "Ahmed E. Hassan"], "title": "When Elo Lies: Hidden Biases in Codeforces-Based Evaluation of Large Language Models", "comment": null, "summary": "As Large Language Models (LLMs) achieve breakthroughs in complex reasoning, Codeforces-based Elo ratings have emerged as a prominent metric for evaluating competitive programming capabilities. However, these ratings are often reported without critical experimental details, leading to significant discrepancies illustrated by recent reports where the score of the same model version fluctuated by nearly 500 points. This paper presents a systematic empirical study on the hidden factors biasing Elo evaluations: (1) the temporal ordering of submissions, (2) contest difficulty selection, and (3) run to run stochastic variability of LLMs. Utilizing a controlled benchmark of 37 recent Codeforces contests and 13,691 generated test cases, we demonstrate that Elo scores are highly sensitive to these parameters. Our findings reveal that varying submission orders can shift scores by 394 points, while contest selection can cause differences of up to 1,122 points for the same model. Run to run performance exhibits substantial instability, with a maximum difference of 349 points in mean scores observed when evaluating identical contests. We conclude that direct Elo comparisons are unreliable and potentially misleading without strict standardization and transparent reporting of experimental settings.", "AI": {"tldr": "Codeforces Elo\u8bc4\u5206\u4f5c\u4e3aLLM\u7f16\u7a0b\u80fd\u529b\u8bc4\u4f30\u6307\u6807\u5b58\u5728\u4e25\u91cd\u504f\u5dee\uff0c\u7814\u7a76\u53d1\u73b0\u63d0\u4ea4\u987a\u5e8f\u3001\u6bd4\u8d5b\u9009\u62e9\u3001\u6a21\u578b\u968f\u673a\u6027\u7b49\u56e0\u7d20\u53ef\u5bfc\u81f4\u8bc4\u5206\u6ce2\u52a8\u9ad8\u8fbe1122\u70b9\uff0c\u76f4\u63a5\u6bd4\u8f83\u4e0d\u53ef\u9760", "motivation": "\u5f53\u524dLLM\u5728\u590d\u6742\u63a8\u7406\u65b9\u9762\u53d6\u5f97\u7a81\u7834\uff0cCodeforces Elo\u8bc4\u5206\u6210\u4e3a\u8bc4\u4f30\u7ade\u4e89\u6027\u7f16\u7a0b\u80fd\u529b\u7684\u4e3b\u6d41\u6307\u6807\uff0c\u4f46\u73b0\u6709\u62a5\u544a\u7f3a\u4e4f\u5173\u952e\u5b9e\u9a8c\u7ec6\u8282\uff0c\u5bfc\u81f4\u540c\u4e00\u6a21\u578b\u7248\u672c\u7684\u8bc4\u5206\u6ce2\u52a8\u8fd1500\u70b9\uff0c\u9700\u8981\u7cfb\u7edf\u7814\u7a76\u8bc4\u4f30\u504f\u5dee\u7684\u9690\u85cf\u56e0\u7d20", "method": "\u4f7f\u752837\u4e2a\u8fd1\u671fCodeforces\u6bd4\u8d5b\u548c13,691\u4e2a\u751f\u6210\u6d4b\u8bd5\u7528\u4f8b\u7684\u53d7\u63a7\u57fa\u51c6\uff0c\u7cfb\u7edf\u5b9e\u8bc1\u7814\u7a76\u4e09\u4e2a\u5173\u952e\u504f\u5dee\u56e0\u7d20\uff1a\u63d0\u4ea4\u65f6\u95f4\u987a\u5e8f\u3001\u6bd4\u8d5b\u96be\u5ea6\u9009\u62e9\u3001LLM\u8fd0\u884c\u5230\u8fd0\u884c\u7684\u968f\u673a\u53d8\u5f02\u6027", "result": "Elo\u8bc4\u5206\u5bf9\u8fd9\u4e9b\u53c2\u6570\u9ad8\u5ea6\u654f\u611f\uff1a\u4e0d\u540c\u63d0\u4ea4\u987a\u5e8f\u53ef\u5bfc\u81f4\u8bc4\u5206\u504f\u79fb394\u70b9\uff1b\u6bd4\u8d5b\u9009\u62e9\u53ef\u9020\u6210\u540c\u4e00\u6a21\u578b\u8bc4\u5206\u5dee\u5f02\u9ad8\u8fbe1122\u70b9\uff1b\u8fd0\u884c\u5230\u8fd0\u884c\u6027\u80fd\u8868\u73b0\u51fa\u663e\u8457\u4e0d\u7a33\u5b9a\u6027\uff0c\u76f8\u540c\u6bd4\u8d5b\u8bc4\u4f30\u4e2d\u5e73\u5747\u8bc4\u5206\u6700\u5927\u5dee\u5f02\u8fbe349\u70b9", "conclusion": "\u76f4\u63a5\u6bd4\u8f83Elo\u8bc4\u5206\u4e0d\u53ef\u9760\u4e14\u53ef\u80fd\u8bef\u5bfc\uff0c\u5fc5\u987b\u5728\u4e25\u683c\u6807\u51c6\u5316\u548c\u900f\u660e\u62a5\u544a\u5b9e\u9a8c\u8bbe\u7f6e\u7684\u6761\u4ef6\u4e0b\u4f7f\u7528\u8be5\u8bc4\u4f30\u65b9\u6cd5"}}
