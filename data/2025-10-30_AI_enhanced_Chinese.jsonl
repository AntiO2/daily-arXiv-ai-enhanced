{"id": "2510.24749", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24749", "abs": "https://arxiv.org/abs/2510.24749", "authors": ["Aofan Liu", "Shiyuan Song", "Haoxuan Li", "Cehao Yang", "Yiyan Qi"], "title": "Beyond Function-Level Search: Repository-Aware Dual-Encoder Code Retrieval with Adversarial Verification", "comment": "Accepted by EMNLP 2025", "summary": "The escalating complexity of modern codebases has intensified the need for\nretrieval systems capable of interpreting cross-component change intents, a\ncapability fundamentally absent in conventional function-level search\nparadigms. While recent studies have improved the alignment between natural\nlanguage queries and code snippets, retrieving contextually relevant code for\nspecific change requests remains largely underexplored. To address this gap, we\nintroduce RepoAlign-Bench, the first benchmark specifically designed to\nevaluate repository-level code retrieval under change request driven scenarios,\nencompassing 52k annotated instances. This benchmark shifts the retrieval\nparadigm from function-centric matching to holistic repository-level reasoning.\nFurthermore, we propose ReflectCode, an adversarial reflection augmented\ndual-tower architecture featuring disentangled code_encoder and doc_encoder\ncomponents. ReflectCode dynamically integrates syntactic patterns, function\ndependencies, and semantic expansion intents through large language model\nguided reflection. Comprehensive experiments demonstrate that ReflectCode\nachieves 12.2% improvement in Top-5 Accuracy and 7.1% in Recall over\nstate-of-the-art baselines, establishing a new direction for context-aware code\nretrieval.", "AI": {"tldr": "RepoAlign-Bench\u662f\u9996\u4e2a\u4e13\u95e8\u8bc4\u4f30\u53d8\u66f4\u8bf7\u6c42\u9a71\u52a8\u573a\u666f\u4e0b\u4ed3\u5e93\u7ea7\u4ee3\u7801\u68c0\u7d22\u7684\u57fa\u51c6\uff0c\u5305\u542b52k\u6807\u6ce8\u5b9e\u4f8b\u3002ReflectCode\u901a\u8fc7\u5bf9\u6297\u6027\u53cd\u5c04\u589e\u5f3a\u7684\u53cc\u5854\u67b6\u6784\uff0c\u5728Top-5\u51c6\u786e\u7387\u548c\u53ec\u56de\u7387\u4e0a\u5206\u522b\u6bd4\u6700\u5148\u8fdb\u65b9\u6cd5\u63d0\u534712.2%\u548c7.1%\u3002", "motivation": "\u73b0\u4ee3\u4ee3\u7801\u5e93\u65e5\u76ca\u590d\u6742\uff0c\u9700\u8981\u80fd\u591f\u7406\u89e3\u8de8\u7ec4\u4ef6\u53d8\u66f4\u610f\u56fe\u7684\u68c0\u7d22\u7cfb\u7edf\uff0c\u800c\u4f20\u7edf\u7684\u51fd\u6570\u7ea7\u641c\u7d22\u8303\u5f0f\u7f3a\u4e4f\u8fd9\u79cd\u80fd\u529b\u3002\u867d\u7136\u8fd1\u671f\u7814\u7a76\u6539\u8fdb\u4e86\u81ea\u7136\u8bed\u8a00\u67e5\u8be2\u4e0e\u4ee3\u7801\u7247\u6bb5\u7684\u5339\u914d\uff0c\u4f46\u9488\u5bf9\u7279\u5b9a\u53d8\u66f4\u8bf7\u6c42\u68c0\u7d22\u4e0a\u4e0b\u6587\u76f8\u5173\u4ee3\u7801\u4ecd\u672a\u88ab\u5145\u5206\u63a2\u7d22\u3002", "method": "\u63d0\u51faReflectCode\uff0c\u4e00\u79cd\u5bf9\u6297\u6027\u53cd\u5c04\u589e\u5f3a\u7684\u53cc\u5854\u67b6\u6784\uff0c\u5305\u542b\u89e3\u8026\u7684\u4ee3\u7801\u7f16\u7801\u5668\u548c\u6587\u6863\u7f16\u7801\u5668\u7ec4\u4ef6\u3002\u901a\u8fc7\u5927\u8bed\u8a00\u6a21\u578b\u5f15\u5bfc\u7684\u53cd\u5c04\uff0c\u52a8\u6001\u6574\u5408\u8bed\u6cd5\u6a21\u5f0f\u3001\u51fd\u6570\u4f9d\u8d56\u5173\u7cfb\u548c\u8bed\u4e49\u6269\u5c55\u610f\u56fe\u3002", "result": "\u7efc\u5408\u5b9e\u9a8c\u8868\u660e\uff0cReflectCode\u5728Top-5\u51c6\u786e\u7387\u4e0a\u6bd4\u6700\u5148\u8fdb\u57fa\u7ebf\u63d0\u534712.2%\uff0c\u5728\u53ec\u56de\u7387\u4e0a\u63d0\u53477.1%\u3002", "conclusion": "\u4e3a\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u4ee3\u7801\u68c0\u7d22\u786e\u7acb\u4e86\u65b0\u65b9\u5411\uff0c\u5c06\u68c0\u7d22\u8303\u5f0f\u4ece\u51fd\u6570\u4e2d\u5fc3\u5339\u914d\u8f6c\u5411\u6574\u4f53\u4ed3\u5e93\u7ea7\u63a8\u7406\u3002"}}
{"id": "2510.24799", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.24799", "abs": "https://arxiv.org/abs/2510.24799", "authors": ["Filipe R. Cogo", "Gustavo A. Oliva", "Ahmed E. Hassan"], "title": "Compiler.next: A Search-Based Compiler to Power the AI-Native Future of Software Engineering", "comment": "31 pages, 5 figures, submitted to ACM Transactions on Software\n  Engineering and Methodology", "summary": "The rapid advancement of AI-assisted software engineering has brought\ntransformative potential to the field of software engineering, but existing\ntools and paradigms remain limited by cognitive overload, inefficient tool\nintegration, and the narrow capabilities of AI copilots. In response, we\npropose Compiler.next, a novel search-based compiler designed to enable the\nseamless evolution of AI-native software systems as part of the emerging\nSoftware Engineering 3.0 era. Unlike traditional static compilers,\nCompiler.next takes human-written intents and automatically generates working\nsoftware by searching for an optimal solution. This process involves dynamic\noptimization of cognitive architectures and their constituents (e.g., prompts,\nfoundation model configurations, and system parameters) while finding the\noptimal trade-off between several objectives, such as accuracy, cost, and\nlatency. This paper outlines the architecture of Compiler.next and positions it\nas a cornerstone in democratizing software development by lowering the\ntechnical barrier for non-experts, enabling scalable, adaptable, and reliable\nAI-powered software. We present a roadmap to address the core challenges in\nintent compilation, including developing quality programming constructs,\neffective search heuristics, reproducibility, and interoperability between\ncompilers. Our vision lays the groundwork for fully automated, search-driven\nsoftware development, fostering faster innovation and more efficient AI-driven\nsystems.", "AI": {"tldr": "Compiler.next\u662f\u4e00\u4e2a\u57fa\u4e8e\u641c\u7d22\u7684\u65b0\u578b\u7f16\u8bd1\u5668\uff0c\u80fd\u591f\u5c06\u4eba\u7c7b\u610f\u56fe\u81ea\u52a8\u8f6c\u6362\u4e3a\u53ef\u5de5\u4f5c\u7684\u8f6f\u4ef6\uff0c\u901a\u8fc7\u52a8\u6001\u4f18\u5316\u8ba4\u77e5\u67b6\u6784\u548c\u53c2\u6570\uff0c\u5728\u51c6\u786e\u6027\u3001\u6210\u672c\u548c\u5ef6\u8fdf\u7b49\u591a\u4e2a\u76ee\u6807\u95f4\u5bfb\u627e\u6700\u4f18\u5e73\u8861\u3002", "motivation": "\u73b0\u6709AI\u8f85\u52a9\u8f6f\u4ef6\u5de5\u7a0b\u5de5\u5177\u5b58\u5728\u8ba4\u77e5\u8fc7\u8f7d\u3001\u5de5\u5177\u96c6\u6210\u6548\u7387\u4f4e\u548cAI\u526f\u9a7e\u9a76\u80fd\u529b\u6709\u9650\u7b49\u95ee\u9898\uff0c\u9700\u8981\u65b0\u7684\u8303\u5f0f\u6765\u63a8\u52a8\u8f6f\u4ef6\u5de5\u7a0b3.0\u65f6\u4ee3\u7684\u53d1\u5c55\u3002", "method": "\u63d0\u51fa\u641c\u7d22\u578b\u7f16\u8bd1\u5668\u67b6\u6784\uff0c\u901a\u8fc7\u52a8\u6001\u4f18\u5316\u8ba4\u77e5\u67b6\u6784\u7ec4\u4ef6\uff08\u5982\u63d0\u793a\u8bcd\u3001\u57fa\u7840\u6a21\u578b\u914d\u7f6e\u548c\u7cfb\u7edf\u53c2\u6570\uff09\uff0c\u5728\u591a\u4e2a\u76ee\u6807\u95f4\u8fdb\u884c\u6743\u8861\u641c\u7d22\u6765\u751f\u6210\u6700\u4f18\u8f6f\u4ef6\u89e3\u51b3\u65b9\u6848\u3002", "result": "\u6784\u5efa\u4e86Compiler.next\u7684\u67b6\u6784\u6846\u67b6\uff0c\u5c06\u5176\u5b9a\u4f4d\u4e3a\u964d\u4f4e\u975e\u4e13\u5bb6\u6280\u672f\u95e8\u69db\u3001\u5b9e\u73b0\u53ef\u6269\u5c55\u3001\u81ea\u9002\u5e94\u548c\u53ef\u9760AI\u9a71\u52a8\u8f6f\u4ef6\u7684\u5173\u952e\u6280\u672f\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u5b8c\u5168\u81ea\u52a8\u5316\u3001\u641c\u7d22\u9a71\u52a8\u7684\u8f6f\u4ef6\u5f00\u53d1\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u5c06\u4fc3\u8fdb\u66f4\u5feb\u7684\u521b\u65b0\u548c\u66f4\u9ad8\u6548\u7684AI\u9a71\u52a8\u7cfb\u7edf\u53d1\u5c55\u3002"}}
{"id": "2510.24819", "categories": ["cs.SE", "cs.PL"], "pdf": "https://arxiv.org/pdf/2510.24819", "abs": "https://arxiv.org/abs/2510.24819", "authors": ["Vincenzo Scotti", "Jan Keim", "Tobias Hey", "Andreas Metzger", "Anne Koziolek", "Raffaela Mirandola"], "title": "A Roadmap for Tamed Interactions with Large Language Models", "comment": null, "summary": "We are witnessing a bloom of AI-powered software driven by Large Language\nModels (LLMs). Although the applications of these LLMs are impressive and\nseemingly countless, their unreliability hinders adoption. In fact, the\ntendency of LLMs to produce faulty or hallucinated content makes them\nunsuitable for automating workflows and pipelines. In this regard, Software\nEngineering (SE) provides valuable support, offering a wide range of formal\ntools to specify, verify, and validate software behaviour. Such SE tools can be\napplied to define constraints over LLM outputs and, consequently, offer\nstronger guarantees on the generated content. In this paper, we argue that the\ndevelopment of a Domain Specific Language (DSL) for scripting interactions with\nLLMs using an LLM Scripting Language (LSL) may be key to improve AI-based\napplications. Currently, LLMs and LLM-based software still lack reliability,\nrobustness, and trustworthiness, and the tools or frameworks to cope with these\nissues suffer from fragmentation. In this paper, we present our vision of LSL.\nWith LSL, we aim to address the limitations above by exploring ways to control\nLLM outputs, enforce structure in interactions, and integrate these aspects\nwith verification, validation, and explainability. Our goal is to make LLM\ninteraction programmable and decoupled from training or implementation.", "AI": {"tldr": "\u63d0\u51faLLM\u811a\u672c\u8bed\u8a00(LSL)\u7684\u6982\u5ff5\uff0c\u65e8\u5728\u901a\u8fc7\u9886\u57df\u7279\u5b9a\u8bed\u8a00\u6765\u89c4\u8303\u548c\u63a7\u5236\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8f93\u51fa\uff0c\u63d0\u9ad8AI\u5e94\u7528\u7684\u53ef\u9760\u6027\u3001\u9c81\u68d2\u6027\u548c\u53ef\u4fe1\u5ea6\u3002", "motivation": "\u5f53\u524dLLM\u5e94\u7528\u867d\u7136\u4ee4\u4eba\u5370\u8c61\u6df1\u523b\uff0c\u4f46\u5176\u4e0d\u53ef\u9760\u6027\u548c\u4ea7\u751f\u5e7b\u89c9\u5185\u5bb9\u7684\u503e\u5411\u963b\u788d\u4e86\u5b9e\u9645\u5e94\u7528\u3002\u9700\u8981\u8f6f\u4ef6\u5de5\u7a0b\u5de5\u5177\u6765\u7ea6\u675fLLM\u8f93\u51fa\uff0c\u63d0\u4f9b\u66f4\u5f3a\u7684\u4fdd\u8bc1\u3002", "method": "\u5f00\u53d1\u9886\u57df\u7279\u5b9a\u8bed\u8a00(DSL)\u6765\u7f16\u5199\u4e0eLLM\u7684\u4ea4\u4e92\u811a\u672c\uff0c\u63a7\u5236LLM\u8f93\u51fa\u3001\u5f3a\u5236\u4ea4\u4e92\u7ed3\u6784\u5316\uff0c\u5e76\u4e0e\u9a8c\u8bc1\u3001\u9a8c\u8bc1\u548c\u53ef\u89e3\u91ca\u6027\u96c6\u6210\u3002", "result": "\u63d0\u51fa\u4e86LSL\u7684\u613f\u666f\u6846\u67b6\uff0c\u4f7fLLM\u4ea4\u4e92\u53ef\u7f16\u7a0b\uff0c\u5e76\u4e0e\u8bad\u7ec3\u6216\u5b9e\u73b0\u89e3\u8026\u3002", "conclusion": "LSL\u53ef\u80fd\u662f\u6539\u8fdb\u57fa\u4e8eAI\u5e94\u7528\u7684\u5173\u952e\uff0c\u901a\u8fc7\u4f7fLLM\u4ea4\u4e92\u53ef\u7f16\u7a0b\u6765\u89e3\u51b3\u5f53\u524d\u5de5\u5177\u788e\u7247\u5316\u95ee\u9898\uff0c\u63d0\u9ad8LLM\u8f6f\u4ef6\u7684\u53ef\u9760\u6027\u3001\u9c81\u68d2\u6027\u548c\u53ef\u4fe1\u5ea6\u3002"}}
{"id": "2510.25015", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.25015", "abs": "https://arxiv.org/abs/2510.25015", "authors": ["Chuyue Sun", "Yican Sun", "Daneshvar Amrollahi", "Ethan Zhang", "Shuvendu Lahiri", "Shan Lu", "David Dill", "Clark Barrett"], "title": "VeriStruct: AI-assisted Automated Verification of Data-Structure Modules in Verus", "comment": null, "summary": "We introduce VeriStruct, a novel framework that extends AI-assisted automated\nverification from single functions to more complex data structure modules in\nVerus. VeriStruct employs a planner module to orchestrate the systematic\ngeneration of abstractions, type invariants, specifications, and proof code. To\naddress the challenge that LLMs often misunderstand Verus' annotation syntax\nand verification-specific semantics, VeriStruct embeds syntax guidance within\nprompts and includes a repair stage to automatically correct annotation errors.\nIn an evaluation on eleven Rust data structure modules, VeriStruct succeeds on\nten of the eleven, successfully verifying 128 out of 129 functions (99.2%) in\ntotal. These results represent an important step toward the goal of automatic\nAI-assisted formal verification.", "AI": {"tldr": "VeriStruct\u662f\u4e00\u4e2a\u6269\u5c55AI\u8f85\u52a9\u81ea\u52a8\u9a8c\u8bc1\u80fd\u529b\u7684\u6846\u67b6\uff0c\u4ece\u5355\u51fd\u6570\u9a8c\u8bc1\u6269\u5c55\u5230\u590d\u6742\u6570\u636e\u7ed3\u6784\u6a21\u5757\u9a8c\u8bc1\uff0c\u5728Verus\u4e2d\u6210\u529f\u9a8c\u8bc1\u4e86128/129\u4e2a\u51fd\u6570\uff0899.2%\uff09\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3LLMs\u5728\u7406\u89e3Verus\u6ce8\u91ca\u8bed\u6cd5\u548c\u9a8c\u8bc1\u7279\u5b9a\u8bed\u4e49\u65f6\u7684\u56f0\u96be\uff0c\u4ee5\u53ca\u5c06AI\u8f85\u52a9\u9a8c\u8bc1\u4ece\u5355\u51fd\u6570\u6269\u5c55\u5230\u590d\u6742\u6570\u636e\u7ed3\u6784\u6a21\u5757\u7684\u9700\u6c42\u3002", "method": "\u4f7f\u7528\u89c4\u5212\u5668\u6a21\u5757\u7cfb\u7edf\u751f\u6210\u62bd\u8c61\u3001\u7c7b\u578b\u4e0d\u53d8\u91cf\u3001\u89c4\u8303\u548c\u8bc1\u660e\u4ee3\u7801\uff0c\u5728\u63d0\u793a\u4e2d\u5d4c\u5165\u8bed\u6cd5\u6307\u5bfc\uff0c\u5e76\u5305\u542b\u4fee\u590d\u9636\u6bb5\u81ea\u52a8\u7ea0\u6b63\u6ce8\u91ca\u9519\u8bef\u3002", "result": "\u572811\u4e2aRust\u6570\u636e\u7ed3\u6784\u6a21\u5757\u8bc4\u4f30\u4e2d\uff0c\u6210\u529f\u9a8c\u8bc1\u4e8610\u4e2a\u6a21\u5757\uff0c\u603b\u8ba1128/129\u4e2a\u51fd\u6570\uff0899.2%\u6210\u529f\u7387\uff09\u3002", "conclusion": "VeriStruct\u4ee3\u8868\u4e86\u5411\u81ea\u52a8AI\u8f85\u52a9\u5f62\u5f0f\u9a8c\u8bc1\u76ee\u6807\u8fc8\u51fa\u7684\u91cd\u8981\u4e00\u6b65\uff0c\u5c55\u793a\u4e86\u5728\u590d\u6742\u6570\u636e\u7ed3\u6784\u9a8c\u8bc1\u4e2d\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2510.24761", "categories": ["cs.DB", "cs.IR", "cs.SE"], "pdf": "https://arxiv.org/pdf/2510.24761", "abs": "https://arxiv.org/abs/2510.24761", "authors": ["Anirudh Ganesh", "Nitin Sood"], "title": "ODataX: A Progressive Evolution of the Open Data Protocol", "comment": null, "summary": "The Open Data Protocol (OData) provides a standardized approach for building\nand consuming RESTful APIs with rich query capabilities. Despite its power and\nmaturity, OData adoption remains confined primarily to enterprise environments,\nparticularly within Microsoft and SAP ecosystems. This paper analyzes the key\nbarriers preventing wider OData adoption and introduces ODataX, an evolved\nversion of the protocol designed to address these limitations. ODataX maintains\nbackward compatibility with OData v4 while introducing progressive complexity\ndisclosure through simplified query syntax, built-in performance guardrails via\nquery cost estimation, and enhanced caching mechanisms. This work aims to\nbridge the gap between enterprise-grade query standardization and the\nsimplicity demanded by modern web development practices.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86OData\u534f\u8bae\u5728\u4f01\u4e1a\u73af\u5883\u5916\u91c7\u7528\u53d7\u9650\u7684\u539f\u56e0\uff0c\u5e76\u63d0\u51fa\u4e86ODataX\u89e3\u51b3\u65b9\u6848\uff0c\u5728\u4fdd\u6301\u5411\u540e\u517c\u5bb9\u7684\u540c\u65f6\u901a\u8fc7\u7b80\u5316\u67e5\u8be2\u8bed\u6cd5\u3001\u6027\u80fd\u9632\u62a4\u548c\u7f13\u5b58\u589e\u5f3a\u6765\u4fc3\u8fdb\u66f4\u5e7f\u6cdb\u91c7\u7528\u3002", "motivation": "OData\u4f5c\u4e3a\u6784\u5efaRESTful API\u7684\u6807\u51c6\u534f\u8bae\uff0c\u867d\u7136\u529f\u80fd\u5f3a\u5927\u4e14\u6210\u719f\uff0c\u4f46\u4e3b\u8981\u5c40\u9650\u4e8e\u5fae\u8f6f\u548cSAP\u7b49\u4f01\u4e1a\u751f\u6001\u7cfb\u7edf\uff0c\u672a\u80fd\u83b7\u5f97\u66f4\u5e7f\u6cdb\u7684\u91c7\u7528\u3002\u672c\u6587\u65e8\u5728\u8bc6\u522b\u963b\u788d\u5176\u5e7f\u6cdb\u91c7\u7528\u7684\u5173\u952e\u969c\u788d\u3002", "method": "\u63d0\u51fa\u4e86ODataX\u534f\u8bae\uff0c\u5728\u4fdd\u6301OData v4\u5411\u540e\u517c\u5bb9\u6027\u7684\u57fa\u7840\u4e0a\uff0c\u5f15\u5165\u6e10\u8fdb\u5f0f\u590d\u6742\u5ea6\u62ab\u9732\uff08\u7b80\u5316\u67e5\u8be2\u8bed\u6cd5\uff09\u3001\u5185\u7f6e\u6027\u80fd\u9632\u62a4\uff08\u67e5\u8be2\u6210\u672c\u4f30\u7b97\uff09\u548c\u589e\u5f3a\u7f13\u5b58\u673a\u5236\u3002", "result": "ODataX\u534f\u8bae\u6210\u529f\u89e3\u51b3\u4e86\u539fOData\u534f\u8bae\u5728\u4f01\u4e1a\u73af\u5883\u5916\u91c7\u7528\u53d7\u9650\u7684\u95ee\u9898\uff0c\u901a\u8fc7\u5e73\u8861\u4f01\u4e1a\u7ea7\u67e5\u8be2\u6807\u51c6\u5316\u4e0e\u73b0\u4ee3Web\u5f00\u53d1\u5bf9\u7b80\u5355\u6027\u7684\u9700\u6c42\u3002", "conclusion": "ODataX\u5728\u4fdd\u6301OData\u5f3a\u5927\u529f\u80fd\u7684\u540c\u65f6\uff0c\u901a\u8fc7\u7b80\u5316\u4f7f\u7528\u548c\u6027\u80fd\u4f18\u5316\uff0c\u6709\u671b\u5f25\u5408\u4f01\u4e1a\u7ea7API\u6807\u51c6\u4e0e\u73b0\u4ee3Web\u5f00\u53d1\u5b9e\u8df5\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u4fc3\u8fdb\u66f4\u5e7f\u6cdb\u91c7\u7528\u3002"}}
{"id": "2510.24943", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2510.24943", "abs": "https://arxiv.org/abs/2510.24943", "authors": ["Alfonso Ladino-Rincon", "Stephen W. Nesbitt"], "title": "Radar DataTree: A FAIR and Cloud-Native Framework for Scalable Weather Radar Archives", "comment": "8 pages, 3 figures", "summary": "We introduce Radar DataTree, the first dataset-level framework that extends\nthe WMO FM-301 standard from individual radar volume scans to time-resolved,\nanalysis-ready archives. Weather radar data are among the most scientifically\nvaluable yet structurally underutilized Earth observation datasets. Despite\nwidespread public availability, radar archives remain fragmented,\nvendor-specific, and poorly aligned with FAIR (Findable, Accessible,\nInteroperable, Reusable) principles, hindering large-scale research,\nreproducibility, and cloud-native computation. Radar DataTree addresses these\nlimitations with a scalable, open-source architecture that transforms\noperational radar archives into FAIR-compliant, cloud-optimized datasets. Built\non the FM-301/CfRadial 2.1 standard and implemented using xarray DataTree,\nRadar DataTree organizes radar volume scans as hierarchical, metadata-rich\nstructures and serializes them to Zarr for scalable analysis. Coupled with\nIcechunk for ACID-compliant storage and versioning, this architecture enables\nefficient, parallel computation across thousands of radar scans with minimal\npreprocessing. We demonstrate significant performance gains in case studies\nincluding Quasi-Vertical Profile (QVP) and precipitation accumulation\nworkflows, and release all tools and datasets openly via the Raw2Zarr\nrepository. This work contributes a reproducible and extensible foundation for\nradar data stewardship, high-performance geoscience, and AI-ready weather\ninfrastructure.", "AI": {"tldr": "Radar DataTree\u662f\u9996\u4e2a\u5c06WMO FM-301\u6807\u51c6\u4ece\u5355\u6b21\u96f7\u8fbe\u4f53\u626b\u63cf\u6269\u5c55\u5230\u65f6\u95f4\u5206\u8fa8\u3001\u5206\u6790\u5c31\u7eea\u6863\u6848\u7684\u6570\u636e\u96c6\u7ea7\u6846\u67b6\uff0c\u901a\u8fc7\u5f00\u6e90\u67b6\u6784\u5c06\u8fd0\u8425\u96f7\u8fbe\u6863\u6848\u8f6c\u5316\u4e3aFAIR\u517c\u5bb9\u7684\u4e91\u4f18\u5316\u6570\u636e\u96c6\u3002", "motivation": "\u5929\u6c14\u96f7\u8fbe\u6570\u636e\u662f\u79d1\u5b66\u4ef7\u503c\u6700\u9ad8\u4f46\u7ed3\u6784\u5229\u7528\u4e0d\u8db3\u7684\u5730\u7403\u89c2\u6d4b\u6570\u636e\u96c6\u4e4b\u4e00\uff0c\u73b0\u6709\u96f7\u8fbe\u6863\u6848\u5206\u6563\u3001\u4f9b\u5e94\u5546\u7279\u5b9a\u4e14\u4e0d\u7b26\u5408FAIR\u539f\u5219\uff0c\u963b\u788d\u4e86\u5927\u89c4\u6a21\u7814\u7a76\u3001\u53ef\u91cd\u590d\u6027\u548c\u4e91\u539f\u751f\u8ba1\u7b97\u3002", "method": "\u57fa\u4e8eFM-301/CfRadial 2.1\u6807\u51c6\uff0c\u4f7f\u7528xarray DataTree\u5c06\u96f7\u8fbe\u4f53\u626b\u63cf\u7ec4\u7ec7\u4e3a\u5206\u5c42\u3001\u5143\u6570\u636e\u4e30\u5bcc\u7684\u7ed3\u6784\uff0c\u5e76\u5e8f\u5217\u5316\u4e3aZarr\u683c\u5f0f\uff0c\u7ed3\u5408Icechunk\u5b9e\u73b0ACID\u517c\u5bb9\u5b58\u50a8\u548c\u7248\u672c\u63a7\u5236\u3002", "result": "\u5728\u51c6\u5782\u76f4\u5256\u9762(QVP)\u548c\u964d\u6c34\u7d2f\u79ef\u5de5\u4f5c\u6d41\u7b49\u6848\u4f8b\u7814\u7a76\u4e2d\u5c55\u793a\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\uff0c\u6240\u6709\u5de5\u5177\u548c\u6570\u636e\u96c6\u901a\u8fc7Raw2Zarr\u4ed3\u5e93\u5f00\u653e\u53d1\u5e03\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3a\u96f7\u8fbe\u6570\u636e\u7ba1\u7406\u3001\u9ad8\u6027\u80fd\u5730\u7403\u79d1\u5b66\u548cAI\u5c31\u7eea\u5929\u6c14\u57fa\u7840\u8bbe\u65bd\u63d0\u4f9b\u4e86\u53ef\u91cd\u590d\u548c\u53ef\u6269\u5c55\u7684\u57fa\u7840\u3002"}}
{"id": "2510.25016", "categories": ["cs.SE", "cs.AI", "cs.HC", "cs.LG", "68T07, 68N30", "D.2.1; I.2.6; I.2.7"], "pdf": "https://arxiv.org/pdf/2510.25016", "abs": "https://arxiv.org/abs/2510.25016", "authors": ["Mateen Ahmed Abbasi", "Petri Ihantola", "Tommi Mikkonen", "Niko M\u00e4kitalo"], "title": "Towards Human-AI Synergy in Requirements Engineering: A Framework and Preliminary Study", "comment": "Accepted at the 2025 Sixth International Conference on Intelligent\n  Data Science Technologies and Applications (IDSTA 2025),8 pages, 4 figures.\n  Published in IEEE", "summary": "The future of Requirements Engineering (RE) is increasingly driven by\nartificial intelligence (AI), reshaping how we elicit, analyze, and validate\nrequirements. Traditional RE is based on labor-intensive manual processes prone\nto errors and complexity. AI-powered approaches, specifically large language\nmodels (LLMs), natural language processing (NLP), and generative AI, offer\ntransformative solutions and reduce inefficiencies. However, the use of AI in\nRE also brings challenges like algorithmic bias, lack of explainability, and\nethical concerns related to automation. To address these issues, this study\nintroduces the Human-AI RE Synergy Model (HARE-SM), a conceptual framework that\nintegrates AI-driven analysis with human oversight to improve requirements\nelicitation, analysis, and validation. The model emphasizes ethical AI use\nthrough transparency, explainability, and bias mitigation. We outline a\nmulti-phase research methodology focused on preparing RE datasets, fine-tuning\nAI models, and designing collaborative human-AI workflows. This preliminary\nstudy presents the conceptual framework and early-stage prototype\nimplementation, establishing a research agenda and practical design direction\nfor applying intelligent data science techniques to semi-structured and\nunstructured RE data in collaborative environments.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86Human-AI RE\u534f\u540c\u6a21\u578b(HARE-SM)\uff0c\u4e00\u4e2a\u5c06AI\u9a71\u52a8\u5206\u6790\u4e0e\u4eba\u7c7b\u76d1\u7763\u76f8\u7ed3\u5408\u7684\u6982\u5ff5\u6846\u67b6\uff0c\u65e8\u5728\u6539\u8fdb\u9700\u6c42\u5de5\u7a0b\u4e2d\u7684\u9700\u6c42\u83b7\u53d6\u3001\u5206\u6790\u548c\u9a8c\u8bc1\u8fc7\u7a0b\u3002", "motivation": "\u4f20\u7edf\u9700\u6c42\u5de5\u7a0b\u4f9d\u8d56\u52b3\u52a8\u5bc6\u96c6\u578b\u624b\u52a8\u6d41\u7a0b\uff0c\u5bb9\u6613\u51fa\u9519\u4e14\u590d\u6742\u3002AI\u6280\u672f\uff08\u7279\u522b\u662f\u5927\u8bed\u8a00\u6a21\u578b\u3001\u81ea\u7136\u8bed\u8a00\u5904\u7406\u548c\u751f\u6210\u5f0fAI\uff09\u63d0\u4f9b\u4e86\u53d8\u9769\u6027\u89e3\u51b3\u65b9\u6848\uff0c\u4f46\u540c\u65f6\u4e5f\u5e26\u6765\u4e86\u7b97\u6cd5\u504f\u89c1\u3001\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\u548c\u4f26\u7406\u95ee\u9898\u7b49\u6311\u6218\u3002", "method": "\u91c7\u7528\u591a\u9636\u6bb5\u7814\u7a76\u65b9\u6cd5\uff0c\u5305\u62ec\u51c6\u5907\u9700\u6c42\u5de5\u7a0b\u6570\u636e\u96c6\u3001\u5fae\u8c03AI\u6a21\u578b\uff0c\u4ee5\u53ca\u8bbe\u8ba1\u534f\u4f5c\u5f0f\u4eba\u673a\u5de5\u4f5c\u6d41\u7a0b\u3002\u7814\u7a76\u63d0\u51fa\u4e86HARE-SM\u6982\u5ff5\u6846\u67b6\u548c\u65e9\u671f\u539f\u578b\u5b9e\u73b0\u3002", "result": "\u5efa\u7acb\u4e86\u7814\u7a76\u8bae\u7a0b\u548c\u5b9e\u9645\u8bbe\u8ba1\u65b9\u5411\uff0c\u4e3a\u5728\u534f\u4f5c\u73af\u5883\u4e2d\u5e94\u7528\u667a\u80fd\u6570\u636e\u79d1\u5b66\u6280\u672f\u5904\u7406\u534a\u7ed3\u6784\u5316\u548c\u975e\u7ed3\u6784\u5316\u9700\u6c42\u5de5\u7a0b\u6570\u636e\u5960\u5b9a\u4e86\u57fa\u7840\u3002", "conclusion": "HARE-SM\u6846\u67b6\u901a\u8fc7\u5f3a\u8c03\u900f\u660e\u5ea6\u3001\u53ef\u89e3\u91ca\u6027\u548c\u504f\u89c1\u7f13\u89e3\uff0c\u4fc3\u8fdb\u4e86\u9700\u6c42\u5de5\u7a0b\u4e2dAI\u7684\u4f26\u7406\u4f7f\u7528\uff0c\u4e3a\u4eba\u673a\u534f\u4f5c\u7684\u9700\u6c42\u5de5\u7a0b\u5b9e\u8df5\u63d0\u4f9b\u4e86\u7406\u8bba\u6846\u67b6\u548c\u5b9e\u73b0\u8def\u5f84\u3002"}}
{"id": "2510.25017", "categories": ["cs.DB", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.25017", "abs": "https://arxiv.org/abs/2510.25017", "authors": ["Qi Lin", "Zhenyu Zhang", "Viraj Thakkar", "Zhenjie Sun", "Mai Zheng", "Zhichao Cao"], "title": "StorageXTuner: An LLM Agent-Driven Automatic Tuning Framework for Heterogeneous Storage Systems", "comment": "ArXiv version; Affiliations: Arizona State University (Lin, Zhang,\n  Thakkar, Sun, Cao) and Iowa State University (Zheng)", "summary": "Automatically configuring storage systems is hard: parameter spaces are large\nand conditions vary across workloads, deployments, and versions. Heuristic and\nML tuners are often system specific, require manual glue, and degrade under\nchanges. Recent LLM-based approaches help but usually treat tuning as a\nsingle-shot, system-specific task, which limits cross-system reuse, constrains\nexploration, and weakens validation. We present StorageXTuner, an LLM\nagent-driven auto-tuning framework for heterogeneous storage engines.\nStorageXTuner separates concerns across four agents - Executor (sandboxed\nbenchmarking), Extractor (performance digest), Searcher (insight-guided\nconfiguration exploration), and Reflector (insight generation and management).\nThe design couples an insight-driven tree search with layered memory that\npromotes empirically validated insights and employs lightweight checkers to\nguard against unsafe actions. We implement a prototype and evaluate it on\nRocksDB, LevelDB, CacheLib, and MySQL InnoDB with YCSB, MixGraph, and TPC-H/C.\nRelative to out-of-the-box settings and to ELMo-Tune, StorageXTuner reaches up\nto 575% and 111% higher throughput, reduces p99 latency by as much as 88% and\n56%, and converges with fewer trials.", "AI": {"tldr": "StorageXTuner\u662f\u4e00\u4e2a\u57fa\u4e8eLLM\u4ee3\u7406\u7684\u5b58\u50a8\u7cfb\u7edf\u81ea\u52a8\u8c03\u4f18\u6846\u67b6\uff0c\u901a\u8fc7\u56db\u4e2a\u4ee3\u7406\u7ec4\u4ef6\u5b9e\u73b0\u5f02\u6784\u5b58\u50a8\u5f15\u64ce\u7684\u667a\u80fd\u8c03\u4f18\uff0c\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u5b58\u50a8\u7cfb\u7edf\u81ea\u52a8\u914d\u7f6e\u56f0\u96be\uff0c\u53c2\u6570\u7a7a\u95f4\u5927\u4e14\u5de5\u4f5c\u8d1f\u8f7d\u6761\u4ef6\u591a\u53d8\u3002\u73b0\u6709\u542f\u53d1\u5f0f\u548cML\u8c03\u4f18\u5668\u901a\u5e38\u7cfb\u7edf\u7279\u5b9a\uff0c\u9700\u8981\u624b\u52a8\u8c03\u6574\uff0c\u4e14\u5728\u7cfb\u7edf\u53d8\u5316\u65f6\u6027\u80fd\u4e0b\u964d\u3002", "method": "\u91c7\u7528\u56db\u4ee3\u7406\u67b6\u6784\uff1aExecutor\uff08\u6c99\u76d2\u57fa\u51c6\u6d4b\u8bd5\uff09\u3001Extractor\uff08\u6027\u80fd\u6458\u8981\uff09\u3001Searcher\uff08\u57fa\u4e8e\u6d1e\u5bdf\u7684\u914d\u7f6e\u63a2\u7d22\uff09\u3001Reflector\uff08\u6d1e\u5bdf\u751f\u6210\u548c\u7ba1\u7406\uff09\u3002\u7ed3\u5408\u6d1e\u5bdf\u9a71\u52a8\u7684\u6811\u641c\u7d22\u548c\u5206\u5c42\u5185\u5b58\uff0c\u4f7f\u7528\u8f7b\u91cf\u7ea7\u68c0\u67e5\u5668\u9632\u6b62\u4e0d\u5b89\u5168\u64cd\u4f5c\u3002", "result": "\u5728RocksDB\u3001LevelDB\u3001CacheLib\u548cMySQL InnoDB\u4e0a\u6d4b\u8bd5\uff0c\u76f8\u6bd4\u9ed8\u8ba4\u8bbe\u7f6e\u548cELMo-Tune\uff0c\u541e\u5410\u91cf\u6700\u9ad8\u63d0\u5347575%\u548c111%\uff0cp99\u5ef6\u8fdf\u964d\u4f4e88%\u548c56%\uff0c\u6536\u655b\u6240\u9700\u8bd5\u9a8c\u6b21\u6570\u66f4\u5c11\u3002", "conclusion": "StorageXTuner\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u5b58\u50a8\u7cfb\u7edf\u81ea\u52a8\u8c03\u4f18\u7684\u6311\u6218\uff0c\u5b9e\u73b0\u4e86\u8de8\u7cfb\u7edf\u7684\u53ef\u91cd\u7528\u6027\u548c\u66f4\u597d\u7684\u6027\u80fd\u4f18\u5316\u3002"}}
{"id": "2510.25170", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2510.25170", "abs": "https://arxiv.org/abs/2510.25170", "authors": ["Kewei Wang", "Claire Songhyun Lee", "Sunwoo Lee", "Vishu Gupta", "Jan Balewski", "Alex Sim", "Peter Nugent", "Ankit Agrawal", "Alok Choudhary", "Kesheng Wu", "Wei-keng Liao"], "title": "Multi-Resolution Model Fusion for Accelerating the Convolutional Neural Network Training", "comment": null, "summary": "Neural networks are rapidly gaining popularity in scientific research, but\ntraining the models is often very time-consuming. Particularly when the\ntraining data samples are large high-dimensional arrays, efficient training\nmethodologies that can reduce the computational costs are crucial. To reduce\nthe training cost, we propose a Multi-Resolution Model Fusion (MRMF) method\nthat combines models trained on reduced-resolution data and then refined with\ndata in the original resolution. We demonstrate that these reduced-resolution\nmodels and datasets could be generated quickly. More importantly, the proposed\napproach reduces the training time by speeding up the model convergence in each\nfusion stage before switching to the final stage of finetuning with data in its\noriginal resolution. This strategy ensures the final model retains\nhigh-resolution insights while benefiting from the computational efficiency of\nlower-resolution training. Our experiment results demonstrate that the\nmulti-resolution model fusion method can significantly reduce end-to-end\ntraining time while maintaining the same model accuracy. Evaluated using two\nreal-world scientific applications, CosmoFlow and Neuron Inverter, the proposed\nmethod improves the training time by up to 47% and 44%, respectively, as\ncompared to the original resolution training, while the model accuracy is not\naffected.", "AI": {"tldr": "\u63d0\u51fa\u591a\u5206\u8fa8\u7387\u6a21\u578b\u878d\u5408\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ed3\u5408\u4f4e\u5206\u8fa8\u7387\u8bad\u7ec3\u6a21\u578b\u4e0e\u539f\u59cb\u5206\u8fa8\u7387\u5fae\u8c03\uff0c\u663e\u8457\u51cf\u5c11\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\u65f6\u95f4\uff0c\u540c\u65f6\u4fdd\u6301\u6a21\u578b\u7cbe\u5ea6\u3002", "motivation": "\u795e\u7ecf\u7f51\u7edc\u5728\u79d1\u5b66\u7814\u7a76\u4e2d\u5e94\u7528\u5e7f\u6cdb\uff0c\u4f46\u8bad\u7ec3\u9ad8\u7ef4\u5927\u6570\u636e\u6837\u672c\u65f6\u8ba1\u7b97\u6210\u672c\u9ad8\u6602\uff0c\u9700\u8981\u9ad8\u6548\u7684\u8bad\u7ec3\u65b9\u6cd5\u6765\u964d\u4f4e\u8ba1\u7b97\u5f00\u9500\u3002", "method": "\u591a\u5206\u8fa8\u7387\u6a21\u578b\u878d\u5408\u65b9\u6cd5\uff1a\u5148\u8bad\u7ec3\u4f4e\u5206\u8fa8\u7387\u6570\u636e\u6a21\u578b\uff0c\u7136\u540e\u4e0e\u539f\u59cb\u5206\u8fa8\u7387\u6570\u636e\u7ed3\u5408\u8fdb\u884c\u5fae\u8c03\uff0c\u52a0\u901f\u6a21\u578b\u6536\u655b\u8fc7\u7a0b\u3002", "result": "\u5728CosmoFlow\u548cNeuron Inverter\u4e24\u4e2a\u5b9e\u9645\u5e94\u7528\u4e2d\uff0c\u8bad\u7ec3\u65f6\u95f4\u5206\u522b\u51cf\u5c1147%\u548c44%\uff0c\u6a21\u578b\u7cbe\u5ea6\u4e0d\u53d7\u5f71\u54cd\u3002", "conclusion": "\u591a\u5206\u8fa8\u7387\u6a21\u578b\u878d\u5408\u65b9\u6cd5\u80fd\u663e\u8457\u964d\u4f4e\u7aef\u5230\u7aef\u8bad\u7ec3\u65f6\u95f4\uff0c\u540c\u65f6\u4fdd\u6301\u6a21\u578b\u7684\u9ad8\u5206\u8fa8\u7387\u6d1e\u5bdf\u529b\uff0c\u4e3a\u79d1\u5b66\u8ba1\u7b97\u63d0\u4f9b\u9ad8\u6548\u8bad\u7ec3\u65b9\u6848\u3002"}}
{"id": "2510.25039", "categories": ["cs.SE", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.25039", "abs": "https://arxiv.org/abs/2510.25039", "authors": ["Amanda Dsouza", "Harit Vishwakarma", "Zhengyang Qi", "Justin Bauer", "Derek Pham", "Thomas Walshe", "Armin Parchami", "Frederic Sala", "Paroma Varma"], "title": "Automating Benchmark Design", "comment": null, "summary": "The rapid progress and widespread deployment of LLMs and LLM-powered agents\nhas outpaced our ability to evaluate them. Hand-crafted, static benchmarks are\nthe primary tool for assessing model capabilities, but these quickly become\nsaturated. In contrast, dynamic benchmarks evolve alongside the models they\nevaluate, but are expensive to create and continuously update. To address these\nchallenges, we develop BeTaL (Benchmark Tuning with an LLM-in-the-loop), a\nframework that leverages environment design principles to automate the process\nof dynamic benchmark design. BeTaL works by parameterizing key design choices\nin base benchmark templates and uses LLMs to reason through the resulting\nparameter space to obtain target properties (such as difficulty and realism) in\na cost-efficient manner. We validate this approach on its ability to create\nbenchmarks with desired difficulty levels. Using BeTaL, we create two new\nbenchmarks and extend a popular agentic benchmark {\\tau} -bench. Extensive\nevaluation on these three tasks and multiple target difficulty levels shows\nthat BeTaL produces benchmarks much closer to the desired difficulty, with\naverage deviations ranging from 5.3% to 13.2% -- a 2-4x improvement over the\nbaselines.", "AI": {"tldr": "BeTaL\u6846\u67b6\u5229\u7528LLM\u81ea\u52a8\u5316\u52a8\u6001\u57fa\u51c6\u8bbe\u8ba1\uff0c\u901a\u8fc7\u53c2\u6570\u5316\u57fa\u51c6\u6a21\u677f\u548cLLM\u63a8\u7406\u6765\u83b7\u5f97\u76ee\u6807\u5c5e\u6027\uff08\u5982\u96be\u5ea6\u548c\u771f\u5b9e\u6027\uff09\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u57fa\u51c6\u8bbe\u8ba1\u7684\u6548\u7387\u548c\u51c6\u786e\u6027\u3002", "motivation": "\u4f20\u7edf\u7684\u624b\u5de5\u9759\u6001\u57fa\u51c6\u8bc4\u4f30\u65b9\u6cd5\u5bb9\u6613\u9971\u548c\uff0c\u800c\u52a8\u6001\u57fa\u51c6\u867d\u7136\u80fd\u968f\u6a21\u578b\u53d1\u5c55\u800c\u8fdb\u5316\uff0c\u4f46\u521b\u5efa\u548c\u66f4\u65b0\u6210\u672c\u9ad8\u6602\u3002", "method": "BeTaL\u6846\u67b6\u53c2\u6570\u5316\u57fa\u51c6\u6a21\u677f\u7684\u5173\u952e\u8bbe\u8ba1\u9009\u62e9\uff0c\u4f7f\u7528LLM\u63a8\u7406\u53c2\u6570\u7a7a\u95f4\uff0c\u4ee5\u6210\u672c\u6548\u76ca\u7684\u65b9\u5f0f\u83b7\u5f97\u76ee\u6807\u5c5e\u6027\u3002", "result": "\u5728\u4e09\u4e2a\u4efb\u52a1\u548c\u591a\u4e2a\u76ee\u6807\u96be\u5ea6\u7ea7\u522b\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\uff0cBeTaL\u4ea7\u751f\u7684\u57fa\u51c6\u4e0e\u671f\u671b\u96be\u5ea6\u66f4\u63a5\u8fd1\uff0c\u5e73\u5747\u504f\u5dee\u4e3a5.3%\u523013.2%\uff0c\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u63d0\u9ad8\u4e862-4\u500d\u3002", "conclusion": "BeTaL\u4e3a\u52a8\u6001\u57fa\u51c6\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u81ea\u52a8\u5316\u65b9\u6cd5\uff0c\u663e\u8457\u6539\u5584\u4e86\u57fa\u51c6\u8bc4\u4f30\u7684\u51c6\u786e\u6027\u548c\u9002\u5e94\u6027\u3002"}}
{"id": "2510.25143", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2510.25143", "abs": "https://arxiv.org/abs/2510.25143", "authors": ["Mingze Xia", "Yuxiao Li", "Pu Jiao", "Bei Wang", "Xin Liang", "Hanqi Guo"], "title": "Time-varying Vector Field Compression with Preserved Critical Point Trajectories", "comment": null, "summary": "Scientific simulations and observations are producing vast amounts of\ntime-varying vector field data, making it hard to store them for archival\npurposes and transmit them for analysis. Lossy compression is considered a\npromising approach to reducing these data because lossless compression yields\nlow compression ratios that barely mitigate the problem. However, directly\napplying existing lossy compression methods to timevarying vector fields may\nintroduce undesired distortions in critical-point trajectories, a crucial\nfeature that encodes key properties of the vector field. In this work, we\npropose an efficient lossy compression framework that exactly preserves all\ncritical-point trajectories in time-varying vector fields. Our contributions\nare threefold. First, we extend the theory for preserving critical points in\nspace to preserving critical-point trajectories in space-time, and develop a\ncompression framework to realize the functionality. Second, we propose a\nsemi-Lagrange predictor to exploit the spatiotemporal correlations in\nadvectiondominated regions, and combine it with the traditional Lorenzo\npredictor for improved compression efficiency. Third, we evaluate our method\nagainst state-of-the-art lossy and lossless compressors using four real-world\nscientific datasets. Experimental results demonstrate that the proposed method\ndelivers up to 124.48X compression ratios while effectively preserving all\ncritical-point trajectories. This compression ratio is up to 56.07X higher than\nthat of the best lossless compressors, and none of the existing lossy\ncompressors can preserve all critical-point trajectories at similar compression\nratios.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u65f6\u53d8\u5411\u91cf\u573a\u6709\u635f\u538b\u7f29\u6846\u67b6\uff0c\u80fd\u591f\u7cbe\u786e\u4fdd\u7559\u6240\u6709\u4e34\u754c\u70b9\u8f68\u8ff9\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u4f1a\u626d\u66f2\u8fd9\u4e00\u5173\u952e\u7279\u5f81\u7684\u95ee\u9898\u3002", "motivation": "\u79d1\u5b66\u6a21\u62df\u548c\u89c2\u6d4b\u4ea7\u751f\u5927\u91cf\u65f6\u53d8\u5411\u91cf\u573a\u6570\u636e\uff0c\u5b58\u50a8\u548c\u4f20\u8f93\u56f0\u96be\u3002\u6709\u635f\u538b\u7f29\u662f\u51cf\u5c11\u6570\u636e\u91cf\u7684\u6709\u6548\u65b9\u6cd5\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u4f1a\u626d\u66f2\u4e34\u754c\u70b9\u8f68\u8ff9\u8fd9\u4e00\u5173\u952e\u7279\u5f81\u3002", "method": "\u6269\u5c55\u4e86\u7a7a\u95f4\u4e34\u754c\u70b9\u4fdd\u62a4\u7406\u8bba\u5230\u65f6\u7a7a\u4e34\u754c\u70b9\u8f68\u8ff9\u4fdd\u62a4\uff0c\u63d0\u51fa\u534a\u62c9\u683c\u6717\u65e5\u9884\u6d4b\u5668\u5229\u7528\u5e73\u6d41\u4e3b\u5bfc\u533a\u57df\u7684\u65f6\u7a7a\u76f8\u5173\u6027\uff0c\u7ed3\u5408\u4f20\u7edfLorenzo\u9884\u6d4b\u5668\u63d0\u9ad8\u538b\u7f29\u6548\u7387\u3002", "result": "\u5728\u56db\u4e2a\u771f\u5b9e\u79d1\u5b66\u6570\u636e\u96c6\u4e0a\u6d4b\u8bd5\uff0c\u538b\u7f29\u6bd4\u9ad8\u8fbe124.48\u500d\uff0c\u6bd4\u6700\u4f73\u65e0\u635f\u538b\u7f29\u5668\u9ad856.07\u500d\uff0c\u4e14\u80fd\u6709\u6548\u4fdd\u7559\u6240\u6709\u4e34\u754c\u70b9\u8f68\u8ff9\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u4fdd\u6301\u9ad8\u538b\u7f29\u6bd4\u7684\u540c\u65f6\uff0c\u6210\u529f\u4fdd\u62a4\u4e86\u65f6\u53d8\u5411\u91cf\u573a\u4e2d\u7684\u5173\u952e\u7279\u5f81\u2014\u2014\u4e34\u754c\u70b9\u8f68\u8ff9\uff0c\u4f18\u4e8e\u73b0\u6709\u6709\u635f\u548c\u65e0\u635f\u538b\u7f29\u65b9\u6cd5\u3002"}}
{"id": "2510.25258", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2510.25258", "abs": "https://arxiv.org/abs/2510.25258", "authors": ["Xinru Tang", "Jingxiang Hou", "Dingcheng Jiang", "Taiquan Wei", "Jiaxin Liu", "Jinyi Deng", "Huizheng Wang", "Qize Yang", "Haoran Shang", "Chao Li", "Yang Hu", "Shouyi Yin"], "title": "MoEntwine: Unleashing the Potential of Wafer-scale Chips for Large-scale Expert Parallel Inference", "comment": null, "summary": "As large language models (LLMs) continue to scale up, mixture-of-experts\n(MoE) has become a common technology in SOTA models. MoE models rely on expert\nparallelism (EP) to alleviate memory bottleneck, which introduces all-to-all\ncommunication to dispatch and combine tokens across devices. However, in\nwidely-adopted GPU clusters, high-overhead cross-node communication makes\nall-to-all expensive, hindering the adoption of EP. Recently, wafer-scale chips\n(WSCs) have emerged as a platform integrating numerous devices on a wafer-sized\ninterposer. WSCs provide a unified high-performance network connecting all\ndevices, presenting a promising potential for hosting MoE models. Yet, their\nnetwork is restricted to a mesh topology, causing imbalanced communication\npressure and performance loss. Moreover, the lack of on-wafer disk leads to\nhigh-overhead expert migration on the critical path.\n  To fully unleash this potential, we first propose Entwined Ring Mapping\n(ER-Mapping), which co-designs the mapping of attention and MoE layers to\nbalance communication pressure and achieve better performance. We find that\nunder ER-Mapping, the distribution of cold and hot links in the attention and\nMoE layers is complementary. Therefore, to hide the migration overhead, we\npropose the Non-invasive Balancer (NI-Balancer), which splits a complete expert\nmigration into multiple steps and alternately utilizes the cold links of both\nlayers. Evaluation shows ER-Mapping achieves communication reduction up to 62%.\nNI-Balancer further delivers 54% and 22% improvements in MoE computation and\ncommunication, respectively. Compared with the SOTA NVL72 supernode, the WSC\nplatform delivers an average 39% higher per-device MoE performance owing to its\nscalability to larger EP.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u6676\u5706\u7ea7\u82af\u7247(WSC)\u4e0a\u8fd0\u884cMoE\u6a21\u578b\u65f6\u7684\u901a\u4fe1\u4e0d\u5e73\u8861\u548c\u4e13\u5bb6\u8fc1\u79fb\u5f00\u9500\u95ee\u9898\uff0c\u63d0\u51fa\u4e86ER-Mapping\u548cNI-Balancer\u4e24\u79cd\u4f18\u5316\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86MoE\u6a21\u578b\u7684\u6027\u80fd\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u89c4\u6a21\u6269\u5927\uff0cMoE\u6280\u672f\u6210\u4e3a\u4e3b\u6d41\uff0c\u4f46GPU\u96c6\u7fa4\u4e2d\u7684\u8de8\u8282\u70b9\u901a\u4fe1\u5f00\u9500\u9650\u5236\u4e86\u4e13\u5bb6\u5e76\u884c\u7684\u5e94\u7528\u3002\u6676\u5706\u7ea7\u82af\u7247\u63d0\u4f9b\u4e86\u9ad8\u6027\u80fd\u7f51\u7edc\uff0c\u4f46\u5176\u7f51\u72b6\u62d3\u6251\u5bfc\u81f4\u901a\u4fe1\u538b\u529b\u4e0d\u5e73\u8861\uff0c\u4e14\u7f3a\u4e4f\u7247\u4e0a\u78c1\u76d8\u5bfc\u81f4\u4e13\u5bb6\u8fc1\u79fb\u5f00\u9500\u5927\u3002", "method": "\u63d0\u51fa\u4e86ER-Mapping\u65b9\u6cd5\uff0c\u534f\u540c\u8bbe\u8ba1\u6ce8\u610f\u529b\u5c42\u548cMoE\u5c42\u7684\u6620\u5c04\u4ee5\u5e73\u8861\u901a\u4fe1\u538b\u529b\uff1b\u63d0\u51fa\u4e86NI-Balancer\u65b9\u6cd5\uff0c\u5c06\u5b8c\u6574\u7684\u4e13\u5bb6\u8fc1\u79fb\u5206\u89e3\u4e3a\u591a\u4e2a\u6b65\u9aa4\uff0c\u4ea4\u66ff\u5229\u7528\u4e24\u5c42\u4e2d\u7684\u51b7\u94fe\u8def\u6765\u9690\u85cf\u8fc1\u79fb\u5f00\u9500\u3002", "result": "ER-Mapping\u5b9e\u73b0\u4e86\u9ad8\u8fbe62%\u7684\u901a\u4fe1\u51cf\u5c11\uff0cNI-Balancer\u5728MoE\u8ba1\u7b97\u548c\u901a\u4fe1\u65b9\u9762\u5206\u522b\u5e26\u6765\u4e8654%\u548c22%\u7684\u6539\u8fdb\u3002\u76f8\u6bd4SOTA\u7684NVL72\u8d85\u7ea7\u8282\u70b9\uff0cWSC\u5e73\u53f0\u5e73\u5747\u63d0\u4f9b\u4e8639%\u66f4\u9ad8\u7684\u6bcf\u8bbe\u5907MoE\u6027\u80fd\u3002", "conclusion": "\u901a\u8fc7ER-Mapping\u548cNI-Balancer\u7684\u534f\u540c\u4f18\u5316\uff0c\u6676\u5706\u7ea7\u82af\u7247\u5e73\u53f0\u80fd\u591f\u5145\u5206\u53d1\u6325\u5176\u5728MoE\u6a21\u578b\u4e0a\u7684\u6f5c\u529b\uff0c\u663e\u8457\u63d0\u5347\u6027\u80fd\u548c\u53ef\u6269\u5c55\u6027\u3002"}}
{"id": "2510.25057", "categories": ["cs.SE", "K.3.2; K.6.5; K.4.1"], "pdf": "https://arxiv.org/pdf/2510.25057", "abs": "https://arxiv.org/abs/2510.25057", "authors": ["Robin Maisch", "Larissa Schmid", "Timur Sa\u011flam", "Nils Niehues"], "title": "Same Same But Different: Preventing Refactoring Attacks on Software Plagiarism Detection", "comment": "To be published at ICSE'26. 13 pages, 6 figures", "summary": "Plagiarism detection in programming education faces growing challenges due to\nincreasingly sophisticated obfuscation techniques, particularly automated\nrefactoring-based attacks. While code plagiarism detection systems used in\neducation practice are resilient against basic obfuscation, they struggle\nagainst structural modifications that preserve program behavior, especially\ncaused by refactoring-based obfuscation. This paper presents a novel and\nextensible framework that enhances state-of-the-art detectors by leveraging\ncode property graphs and graph transformations to counteract refactoring-based\nobfuscation. Our comprehensive evaluation of real-world student submissions,\nobfuscated using both algorithmic and AI-based obfuscation attacks,\ndemonstrates a significant improvement in detecting plagiarized code.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4ee3\u7801\u5c5e\u6027\u56fe\u548c\u56fe\u53d8\u6362\u7684\u65b0\u6846\u67b6\uff0c\u7528\u4e8e\u589e\u5f3a\u73b0\u6709\u6284\u88ad\u68c0\u6d4b\u7cfb\u7edf\u5bf9\u6297\u91cd\u6784\u6df7\u6dc6\u653b\u51fb\u7684\u80fd\u529b\u3002", "motivation": "\u7f16\u7a0b\u6559\u80b2\u4e2d\u7684\u6284\u88ad\u68c0\u6d4b\u9762\u4e34\u65e5\u76ca\u590d\u6742\u7684\u6df7\u6dc6\u6280\u672f\u6311\u6218\uff0c\u7279\u522b\u662f\u81ea\u52a8\u5316\u91cd\u6784\u653b\u51fb\u3002\u73b0\u6709\u7cfb\u7edf\u5bf9\u57fa\u672c\u6df7\u6dc6\u6709\u62b5\u6297\u529b\uff0c\u4f46\u96be\u4ee5\u5e94\u5bf9\u4fdd\u6301\u7a0b\u5e8f\u884c\u4e3a\u7684\u7ed3\u6784\u6027\u4fee\u6539\u3002", "method": "\u5229\u7528\u4ee3\u7801\u5c5e\u6027\u56fe\u548c\u56fe\u53d8\u6362\u6784\u5efa\u53ef\u6269\u5c55\u6846\u67b6\uff0c\u589e\u5f3a\u6700\u5148\u8fdb\u7684\u68c0\u6d4b\u5668\u5bf9\u6297\u91cd\u6784\u6df7\u6dc6\u7684\u80fd\u529b\u3002", "result": "\u5728\u771f\u5b9e\u5b66\u751f\u63d0\u4ea4\u4ee3\u7801\u4e0a\u7684\u7efc\u5408\u8bc4\u4f30\u663e\u793a\uff0c\u8be5\u6846\u67b6\u5728\u68c0\u6d4b\u6284\u88ad\u4ee3\u7801\u65b9\u9762\u6709\u663e\u8457\u6539\u8fdb\uff0c\u80fd\u591f\u6709\u6548\u5bf9\u6297\u7b97\u6cd5\u548cAI\u9a71\u52a8\u7684\u6df7\u6dc6\u653b\u51fb\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u7f16\u7a0b\u6559\u80b2\u4e2d\u7684\u6284\u88ad\u68c0\u6d4b\u63d0\u4f9b\u4e86\u5bf9\u6297\u91cd\u6784\u6df7\u6dc6\u653b\u51fb\u7684\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.25401", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2510.25401", "abs": "https://arxiv.org/abs/2510.25401", "authors": ["Jiahao Lou", "Quan Yu", "Shufeng Gong", "Song Yu", "Yanfeng Zhang", "Ge Yu"], "title": "DGAI: Decoupled On-Disk Graph-Based ANN Index for Efficient Updates and Queries", "comment": "12 pages", "summary": "On-disk graph-based indexes are widely used in approximate nearest neighbor\n(ANN) search systems for large-scale, high-dimensional vectors. However,\ntraditional coupled storage methods, which store vectors within the index, are\ninefficient for index updates. Coupled storage incurs excessive redundant\nvector reads and writes when updating the graph topology, leading to\nsignificant invalid I/O. To address this issue, we propose a decoupled storage\narchitecture. While a decoupled architecture reduces query performance. To\novercome this limitation, we design two tailored strategies: (i) a three-stage\nquery mechanism that leverages multiple PQ compressed vectors to filter invalid\nI/O and computations, and (ii) an incremental page-level topological reordering\nstrategy that incrementally inserts new nodes into pages containing their most\nsimilar neighbors to mitigate read amplification. Together, these techniques\nsubstantially reduce both I/O and computational overhead during ANN search.\nExperimental results show that the decoupled architecture improves update speed\nby 10.05x for insertions and 6.89x for deletions, while the three-stage query\nand incremental reordering enhance query efficiency by 2.66x compared to the\ntraditional coupled architecture.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u89e3\u8026\u5b58\u50a8\u67b6\u6784\u6765\u6539\u8fdb\u57fa\u4e8e\u56fe\u7684\u8fd1\u4f3c\u6700\u8fd1\u90bb\u641c\u7d22\u7cfb\u7edf\uff0c\u901a\u8fc7\u4e09\u9636\u6bb5\u67e5\u8be2\u673a\u5236\u548c\u589e\u91cf\u9875\u9762\u7ea7\u62d3\u6251\u91cd\u6392\u5e8f\u7b56\u7565\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u66f4\u65b0\u901f\u5ea6\u548c\u67e5\u8be2\u6548\u7387\u3002", "motivation": "\u4f20\u7edf\u7684\u8026\u5408\u5b58\u50a8\u65b9\u6cd5\u5728\u66f4\u65b0\u56fe\u62d3\u6251\u65f6\u4f1a\u4ea7\u751f\u5927\u91cf\u5197\u4f59\u5411\u91cf\u8bfb\u5199\uff0c\u5bfc\u81f4\u65e0\u6548I/O\uff0c\u5f71\u54cd\u7d22\u5f15\u66f4\u65b0\u6548\u7387\u3002", "method": "\u91c7\u7528\u89e3\u8026\u5b58\u50a8\u67b6\u6784\uff0c\u8bbe\u8ba1\u4e09\u9636\u6bb5\u67e5\u8be2\u673a\u5236\u5229\u7528\u591a\u4e2aPQ\u538b\u7f29\u5411\u91cf\u8fc7\u6ee4\u65e0\u6548I/O\u548c\u8ba1\u7b97\uff0c\u4ee5\u53ca\u589e\u91cf\u9875\u9762\u7ea7\u62d3\u6251\u91cd\u6392\u5e8f\u7b56\u7565\u5c06\u65b0\u8282\u70b9\u63d2\u5165\u5230\u5305\u542b\u6700\u76f8\u4f3c\u90bb\u5c45\u7684\u9875\u9762\u4e2d\u3002", "result": "\u89e3\u8026\u67b6\u6784\u4f7f\u63d2\u5165\u901f\u5ea6\u63d0\u534710.05\u500d\uff0c\u5220\u9664\u901f\u5ea6\u63d0\u53476.89\u500d\uff1b\u4e09\u9636\u6bb5\u67e5\u8be2\u548c\u589e\u91cf\u91cd\u6392\u5e8f\u4f7f\u67e5\u8be2\u6548\u7387\u76f8\u6bd4\u4f20\u7edf\u8026\u5408\u67b6\u6784\u63d0\u53472.66\u500d\u3002", "conclusion": "\u89e3\u8026\u5b58\u50a8\u67b6\u6784\u7ed3\u5408\u4f18\u5316\u7684\u67e5\u8be2\u548c\u91cd\u6392\u5e8f\u7b56\u7565\uff0c\u80fd\u6709\u6548\u51cf\u5c11ANN\u641c\u7d22\u4e2d\u7684I/O\u548c\u8ba1\u7b97\u5f00\u9500\uff0c\u663e\u8457\u63d0\u5347\u7cfb\u7edf\u6027\u80fd\u3002"}}
{"id": "2510.25277", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2510.25277", "abs": "https://arxiv.org/abs/2510.25277", "authors": ["Simon S\u00fcwer", "Mai Khanh Mai", "Christoph Klein", "Nicola G\u00f6tzenberger", "Denis Dali\u0107", "Andreas Maier", "Jan Baumbach"], "title": "A Privacy-Preserving Ecosystem for Developing Machine Learning Algorithms Using Patient Data: Insights from the TUM.ai Makeathon", "comment": null, "summary": "The integration of clinical data offers significant potential for the\ndevelopment of personalized medicine. However, its use is severely restricted\nby the General Data Protection Regulation (GDPR), especially for small cohorts\nwith rare diseases. High-quality, structured data is essential for the\ndevelopment of predictive medical AI. In this case study, we propose a novel,\nmulti-stage approach to secure AI training: (1) The model is designed on a\nsimulated clinical knowledge graph (cKG). This graph is used exclusively to\nrepresent the structural characteristics of the real cKG without revealing any\nsensitive content. (2) The model is then integrated into the FeatureCloud (FC)\nfederated learning framework, where it is prepared in a single-client\nconfiguration within a protected execution environment. (3) Training then takes\nplace within the hospital environment on the real cKG, either under the direct\nsupervision of hospital staff or via a fully automated pipeline controlled by\nthe hospital. (4) Finally, verified evaluation scripts are executed, which only\nreturn aggregated performance metrics. This enables immediate performance\nfeedback without sensitive patient data or individual predictions, leaving the\nclinic. A fundamental element of this approach involves the incorporation of a\ncKG, which serves to organize multi-omics and patient data within the context\nof real-world hospital environments. This approach was successfully validated\nduring the TUM.ai Makeathon 2024 (TUMaiM24) challenge set by the Dr. von Hauner\nChildren's Hospital (HCH-LMU): 50 students developed models for patient\nclassification and diagnosis without access to real data. Deploying secure\nalgorithms via federated frameworks, such as the FC framework, could be a\npractical way of achieving privacy-preserving AI in healthcare.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u591a\u9636\u6bb5\u5b89\u5168AI\u8bad\u7ec3\u65b9\u6cd5\uff0c\u901a\u8fc7\u6a21\u62df\u4e34\u5e8a\u77e5\u8bc6\u56fe\u8c31\u8bbe\u8ba1\u6a21\u578b\uff0c\u5728\u8054\u90a6\u5b66\u4e60\u6846\u67b6\u4e2d\u8bad\u7ec3\uff0c\u4fdd\u62a4\u60a3\u8005\u9690\u79c1\u7684\u540c\u65f6\u5b9e\u73b0\u533b\u7597AI\u5f00\u53d1\u3002", "motivation": "\u4e34\u5e8a\u6570\u636e\u6574\u5408\u5bf9\u4e2a\u6027\u5316\u533b\u7597\u53d1\u5c55\u81f3\u5173\u91cd\u8981\uff0c\u4f46GDPR\u6cd5\u89c4\u9650\u5236\u4e86\u5c0f\u89c4\u6a21\u7f55\u89c1\u75c5\u961f\u5217\u6570\u636e\u7684\u4f7f\u7528\uff0c\u9700\u8981\u4fdd\u62a4\u9690\u79c1\u7684AI\u8bad\u7ec3\u65b9\u6848\u3002", "method": "\u56db\u9636\u6bb5\u65b9\u6cd5\uff1a1) \u5728\u6a21\u62df\u4e34\u5e8a\u77e5\u8bc6\u56fe\u8c31\u4e0a\u8bbe\u8ba1\u6a21\u578b\uff1b2) \u5728FeatureCloud\u8054\u90a6\u5b66\u4e60\u6846\u67b6\u4e2d\u51c6\u5907\u6a21\u578b\uff1b3) \u5728\u533b\u9662\u73af\u5883\u4e2d\u8bad\u7ec3\u771f\u5b9e\u6570\u636e\uff1b4) \u6267\u884c\u9a8c\u8bc1\u8bc4\u4f30\u811a\u672c\u4ec5\u8fd4\u56de\u805a\u5408\u6027\u80fd\u6307\u6807\u3002", "result": "\u5728TUM.ai Makeathon 2024\u6311\u6218\u4e2d\u6210\u529f\u9a8c\u8bc1\uff0c50\u540d\u5b66\u751f\u65e0\u9700\u8bbf\u95ee\u771f\u5b9e\u6570\u636e\u5373\u5f00\u53d1\u51fa\u60a3\u8005\u5206\u7c7b\u548c\u8bca\u65ad\u6a21\u578b\u3002", "conclusion": "\u901a\u8fc7\u8054\u90a6\u5b66\u4e60\u6846\u67b6\u90e8\u7f72\u5b89\u5168\u7b97\u6cd5\u662f\u5b9e\u73b0\u533b\u7597\u9886\u57df\u9690\u79c1\u4fdd\u62a4AI\u7684\u5b9e\u7528\u9014\u5f84\u3002"}}
{"id": "2510.25103", "categories": ["cs.SE", "D.2.4"], "pdf": "https://arxiv.org/pdf/2510.25103", "abs": "https://arxiv.org/abs/2510.25103", "authors": ["Minghai Lu", "Zhe Zhou", "Danning Xie", "Songlin Jia", "Benjamin Delaware", "Tianyi Zhang"], "title": "Adaptive Proof Refinement with LLM-Guided Strategy Selection", "comment": "11 pages, 11 figures", "summary": "Formal verification via theorem proving enables the expressive specification\nand rigorous proof of software correctness, but it is difficult to scale due to\nthe significant manual effort and expertise required. While Large Language\nModels (LLMs) show potential in proof generation, they frequently produce\nincorrect proofs on the first attempt and require additional strategies for\niterative refinement. However, existing approaches employ fixed refinement\nstrategies and cannot dynamically choose an effective strategy based on the\nparticular issues in a generated proof, which limits their performance. To\novercome this limitation, we introduce Adapt, a novel proof refinement\nframework that leverages an LLM-guided decision-maker to dynamically select a\nsuitable refinement strategy according to the state of the proof assistant and\navailable context of an incorrect proof. We evaluate Adapt on two benchmarks\nagainst four existing methods and find that it significantly outperforms the\nbest baseline on both by proving 16.63% and 18.58% more theorems, respectively.\nFurthermore, we demonstrate Adapt's generalizability by evaluating it across\nfive different LLMs. We also conduct ablation studies to measure the\ncontribution of each component and compare the trade-offs of alternative\ndecision-maker designs.", "AI": {"tldr": "Adapt\u662f\u4e00\u4e2a\u57fa\u4e8eLLM\u7684\u52a8\u6001\u8bc1\u660e\u7cbe\u70bc\u6846\u67b6\uff0c\u901a\u8fc7LLM\u5f15\u5bfc\u7684\u51b3\u7b56\u5668\u6839\u636e\u8bc1\u660e\u72b6\u6001\u548c\u9519\u8bef\u4e0a\u4e0b\u6587\u52a8\u6001\u9009\u62e9\u7cbe\u70bc\u7b56\u7565\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5b9a\u7406\u8bc1\u660e\u7684\u6210\u529f\u7387\u3002", "motivation": "\u73b0\u6709\u5f62\u5f0f\u5316\u9a8c\u8bc1\u65b9\u6cd5\u9700\u8981\u5927\u91cf\u4eba\u5de5\u52aa\u529b\uff0c\u800cLLM\u751f\u6210\u7684\u8bc1\u660e\u7ecf\u5e38\u9996\u6b21\u5c1d\u8bd5\u5c31\u51fa\u9519\uff0c\u4e14\u73b0\u6709\u7cbe\u70bc\u65b9\u6cd5\u4f7f\u7528\u56fa\u5b9a\u7b56\u7565\uff0c\u65e0\u6cd5\u6839\u636e\u5177\u4f53\u8bc1\u660e\u95ee\u9898\u52a8\u6001\u8c03\u6574\u3002", "method": "\u63d0\u51faAdapt\u6846\u67b6\uff0c\u4f7f\u7528LLM\u5f15\u5bfc\u7684\u51b3\u7b56\u5668\u6839\u636e\u8bc1\u660e\u52a9\u624b\u72b6\u6001\u548c\u9519\u8bef\u8bc1\u660e\u7684\u4e0a\u4e0b\u6587\u4fe1\u606f\uff0c\u52a8\u6001\u9009\u62e9\u5408\u9002\u7684\u7cbe\u70bc\u7b56\u7565\u3002", "result": "\u5728\u4e24\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cAdapt\u6bd4\u6700\u4f73\u57fa\u7ebf\u65b9\u6cd5\u5206\u522b\u591a\u8bc1\u660e\u4e8616.63%\u548c18.58%\u7684\u5b9a\u7406\uff0c\u5e76\u5728\u4e94\u4e2a\u4e0d\u540cLLM\u4e0a\u5c55\u793a\u4e86\u826f\u597d\u7684\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "Adapt\u6846\u67b6\u901a\u8fc7\u52a8\u6001\u7b56\u7565\u9009\u62e9\u663e\u8457\u63d0\u5347\u4e86\u5b9a\u7406\u8bc1\u660e\u7684\u6210\u529f\u7387\uff0c\u8bc1\u660e\u4e86\u57fa\u4e8eLLM\u7684\u52a8\u6001\u7cbe\u70bc\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2510.25684", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2510.25684", "abs": "https://arxiv.org/abs/2510.25684", "authors": ["Yujun He", "Hangdong Zhao", "Simon Frisk", "Yifei Yang", "Kevin Kristensen", "Paraschos Koutris", "Xiangyao Yu"], "title": "One Join Order Does Not Fit All: Reducing Intermediate Results with Per-Split Query Plans", "comment": null, "summary": "Minimizing intermediate results is critical for efficient multi-join query\nprocessing. Although the seminal Yannakakis algorithm offers strong guarantees\nfor acyclic queries, cyclic queries remain an open challenge. In this paper, we\npropose SplitJoin, a framework that introduces split as a first-class query\noperator. By partitioning input tables into heavy and light parts, SplitJoin\nallows different data partitions to use distinct query plans, with the goal of\nreducing intermediate sizes using existing binary join engines. We\nsystematically explore the design space for split-based optimizations,\nincluding threshold selection, split strategies, and join ordering after\nsplits. Implemented as a front-end to DuckDB and Umbra, SplitJoin achieves\nsubstantial improvements: on DuckDB, SplitJoin completes 43 social network\nqueries (vs. 29 natively), achieving 2.1x faster runtime and 7.9x smaller\nintermediates on average (up to 13.6x and 74x, respectively); on Umbra, it\ncompletes 45 queries (vs. 35), achieving 1.3x speedups and 1.2x smaller\nintermediates on average (up to 6.1x and 2.1x, respectively).", "AI": {"tldr": "SplitJoin\u6846\u67b6\u901a\u8fc7\u5f15\u5165split\u4f5c\u4e3a\u4e00\u7b49\u67e5\u8be2\u64cd\u4f5c\u7b26\uff0c\u5c06\u8f93\u5165\u8868\u5206\u533a\u4e3a\u91cd\u548c\u8f7b\u4e24\u90e8\u5206\uff0c\u5141\u8bb8\u4e0d\u540c\u6570\u636e\u5206\u533a\u4f7f\u7528\u4e0d\u540c\u7684\u67e5\u8be2\u8ba1\u5212\uff0c\u4ee5\u51cf\u5c11\u591a\u8fde\u63a5\u67e5\u8be2\u4e2d\u7684\u4e2d\u95f4\u7ed3\u679c\u5927\u5c0f\u3002", "motivation": "\u6700\u5c0f\u5316\u4e2d\u95f4\u7ed3\u679c\u5bf9\u4e8e\u9ad8\u6548\u7684\u591a\u8fde\u63a5\u67e5\u8be2\u5904\u7406\u81f3\u5173\u91cd\u8981\u3002\u867d\u7136Yannakakis\u7b97\u6cd5\u4e3a\u65e0\u73af\u67e5\u8be2\u63d0\u4f9b\u4e86\u5f3a\u4fdd\u8bc1\uff0c\u4f46\u5faa\u73af\u67e5\u8be2\u4ecd\u7136\u662f\u4e00\u4e2a\u5f00\u653e\u6311\u6218\u3002", "method": "\u63d0\u51faSplitJoin\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u533a\u8f93\u5165\u8868\u4e3a\u91cd\u548c\u8f7b\u90e8\u5206\uff0c\u4f7f\u4e0d\u540c\u6570\u636e\u5206\u533a\u80fd\u591f\u4f7f\u7528\u4e0d\u540c\u7684\u67e5\u8be2\u8ba1\u5212\uff0c\u5229\u7528\u73b0\u6709\u7684\u4e8c\u5143\u8fde\u63a5\u5f15\u64ce\u51cf\u5c11\u4e2d\u95f4\u7ed3\u679c\u5927\u5c0f\u3002\u7cfb\u7edf\u63a2\u7d22\u4e86\u57fa\u4e8e\u5206\u5272\u4f18\u5316\u7684\u8bbe\u8ba1\u7a7a\u95f4\uff0c\u5305\u62ec\u9608\u503c\u9009\u62e9\u3001\u5206\u5272\u7b56\u7565\u548c\u5206\u5272\u540e\u7684\u8fde\u63a5\u6392\u5e8f\u3002", "result": "\u5728DuckDB\u4e0a\uff0cSplitJoin\u5b8c\u6210\u4e8643\u4e2a\u793e\u4ea4\u7f51\u7edc\u67e5\u8be2\uff08\u539f\u751f\u4e3a29\u4e2a\uff09\uff0c\u5e73\u5747\u8fd0\u884c\u65f6\u95f4\u5feb2.1\u500d\uff0c\u4e2d\u95f4\u7ed3\u679c\u5c0f7.9\u500d\uff08\u6700\u9ad8\u5206\u522b\u8fbe13.6\u500d\u548c74\u500d\uff09\uff1b\u5728Umbra\u4e0a\uff0c\u5b8c\u6210\u4e8645\u4e2a\u67e5\u8be2\uff08\u539f\u751f\u4e3a35\u4e2a\uff09\uff0c\u5e73\u5747\u901f\u5ea6\u63d0\u53471.3\u500d\uff0c\u4e2d\u95f4\u7ed3\u679c\u5c0f1.2\u500d\uff08\u6700\u9ad8\u5206\u522b\u8fbe6.1\u500d\u548c2.1\u500d\uff09\u3002", "conclusion": "SplitJoin\u6846\u67b6\u901a\u8fc7\u5f15\u5165\u5206\u5272\u64cd\u4f5c\u7b26\uff0c\u6709\u6548\u51cf\u5c11\u4e86\u591a\u8fde\u63a5\u67e5\u8be2\u4e2d\u7684\u4e2d\u95f4\u7ed3\u679c\u5927\u5c0f\uff0c\u663e\u8457\u63d0\u5347\u4e86\u67e5\u8be2\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u5faa\u73af\u67e5\u8be2\u65f6\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2510.25362", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2510.25362", "abs": "https://arxiv.org/abs/2510.25362", "authors": ["Georgios L. Stavrinides", "Helen D. Karatza"], "title": "Scheduling Data-Intensive Workloads in Large-Scale Distributed Systems: Trends and Challenges", "comment": "This version of the manuscript has been accepted for publication in\n  Modeling and Simulation in HPC and Cloud Systems, ser. Studies in Big Data,\n  after peer review (Author Accepted Manuscript). It is not the final published\n  version (Version of Record) and does not reflect any post-acceptance\n  improvements. The Version of Record is available online at\n  https://doi.org/10.1007/978-3-319-73767-6_2", "summary": "With the explosive growth of big data, workloads tend to get more complex and\ncomputationally demanding. Such applications are processed on distributed\ninterconnected resources that are becoming larger in scale and computational\ncapacity. Data-intensive applications may have different degrees of parallelism\nand must effectively exploit data locality. Furthermore, they may impose\nseveral Quality of Service requirements, such as time constraints and\nresilience against failures, as well as other objectives, like energy\nefficiency. These features of the workloads, as well as the inherent\ncharacteristics of the computing resources required to process them, present\nmajor challenges that require the employment of effective scheduling\ntechniques. In this chapter, a classification of data-intensive workloads is\nproposed and an overview of the most commonly used approaches for their\nscheduling in large-scale distributed systems is given. We present novel\nstrategies that have been proposed in the literature and shed light on open\nchallenges and future directions.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u6570\u636e\u5bc6\u96c6\u578b\u5de5\u4f5c\u8d1f\u8f7d\u7684\u5206\u7c7b\u65b9\u6cd5\uff0c\u5e76\u7efc\u8ff0\u4e86\u5927\u89c4\u6a21\u5206\u5e03\u5f0f\u7cfb\u7edf\u4e2d\u5e38\u7528\u7684\u8c03\u5ea6\u6280\u672f\uff0c\u63a2\u8ba8\u4e86\u65b0\u7684\u8c03\u5ea6\u7b56\u7565\u548c\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u968f\u7740\u5927\u6570\u636e\u7206\u70b8\u6027\u589e\u957f\uff0c\u5de5\u4f5c\u8d1f\u8f7d\u53d8\u5f97\u66f4\u52a0\u590d\u6742\u548c\u8ba1\u7b97\u5bc6\u96c6\uff0c\u9700\u8981\u6709\u6548\u7684\u8c03\u5ea6\u6280\u672f\u6765\u5e94\u5bf9\u6570\u636e\u5bc6\u96c6\u578b\u5e94\u7528\u5728\u5e76\u884c\u5ea6\u3001\u6570\u636e\u5c40\u90e8\u6027\u3001\u670d\u52a1\u8d28\u91cf\u7b49\u65b9\u9762\u7684\u6311\u6218\u3002", "method": "\u63d0\u51fa\u6570\u636e\u5bc6\u96c6\u578b\u5de5\u4f5c\u8d1f\u8f7d\u7684\u5206\u7c7b\u65b9\u6cd5\uff0c\u7efc\u8ff0\u5927\u89c4\u6a21\u5206\u5e03\u5f0f\u7cfb\u7edf\u4e2d\u5e38\u7528\u7684\u8c03\u5ea6\u65b9\u6cd5\uff0c\u4ecb\u7ecd\u6587\u732e\u4e2d\u63d0\u51fa\u7684\u65b0\u7b56\u7565\u3002", "result": "\u63d0\u4f9b\u4e86\u6570\u636e\u5bc6\u96c6\u578b\u5de5\u4f5c\u8d1f\u8f7d\u7684\u7cfb\u7edf\u5206\u7c7b\u6846\u67b6\uff0c\u603b\u7ed3\u4e86\u73b0\u6709\u8c03\u5ea6\u65b9\u6cd5\u7684\u4f18\u7f3a\u70b9\uff0c\u8bc6\u522b\u4e86\u5f53\u524d\u9762\u4e34\u7684\u4e3b\u8981\u6311\u6218\u3002", "conclusion": "\u6570\u636e\u5bc6\u96c6\u578b\u5e94\u7528\u7684\u8c03\u5ea6\u5728\u5927\u89c4\u6a21\u5206\u5e03\u5f0f\u7cfb\u7edf\u4e2d\u9762\u4e34\u91cd\u5927\u6311\u6218\uff0c\u9700\u8981\u5f00\u53d1\u66f4\u6709\u6548\u7684\u8c03\u5ea6\u6280\u672f\u6765\u5e94\u5bf9\u4e0d\u65ad\u589e\u957f\u7684\u8ba1\u7b97\u9700\u6c42\u548c\u670d\u52a1\u8d28\u91cf\u8981\u6c42\u3002"}}
{"id": "2510.25148", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.25148", "abs": "https://arxiv.org/abs/2510.25148", "authors": ["Katsuki Yamagishi", "Norihiro Yoshida", "Erina Makihara", "Katsuro Inoue"], "title": "Automated Program Repair Based on REST API Specifications Using Large Language Models", "comment": null, "summary": "Many cloud services provide REST API accessible to client applications.\nHowever, developers often identify specification violations only during\ntesting, as error messages typically lack the detail necessary for effective\ndiagnosis. Consequently, debugging requires trial and error. This study\nproposes dcFix, a method for detecting and automatically repairing REST API\nmisuses in client programs. In particular, dcFix identifies non-conforming code\nfragments, integrates them with the relevant API specifications into prompts,\nand leverages a Large Language Model (LLM) to produce the corrected code. Our\nevaluation demonstrates that dcFix accurately detects misuse and outperforms\nthe baseline approach, in which prompts to the LLM omit any indication of code\nfragments non conforming to REST API specifications.", "AI": {"tldr": "dcFix\u662f\u4e00\u4e2a\u81ea\u52a8\u68c0\u6d4b\u548c\u4fee\u590dREST API\u8bef\u7528\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u8bc6\u522b\u4e0d\u7b26\u5408\u89c4\u8303\u7684\u4ee3\u7801\u7247\u6bb5\uff0c\u7ed3\u5408API\u89c4\u8303\u751f\u6210\u63d0\u793a\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u4fee\u6b63\u4ee3\u7801\u3002", "motivation": "\u5f00\u53d1\u8005\u5728\u6d4b\u8bd5\u9636\u6bb5\u624d\u80fd\u53d1\u73b0REST API\u89c4\u8303\u8fdd\u53cd\u95ee\u9898\uff0c\u9519\u8bef\u4fe1\u606f\u7f3a\u4e4f\u6709\u6548\u8bca\u65ad\u7ec6\u8282\uff0c\u8c03\u8bd5\u9700\u8981\u53cd\u590d\u8bd5\u9519\u3002", "method": "\u8bc6\u522b\u4e0d\u7b26\u5408\u89c4\u8303\u7684\u4ee3\u7801\u7247\u6bb5\uff0c\u5c06\u5176\u4e0e\u76f8\u5173API\u89c4\u8303\u6574\u5408\u5230\u63d0\u793a\u4e2d\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u4fee\u6b63\u4ee3\u7801\u3002", "result": "dcFix\u80fd\u591f\u51c6\u786e\u68c0\u6d4bAPI\u8bef\u7528\uff0c\u5e76\u4e14\u5728\u6027\u80fd\u4e0a\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff08\u57fa\u7ebf\u65b9\u6cd5\u5728\u63d0\u793a\u4e2d\u4e0d\u5305\u542b\u4ee3\u7801\u7247\u6bb5\u4e0d\u7b26\u5408REST API\u89c4\u8303\u7684\u6307\u793a\uff09\u3002", "conclusion": "dcFix\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86REST API\u8bef\u7528\u68c0\u6d4b\u548c\u81ea\u52a8\u4fee\u590d\u7684\u95ee\u9898\uff0c\u901a\u8fc7\u7ed3\u5408\u4ee3\u7801\u7247\u6bb5\u548cAPI\u89c4\u8303\u7684\u5927\u8bed\u8a00\u6a21\u578b\u63d0\u793a\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4fee\u590d\u6548\u679c\u3002"}}
{"id": "2510.25451", "categories": ["cs.DC", "cs.DS"], "pdf": "https://arxiv.org/pdf/2510.25451", "abs": "https://arxiv.org/abs/2510.25451", "authors": ["St\u00e9phane Devismes", "Yoann Dieudonn\u00e9", "Arnaud Labourel"], "title": "Can Like Attract Like? A Study of Homonymous Gathering in Networks", "comment": null, "summary": "A team of mobile agents, starting from distinct nodes of a network, have to\nmeet at the same node and declare that they all met. Agents execute the same\nalgorithm, which they start when activated by an adversary or by an agent\nentering their initial node. When activated, agents traverse edges of the\nnetwork in synchronous rounds. Their perception and communication are strictly\nlocal. This task, known as gathering, is a central problem in distributed\nmobile systems. Most prior work focuses on minimizing its time complexity,\ni.e., the worst-case number of rounds between the start of the earliest agent\nand the task completion. To break possible symmetries, deterministic solutions\ntypically assume that agents have pairwise distinct IDs, called labels, known\nonly to themselves. But must all labels be pairwise distinct to guarantee\ndeterministic gathering?\n  We address this question by considering agents that may share the same label.\nA team L is said to be gatherable if, for every initial setting of L, there is\nan algorithm that solves gathering. Our contribution is threefold. (1) We give\na full characterization of the gatherable teams. (2) We design an algorithm\nthat gathers all of them in poly$(n,\\log\\lambda)$ time, where $n$ (resp.\n$\\lambda$) is the graph order (resp. the smallest label in L). This algorithm\nrequires the agents to initially share only $O(\\log \\log \\log \\mu)$ bits of\ncommon knowledge, where $\\mu$ is the largest label multiplicity in L. (3) We\nshow this dependency is almost optimal to get a poly$(n,\\log\\lambda)$-time\ncomplexity.\n  As a by-product, we get the first deterministic poly$(n,\\log\\lambda)$-time\nalgorithm requiring no common knowledge to gather any team when all labels are\ndistinct. Known to be achievable for two-agent teams, extending this to any\nteam size faced a major challenge: termination detection. Our techniques to\naddress it may be of independent interest.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u79fb\u52a8\u4ee3\u7406\u5728\u5206\u5e03\u5f0f\u7f51\u7edc\u4e2d\u7684\u805a\u96c6\u95ee\u9898\uff0c\u7279\u522b\u5173\u6ce8\u5f53\u4ee3\u7406\u6807\u7b7e\u53ef\u80fd\u91cd\u590d\u65f6\u7684\u60c5\u51b5\u3002\u4f5c\u8005\u5b8c\u5168\u523b\u753b\u4e86\u53ef\u805a\u96c6\u56e2\u961f\u7684\u7279\u5f81\uff0c\u8bbe\u8ba1\u4e86\u591a\u9879\u5f0f\u65f6\u95f4\u7b97\u6cd5\uff0c\u5e76\u8bc1\u660e\u4e86\u6240\u9700\u516c\u5171\u77e5\u8bc6\u7684\u6700\u4f18\u6027\u3002", "motivation": "\u4f20\u7edf\u786e\u5b9a\u6027\u805a\u96c6\u7b97\u6cd5\u5047\u8bbe\u4ee3\u7406\u5177\u6709\u4e92\u4e0d\u76f8\u540c\u7684\u6807\u7b7e\uff0c\u4f46\u73b0\u5b9e\u4e2d\u6807\u7b7e\u53ef\u80fd\u91cd\u590d\u3002\u672c\u6587\u65e8\u5728\u63a2\u7d22\u5728\u6807\u7b7e\u53ef\u80fd\u91cd\u590d\u7684\u60c5\u51b5\u4e0b\uff0c\u54ea\u4e9b\u56e2\u961f\u80fd\u591f\u88ab\u786e\u5b9a\u6027\u805a\u96c6\uff0c\u4ee5\u53ca\u5982\u4f55\u9ad8\u6548\u5b9e\u73b0\u805a\u96c6\u3002", "method": "\u4f5c\u8005\u9996\u5148\u7ed9\u51fa\u4e86\u53ef\u805a\u96c6\u56e2\u961f\u7684\u5b8c\u6574\u7279\u5f81\u523b\u753b\uff0c\u7136\u540e\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u65f6\u95f4\u590d\u6742\u5ea6\u4e3apoly(n,log\u03bb)\u7684\u7b97\u6cd5\uff0c\u8be5\u7b97\u6cd5\u4ec5\u9700\u8981\u4ee3\u7406\u521d\u59cb\u5171\u4eabO(log log log \u03bc)\u6bd4\u7279\u7684\u516c\u5171\u77e5\u8bc6\u3002", "result": "\u8bba\u6587\u5b8c\u5168\u523b\u753b\u4e86\u53ef\u805a\u96c6\u56e2\u961f\u7684\u7279\u5f81\uff0c\u63d0\u51fa\u7684\u7b97\u6cd5\u80fd\u591f\u5728\u591a\u9879\u5f0f\u65f6\u95f4\u5185\u805a\u96c6\u6240\u6709\u53ef\u805a\u96c6\u56e2\u961f\uff0c\u4e14\u6240\u9700\u7684\u516c\u5171\u77e5\u8bc6\u51e0\u4e4e\u662f\u6700\u4f18\u7684\u3002\u4f5c\u4e3a\u526f\u4ea7\u54c1\uff0c\u8fd8\u5f97\u5230\u4e86\u7b2c\u4e00\u4e2a\u65e0\u9700\u516c\u5171\u77e5\u8bc6\u3001\u5728\u6807\u7b7e\u4e92\u5f02\u65f6\u80fd\u5728\u591a\u9879\u5f0f\u65f6\u95f4\u5185\u805a\u96c6\u4efb\u610f\u89c4\u6a21\u56e2\u961f\u7684\u786e\u5b9a\u6027\u7b97\u6cd5\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\u6807\u7b7e\u91cd\u590d\u5e76\u4e0d\u5fc5\u7136\u963b\u788d\u786e\u5b9a\u6027\u805a\u96c6\uff0c\u901a\u8fc7\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u7b97\u6cd5\u548c\u5c11\u91cf\u516c\u5171\u77e5\u8bc6\uff0c\u53ef\u4ee5\u5728\u591a\u9879\u5f0f\u65f6\u95f4\u5185\u89e3\u51b3\u805a\u96c6\u95ee\u9898\u3002\u7ec8\u6b62\u68c0\u6d4b\u662f\u6269\u5c55\u7b97\u6cd5\u5230\u4efb\u610f\u56e2\u961f\u89c4\u6a21\u65f6\u7684\u4e3b\u8981\u6311\u6218\uff0c\u76f8\u5173\u6280\u672f\u5177\u6709\u72ec\u7acb\u4ef7\u503c\u3002"}}
{"id": "2510.25195", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.25195", "abs": "https://arxiv.org/abs/2510.25195", "authors": ["Shuochuan Li", "Zan Wang", "Xiaoning Du", "Zhuo Wu", "Jiuqiao Yu", "Junjie Chen"], "title": "Optimizing Knowledge Utilization for Multi-Intent Comment Generation with Large Language Models", "comment": null, "summary": "Code comment generation aims to produce a generic overview of a code snippet,\nhelping developers understand and maintain code. However, generic summaries\nalone are insufficient to meet the diverse needs of practitioners; for example,\ndevelopers expect the implementation insights to be presented in an untangled\nmanner, while users seek clear usage instructions. This highlights the\nnecessity of multi-intent comment generation. With the widespread adoption of\nLarge Language Models (LLMs) for code-related tasks, these models have been\nleveraged to tackle the challenge of multi-intent comment generation. Despite\ntheir successes, state-of-the-art LLM-based approaches often struggle to\nconstruct correct relationships among intents, code, and comments within a\nsmaller number of demonstration examples. To mitigate this issue, we propose a\nframework named KUMIC for multi-intent comment generation. Built upon\nin-context learning, KUMIC leverages Chain-of-Thought (CoT) to optimize\nknowledge utilization for LLMs to generate intent-specific comments.\nSpecifically, KUMIC first designs a retrieval mechanism to obtain similar\ndemonstration examples, which exhibit high code-comment consistency. Then,\nKUMIC leverages CoT to guide LLMs to focus on statements facilitating the\nderivation of code comments aligned with specific intents. In this context,\nKUMIC constructs a mapping knowledge chain, linking code to intent-specific\nstatements to comments, which enables LLMs to follow similar reasoning steps\nwhen generating the desired comments. We conduct extensive experiments to\nevaluate KUMIC, and the results demonstrate that KUMIC outperforms\nstate-of-the-art baselines by 14.49\\%, 22.41\\%, 20.72\\%, and 12.94\\% in terms\nof BLEU, METEOR, ROUGE-L, and SBERT, respectively.", "AI": {"tldr": "KUMIC\u662f\u4e00\u4e2a\u57fa\u4e8e\u4e0a\u4e0b\u6587\u5b66\u4e60\u7684\u591a\u610f\u56fe\u4ee3\u7801\u6ce8\u91ca\u751f\u6210\u6846\u67b6\uff0c\u901a\u8fc7\u68c0\u7d22\u673a\u5236\u548c\u601d\u7ef4\u94fe\u4f18\u5316LLM\u7684\u77e5\u8bc6\u5229\u7528\uff0c\u663e\u8457\u63d0\u5347\u6ce8\u91ca\u751f\u6210\u8d28\u91cf\u3002", "motivation": "\u4f20\u7edf\u4ee3\u7801\u6ce8\u91ca\u751f\u6210\u53ea\u80fd\u63d0\u4f9b\u901a\u7528\u6982\u8ff0\uff0c\u65e0\u6cd5\u6ee1\u8db3\u5f00\u53d1\u8005\u5bf9\u5b9e\u73b0\u6d1e\u5bdf\u548c\u7528\u6237\u5bf9\u4f7f\u7528\u8bf4\u660e\u7684\u591a\u6837\u5316\u9700\u6c42\uff0c\u56e0\u6b64\u9700\u8981\u591a\u610f\u56fe\u6ce8\u91ca\u751f\u6210\u3002", "method": "KUMIC\u6846\u67b6\uff1a1) \u8bbe\u8ba1\u68c0\u7d22\u673a\u5236\u83b7\u53d6\u4ee3\u7801-\u6ce8\u91ca\u4e00\u81f4\u6027\u9ad8\u7684\u6f14\u793a\u793a\u4f8b\uff1b2) \u5229\u7528\u601d\u7ef4\u94fe\u5f15\u5bfcLLM\u5173\u6ce8\u4e0e\u7279\u5b9a\u610f\u56fe\u5bf9\u9f50\u7684\u4ee3\u7801\u8bed\u53e5\uff1b3) \u6784\u5efa\u4ece\u4ee3\u7801\u5230\u610f\u56fe\u7279\u5b9a\u8bed\u53e5\u518d\u5230\u6ce8\u91ca\u7684\u6620\u5c04\u77e5\u8bc6\u94fe\u3002", "result": "KUMIC\u5728BLEU\u3001METEOR\u3001ROUGE-L\u548cSBERT\u6307\u6807\u4e0a\u5206\u522b\u6bd4\u6700\u5148\u8fdb\u57fa\u7ebf\u65b9\u6cd5\u63d0\u5347\u4e8614.49%\u300122.41%\u300120.72%\u548c12.94%\u3002", "conclusion": "KUMIC\u901a\u8fc7\u4f18\u5316\u77e5\u8bc6\u5229\u7528\u548c\u6784\u5efa\u6620\u5c04\u77e5\u8bc6\u94fe\uff0c\u6709\u6548\u89e3\u51b3\u4e86LLM\u5728\u591a\u610f\u56fe\u6ce8\u91ca\u751f\u6210\u4e2d\u6784\u5efa\u6b63\u786e\u5173\u7cfb\u7684\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u751f\u6210\u8d28\u91cf\u3002"}}
{"id": "2510.25757", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2510.25757", "abs": "https://arxiv.org/abs/2510.25757", "authors": ["Jonas Spenger", "Kolya Krafeld", "Ruben van Gemeren", "Philipp Haller", "Paris Carbone"], "title": "Holon Streaming: Global Aggregations with Windowed CRDTs", "comment": "10 pages, 9 figures, 2 tables, 2 listings, 2 algorithms", "summary": "Scaling global aggregations is a challenge for exactly-once stream processing\nsystems. Current systems implement these either by computing the aggregation in\na single task instance, or by static aggregation trees, which limits\nscalability and may become a bottleneck. Moreover, the end-to-end latency is\ndetermined by the slowest path in the tree, and failures and reconfiguration\ncause large latency spikes due to the centralized coordination. Towards these\nissues, we present Holon Streaming, an exactly-once stream processing system\nfor global aggregations. Its deterministic programming model uses windowed\nconflict-free replicated data types (Windowed CRDTs), a novel abstraction for\nshared replicated state. Windowed CRDTs make computing global aggregations\nscalable. Furthermore, their guarantees such as determinism and convergence\nenable the design of efficient failure recovery algorithms by decentralized\ncoordination. Our evaluation shows a 5x lower latency and 2x higher throughput\nthan an existing stream processing system on global aggregation workloads, with\nan 11x latency reduction under failure scenarios. The paper demonstrates the\neffectiveness of decentralized coordination with determinism, and the utility\nof Windowed CRDTs for global aggregations.", "AI": {"tldr": "Holon Streaming\u662f\u4e00\u4e2a\u7528\u4e8e\u5168\u5c40\u805a\u5408\u7684\u7cbe\u786e\u4e00\u6b21\u6d41\u5904\u7406\u7cfb\u7edf\uff0c\u901a\u8fc7\u7a97\u53e3\u5316\u65e0\u51b2\u7a81\u590d\u5236\u6570\u636e\u7c7b\u578b\uff08Windowed CRDTs\uff09\u5b9e\u73b0\u53ef\u6269\u5c55\u7684\u5168\u5c40\u805a\u5408\u8ba1\u7b97\uff0c\u91c7\u7528\u53bb\u4e2d\u5fc3\u5316\u534f\u8c03\u673a\u5236\u663e\u8457\u964d\u4f4e\u5ef6\u8fdf\u5e76\u63d0\u9ad8\u541e\u5410\u91cf\u3002", "motivation": "\u73b0\u6709\u7cfb\u7edf\u5728\u5168\u5c40\u805a\u5408\u8ba1\u7b97\u65f6\u91c7\u7528\u5355\u4efb\u52a1\u5b9e\u4f8b\u6216\u9759\u6001\u805a\u5408\u6811\uff0c\u5b58\u5728\u53ef\u6269\u5c55\u6027\u9650\u5236\u3001\u74f6\u9888\u95ee\u9898\u3001\u7aef\u5230\u7aef\u5ef6\u8fdf\u53d7\u6700\u6162\u8def\u5f84\u5f71\u54cd\uff0c\u4ee5\u53ca\u6545\u969c\u548c\u91cd\u914d\u7f6e\u5bfc\u81f4\u7684\u5927\u5ef6\u8fdf\u5cf0\u503c\u7b49\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u786e\u5b9a\u6027\u7f16\u7a0b\u6a21\u578b\uff0c\u4f7f\u7528\u7a97\u53e3\u5316\u65e0\u51b2\u7a81\u590d\u5236\u6570\u636e\u7c7b\u578b\uff08Windowed CRDTs\uff09\u4f5c\u4e3a\u5171\u4eab\u590d\u5236\u72b6\u6001\u7684\u65b0\u62bd\u8c61\uff0c\u652f\u6301\u53bb\u4e2d\u5fc3\u5316\u534f\u8c03\u7684\u9ad8\u6548\u6545\u969c\u6062\u590d\u7b97\u6cd5\u3002", "result": "\u4e0e\u73b0\u6709\u6d41\u5904\u7406\u7cfb\u7edf\u76f8\u6bd4\uff0c\u5728\u5168\u5c40\u805a\u5408\u5de5\u4f5c\u8d1f\u8f7d\u4e0a\u5b9e\u73b05\u500d\u5ef6\u8fdf\u964d\u4f4e\u548c2\u500d\u541e\u5410\u91cf\u63d0\u5347\uff0c\u5728\u6545\u969c\u573a\u666f\u4e0b\u5ef6\u8fdf\u51cf\u5c1111\u500d\u3002", "conclusion": "\u8bc1\u660e\u4e86\u786e\u5b9a\u6027\u53bb\u4e2d\u5fc3\u5316\u534f\u8c03\u7684\u6709\u6548\u6027\uff0c\u4ee5\u53caWindowed CRDTs\u5728\u5168\u5c40\u805a\u5408\u4e2d\u7684\u5b9e\u7528\u6027\u3002"}}
{"id": "2510.25242", "categories": ["cs.SE", "C.3; D.2"], "pdf": "https://arxiv.org/pdf/2510.25242", "abs": "https://arxiv.org/abs/2510.25242", "authors": ["Nao Yoshimura", "Hiroshi Oyama", "Takuya Azumi"], "title": "TECS/Rust-OE: Optimizing Exclusive Control in Rust-based Component Systems for Embedded Devices", "comment": "5 pages (layout expanded from the 4-page IEEE version due to minor\n  lstlisting configuration adjustments for compilation). Originally published\n  as a poster paper at IEEE ISORC 2025", "summary": "The diversification of functionalities and the development of the IoT are\nmaking embedded systems larger and more complex in structure. Ensuring system\nreliability, especially in terms of security, necessitates selecting an\nappropriate programming language. As part of existing research, TECS/Rust has\nbeen proposed as a framework that combines Rust and component-based development\n(CBD) to enable scalable system design and enhanced reliability. This framework\nrepresents system structures using static mutable variables, but excessive\nexclusive controls applied to ensure thread safety have led to performance\ndegradation. This paper proposes TECS/Rust-OE, a memory-safe CBD framework\nutilizing call flows to address these limitations. The proposed Rust code\nleverages real-time OS exclusive control mechanisms, optimizing performance\nwithout compromising reusability. Rust code is automatically generated based on\ncomponent descriptions. Evaluations demonstrate reduced overhead due to\noptimized exclusion control and high reusability of the generated code.", "AI": {"tldr": "TECS/Rust-OE\u662f\u4e00\u4e2a\u5185\u5b58\u5b89\u5168\u7684\u57fa\u4e8e\u7ec4\u4ef6\u7684\u5f00\u53d1\u6846\u67b6\uff0c\u901a\u8fc7\u5229\u7528\u8c03\u7528\u6d41\u548c\u5b9e\u65f6\u64cd\u4f5c\u7cfb\u7edf\u72ec\u5360\u63a7\u5236\u673a\u5236\u6765\u4f18\u5316\u6027\u80fd\uff0c\u540c\u65f6\u4fdd\u6301\u4ee3\u7801\u53ef\u91cd\u7528\u6027\u3002", "motivation": "\u5d4c\u5165\u5f0f\u7cfb\u7edf\u53d8\u5f97\u8d8a\u6765\u8d8a\u590d\u6742\uff0c\u9700\u8981\u786e\u4fdd\u7cfb\u7edf\u53ef\u9760\u6027\uff0c\u7279\u522b\u662f\u5b89\u5168\u6027\u3002\u73b0\u6709\u7684TECS/Rust\u6846\u67b6\u7531\u4e8e\u8fc7\u5ea6\u4f7f\u7528\u72ec\u5360\u63a7\u5236\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\uff0c\u9700\u8981\u6539\u8fdb\u3002", "method": "\u63d0\u51faTECS/Rust-OE\u6846\u67b6\uff0c\u5229\u7528\u8c03\u7528\u6d41\u548c\u5b9e\u65f6\u64cd\u4f5c\u7cfb\u7edf\u72ec\u5360\u63a7\u5236\u673a\u5236\uff0c\u57fa\u4e8e\u7ec4\u4ef6\u63cf\u8ff0\u81ea\u52a8\u751f\u6210Rust\u4ee3\u7801\uff0c\u4f18\u5316\u6027\u80fd\u800c\u4e0d\u727a\u7272\u53ef\u91cd\u7528\u6027\u3002", "result": "\u8bc4\u4f30\u663e\u793a\u4f18\u5316\u540e\u7684\u72ec\u5360\u63a7\u5236\u51cf\u5c11\u4e86\u5f00\u9500\uff0c\u751f\u6210\u7684\u4ee3\u7801\u5177\u6709\u9ad8\u53ef\u91cd\u7528\u6027\u3002", "conclusion": "TECS/Rust-OE\u6846\u67b6\u6210\u529f\u89e3\u51b3\u4e86TECS/Rust\u7684\u6027\u80fd\u95ee\u9898\uff0c\u5728\u4fdd\u6301\u5185\u5b58\u5b89\u5168\u7684\u540c\u65f6\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u6027\u80fd\u548c\u53ef\u91cd\u7528\u6027\u3002"}}
{"id": "2510.25270", "categories": ["cs.SE", "C.3; D.2"], "pdf": "https://arxiv.org/pdf/2510.25270", "abs": "https://arxiv.org/abs/2510.25270", "authors": ["Nao Yoshimura", "Hiroshi Oyama", "Takuya Azumi"], "title": "TECS/Rust: Memory-safe Component Framework for Embedded Systems", "comment": "10 pages. This version includes minor lstlisting configuration\n  adjustments for successful compilation. No changes to content or layout.\n  Originally published at IEEE ISORC 2024", "summary": "As embedded systems grow in complexity and scale due to increased functional\ndiversity, component-based development (CBD) emerges as a solution to\nstreamline their architecture and enhance functionality reuse. CBD typically\nutilizes the C programming language for its direct hardware access and\nlow-level operations, despite its susceptibility to memory-related issues. To\naddress these concerns, this paper proposes TECS/Rust, a Rust-based framework\nspecifically designed for TECS, which is a component framework for embedded\nsystems. It leverages Rust's compile-time memory-safe features, such as\nlifetime and borrowing, to mitigate memory vulnerabilities common with C. The\nproposed framework not only ensures memory safety but also maintains the\nflexibility of CBD, automates Rust code generation for CBD components, and\nsupports efficient integration with real-time operating systems. An evaluation\nof the amount of generated code indicates that the code generated by this paper\nframework accounts for a large percentage of the actual code. Compared to code\ndeveloped without the proposed framework, the difference in execution time is\nminimal, indicating that the overhead introduced by the proposed framework is\nnegligible.", "AI": {"tldr": "\u63d0\u51fa\u4e86TECS/Rust\u6846\u67b6\uff0c\u5c06Rust\u7684\u5185\u5b58\u5b89\u5168\u7279\u6027\u4e0e\u5d4c\u5165\u5f0f\u7cfb\u7edf\u7ec4\u4ef6\u6846\u67b6TECS\u7ed3\u5408\uff0c\u89e3\u51b3C\u8bed\u8a00\u5728\u7ec4\u4ef6\u5316\u5f00\u53d1\u4e2d\u7684\u5185\u5b58\u5b89\u5168\u95ee\u9898\uff0c\u540c\u65f6\u4fdd\u6301\u6267\u884c\u6548\u7387\u3002", "motivation": "\u5d4c\u5165\u5f0f\u7cfb\u7edf\u590d\u6742\u5ea6\u589e\u52a0\uff0c\u7ec4\u4ef6\u5316\u5f00\u53d1(CBD)\u6210\u4e3a\u89e3\u51b3\u65b9\u6848\uff0c\u4f46C\u8bed\u8a00\u5b58\u5728\u5185\u5b58\u5b89\u5168\u95ee\u9898\u3002\u9700\u8981\u7ed3\u5408Rust\u7684\u5185\u5b58\u5b89\u5168\u7279\u6027\u6765\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u5f00\u53d1\u57fa\u4e8eRust\u7684TECS\u6846\u67b6\uff0c\u5229\u7528Rust\u7684\u7f16\u8bd1\u65f6\u5185\u5b58\u5b89\u5168\u7279\u6027\uff08\u751f\u547d\u5468\u671f\u548c\u501f\u7528\u68c0\u67e5\uff09\uff0c\u81ea\u52a8\u751f\u6210CBD\u7ec4\u4ef6\u7684Rust\u4ee3\u7801\uff0c\u5e76\u652f\u6301\u4e0e\u5b9e\u65f6\u64cd\u4f5c\u7cfb\u7edf\u7684\u96c6\u6210\u3002", "result": "\u751f\u6210\u7684\u4ee3\u7801\u5360\u5b9e\u9645\u4ee3\u7801\u7684\u5f88\u5927\u6bd4\u4f8b\uff0c\u4e0e\u65e0\u6846\u67b6\u5f00\u53d1\u76f8\u6bd4\u6267\u884c\u65f6\u95f4\u5dee\u5f02\u6781\u5c0f\uff0c\u6846\u67b6\u5f15\u5165\u7684\u5f00\u9500\u53ef\u5ffd\u7565\u4e0d\u8ba1\u3002", "conclusion": "TECS/Rust\u6846\u67b6\u6210\u529f\u5c06Rust\u7684\u5185\u5b58\u5b89\u5168\u4f18\u52bf\u4e0e\u5d4c\u5165\u5f0f\u7cfb\u7edf\u7ec4\u4ef6\u5316\u5f00\u53d1\u7ed3\u5408\uff0c\u5728\u4fdd\u8bc1\u5b89\u5168\u6027\u7684\u540c\u65f6\u4fdd\u6301\u4e86\u6267\u884c\u6548\u7387\u3002"}}
{"id": "2510.25297", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.25297", "abs": "https://arxiv.org/abs/2510.25297", "authors": ["Hidetake Tanaka", "Haruto Tanaka", "Kazumasa Shimari", "Kenichi Matsumoto"], "title": "Understanding the Characteristics of LLM-Generated Property-Based Tests in Exploring Edge Cases", "comment": "Accepted for publication in 2nd IEEE/ACM international conference on\n  AI-powered Software (AIware 2025) : 8 pages, 1 table, 8 figures", "summary": "As Large Language Models (LLMs) increasingly generate code in software\ndevelopment, ensuring the quality of LLM-generated code has become important.\nTraditional testing approaches using Example-based Testing (EBT) often miss\nedge cases -- defects that occur at boundary values, special input patterns, or\nextreme conditions. This research investigates the characteristics of\nLLM-generated Property-based Testing (PBT) compared to EBT for exploring edge\ncases. We analyze 16 HumanEval problems where standard solutions failed on\nextended test cases, generating both PBT and EBT test codes using\nClaude-4-sonnet. Our experimental results reveal that while each method\nindividually achieved a 68.75\\% bug detection rate, combining both approaches\nimproved detection to 81.25\\%. The analysis demonstrates complementary\ncharacteristics: PBT effectively detects performance issues and edge cases\nthrough extensive input space exploration, while EBT effectively detects\nspecific boundary conditions and special patterns. These findings suggest that\na hybrid approach leveraging both testing methods can improve the reliability\nof LLM-generated code, providing guidance for test generation strategies in\nLLM-based code generation.", "AI": {"tldr": "\u7814\u7a76\u6bd4\u8f83\u4e86\u57fa\u4e8e\u5c5e\u6027\u7684\u6d4b\u8bd5(PBT)\u548c\u57fa\u4e8e\u793a\u4f8b\u7684\u6d4b\u8bd5(EBT)\u5728\u68c0\u6d4bLLM\u751f\u6210\u4ee3\u7801\u8fb9\u7f18\u6848\u4f8b\u65b9\u9762\u7684\u6548\u679c\uff0c\u53d1\u73b0\u4e24\u79cd\u65b9\u6cd5\u5404\u6709\u4f18\u52bf\uff0c\u7ed3\u5408\u4f7f\u7528\u53ef\u5c06\u7f3a\u9677\u68c0\u6d4b\u7387\u4ece68.75%\u63d0\u5347\u81f381.25%\u3002", "motivation": "\u968f\u7740LLM\u5728\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u751f\u6210\u4ee3\u7801\u7684\u666e\u53ca\uff0c\u786e\u4fddLLM\u751f\u6210\u4ee3\u7801\u8d28\u91cf\u53d8\u5f97\u91cd\u8981\u3002\u4f20\u7edf\u57fa\u4e8e\u793a\u4f8b\u7684\u6d4b\u8bd5\u65b9\u6cd5\u7ecf\u5e38\u9057\u6f0f\u8fb9\u7f18\u6848\u4f8b\uff0c\u9700\u8981\u63a2\u7d22\u66f4\u6709\u6548\u7684\u6d4b\u8bd5\u65b9\u6cd5\u3002", "method": "\u5206\u6790\u4e8616\u4e2aHumanEval\u95ee\u9898\uff0c\u4f7f\u7528Claude-4-sonnet\u751f\u6210PBT\u548cEBT\u6d4b\u8bd5\u4ee3\u7801\uff0c\u6bd4\u8f83\u4e24\u79cd\u65b9\u6cd5\u5728\u68c0\u6d4b\u8fb9\u7f18\u6848\u4f8b\u65b9\u9762\u7684\u8868\u73b0\u3002", "result": "\u5355\u72ec\u4f7f\u7528PBT\u6216EBT\u7684\u7f3a\u9677\u68c0\u6d4b\u7387\u4e3a68.75%\uff0c\u4f46\u7ed3\u5408\u4e24\u79cd\u65b9\u6cd5\u53ef\u5c06\u68c0\u6d4b\u7387\u63d0\u5347\u81f381.25%\u3002PBT\u64c5\u957f\u68c0\u6d4b\u6027\u80fd\u95ee\u9898\u548c\u901a\u8fc7\u5e7f\u6cdb\u8f93\u5165\u7a7a\u95f4\u63a2\u7d22\u8fb9\u7f18\u6848\u4f8b\uff0cEBT\u64c5\u957f\u68c0\u6d4b\u7279\u5b9a\u8fb9\u754c\u6761\u4ef6\u548c\u7279\u6b8a\u6a21\u5f0f\u3002", "conclusion": "\u7ed3\u5408PBT\u548cEBT\u7684\u6df7\u5408\u65b9\u6cd5\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8LLM\u751f\u6210\u4ee3\u7801\u7684\u53ef\u9760\u6027\uff0c\u4e3aLLM\u4ee3\u7801\u751f\u6210\u7684\u6d4b\u8bd5\u7b56\u7565\u63d0\u4f9b\u6307\u5bfc\u3002"}}
{"id": "2510.25406", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.25406", "abs": "https://arxiv.org/abs/2510.25406", "authors": ["Changjie Wang", "Mariano Scazzariello", "Anoud Alshnaka", "Roberto Guanciale", "Dejan Kosti\u0107", "Marco Chiesa"], "title": "Dissect-and-Restore: AI-based Code Verification with Transient Refactoring", "comment": null, "summary": "Formal verification is increasingly recognized as a critical foundation for\nbuilding reliable software systems. However, the need for specialized expertise\nto write precise specifications, navigate complex proof obligations, and learn\nannotations often makes verification an order of magnitude more expensive than\nimplementation. While modern AI systems can recognize patterns in mathematical\nproofs and interpret natural language, effectively integrating them into the\nformal verification process remains an open challenge. We present Prometheus, a\nnovel AI-assisted system that facilitates automated code verification with\ncurrent AI capabilities in conjunction with modular software engineering\nprinciples (e.g., modular refactoring). Our approach begins by decomposing\ncomplex program logic, such as nested loops, into smaller, verifiable\ncomponents. Once verified, these components are recomposed to construct a proof\nof the original program. This decomposition-recomposition workflow is\nnon-trivial. Prometheus addresses this by guiding the proof search through\nstructured decomposition of complex lemmas into smaller, verifiable sub-lemmas.\nWhen automated tools are insufficient, users can provide lightweight natural\nlanguage guidance to steer the proof process effectively. Our evaluation\ndemonstrates that transiently applying modular restructuring to the code\nsubstantially improves the AI's effectiveness in verifying individual\ncomponents. This approach successfully verifies 86% of tasks in our curated\ndataset, compared to 68% for the baseline. Gains are more pronounced with\nincreasing specification complexity, improving from 30% to 69%, and when\nintegrating proof outlines for complex programs, from 25% to 87%.", "AI": {"tldr": "Prometheus\u662f\u4e00\u4e2aAI\u8f85\u52a9\u7684\u81ea\u52a8\u5316\u4ee3\u7801\u9a8c\u8bc1\u7cfb\u7edf\uff0c\u901a\u8fc7\u6a21\u5757\u5316\u91cd\u6784\u5c06\u590d\u6742\u7a0b\u5e8f\u5206\u89e3\u4e3a\u53ef\u9a8c\u8bc1\u7684\u5c0f\u7ec4\u4ef6\uff0c\u7136\u540e\u91cd\u65b0\u7ec4\u5408\u6784\u5efa\u539f\u59cb\u7a0b\u5e8f\u7684\u8bc1\u660e\uff0c\u663e\u8457\u63d0\u9ad8\u4e86AI\u5728\u5f62\u5f0f\u5316\u9a8c\u8bc1\u4e2d\u7684\u6709\u6548\u6027\u3002", "motivation": "\u5f62\u5f0f\u5316\u9a8c\u8bc1\u5bf9\u6784\u5efa\u53ef\u9760\u8f6f\u4ef6\u7cfb\u7edf\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u9700\u8981\u4e13\u4e1a\u77e5\u8bc6\u4e14\u6210\u672c\u9ad8\u6602\u3002\u867d\u7136\u73b0\u4ee3AI\u7cfb\u7edf\u80fd\u8bc6\u522b\u6570\u5b66\u8bc1\u660e\u6a21\u5f0f\uff0c\u4f46\u5982\u4f55\u6709\u6548\u5c06\u5176\u96c6\u6210\u5230\u5f62\u5f0f\u5316\u9a8c\u8bc1\u8fc7\u7a0b\u4ecd\u662f\u4e00\u4e2a\u5f00\u653e\u6311\u6218\u3002", "method": "\u91c7\u7528\u5206\u89e3-\u91cd\u7ec4\u5de5\u4f5c\u6d41\uff1a\u9996\u5148\u5c06\u590d\u6742\u7a0b\u5e8f\u903b\u8f91\uff08\u5982\u5d4c\u5957\u5faa\u73af\uff09\u5206\u89e3\u4e3a\u66f4\u5c0f\u53ef\u9a8c\u8bc1\u7ec4\u4ef6\uff0c\u9a8c\u8bc1\u540e\u91cd\u65b0\u7ec4\u5408\u6784\u5efa\u539f\u59cb\u7a0b\u5e8f\u8bc1\u660e\u3002\u7cfb\u7edf\u901a\u8fc7\u7ed3\u6784\u5316\u5206\u89e3\u590d\u6742\u5f15\u7406\u6307\u5bfc\u8bc1\u660e\u641c\u7d22\uff0c\u5f53\u81ea\u52a8\u5316\u5de5\u5177\u4e0d\u8db3\u65f6\uff0c\u7528\u6237\u53ef\u63d0\u4f9b\u8f7b\u91cf\u7ea7\u81ea\u7136\u8bed\u8a00\u6307\u5bfc\u3002", "result": "\u5728\u7b56\u5212\u7684\u6570\u636e\u96c6\u4e2d\u6210\u529f\u9a8c\u8bc1\u4e8686%\u7684\u4efb\u52a1\uff08\u57fa\u7ebf\u4e3a68%\uff09\u3002\u968f\u7740\u89c4\u8303\u590d\u6742\u5ea6\u7684\u589e\u52a0\uff0c\u9a8c\u8bc1\u6210\u529f\u7387\u4ece30%\u63d0\u5347\u523069%\uff1b\u5728\u96c6\u6210\u590d\u6742\u7a0b\u5e8f\u7684\u8bc1\u660e\u5927\u7eb2\u65f6\uff0c\u4ece25%\u63d0\u5347\u523087%\u3002", "conclusion": "\u901a\u8fc7\u6a21\u5757\u5316\u91cd\u6784\u4ee3\u7801\u53ef\u663e\u8457\u63d0\u9ad8AI\u9a8c\u8bc1\u5355\u4e2a\u7ec4\u4ef6\u7684\u6709\u6548\u6027\uff0cPrometheus\u7cfb\u7edf\u6210\u529f\u89e3\u51b3\u4e86\u5c06AI\u96c6\u6210\u5230\u5f62\u5f0f\u5316\u9a8c\u8bc1\u8fc7\u7a0b\u7684\u6311\u6218\u3002"}}
{"id": "2510.25423", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.25423", "abs": "https://arxiv.org/abs/2510.25423", "authors": ["Ali Asgari", "Annibale Panichella", "Pouria Derakhshanfar", "Mitchell Olsthoorn"], "title": "What Challenges Do Developers Face in AI Agent Systems? An Empirical Study on Stack Overflow", "comment": "12 pages, 4 Figures", "summary": "AI agents have rapidly gained popularity across research and industry as\nsystems that extend large language models with additional capabilities to plan,\nuse tools, remember, and act toward specific goals. Yet despite their promise,\ndevelopers face persistent and often underexplored challenges when building,\ndeploying, and maintaining these emerging systems. To identify these\nchallenges, we study developer discussions on Stack Overflow, the world's\nlargest developer-focused Q and A platform with about 60 million questions and\nanswers and 30 million users. We construct a taxonomy of developer challenges\nthrough tag expansion and filtering, apply LDA-MALLET for topic modeling, and\nmanually validate and label the resulting themes. Our analysis reveals seven\nmajor areas of recurring issues encompassing 77 distinct technical challenges\nrelated to runtime integration, dependency management, orchestration\ncomplexity, and evaluation reliability. We further quantify topic popularity\nand difficulty to identify which issues are most common and hardest to resolve,\nmap the tools and programming languages used in agent development, and track\ntheir evolution from 2021 to 2025 in relation to major AI model and framework\nreleases. Finally, we present the implications of our results, offering\nconcrete guidance for practitioners, researchers, and educators on agent\nreliability and developer support.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u5206\u6790Stack Overflow\u4e0aAI\u667a\u80fd\u4f53\u5f00\u53d1\u8005\u7684\u8ba8\u8bba\uff0c\u8bc6\u522b\u51fa77\u4e2a\u6280\u672f\u6311\u6218\uff0c\u6db5\u76d6\u8fd0\u884c\u65f6\u96c6\u6210\u3001\u4f9d\u8d56\u7ba1\u7406\u3001\u7f16\u6392\u590d\u6742\u6027\u548c\u8bc4\u4f30\u53ef\u9760\u6027\u7b497\u5927\u9886\u57df\uff0c\u5e76\u91cf\u5316\u4e86\u95ee\u9898\u7684\u6d41\u884c\u5ea6\u548c\u96be\u5ea6\u3002", "motivation": "AI\u667a\u80fd\u4f53\u867d\u7136\u53d1\u5c55\u8fc5\u901f\uff0c\u4f46\u5f00\u53d1\u8005\u5728\u6784\u5efa\u3001\u90e8\u7f72\u548c\u7ef4\u62a4\u8fd9\u4e9b\u7cfb\u7edf\u65f6\u9762\u4e34\u6301\u7eed\u4e14\u672a\u88ab\u5145\u5206\u63a2\u7d22\u7684\u6311\u6218\uff0c\u9700\u8981\u7cfb\u7edf\u6027\u5730\u8bc6\u522b\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u6807\u7b7e\u6269\u5c55\u548c\u8fc7\u6ee4\u6784\u5efa\u5206\u7c7b\u6cd5\uff0c\u5e94\u7528LDA-MALLET\u8fdb\u884c\u4e3b\u9898\u5efa\u6a21\uff0c\u5e76\u624b\u52a8\u9a8c\u8bc1\u548c\u6807\u8bb0\u4e3b\u9898\uff0c\u5206\u67902021-2025\u5e74\u5f00\u53d1\u8005\u8ba8\u8bba\u3002", "result": "\u8bc6\u522b\u51fa7\u5927\u9886\u57df77\u4e2a\u6280\u672f\u6311\u6218\uff0c\u91cf\u5316\u4e86\u4e3b\u9898\u6d41\u884c\u5ea6\u548c\u96be\u5ea6\uff0c\u7ed8\u5236\u4e86\u667a\u80fd\u4f53\u5f00\u53d1\u4f7f\u7528\u7684\u5de5\u5177\u548c\u7f16\u7a0b\u8bed\u8a00\u56fe\u8c31\uff0c\u5e76\u8ffd\u8e2a\u4e86\u5176\u4e0eAI\u6a21\u578b\u548c\u6846\u67b6\u53d1\u5e03\u7684\u6f14\u53d8\u5173\u7cfb\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u4e3a\u4ece\u4e1a\u8005\u3001\u7814\u7a76\u4eba\u5458\u548c\u6559\u80b2\u5de5\u4f5c\u8005\u63d0\u4f9b\u4e86\u5173\u4e8e\u667a\u80fd\u4f53\u53ef\u9760\u6027\u548c\u5f00\u53d1\u8005\u652f\u6301\u7684\u5177\u4f53\u6307\u5bfc\u3002"}}
{"id": "2510.25506", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.25506", "abs": "https://arxiv.org/abs/2510.25506", "authors": ["Florian Angermeir", "Maximilian Amougou", "Mark Kreitz", "Andreas Bauer", "Matthias Linhuber", "Davide Fucci", "Fabiola Moy\u00f3n C.", "Daniel Mendez", "Tony Gorschek"], "title": "Reflections on the Reproducibility of Commercial LLM Performance in Empirical Software Engineering Studies", "comment": null, "summary": "Large Language Models have gained remarkable interest in industry and\nacademia. The increasing interest in LLMs in academia is also reflected in the\nnumber of publications on this topic over the last years. For instance, alone\n78 of the around 425 publications at ICSE 2024 performed experiments with LLMs.\nConducting empirical studies with LLMs remains challenging and raises questions\non how to achieve reproducible results, for both other researchers and\npractitioners. One important step towards excelling in empirical research on\nLLMs and their application is to first understand to what extent current\nresearch results are eventually reproducible and what factors may impede\nreproducibility. This investigation is within the scope of our work. We\ncontribute an analysis of the reproducibility of LLM-centric studies, provide\ninsights into the factors impeding reproducibility, and discuss suggestions on\nhow to improve the current state. In particular, we studied the 86 articles\ndescribing LLM-centric studies, published at ICSE 2024 and ASE 2024. Of the 86\narticles, 18 provided research artefacts and used OpenAI models. We attempted\nto replicate those 18 studies. Of the 18 studies, only five were fit for\nreproduction. For none of the five studies, we were able to fully reproduce the\nresults. Two studies seemed to be partially reproducible, and three studies did\nnot seem to be reproducible. Our results highlight not only the need for\nstricter research artefact evaluations but also for more robust study designs\nto ensure the reproducible value of future publications.", "AI": {"tldr": "\u5bf9ICSE 2024\u548cASE 2024\u4f1a\u8bae\u4e0a86\u7bc7LLM\u76f8\u5173\u8bba\u6587\u7684\u53ef\u590d\u73b0\u6027\u5206\u6790\u663e\u793a\uff0c\u53ea\u670918\u7bc7\u63d0\u4f9b\u4e86\u7814\u7a76\u5de5\u4ef6\u5e76\u4f7f\u7528OpenAI\u6a21\u578b\u3002\u5728\u8fd918\u7bc7\u4e2d\uff0c\u4ec55\u7bc7\u9002\u5408\u590d\u73b0\uff0c\u4f46\u6ca1\u6709\u4e00\u7bc7\u80fd\u5b8c\u5168\u590d\u73b0\u7ed3\u679c\uff0c2\u7bc7\u90e8\u5206\u53ef\u590d\u73b0\uff0c3\u7bc7\u4e0d\u53ef\u590d\u73b0\u3002", "motivation": "\u968f\u7740LLM\u5728\u5b66\u672f\u754c\u548c\u5de5\u4e1a\u754c\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u8fdb\u884c\u53ef\u590d\u73b0\u7684\u5b9e\u8bc1\u7814\u7a76\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002\u672c\u7814\u7a76\u65e8\u5728\u8bc4\u4f30\u5f53\u524dLLM\u76f8\u5173\u7814\u7a76\u7684\u53ef\u590d\u73b0\u6027\u7a0b\u5ea6\uff0c\u5e76\u8bc6\u522b\u963b\u788d\u53ef\u590d\u73b0\u6027\u7684\u56e0\u7d20\u3002", "method": "\u5206\u6790\u4e86ICSE 2024\u548cASE 2024\u4f1a\u8bae\u4e0a\u53d1\u8868\u768486\u7bc7LLM\u76f8\u5173\u8bba\u6587\uff0c\u91cd\u70b9\u5173\u6ce8\u5176\u4e2d18\u7bc7\u63d0\u4f9b\u4e86\u7814\u7a76\u5de5\u4ef6\u5e76\u4f7f\u7528OpenAI\u6a21\u578b\u7684\u7814\u7a76\uff0c\u5e76\u5c1d\u8bd5\u590d\u73b0\u8fd9\u4e9b\u7814\u7a76\u3002", "result": "\u572818\u7bc7\u7814\u7a76\u4e2d\uff0c\u53ea\u67095\u7bc7\u9002\u5408\u590d\u73b0\u5c1d\u8bd5\u3002\u5176\u4e2d\u6ca1\u6709\u4e00\u7bc7\u80fd\u5b8c\u5168\u590d\u73b0\u539f\u59cb\u7ed3\u679c\uff0c2\u7bc7\u90e8\u5206\u53ef\u590d\u73b0\uff0c3\u7bc7\u5b8c\u5168\u4e0d\u53ef\u590d\u73b0\u3002", "conclusion": "\u5f53\u524dLLM\u7814\u7a76\u7684\u53ef\u590d\u73b0\u6027\u72b6\u51b5\u4ee4\u4eba\u62c5\u5fe7\uff0c\u9700\u8981\u66f4\u4e25\u683c\u7684\u7814\u7a76\u5de5\u4ef6\u8bc4\u4f30\u548c\u66f4\u7a33\u5065\u7684\u7814\u7a76\u8bbe\u8ba1\uff0c\u4ee5\u786e\u4fdd\u672a\u6765\u53d1\u8868\u6210\u679c\u7684\u53ef\u590d\u73b0\u4ef7\u503c\u3002"}}
{"id": "2510.25665", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.25665", "abs": "https://arxiv.org/abs/2510.25665", "authors": ["Ayse Irmak Ercevik", "Aidan Dakhama", "Melane Navaratnarajah", "Yazhuo Cao", "Leo Fernandes"], "title": "Fuzz Smarter, Not Harder: Towards Greener Fuzzing with GreenAFL", "comment": null, "summary": "Fuzzing has become a key search-based technique for software testing, but\ncontinuous fuzzing campaigns consume substantial computational resources and\ngenerate significant carbon footprints. Existing grey-box fuzzing approaches\nlike AFL++ focus primarily on coverage maximisation, without considering the\nenergy costs of exploring different execution paths. This paper presents\nGreenAFL, an energy-aware framework that incorporates power consumption into\nthe fuzzing heuristics to reduce the environmental impact of automated testing\nwhilst maintaining coverage. GreenAFL introduces two key modifications to\ntraditional fuzzing workflows: energy-aware corpus minimisation considering\npower consumption when reducing initial corpora, and energy-guided heuristics\nthat direct mutation towards high-coverage, low-energy inputs. We conduct an\nablation study comparing vanilla AFL++, energy-based corpus minimisation, and\nenergy-based heuristics to evaluate the individual contributions of each\ncomponent. Results show that highest coverage, and lowest energy usage is\nachieved whenever at least one of our modifications is used.", "AI": {"tldr": "GreenAFL\u662f\u4e00\u4e2a\u80fd\u91cf\u611f\u77e5\u7684\u6a21\u7cca\u6d4b\u8bd5\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u529f\u8017\u7eb3\u5165\u6a21\u7cca\u6d4b\u8bd5\u542f\u53d1\u5f0f\u7b97\u6cd5\uff0c\u5728\u4fdd\u6301\u8986\u76d6\u7387\u7684\u540c\u65f6\u51cf\u5c11\u81ea\u52a8\u5316\u6d4b\u8bd5\u7684\u73af\u5883\u5f71\u54cd\u3002", "motivation": "\u73b0\u6709\u7070\u76d2\u6a21\u7cca\u6d4b\u8bd5\u65b9\u6cd5\u5982AFL++\u4e3b\u8981\u5173\u6ce8\u8986\u76d6\u7387\u6700\u5927\u5316\uff0c\u800c\u4e0d\u8003\u8651\u63a2\u7d22\u4e0d\u540c\u6267\u884c\u8def\u5f84\u7684\u80fd\u91cf\u6210\u672c\uff0c\u5bfc\u81f4\u6301\u7eed\u6a21\u7cca\u6d4b\u8bd5\u6d3b\u52a8\u6d88\u8017\u5927\u91cf\u8ba1\u7b97\u8d44\u6e90\u5e76\u4ea7\u751f\u663e\u8457\u78b3\u8db3\u8ff9\u3002", "method": "GreenAFL\u5bf9\u4f20\u7edf\u6a21\u7cca\u6d4b\u8bd5\u5de5\u4f5c\u6d41\u8fdb\u884c\u4e24\u4e2a\u5173\u952e\u4fee\u6539\uff1a\u8003\u8651\u529f\u8017\u7684\u80fd\u91cf\u611f\u77e5\u8bed\u6599\u5e93\u6700\u5c0f\u5316\uff0c\u4ee5\u53ca\u5f15\u5bfc\u53d8\u5f02\u671d\u5411\u9ad8\u8986\u76d6\u7387\u3001\u4f4e\u80fd\u91cf\u8f93\u5165\u7684\u80fd\u91cf\u5f15\u5bfc\u542f\u53d1\u5f0f\u7b97\u6cd5\u3002", "result": "\u6d88\u878d\u7814\u7a76\u8868\u660e\uff0c\u4f7f\u7528\u81f3\u5c11\u4e00\u4e2a\u4fee\u6539\u7ec4\u4ef6\u65f6\uff0c\u80fd\u591f\u5b9e\u73b0\u6700\u9ad8\u8986\u76d6\u7387\u548c\u6700\u4f4e\u80fd\u91cf\u4f7f\u7528\u3002", "conclusion": "\u5c06\u80fd\u91cf\u6d88\u8017\u7eb3\u5165\u6a21\u7cca\u6d4b\u8bd5\u542f\u53d1\u5f0f\u7b97\u6cd5\u53ef\u4ee5\u6709\u6548\u51cf\u5c11\u73af\u5883\u8db3\u8ff9\uff0c\u540c\u65f6\u4fdd\u6301\u6d4b\u8bd5\u6548\u679c\u3002"}}
{"id": "2510.25692", "categories": ["cs.SE", "cs.LG", "D.2.6; I.2.6"], "pdf": "https://arxiv.org/pdf/2510.25692", "abs": "https://arxiv.org/abs/2510.25692", "authors": ["Tim Strnad", "Bla\u017e Bertalani\u010d", "Carolina Fortuna"], "title": "A Configuration-First Framework for Reproducible, Low-Code Localization", "comment": "20 pages, 7 figures. Preprint submitted to ACM Transactions on\n  Software Engineering and Methodology (TOSEM), 2025", "summary": "Machine learning is increasingly permeating radio-based localization\nservices. To keep results credible and comparable, everyday workflows should\nmake rigorous experiment specification and exact repeatability the default,\nwithout blocking advanced experimentation. However, in practice, researchers\nface a three-way gap that could be filled by a framework that offers (i) low\ncoding effort for end-to-end studies, (ii) reproducibility by default including\nversioned code, data, and configurations, controlled randomness, isolated runs,\nand recorded artifacts, and (iii) built-in extensibility so new models,\nmetrics, and stages can be added with minimal integration effort. Existing\ntools rarely deliver all three for machine learning in general and localization\nworkflows in particular. In this paper we introduce LOCALIZE, a low-code,\nconfiguration-first framework for radio localization in which experiments are\ndeclared in human-readable configuration, a workflow orchestrator runs\nstandardized pipelines from data preparation to reporting, and all artifacts,\nsuch as datasets, models, metrics, and reports, are versioned. The\npreconfigured, versioned datasets reduce initial setup and boilerplate,\nspeeding up model development and evaluation. The design, with clear extension\npoints, allows experts to add components without reworking the infrastructure.\nIn a qualitative comparison and a head-to-head study against a plain Jupyter\nnotebook baseline, we show that the framework reduces authoring effort while\nmaintaining comparable runtime and memory behavior. Furthermore, using a\nBluetooth Low Energy dataset, we show that scaling across training data (1x to\n10x) keeps orchestration overheads bounded as data grows. Overall, the\nframework makes reproducible machine-learning-based localization\nexperimentation practical, accessible, and extensible.", "AI": {"tldr": "LOCALIZE\u662f\u4e00\u4e2a\u4f4e\u4ee3\u7801\u3001\u914d\u7f6e\u4f18\u5148\u7684\u65e0\u7ebf\u7535\u5b9a\u4f4d\u6846\u67b6\uff0c\u901a\u8fc7\u58f0\u660e\u5f0f\u914d\u7f6e\u548c\u6807\u51c6\u5316\u5de5\u4f5c\u6d41\u5b9e\u73b0\u53ef\u590d\u73b0\u7684\u673a\u5668\u5b66\u4e60\u5b9e\u9a8c\uff0c\u51cf\u5c11\u7f16\u7801\u5de5\u4f5c\u91cf\uff0c\u540c\u65f6\u4fdd\u6301\u53ef\u6269\u5c55\u6027\u3002", "motivation": "\u89e3\u51b3\u673a\u5668\u5b66\u4e60\u5728\u65e0\u7ebf\u7535\u5b9a\u4f4d\u4e2d\u9762\u4e34\u7684\u4e09\u91cd\u5dee\u8ddd\uff1a\u4f4e\u7f16\u7801\u5de5\u4f5c\u91cf\u3001\u9ed8\u8ba4\u53ef\u590d\u73b0\u6027\uff08\u5305\u62ec\u7248\u672c\u5316\u4ee3\u7801\u3001\u6570\u636e\u548c\u914d\u7f6e\uff09\u4ee5\u53ca\u5185\u7f6e\u53ef\u6269\u5c55\u6027\u3002\u73b0\u6709\u5de5\u5177\u5f88\u5c11\u80fd\u540c\u65f6\u6ee1\u8db3\u8fd9\u4e09\u4e2a\u9700\u6c42\u3002", "method": "\u5f00\u53d1\u4e86LOCALIZE\u6846\u67b6\uff0c\u4f7f\u7528\u4eba\u7c7b\u53ef\u8bfb\u7684\u914d\u7f6e\u58f0\u660e\u5b9e\u9a8c\uff0c\u5de5\u4f5c\u6d41\u7f16\u6392\u5668\u8fd0\u884c\u4ece\u6570\u636e\u51c6\u5907\u5230\u62a5\u544a\u7684\u6807\u51c6\u5316\u6d41\u6c34\u7ebf\uff0c\u6240\u6709\u5de5\u4ef6\uff08\u6570\u636e\u96c6\u3001\u6a21\u578b\u3001\u6307\u6807\u548c\u62a5\u544a\uff09\u90fd\u8fdb\u884c\u7248\u672c\u63a7\u5236\u3002", "result": "\u4e0e\u666e\u901aJupyter\u7b14\u8bb0\u672c\u57fa\u7ebf\u76f8\u6bd4\uff0c\u8be5\u6846\u67b6\u51cf\u5c11\u4e86\u7f16\u5199\u5de5\u4f5c\u91cf\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u76f8\u5f53\u7684\u8fd0\u884c\u65f6\u95f4\u548c\u5185\u5b58\u884c\u4e3a\u3002\u4f7f\u7528\u84dd\u7259\u4f4e\u529f\u8017\u6570\u636e\u96c6\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u968f\u7740\u6570\u636e\u91cf\u4ece1\u500d\u589e\u957f\u523010\u500d\uff0c\u7f16\u6392\u5f00\u9500\u4fdd\u6301\u6709\u754c\u3002", "conclusion": "\u8be5\u6846\u67b6\u4f7f\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u53ef\u590d\u73b0\u5b9a\u4f4d\u5b9e\u9a8c\u53d8\u5f97\u5b9e\u7528\u3001\u6613\u8bbf\u95ee\u548c\u53ef\u6269\u5c55\u3002"}}
{"id": "2510.25694", "categories": ["cs.SE", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.25694", "abs": "https://arxiv.org/abs/2510.25694", "authors": ["Jiayi Kuang", "Yinghui Li", "Xin Zhang", "Yangning Li", "Di Yin", "Xing Sun", "Ying Shen", "Philip S. Yu"], "title": "Process-Level Trajectory Evaluation for Environment Configuration in Software Engineering Agents", "comment": null, "summary": "Large language model-based agents show promise for software engineering, but\nenvironment configuration remains a bottleneck due to heavy manual effort and\nscarce large-scale, high-quality datasets. Existing benchmarks assess only\nend-to-end build/test success, obscuring where and why agents succeed or fail.\nWe introduce the Environment Configuration Diagnosis Benchmark, Enconda-bench,\nwhich provides process-level trajectory assessment of fine-grained agent\ncapabilities during environment setup-planning, perception-driven error\ndiagnosis, feedback-driven repair, and action to execute final environment\nconfiguration. Our task instances are automatically constructed by injecting\nrealistic README errors and are validated in Docker for scalable, high-quality\nevaluation. Enconda-bench combines process-level analysis with end-to-end\nexecutability to enable capability assessments beyond aggregate success rates.\nEvaluations across state-of-the-art LLMs and agent frameworks show that while\nagents can localize errors, they struggle to translate feedback into effective\ncorrections, limiting end-to-end performance. To our knowledge, Enconda-bench\nis the first framework to provide process-level internal capability assessment\nfor environment configuration, offering actionable insights for improving\nsoftware engineering agents.", "AI": {"tldr": "Enconda-bench\u662f\u4e00\u4e2a\u73af\u5883\u914d\u7f6e\u8bca\u65ad\u57fa\u51c6\u6d4b\u8bd5\uff0c\u901a\u8fc7\u8fc7\u7a0b\u7ea7\u8f68\u8ff9\u8bc4\u4f30\u6765\u8bca\u65adLLM\u4ee3\u7406\u5728\u8f6f\u4ef6\u73af\u5883\u914d\u7f6e\u4e2d\u7684\u7ec6\u7c92\u5ea6\u80fd\u529b\uff0c\u5305\u62ec\u89c4\u5212\u3001\u9519\u8bef\u8bca\u65ad\u3001\u53cd\u9988\u4fee\u590d\u7b49\u73af\u8282\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u4ec5\u8bc4\u4f30\u7aef\u5230\u7aef\u7684\u6784\u5efa/\u6d4b\u8bd5\u6210\u529f\u7387\uff0c\u65e0\u6cd5\u63ed\u793a\u4ee3\u7406\u5728\u73af\u5883\u914d\u7f6e\u8fc7\u7a0b\u4e2d\u5177\u4f53\u5728\u54ea\u91cc\u5931\u8d25\u4ee5\u53ca\u5931\u8d25\u539f\u56e0\uff0c\u9650\u5236\u4e86\u8f6f\u4ef6\u5de5\u7a0b\u4ee3\u7406\u80fd\u529b\u7684\u6df1\u5165\u5206\u6790\u3002", "method": "\u901a\u8fc7\u81ea\u52a8\u6ce8\u5165\u771f\u5b9e\u7684README\u9519\u8bef\u6784\u5efa\u4efb\u52a1\u5b9e\u4f8b\uff0c\u5728Docker\u4e2d\u8fdb\u884c\u53ef\u6269\u5c55\u7684\u9ad8\u8d28\u91cf\u8bc4\u4f30\uff0c\u7ed3\u5408\u8fc7\u7a0b\u7ea7\u5206\u6790\u548c\u7aef\u5230\u7aef\u53ef\u6267\u884c\u6027\u6765\u8bc4\u4f30\u4ee3\u7406\u80fd\u529b\u3002", "result": "\u8bc4\u4f30\u663e\u793a\uff0c\u867d\u7136\u4ee3\u7406\u80fd\u591f\u5b9a\u4f4d\u9519\u8bef\uff0c\u4f46\u96be\u4ee5\u5c06\u53cd\u9988\u8f6c\u5316\u4e3a\u6709\u6548\u4fee\u6b63\uff0c\u8fd9\u9650\u5236\u4e86\u7aef\u5230\u7aef\u6027\u80fd\u3002", "conclusion": "Enconda-bench\u662f\u9996\u4e2a\u4e3a\u73af\u5883\u914d\u7f6e\u63d0\u4f9b\u8fc7\u7a0b\u7ea7\u5185\u90e8\u80fd\u529b\u8bc4\u4f30\u7684\u6846\u67b6\uff0c\u4e3a\u6539\u8fdb\u8f6f\u4ef6\u5de5\u7a0b\u4ee3\u7406\u63d0\u4f9b\u4e86\u53ef\u64cd\u4f5c\u7684\u89c1\u89e3\u3002"}}
