{"id": "2602.02584", "categories": ["cs.SE", "cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2602.02584", "abs": "https://arxiv.org/abs/2602.02584", "authors": ["Srinivas Rao Marri"], "title": "Constitutional Spec-Driven Development: Enforcing Security by Construction in AI-Assisted Code Generation", "comment": "15 pages, 2 figures, 5 tables, 11 code listings, 14 references. Includes reference implementation and compliance traceability matrix", "summary": "The proliferation of AI-assisted \"vibe coding\" enables rapid software development but introduces significant security risks, as Large Language Models (LLMs) prioritize functional correctness over security. We present Constitutional Spec-Driven Development, a methodology that embeds non-negotiable security principles into the specification layer, ensuring AI-generated code adheres to security requirements by construction rather than inspection. Our approach introduces a Constitution: a versioned, machine-readable document encoding security constraints derived from Common Weakness Enumeration (CWE)/MITRE Top 25 vulnerabilities and regulatory frameworks. We demonstrate the methodology through a banking microservices application, selected as a representative example domain due to its stringent regulatory and security requirements, implementing customer management, account operations, and transaction processing. The methodology itself is domain-agnostic. The implementation addresses 10 critical CWE vulnerabilities through constitutional constraints with full traceability from principles to code locations. Our case study shows that constitutional constraints reduce security defects by 73% compared to unconstrained AI generation while maintaining developer velocity. We contribute a formal framework for constitutional security, a complete development methodology, and empirical evidence that proactive security specification outperforms reactive security verification in AI-assisted development workflows.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faConstitutional Spec-Driven Development\u65b9\u6cd5\uff0c\u5c06\u5b89\u5168\u539f\u5219\u5d4c\u5165\u89c4\u8303\u5c42\uff0c\u4f7fAI\u751f\u6210\u7684\u4ee3\u7801\u4ece\u4e00\u5f00\u59cb\u5c31\u7b26\u5408\u5b89\u5168\u8981\u6c42\uff0c\u5728\u94f6\u884c\u5fae\u670d\u52a1\u6848\u4f8b\u4e2d\u51cf\u5c1173%\u5b89\u5168\u7f3a\u9677\u3002", "motivation": "AI\u8f85\u52a9\u7684\"\u6c1b\u56f4\u7f16\u7a0b\"\u867d\u7136\u52a0\u901f\u8f6f\u4ef6\u5f00\u53d1\uff0c\u4f46\u5927\u8bed\u8a00\u6a21\u578b\u4f18\u5148\u8003\u8651\u529f\u80fd\u6b63\u786e\u6027\u800c\u975e\u5b89\u5168\u6027\uff0c\u5f15\u5165\u4e86\u91cd\u5927\u5b89\u5168\u98ce\u9669\u3002\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u786e\u4fddAI\u751f\u6210\u7684\u4ee3\u7801\u7b26\u5408\u5b89\u5168\u8981\u6c42\u3002", "method": "\u63d0\u51faConstitutional Spec-Driven Development\u65b9\u6cd5\uff0c\u5f15\u5165\"\u5baa\u6cd5\"\u6982\u5ff5\uff1a\u4e00\u4e2a\u7248\u672c\u5316\u3001\u673a\u5668\u53ef\u8bfb\u7684\u6587\u6863\uff0c\u7f16\u7801\u4eceCWE/MITRE Top 25\u6f0f\u6d1e\u548c\u76d1\u7ba1\u6846\u67b6\u884d\u751f\u7684\u5b89\u5168\u7ea6\u675f\u3002\u8be5\u65b9\u6cd5\u5c06\u4e0d\u53ef\u534f\u5546\u7684\u5b89\u5168\u539f\u5219\u5d4c\u5165\u89c4\u8303\u5c42\uff0c\u786e\u4fddAI\u751f\u6210\u7684\u4ee3\u7801\u901a\u8fc7\u6784\u9020\u800c\u975e\u68c0\u67e5\u6765\u9075\u5b88\u5b89\u5168\u8981\u6c42\u3002", "result": "\u5728\u94f6\u884c\u5fae\u670d\u52a1\u5e94\u7528\u6848\u4f8b\u4e2d\uff0c\u901a\u8fc7\u5baa\u6cd5\u7ea6\u675f\u89e3\u51b3\u4e8610\u4e2a\u5173\u952eCWE\u6f0f\u6d1e\uff0c\u5b9e\u73b0\u4e86\u4ece\u539f\u5219\u5230\u4ee3\u7801\u4f4d\u7f6e\u7684\u5168\u94fe\u8def\u53ef\u8ffd\u6eaf\u6027\u3002\u76f8\u6bd4\u65e0\u7ea6\u675f\u7684AI\u751f\u6210\uff0c\u5baa\u6cd5\u7ea6\u675f\u51cf\u5c11\u4e8673%\u7684\u5b89\u5168\u7f3a\u9677\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u5f00\u53d1\u901f\u5ea6\u3002", "conclusion": "\u8d21\u732e\u4e86\u5baa\u6cd5\u5b89\u5168\u7684\u5f62\u5f0f\u5316\u6846\u67b6\u3001\u5b8c\u6574\u7684\u5f00\u53d1\u65b9\u6cd5\u5b66\uff0c\u4ee5\u53ca\u5b9e\u8bc1\u8bc1\u636e\u8868\u660e\u5728AI\u8f85\u52a9\u5f00\u53d1\u5de5\u4f5c\u6d41\u4e2d\uff0c\u4e3b\u52a8\u7684\u5b89\u5168\u89c4\u8303\u4f18\u4e8e\u88ab\u52a8\u7684\u5b89\u5168\u9a8c\u8bc1\u3002\u8be5\u65b9\u6cd5\u672c\u8eab\u662f\u9886\u57df\u65e0\u5173\u7684\u3002"}}
{"id": "2602.02585", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.02585", "abs": "https://arxiv.org/abs/2602.02585", "authors": ["Aprameya Bharadwaj", "Kyle Tu"], "title": "Agentic Observability: Automated Alert Triage for Adobe E-Commerce", "comment": "Accepted at AAAI'26 Agentic AI Benchmarks and Applications for Enterprise Tasks Workshop", "summary": "Modern enterprise systems exhibit complex interdependencies that make observability and incident response increasingly challenging. Manual alert triage, which typically involves log inspection, API verification, and cross-referencing operational knowledge bases, remains a major bottleneck in reducing mean recovery time (MTTR). This paper presents an agentic observability framework deployed within Adobe's e-commerce infrastructure that autonomously performs alert triage using a ReAct paradigm. Upon alert detection, the agent dynamically identifies the affected service, retrieves and analyzes correlated logs across distributed systems, and plans context-dependent actions such as handbook consultation, runbook execution, or retrieval-augmented analysis of recently deployed code. Empirical results from production deployment indicate a 90% reduction in mean time to insight compared to manual triage, while maintaining comparable diagnostic accuracy. Our results show that agentic AI enables an order-of-magnitude reduction in triage latency and a step-change in resolution accuracy, marking a pivotal shift toward autonomous observability in enterprise operations.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eReAct\u8303\u5f0f\u7684\u667a\u80fd\u53ef\u89c2\u6d4b\u6027\u6846\u67b6\uff0c\u5728Adobe\u7535\u5546\u57fa\u7840\u8bbe\u65bd\u4e2d\u90e8\u7f72\uff0c\u80fd\u81ea\u4e3b\u8fdb\u884c\u544a\u8b66\u5206\u7c7b\uff0c\u76f8\u6bd4\u4eba\u5de5\u5904\u7406\u5c06\u5e73\u5747\u6d1e\u5bdf\u65f6\u95f4\u51cf\u5c1190%", "motivation": "\u73b0\u4ee3\u4f01\u4e1a\u7cfb\u7edf\u5b58\u5728\u590d\u6742\u7684\u76f8\u4e92\u4f9d\u8d56\u6027\uff0c\u4f7f\u5f97\u53ef\u89c2\u6d4b\u6027\u548c\u4e8b\u4ef6\u54cd\u5e94\u53d8\u5f97\u65e5\u76ca\u56f0\u96be\u3002\u4eba\u5de5\u544a\u8b66\u5206\u7c7b\uff08\u5305\u62ec\u65e5\u5fd7\u68c0\u67e5\u3001API\u9a8c\u8bc1\u548c\u64cd\u4f5c\u77e5\u8bc6\u5e93\u4ea4\u53c9\u5f15\u7528\uff09\u4ecd\u7136\u662f\u964d\u4f4e\u5e73\u5747\u6062\u590d\u65f6\u95f4\uff08MTTR\uff09\u7684\u4e3b\u8981\u74f6\u9888\u3002", "method": "\u91c7\u7528ReAct\u8303\u5f0f\u7684\u667a\u80fd\u53ef\u89c2\u6d4b\u6027\u6846\u67b6\uff0c\u5728\u68c0\u6d4b\u5230\u544a\u8b66\u65f6\uff0c\u4ee3\u7406\u80fd\u52a8\u6001\u8bc6\u522b\u53d7\u5f71\u54cd\u7684\u670d\u52a1\uff0c\u68c0\u7d22\u548c\u5206\u6790\u5206\u5e03\u5f0f\u7cfb\u7edf\u4e2d\u7684\u76f8\u5173\u65e5\u5fd7\uff0c\u5e76\u89c4\u5212\u4e0a\u4e0b\u6587\u76f8\u5173\u7684\u64cd\u4f5c\uff0c\u5982\u624b\u518c\u54a8\u8be2\u3001\u8fd0\u884c\u624b\u518c\u6267\u884c\u6216\u6700\u8fd1\u90e8\u7f72\u4ee3\u7801\u7684\u68c0\u7d22\u589e\u5f3a\u5206\u6790\u3002", "result": "\u751f\u4ea7\u90e8\u7f72\u7684\u5b9e\u8bc1\u7ed3\u679c\u8868\u660e\uff0c\u4e0e\u4eba\u5de5\u5206\u7c7b\u76f8\u6bd4\uff0c\u5e73\u5747\u6d1e\u5bdf\u65f6\u95f4\u51cf\u5c11\u4e8690%\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u76f8\u5f53\u7684\u8bca\u65ad\u51c6\u786e\u6027\u3002\u667a\u80fdAI\u4f7f\u5206\u7c7b\u5ef6\u8fdf\u964d\u4f4e\u4e86\u4e00\u4e2a\u6570\u91cf\u7ea7\uff0c\u5e76\u5728\u89e3\u51b3\u51c6\u786e\u6027\u65b9\u9762\u5b9e\u73b0\u4e86\u9636\u8dc3\u5f0f\u6539\u8fdb\u3002", "conclusion": "\u667a\u80fdAI\u5b9e\u73b0\u4e86\u5206\u7c7b\u5ef6\u8fdf\u7684\u6570\u91cf\u7ea7\u51cf\u5c11\u548c\u89e3\u51b3\u51c6\u786e\u6027\u7684\u9636\u8dc3\u5f0f\u6539\u8fdb\uff0c\u6807\u5fd7\u7740\u4f01\u4e1a\u8fd0\u8425\u5411\u81ea\u4e3b\u53ef\u89c2\u6d4b\u6027\u7684\u5173\u952e\u8f6c\u53d8\u3002"}}
{"id": "2602.02614", "categories": ["cs.SE", "cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2602.02614", "abs": "https://arxiv.org/abs/2602.02614", "authors": ["Ying Wang", "Jiahui Chen", "Dejun Jiang"], "title": "Testing Storage-System Correctness: Challenges, Fuzzing Limitations, and AI-Augmented Opportunities", "comment": null, "summary": "Storage systems are fundamental to modern computing infrastructures, yet ensuring their correctness remains challenging in practice. Despite decades of research on system testing, many storage-system failures (including durability, ordering, recovery, and consistency violations) remain difficult to expose systematically. This difficulty stems not primarily from insufficient testing tooling, but from intrinsic properties of storage-system execution, including nondeterministic interleavings, long-horizon state evolution, and correctness semantics that span multiple layers and execution phases.\n  This survey adopts a storage-centric view of system testing and organizes existing techniques according to the execution properties and failure mechanisms they target. We review a broad spectrum of approaches, ranging from concurrency testing and long-running workloads to crash-consistency analysis, hardware-level semantic validation, and distributed fault injection, and analyze their fundamental strengths and limitations. Within this framework, we examine fuzzing as an automated testing paradigm, highlighting systematic mismatches between conventional fuzzing assumptions and storage-system semantics, and discuss how recent artificial intelligence advances may complement fuzzing through state-aware and semantic guidance. Overall, this survey provides a unified perspective on storage-system correctness testing and outlines key challenges", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u7efc\u8ff0\u4e86\u5b58\u50a8\u7cfb\u7edf\u6b63\u786e\u6027\u6d4b\u8bd5\u7684\u6311\u6218\u4e0e\u73b0\u72b6\uff0c\u5206\u6790\u4e86\u73b0\u6709\u6d4b\u8bd5\u6280\u672f\u7684\u4f18\u7f3a\u70b9\uff0c\u5e76\u63a2\u8ba8\u4e86\u6a21\u7cca\u6d4b\u8bd5\u4e0eAI\u6280\u672f\u5728\u8be5\u9886\u57df\u7684\u5e94\u7528\u524d\u666f\u3002", "motivation": "\u5b58\u50a8\u7cfb\u7edf\u662f\u73b0\u4ee3\u8ba1\u7b97\u57fa\u7840\u8bbe\u65bd\u7684\u57fa\u7840\uff0c\u4f46\u786e\u4fdd\u5176\u6b63\u786e\u6027\u5728\u5b9e\u8df5\u4e2d\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\u3002\u5c3d\u7ba1\u7cfb\u7edf\u6d4b\u8bd5\u7814\u7a76\u5df2\u6709\u6570\u5341\u5e74\uff0c\u4f46\u8bb8\u591a\u5b58\u50a8\u7cfb\u7edf\u6545\u969c\uff08\u5305\u62ec\u6301\u4e45\u6027\u3001\u987a\u5e8f\u6027\u3001\u6062\u590d\u548c\u4e00\u81f4\u6027\u8fdd\u89c4\uff09\u4ecd\u7136\u96be\u4ee5\u7cfb\u7edf\u6027\u5730\u66b4\u9732\u3002\u8fd9\u79cd\u56f0\u96be\u4e3b\u8981\u6e90\u4e8e\u5b58\u50a8\u7cfb\u7edf\u6267\u884c\u7684\u5185\u5728\u7279\u6027\uff0c\u800c\u975e\u6d4b\u8bd5\u5de5\u5177\u4e0d\u8db3\u3002", "method": "\u91c7\u7528\u5b58\u50a8\u4e2d\u5fc3\u89c6\u89d2\u7ec4\u7ec7\u7cfb\u7edf\u6d4b\u8bd5\u6280\u672f\uff0c\u6839\u636e\u6267\u884c\u5c5e\u6027\u548c\u6545\u969c\u673a\u5236\u5bf9\u73b0\u6709\u6280\u672f\u8fdb\u884c\u5206\u7c7b\u3002\u7efc\u8ff0\u4e86\u4ece\u5e76\u53d1\u6d4b\u8bd5\u3001\u957f\u671f\u8fd0\u884c\u5de5\u4f5c\u8d1f\u8f7d\u5230\u5d29\u6e83\u4e00\u81f4\u6027\u5206\u6790\u3001\u786c\u4ef6\u7ea7\u8bed\u4e49\u9a8c\u8bc1\u548c\u5206\u5e03\u5f0f\u6545\u969c\u6ce8\u5165\u7b49\u591a\u79cd\u65b9\u6cd5\uff0c\u5e76\u5206\u6790\u5176\u57fa\u672c\u4f18\u52bf\u548c\u5c40\u9650\u6027\u3002\u7279\u522b\u5173\u6ce8\u6a21\u7cca\u6d4b\u8bd5\u4f5c\u4e3a\u81ea\u52a8\u5316\u6d4b\u8bd5\u8303\u5f0f\uff0c\u5e76\u63a2\u8ba8AI\u6280\u672f\u5982\u4f55\u901a\u8fc7\u72b6\u6001\u611f\u77e5\u548c\u8bed\u4e49\u6307\u5bfc\u6765\u8865\u5145\u6a21\u7cca\u6d4b\u8bd5\u3002", "result": "\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u5b58\u50a8\u7cfb\u7edf\u6b63\u786e\u6027\u6d4b\u8bd5\u89c6\u89d2\uff0c\u8bc6\u522b\u4e86\u73b0\u6709\u6d4b\u8bd5\u6280\u672f\u7684\u5173\u952e\u5c40\u9650\u6027\uff0c\u7279\u522b\u662f\u4f20\u7edf\u6a21\u7cca\u6d4b\u8bd5\u5047\u8bbe\u4e0e\u5b58\u50a8\u7cfb\u7edf\u8bed\u4e49\u4e4b\u95f4\u7684\u7cfb\u7edf\u6027\u4e0d\u5339\u914d\u95ee\u9898\u3002", "conclusion": "\u5b58\u50a8\u7cfb\u7edf\u6d4b\u8bd5\u9762\u4e34\u56fa\u6709\u6311\u6218\uff0c\u9700\u8981\u9488\u5bf9\u5176\u7279\u6b8a\u6267\u884c\u7279\u6027\u5f00\u53d1\u4e13\u95e8\u7684\u6d4b\u8bd5\u65b9\u6cd5\u3002\u6a21\u7cca\u6d4b\u8bd5\u9700\u8981\u9002\u5e94\u5b58\u50a8\u7cfb\u7edf\u8bed\u4e49\uff0c\u800cAI\u6280\u672f\u53ef\u80fd\u63d0\u4f9b\u65b0\u7684\u6d4b\u8bd5\u6307\u5bfc\u65b9\u5411\u3002\u8be5\u7efc\u8ff0\u4e3a\u5b58\u50a8\u7cfb\u7edf\u6b63\u786e\u6027\u6d4b\u8bd5\u63d0\u4f9b\u4e86\u7cfb\u7edf\u5316\u7684\u5206\u6790\u6846\u67b6\uff0c\u5e76\u6307\u51fa\u4e86\u672a\u6765\u7814\u7a76\u7684\u5173\u952e\u6311\u6218\u3002"}}
{"id": "2602.02690", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.02690", "abs": "https://arxiv.org/abs/2602.02690", "authors": ["Chenxi Huang", "Alex Mathai", "Feiyang Yu", "Aleksandr Nogikh", "Petros Maniatis", "Franjo Ivan\u010di\u0107", "Eugene Wu", "Kostis Kaffes", "Junfeng Yang", "Baishakhi Ray"], "title": "Outrunning LLM Cutoffs: A Live Kernel Crash Resolution Benchmark for All", "comment": null, "summary": "Repairing system crashes discovered by kernel fuzzers like Syzkaller is a critical yet underexplored challenge in software engineering. While recent works have introduced Large Language Model (LLM) based agents for Linux kernel crash-resolution, their evaluation benchmarks are usually static and thus, do not capture the evolving nature of the Linux kernel, and suffer from potential data contamination due to LLM knowledge cutoffs. To address the above problem, we present (i) Live-kBench, an evaluation framework for self-evolving benchmarks that continuously scrapes and evaluates agents on freshly discovered kernel bugs, and (ii) kEnv, an agent-agnostic standardized crash-resolution environment for kernel compilation, execution, and feedback. This design decouples agent workflows from heavy-weight execution, enabling fair and scalable comparison across diverse agent frameworks under identical conditions.\n  To this end, we curate an inaugural dataset of 534 Linux kernel bugs and empirically demonstrate a significant performance gap, with agents achieving up to 25% higher equivalent patch rate on bugs fixed before the LLM knowledge cutoff. Using kEnv, we benchmark three state-of-the-art agents, showing that they resolve 74% of crashes on the first attempt (plausible patches); however only ~20% of generated patches closely match developer fixes. Additionally, exposing crash resolution feedback improves crash resolution rate by 29%. Live-kBench provides the community with an evaluation infrastructure for self-evolving benchmarks that is both time and attribute sensitive; complete with a public dashboard to track agent progress on Linux kernel bugs.", "AI": {"tldr": "\u63d0\u51fa\u4e86Live-kBench\u548ckEnv\u6846\u67b6\uff0c\u7528\u4e8e\u8bc4\u4f30LLM\u4ee3\u7406\u4fee\u590dLinux\u5185\u6838\u5d29\u6e83\u7684\u80fd\u529b\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u9759\u6001\u57fa\u51c6\u65e0\u6cd5\u6355\u6349\u5185\u6838\u6f14\u5316\u548c\u6570\u636e\u6c61\u67d3\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u7684LLM\u4ee3\u7406\u8bc4\u4f30\u57fa\u51c6\u662f\u9759\u6001\u7684\uff0c\u65e0\u6cd5\u53cd\u6620Linux\u5185\u6838\u7684\u6301\u7eed\u6f14\u5316\u7279\u6027\uff0c\u4e14\u5b58\u5728\u56e0LLM\u77e5\u8bc6\u622a\u6b62\u65e5\u671f\u5bfc\u81f4\u7684\u6570\u636e\u6c61\u67d3\u95ee\u9898\uff0c\u9700\u8981\u66f4\u52a8\u6001\u3001\u516c\u5e73\u7684\u8bc4\u4f30\u6846\u67b6\u3002", "method": "\u5f00\u53d1\u4e86Live-kBench\uff08\u81ea\u6f14\u5316\u57fa\u51c6\u8bc4\u4f30\u6846\u67b6\uff09\u548ckEnv\uff08\u4ee3\u7406\u65e0\u5173\u7684\u6807\u51c6\u5316\u5d29\u6e83\u4fee\u590d\u73af\u5883\uff09\uff0c\u524d\u8005\u6301\u7eed\u722c\u53d6\u65b0\u53d1\u73b0\u7684\u5185\u6838bug\uff0c\u540e\u8005\u63d0\u4f9b\u5185\u6838\u7f16\u8bd1\u3001\u6267\u884c\u548c\u53cd\u9988\u7684\u7edf\u4e00\u73af\u5883\u3002", "result": "\u5728534\u4e2aLinux\u5185\u6838bug\u6570\u636e\u96c6\u4e0a\uff0c\u4ee3\u7406\u5728LLM\u77e5\u8bc6\u622a\u6b62\u65e5\u671f\u524d\u4fee\u590d\u7684bug\u4e0a\u8fbe\u523025%\u66f4\u9ad8\u7684\u7b49\u6548\u8865\u4e01\u7387\uff1b\u4ee3\u7406\u9996\u5c1d\u8bd5\u4fee\u590d74%\u7684\u5d29\u6e83\uff0c\u4f46\u53ea\u6709\u7ea620%\u7684\u8865\u4e01\u4e0e\u5f00\u53d1\u8005\u4fee\u590d\u9ad8\u5ea6\u5339\u914d\uff1b\u66b4\u9732\u5d29\u6e83\u4fee\u590d\u53cd\u9988\u53ef\u5c06\u4fee\u590d\u7387\u63d0\u9ad829%\u3002", "conclusion": "Live-kBench\u548ckEnv\u4e3a\u5185\u6838\u5d29\u6e83\u4fee\u590d\u63d0\u4f9b\u4e86\u52a8\u6001\u3001\u516c\u5e73\u7684\u8bc4\u4f30\u57fa\u7840\u8bbe\u65bd\uff0c\u63ed\u793a\u4e86\u5f53\u524dLLM\u4ee3\u7406\u4e0e\u5f00\u53d1\u8005\u4fee\u590d\u4e4b\u95f4\u7684\u663e\u8457\u5dee\u8ddd\uff0c\u5e76\u5c55\u793a\u4e86\u53cd\u9988\u673a\u5236\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2602.02892", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2602.02892", "abs": "https://arxiv.org/abs/2602.02892", "authors": ["Zhuolun Xiang", "Andrei Tonkikh", "Alexander Spiegelman"], "title": "Prefix Consensus For Censorship Resistant BFT", "comment": null, "summary": "Despite broad use of BFT consensus in blockchains, censorship resistance is weak: leaders can exclude transactions, a growing concern for trading and DeFi.\n  We address this by introducing a new abstraction and protocol stack. First, we introduce \\emph{Prefix Consensus}, where parties input vectors and output $(v^{\\sf low},v^{\\sf high})$ that (i) extend the maximum common prefix of honest inputs and (ii) satisfy $v_i^{\\sf low}\\preceq v_j^{\\sf high}$ for all honest $i,j$. Unlike classical consensus, no single output is required. We show Prefix Consensus is solvable asynchronously and give tight round-complexity bounds.\n  We then define \\emph{Strong Prefix Consensus}, requiring agreement on the \\emph{high} output. Our protocol is leaderless and partially synchronous: one Prefix Consensus instance decides (possibly different) lows, and additional instances yield a unique safe-to-extend high, even if an adversary can suspend one party per round.\n  We lift this to a leaderless, multi-proposer, censorship-resistant BFT SMR protocol: per slot, all parties broadcast proposals, deterministically rank them, and run one Strong Prefix Consensus on proposal hashes, committing honest proposals in \\emph{four rounds}. A deterministic demotion rule updates the ranking when a party's proposal is excluded, implying that after GST at most $f$ slots can miss an honest proposal while progress remains leaderless under suspension and up to $f{-}1$ Byzantine faults.\n  Finally, we connect Prefix Consensus to graded and binary/validated consensus: we obtain an optimal-latency graded consensus (3 message delays) and leaderless Binary/Validated Consensus with worst-case message complexity $O(n^3)$ and communication $O(n^4)$.", "AI": {"tldr": "\u63d0\u51faPrefix Consensus\u65b0\u62bd\u8c61\u548c\u534f\u8bae\u6808\uff0c\u89e3\u51b3BFT\u5171\u8bc6\u4e2d\u7684\u5ba1\u67e5\u62b5\u6297\u95ee\u9898\uff0c\u5b9e\u73b0\u65e0\u9886\u5bfc\u3001\u591a\u63d0\u8bae\u8005\u7684\u6297\u5ba1\u67e5BFT SMR\u534f\u8bae", "motivation": "\u73b0\u6709BFT\u5171\u8bc6\u5728\u533a\u5757\u94fe\u4e2d\u5ba1\u67e5\u62b5\u6297\u6027\u5f31\uff0c\u9886\u5bfc\u8005\u53ef\u4ee5\u6392\u9664\u4ea4\u6613\uff0c\u8fd9\u5bf9\u4ea4\u6613\u548cDeFi\u6784\u6210\u65e5\u76ca\u589e\u957f\u7684\u62c5\u5fe7", "method": "1. \u5f15\u5165Prefix Consensus\u62bd\u8c61\uff0c\u5404\u65b9\u8f93\u5165\u5411\u91cf\u5e76\u8f93\u51fa(v_low,v_high)\uff1b2. \u5b9a\u4e49Strong Prefix Consensus\uff0c\u8981\u6c42\u5bf9high\u8f93\u51fa\u8fbe\u6210\u4e00\u81f4\uff1b3. \u6784\u5efa\u65e0\u9886\u5bfc\u3001\u591a\u63d0\u8bae\u8005\u7684\u6297\u5ba1\u67e5BFT SMR\u534f\u8bae\uff0c\u6bcf\u65f6\u9699\u6240\u6709\u65b9\u5e7f\u64ad\u63d0\u6848\u5e76\u8fd0\u884cStrong Prefix Consensus", "result": "1. Prefix Consensus\u53ef\u5728\u5f02\u6b65\u73af\u5883\u4e0b\u89e3\u51b3\u5e76\u7ed9\u51fa\u7d27\u7684\u8f6e\u590d\u6742\u5ea6\u754c\u9650\uff1b2. Strong Prefix Consensus\u534f\u8bae\u662f\u65e0\u9886\u5bfc\u7684\u4e14\u90e8\u5206\u540c\u6b65\uff1b3. BFT SMR\u534f\u8bae\u5728\u56db\u8f6e\u5185\u63d0\u4ea4\u8bda\u5b9e\u63d0\u6848\uff0cGST\u540e\u6700\u591af\u4e2a\u65f6\u9699\u53ef\u80fd\u4e22\u5931\u8bda\u5b9e\u63d0\u6848", "conclusion": "\u901a\u8fc7Prefix Consensus\u65b0\u62bd\u8c61\u6784\u5efa\u4e86\u6297\u5ba1\u67e5\u7684BFT\u5171\u8bc6\u534f\u8bae\u6808\uff0c\u8fde\u63a5\u4e86\u5206\u7ea7\u5171\u8bc6\u548c\u4e8c\u5143/\u9a8c\u8bc1\u5171\u8bc6\uff0c\u5b9e\u73b0\u4e86\u6700\u4f18\u5ef6\u8fdf\u7684\u5206\u7ea7\u5171\u8bc6\u548c\u4f4e\u590d\u6742\u5ea6\u7684\u65e0\u9886\u5bfc\u4e8c\u5143\u5171\u8bc6"}}
{"id": "2602.02999", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2602.02999", "abs": "https://arxiv.org/abs/2602.02999", "authors": ["Zhengle Wang", "Yanfei Zhang", "Chunwei Liu"], "title": "ResQ: Realistic Performance-Aware Query Generation", "comment": "13 pages, 4 figures", "summary": "Database research and development rely heavily on realistic user workloads for benchmarking, instance optimization, migration testing, and database tuning. However, acquiring real-world SQL queries is notoriously challenging due to strict privacy regulations. While cloud database vendors have begun releasing anonymized performance traces to the research community, these traces typi- cally provide only high-level execution statistics without the origi- nal query text or data, which is insufficient for scenarios that require actual execution. Existing tools fail to capture fine-grained perfor- mance patterns or generate runnable workloads that reproduce these public traces with both high fidelity and efficiency. To bridge this gap, we propose ResQ, a fine-grained workload synthesis sys- tem designed to generate executable SQL workloads that faithfully match the per-query execution targets and operator distributions of production traces. ResQ constructs execution-aware query graphs, instantiates them into SQL via Bayesian Optimization-driven pred- icate search, and explicitly models workload repetition through reuse at both exact-query and parameterized-template levels. To ensure practical scalability, ResQ combines search-space bounding with lightweight local cost models to accelerate optimization. Ex- periments on public cloud traces (Snowset, Redset) and a newly released industrial trace (Bendset) demonstrate that ResQ signif- icantly outperforms state-of-the-art baselines, achieving 96.71% token savings and a 86.97% reduction in runtime, while lowering maximum Q-error by 14.8x on CPU time and 997.7x on scanned bytes, and closely matching operator composition.", "AI": {"tldr": "ResQ\u662f\u4e00\u4e2a\u7ec6\u7c92\u5ea6\u5de5\u4f5c\u8d1f\u8f7d\u5408\u6210\u7cfb\u7edf\uff0c\u80fd\u591f\u4ece\u533f\u540d\u6027\u80fd\u8ffd\u8e2a\u751f\u6210\u53ef\u6267\u884c\u7684SQL\u5de5\u4f5c\u8d1f\u8f7d\uff0c\u5339\u914d\u67e5\u8be2\u6267\u884c\u76ee\u6807\u548c\u64cd\u4f5c\u7b26\u5206\u5e03\u3002", "motivation": "\u6570\u636e\u5e93\u7814\u53d1\u9700\u8981\u771f\u5b9e\u7528\u6237\u5de5\u4f5c\u8d1f\u8f7d\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\u548c\u4f18\u5316\uff0c\u4f46\u7531\u4e8e\u9690\u79c1\u6cd5\u89c4\u96be\u4ee5\u83b7\u53d6\u771f\u5b9eSQL\u67e5\u8be2\u3002\u73b0\u6709\u4e91\u6570\u636e\u5e93\u5382\u5546\u53d1\u5e03\u7684\u533f\u540d\u6027\u80fd\u8ffd\u8e2a\u7f3a\u4e4f\u539f\u59cb\u67e5\u8be2\u6587\u672c\u548c\u6570\u636e\uff0c\u65e0\u6cd5\u7528\u4e8e\u9700\u8981\u5b9e\u9645\u6267\u884c\u7684\u573a\u666f\u3002", "method": "ResQ\u6784\u5efa\u6267\u884c\u611f\u77e5\u7684\u67e5\u8be2\u56fe\uff0c\u901a\u8fc7\u8d1d\u53f6\u65af\u4f18\u5316\u9a71\u52a8\u7684\u8c13\u8bcd\u641c\u7d22\u5c06\u5176\u5b9e\u4f8b\u5316\u4e3aSQL\uff0c\u5e76\u5728\u7cbe\u786e\u67e5\u8be2\u548c\u53c2\u6570\u5316\u6a21\u677f\u4e24\u4e2a\u5c42\u9762\u663e\u5f0f\u5efa\u6a21\u5de5\u4f5c\u8d1f\u8f7d\u91cd\u590d\u3002\u91c7\u7528\u641c\u7d22\u7a7a\u95f4\u8fb9\u754c\u548c\u8f7b\u91cf\u7ea7\u672c\u5730\u6210\u672c\u6a21\u578b\u52a0\u901f\u4f18\u5316\u3002", "result": "\u5728\u516c\u5f00\u4e91\u8ffd\u8e2a(Snowset\u3001Redset)\u548c\u65b0\u53d1\u5e03\u7684\u5de5\u4e1a\u8ffd\u8e2a(Bendset)\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cResQ\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\uff1a\u8282\u770196.71%\u7684token\u3001\u51cf\u5c1186.97%\u7684\u8fd0\u884c\u65f6\u95f4\uff0cCPU\u65f6\u95f4\u7684\u6700\u5927Q-error\u964d\u4f4e14.8\u500d\uff0c\u626b\u63cf\u5b57\u8282\u6570\u964d\u4f4e997.7\u500d\uff0c\u64cd\u4f5c\u7b26\u7ec4\u6210\u5339\u914d\u5ea6\u9ad8\u3002", "conclusion": "ResQ\u80fd\u591f\u9ad8\u6548\u751f\u6210\u5fe0\u5b9e\u5339\u914d\u751f\u4ea7\u8ffd\u8e2a\u6267\u884c\u7279\u5f81\u7684\u53ef\u6267\u884cSQL\u5de5\u4f5c\u8d1f\u8f7d\uff0c\u89e3\u51b3\u4e86\u4ece\u533f\u540d\u6027\u80fd\u8ffd\u8e2a\u751f\u6210\u53ef\u8fd0\u884c\u5de5\u4f5c\u8d1f\u8f7d\u7684\u6311\u6218\u3002"}}
{"id": "2602.02752", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.02752", "abs": "https://arxiv.org/abs/2602.02752", "authors": ["Srinath Srinivasan", "Tim Menzies"], "title": "Beyond the Prompt: Assessing Domain Knowledge Strategies for High-Dimensional LLM Optimization in Software Engineering", "comment": "Accepted at MSR 2026 (Registered Reports Track)", "summary": "Background/Context: Large Language Models (LLMs) demonstrate strong performance on low-dimensional software engineering optimization tasks ($\\le$11 features) but consistently underperform on high-dimensional problems where Bayesian methods dominate. A fundamental gap exists in understanding how systematic integration of domain knowledge (whether from humans or automated reasoning) can bridge this divide.\n  Objective/Aim: We compare human versus artificial intelligence strategies for generating domain knowledge. We systematically evaluate four distinct architectures to determine if structured knowledge integration enables LLMs to generate effective warm starts for high-dimensional optimization.\n  Method: We evaluate four approaches on MOOT datasets stratified by dimensionality: (1) Human-in-the-Loop Domain Knowledge Prompting (H-DKP), utilizing asynchronous expert feedback loops; (2) Adaptive Multi-Stage Prompting (AMP), implementing sequential constraint identification and validation; (3) Dimension-Aware Progressive Refinement (DAPR), conducting optimization in progressively expanding feature subspaces; and (4) Hybrid Knowledge-Model Approach (HKMA), synthesizing statistical scouting (TPE) with RAG-enhanced prompting. Performance is quantified via Chebyshev distance to optimal solutions and ranked using Scott-Knott clustering against an established baseline for LLM generated warm starts.\n  Note that all human studies conducted as part of this study will comply with the policies of our local Institutional Review Board.", "AI": {"tldr": "\u672c\u7814\u7a76\u6bd4\u8f83\u4e86\u4eba\u7c7b\u4e0e\u4eba\u5de5\u667a\u80fd\u751f\u6210\u9886\u57df\u77e5\u8bc6\u7684\u65b9\u6cd5\uff0c\u8bc4\u4f30\u4e86\u56db\u79cd\u67b6\u6784\u80fd\u5426\u5e2e\u52a9LLM\u4e3a\u9ad8\u7ef4\u4f18\u5316\u751f\u6210\u6709\u6548\u7684\u9884\u70ed\u542f\u52a8\uff0c\u53d1\u73b0\u7ed3\u6784\u5316\u77e5\u8bc6\u96c6\u6210\u80fd\u663e\u8457\u63d0\u5347LLM\u5728\u9ad8\u7ef4\u4f18\u5316\u4e2d\u7684\u8868\u73b0\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4f4e\u7ef4\u8f6f\u4ef6\u5de5\u7a0b\u4f18\u5316\u4efb\u52a1\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u9ad8\u7ef4\u95ee\u9898\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0c\u800c\u8d1d\u53f6\u65af\u65b9\u6cd5\u5728\u9ad8\u7ef4\u4f18\u5316\u4e2d\u5360\u4e3b\u5bfc\u5730\u4f4d\u3002\u9700\u8981\u7406\u89e3\u5982\u4f55\u901a\u8fc7\u7cfb\u7edf\u96c6\u6210\u9886\u57df\u77e5\u8bc6\uff08\u65e0\u8bba\u662f\u6765\u81ea\u4eba\u7c7b\u8fd8\u662f\u81ea\u52a8\u63a8\u7406\uff09\u6765\u5f25\u5408\u8fd9\u4e00\u5dee\u8ddd\u3002", "method": "\u5728\u6309\u7ef4\u5ea6\u5206\u5c42\u7684MOOT\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\u56db\u79cd\u65b9\u6cd5\uff1a1\uff09\u4eba\u673a\u4ea4\u4e92\u9886\u57df\u77e5\u8bc6\u63d0\u793a\uff08H-DKP\uff09\uff0c\u5229\u7528\u5f02\u6b65\u4e13\u5bb6\u53cd\u9988\u5faa\u73af\uff1b2\uff09\u81ea\u9002\u5e94\u591a\u9636\u6bb5\u63d0\u793a\uff08AMP\uff09\uff0c\u5b9e\u73b0\u987a\u5e8f\u7ea6\u675f\u8bc6\u522b\u548c\u9a8c\u8bc1\uff1b3\uff09\u7ef4\u5ea6\u611f\u77e5\u6e10\u8fdb\u7ec6\u5316\uff08DAPR\uff09\uff0c\u5728\u9010\u6b65\u6269\u5c55\u7684\u7279\u5f81\u5b50\u7a7a\u95f4\u4e2d\u8fdb\u884c\u4f18\u5316\uff1b4\uff09\u6df7\u5408\u77e5\u8bc6\u6a21\u578b\u65b9\u6cd5\uff08HKMA\uff09\uff0c\u5c06\u7edf\u8ba1\u4fa6\u5bdf\uff08TPE\uff09\u4e0eRAG\u589e\u5f3a\u63d0\u793a\u76f8\u7ed3\u5408\u3002\u901a\u8fc7\u5207\u6bd4\u96ea\u592b\u8ddd\u79bb\u5230\u6700\u4f18\u89e3\u6765\u91cf\u5316\u6027\u80fd\uff0c\u5e76\u4f7f\u7528Scott-Knott\u805a\u7c7b\u4e0eLLM\u751f\u6210\u9884\u70ed\u542f\u52a8\u7684\u57fa\u7ebf\u8fdb\u884c\u6392\u540d\u6bd4\u8f83\u3002", "result": "\u8bba\u6587\u901a\u8fc7\u7cfb\u7edf\u8bc4\u4f30\u53d1\u73b0\uff0c\u7ed3\u6784\u5316\u77e5\u8bc6\u96c6\u6210\u80fd\u591f\u4f7fLLM\u4e3a\u9ad8\u7ef4\u4f18\u5316\u751f\u6210\u6709\u6548\u7684\u9884\u70ed\u542f\u52a8\u3002\u56db\u79cd\u67b6\u6784\u5728\u4e0d\u540c\u7ef4\u5ea6\u95ee\u9898\u4e0a\u8868\u73b0\u51fa\u4e0d\u540c\u7684\u6027\u80fd\u4f18\u52bf\uff0c\u8868\u660e\u9886\u57df\u77e5\u8bc6\u7684\u7cfb\u7edf\u96c6\u6210\u786e\u5b9e\u80fd\u591f\u5e2e\u52a9LLM\u5728\u9ad8\u7ef4\u4f18\u5316\u4efb\u52a1\u4e2d\u53d6\u5f97\u66f4\u597d\u7684\u8868\u73b0\u3002", "conclusion": "\u901a\u8fc7\u6bd4\u8f83\u4eba\u7c7b\u4e0e\u4eba\u5de5\u667a\u80fd\u751f\u6210\u9886\u57df\u77e5\u8bc6\u7684\u7b56\u7565\uff0c\u7814\u7a76\u8868\u660e\u7ed3\u6784\u5316\u77e5\u8bc6\u96c6\u6210\u80fd\u591f\u663e\u8457\u63d0\u5347LLM\u5728\u9ad8\u7ef4\u4f18\u5316\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u4e3aLLM\u5728\u9ad8\u7ef4\u8f6f\u4ef6\u5de5\u7a0b\u4f18\u5316\u4e2d\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6cd5\u3002"}}
{"id": "2602.02987", "categories": ["cs.DC", "math.OC"], "pdf": "https://arxiv.org/pdf/2602.02987", "abs": "https://arxiv.org/abs/2602.02987", "authors": ["Ruihan Lin", "Zezhen Ding", "Zean Han", "Jiheng Zhang"], "title": "Large-Scale LLM Inference with Heterogeneous Workloads: Prefill-Decode Contention and Asymptotically Optimal Control", "comment": null, "summary": "Large Language Models (LLMs) are rapidly becoming critical infrastructure for enterprise applications, driving unprecedented demand for GPU-based inference services. A key operational challenge arises from the two-phase nature of LLM inference: a compute-intensive \\emph{prefill} phase that processes user input, followed by a memory-bound \\emph{decode} phase that generates output tokens. When these phases share GPU resources, prefill tasks throttle the processing speed of concurrent decodes, creating state-dependent contention. This contention is further complicated by workload heterogeneity, as different applications exhibit vastly different input and output lengths. We develop a stochastic control framework for scheduling heterogeneous LLM workloads across large GPU clusters. We formulate LLM inference as a multiclass many-server queueing network with state-dependent service rates, grounded in empirical iteration-time measurements. We analyze the fluid approximation of this system and solve steady-state linear programs that characterize optimal resource allocation. We design gate-and-route policies that regulate prefill admission and decode routing, and prove that they are asymptotically optimal in the many-GPU limit under both bundled and separate token-pricing schemes. We further extend the framework to incorporate Service Level Indicators (SLIs) such as latency and fairness, providing a general approach to constrained scheduling. Numerical experiments calibrated to empirical iteration-time data demonstrate that our policies outperform standard serving heuristics.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u968f\u673a\u63a7\u5236\u7684LLM\u63a8\u7406\u8c03\u5ea6\u6846\u67b6\uff0c\u89e3\u51b3GPU\u96c6\u7fa4\u4e2d\u9884\u586b\u5145\u548c\u89e3\u7801\u9636\u6bb5\u8d44\u6e90\u4e89\u7528\u95ee\u9898\uff0c\u901a\u8fc7\u95e8\u63a7\u8def\u7531\u7b56\u7565\u5b9e\u73b0\u6700\u4f18\u8d44\u6e90\u5206\u914d\u3002", "motivation": "LLM\u5728\u4f01\u4e1a\u5e94\u7528\u4e2d\u9700\u6c42\u6fc0\u589e\uff0c\u4f46\u63a8\u7406\u8fc7\u7a0b\u5b58\u5728\u4e24\u9636\u6bb5\u7279\u6027\uff1a\u8ba1\u7b97\u5bc6\u96c6\u7684\u9884\u586b\u5145\u9636\u6bb5\u548c\u5185\u5b58\u53d7\u9650\u7684\u89e3\u7801\u9636\u6bb5\u3002\u5f53\u8fd9\u4e24\u4e2a\u9636\u6bb5\u5171\u4eabGPU\u8d44\u6e90\u65f6\uff0c\u9884\u586b\u5145\u4efb\u52a1\u4f1a\u62d6\u6162\u5e76\u53d1\u89e3\u7801\u901f\u5ea6\uff0c\u5f62\u6210\u72b6\u6001\u4f9d\u8d56\u7684\u8d44\u6e90\u4e89\u7528\u3002\u540c\u65f6\uff0c\u4e0d\u540c\u5e94\u7528\u7684\u8f93\u5165\u8f93\u51fa\u957f\u5ea6\u5dee\u5f02\u5f88\u5927\uff0c\u589e\u52a0\u4e86\u8c03\u5ea6\u590d\u6742\u6027\u3002", "method": "\u5c06LLM\u63a8\u7406\u5efa\u6a21\u4e3a\u5177\u6709\u72b6\u6001\u4f9d\u8d56\u670d\u52a1\u901f\u7387\u7684\u591a\u7c7b\u591a\u670d\u52a1\u5668\u6392\u961f\u7f51\u7edc\uff0c\u57fa\u4e8e\u7ecf\u9a8c\u8fed\u4ee3\u65f6\u95f4\u6d4b\u91cf\u5efa\u7acb\u6a21\u578b\u3002\u5206\u6790\u7cfb\u7edf\u7684\u6d41\u4f53\u8fd1\u4f3c\uff0c\u6c42\u89e3\u7a33\u6001\u7ebf\u6027\u89c4\u5212\u4ee5\u8868\u5f81\u6700\u4f18\u8d44\u6e90\u5206\u914d\u3002\u8bbe\u8ba1\u95e8\u63a7\u8def\u7531\u7b56\u7565\u6765\u8c03\u8282\u9884\u586b\u5145\u51c6\u5165\u548c\u89e3\u7801\u8def\u7531\uff0c\u8bc1\u660e\u5728\u5927\u91cfGPU\u9650\u5236\u4e0b\u5bf9\u6346\u7ed1\u548c\u5206\u79bb\u4ee4\u724c\u5b9a\u4ef7\u65b9\u6848\u90fd\u662f\u6e10\u8fd1\u6700\u4f18\u7684\u3002", "result": "\u6570\u503c\u5b9e\u9a8c\u4f7f\u7528\u7ecf\u9a8c\u8fed\u4ee3\u65f6\u95f4\u6570\u636e\u8fdb\u884c\u6821\u51c6\uff0c\u8868\u660e\u6240\u63d0\u51fa\u7684\u7b56\u7565\u4f18\u4e8e\u6807\u51c6\u670d\u52a1\u542f\u53d1\u5f0f\u65b9\u6cd5\u3002\u6846\u67b6\u8fd8\u53ef\u6269\u5c55\u4ee5\u7eb3\u5165\u670d\u52a1\u7ea7\u522b\u6307\u6807\uff08\u5982\u5ef6\u8fdf\u548c\u516c\u5e73\u6027\uff09\uff0c\u63d0\u4f9b\u7ea6\u675f\u8c03\u5ea6\u7684\u901a\u7528\u65b9\u6cd5\u3002", "conclusion": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u968f\u673a\u63a7\u5236\u6846\u67b6\u6765\u8c03\u5ea6\u5f02\u6784LLM\u5de5\u4f5c\u8d1f\u8f7d\uff0c\u901a\u8fc7\u7406\u8bba\u5206\u6790\u548c\u5b9e\u8bc1\u9a8c\u8bc1\uff0c\u8bc1\u660e\u4e86\u95e8\u63a7\u8def\u7531\u7b56\u7565\u5728\u5927\u578bGPU\u96c6\u7fa4\u4e2d\u7684\u6e10\u8fd1\u6700\u4f18\u6027\uff0c\u4e3a\u89e3\u51b3LLM\u63a8\u7406\u4e2d\u7684\u8d44\u6e90\u4e89\u7528\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6848\u3002"}}
{"id": "2602.03069", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2602.03069", "abs": "https://arxiv.org/abs/2602.03069", "authors": ["Yue Wu", "Tianhao Su", "Shunbo Hu", "Deng Pan"], "title": "Skill-Based Autonomous Agents for Material Creep Database Construction", "comment": null, "summary": "The advancement of data-driven materials science is currently constrained by a fundamental bottleneck: the vast majority of historical experimental data remains locked within the unstructured text and rasterized figures of legacy scientific literature. Manual curation of this knowledge is prohibitively labor-intensive and prone to human error. To address this challenge, we introduce an autonomous, agent-based framework powered by Large Language Models (LLMs) designed to excavate high-fidelity datasets from scientific PDFs without human intervention. By deploying a modular \"skill-based\" architecture, the agent orchestrates complex cognitive tasks - including semantic filtering, multi-modal information extraction, and physics-informed validation. We demonstrate the efficacy of this framework by constructing a physically self-consistent database for material creep mechanics, a domain characterized by complex graphical trajectories and heterogeneous constitutive models. Applying the pipeline to 243 publications, the agent achieved a verified extraction success rate exceeding 90% for graphical data digitization. Crucially, we introduce a cross-modal verification protocol, demonstrating that the agent can autonomously align visually extracted data points with textually extracted constitutive parameters ($R^2 > 0.99$), ensuring the physical self-consistency of the database. This work not only provides a critical resource for investigating time-dependent deformation across diverse material systems but also establishes a scalable paradigm for autonomous knowledge acquisition, paving the way for the next generation of self-driving laboratories.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eLLM\u7684\u81ea\u4e3b\u4ee3\u7406\u6846\u67b6\uff0c\u4ece\u79d1\u5b66PDF\u4e2d\u81ea\u52a8\u63d0\u53d6\u9ad8\u8d28\u91cf\u6750\u6599\u6570\u636e\uff0c\u65e0\u9700\u4eba\u5de5\u5e72\u9884\uff0c\u6210\u529f\u6784\u5efa\u6750\u6599\u8815\u53d8\u529b\u5b66\u6570\u636e\u5e93", "motivation": "\u6570\u636e\u9a71\u52a8\u7684\u6750\u6599\u79d1\u5b66\u53d1\u5c55\u53d7\u9650\u4e8e\u5386\u53f2\u5b9e\u9a8c\u6570\u636e\u5927\u591a\u88ab\u9501\u5b9a\u5728\u975e\u7ed3\u6784\u5316\u7684\u79d1\u5b66\u6587\u732e\u4e2d\uff0c\u4eba\u5de5\u6574\u7406\u6210\u672c\u9ad8\u4e14\u6613\u51fa\u9519", "method": "\u91c7\u7528\u57fa\u4e8e\u6280\u80fd\u7684\u6a21\u5757\u5316\u67b6\u6784\uff0c\u90e8\u7f72\u81ea\u4e3b\u4ee3\u7406\u6846\u67b6\uff0c\u6267\u884c\u8bed\u4e49\u8fc7\u6ee4\u3001\u591a\u6a21\u6001\u4fe1\u606f\u63d0\u53d6\u548c\u7269\u7406\u9a8c\u8bc1\u7b49\u590d\u6742\u8ba4\u77e5\u4efb\u52a1", "result": "\u5bf9243\u7bc7\u6587\u732e\u5e94\u7528\u8be5\u6846\u67b6\uff0c\u56fe\u5f62\u6570\u636e\u6570\u5b57\u5316\u9a8c\u8bc1\u63d0\u53d6\u6210\u529f\u7387\u8d85\u8fc790%\uff0c\u8de8\u6a21\u6001\u9a8c\u8bc1\u663e\u793a\u89c6\u89c9\u63d0\u53d6\u6570\u636e\u70b9\u4e0e\u6587\u672c\u63d0\u53d6\u672c\u6784\u53c2\u6570\u9ad8\u5ea6\u4e00\u81f4\uff08R\u00b2>0.99\uff09", "conclusion": "\u8be5\u5de5\u4f5c\u4e0d\u4ec5\u4e3a\u7814\u7a76\u4e0d\u540c\u6750\u6599\u7cfb\u7edf\u7684\u65f6\u95f4\u4f9d\u8d56\u6027\u53d8\u5f62\u63d0\u4f9b\u4e86\u5173\u952e\u8d44\u6e90\uff0c\u8fd8\u5efa\u7acb\u4e86\u53ef\u6269\u5c55\u7684\u81ea\u4e3b\u77e5\u8bc6\u83b7\u53d6\u8303\u5f0f\uff0c\u4e3a\u4e0b\u4e00\u4ee3\u81ea\u4e3b\u5b9e\u9a8c\u5ba4\u94fa\u5e73\u9053\u8def"}}
{"id": "2602.02869", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.02869", "abs": "https://arxiv.org/abs/2602.02869", "authors": ["Wei Wang", "Anuradha Madugalla", "John Grundy", "Paul McIntosh", "Charmine E. J. H\u00e4rtel"], "title": "A Proxy Stakeholder Approach to Requirements Engineering for Inclusive Navigation", "comment": null, "summary": "Wayfinding, or the ability to navigate one's surroundings, is crucial for independent living and requires a complex combination of cognitive abilities, environmental awareness, and technology to manage this successfully. Individuals with cognitive impairment (IwCI) often face significant challenges in learning and navigating their environment. Despite its importance, mainstream navigation technologies are rarely designed with their diverse needs in mind. This study reframes the search for places as a socially distributed task and emphasizes the role of proxy stakeholders, who act on behalf or in coordination with IwCI during navigation. Using a qualitatively led mixed-methods approach, which includes an international survey and a three-stage interview study, we examine the real-world strategies that proxy stakeholders employ to support daily navigation. The findings are synthesized into a set of empirically grounded design recommendations that emphasize customisability, collaborative use, and support for routine-based navigation. Our findings highlight key challenges and adaptive practices, which are synthesized into design recommendations that prioritize customisability, routine-based navigation, and multi-user coordination. By introducing the proxy stakeholder concept into the software engineering literature, we propose a more inclusive approach to requirements elicitation and offer practical guidance for designing navigation technologies that better reflect the complex realities of cognitive support.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5c06\u5bfc\u822a\u91cd\u65b0\u5b9a\u4e49\u4e3a\u793e\u4f1a\u5206\u5e03\u5f0f\u4efb\u52a1\uff0c\u5f3a\u8c03\u4ee3\u7406\u5229\u76ca\u76f8\u5173\u8005\u5728\u8ba4\u77e5\u969c\u788d\u8005\u5bfc\u822a\u4e2d\u7684\u4f5c\u7528\uff0c\u63d0\u51fa\u4ee5\u5b9a\u5236\u5316\u3001\u534f\u4f5c\u548c\u57fa\u4e8e\u65e5\u5e38\u5bfc\u822a\u4e3a\u6838\u5fc3\u7684\u8bbe\u8ba1\u5efa\u8bae\u3002", "motivation": "\u8ba4\u77e5\u969c\u788d\u8005\u5728\u5bfc\u822a\u65b9\u9762\u9762\u4e34\u91cd\u5927\u6311\u6218\uff0c\u800c\u4e3b\u6d41\u5bfc\u822a\u6280\u672f\u5f88\u5c11\u8003\u8651\u4ed6\u4eec\u7684\u591a\u6837\u5316\u9700\u6c42\u3002\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u5173\u6ce8\u4ee3\u7406\u5229\u76ca\u76f8\u5173\u8005\uff08\u4ee3\u8868\u6216\u534f\u8c03\u8ba4\u77e5\u969c\u788d\u8005\u8fdb\u884c\u5bfc\u822a\u7684\u4eba\uff09\u6765\u5f00\u53d1\u66f4\u5305\u5bb9\u7684\u5bfc\u822a\u6280\u672f\u3002", "method": "\u91c7\u7528\u8d28\u6027\u4e3b\u5bfc\u7684\u6df7\u5408\u65b9\u6cd5\uff0c\u5305\u62ec\u56fd\u9645\u8c03\u67e5\u548c\u4e09\u9636\u6bb5\u8bbf\u8c08\u7814\u7a76\uff0c\u8003\u5bdf\u4ee3\u7406\u5229\u76ca\u76f8\u5173\u8005\u5728\u65e5\u5e38\u5bfc\u822a\u4e2d\u4f7f\u7528\u7684\u73b0\u5b9e\u7b56\u7565\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u4ee3\u7406\u5229\u76ca\u76f8\u5173\u8005\u91c7\u7528\u591a\u79cd\u7b56\u7565\u652f\u6301\u5bfc\u822a\uff0c\u8fd9\u4e9b\u53d1\u73b0\u88ab\u7efc\u5408\u6210\u4e00\u5957\u57fa\u4e8e\u7ecf\u9a8c\u7684\u8bbe\u8ba1\u5efa\u8bae\uff0c\u5f3a\u8c03\u5b9a\u5236\u5316\u3001\u534f\u4f5c\u4f7f\u7528\u548c\u57fa\u4e8e\u65e5\u5e38\u7684\u5bfc\u822a\u652f\u6301\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165\u4ee3\u7406\u5229\u76ca\u76f8\u5173\u8005\u6982\u5ff5\u5230\u8f6f\u4ef6\u5de5\u7a0b\u6587\u732e\uff0c\u63d0\u51fa\u4e86\u66f4\u5305\u5bb9\u7684\u9700\u6c42\u83b7\u53d6\u65b9\u6cd5\uff0c\u5e76\u4e3a\u8bbe\u8ba1\u80fd\u66f4\u597d\u53cd\u6620\u8ba4\u77e5\u652f\u6301\u590d\u6742\u73b0\u5b9e\u7684\u5bfc\u822a\u6280\u672f\u63d0\u4f9b\u4e86\u5b9e\u7528\u6307\u5bfc\u3002"}}
{"id": "2602.03081", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2602.03081", "abs": "https://arxiv.org/abs/2602.03081", "authors": ["Mohammadali Khodabandehlou", "Jared Coleman", "Niranjan Suri", "Bhaskar Krishnamachari"], "title": "Studying the Effect of Schedule Preemption on Dynamic Task Graph Scheduling", "comment": null, "summary": "Dynamic scheduling of task graphs is often addressed without revisiting prior task allocations, with a primary focus on minimizing makespan. We study controlled schedule preemption, introducing the Last-K Preemption model, which selectively reschedules recent task graphs while preserving earlier allocations. Using synthetic, RIoTBench, WFCommons, and adversarial workloads, we compare preemptive, non-preemptive, and partial-preemptive strategies across makespan, fairness, utilization, and runtime. Results show moderate preemption can match most makespan and utilization gains of full preemption while maintaining fairness and low overhead.", "AI": {"tldr": "\u7814\u7a76\u52a8\u6001\u4efb\u52a1\u56fe\u8c03\u5ea6\u4e2d\u7684\u53ef\u63a7\u62a2\u5360\u6a21\u578b\uff08Last-K Preemption\uff09\uff0c\u901a\u8fc7\u9009\u62e9\u6027\u91cd\u8c03\u5ea6\u8fd1\u671f\u4efb\u52a1\u56fe\u6765\u5e73\u8861\u6027\u80fd\u6307\u6807\uff0c\u5b9e\u9a8c\u8868\u660e\u9002\u5ea6\u62a2\u5360\u80fd\u5728\u4fdd\u6301\u516c\u5e73\u6027\u548c\u4f4e\u5f00\u9500\u7684\u540c\u65f6\u83b7\u5f97\u5927\u90e8\u5206\u6027\u80fd\u6536\u76ca\u3002", "motivation": "\u4f20\u7edf\u52a8\u6001\u4efb\u52a1\u56fe\u8c03\u5ea6\u901a\u5e38\u4e0d\u91cd\u65b0\u5ba1\u89c6\u5df2\u5206\u914d\u4efb\u52a1\uff0c\u4e3b\u8981\u5173\u6ce8\u6700\u5c0f\u5316\u5b8c\u6210\u65f6\u95f4\u3002\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u53ef\u63a7\u7684\u8c03\u5ea6\u62a2\u5360\u673a\u5236\uff0c\u5728\u4fdd\u6301\u65e9\u671f\u5206\u914d\u7684\u540c\u65f6\u9009\u62e9\u6027\u91cd\u8c03\u5ea6\u8fd1\u671f\u4efb\u52a1\u56fe\u3002", "method": "\u63d0\u51faLast-K\u62a2\u5360\u6a21\u578b\uff0c\u9009\u62e9\u6027\u91cd\u8c03\u5ea6\u6700\u8fd1K\u4e2a\u4efb\u52a1\u56fe\uff0c\u540c\u65f6\u4fdd\u7559\u66f4\u65e9\u7684\u4efb\u52a1\u5206\u914d\u3002\u4f7f\u7528\u5408\u6210\u6570\u636e\u96c6\u3001RIoTBench\u3001WFCommons\u548c\u5bf9\u6297\u6027\u5de5\u4f5c\u8d1f\u8f7d\uff0c\u6bd4\u8f83\u62a2\u5360\u5f0f\u3001\u975e\u62a2\u5360\u5f0f\u548c\u90e8\u5206\u62a2\u5360\u5f0f\u7b56\u7565\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u9002\u5ea6\u62a2\u5360\uff08\u90e8\u5206\u62a2\u5360\uff09\u80fd\u591f\u5339\u914d\u5b8c\u5168\u62a2\u5360\u5728\u5b8c\u6210\u65f6\u95f4\u548c\u8d44\u6e90\u5229\u7528\u7387\u65b9\u9762\u7684\u5927\u90e8\u5206\u6536\u76ca\uff0c\u540c\u65f6\u4fdd\u6301\u516c\u5e73\u6027\u548c\u8f83\u4f4e\u7684\u5f00\u9500\u3002", "conclusion": "\u53ef\u63a7\u7684\u8c03\u5ea6\u62a2\u5360\u673a\u5236\uff08\u5982Last-K\u6a21\u578b\uff09\u80fd\u591f\u5728\u6027\u80fd\u6307\u6807\uff08\u5b8c\u6210\u65f6\u95f4\u3001\u5229\u7528\u7387\uff09\u548c\u7cfb\u7edf\u8d28\u91cf\uff08\u516c\u5e73\u6027\u3001\u5f00\u9500\uff09\u4e4b\u95f4\u53d6\u5f97\u826f\u597d\u5e73\u8861\uff0c\u4e3a\u52a8\u6001\u4efb\u52a1\u56fe\u8c03\u5ea6\u63d0\u4f9b\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.03189", "categories": ["cs.DB", "cs.DC"], "pdf": "https://arxiv.org/pdf/2602.03189", "abs": "https://arxiv.org/abs/2602.03189", "authors": ["Yong Fang", "Yuxing Han", "Meng Wang", "Yifan Zhang", "Yue Ma", "Chi Zhang"], "title": "StreamShield: A Production-Proven Resiliency Solution for Apache Flink at ByteDance", "comment": null, "summary": "Distributed Stream Processing Systems (DSPSs) form the backbone of real-time processing and analytics at ByteDance, where Apache Flink powers one of the largest production clusters worldwide. Ensuring resiliency, the ability to withstand and rapidly recover from failures, together with operational stability, which provides consistent and predictable performance under normal conditions, is essential for meeting strict Service Level Objectives (SLOs). However, achieving resiliency and stability in large-scale production environments remains challenging due to the cluster scale, business diversity, and significant operational overhead. In this work, we present StreamShield, a production-proven resiliency solution deployed in ByteDance's Flink clusters. Designed along complementary perspectives of the engine and cluster, StreamShield introduces key techniques to enhance resiliency, covering runtime optimization, fine-grained fault-tolerance, hybrid replication strategy, and high availability under external systems. Furthermore, StreamShield proposes a robust testing and deployment pipeline that ensures reliability and robustness in production releases. Extensive evaluations on a production cluster demonstrate the efficiency and effectiveness of techniques proposed by StreamShield.", "AI": {"tldr": "StreamShield\u662f\u5b57\u8282\u8df3\u52a8\u4e3aApache Flink\u96c6\u7fa4\u8bbe\u8ba1\u7684\u751f\u4ea7\u7ea7\u5f39\u6027\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u5f15\u64ce\u548c\u96c6\u7fa4\u53cc\u89c6\u89d2\u4f18\u5316\uff0c\u63d0\u5347\u5927\u89c4\u6a21\u5206\u5e03\u5f0f\u6d41\u5904\u7406\u7cfb\u7edf\u7684\u6545\u969c\u6062\u590d\u80fd\u529b\u548c\u8fd0\u884c\u7a33\u5b9a\u6027\u3002", "motivation": "\u5728\u5b57\u8282\u8df3\u52a8\u8fd9\u6837\u7684\u5927\u89c4\u6a21\u751f\u4ea7\u73af\u5883\u4e2d\uff0c\u5206\u5e03\u5f0f\u6d41\u5904\u7406\u7cfb\u7edf\u9700\u8981\u6ee1\u8db3\u4e25\u683c\u7684SLO\u8981\u6c42\uff0c\u4f46\u96c6\u7fa4\u89c4\u6a21\u5927\u3001\u4e1a\u52a1\u591a\u6837\u6027\u548c\u8fd0\u7ef4\u5f00\u9500\u4f7f\u5f97\u5b9e\u73b0\u5f39\u6027\u548c\u7a33\u5b9a\u6027\u9762\u4e34\u6311\u6218\u3002", "method": "StreamShield\u4ece\u5f15\u64ce\u548c\u96c6\u7fa4\u4e24\u4e2a\u4e92\u8865\u89c6\u89d2\u8bbe\u8ba1\uff0c\u5305\u542b\u8fd0\u884c\u65f6\u4f18\u5316\u3001\u7ec6\u7c92\u5ea6\u5bb9\u9519\u3001\u6df7\u5408\u590d\u5236\u7b56\u7565\u548c\u5916\u90e8\u7cfb\u7edf\u9ad8\u53ef\u7528\u6027\u7b49\u5173\u952e\u6280\u672f\uff0c\u5e76\u5efa\u7acb\u4e86\u7a33\u5065\u7684\u6d4b\u8bd5\u548c\u90e8\u7f72\u6d41\u6c34\u7ebf\u3002", "result": "\u5728\u751f\u4ea7\u96c6\u7fa4\u4e0a\u7684\u5e7f\u6cdb\u8bc4\u4f30\u8868\u660e\uff0cStreamShield\u63d0\u51fa\u7684\u6280\u672f\u65b9\u6848\u5177\u6709\u9ad8\u6548\u6027\u548c\u6709\u6548\u6027\u3002", "conclusion": "StreamShield\u662f\u4e00\u4e2a\u7ecf\u8fc7\u751f\u4ea7\u9a8c\u8bc1\u7684\u5f39\u6027\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u663e\u8457\u63d0\u5347\u5927\u89c4\u6a21Flink\u96c6\u7fa4\u7684\u6545\u969c\u6062\u590d\u80fd\u529b\u548c\u8fd0\u884c\u7a33\u5b9a\u6027\u3002"}}
{"id": "2602.02881", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.02881", "abs": "https://arxiv.org/abs/2602.02881", "authors": ["Arshad Beg", "Diarmuid O'Donoghue", "Rosemary Monahan"], "title": "Learning-Infused Formal Reasoning: From Contract Synthesis to Artifact Reuse and Formal Semantics", "comment": "18 pages. Accepted at VERIFAI-2026: The Interplay between Artificial Intelligence and Software Verification LASER center, Villebrumier, France, March 8-11, 2026", "summary": "This vision paper articulates a long-term research agenda for formal methods at the intersection with artificial intelligence, outlining multiple conceptual and technical dimensions and reporting on our ongoing work toward realising this agenda. It advances a forward-looking perspective on the next generation of formal methods based on the integration of automated contract synthesis, semantic artifact reuse, and refinement-based theory. We argue that future verification systems must move beyond isolated correctness proofs toward a cumulative, knowledge-driven paradigm in which specifications, contracts, and proofs are continuously synthesised and transferred across systems. To support this shift, we outline a hybrid framework combining large language models with graph-based representations to enable scalable semantic matching and principled reuse of verification artifacts. Learning-based components provide semantic guidance across heterogeneous notations and abstraction levels, while symbolic matching ensures formal soundness. Grounded in compositional reasoning, this vision points toward verification ecosystems that evolve systematically, leveraging past verification efforts to accelerate future assurance.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u957f\u671f\u7814\u7a76\u8bae\u7a0b\uff0c\u5c06\u5f62\u5f0f\u5316\u65b9\u6cd5\u4e0e\u4eba\u5de5\u667a\u80fd\u7ed3\u5408\uff0c\u901a\u8fc7\u81ea\u52a8\u5316\u5408\u7ea6\u5408\u6210\u3001\u8bed\u4e49\u6784\u4ef6\u91cd\u7528\u548c\u7cbe\u5316\u7406\u8bba\uff0c\u6784\u5efa\u4e0b\u4e00\u4ee3\u77e5\u8bc6\u9a71\u52a8\u7684\u9a8c\u8bc1\u751f\u6001\u7cfb\u7edf\u3002", "motivation": "\u5f53\u524d\u9a8c\u8bc1\u7cfb\u7edf\u5c40\u9650\u4e8e\u5b64\u7acb\u7684\u6b63\u786e\u6027\u8bc1\u660e\uff0c\u9700\u8981\u8f6c\u5411\u7d2f\u79ef\u6027\u3001\u77e5\u8bc6\u9a71\u52a8\u7684\u8303\u5f0f\uff0c\u5b9e\u73b0\u8de8\u7cfb\u7edf\u7684\u89c4\u683c\u3001\u5408\u7ea6\u548c\u8bc1\u660e\u7684\u6301\u7eed\u5408\u6210\u4e0e\u8f6c\u79fb\u3002", "method": "\u63d0\u51fa\u6df7\u5408\u6846\u67b6\uff0c\u7ed3\u5408\u5927\u8bed\u8a00\u6a21\u578b\u548c\u56fe\u8868\u793a\uff0c\u5b9e\u73b0\u53ef\u6269\u5c55\u7684\u8bed\u4e49\u5339\u914d\u548c\u9a8c\u8bc1\u6784\u4ef6\u7684\u539f\u5219\u6027\u91cd\u7528\u3002\u5b66\u4e60\u7ec4\u4ef6\u63d0\u4f9b\u8de8\u5f02\u6784\u8868\u793a\u548c\u62bd\u8c61\u5c42\u6b21\u7684\u8bed\u4e49\u6307\u5bfc\uff0c\u7b26\u53f7\u5339\u914d\u786e\u4fdd\u5f62\u5f0f\u6b63\u786e\u6027\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u524d\u77bb\u6027\u613f\u666f\uff0c\u57fa\u4e8e\u7ec4\u5408\u63a8\u7406\uff0c\u6307\u5411\u80fd\u591f\u7cfb\u7edf\u6f14\u5316\u3001\u5229\u7528\u8fc7\u5f80\u9a8c\u8bc1\u6210\u679c\u52a0\u901f\u672a\u6765\u4fdd\u8bc1\u7684\u9a8c\u8bc1\u751f\u6001\u7cfb\u7edf\u3002", "conclusion": "\u5f62\u5f0f\u5316\u65b9\u6cd5\u4e0e\u4eba\u5de5\u667a\u80fd\u7684\u4ea4\u53c9\u9886\u57df\u5177\u6709\u5de8\u5927\u6f5c\u529b\uff0c\u901a\u8fc7\u77e5\u8bc6\u9a71\u52a8\u7684\u9a8c\u8bc1\u8303\u5f0f\u8f6c\u53d8\uff0c\u53ef\u4ee5\u6784\u5efa\u66f4\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u7684\u4e0b\u4e00\u4ee3\u9a8c\u8bc1\u7cfb\u7edf\u3002"}}
{"id": "2602.03246", "categories": ["cs.DC", "cs.NI", "eess.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2602.03246", "abs": "https://arxiv.org/abs/2602.03246", "authors": ["Tamoghna Sarkar", "Bhaskar Krishnamachari"], "title": "Joint Network-and-Server Congestion in Multi-Source Traffic Allocation: A Convex Formulation and Price-Based Decentralization", "comment": "10pages, 7 figures, submitted a version conference", "summary": "This paper studies an important rate allocation problem that arises in many networked and distributed systems: steady-state traffic rate allocation from multiple sources to multiple service nodes when both (i) the access-path delay on each source-node route is rate-dependent (capacity-constrained) and convex, and (ii) each service node (also capacity-constrained) experiences a load-dependent queueing delay driven by aggregate load from all sources. We show that the resulting flow-weighted end-to-end delay minimization is a convex program, yielding a global system-optimal solution characterized by KKT conditions that equalize total marginal costs (a path marginal access term plus a node congestion price) across all utilized routes. This condition admits a Wardrop-type interpretation: for each source, all utilized options equalize total marginal cost, while any option with strictly larger total marginal cost receives no flow. Building on this structure, we develop a lightweight distributed pricing-based algorithm in which each service node locally computes and broadcasts a scalar congestion price from its observed aggregate load, while each source updates its traffic split by solving a small separable convex allocation problem under the advertised prices. Numerical illustrations demonstrate convergence of the distributed iteration to the centralized optimum and highlight the trade-offs induced by jointly modeling access and service congestion.", "AI": {"tldr": "\u7814\u7a76\u591a\u6e90\u591a\u670d\u52a1\u8282\u70b9\u7684\u7a33\u6001\u6d41\u91cf\u5206\u914d\u95ee\u9898\uff0c\u8003\u8651\u8def\u5f84\u4f9d\u8d56\u7684\u63a5\u5165\u5ef6\u8fdf\u548c\u8282\u70b9\u8d1f\u8f7d\u4f9d\u8d56\u7684\u6392\u961f\u5ef6\u8fdf\uff0c\u63d0\u51fa\u5206\u5e03\u5f0f\u5b9a\u4ef7\u7b97\u6cd5\u5b9e\u73b0\u7cfb\u7edf\u6700\u4f18\u7684\u7aef\u5230\u7aef\u5ef6\u8fdf\u6700\u5c0f\u5316\u3002", "motivation": "\u5728\u5206\u5e03\u5f0f\u7f51\u7edc\u7cfb\u7edf\u4e2d\uff0c\u5f53\u591a\u4e2a\u6e90\u8282\u70b9\u5411\u591a\u4e2a\u670d\u52a1\u8282\u70b9\u53d1\u9001\u6d41\u91cf\u65f6\uff0c\u5b58\u5728\u4e24\u4e2a\u5173\u952e\u5ef6\u8fdf\u56e0\u7d20\uff1a1) \u6bcf\u6761\u6e90-\u8282\u70b9\u8def\u5f84\u4e0a\u7684\u63a5\u5165\u5ef6\u8fdf\uff08\u4e0e\u901f\u7387\u76f8\u5173\u4e14\u51f8\uff09\uff0c2) \u6bcf\u4e2a\u670d\u52a1\u8282\u70b9\u7684\u6392\u961f\u5ef6\u8fdf\uff08\u4e0e\u805a\u5408\u8d1f\u8f7d\u76f8\u5173\uff09\u3002\u73b0\u6709\u7814\u7a76\u5f80\u5f80\u5355\u72ec\u5904\u7406\u8fd9\u4e24\u79cd\u5ef6\u8fdf\uff0c\u9700\u8981\u8054\u5408\u5efa\u6a21\u4ee5\u5b9e\u73b0\u7cfb\u7edf\u6700\u4f18\u7684\u6d41\u91cf\u5206\u914d\u3002", "method": "\u5c06\u7aef\u5230\u7aef\u5ef6\u8fdf\u6700\u5c0f\u5316\u95ee\u9898\u5efa\u6a21\u4e3a\u51f8\u4f18\u5316\u95ee\u9898\uff0c\u5229\u7528KKT\u6761\u4ef6\u63a8\u5bfc\u51fa\u6700\u4f18\u6761\u4ef6\uff1a\u6240\u6709\u4f7f\u7528\u8def\u5f84\u7684\u603b\u8fb9\u9645\u6210\u672c\uff08\u8def\u5f84\u8fb9\u9645\u63a5\u5165\u9879+\u8282\u70b9\u62e5\u585e\u4ef7\u683c\uff09\u76f8\u7b49\u3002\u57fa\u4e8e\u6b64\u7ed3\u6784\u8bbe\u8ba1\u5206\u5e03\u5f0f\u5b9a\u4ef7\u7b97\u6cd5\uff1a\u670d\u52a1\u8282\u70b9\u6839\u636e\u89c2\u6d4b\u8d1f\u8f7d\u8ba1\u7b97\u5e76\u5e7f\u64ad\u6807\u91cf\u62e5\u585e\u4ef7\u683c\uff0c\u6e90\u8282\u70b9\u6839\u636e\u4ef7\u683c\u66f4\u65b0\u6d41\u91cf\u5206\u914d\u3002", "result": "\u7406\u8bba\u8bc1\u660e\u8be5\u95ee\u9898\u4e3a\u51f8\u89c4\u5212\uff0c\u5b58\u5728\u5168\u5c40\u6700\u4f18\u89e3\uff0c\u53ef\u901a\u8fc7KKT\u6761\u4ef6\u63cf\u8ff0\u3002\u5206\u5e03\u5f0f\u7b97\u6cd5\u80fd\u6536\u655b\u5230\u96c6\u4e2d\u5f0f\u6700\u4f18\u89e3\uff0c\u6570\u503c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u7b97\u6cd5\u7684\u6536\u655b\u6027\u548c\u6027\u80fd\uff0c\u5c55\u793a\u4e86\u8054\u5408\u5efa\u6a21\u63a5\u5165\u548c\u670d\u52a1\u62e5\u585e\u5e26\u6765\u7684\u6743\u8861\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u591a\u6e90\u591a\u8282\u70b9\u7684\u7f51\u7edc\u6d41\u91cf\u5206\u914d\u63d0\u4f9b\u4e86\u7edf\u4e00\u7684\u51f8\u4f18\u5316\u6846\u67b6\uff0c\u63d0\u51fa\u7684\u5206\u5e03\u5f0f\u5b9a\u4ef7\u7b97\u6cd5\u8f7b\u91cf\u4e14\u6709\u6548\uff0c\u80fd\u591f\u5b9e\u73b0\u7cfb\u7edf\u6700\u4f18\u7684\u7aef\u5230\u7aef\u5ef6\u8fdf\u6700\u5c0f\u5316\uff0c\u4e3a\u5b9e\u9645\u7f51\u7edc\u7cfb\u7edf\u7684\u6d41\u91cf\u7ba1\u7406\u63d0\u4f9b\u4e86\u7406\u8bba\u4f9d\u636e\u548c\u5b9e\u7528\u65b9\u6cd5\u3002"}}
{"id": "2602.03278", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2602.03278", "abs": "https://arxiv.org/abs/2602.03278", "authors": ["Saige Rutherford", "Zeshawn Zahid", "Robert C. Welsh", "Andrea Avena-Koenigsberger", "Vincent Koppelmans", "Amanda F. Mejia"], "title": "A Pipeline for ADNI Resting-State Functional MRI Processing and Quality Control", "comment": null, "summary": "The Alzheimer's Disease Neuroimaging Initiative (ADNI) provides a comprehensive multimodal neuroimaging resource for studying aging and Alzheimer's disease (AD). Since its second wave, ADNI has increasingly collected resting-state functional MRI (rs-fMRI), a valuable resource for discovering brain connectivity changes predictive of cognitive decline and AD. A major barrier to its use is the considerable variability in acquisition protocols and data quality, compounded by missing imaging sessions and inconsistencies in how functional scans temporally align with clinical assessments. As a result, many studies only utilize a small subset of the total rs-fMRI data, limiting statistical power, reproducibility, and the ability to study longitudinal functional brain changes at scale. Here, we describe a pipeline for ADNI rs-fMRI data that encompasses the download of necessary imaging and clinical data, temporally aligning the clinical and imaging data, preprocessing, and quality control. We integrate data curation and preprocessing across all ADNI sites and scanner types using a combination of open-source software (Clinica, fMRIPrep, and MRIQC) and bespoke tools. Quality metrics and reports are generated for each subject and session to facilitate rigorous data screening. All scripts and configuration files are available to enable reproducibility. The pipeline, which currently supports ADNI-GO, ADNI-2, and ADNI-3 data releases, outputs high-quality rs-fMRI time series data adhering to the BIDS-derivatives specification. This protocol provides a transparent and scalable framework for curating and utilizing ADNI fMRI data, empowering large-scale functional biomarker discovery and integrative multimodal analyses in Alzheimer's disease research.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u7528\u4e8eADNI\u9759\u606f\u6001fMRI\u6570\u636e\u7684\u6807\u51c6\u5316\u5904\u7406\u6d41\u7a0b\uff0c\u89e3\u51b3\u6570\u636e\u83b7\u53d6\u534f\u8bae\u4e0d\u4e00\u81f4\u3001\u8d28\u91cf\u53c2\u5dee\u4e0d\u9f50\u548c\u5bf9\u9f50\u95ee\u9898\uff0c\u4fc3\u8fdb\u5927\u89c4\u6a21\u529f\u80fd\u8fde\u63a5\u7814\u7a76\u3002", "motivation": "ADNI\u6536\u96c6\u4e86\u5927\u91cf\u9759\u606f\u6001fMRI\u6570\u636e\uff0c\u4f46\u7531\u4e8e\u91c7\u96c6\u534f\u8bae\u4e0d\u4e00\u81f4\u3001\u6570\u636e\u8d28\u91cf\u53c2\u5dee\u4e0d\u9f50\u3001\u6210\u50cf\u4e0e\u4e34\u5e8a\u8bc4\u4f30\u65f6\u95f4\u4e0d\u5bf9\u9f50\u7b49\u95ee\u9898\uff0c\u5bfc\u81f4\u8bb8\u591a\u7814\u7a76\u53ea\u80fd\u4f7f\u7528\u5c0f\u90e8\u5206\u6570\u636e\uff0c\u9650\u5236\u4e86\u7edf\u8ba1\u529f\u6548\u548c\u53ef\u91cd\u590d\u6027\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u96c6\u6210\u5316\u5904\u7406\u6d41\u7a0b\uff0c\u7ed3\u5408\u5f00\u6e90\u8f6f\u4ef6\uff08Clinica\u3001fMRIPrep\u3001MRIQC\uff09\u548c\u5b9a\u5236\u5de5\u5177\uff0c\u6db5\u76d6\u6570\u636e\u4e0b\u8f7d\u3001\u4e34\u5e8a\u4e0e\u6210\u50cf\u6570\u636e\u65f6\u95f4\u5bf9\u9f50\u3001\u9884\u5904\u7406\u548c\u8d28\u91cf\u63a7\u5236\uff0c\u652f\u6301ADNI-GO\u3001ADNI-2\u548cADNI-3\u6570\u636e\u3002", "result": "\u521b\u5efa\u4e86\u4e00\u4e2a\u900f\u660e\u3001\u53ef\u6269\u5c55\u7684\u6846\u67b6\uff0c\u8f93\u51fa\u7b26\u5408BIDS-derivatives\u89c4\u8303\u7684\u9ad8\u8d28\u91cfrs-fMRI\u65f6\u95f4\u5e8f\u5217\u6570\u636e\uff0c\u63d0\u4f9b\u6bcf\u4e2a\u53d7\u8bd5\u8005\u548c\u626b\u63cf\u7684\u8d28\u91cf\u6307\u6807\u548c\u62a5\u544a\uff0c\u4fbf\u4e8e\u4e25\u683c\u6570\u636e\u7b5b\u9009\u3002", "conclusion": "\u8be5\u6d41\u7a0b\u4e3aADNI fMRI\u6570\u636e\u7684\u6574\u7406\u548c\u4f7f\u7528\u63d0\u4f9b\u4e86\u6807\u51c6\u5316\u89e3\u51b3\u65b9\u6848\uff0c\u652f\u6301\u5927\u89c4\u6a21\u529f\u80fd\u751f\u7269\u6807\u5fd7\u7269\u53d1\u73b0\u548c\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\u7814\u7a76\u7684\u6574\u5408\u591a\u6a21\u6001\u5206\u6790\uff0c\u6240\u6709\u811a\u672c\u548c\u914d\u7f6e\u6587\u4ef6\u516c\u5f00\u4ee5\u786e\u4fdd\u53ef\u91cd\u590d\u6027\u3002"}}
{"id": "2602.02896", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.02896", "abs": "https://arxiv.org/abs/2602.02896", "authors": ["Jianru Shen", "Zedong Peng", "Lucy Owen"], "title": "Failure-Aware Enhancements for Large Language Model (LLM) Code Generation: An Empirical Study on Decision Framework", "comment": "Accepted at SANER 2026", "summary": "Large language models (LLMs) show promise for automating software development by translating requirements into code. However, even advanced prompting workflows like progressive prompting often leave some requirements unmet. Although methods such as self-critique, multi-model collaboration, and retrieval-augmented generation (RAG) have been proposed to address these gaps, developers lack clear guidance on when to use each. In an empirical study of 25 GitHub projects, we found that progressive prompting achieves 96.9% average task completion, significantly outperforming direct prompting (80.5%, Cohen's d=1.63, p<0.001) but still leaving 8 projects incomplete. For 6 of the most representative projects, we evaluated each enhancement strategy across 4 failure types. Our results reveal that method effectiveness depends critically on failure characteristics: Self-Critique succeeds on code-reviewable logic errors but fails completely on external service integration (0% improvement), while RAG achieves highest completion across all failure types with superior efficiency. Based on these findings, we propose a decision framework that maps each failure pattern to the most suitable enhancement method, giving practitioners practical, data-driven guidance instead of trial-and-error.", "AI": {"tldr": "\u8bba\u6587\u901a\u8fc7\u5b9e\u8bc1\u7814\u7a76\u53d1\u73b0\uff0c\u6e10\u8fdb\u5f0f\u63d0\u793a\u5728\u4ee3\u7801\u751f\u6210\u4efb\u52a1\u4e2d\u8fbe\u523096.9%\u5b8c\u6210\u7387\uff0c\u4f46\u4ecd\u5b58\u5728\u672a\u6ee1\u8db3\u9700\u6c42\u3002\u4e0d\u540c\u589e\u5f3a\u7b56\u7565\uff08\u81ea\u6211\u6279\u8bc4\u3001RAG\u7b49\uff09\u7684\u6709\u6548\u6027\u53d6\u51b3\u4e8e\u5931\u8d25\u7c7b\u578b\uff0c\u4f5c\u8005\u636e\u6b64\u63d0\u51fa\u4e86\u57fa\u4e8e\u5931\u8d25\u6a21\u5f0f\u7684\u51b3\u7b56\u6846\u67b6\u3002", "motivation": "\u5c3d\u7ba1LLMs\u5728\u81ea\u52a8\u5316\u8f6f\u4ef6\u5f00\u53d1\u65b9\u9762\u663e\u793a\u51fa\u6f5c\u529b\uff0c\u4f46\u5373\u4f7f\u4f7f\u7528\u6e10\u8fdb\u5f0f\u63d0\u793a\u7b49\u9ad8\u7ea7\u5de5\u4f5c\u6d41\uff0c\u4ecd\u6709\u4e00\u4e9b\u9700\u6c42\u65e0\u6cd5\u6ee1\u8db3\u3002\u73b0\u6709\u589e\u5f3a\u65b9\u6cd5\uff08\u5982\u81ea\u6211\u6279\u8bc4\u3001\u591a\u6a21\u578b\u534f\u4f5c\u3001RAG\uff09\u7f3a\u4e4f\u660e\u786e\u7684\u4f7f\u7528\u6307\u5bfc\uff0c\u5f00\u53d1\u8005\u4e0d\u77e5\u9053\u4f55\u65f6\u8be5\u4f7f\u7528\u54ea\u79cd\u65b9\u6cd5\u3002", "method": "\u5bf925\u4e2aGitHub\u9879\u76ee\u8fdb\u884c\u5b9e\u8bc1\u7814\u7a76\uff0c\u6bd4\u8f83\u6e10\u8fdb\u5f0f\u63d0\u793a\u548c\u76f4\u63a5\u63d0\u793a\u7684\u6548\u679c\u3002\u9488\u5bf96\u4e2a\u6700\u5177\u4ee3\u8868\u6027\u7684\u9879\u76ee\uff0c\u8bc4\u4f30\u56db\u79cd\u589e\u5f3a\u7b56\u7565\uff08\u81ea\u6211\u6279\u8bc4\u3001\u591a\u6a21\u578b\u534f\u4f5c\u3001RAG\u7b49\uff09\u5728\u4e0d\u540c\u5931\u8d25\u7c7b\u578b\u4e0a\u7684\u8868\u73b0\u3002", "result": "\u6e10\u8fdb\u5f0f\u63d0\u793a\u5e73\u5747\u4efb\u52a1\u5b8c\u6210\u7387\u8fbe\u523096.9%\uff0c\u663e\u8457\u4f18\u4e8e\u76f4\u63a5\u63d0\u793a\uff0880.5%\uff09\uff0c\u4f46\u4ecd\u7559\u4e0b8\u4e2a\u9879\u76ee\u672a\u5b8c\u6210\u3002\u4e0d\u540c\u589e\u5f3a\u7b56\u7565\u7684\u6709\u6548\u6027\u53d6\u51b3\u4e8e\u5931\u8d25\u7279\u5f81\uff1a\u81ea\u6211\u6279\u8bc4\u5bf9\u4ee3\u7801\u53ef\u5ba1\u67e5\u7684\u903b\u8f91\u9519\u8bef\u6709\u6548\uff0c\u4f46\u5bf9\u5916\u90e8\u670d\u52a1\u96c6\u6210\u5b8c\u5168\u65e0\u6548\uff1bRAG\u5728\u6240\u6709\u5931\u8d25\u7c7b\u578b\u4e0a\u5b9e\u73b0\u6700\u9ad8\u5b8c\u6210\u7387\u4e14\u6548\u7387\u6700\u4f18\u3002", "conclusion": "\u57fa\u4e8e\u7814\u7a76\u53d1\u73b0\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u51b3\u7b56\u6846\u67b6\uff0c\u5c06\u6bcf\u79cd\u5931\u8d25\u6a21\u5f0f\u6620\u5c04\u5230\u6700\u5408\u9002\u7684\u589e\u5f3a\u65b9\u6cd5\uff0c\u4e3a\u4ece\u4e1a\u8005\u63d0\u4f9b\u5b9e\u7528\u3001\u6570\u636e\u9a71\u52a8\u7684\u6307\u5bfc\uff0c\u907f\u514d\u8bd5\u9519\u3002"}}
{"id": "2602.03444", "categories": ["cs.DC", "cs.DS"], "pdf": "https://arxiv.org/pdf/2602.03444", "abs": "https://arxiv.org/abs/2602.03444", "authors": ["Arivarasan Karmegam", "Lucianna Kiffer", "Antonio Fern\u00e1ndez Anta"], "title": "Exploiting Multi-Core Parallelism in Blockchain Validation and Construction", "comment": null, "summary": "Blockchain validators can reduce block processing time by exploiting multi-core CPUs, but deterministic execution must preserve a given total order while respecting transaction conflicts and per-block runtime limits. This paper systematically examines how validators can exploit multi-core parallelism during both block construction and execution without violating blockchain semantics. We formalize two validator-side optimization problems: (i) executing an already ordered block on \\(p\\) cores to minimize makespan while ensuring equivalence to sequential execution; and (ii) selecting and scheduling a subset of mempool transactions under a runtime limit \\(B\\) to maximize validator reward. For both, we develop exact Mixed-Integer Linear Programming (MILP) formulations that capture conflict, order, and capacity constraints, and propose fast deterministic heuristics that scale to realistic workloads. Using Ethereum mainnet traces and including a Solana-inspired declared-access baseline (Sol) for ordered-block scheduling and a simple reward-greedy baseline (RG) for block construction, we empirically quantify the trade-offs between optimality and runtime.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u7814\u7a76\u4e86\u533a\u5757\u94fe\u9a8c\u8bc1\u5668\u5982\u4f55\u5229\u7528\u591a\u6838CPU\u5e76\u884c\u5904\u7406\u533a\u5757\uff0c\u540c\u65f6\u4fdd\u6301\u786e\u5b9a\u6027\u6267\u884c\u548c\u533a\u5757\u94fe\u8bed\u4e49\u3002\u63d0\u51fa\u4e86\u4e24\u4e2a\u4f18\u5316\u95ee\u9898\uff1a\u5df2\u6392\u5e8f\u533a\u5757\u7684\u5e76\u884c\u6267\u884c\u8c03\u5ea6\u548c\u5185\u5b58\u6c60\u4ea4\u6613\u7684\u9009\u62e9\u8c03\u5ea6\uff0c\u5e76\u5f00\u53d1\u4e86MILP\u7cbe\u786e\u89e3\u548c\u5feb\u901f\u542f\u53d1\u5f0f\u7b97\u6cd5\u3002", "motivation": "\u533a\u5757\u94fe\u9a8c\u8bc1\u5668\u53ef\u4ee5\u5229\u7528\u591a\u6838CPU\u51cf\u5c11\u533a\u5757\u5904\u7406\u65f6\u95f4\uff0c\u4f46\u5fc5\u987b\u4fdd\u6301\u786e\u5b9a\u6027\u6267\u884c\uff0c\u540c\u65f6\u5c0a\u91cd\u4ea4\u6613\u51b2\u7a81\u548c\u6bcf\u4e2a\u533a\u5757\u7684\u8fd0\u884c\u65f6\u95f4\u9650\u5236\u3002\u76ee\u524d\u7f3a\u4e4f\u7cfb\u7edf\u6027\u7684\u65b9\u6cd5\u6765\u5728\u533a\u5757\u6784\u5efa\u548c\u6267\u884c\u9636\u6bb5\u6709\u6548\u5229\u7528\u591a\u6838\u5e76\u884c\u6027\u800c\u4e0d\u8fdd\u53cd\u533a\u5757\u94fe\u8bed\u4e49\u3002", "method": "1) \u5f62\u5f0f\u5316\u4e24\u4e2a\u9a8c\u8bc1\u5668\u7aef\u4f18\u5316\u95ee\u9898\uff1a\u5df2\u6392\u5e8f\u533a\u5757\u5728p\u4e2a\u6838\u5fc3\u4e0a\u7684\u6700\u5c0f\u5316\u5b8c\u6210\u65f6\u95f4\u8c03\u5ea6\uff0c\u4ee5\u53ca\u5728\u8fd0\u884c\u65f6\u9650\u5236B\u4e0b\u9009\u62e9\u8c03\u5ea6\u5185\u5b58\u6c60\u4ea4\u6613\u4ee5\u6700\u5927\u5316\u9a8c\u8bc1\u5668\u5956\u52b1\uff1b2) \u5f00\u53d1\u7cbe\u786e\u7684\u6df7\u5408\u6574\u6570\u7ebf\u6027\u89c4\u5212(MILP)\u516c\u5f0f\uff0c\u6355\u6349\u51b2\u7a81\u3001\u987a\u5e8f\u548c\u5bb9\u91cf\u7ea6\u675f\uff1b3) \u63d0\u51fa\u53ef\u6269\u5c55\u5230\u5b9e\u9645\u5de5\u4f5c\u8d1f\u8f7d\u7684\u5feb\u901f\u786e\u5b9a\u6027\u542f\u53d1\u5f0f\u7b97\u6cd5\u3002", "result": "\u4f7f\u7528\u4ee5\u592a\u574a\u4e3b\u7f51\u8ddf\u8e2a\u6570\u636e\uff0c\u5305\u62ecSolana\u542f\u53d1\u7684\u58f0\u660e\u8bbf\u95ee\u57fa\u7ebf(Sol)\u7528\u4e8e\u5df2\u6392\u5e8f\u533a\u5757\u8c03\u5ea6\uff0c\u4ee5\u53ca\u7b80\u5355\u7684\u5956\u52b1\u8d2a\u5a6a\u57fa\u7ebf(RG)\u7528\u4e8e\u533a\u5757\u6784\u5efa\u3002\u5b9e\u8bc1\u91cf\u5316\u4e86\u6700\u4f18\u6027\u548c\u8fd0\u884c\u65f6\u95f4\u4e4b\u95f4\u7684\u6743\u8861\u5173\u7cfb\u3002", "conclusion": "\u672c\u6587\u4e3a\u533a\u5757\u94fe\u9a8c\u8bc1\u5668\u5728\u591a\u6838\u73af\u5883\u4e0b\u7684\u5e76\u884c\u5904\u7406\u63d0\u4f9b\u4e86\u7cfb\u7edf\u6027\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u5f62\u5f0f\u5316\u4f18\u5316\u95ee\u9898\u3001\u5f00\u53d1\u7cbe\u786e\u7b97\u6cd5\u548c\u542f\u53d1\u5f0f\u65b9\u6cd5\uff0c\u5728\u4fdd\u6301\u533a\u5757\u94fe\u8bed\u4e49\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u4e86\u5904\u7406\u6548\u7387\uff0c\u4e3a\u5b9e\u9645\u90e8\u7f72\u63d0\u4f9b\u4e86\u7406\u8bba\u548c\u6280\u672f\u57fa\u7840\u3002"}}
{"id": "2602.02934", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.02934", "abs": "https://arxiv.org/abs/2602.02934", "authors": ["Yu Shi", "Hao Li", "Bram Adams", "Ahmed E. Hassan"], "title": "Beyond Blame: Rethinking SZZ with Knowledge Graph Search", "comment": null, "summary": "Identifying Bug-Inducing Commits (BICs) is fundamental for understanding software defects and enabling downstream tasks such as defect prediction and automated program repair. Yet existing SZZ-based approaches are limited by their reliance on git blame, which restricts the search space to commits that directly modified the fixed lines. Our preliminary study on 2,102 validated bug-fixing commits reveals that this limitation is significant: over 40% of cases cannot be solved by blame alone, as 28% of BICs require traversing commit history beyond blame results and 14% are blameless.\n  We present AgenticSZZ, the first approach to apply Temporal Knowledge Graphs (TKGs) to software evolution analysis. AgenticSZZ reframes BIC identification from a ranking problem over blame commits into a graph search problem, where temporal ordering is fundamental to causal reasoning about bug introduction. The approach operates in two phases: (1) constructing a TKG that encodes commits with temporal and structural relationships, expanding the search space by traversing file history backward from two reference points (blame commits and the BFC); and (2) leveraging an LLM agent to navigate the graph using specialized tools for candidate exploration and causal analysis.\n  Evaluation on three datasets shows that AgenticSZZ achieves F1-scores of 0.48 to 0.74, with statistically significant improvements over state-of-the-art by up to 27%. Our ablation study confirms that both components are essential, reflecting a classic exploration-exploitation trade-off: the TKG expands the search space while the agent provides intelligent selection. By transforming BIC identification into a graph search problem, we open a new research direction for temporal and causal reasoning in software evolution analysis.", "AI": {"tldr": "AgenticSZZ\uff1a\u9996\u4e2a\u5c06\u65f6\u5e8f\u77e5\u8bc6\u56fe\u8c31\u5e94\u7528\u4e8e\u8f6f\u4ef6\u6f14\u5316\u5206\u6790\u7684\u65b9\u6cd5\uff0c\u5c06bug\u5f15\u5165\u63d0\u4ea4\u8bc6\u522b\u4ece\u57fa\u4e8eblame\u7684\u6392\u5e8f\u95ee\u9898\u91cd\u6784\u4e3a\u56fe\u641c\u7d22\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8bc6\u522b\u51c6\u786e\u7387\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8eSZZ\u7684\u65b9\u6cd5\u4f9d\u8d56git blame\uff0c\u641c\u7d22\u7a7a\u95f4\u4ec5\u9650\u4e8e\u76f4\u63a5\u4fee\u6539\u4fee\u590d\u884c\u7684\u63d0\u4ea4\u3002\u521d\u6b65\u7814\u7a76\u53d1\u73b0\u8d85\u8fc740%\u7684bug\u5f15\u5165\u63d0\u4ea4\u65e0\u6cd5\u901a\u8fc7blame\u5355\u72ec\u89e3\u51b3\uff0c\u9700\u8981\u8d85\u8d8ablame\u7ed3\u679c\u8fdb\u884c\u5386\u53f2\u904d\u5386\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u65b9\u6cd5\uff1a1) \u6784\u5efa\u65f6\u5e8f\u77e5\u8bc6\u56fe\u8c31\uff0c\u7f16\u7801\u63d0\u4ea4\u7684\u65f6\u95f4\u987a\u5e8f\u548c\u7ed3\u6784\u5173\u7cfb\uff0c\u4ece\u4e24\u4e2a\u53c2\u8003\u70b9\uff08blame\u63d0\u4ea4\u548cbug\u4fee\u590d\u63d0\u4ea4\uff09\u5411\u540e\u904d\u5386\u6587\u4ef6\u5386\u53f2\u6269\u5c55\u641c\u7d22\u7a7a\u95f4\uff1b2) \u5229\u7528LLM\u4ee3\u7406\u901a\u8fc7\u4e13\u7528\u5de5\u5177\u5bfc\u822a\u56fe\u8c31\u8fdb\u884c\u5019\u9009\u63a2\u7d22\u548c\u56e0\u679c\u5206\u6790\u3002", "result": "\u5728\u4e09\u4e2a\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0cF1\u5206\u6570\u8fbe\u52300.48-0.74\uff0c\u76f8\u6bd4\u6700\u5148\u8fdb\u65b9\u6cd5\u6709\u9ad8\u8fbe27%\u7684\u7edf\u8ba1\u663e\u8457\u63d0\u5347\u3002\u6d88\u878d\u7814\u7a76\u8bc1\u5b9e\u4e24\u4e2a\u7ec4\u4ef6\u90fd\u5fc5\u4e0d\u53ef\u5c11\uff0c\u4f53\u73b0\u4e86\u7ecf\u5178\u7684\u63a2\u7d22-\u5229\u7528\u6743\u8861\u3002", "conclusion": "\u901a\u8fc7\u5c06bug\u5f15\u5165\u63d0\u4ea4\u8bc6\u522b\u8f6c\u5316\u4e3a\u56fe\u641c\u7d22\u95ee\u9898\uff0c\u4e3a\u8f6f\u4ef6\u6f14\u5316\u5206\u6790\u4e2d\u7684\u65f6\u5e8f\u548c\u56e0\u679c\u63a8\u7406\u5f00\u8f9f\u4e86\u65b0\u7684\u7814\u7a76\u65b9\u5411\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2602.03474", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2602.03474", "abs": "https://arxiv.org/abs/2602.03474", "authors": ["Shachar Meir", "David Peleg"], "title": "Recursive Energy Efficient Agreement", "comment": null, "summary": "Agreement is a foundational problem in distributed computing that have been studied extensively for over four decades. Recently, Meir, Mirault, Peleg and Robinson introduced the notion of \\emph{Energy Efficient Agreement}, where the goal is to solve Agreement while minimizing the number of round a party participates in, thereby reducing the energy cost per participant. We show a recursive Agreement algorithm that has $O(\\log f)$ active rounds per participant, where $f<n$ represents the maximum number of crash faults in the system.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u9012\u5f52\u5f0f\u5171\u8bc6\u7b97\u6cd5\uff0c\u4f7f\u6bcf\u4e2a\u53c2\u4e0e\u8005\u4ec5\u9700\u53c2\u4e0eO(log f)\u8f6e\u901a\u4fe1\uff0c\u663e\u8457\u964d\u4f4e\u80fd\u8017\u6210\u672c", "motivation": "\u5206\u5e03\u5f0f\u8ba1\u7b97\u4e2d\u7684\u5171\u8bc6\u95ee\u9898\u5df2\u7814\u7a76\u6570\u5341\u5e74\uff0c\u6700\u8fd1Meir\u7b49\u4eba\u63d0\u51fa\"\u80fd\u91cf\u9ad8\u6548\u5171\u8bc6\"\u6982\u5ff5\uff0c\u65e8\u5728\u6700\u5c0f\u5316\u6bcf\u4e2a\u53c2\u4e0e\u8005\u53c2\u4e0e\u7684\u8f6e\u6570\u4ee5\u51cf\u5c11\u80fd\u8017\u6210\u672c", "method": "\u8bbe\u8ba1\u9012\u5f52\u5f0f\u5171\u8bc6\u7b97\u6cd5\uff0c\u901a\u8fc7\u9012\u5f52\u7ed3\u6784\u51cf\u5c11\u6bcf\u4e2a\u53c2\u4e0e\u8005\u7684\u6d3b\u8dc3\u8f6e\u6570\uff0c\u5176\u4e2df<n\u8868\u793a\u7cfb\u7edf\u4e2d\u7684\u6700\u5927\u5d29\u6e83\u6545\u969c\u6570", "result": "\u7b97\u6cd5\u5b9e\u73b0\u6bcf\u4e2a\u53c2\u4e0e\u8005\u4ec5\u9700\u53c2\u4e0eO(log f)\u8f6e\u6d3b\u8dc3\u901a\u4fe1\uff0c\u76f8\u6bd4\u4f20\u7edf\u65b9\u6cd5\u663e\u8457\u964d\u4f4e\u80fd\u8017", "conclusion": "\u8be5\u9012\u5f52\u7b97\u6cd5\u5728\u4fdd\u8bc1\u5171\u8bc6\u6b63\u786e\u6027\u7684\u540c\u65f6\uff0c\u5927\u5e45\u51cf\u5c11\u4e86\u53c2\u4e0e\u8005\u7684\u80fd\u91cf\u6d88\u8017\uff0c\u4e3a\u80fd\u91cf\u9ad8\u6548\u5206\u5e03\u5f0f\u7cfb\u7edf\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848"}}
{"id": "2602.02964", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.02964", "abs": "https://arxiv.org/abs/2602.02964", "authors": ["Altino Alves", "Jo\u00e3o Eduardo Montandon", "Andre Hora"], "title": "Testing Framework Migration with Large Language Models", "comment": "Accepted for publication at AST 2026", "summary": "Python developers rely on two major testing frameworks: \\texttt{unittest} and \\texttt{Pytest}. While \\texttt{Pytest} offers simpler assertions, reusable fixtures, and better interoperability, migrating existing suites from \\texttt{unittest} remains a manual and time-consuming process. Automating this migration could substantially reduce effort and accelerate test modernization. In this paper, we investigate the capability of Large Language Models (LLMs) to automate test framework migrations from \\texttt{unittest} to \\texttt{Pytest}. We evaluate GPT 4o and Claude Sonnet 4 under three prompting strategies (Zero-shot, One-shot, and Chain-of-Thought) and two temperature settings (0.0 and 1.0). To support this analysis, we first introduce a curated dataset of real-world migrations extracted from the top 100 Python open-source projects. Next, we actually execute the LLM-generated test migrations in their respective test suites. Overall, we find that 51.5% of the LLM-generated test migrations failed, while 48.5% passed. The results suggest that LLMs can accelerate test migration, but there are often caveats. For example, Claude Sonnet 4 exhibited more conservative migrations (e.g., preserving class-based tests and legacy \\texttt{unittest} references), while GPT-4o favored more transformations (e.g., to function-based tests). We conclude by discussing multiple implications for practitioners and researchers.", "AI": {"tldr": "\u7814\u7a76\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08GPT-4o\u548cClaude Sonnet 4\uff09\u5728\u81ea\u52a8\u5316Python\u6d4b\u8bd5\u6846\u67b6\u4eceunittest\u8fc1\u79fb\u5230Pytest\u65b9\u9762\u7684\u80fd\u529b\uff0c\u53d1\u73b0\u7ea648.5%\u7684\u8fc1\u79fb\u6d4b\u8bd5\u80fd\u901a\u8fc7\u6267\u884c\uff0c\u4f46\u4ecd\u6709\u8d85\u8fc7\u4e00\u534a\u5931\u8d25\u3002", "motivation": "Python\u5f00\u53d1\u8005\u9762\u4e34\u4eceunittest\u8fc1\u79fb\u5230Pytest\u7684\u6311\u6218\uff0c\u8fd9\u4e2a\u8fc7\u7a0b\u76ee\u524d\u662f\u624b\u52a8\u4e14\u8017\u65f6\u7684\u3002\u81ea\u52a8\u5316\u8fc1\u79fb\u53ef\u4ee5\u663e\u8457\u51cf\u5c11\u5de5\u4f5c\u91cf\u5e76\u52a0\u901f\u6d4b\u8bd5\u73b0\u4ee3\u5316\u8fdb\u7a0b\u3002", "method": "\u4f7f\u7528GPT-4o\u548cClaude Sonnet 4\u4e24\u79cdLLM\uff0c\u5728\u4e09\u79cd\u63d0\u793a\u7b56\u7565\uff08\u96f6\u6837\u672c\u3001\u5355\u6837\u672c\u3001\u601d\u7ef4\u94fe\uff09\u548c\u4e24\u79cd\u6e29\u5ea6\u8bbe\u7f6e\uff080.0\u548c1.0\uff09\u4e0b\u8fdb\u884c\u8bc4\u4f30\u3002\u9996\u5148\u4eceTop 100 Python\u5f00\u6e90\u9879\u76ee\u4e2d\u63d0\u53d6\u771f\u5b9e\u8fc1\u79fb\u6570\u636e\u96c6\uff0c\u7136\u540e\u5b9e\u9645\u6267\u884cLLM\u751f\u6210\u7684\u6d4b\u8bd5\u8fc1\u79fb\u3002", "result": "\u603b\u4f53\u800c\u8a00\uff0c51.5%\u7684LLM\u751f\u6210\u7684\u6d4b\u8bd5\u8fc1\u79fb\u5931\u8d25\uff0c48.5%\u901a\u8fc7\u3002Claude Sonnet 4\u8868\u73b0\u51fa\u66f4\u4fdd\u5b88\u7684\u8fc1\u79fb\u7b56\u7565\uff08\u4fdd\u7559\u57fa\u4e8e\u7c7b\u7684\u6d4b\u8bd5\u548c\u9057\u7559unittest\u5f15\u7528\uff09\uff0c\u800cGPT-4o\u66f4\u503e\u5411\u4e8e\u8f6c\u6362\uff08\u5982\u8f6c\u6362\u4e3a\u57fa\u4e8e\u51fd\u6570\u7684\u6d4b\u8bd5\uff09\u3002", "conclusion": "LLM\u53ef\u4ee5\u52a0\u901f\u6d4b\u8bd5\u8fc1\u79fb\uff0c\u4f46\u5b58\u5728\u5c40\u9650\u6027\u3002\u4e0d\u540c\u6a21\u578b\u8868\u73b0\u51fa\u4e0d\u540c\u7684\u8fc1\u79fb\u7b56\u7565\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u6539\u8fdb\u3002\u5bf9\u5b9e\u8df5\u8005\u548c\u7814\u7a76\u8005\u63d0\u51fa\u4e86\u591a\u4e2a\u542f\u793a\u3002"}}
{"id": "2602.03495", "categories": ["cs.DC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.03495", "abs": "https://arxiv.org/abs/2602.03495", "authors": ["Zeyu Zhu", "Gang Li", "Peisong Wang", "Zitao Mo", "Minnan Pei", "Zhuoran Song", "Xiaoyao Liang", "Jian Cheng"], "title": "DALI: A Workload-Aware Offloading Framework for Efficient MoE Inference on Local PCs", "comment": null, "summary": "Mixture of Experts (MoE) architectures significantly enhance the capacity of LLMs without proportional increases in computation, but at the cost of a vast parameter size. Offloading MoE expert parameters to host memory and leveraging both CPU and GPU computation has recently emerged as a promising direction to support such models on resourceconstrained local PC platforms. While promising, we notice that existing approaches mismatch the dynamic nature of expert workloads, which leads to three fundamental inefficiencies: (1) Static expert assignment causes severe CPUGPU load imbalance, underutilizing CPU and GPU resources; (2) Existing prefetching techniques fail to accurately predict high-workload experts, leading to costly inaccurate prefetches; (3) GPU cache policies neglect workload dynamics, resulting in poor hit rates and limited effectiveness. To address these challenges, we propose DALI, a workloaDAware offLoadIng framework for efficient MoE inference on local PCs. To fully utilize hardware resources, DALI first dynamically assigns experts to CPU or GPU by modeling assignment as a 0-1 integer optimization problem and solving it efficiently using a Greedy Assignment strategy at runtime. To improve prefetching accuracy, we develop a Residual-Based Prefetching method leveraging inter-layer residual information to accurately predict high-workload experts. Additionally, we introduce a Workload-Aware Cache Replacement policy that exploits temporal correlation in expert activations to improve GPU cache efficiency. By evaluating across various MoE models and settings, DALI achieves significant speedups in the both prefill and decoding phases over the state-of-the-art offloading frameworks.", "AI": {"tldr": "DALI\uff1a\u9762\u5411\u672c\u5730PC\u4e0aMoE\u63a8\u7406\u7684\u5de5\u4f5c\u8d1f\u8f7d\u611f\u77e5\u5378\u8f7d\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u4e13\u5bb6\u5206\u914d\u3001\u57fa\u4e8e\u6b8b\u5dee\u7684\u9884\u53d6\u548c\u5de5\u4f5c\u8d1f\u8f7d\u611f\u77e5\u7f13\u5b58\u66ff\u6362\uff0c\u663e\u8457\u63d0\u5347\u63a8\u7406\u6548\u7387\u3002", "motivation": "MoE\u67b6\u6784\u867d\u7136\u80fd\u63d0\u5347LLM\u5bb9\u91cf\u800c\u4e0d\u6210\u6bd4\u4f8b\u589e\u52a0\u8ba1\u7b97\u91cf\uff0c\u4f46\u53c2\u6570\u89c4\u6a21\u5de8\u5927\u3002\u73b0\u6709\u5378\u8f7d\u65b9\u6cd5\u65e0\u6cd5\u5339\u914d\u4e13\u5bb6\u5de5\u4f5c\u8d1f\u8f7d\u7684\u52a8\u6001\u7279\u6027\uff0c\u5bfc\u81f4CPU-GPU\u8d1f\u8f7d\u4e0d\u5e73\u8861\u3001\u9884\u53d6\u4e0d\u51c6\u786e\u548cGPU\u7f13\u5b58\u6548\u7387\u4f4e\u4e0b\u7b49\u95ee\u9898\u3002", "method": "\u63d0\u51faDALI\u6846\u67b6\uff1a1) \u5c06\u4e13\u5bb6\u5206\u914d\u5efa\u6a21\u4e3a0-1\u6574\u6570\u4f18\u5316\u95ee\u9898\uff0c\u4f7f\u7528\u8d2a\u5fc3\u5206\u914d\u7b56\u7565\u52a8\u6001\u5206\u914d\u4e13\u5bb6\u5230CPU\u6216GPU\uff1b2) \u57fa\u4e8e\u6b8b\u5dee\u7684\u9884\u53d6\u65b9\u6cd5\uff0c\u5229\u7528\u5c42\u95f4\u6b8b\u5dee\u4fe1\u606f\u51c6\u786e\u9884\u6d4b\u9ad8\u8d1f\u8f7d\u4e13\u5bb6\uff1b3) \u5de5\u4f5c\u8d1f\u8f7d\u611f\u77e5\u7f13\u5b58\u66ff\u6362\u7b56\u7565\uff0c\u5229\u7528\u4e13\u5bb6\u6fc0\u6d3b\u7684\u65f6\u95f4\u76f8\u5173\u6027\u63d0\u5347GPU\u7f13\u5b58\u6548\u7387\u3002", "result": "\u5728\u5404\u79cdMoE\u6a21\u578b\u548c\u8bbe\u7f6e\u4e0b\u8bc4\u4f30\uff0cDALI\u5728\u9884\u586b\u5145\u548c\u89e3\u7801\u9636\u6bb5\u76f8\u6bd4\u6700\u5148\u8fdb\u7684\u5378\u8f7d\u6846\u67b6\u90fd\u5b9e\u73b0\u4e86\u663e\u8457\u52a0\u901f\u3002", "conclusion": "DALI\u901a\u8fc7\u5de5\u4f5c\u8d1f\u8f7d\u611f\u77e5\u7684\u5378\u8f7d\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86MoE\u63a8\u7406\u4e2d\u7684\u8d44\u6e90\u5229\u7528\u548c\u6548\u7387\u95ee\u9898\uff0c\u4e3a\u8d44\u6e90\u53d7\u9650\u7684\u672c\u5730PC\u5e73\u53f0\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684MoE\u63a8\u7406\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.02965", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.02965", "abs": "https://arxiv.org/abs/2602.02965", "authors": ["Andre Hora", "Gordon Fraser"], "title": "Understanding Bug-Reproducing Tests: A First Empirical Study", "comment": "Accepted for publication at AST 2026", "summary": "Developers create bug-reproducing tests that support debugging by failing as long as the bug is present, and passing once the bug has been fixed. These tests are usually integrated into existing test suites and executed regularly alongside all other tests to ensure that future regressions are caught. Despite this co-existence with other types of tests, the properties of bug-reproducing tests are scarcely researched, and it remains unclear whether they differ fundamentally. In this short paper, we provide an initial empirical study to understand bug-reproducing tests better. We analyze 642 bug-reproducing tests of 15 real-world Python systems. Overall, we find that bug-reproducing tests are not (statistically significantly) different from other tests regarding LOC, number of assertions, and complexity. However, bug-reproducing tests contain slightly more try/except blocks and ``weak assertions'' (e.g.,~\\texttt{assertNotEqual}). Lastly, we detect that the majority (95%) of the bug-reproducing tests reproduce a single bug, while 5% reproduce multiple bugs. We conclude by discussing implications and future research directions.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5bf9Python\u7cfb\u7edf\u4e2d\u7684bug\u590d\u73b0\u6d4b\u8bd5\u8fdb\u884c\u4e86\u9996\u6b21\u5b9e\u8bc1\u7814\u7a76\uff0c\u53d1\u73b0\u5176\u4e0e\u666e\u901a\u6d4b\u8bd5\u5728\u4ee3\u7801\u884c\u6570\u3001\u65ad\u8a00\u6570\u91cf\u548c\u590d\u6742\u5ea6\u4e0a\u65e0\u663e\u8457\u5dee\u5f02\uff0c\u4f46\u5305\u542b\u66f4\u591atry/except\u5757\u548c\u5f31\u65ad\u8a00\uff0c\u4e1495%\u7684bug\u590d\u73b0\u6d4b\u8bd5\u4ec5\u9488\u5bf9\u5355\u4e2abug\u3002", "motivation": "\u5c3d\u7ba1bug\u590d\u73b0\u6d4b\u8bd5\u4e0e\u666e\u901a\u6d4b\u8bd5\u5171\u5b58\u4e8e\u6d4b\u8bd5\u5957\u4ef6\u4e2d\uff0c\u4f46\u5176\u7279\u6027\u7814\u7a76\u751a\u5c11\uff0c\u4e0d\u6e05\u695a\u5b83\u4eec\u662f\u5426\u5b58\u5728\u6839\u672c\u6027\u5dee\u5f02\u3002\u672c\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u5b9e\u8bc1\u5206\u6790\u66f4\u597d\u5730\u7406\u89e3bug\u590d\u73b0\u6d4b\u8bd5\u7684\u7279\u6027\u3002", "method": "\u5bf915\u4e2a\u771f\u5b9ePython\u7cfb\u7edf\u4e2d\u7684642\u4e2abug\u590d\u73b0\u6d4b\u8bd5\u8fdb\u884c\u5b9e\u8bc1\u5206\u6790\uff0c\u6bd4\u8f83\u5176\u4e0e\u666e\u901a\u6d4b\u8bd5\u5728LOC\uff08\u4ee3\u7801\u884c\u6570\uff09\u3001\u65ad\u8a00\u6570\u91cf\u3001\u590d\u6742\u5ea6\u3001try/except\u5757\u4f7f\u7528\u4ee5\u53ca\u65ad\u8a00\u7c7b\u578b\u7b49\u65b9\u9762\u7684\u5dee\u5f02\u3002", "result": "1. bug\u590d\u73b0\u6d4b\u8bd5\u5728LOC\u3001\u65ad\u8a00\u6570\u91cf\u548c\u590d\u6742\u5ea6\u65b9\u9762\u4e0e\u666e\u901a\u6d4b\u8bd5\u65e0\u7edf\u8ba1\u5b66\u663e\u8457\u5dee\u5f02\uff1b2. \u5305\u542b\u66f4\u591atry/except\u5757\u548c\u5f31\u65ad\u8a00\uff08\u5982assertNotEqual\uff09\uff1b3. 95%\u7684bug\u590d\u73b0\u6d4b\u8bd5\u4ec5\u590d\u73b0\u5355\u4e2abug\uff0c5%\u590d\u73b0\u591a\u4e2abug\u3002", "conclusion": "bug\u590d\u73b0\u6d4b\u8bd5\u4e0e\u666e\u901a\u6d4b\u8bd5\u5728\u591a\u6570\u6307\u6807\u4e0a\u76f8\u4f3c\uff0c\u4f46\u5728\u5f02\u5e38\u5904\u7406\u548c\u65ad\u8a00\u7c7b\u578b\u4e0a\u5b58\u5728\u7ec6\u5fae\u5dee\u5f02\u3002\u7814\u7a76\u4e3a\u7406\u89e3bug\u590d\u73b0\u6d4b\u8bd5\u7279\u6027\u63d0\u4f9b\u4e86\u521d\u6b65\u57fa\u7840\uff0c\u5e76\u8ba8\u8bba\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2602.03802", "categories": ["cs.DC", "cs.AI", "math.NA", "math.OC"], "pdf": "https://arxiv.org/pdf/2602.03802", "abs": "https://arxiv.org/abs/2602.03802", "authors": ["Grigory Begunov", "Alexander Tyurin"], "title": "Do We Need Asynchronous SGD? On the Near-Optimality of Synchronous Methods", "comment": null, "summary": "Modern distributed optimization methods mostly rely on traditional synchronous approaches, despite substantial recent progress in asynchronous optimization. We revisit Synchronous SGD and its robust variant, called $m$-Synchronous SGD, and theoretically show that they are nearly optimal in many heterogeneous computation scenarios, which is somewhat unexpected. We analyze the synchronous methods under random computation times and adversarial partial participation of workers, and prove that their time complexities are optimal in many practical regimes, up to logarithmic factors. While synchronous methods are not universal solutions and there exist tasks where asynchronous methods may be necessary, we show that they are sufficient for many modern heterogeneous computation scenarios.", "AI": {"tldr": "\u540c\u6b65SGD\u53ca\u5176\u53d8\u4f53m-Synchronous SGD\u5728\u5f02\u6784\u8ba1\u7b97\u573a\u666f\u4e0b\u8fd1\u4e4e\u6700\u4f18\uff0c\u6253\u7834\u4e86\u5f02\u6b65\u65b9\u6cd5\u66f4\u4f18\u7684\u4f20\u7edf\u8ba4\u77e5", "motivation": "\u5c3d\u7ba1\u5f02\u6b65\u4f18\u5316\u65b9\u6cd5\u8fd1\u671f\u53d6\u5f97\u663e\u8457\u8fdb\u5c55\uff0c\u4f46\u73b0\u4ee3\u5206\u5e03\u5f0f\u4f18\u5316\u4ecd\u4e3b\u8981\u4f9d\u8d56\u4f20\u7edf\u540c\u6b65\u65b9\u6cd5\u3002\u672c\u6587\u65e8\u5728\u91cd\u65b0\u8bc4\u4f30\u540c\u6b65\u65b9\u6cd5\u5728\u5f02\u6784\u8ba1\u7b97\u73af\u5883\u4e2d\u7684\u6027\u80fd\uff0c\u6311\u6218\u5f02\u6b65\u65b9\u6cd5\u66f4\u4f18\u7684\u666e\u904d\u8ba4\u77e5\u3002", "method": "\u91cd\u65b0\u5ba1\u89c6Synchronous SGD\u53ca\u5176\u9c81\u68d2\u53d8\u4f53m-Synchronous SGD\uff0c\u5728\u968f\u673a\u8ba1\u7b97\u65f6\u95f4\u548c\u5bf9\u6297\u6027\u90e8\u5206\u53c2\u4e0e\u7684\u5de5\u4f5c\u8282\u70b9\u6761\u4ef6\u4e0b\u8fdb\u884c\u7406\u8bba\u5206\u6790\uff0c\u8bc4\u4f30\u5176\u5728\u5f02\u6784\u8ba1\u7b97\u573a\u666f\u4e0b\u7684\u6027\u80fd\u3002", "result": "\u7406\u8bba\u8bc1\u660e\u540c\u6b65\u65b9\u6cd5\u5728\u8bb8\u591a\u5f02\u6784\u8ba1\u7b97\u573a\u666f\u4e0b\u8fd1\u4e4e\u6700\u4f18\uff0c\u5176\u65f6\u95f4\u590d\u6742\u5ea6\u5728\u8bb8\u591a\u5b9e\u9645\u573a\u666f\u4e2d\u8fbe\u5230\u6700\u4f18\uff08\u6700\u591a\u76f8\u5dee\u5bf9\u6570\u56e0\u5b50\uff09\uff0c\u8fd9\u4e00\u7ed3\u679c\u51fa\u4eba\u610f\u6599\u3002", "conclusion": "\u867d\u7136\u540c\u6b65\u65b9\u6cd5\u4e0d\u662f\u901a\u7528\u89e3\u51b3\u65b9\u6848\uff08\u67d0\u4e9b\u4efb\u52a1\u53ef\u80fd\u9700\u8981\u5f02\u6b65\u65b9\u6cd5\uff09\uff0c\u4f46\u7814\u7a76\u8868\u660e\u5b83\u4eec\u8db3\u4ee5\u5e94\u5bf9\u8bb8\u591a\u73b0\u4ee3\u5f02\u6784\u8ba1\u7b97\u573a\u666f\uff0c\u6311\u6218\u4e86\u5f02\u6b65\u65b9\u6cd5\u66f4\u4f18\u7684\u4f20\u7edf\u89c2\u70b9\u3002"}}
{"id": "2602.02966", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.02966", "abs": "https://arxiv.org/abs/2602.02966", "authors": ["Bruna Falcucci", "Felipe Gomide", "Andre Hora"], "title": "What Do Contribution Guidelines Say About Software Testing?", "comment": "Published at MSR 2025", "summary": "Software testing plays a crucial role in the contribution process of open-source projects. For example, contributions introducing new features are expected to include tests, and contributions with tests are more likely to be accepted. Although most real-world projects require contributors to write tests, the specific testing practices communicated to contributors remain unclear. In this paper, we present an empirical study to understand better how software testing is approached in contribution guidelines. We analyze the guidelines of 200 Python and JavaScript open-source software projects. We find that 78\\% of the projects include some form of test documentation for contributors. Test documentation is located in multiple sources, including \\texttt{CONTRIBUTING} files (58\\%), external documentation (24\\%), and \\texttt{README} files (8\\%). Furthermore, test documentation commonly explains how to run tests (83.5\\%), but less often provides guidance on how to write tests (37\\%). It frequently covers unit tests (71\\%), but rarely addresses integration (20.5\\%) and end-to-end tests (15.5\\%). Other key testing aspects are also less frequently discussed: test coverage (25.5\\%) and mocking (9.5\\%). We conclude by discussing implications and future research.", "AI": {"tldr": "\u5bf9200\u4e2aPython\u548cJavaScript\u5f00\u6e90\u9879\u76ee\u7684\u8d21\u732e\u6307\u5357\u8fdb\u884c\u5b9e\u8bc1\u7814\u7a76\uff0c\u53d1\u73b078%\u7684\u9879\u76ee\u5305\u542b\u6d4b\u8bd5\u6587\u6863\uff0c\u4f46\u4e3b\u8981\u96c6\u4e2d\u5728\u5982\u4f55\u8fd0\u884c\u6d4b\u8bd5\uff0883.5%\uff09\uff0c\u8f83\u5c11\u6307\u5bfc\u5982\u4f55\u7f16\u5199\u6d4b\u8bd5\uff0837%\uff09\uff0c\u4e14\u6d4b\u8bd5\u7c7b\u578b\u8986\u76d6\u4e0d\u5747\u8861\u3002", "motivation": "\u5f00\u6e90\u9879\u76ee\u4e2d\u6d4b\u8bd5\u5bf9\u8d21\u732e\u8fc7\u7a0b\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5c3d\u7ba1\u5927\u591a\u6570\u9879\u76ee\u8981\u6c42\u8d21\u732e\u8005\u7f16\u5199\u6d4b\u8bd5\uff0c\u5177\u4f53\u7684\u6d4b\u8bd5\u5b9e\u8df5\u6307\u5bfc\u5728\u8d21\u732e\u6307\u5357\u4e2d\u4ecd\u4e0d\u660e\u786e\uff0c\u9700\u8981\u7814\u7a76\u5f00\u6e90\u9879\u76ee\u5982\u4f55\u5411\u8d21\u732e\u8005\u4f20\u8fbe\u6d4b\u8bd5\u5b9e\u8df5\u3002", "method": "\u5206\u6790200\u4e2aPython\u548cJavaScript\u5f00\u6e90\u8f6f\u4ef6\u9879\u76ee\u7684\u8d21\u732e\u6307\u5357\uff0c\u5305\u62ecCONTRIBUTING\u6587\u4ef6\u3001\u5916\u90e8\u6587\u6863\u548cREADME\u6587\u4ef6\uff0c\u7edf\u8ba1\u6d4b\u8bd5\u6587\u6863\u7684\u5b58\u5728\u4f4d\u7f6e\u3001\u5185\u5bb9\u548c\u8986\u76d6\u8303\u56f4\u3002", "result": "78%\u7684\u9879\u76ee\u5305\u542b\u6d4b\u8bd5\u6587\u6863\uff0c\u4e3b\u8981\u4f4d\u4e8eCONTRIBUTING\u6587\u4ef6\uff0858%\uff09\u3001\u5916\u90e8\u6587\u6863\uff0824%\uff09\u548cREADME\u6587\u4ef6\uff088%\uff09\u300283.5%\u7684\u6587\u6863\u89e3\u91ca\u5982\u4f55\u8fd0\u884c\u6d4b\u8bd5\uff0c\u4f46\u53ea\u670937%\u6307\u5bfc\u5982\u4f55\u7f16\u5199\u6d4b\u8bd5\u3002\u6d4b\u8bd5\u7c7b\u578b\u8986\u76d6\u4e0d\u5747\u8861\uff1a\u5355\u5143\u6d4b\u8bd571%\uff0c\u96c6\u6210\u6d4b\u8bd520.5%\uff0c\u7aef\u5230\u7aef\u6d4b\u8bd515.5%\u3002\u6d4b\u8bd5\u8986\u76d6\u7387\uff0825.5%\uff09\u548c\u6a21\u62df\uff089.5%\uff09\u8f83\u5c11\u8ba8\u8bba\u3002", "conclusion": "\u5f00\u6e90\u9879\u76ee\u5728\u8d21\u732e\u6307\u5357\u4e2d\u63d0\u4f9b\u4e86\u57fa\u672c\u7684\u6d4b\u8bd5\u6587\u6863\uff0c\u4f46\u5b58\u5728\u91cd\u8981\u7f3a\u9677\uff1a\u7f3a\u4e4f\u7f16\u5199\u6d4b\u8bd5\u7684\u6307\u5bfc\uff0c\u6d4b\u8bd5\u7c7b\u578b\u8986\u76d6\u4e0d\u5b8c\u6574\uff0c\u5173\u952e\u6d4b\u8bd5\u6982\u5ff5\u8ba8\u8bba\u4e0d\u8db3\u3002\u9700\u8981\u6539\u8fdb\u8d21\u732e\u6307\u5357\u4ee5\u66f4\u597d\u5730\u652f\u6301\u8d21\u732e\u8005\u8fdb\u884c\u6709\u6548\u7684\u8f6f\u4ef6\u6d4b\u8bd5\u3002"}}
{"id": "2602.03093", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.03093", "abs": "https://arxiv.org/abs/2602.03093", "authors": ["Yang Yue", "Zheng Jiang", "Yi Wang"], "title": "Maintaining the Heterogeneity in the Organization of Software Engineering Research", "comment": "Accepted at the 48th International Conference on Software Engineering, Future of Software Engineering (ICSE 2026-FoSE)", "summary": "The heterogeneity in the organization of software engineering (SE) research historically exists, i.e., funded research model and hands-on model, which makes software engineering become a thriving interdisciplinary field in the last 50 years. However, the funded research model is becoming dominant in SE research recently, indicating such heterogeneity has been seriously and systematically threatened. In this essay, we first explain why the heterogeneity is needed in the organization of SE research, then present the current trend of SE research nowadays, as well as the consequences and potential futures. The choice is at our hands, and we urge our community to seriously consider maintaining the heterogeneity in the organization of software engineering research.", "AI": {"tldr": "\u8f6f\u4ef6\u5de5\u7a0b\u7814\u7a76\u7ec4\u7ec7\u4e2d\u7684\u5f02\u8d28\u6027\uff08\u8d44\u52a9\u7814\u7a76\u6a21\u5f0f\u4e0e\u52a8\u624b\u5b9e\u8df5\u6a21\u5f0f\u5e76\u5b58\uff09\u6b63\u53d7\u5230\u5a01\u80c1\uff0c\u4f5c\u8005\u547c\u5401\u793e\u533a\u7ef4\u62a4\u8fd9\u79cd\u591a\u6837\u6027", "motivation": "\u8f6f\u4ef6\u5de5\u7a0b\u7814\u7a76\u5386\u53f2\u4e0a\u5b58\u5728\u4e24\u79cd\u7ec4\u7ec7\u6a21\u5f0f\uff1a\u8d44\u52a9\u7814\u7a76\u6a21\u5f0f\u548c\u52a8\u624b\u5b9e\u8df5\u6a21\u5f0f\uff0c\u8fd9\u79cd\u5f02\u8d28\u6027\u4f7f\u8f6f\u4ef6\u5de5\u7a0b\u5728\u8fc7\u53bb50\u5e74\u6210\u4e3a\u7e41\u8363\u7684\u8de8\u5b66\u79d1\u9886\u57df\u3002\u7136\u800c\uff0c\u8fd1\u5e74\u6765\u8d44\u52a9\u7814\u7a76\u6a21\u5f0f\u9010\u6e10\u5360\u636e\u4e3b\u5bfc\u5730\u4f4d\uff0c\u8fd9\u79cd\u5f02\u8d28\u6027\u6b63\u53d7\u5230\u4e25\u91cd\u7cfb\u7edf\u6027\u5a01\u80c1\u3002", "method": "\u672c\u6587\u91c7\u7528\u8bba\u8ff0\u6027\u65b9\u6cd5\uff0c\u9996\u5148\u89e3\u91ca\u8f6f\u4ef6\u5de5\u7a0b\u7814\u7a76\u7ec4\u7ec7\u4e3a\u4f55\u9700\u8981\u5f02\u8d28\u6027\uff0c\u7136\u540e\u5448\u73b0\u5f53\u524d\u8f6f\u4ef6\u5de5\u7a0b\u7814\u7a76\u7684\u8d8b\u52bf\u3001\u540e\u679c\u53ca\u6f5c\u5728\u672a\u6765\u3002", "result": "\u5206\u6790\u8868\u660e\uff0c\u8f6f\u4ef6\u5de5\u7a0b\u7814\u7a76\u7ec4\u7ec7\u7684\u5f02\u8d28\u6027\u6b63\u5728\u88ab\u524a\u5f31\uff0c\u8d44\u52a9\u7814\u7a76\u6a21\u5f0f\u65e5\u76ca\u4e3b\u5bfc\uff0c\u8fd9\u53ef\u80fd\u5bf9\u8f6f\u4ef6\u5de5\u7a0b\u9886\u57df\u7684\u591a\u6837\u6027\u548c\u521b\u65b0\u4ea7\u751f\u8d1f\u9762\u5f71\u54cd\u3002", "conclusion": "\u9009\u62e9\u6743\u5728\u6211\u4eec\u624b\u4e2d\uff0c\u4f5c\u8005\u5f3a\u70c8\u547c\u5401\u8f6f\u4ef6\u5de5\u7a0b\u793e\u533a\u8ba4\u771f\u8003\u8651\u7ef4\u62a4\u7814\u7a76\u7ec4\u7ec7\u4e2d\u7684\u5f02\u8d28\u6027\uff0c\u4ee5\u4fdd\u6301\u8be5\u9886\u57df\u7684\u6d3b\u529b\u548c\u521b\u65b0\u6027\u3002"}}
{"id": "2602.03181", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.03181", "abs": "https://arxiv.org/abs/2602.03181", "authors": ["Ziyue Hua", "Tianyu Chen", "Yeyun Gong", "Shuai Lu", "Peng Cheng", "Qinglin Zhu", "Yibo He", "Yingjie Fu", "Wenpin Jiao", "Wei Yang", "Tao Xie"], "title": "Synthesizing File-Level Data for Unit Test Generation with Chain-of-Thoughts via Self-Debugging", "comment": null, "summary": "Automatic unit test (UT) generation is essential for software quality assurance, but existing approaches--including symbolic execution, search-based approaches, and recent LLM-based generators--struggle to produce human-quality tests with correct, meaningful assertions and reliable chain-of-thought (CoT) explanations. We identify a gap in UT training data: repository-mined tests lack developer CoTs, while LLM-distilled CoTs are often incorrect or incomplete. To address this issue, we propose a novel data-distillation approach that uses self-debugging to produce high-quality UT training examples paired with faithful CoTs. Our approach combines (1) guided test repair, a heuristic loop (error-, failure-, and coverage-focused steps) that asks the used model to diagnose and iteratively fix generated tests, and (2) CoT compression, which compacts original and debugging CoTs into concise explanations that directly justify correct tests. We apply this pipeline to a large corpus of open-source projects to construct a dataset of 74,518 high-quality <focal method, test, CoT> examples, and then use it for supervised fine-tuning of a base model. An empirical evaluation shows that the fine-tuned model achieves high UT generation effectiveness: it attains a pass rate of 36.17% on test assertions, a branch coverage of 43.90%, and a mutation score of 88.66%, substantially higher than state-of-the-art commercial models like o4-mini.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u81ea\u8c03\u8bd5\u7684\u6570\u636e\u84b8\u998f\u65b9\u6cd5\uff0c\u751f\u6210\u9ad8\u8d28\u91cf\u5355\u5143\u6d4b\u8bd5\u8bad\u7ec3\u6570\u636e\uff0c\u901a\u8fc7\u76d1\u7763\u5fae\u8c03\u663e\u8457\u63d0\u5347LLM\u751f\u6210\u5355\u5143\u6d4b\u8bd5\u7684\u6548\u679c\u3002", "motivation": "\u73b0\u6709\u5355\u5143\u6d4b\u8bd5\u751f\u6210\u65b9\u6cd5\uff08\u5305\u62ec\u7b26\u53f7\u6267\u884c\u3001\u57fa\u4e8e\u641c\u7d22\u7684\u65b9\u6cd5\u548cLLM\u751f\u6210\u5668\uff09\u96be\u4ee5\u751f\u6210\u5177\u6709\u6b63\u786e\u65ad\u8a00\u548c\u53ef\u9760\u601d\u7ef4\u94fe\u89e3\u91ca\u7684\u4eba\u7c7b\u8d28\u91cf\u6d4b\u8bd5\u3002\u73b0\u6709\u8bad\u7ec3\u6570\u636e\u5b58\u5728\u7f3a\u9677\uff1a\u4ed3\u5e93\u6316\u6398\u7684\u6d4b\u8bd5\u7f3a\u4e4f\u5f00\u53d1\u8005\u601d\u7ef4\u94fe\uff0c\u800cLLM\u84b8\u998f\u7684\u601d\u7ef4\u94fe\u5f80\u5f80\u4e0d\u6b63\u786e\u6216\u4e0d\u5b8c\u6574\u3002", "method": "\u63d0\u51fa\u65b0\u9896\u7684\u6570\u636e\u84b8\u998f\u65b9\u6cd5\uff0c\u7ed3\u5408(1)\u5f15\u5bfc\u5f0f\u6d4b\u8bd5\u4fee\u590d\uff1a\u5305\u542b\u9519\u8bef\u3001\u5931\u8d25\u548c\u8986\u76d6\u7387\u805a\u7126\u6b65\u9aa4\u7684\u542f\u53d1\u5f0f\u5faa\u73af\uff0c\u8ba9\u6a21\u578b\u8bca\u65ad\u5e76\u8fed\u4ee3\u4fee\u590d\u751f\u6210\u7684\u6d4b\u8bd5\uff1b(2)\u601d\u7ef4\u94fe\u538b\u7f29\uff1a\u5c06\u539f\u59cb\u548c\u8c03\u8bd5\u601d\u7ef4\u94fe\u538b\u7f29\u4e3a\u76f4\u63a5\u8bc1\u660e\u6d4b\u8bd5\u6b63\u786e\u7684\u7b80\u6d01\u89e3\u91ca\u3002\u5c06\u6b64\u6d41\u7a0b\u5e94\u7528\u4e8e\u5f00\u6e90\u9879\u76ee\u6784\u5efa\u9ad8\u8d28\u91cf\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u76d1\u7763\u5fae\u8c03\u57fa\u7840\u6a21\u578b\u3002", "result": "\u6784\u5efa\u4e86\u5305\u542b74,518\u4e2a\u9ad8\u8d28\u91cf<\u7126\u70b9\u65b9\u6cd5\u3001\u6d4b\u8bd5\u3001\u601d\u7ef4\u94fe>\u793a\u4f8b\u7684\u6570\u636e\u96c6\u3002\u5fae\u8c03\u540e\u7684\u6a21\u578b\u5728\u5355\u5143\u6d4b\u8bd5\u751f\u6210\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff1a\u6d4b\u8bd5\u65ad\u8a00\u901a\u8fc7\u7387\u8fbe\u523036.17%\uff0c\u5206\u652f\u8986\u76d6\u7387\u8fbe\u523043.90%\uff0c\u53d8\u5f02\u6d4b\u8bd5\u5f97\u5206\u8fbe\u523088.66%\uff0c\u663e\u8457\u4f18\u4e8eo4-mini\u7b49\u6700\u5148\u8fdb\u7684\u5546\u4e1a\u6a21\u578b\u3002", "conclusion": "\u901a\u8fc7\u81ea\u8c03\u8bd5\u6570\u636e\u84b8\u998f\u65b9\u6cd5\u751f\u6210\u7684\u9ad8\u8d28\u91cf\u8bad\u7ec3\u6570\u636e\uff0c\u80fd\u591f\u663e\u8457\u63d0\u5347LLM\u751f\u6210\u5355\u5143\u6d4b\u8bd5\u7684\u80fd\u529b\uff0c\u5728\u591a\u4e2a\u8bc4\u4f30\u6307\u6807\u4e0a\u8d85\u8d8a\u73b0\u6709\u6700\u5148\u8fdb\u6a21\u578b\uff0c\u4e3a\u89e3\u51b3\u5355\u5143\u6d4b\u8bd5\u751f\u6210\u4e2d\u7684\u601d\u7ef4\u94fe\u8d28\u91cf\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6848\u3002"}}
{"id": "2602.03311", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.03311", "abs": "https://arxiv.org/abs/2602.03311", "authors": ["Elena Masserini"], "title": "Multi-Level Testing of Conversational AI Systems", "comment": "3 pages, 1 figure, Accepted at IEEE/ACM International Conference on Software Engineering (ICSE) - Doctoral Symposium Track, 2026", "summary": "Conversational AI systems combine AI-based solutions with the flexibility of conversational interfaces. However, most existing testing solutions do not straightforwardly adapt to the characteristics of conversational interaction or to the behavior of AI components. To address this limitation, this Ph.D. thesis investigates a new family of testing approaches for conversational AI systems, focusing on the validation of their constituent elements at different levels of granularity, from the integration between the language and the AI components, to individual conversational agents, up to multi-agent implementations of conversational AI systems", "AI": {"tldr": "\u8be5\u535a\u58eb\u8bba\u6587\u63d0\u51fa\u9488\u5bf9\u4f1a\u8bddAI\u7cfb\u7edf\u7684\u65b0\u578b\u6d4b\u8bd5\u65b9\u6cd5\uff0c\u5173\u6ce8\u4ece\u8bed\u8a00\u4e0eAI\u7ec4\u4ef6\u96c6\u6210\u5230\u5355\u4ee3\u7406\u548c\u591a\u4ee3\u7406\u7cfb\u7edf\u7684\u591a\u5c42\u6b21\u9a8c\u8bc1", "motivation": "\u73b0\u6709\u6d4b\u8bd5\u65b9\u6848\u96be\u4ee5\u9002\u5e94\u4f1a\u8bdd\u4ea4\u4e92\u7279\u6027\u548cAI\u7ec4\u4ef6\u884c\u4e3a\uff0c\u9700\u8981\u4e13\u95e8\u9488\u5bf9\u4f1a\u8bddAI\u7cfb\u7edf\u7684\u6d4b\u8bd5\u65b9\u6cd5", "method": "\u7814\u7a76\u65b0\u578b\u6d4b\u8bd5\u65b9\u6cd5\u5bb6\u65cf\uff0c\u5173\u6ce8\u4e0d\u540c\u7c92\u5ea6\u5c42\u6b21\u7684\u9a8c\u8bc1\uff1a\u8bed\u8a00\u4e0eAI\u7ec4\u4ef6\u96c6\u6210\u3001\u5355\u4e2a\u4f1a\u8bdd\u4ee3\u7406\u3001\u591a\u4ee3\u7406\u5b9e\u73b0", "result": "\u63d0\u51fa\u4e86\u4e13\u95e8\u9488\u5bf9\u4f1a\u8bddAI\u7cfb\u7edf\u7684\u591a\u5c42\u6b21\u6d4b\u8bd5\u6846\u67b6", "conclusion": "\u8be5\u7814\u7a76\u586b\u8865\u4e86\u4f1a\u8bddAI\u7cfb\u7edf\u6d4b\u8bd5\u65b9\u6cd5\u7684\u7a7a\u767d\uff0c\u4e3a\u8fd9\u7c7b\u7cfb\u7edf\u7684\u8d28\u91cf\u4fdd\u8bc1\u63d0\u4f9b\u4e86\u7cfb\u7edf\u5316\u89e3\u51b3\u65b9\u6848"}}
{"id": "2602.03400", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.03400", "abs": "https://arxiv.org/abs/2602.03400", "authors": ["Jintai Li", "Songqiang Chen", "Shuo Jin", "Xiaoyuan Xie"], "title": "Precision in Practice: Knowledge Guided Code Summarizing Grounded in Industrial Expectations", "comment": null, "summary": "Code summaries are essential for helping developers understand code functionality and reducing maintenance and collaboration costs. Although recent advances in large language models (LLMs) have significantly improved automatic code summarization, the practical usefulness of generated summaries in industrial settings remains insufficiently explored. In collaboration with documentation experts from the industrial HarmonyOS project, we conducted a questionnaire study showing that over 57.4% of code summaries produced by state-of-the-art approaches were rejected due to violations of developers' expectations for industrial documentation. Beyond semantic similarity to reference summaries, developers emphasize additional requirements, including the use of appropriate domain terminology, explicit function categorization, and the avoidance of redundant implementation details.\n  To address these expectations, we propose ExpSum, an expectation-aware code summarization approach that integrates function metadata abstraction, informative metadata filtering, context-aware domain knowledge retrieval, and constraint-driven prompting to guide LLMs in generating structured, expectation-aligned summaries. We evaluate ExpSum on the HarmonyOS project and widely used code summarization benchmarks. Experimental results show that ExpSum consistently outperforms all baselines, achieving improvements of up to 26.71% in BLEU-4 and 20.10% in ROUGE-L on HarmonyOS. Furthermore, LLM-based evaluations indicate that ExpSum-generated summaries better align with developer expectations across other projects, demonstrating its effectiveness for industrial code documentation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faExpSum\u65b9\u6cd5\uff0c\u901a\u8fc7\u6574\u5408\u51fd\u6570\u5143\u6570\u636e\u62bd\u8c61\u3001\u4fe1\u606f\u8fc7\u6ee4\u3001\u4e0a\u4e0b\u6587\u611f\u77e5\u9886\u57df\u77e5\u8bc6\u68c0\u7d22\u548c\u7ea6\u675f\u9a71\u52a8\u63d0\u793a\uff0c\u751f\u6210\u7b26\u5408\u5f00\u53d1\u8005\u671f\u671b\u7684\u5de5\u4e1a\u7ea7\u4ee3\u7801\u6458\u8981\uff0c\u5728HarmonyOS\u9879\u76ee\u4e2d\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u5c3d\u7ba1\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4ee3\u7801\u6458\u8981\u751f\u6210\u65b9\u9762\u53d6\u5f97\u8fdb\u5c55\uff0c\u4f46\u5728\u5de5\u4e1a\u73af\u5883\u4e2d\u751f\u6210\u7684\u6458\u8981\u5b9e\u7528\u6027\u4e0d\u8db3\u3002\u7814\u7a76\u53d1\u73b0\u8d85\u8fc757.4%\u7684\u73b0\u6709\u65b9\u6cd5\u751f\u6210\u7684\u6458\u8981\u56e0\u4e0d\u7b26\u5408\u5f00\u53d1\u8005\u5bf9\u5de5\u4e1a\u6587\u6863\u7684\u671f\u671b\u800c\u88ab\u62d2\u7edd\uff0c\u5f00\u53d1\u8005\u9700\u8981\u9002\u5f53\u7684\u9886\u57df\u672f\u8bed\u3001\u660e\u786e\u7684\u529f\u80fd\u5206\u7c7b\uff0c\u5e76\u907f\u514d\u5197\u4f59\u5b9e\u73b0\u7ec6\u8282\u3002", "method": "\u63d0\u51faExpSum\u65b9\u6cd5\uff0c\u5305\u542b\u56db\u4e2a\u5173\u952e\u7ec4\u4ef6\uff1a1) \u51fd\u6570\u5143\u6570\u636e\u62bd\u8c61\uff0c2) \u4fe1\u606f\u5143\u6570\u636e\u8fc7\u6ee4\uff0c3) \u4e0a\u4e0b\u6587\u611f\u77e5\u9886\u57df\u77e5\u8bc6\u68c0\u7d22\uff0c4) \u7ea6\u675f\u9a71\u52a8\u63d0\u793a\uff0c\u6307\u5bfcLLM\u751f\u6210\u7ed3\u6784\u5316\u3001\u7b26\u5408\u671f\u671b\u7684\u6458\u8981\u3002", "result": "\u5728HarmonyOS\u9879\u76ee\u548c\u5e7f\u6cdb\u4f7f\u7528\u7684\u4ee3\u7801\u6458\u8981\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cExpSum\u59cb\u7ec8\u4f18\u4e8e\u6240\u6709\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5728HarmonyOS\u4e0aBLEU-4\u63d0\u534726.71%\uff0cROUGE-L\u63d0\u534720.10%\u3002\u57fa\u4e8eLLM\u7684\u8bc4\u4f30\u8868\u660e\uff0cExpSum\u751f\u6210\u7684\u6458\u8981\u5728\u5176\u4ed6\u9879\u76ee\u4e2d\u4e5f\u80fd\u66f4\u597d\u5730\u7b26\u5408\u5f00\u53d1\u8005\u671f\u671b\u3002", "conclusion": "ExpSum\u901a\u8fc7\u6574\u5408\u5f00\u53d1\u8005\u671f\u671b\u7684\u5173\u952e\u8981\u7d20\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u5de5\u4e1a\u4ee3\u7801\u6458\u8981\u7684\u8d28\u91cf\u548c\u5b9e\u7528\u6027\uff0c\u4e3a\u5de5\u4e1a\u4ee3\u7801\u6587\u6863\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.03411", "categories": ["cs.SE", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.03411", "abs": "https://arxiv.org/abs/2602.03411", "authors": ["Huatong Song", "Lisheng Huang", "Shuang Sun", "Jinhao Jiang", "Ran Le", "Daixuan Cheng", "Guoxin Chen", "Yiwen Hu", "Zongchao Chen", "Wayne Xin Zhao", "Yang Song", "Tao Zhang", "Ji-Rong Wen"], "title": "SWE-Master: Unleashing the Potential of Software Engineering Agents via Post-Training", "comment": null, "summary": "In this technical report, we present SWE-Master, an open-source and fully reproducible post-training framework for building effective software engineering agents. SWE-Master systematically explores the complete agent development pipeline, including teacher-trajectory synthesis and data curation, long-horizon SFT, RL with real execution feedback, and inference framework design. Starting from an open-source base model with limited initial SWE capability, SWE-Master demonstrates how systematical optimization method can elicit strong long-horizon SWE task solving abilities. We evaluate SWE-Master on SWE-bench Verified, a standard benchmark for realistic software engineering tasks. Under identical experimental settings, our approach achieves a resolve rate of 61.4\\% with Qwen2.5-Coder-32B, substantially outperforming existing open-source baselines. By further incorporating test-time scaling~(TTS) with LLM-based environment feedback, SWE-Master reaches 70.8\\% at TTS@8, demonstrating a strong performance potential. SWE-Master provides a practical and transparent foundation for advancing reproducible research on software engineering agents. The code is available at https://github.com/RUCAIBox/SWE-Master.", "AI": {"tldr": "SWE-Master\u662f\u4e00\u4e2a\u5f00\u6e90\u3001\u53ef\u590d\u73b0\u7684\u8f6f\u4ef6\u5de5\u7a0b\u667a\u80fd\u4f53\u8bad\u7ec3\u6846\u67b6\uff0c\u901a\u8fc7\u7cfb\u7edf\u5316\u7684\u540e\u8bad\u7ec3\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u6a21\u578b\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4efb\u52a1\u4e0a\u7684\u89e3\u51b3\u80fd\u529b\uff0c\u5728SWE-bench Verified\u57fa\u51c6\u4e0a\u8fbe\u523061.4%\u7684\u89e3\u51b3\u7387\uff0c\u7ed3\u5408\u6d4b\u8bd5\u65f6\u6269\u5c55\u540e\u53ef\u8fbe70.8%\u3002", "motivation": "\u73b0\u6709\u5f00\u6e90\u6a21\u578b\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4efb\u52a1\u4e0a\u7684\u80fd\u529b\u6709\u9650\uff0c\u9700\u8981\u7cfb\u7edf\u5316\u7684\u8bad\u7ec3\u6846\u67b6\u6765\u63d0\u5347\u667a\u80fd\u4f53\u5728\u957f\u89c6\u91ce\u8f6f\u4ef6\u5de5\u7a0b\u4efb\u52a1\u4e0a\u7684\u89e3\u51b3\u80fd\u529b\uff0c\u540c\u65f6\u63a8\u52a8\u53ef\u590d\u73b0\u7684\u7814\u7a76\u3002", "method": "\u7cfb\u7edf\u63a2\u7d22\u5b8c\u6574\u7684\u667a\u80fd\u4f53\u5f00\u53d1\u6d41\u7a0b\uff1a\u5305\u62ec\u6559\u5e08\u8f68\u8ff9\u5408\u6210\u4e0e\u6570\u636e\u6574\u7406\u3001\u957f\u89c6\u91ce\u76d1\u7763\u5fae\u8c03\u3001\u57fa\u4e8e\u771f\u5b9e\u6267\u884c\u53cd\u9988\u7684\u5f3a\u5316\u5b66\u4e60\u3001\u4ee5\u53ca\u63a8\u7406\u6846\u67b6\u8bbe\u8ba1\u3002", "result": "\u5728SWE-bench Verified\u57fa\u51c6\u4e0a\uff0c\u4f7f\u7528Qwen2.5-Coder-32B\u6a21\u578b\u8fbe\u523061.4%\u7684\u89e3\u51b3\u7387\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u5f00\u6e90\u57fa\u7ebf\uff1b\u7ed3\u5408\u6d4b\u8bd5\u65f6\u6269\u5c55\uff08TTS@8\uff09\u540e\u63d0\u5347\u81f370.8%\u3002", "conclusion": "SWE-Master\u5c55\u793a\u4e86\u7cfb\u7edf\u5316\u4f18\u5316\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u6fc0\u53d1\u6a21\u578b\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4efb\u52a1\u4e0a\u7684\u5f3a\u5927\u80fd\u529b\uff0c\u4e3a\u8f6f\u4ef6\u5de5\u7a0b\u667a\u80fd\u4f53\u7684\u53ef\u590d\u73b0\u7814\u7a76\u63d0\u4f9b\u4e86\u5b9e\u7528\u4e14\u900f\u660e\u7684\u57fa\u7840\u3002"}}
{"id": "2602.03419", "categories": ["cs.SE", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.03419", "abs": "https://arxiv.org/abs/2602.03419", "authors": ["Shuang Sun", "Huatong Song", "Lisheng Huang", "Jinhao Jiang", "Ran Le", "Zhihao Lv", "Zongchao Chen", "Yiwen Hu", "Wenyang Luo", "Wayne Xin Zhao", "Yang Song", "Hongteng Xu", "Tao Zhang", "Ji-Rong Wen"], "title": "SWE-World: Building Software Engineering Agents in Docker-Free Environments", "comment": null, "summary": "Recent advances in large language models (LLMs) have enabled software engineering agents to tackle complex code modification tasks. Most existing approaches rely on execution feedback from containerized environments, which require dependency-complete setup and physical execution of programs and tests. While effective, this paradigm is resource-intensive and difficult to maintain, substantially complicating agent training and limiting scalability. We propose SWE-World, a Docker-free framework that replaces physical execution environments with a learned surrogate for training and evaluating software engineering agents. SWE-World leverages LLM-based models trained on real agent-environment interaction data to predict intermediate execution outcomes and final test feedback, enabling agents to learn without interacting with physical containerized environments. This design preserves the standard agent-environment interaction loop while eliminating the need for costly environment construction and maintenance during agent optimization and evaluation. Furthermore, because SWE-World can simulate the final evaluation outcomes of candidate trajectories without real submission, it enables selecting the best solution among multiple test-time attempts, thereby facilitating effective test-time scaling (TTS) in software engineering tasks. Experiments on SWE-bench Verified demonstrate that SWE-World raises Qwen2.5-Coder-32B from 6.2\\% to 52.0\\% via Docker-free SFT, 55.0\\% with Docker-free RL, and 68.2\\% with further TTS. The code is available at https://github.com/RUCAIBox/SWE-World", "AI": {"tldr": "SWE-World\u662f\u4e00\u4e2a\u65e0\u9700Docker\u7684\u8f6f\u4ef6\u5de5\u7a0b\u4ee3\u7406\u8bad\u7ec3\u6846\u67b6\uff0c\u4f7f\u7528\u5b66\u4e60\u5230\u7684\u6267\u884c\u73af\u5883\u66ff\u4ee3\u7269\u7406\u5bb9\u5668\u5316\u73af\u5883\uff0c\u663e\u8457\u63d0\u5347\u4ee3\u7801\u4fee\u6539\u4efb\u52a1\u7684\u6027\u80fd", "motivation": "\u73b0\u6709\u8f6f\u4ef6\u5de5\u7a0b\u4ee3\u7406\u4f9d\u8d56\u5bb9\u5668\u5316\u73af\u5883\u7684\u6267\u884c\u53cd\u9988\uff0c\u8fd9\u79cd\u65b9\u6cd5\u8d44\u6e90\u5bc6\u96c6\u4e14\u96be\u4ee5\u7ef4\u62a4\uff0c\u9650\u5236\u4e86\u4ee3\u7406\u8bad\u7ec3\u7684\u53ef\u6269\u5c55\u6027", "method": "\u63d0\u51faSWE-World\u6846\u67b6\uff0c\u5229\u7528\u57fa\u4e8eLLM\u7684\u6a21\u578b\u5728\u771f\u5b9e\u4ee3\u7406-\u73af\u5883\u4ea4\u4e92\u6570\u636e\u4e0a\u8bad\u7ec3\uff0c\u9884\u6d4b\u4e2d\u95f4\u6267\u884c\u7ed3\u679c\u548c\u6700\u7ec8\u6d4b\u8bd5\u53cd\u9988\uff0c\u66ff\u4ee3\u7269\u7406\u6267\u884c\u73af\u5883", "result": "\u5728SWE-bench Verified\u4e0a\uff0cSWE-World\u5c06Qwen2.5-Coder-32B\u4ece6.2%\u63d0\u5347\u523052.0%\uff08\u65e0Docker SFT\uff09\u300155.0%\uff08\u65e0Docker RL\uff09\u548c68.2%\uff08\u8fdb\u4e00\u6b65TTS\uff09", "conclusion": "SWE-World\u901a\u8fc7\u6d88\u9664\u7269\u7406\u73af\u5883\u4f9d\u8d56\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u8f6f\u4ef6\u5de5\u7a0b\u4ee3\u7406\u8bad\u7ec3\u548c\u8bc4\u4f30\uff0c\u652f\u6301\u6d4b\u8bd5\u65f6\u6269\u5c55\uff0c\u663e\u8457\u63d0\u5347\u6027\u80fd\u540c\u65f6\u964d\u4f4e\u8d44\u6e90\u6d88\u8017"}}
{"id": "2602.03462", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.03462", "abs": "https://arxiv.org/abs/2602.03462", "authors": ["Ruwei Pan", "Yakun Zhang", "Qingyuan Liang", "Yueheng Zhu", "Chao Liu", "Lu Zhang", "Hongyu Zhang"], "title": "RAL-Bench: Benchmarking for Application-Level Functional Correctness and Non-Functional Quality Attributes", "comment": null, "summary": "Code generation has advanced rapidly with code-focused large language models (LLMs), especially on snippet-level tasks. However, application-level generation requires producing a runnable multi-file repository with correct structure, dependencies, and end-to-end executability, and real-world software must satisfy both functional correctness and non-functional quality (e.g., maintainability, security). Existing benchmarks provide a limited execution-based assessment of these requirements at the application level. We ask: Can current LLMs generate application-level repositories that meet both functional and non-functional criteria? We propose RAL-Bench, a benchmark and evaluation framework for application-level code generation. For each task, we distill a concise natural-language requirement from a high-quality reference project, build black-box system tests covering functional and non-functional attributes, and keep only tests that pass on the reference repository to ensure a sound oracle and an end-to-end executable suite. Functional correctness is measured by system-test pass rate. Non-functional quality is measured along five ISO/IEC 25010-inspired dimensions and aggregated with an Analytic Hierarchy Process (AHP)-derived weight vector, with per-dimension diagnostics and baseline-normalized scoring using reference measurements. Across 16 LLMs evaluated zero-shot with greedy decoding, functional correctness is the dominant bottleneck: no model exceeds a 45% functional pass rate under our requirement-driven, reference-validated tests. We release RAL-Bench at https://github.com/Wwstarry/RAL-Bench. .", "AI": {"tldr": "RAL-Bench\u662f\u4e00\u4e2a\u5e94\u7528\u7ea7\u4ee3\u7801\u751f\u6210\u57fa\u51c6\u6d4b\u8bd5\u6846\u67b6\uff0c\u8bc4\u4f30LLM\u751f\u6210\u53ef\u8fd0\u884c\u591a\u6587\u4ef6\u4ed3\u5e93\u7684\u80fd\u529b\uff0c\u6db5\u76d6\u529f\u80fd\u6b63\u786e\u6027\u548c\u975e\u529f\u80fd\u6027\u8d28\u91cf\uff08\u53ef\u7ef4\u62a4\u6027\u3001\u5b89\u5168\u6027\u7b49\uff09\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u5728\u5e94\u7528\u7ea7\u4ee3\u7801\u751f\u6210\u8bc4\u4f30\u65b9\u9762\u6709\u9650\uff0c\u9700\u8981\u540c\u65f6\u8bc4\u4f30\u529f\u80fd\u6b63\u786e\u6027\u548c\u975e\u529f\u80fd\u6027\u8d28\u91cf\uff0c\u4ee5\u4e86\u89e3LLM\u80fd\u5426\u751f\u6210\u6ee1\u8db3\u5b9e\u9645\u8f6f\u4ef6\u9700\u6c42\u7684\u4ee3\u7801\u4ed3\u5e93\u3002", "method": "\u4ece\u9ad8\u8d28\u91cf\u53c2\u8003\u9879\u76ee\u4e2d\u63d0\u53d6\u81ea\u7136\u8bed\u8a00\u9700\u6c42\uff0c\u6784\u5efa\u8986\u76d6\u529f\u80fd\u548c\u975e\u529f\u80fd\u5c5e\u6027\u7684\u9ed1\u76d2\u7cfb\u7edf\u6d4b\u8bd5\uff0c\u4f7f\u7528\u53c2\u8003\u4ed3\u5e93\u9a8c\u8bc1\u6d4b\u8bd5\uff0c\u529f\u80fd\u6b63\u786e\u6027\u901a\u8fc7\u6d4b\u8bd5\u901a\u8fc7\u7387\u8861\u91cf\uff0c\u975e\u529f\u80fd\u6027\u8d28\u91cf\u57fa\u4e8eISO/IEC 25010\u4e94\u4e2a\u7ef4\u5ea6\uff0c\u4f7f\u7528AHP\u6743\u91cd\u5411\u91cf\u805a\u5408\u3002", "result": "\u8bc4\u4f3016\u4e2aLLM\u7684\u96f6\u6837\u672c\u8d2a\u5a6a\u89e3\u7801\u7ed3\u679c\u663e\u793a\uff0c\u529f\u80fd\u6b63\u786e\u6027\u662f\u4e3b\u8981\u74f6\u9888\uff1a\u5728\u9700\u6c42\u9a71\u52a8\u3001\u53c2\u8003\u9a8c\u8bc1\u7684\u6d4b\u8bd5\u4e0b\uff0c\u6ca1\u6709\u6a21\u578b\u8d85\u8fc745%\u7684\u529f\u80fd\u901a\u8fc7\u7387\u3002", "conclusion": "\u5f53\u524dLLM\u5728\u5e94\u7528\u7ea7\u4ee3\u7801\u751f\u6210\u4e2d\u529f\u80fd\u6b63\u786e\u6027\u4ecd\u6709\u663e\u8457\u4e0d\u8db3\uff0cRAL-Bench\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5168\u9762\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u6709\u52a9\u4e8e\u63a8\u52a8\u5e94\u7528\u7ea7\u4ee3\u7801\u751f\u6210\u7814\u7a76\u3002"}}
{"id": "2602.03550", "categories": ["cs.SE", "cs.FL", "cs.LO", "cs.RO"], "pdf": "https://arxiv.org/pdf/2602.03550", "abs": "https://arxiv.org/abs/2602.03550", "authors": ["Fang Yan", "Simon Foster", "Ana Cavalcanti", "Ibrahim Habli", "James Baxter"], "title": "Formal Evidence Generation for Assurance Cases for Robotic Software Models", "comment": "This is a preprint. The paper is currently under review at Software and Systems Modeling", "summary": "Robotics and Autonomous Systems are increasingly deployed in safety-critical domains, so that demonstrating their safety is essential. Assurance Cases (ACs) provide structured arguments supported by evidence, but generating and maintaining this evidence is labour-intensive, error-prone, and difficult to keep consistent as systems evolve. We present a model-based approach to systematically generating AC evidence by embedding formal verification into the assurance workflow. The approach addresses three challenges: systematically deriving formal assertions from natural language requirements using templates, orchestrating multiple formal verification tools to handle diverse property types, and integrating formal evidence production into the workflow. Leveraging RoboChart, a domain-specific modelling language with formal semantics, we combine model checking and theorem proving in our approach. Structured requirements are automatically transformed into formal assertions using predefined templates, and verification results are automatically integrated as evidence. Case studies demonstrate the effectiveness of our approach.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u6a21\u578b\u7684\u7cfb\u7edf\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u5f62\u5f0f\u5316\u9a8c\u8bc1\u5d4c\u5165\u4fdd\u8bc1\u5de5\u4f5c\u6d41\uff0c\u81ea\u52a8\u751f\u6210\u4fdd\u8bc1\u6848\u4f8b\u8bc1\u636e", "motivation": "\u673a\u5668\u4eba\u548c\u81ea\u4e3b\u7cfb\u7edf\u5728\u5b89\u5168\u5173\u952e\u9886\u57df\u90e8\u7f72\u589e\u52a0\uff0c\u9700\u8981\u8bc1\u660e\u5176\u5b89\u5168\u6027\u3002\u4fdd\u8bc1\u6848\u4f8b\uff08ACs\uff09\u867d\u7136\u63d0\u4f9b\u7ed3\u6784\u5316\u8bba\u8bc1\uff0c\u4f46\u8bc1\u636e\u751f\u6210\u548c\u7ef4\u62a4\u5de5\u4f5c\u91cf\u5927\u3001\u6613\u51fa\u9519\uff0c\u4e14\u7cfb\u7edf\u6f14\u5316\u65f6\u96be\u4ee5\u4fdd\u6301\u4e00\u81f4\u6027\u3002", "method": "\u57fa\u4e8eRoboChart\u9886\u57df\u7279\u5b9a\u5efa\u6a21\u8bed\u8a00\uff0c\u7ed3\u5408\u6a21\u578b\u68c0\u67e5\u548c\u5b9a\u7406\u8bc1\u660e\u3002\u4f7f\u7528\u6a21\u677f\u4ece\u81ea\u7136\u8bed\u8a00\u9700\u6c42\u7cfb\u7edf\u5316\u63a8\u5bfc\u5f62\u5f0f\u5316\u65ad\u8a00\uff0c\u534f\u8c03\u591a\u79cd\u5f62\u5f0f\u5316\u9a8c\u8bc1\u5de5\u5177\u5904\u7406\u4e0d\u540c\u5c5e\u6027\u7c7b\u578b\uff0c\u5e76\u5c06\u5f62\u5f0f\u5316\u8bc1\u636e\u751f\u4ea7\u96c6\u6210\u5230\u5de5\u4f5c\u6d41\u4e2d\u3002", "result": "\u7ed3\u6784\u5316\u9700\u6c42\u901a\u8fc7\u9884\u5b9a\u4e49\u6a21\u677f\u81ea\u52a8\u8f6c\u6362\u4e3a\u5f62\u5f0f\u5316\u65ad\u8a00\uff0c\u9a8c\u8bc1\u7ed3\u679c\u81ea\u52a8\u96c6\u6210\u4e3a\u8bc1\u636e\u3002\u6848\u4f8b\u7814\u7a76\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u89e3\u51b3\u4e86\u4fdd\u8bc1\u6848\u4f8b\u8bc1\u636e\u751f\u6210\u7684\u5173\u952e\u6311\u6218\uff0c\u901a\u8fc7\u7cfb\u7edf\u5316\u96c6\u6210\u5f62\u5f0f\u5316\u9a8c\u8bc1\uff0c\u63d0\u9ad8\u4e86\u5b89\u5168\u5173\u952e\u7cfb\u7edf\u4fdd\u8bc1\u5de5\u4f5c\u7684\u6548\u7387\u548c\u53ef\u9760\u6027\u3002"}}
{"id": "2602.03556", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.03556", "abs": "https://arxiv.org/abs/2602.03556", "authors": ["Alexander Berndt", "Thomas Bach", "Sebastian Baltes"], "title": "Flaky Tests in a Large Industrial Database Management System: An Empirical Study of Fixed Issue Reports for SAP HANA", "comment": "8 pages, 2 tables, 5 figures, 3rd International Flaky Tests Workshop 2026 (FTW 2026)", "summary": "Flaky tests yield different results when executed multiple times for the same version of the source code. Thus, they provide an ambiguous signal about the quality of the code and interfere with the automated assessment of code changes. While a variety of factors can cause test flakiness, approaches to fix flaky tests are typically tailored to address specific causes. However, the prevalent root causes of flaky tests can vary depending on the programming language, application domain, or size of the software project. Since manually labeling flaky tests is time-consuming and tedious, this work proposes an LLMs-as-annotators approach that leverages intra- and inter-model consistency to label issue reports related to fixed flakiness issues with the relevant root cause category. This allows us to gain an overview of prevalent flakiness categories in the issue reports. We evaluated our labeling approach in the context of SAP HANA, a large industrial database management system. Our results suggest that SAP HANA's tests most commonly suffer from issues related to concurrency (23%, 130 of 559 analyzed issue reports). Moreover, our results suggest that different test types face different flakiness challenges. Therefore, we encourage future research on flakiness mitigation to consider evaluating the generalizability of proposed approaches across different test types.", "AI": {"tldr": "\u5229\u7528LLMs\u6807\u6ce8\u65b9\u6cd5\u5206\u6790SAP HANA\u4e2d\u6d4b\u8bd5\u4e0d\u7a33\u5b9a\u7684\u6839\u672c\u539f\u56e0\uff0c\u53d1\u73b0\u5e76\u53d1\u95ee\u9898\u662f\u4e3b\u8981\u6839\u6e90\uff08\u536023%\uff09\uff0c\u4e0d\u540c\u6d4b\u8bd5\u7c7b\u578b\u9762\u4e34\u4e0d\u540c\u7684\u4e0d\u7a33\u5b9a\u6027\u6311\u6218\u3002", "motivation": "\u6d4b\u8bd5\u4e0d\u7a33\u5b9a\u6027\uff08flaky tests\uff09\u4f1a\u5bfc\u81f4\u4ee3\u7801\u8d28\u91cf\u8bc4\u4f30\u7684\u6a21\u7cca\u4fe1\u53f7\uff0c\u5e72\u6270\u4ee3\u7801\u53d8\u66f4\u7684\u81ea\u52a8\u5316\u8bc4\u4f30\u3002\u7531\u4e8e\u624b\u52a8\u6807\u6ce8\u4e0d\u7a33\u5b9a\u6d4b\u8bd5\u7684\u6839\u672c\u539f\u56e0\u8017\u65f6\u8d39\u529b\uff0c\u4e14\u4e0d\u540c\u7f16\u7a0b\u8bed\u8a00\u3001\u5e94\u7528\u9886\u57df\u6216\u9879\u76ee\u89c4\u6a21\u4e0b\u7684\u4e3b\u8981\u539f\u56e0\u53ef\u80fd\u4e0d\u540c\uff0c\u9700\u8981\u4e00\u79cd\u81ea\u52a8\u5316\u7684\u6807\u6ce8\u65b9\u6cd5\u6765\u5206\u6790\u5de5\u4e1a\u7cfb\u7edf\u4e2d\u7684\u4e0d\u7a33\u5b9a\u6d4b\u8bd5\u6a21\u5f0f\u3002", "method": "\u63d0\u51faLLMs-as-annotators\u65b9\u6cd5\uff0c\u5229\u7528\u6a21\u578b\u5185\u548c\u6a21\u578b\u95f4\u7684\u4e00\u81f4\u6027\u6765\u6807\u6ce8\u4e0e\u5df2\u4fee\u590d\u4e0d\u7a33\u5b9a\u6027\u95ee\u9898\u76f8\u5173\u7684issue\u62a5\u544a\uff0c\u8bc6\u522b\u76f8\u5173\u7684\u6839\u672c\u539f\u56e0\u7c7b\u522b\u3002\u8be5\u65b9\u6cd5\u5728SAP HANA\uff08\u5927\u578b\u5de5\u4e1a\u6570\u636e\u5e93\u7ba1\u7406\u7cfb\u7edf\uff09\u7684\u80cc\u666f\u4e0b\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u5728\u5206\u6790\u7684559\u4e2aissue\u62a5\u544a\u4e2d\uff0cSAP HANA\u6d4b\u8bd5\u6700\u5e38\u89c1\u7684\u95ee\u9898\u4e0e\u5e76\u53d1\u76f8\u5173\uff0823%\uff0c130\u4e2a\u62a5\u544a\uff09\u3002\u7814\u7a76\u8fd8\u8868\u660e\uff0c\u4e0d\u540c\u7684\u6d4b\u8bd5\u7c7b\u578b\u9762\u4e34\u4e0d\u540c\u7684\u4e0d\u7a33\u5b9a\u6027\u6311\u6218\u3002", "conclusion": "\u5e76\u53d1\u662fSAP HANA\u6d4b\u8bd5\u4e0d\u7a33\u5b9a\u6027\u7684\u4e3b\u8981\u6839\u6e90\u3002\u5efa\u8bae\u672a\u6765\u5173\u4e8e\u4e0d\u7a33\u5b9a\u6027\u7f13\u89e3\u7684\u7814\u7a76\u5e94\u8003\u8651\u8bc4\u4f30\u6240\u63d0\u65b9\u6cd5\u5728\u4e0d\u540c\u6d4b\u8bd5\u7c7b\u578b\u95f4\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u56e0\u4e3a\u4e0d\u540c\u6d4b\u8bd5\u7c7b\u578b\u9762\u4e34\u4e0d\u540c\u7684\u6311\u6218\u3002"}}
{"id": "2602.03557", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.03557", "abs": "https://arxiv.org/abs/2602.03557", "authors": ["Yunhao Liang", "Ruixuan Ying", "Shiwen Ni", "Zhe Cui"], "title": "Scaling Test-Driven Code Generation from Functions to Classes: An Empirical Study", "comment": null, "summary": "Test-driven development (TDD) has been adopted to improve Large Language Model (LLM)-based code generation by using tests as executable specifications. However, existing TDD-style code generation studies are largely limited to function-level tasks, leaving class-level synthesis where multiple methods interact through shared state and call dependencies underexplored. In this paper, we scale test-driven code generation from functions to classes via an iterative TDD framework. Our approach first analyzes intra-class method dependencies to derive a feasible generation schedule, and then incrementally implements each method under method-level public tests with reflection-style execution feedback and bounded repair iterations. To support test-driven generation and rigorous class-level evaluation, we construct ClassEval-TDD, a cleaned and standardized variant of ClassEval with consistent specifications, deterministic test environments, and complete method-level public tests. We conduct an empirical study across eight LLMs and compare against the strongest direct-generation baseline (the best of holistic, incremental, and compositional strategies). Our class-level TDD framework consistently improves class-level correctness by 12 to 26 absolute points and achieves up to 71% fully correct classes, while requiring only a small number of repairs on average. These results demonstrate that test-driven generation can effectively scale beyond isolated functions and substantially improve class-level code generation reliability. All code and data are available at https://anonymous.4open.science/r/ClassEval-TDD-C4C9/", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5c06\u6d4b\u8bd5\u9a71\u52a8\u5f00\u53d1(TDD)\u4ece\u51fd\u6570\u7ea7\u4ee3\u7801\u751f\u6210\u6269\u5c55\u5230\u7c7b\u7ea7\u4ee3\u7801\u751f\u6210\u7684\u8fed\u4ee3\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u6790\u7c7b\u5185\u65b9\u6cd5\u4f9d\u8d56\u5173\u7cfb\u5236\u5b9a\u751f\u6210\u8ba1\u5212\uff0c\u5e76\u5229\u7528\u53cd\u5c04\u5f0f\u6267\u884c\u53cd\u9988\u548c\u6709\u9650\u4fee\u590d\u8fed\u4ee3\u6765\u589e\u91cf\u5b9e\u73b0\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709TDD\u98ce\u683c\u7684\u4ee3\u7801\u751f\u6210\u7814\u7a76\u4e3b\u8981\u5c40\u9650\u4e8e\u51fd\u6570\u7ea7\u4efb\u52a1\uff0c\u800c\u7c7b\u7ea7\u5408\u6210\u4e2d\u591a\u4e2a\u65b9\u6cd5\u901a\u8fc7\u5171\u4eab\u72b6\u6001\u548c\u8c03\u7528\u4f9d\u8d56\u4ea4\u4e92\u7684\u95ee\u9898\u5c1a\u672a\u5145\u5206\u63a2\u7d22\u3002\u9700\u8981\u5c06\u6d4b\u8bd5\u9a71\u52a8\u7684\u4ee3\u7801\u751f\u6210\u4ece\u51fd\u6570\u6269\u5c55\u5230\u7c7b\uff0c\u4ee5\u63d0\u9ad8\u7c7b\u7ea7\u4ee3\u7801\u751f\u6210\u7684\u53ef\u9760\u6027\u3002", "method": "\u63d0\u51fa\u8fed\u4ee3TDD\u6846\u67b6\uff1a1) \u5206\u6790\u7c7b\u5185\u65b9\u6cd5\u4f9d\u8d56\u5173\u7cfb\u4ee5\u5236\u5b9a\u53ef\u884c\u7684\u751f\u6210\u8ba1\u5212\uff1b2) \u5728\u65b9\u6cd5\u7ea7\u516c\u5171\u6d4b\u8bd5\u4e0b\u589e\u91cf\u5b9e\u73b0\u6bcf\u4e2a\u65b9\u6cd5\uff0c\u5229\u7528\u53cd\u5c04\u5f0f\u6267\u884c\u53cd\u9988\u548c\u6709\u9650\u4fee\u590d\u8fed\u4ee3\u3002\u6784\u5efaClassEval-TDD\u6570\u636e\u96c6\uff0c\u5305\u542b\u4e00\u81f4\u7684\u89c4\u8303\u3001\u786e\u5b9a\u6027\u6d4b\u8bd5\u73af\u5883\u548c\u5b8c\u6574\u7684\u65b9\u6cd5\u7ea7\u516c\u5171\u6d4b\u8bd5\u3002", "result": "\u5728\u516b\u4e2aLLM\u4e0a\u7684\u5b9e\u8bc1\u7814\u7a76\u8868\u660e\uff0c\u7c7b\u7ea7TDD\u6846\u67b6\u5c06\u7c7b\u7ea7\u6b63\u786e\u6027\u63d0\u9ad8\u4e8612-26\u4e2a\u7edd\u5bf9\u767e\u5206\u70b9\uff0c\u8fbe\u5230\u6700\u9ad871%\u5b8c\u5168\u6b63\u786e\u7684\u7c7b\uff0c\u5e73\u5747\u53ea\u9700\u8981\u5c11\u91cf\u4fee\u590d\u3002\u76f8\u6bd4\u6700\u5f3a\u7684\u76f4\u63a5\u751f\u6210\u57fa\u7ebf\uff08\u6574\u4f53\u3001\u589e\u91cf\u548c\u7ec4\u5408\u7b56\u7565\u7684\u6700\u4f73\u8868\u73b0\uff09\u6709\u663e\u8457\u6539\u8fdb\u3002", "conclusion": "\u6d4b\u8bd5\u9a71\u52a8\u751f\u6210\u53ef\u4ee5\u6709\u6548\u5730\u6269\u5c55\u5230\u5b64\u7acb\u51fd\u6570\u4e4b\u5916\uff0c\u663e\u8457\u63d0\u9ad8\u7c7b\u7ea7\u4ee3\u7801\u751f\u6210\u7684\u53ef\u9760\u6027\u3002\u8be5\u65b9\u6cd5\u4e3a\u590d\u6742\u7c7b\u7ea7\u4ee3\u7801\u5408\u6210\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.03585", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.03585", "abs": "https://arxiv.org/abs/2602.03585", "authors": ["Lukas Schulte", "Gordon Fraser", "Steffen Herbold"], "title": "Causal Inference for the Effect of Code Coverage on Bug Introduction", "comment": "Registered Report with Continuity Acceptance (CA) for submission to Empirical Software Engineering granted by RR-Committee of the MSR'26", "summary": "Context: Code coverage is widely used as a software quality assurance measure. However, its effect, and specifically the advisable dose, are disputed in both the research and engineering communities. Prior work reports only correlational associations, leaving results vulnerable to confounding factors. Objective: We aim to quantify the causal effect of code coverage (exposure) on bug introduction (outcome) in the context of mature JavaScript and TypeScript open source projects, addressing both the overall effect and its variance across coverage levels. Method: We construct a causal directed acyclic graph to identify confounders within the software engineering process, modeling key variables from the source code, issue- and review systems, and continuous integration. Using generalized propensity score adjustment, we will apply doubly robust regression-based causal inference for continuous exposure to a novel dataset of bug-introducing and non-bug-introducing changes. We estimate the average treatment effect and dose-response relationship to examine potential non-linear patterns (e.g., thresholds or diminishing returns) within the projects of our dataset.", "AI": {"tldr": "\u8be5\u7814\u7a76\u4f7f\u7528\u56e0\u679c\u63a8\u65ad\u65b9\u6cd5\u91cf\u5316\u4ee3\u7801\u8986\u76d6\u7387\u5bf9bug\u5f15\u5165\u7684\u5f71\u54cd\uff0c\u901a\u8fc7\u5e7f\u4e49\u503e\u5411\u5f97\u5206\u8c03\u6574\u548c\u53cc\u91cd\u7a33\u5065\u56de\u5f52\u5206\u6790JavaScript/TypeScript\u9879\u76ee\u4e2d\u8986\u76d6\u7387\u4e0ebug\u5f15\u5165\u7684\u56e0\u679c\u5173\u7cfb\u3002", "motivation": "\u4ee3\u7801\u8986\u76d6\u7387\u88ab\u5e7f\u6cdb\u7528\u4f5c\u8f6f\u4ef6\u8d28\u91cf\u4fdd\u8bc1\u6307\u6807\uff0c\u4f46\u5176\u6548\u679c\u548c\u9002\u5f53\u5242\u91cf\u5728\u7814\u7a76\u548c\u5de5\u7a0b\u793e\u533a\u4e2d\u5b58\u5728\u4e89\u8bae\u3002\u5148\u524d\u5de5\u4f5c\u4ec5\u62a5\u544a\u76f8\u5173\u6027\u5173\u8054\uff0c\u7ed3\u679c\u5bb9\u6613\u53d7\u5230\u6df7\u6742\u56e0\u7d20\u5f71\u54cd\uff0c\u9700\u8981\u91cf\u5316\u8986\u76d6\u7387\u5bf9bug\u5f15\u5165\u7684\u56e0\u679c\u6548\u5e94\u3002", "method": "\u6784\u5efa\u56e0\u679c\u6709\u5411\u65e0\u73af\u56fe\u8bc6\u522b\u8f6f\u4ef6\u5de5\u7a0b\u8fc7\u7a0b\u4e2d\u7684\u6df7\u6742\u56e0\u7d20\uff0c\u4ece\u6e90\u4ee3\u7801\u3001\u95ee\u9898\u8ddf\u8e2a\u7cfb\u7edf\u3001\u8bc4\u5ba1\u7cfb\u7edf\u548c\u6301\u7eed\u96c6\u6210\u4e2d\u5efa\u6a21\u5173\u952e\u53d8\u91cf\u3002\u4f7f\u7528\u5e7f\u4e49\u503e\u5411\u5f97\u5206\u8c03\u6574\uff0c\u5bf9\u8fde\u7eed\u66b4\u9732\uff08\u8986\u76d6\u7387\uff09\u5e94\u7528\u53cc\u91cd\u7a33\u5065\u56de\u5f52\u7684\u56e0\u679c\u63a8\u65ad\u65b9\u6cd5\uff0c\u5206\u6790bug\u5f15\u5165\u548c\u975ebug\u5f15\u5165\u53d8\u66f4\u7684\u6570\u636e\u96c6\u3002", "result": "\u7814\u7a76\u5c06\u4f30\u8ba1\u5e73\u5747\u5904\u7406\u6548\u5e94\u548c\u5242\u91cf-\u54cd\u5e94\u5173\u7cfb\uff0c\u4ee5\u68c0\u67e5\u6570\u636e\u96c6\u4e2d\u9879\u76ee\u5185\u6f5c\u5728\u7684\u975e\u7ebf\u6027\u6a21\u5f0f\uff08\u5982\u9608\u503c\u6216\u6536\u76ca\u9012\u51cf\u6548\u5e94\uff09\u3002", "conclusion": "\u8be5\u7814\u7a76\u65e8\u5728\u4e3aJavaScript/TypeScript\u5f00\u6e90\u9879\u76ee\u4e2d\u4ee3\u7801\u8986\u76d6\u7387\u5bf9bug\u5f15\u5165\u7684\u56e0\u679c\u6548\u5e94\u63d0\u4f9b\u91cf\u5316\u8bc1\u636e\uff0c\u5e2e\u52a9\u786e\u5b9a\u6700\u4f73\u8986\u76d6\u7387\u6c34\u5e73\u3002"}}
{"id": "2602.03593", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.03593", "abs": "https://arxiv.org/abs/2602.03593", "authors": ["Valerie Chen", "Jasmyn He", "Behnjamin Williams", "Jason Valentino", "Ameet Talwalkar"], "title": "Beyond the Commit: Developer Perspectives on Productivity with AI Coding Assistants", "comment": "ICSE SEIP", "summary": "Measuring developer productivity is a topic that has attracted attention from both academic research and industrial practice. In the age of AI coding assistants, it has become even more important for both academia and industry to understand how to measure their impact on developer productivity, and to reconsider whether earlier measures and frameworks still apply. This study analyzes the validity of different approaches to evaluating the productivity impacts of AI coding assistants by leveraging mixed-method research. At BNY Mellon, we conduct a survey with 2989 developer responses and 11 in-depth interviews. Our findings demonstrate that a multifaceted approach is needed to measure AI productivity impacts: survey results expose conflicting perspectives on AI tool usefulness, while interviews elicit six distinct factors that capture both short-term and long-term dimensions of productivity. In contrast to prior work, our factors highlight the importance of long-term metrics like technical expertise and ownership of work. We hope this work encourages future research to incorporate a broader range of human-centered factors, and supports industry in adopting more holistic approaches to evaluating developer productivity.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7\u6df7\u5408\u65b9\u6cd5\u5206\u6790AI\u7f16\u7a0b\u52a9\u624b\u5bf9\u5f00\u53d1\u8005\u751f\u4ea7\u529b\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u9700\u8981\u591a\u7ef4\u5ea6\u8bc4\u4f30\u65b9\u6cd5\uff0c\u5f3a\u8c03\u957f\u671f\u6307\u6807\u7684\u91cd\u8981\u6027", "motivation": "\u5728AI\u7f16\u7a0b\u52a9\u624b\u65f6\u4ee3\uff0c\u9700\u8981\u91cd\u65b0\u8bc4\u4f30\u5982\u4f55\u6d4b\u91cf\u5176\u5bf9\u5f00\u53d1\u8005\u751f\u4ea7\u529b\u7684\u5f71\u54cd\uff0c\u5e76\u68c0\u9a8c\u73b0\u6709\u6d4b\u91cf\u6846\u67b6\u662f\u5426\u4ecd\u7136\u9002\u7528", "method": "\u91c7\u7528\u6df7\u5408\u7814\u7a76\u65b9\u6cd5\uff0c\u5728BNY Mellon\u8fdb\u884c\u5305\u542b2989\u4efd\u5f00\u53d1\u8005\u8c03\u67e5\u548c11\u6b21\u6df1\u5ea6\u8bbf\u8c08\u7684\u5b9e\u8bc1\u7814\u7a76", "result": "\u8c03\u67e5\u663e\u793a\u5bf9AI\u5de5\u5177\u6709\u7528\u6027\u5b58\u5728\u77db\u76fe\u89c2\u70b9\uff0c\u8bbf\u8c08\u8bc6\u522b\u51fa\u516d\u4e2a\u4e0d\u540c\u56e0\u7d20\uff0c\u6db5\u76d6\u77ed\u671f\u548c\u957f\u671f\u751f\u4ea7\u529b\u7ef4\u5ea6\uff0c\u5f3a\u8c03\u6280\u672f\u4e13\u957f\u548c\u5de5\u4f5c\u6240\u6709\u6743\u7b49\u957f\u671f\u6307\u6807\u7684\u91cd\u8981\u6027", "conclusion": "\u9700\u8981\u591a\u7ef4\u5ea6\u65b9\u6cd5\u6d4b\u91cfAI\u751f\u4ea7\u529b\u5f71\u54cd\uff0c\u672a\u6765\u7814\u7a76\u5e94\u7eb3\u5165\u66f4\u5e7f\u6cdb\u7684\u4eba\u672c\u56e0\u7d20\uff0c\u884c\u4e1a\u5e94\u91c7\u7528\u66f4\u5168\u9762\u7684\u5f00\u53d1\u8005\u751f\u4ea7\u529b\u8bc4\u4f30\u65b9\u6cd5"}}
{"id": "2602.03632", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.03632", "abs": "https://arxiv.org/abs/2602.03632", "authors": ["Hemang Jain", "Divyansh Pandey", "Karthik Vaidhyanathan"], "title": "CALM: A Self-Adaptive Orchestration Approach for QoS-Aware Routing in Small Language Model based Systems", "comment": "Accepted as full paper at SEAMS 2026", "summary": "AI-enabled systems are subjected to various types of runtime uncertainties, ranging from dynamic workloads, resource requirements, model drift, etc. These uncertainties have a big impact on the overall Quality of Service (QoS). This is particularly true in the case of Language Model (LM) enabled systems where the autoregressive nature of token generation introduces variability in latency, energy usage and response quality. These systems, powered by LLMs, are either resource-intensive (if run on-prem) or raise privacy/cost concerns (if leveraged using APIs). While deploying a Small Language Model (SLM) can be resource-efficient, it often falls short in addressing the diversity and scale of real-world requirements. To this, we argue that, rather than relying on any one SLM, leveraging a coordinated fleet of SLMs, each with specialized strengths can enable systems to dynamically adapt to shifting contexts and workload patterns. However, realizing the full potential of such an approach demands intelligent orchestration and continuous adaptation. To this end, we introduce CALM , a self-adaptive orchestration mechanism based on MAPE-K. Our approach continuously monitors user queries, analyzes the QoS metrics of the SLMs, identifies the optimal SLM to be used, routes the query to the identified SLM and further to enhance the effectiveness and efficiency, leverages caching and scheduling to decide the SLMs to be kept in memory. Our evaluation shows that CALM reduces latency by approximately 40% and energy consumption by 50%, while preserving domain-specific task performance when compared to single-LLM baselines.", "AI": {"tldr": "CALM\u662f\u4e00\u4e2a\u57fa\u4e8eMAPE-K\u7684\u81ea\u9002\u5e94\u7f16\u6392\u673a\u5236\uff0c\u901a\u8fc7\u534f\u8c03\u591a\u4e2a\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\uff08SLM\uff09\u7ec4\u6210\u7684\u8230\u961f\u6765\u52a8\u6001\u9002\u5e94\u8fd0\u884c\u65f6\u4e0d\u786e\u5b9a\u6027\uff0c\u76f8\u6bd4\u5355\u4e00LLM\u57fa\u7ebf\u964d\u4f4e40%\u5ef6\u8fdf\u548c50%\u80fd\u8017\u3002", "motivation": "AI\u7cfb\u7edf\u9762\u4e34\u8fd0\u884c\u65f6\u4e0d\u786e\u5b9a\u6027\uff08\u52a8\u6001\u5de5\u4f5c\u8d1f\u8f7d\u3001\u8d44\u6e90\u9700\u6c42\u3001\u6a21\u578b\u6f02\u79fb\u7b49\uff09\uff0c\u4e25\u91cd\u5f71\u54cdQoS\u3002LLM\u7cfb\u7edf\u5b58\u5728\u8d44\u6e90\u5bc6\u96c6\u6216\u9690\u79c1/\u6210\u672c\u95ee\u9898\uff0c\u800c\u5355\u4e2aSLM\u96be\u4ee5\u6ee1\u8db3\u591a\u6837\u5316\u9700\u6c42\u3002\u9700\u8981\u534f\u8c03\u591a\u4e2aSLM\u6765\u52a8\u6001\u9002\u5e94\u53d8\u5316\u3002", "method": "\u63d0\u51faCALM\uff1a\u57fa\u4e8eMAPE-K\u7684\u81ea\u9002\u5e94\u7f16\u6392\u673a\u5236\u3002\u6301\u7eed\u76d1\u63a7\u7528\u6237\u67e5\u8be2\uff0c\u5206\u6790\u5404SLM\u7684QoS\u6307\u6807\uff0c\u8bc6\u522b\u6700\u4f18SLM\uff0c\u8def\u7531\u67e5\u8be2\u5230\u9009\u5b9aSLM\uff0c\u5e76\u5229\u7528\u7f13\u5b58\u548c\u8c03\u5ea6\u51b3\u5b9a\u54ea\u4e9bSLM\u4fdd\u6301\u5728\u5185\u5b58\u4e2d\u3002", "result": "CALM\u76f8\u6bd4\u5355\u4e00LLM\u57fa\u7ebf\uff0c\u5ef6\u8fdf\u964d\u4f4e\u7ea640%\uff0c\u80fd\u8017\u964d\u4f4e50%\uff0c\u540c\u65f6\u4fdd\u6301\u9886\u57df\u7279\u5b9a\u4efb\u52a1\u6027\u80fd\u3002", "conclusion": "\u901a\u8fc7\u534f\u8c03\u591a\u4e2aSLM\u7ec4\u6210\u7684\u8230\u961f\uff0c\u7ed3\u5408\u667a\u80fd\u7f16\u6392\u548c\u6301\u7eed\u81ea\u9002\u5e94\uff0c\u53ef\u4ee5\u6709\u6548\u5e94\u5bf9AI\u7cfb\u7edf\u7684\u8fd0\u884c\u65f6\u4e0d\u786e\u5b9a\u6027\uff0c\u663e\u8457\u63d0\u5347QoS\uff08\u5ef6\u8fdf\u548c\u80fd\u8017\uff09\uff0c\u540c\u65f6\u4fdd\u6301\u4efb\u52a1\u6027\u80fd\u3002"}}
{"id": "2602.03712", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.03712", "abs": "https://arxiv.org/abs/2602.03712", "authors": ["Yisen Xu", "Jinqiu Yang", "Tse-Hsun", "Chen"], "title": "SWE-Refactor: A Repository-Level Benchmark for Real-World LLM-Based Code Refactoring", "comment": null, "summary": "Large Language Models (LLMs) have recently attracted wide interest for tackling software engineering tasks. In contrast to code generation, refactoring demands precise, semantics-preserving edits that improve program structure, which also makes automated evaluation challenging. However, existing refactoring benchmarks commonly suffer from three shortcomings: limited coverage of refactoring scenarios, the inclusion of instances that mix refactoring with unrelated changes, and insufficient repository-level context for realistic assessment. To mitigate these issues, we introduce SWE-Refactor, a new benchmark for LLM-based code refactoring. SWE-Refactor comprises 1,099 developer-written, behavior-preserving refactorings mined from 18 Java projects, including 922 atomic and 177 compound instances. Each instance is validated via compilation, test execution, and automated refactoring detection tools to ensure correctness. We evaluate nine widely used LLMs on SWE-Refactor, covering models such as GPT-4o-mini, DeepSeek-V3, and CodeLLaMa, to provide representative reference results. Our results show that complex and compound refactorings remain the primary source of failures; notably, an OpenAI Codex agent achieves only 39.4% success on compound instances. We release SWE-Refactor and all evaluation results to facilitate future research on LLM-based code refactoring.", "AI": {"tldr": "SWE-Refactor\u662f\u4e00\u4e2a\u65b0\u7684\u4ee3\u7801\u91cd\u6784\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b1,099\u4e2a\u5f00\u53d1\u8005\u7f16\u5199\u7684Java\u91cd\u6784\u5b9e\u4f8b\uff0c\u7528\u4e8e\u8bc4\u4f30LLM\u5728\u4ee3\u7801\u91cd\u6784\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u3002", "motivation": "\u73b0\u6709\u91cd\u6784\u57fa\u51c6\u6d4b\u8bd5\u5b58\u5728\u4e09\u4e2a\u4e3b\u8981\u95ee\u9898\uff1a\u91cd\u6784\u573a\u666f\u8986\u76d6\u6709\u9650\u3001\u5b9e\u4f8b\u4e2d\u6df7\u6742\u4e86\u4e0e\u91cd\u6784\u65e0\u5173\u7684\u4fee\u6539\u3001\u7f3a\u4e4f\u771f\u5b9e\u7684\u4ed3\u5e93\u7ea7\u4e0a\u4e0b\u6587\u8bc4\u4f30\u3002\u8fd9\u4e9b\u95ee\u9898\u9650\u5236\u4e86LLM\u5728\u4ee3\u7801\u91cd\u6784\u4efb\u52a1\u4e0a\u7684\u51c6\u786e\u8bc4\u4f30\u3002", "method": "\u4ece18\u4e2aJava\u9879\u76ee\u4e2d\u6316\u6398\u51fa1,099\u4e2a\u5f00\u53d1\u8005\u7f16\u5199\u7684\u3001\u884c\u4e3a\u4fdd\u6301\u7684\u91cd\u6784\u5b9e\u4f8b\uff08\u5305\u62ec922\u4e2a\u539f\u5b50\u91cd\u6784\u548c177\u4e2a\u590d\u5408\u91cd\u6784\uff09\uff0c\u901a\u8fc7\u7f16\u8bd1\u3001\u6d4b\u8bd5\u6267\u884c\u548c\u81ea\u52a8\u5316\u91cd\u6784\u68c0\u6d4b\u5de5\u5177\u9a8c\u8bc1\u6b63\u786e\u6027\uff0c\u7136\u540e\u8bc4\u4f309\u4e2a\u5e7f\u6cdb\u4f7f\u7528\u7684LLM\u6a21\u578b\u3002", "result": "\u8bc4\u4f30\u7ed3\u679c\u663e\u793a\uff0c\u590d\u6742\u548c\u590d\u5408\u91cd\u6784\u662f\u5931\u8d25\u7684\u4e3b\u8981\u6765\u6e90\uff0cOpenAI Codex\u4ee3\u7406\u5728\u590d\u5408\u5b9e\u4f8b\u4e0a\u4ec5\u8fbe\u523039.4%\u7684\u6210\u529f\u7387\u3002\u6a21\u578b\u5728\u539f\u5b50\u91cd\u6784\u4e0a\u8868\u73b0\u8f83\u597d\uff0c\u4f46\u5728\u590d\u6742\u573a\u666f\u4e2d\u4ecd\u6709\u663e\u8457\u6311\u6218\u3002", "conclusion": "SWE-Refactor\u57fa\u51c6\u6d4b\u8bd5\u89e3\u51b3\u4e86\u73b0\u6709\u91cd\u6784\u8bc4\u4f30\u7684\u4e0d\u8db3\uff0c\u4e3aLLM-based\u4ee3\u7801\u91cd\u6784\u7814\u7a76\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u7684\u8bc4\u4f30\u6846\u67b6\u3002\u590d\u6742\u91cd\u6784\u4ecd\u7136\u662fLLM\u9762\u4e34\u7684\u4e3b\u8981\u6311\u6218\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u6539\u8fdb\u3002"}}
{"id": "2602.03755", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.03755", "abs": "https://arxiv.org/abs/2602.03755", "authors": ["Facundo Molina", "M M Abid Naziri", "Feiran Qin", "Alessandra Gorla", "Marcelo d'Amorim"], "title": "Improving Deep Learning Library Testing with Machine Learning", "comment": "In proceedings of the 7th ACM/IEEE International Conference on Automation of Software Test (AST 2026)", "summary": "Deep Learning (DL) libraries like TensorFlow and Pytorch simplify machine learning (ML) model development but are prone to bugs due to their complex design. Bug-finding techniques exist, but without precise API specifications, they produce many false alarms. Existing methods to mine API specifications lack accuracy. We explore using ML classifiers to determine input validity. We hypothesize that tensor shapes are a precise abstraction to encode concrete inputs and capture relationships of the data. Shape abstraction severely reduces problem dimensionality, which is important to facilitate ML training. Labeled data are obtained by observing runtime outcomes on a sample of inputs and classifiers are trained on sets of labeled inputs to capture API constraints. Our evaluation, conducted over 183 APIs from TensorFlow and Pytorch, shows that the classifiers generalize well on unseen data with over 91% accuracy. Integrating these classifiers into the pipeline of ACETest, a SoTA bug-finding technique, improves its pass rate from ~29% to ~61%. Our findings suggest that ML-enhanced input classification is an important aid to scale DL library testing.", "AI": {"tldr": "\u4f7f\u7528\u673a\u5668\u5b66\u4e60\u5206\u7c7b\u5668\u5b66\u4e60\u6df1\u5ea6\u5b66\u4e60API\u7684\u8f93\u5165\u7ea6\u675f\uff0c\u901a\u8fc7\u5f20\u91cf\u5f62\u72b6\u62bd\u8c61\u964d\u4f4e\u95ee\u9898\u7ef4\u5ea6\uff0c\u63d0\u9ad8API\u89c4\u8303\u6316\u6398\u7cbe\u5ea6\uff0c\u663e\u8457\u63d0\u5347\u73b0\u6709bug\u68c0\u6d4b\u5de5\u5177\u7684\u6548\u679c\u3002", "motivation": "TensorFlow\u548cPyTorch\u7b49\u6df1\u5ea6\u5b66\u4e60\u5e93\u8bbe\u8ba1\u590d\u6742\u6613\u4ea7\u751fbug\uff0c\u73b0\u6709bug\u68c0\u6d4b\u6280\u672f\u56e0\u7f3a\u4e4f\u7cbe\u786eAPI\u89c4\u8303\u800c\u4ea7\u751f\u5927\u91cf\u8bef\u62a5\uff0c\u800c\u73b0\u6709\u7684API\u89c4\u8303\u6316\u6398\u65b9\u6cd5\u51c6\u786e\u6027\u4e0d\u8db3\u3002", "method": "\u63d0\u51fa\u4f7f\u7528ML\u5206\u7c7b\u5668\u5224\u65ad\u8f93\u5165\u6709\u6548\u6027\uff1a1) \u5047\u8bbe\u5f20\u91cf\u5f62\u72b6\u662f\u7f16\u7801\u5177\u4f53\u8f93\u5165\u548c\u6355\u83b7\u6570\u636e\u5173\u7cfb\u7684\u7cbe\u786e\u62bd\u8c61\uff1b2) \u5f62\u72b6\u62bd\u8c61\u5927\u5e45\u964d\u4f4e\u95ee\u9898\u7ef4\u5ea6\u4fbf\u4e8eML\u8bad\u7ec3\uff1b3) \u901a\u8fc7\u89c2\u5bdf\u8fd0\u884c\u65f6\u7ed3\u679c\u83b7\u53d6\u6807\u6ce8\u6570\u636e\uff1b4) \u5728\u6807\u6ce8\u8f93\u5165\u96c6\u4e0a\u8bad\u7ec3\u5206\u7c7b\u5668\u6355\u83b7API\u7ea6\u675f\u3002", "result": "\u5728TensorFlow\u548cPyTorch\u7684183\u4e2aAPI\u4e0a\u8bc4\u4f30\uff0c\u5206\u7c7b\u5668\u5728\u672a\u89c1\u6570\u636e\u4e0a\u6cdb\u5316\u80fd\u529b\u826f\u597d\uff0c\u51c6\u786e\u7387\u8d85\u8fc791%\u3002\u96c6\u6210\u5230ACETest\uff08\u6700\u5148\u8fdb\u7684bug\u68c0\u6d4b\u6280\u672f\uff09\u540e\uff0c\u5176\u901a\u8fc7\u7387\u4ece\u7ea629%\u63d0\u5347\u5230\u7ea661%\u3002", "conclusion": "ML\u589e\u5f3a\u7684\u8f93\u5165\u5206\u7c7b\u662f\u6269\u5c55\u6df1\u5ea6\u5b66\u4e60\u5e93\u6d4b\u8bd5\u7684\u91cd\u8981\u8f85\u52a9\u624b\u6bb5\uff0c\u80fd\u591f\u6709\u6548\u63d0\u9ad8API\u89c4\u8303\u6316\u6398\u7cbe\u5ea6\uff0c\u4ece\u800c\u63d0\u5347bug\u68c0\u6d4b\u5de5\u5177\u7684\u5b9e\u7528\u6027\u3002"}}
{"id": "2602.03798", "categories": ["cs.SE", "cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.03798", "abs": "https://arxiv.org/abs/2602.03798", "authors": ["Zimu Lu", "Houxing Ren", "Yunqiao Yang", "Ke Wang", "Zhuofan Zong", "Mingjie Zhan", "Hongsheng Li"], "title": "FullStack-Agent: Enhancing Agentic Full-Stack Web Coding via Development-Oriented Testing and Repository Back-Translation", "comment": null, "summary": "Assisting non-expert users to develop complex interactive websites has become a popular task for LLM-powered code agents. However, existing code agents tend to only generate frontend web pages, masking the lack of real full-stack data processing and storage with fancy visual effects. Notably, constructing production-level full-stack web applications is far more challenging than only generating frontend web pages, demanding careful control of data flow, comprehensive understanding of constantly updating packages and dependencies, and accurate localization of obscure bugs in the codebase. To address these difficulties, we introduce FullStack-Agent, a unified agent system for full-stack agentic coding that consists of three parts: (1) FullStack-Dev, a multi-agent framework with strong planning, code editing, codebase navigation, and bug localization abilities. (2) FullStack-Learn, an innovative data-scaling and self-improving method that back-translates crawled and synthesized website repositories to improve the backbone LLM of FullStack-Dev. (3) FullStack-Bench, a comprehensive benchmark that systematically tests the frontend, backend and database functionalities of the generated website. Our FullStack-Dev outperforms the previous state-of-the-art method by 8.7%, 38.2%, and 15.9% on the frontend, backend, and database test cases respectively. Additionally, FullStack-Learn raises the performance of a 30B model by 9.7%, 9.5%, and 2.8% on the three sets of test cases through self-improvement, demonstrating the effectiveness of our approach. The code is released at https://github.com/mnluzimu/FullStack-Agent.", "AI": {"tldr": "FullStack-Agent\u662f\u4e00\u4e2a\u7528\u4e8e\u5168\u6808Web\u5e94\u7528\u5f00\u53d1\u7684\u7edf\u4e00\u4ee3\u7406\u7cfb\u7edf\uff0c\u5305\u542b\u591a\u4ee3\u7406\u6846\u67b6\u3001\u6570\u636e\u6269\u5c55\u81ea\u5b66\u4e60\u65b9\u6cd5\u4ee5\u53ca\u5168\u6808\u57fa\u51c6\u6d4b\u8bd5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u524d\u7aef\u3001\u540e\u7aef\u548c\u6570\u636e\u5e93\u529f\u80fd\u7684\u751f\u6210\u8d28\u91cf\u3002", "motivation": "\u73b0\u6709LLM\u4ee3\u7801\u4ee3\u7406\u4e3b\u8981\u751f\u6210\u524d\u7aef\u7f51\u9875\uff0c\u7f3a\u4e4f\u771f\u6b63\u7684\u5168\u6808\u6570\u636e\u5904\u7406\u548c\u5b58\u50a8\u80fd\u529b\u3002\u6784\u5efa\u751f\u4ea7\u7ea7\u5168\u6808Web\u5e94\u7528\u6bd4\u4ec5\u751f\u6210\u524d\u7aef\u9875\u9762\u66f4\u5177\u6311\u6218\u6027\uff0c\u9700\u8981\u7cbe\u5fc3\u63a7\u5236\u6570\u636e\u6d41\u3001\u7406\u89e3\u4e0d\u65ad\u66f4\u65b0\u7684\u5305\u548c\u4f9d\u8d56\u5173\u7cfb\uff0c\u4ee5\u53ca\u51c6\u786e\u5b9a\u4f4d\u4ee3\u7801\u5e93\u4e2d\u7684\u9690\u853dbug\u3002", "method": "\u63d0\u51faFullStack-Agent\u7cfb\u7edf\uff0c\u5305\u542b\u4e09\u4e2a\u90e8\u5206\uff1a1) FullStack-Dev\uff1a\u5177\u6709\u5f3a\u5927\u89c4\u5212\u3001\u4ee3\u7801\u7f16\u8f91\u3001\u4ee3\u7801\u5e93\u5bfc\u822a\u548cbug\u5b9a\u4f4d\u80fd\u529b\u7684\u591a\u4ee3\u7406\u6846\u67b6\uff1b2) FullStack-Learn\uff1a\u901a\u8fc7\u53cd\u5411\u7ffb\u8bd1\u722c\u53d6\u548c\u5408\u6210\u7684\u7f51\u7ad9\u4ed3\u5e93\u6765\u6539\u8fdb\u9aa8\u5e72LLM\u7684\u521b\u65b0\u6570\u636e\u6269\u5c55\u548c\u81ea\u5b66\u4e60\u65b9\u6cd5\uff1b3) FullStack-Bench\uff1a\u7cfb\u7edf\u6d4b\u8bd5\u751f\u6210\u7f51\u7ad9\u524d\u7aef\u3001\u540e\u7aef\u548c\u6570\u636e\u5e93\u529f\u80fd\u7684\u7efc\u5408\u57fa\u51c6\u3002", "result": "FullStack-Dev\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u524d\u7aef\u3001\u540e\u7aef\u548c\u6570\u636e\u5e93\u6d4b\u8bd5\u7528\u4f8b\u5206\u522b\u6bd4\u5148\u524d\u6700\u5148\u8fdb\u65b9\u6cd5\u63d0\u5347\u4e868.7%\u300138.2%\u548c15.9%\u3002FullStack-Learn\u901a\u8fc7\u81ea\u6539\u8fdb\uff0c\u4f7f30B\u6a21\u578b\u5728\u4e09\u4e2a\u6d4b\u8bd5\u96c6\u4e0a\u7684\u6027\u80fd\u5206\u522b\u63d0\u5347\u4e869.7%\u30019.5%\u548c2.8%\u3002", "conclusion": "FullStack-Agent\u7cfb\u7edf\u6709\u6548\u89e3\u51b3\u4e86\u5168\u6808Web\u5e94\u7528\u5f00\u53d1\u7684\u6311\u6218\uff0c\u901a\u8fc7\u591a\u4ee3\u7406\u6846\u67b6\u3001\u6570\u636e\u9a71\u52a8\u7684\u81ea\u6539\u8fdb\u65b9\u6cd5\u548c\u5168\u9762\u57fa\u51c6\u6d4b\u8bd5\uff0c\u663e\u8457\u63d0\u5347\u4e86LLM\u5728\u5168\u6808\u7f16\u7801\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\u3002"}}
