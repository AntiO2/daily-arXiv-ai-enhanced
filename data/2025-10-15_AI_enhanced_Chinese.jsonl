{"id": "2510.11722", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.11722", "abs": "https://arxiv.org/abs/2510.11722", "authors": ["Haruhiko Yoshioka", "Kazumasa Shimari", "Hidetake Uwano", "Kenichi Matsumoto"], "title": "eye2vec: Learning Distributed Representations of Eye Movement for Program Comprehension Analysis", "comment": "2 pages, 1 figure, conference", "summary": "This paper presents eye2vec, an infrastructure for analyzing software\ndevelopers' eye movements while reading source code. In common eye-tracking\nstudies in program comprehension, researchers must preselect analysis targets\nsuch as control flow or syntactic elements, and then develop analysis methods\nto extract appropriate metrics from the fixation for source code. Here,\nresearchers can define various levels of AOIs like words, lines, or code\nblocks, and the difference leads to different results. Moreover, the\ninterpretation of fixation for word/line can vary across the purposes of the\nanalyses. Hence, the eye-tracking analysis is a difficult task that depends on\nthe time-consuming manual work of the researchers. eye2vec represents\ncontinuous two fixations as transitions between syntactic elements using\ndistributed representations. The distributed representation facilitates the\nadoption of diverse data analysis methods with rich semantic interpretations.", "AI": {"tldr": "eye2vec\u662f\u4e00\u4e2a\u5206\u6790\u8f6f\u4ef6\u5f00\u53d1\u8005\u5728\u9605\u8bfb\u6e90\u4ee3\u7801\u65f6\u773c\u52a8\u7684\u57fa\u7840\u8bbe\u65bd\uff0c\u4f7f\u7528\u5206\u5e03\u5f0f\u8868\u793a\u5c06\u8fde\u7eed\u6ce8\u89c6\u8868\u793a\u4e3a\u8bed\u6cd5\u5143\u7d20\u95f4\u7684\u8f6c\u6362\uff0c\u51cf\u5c11\u624b\u52a8\u5206\u6790\u5de5\u4f5c\u3002", "motivation": "\u4f20\u7edf\u773c\u52a8\u8ffd\u8e2a\u7814\u7a76\u9700\u8981\u7814\u7a76\u8005\u9884\u5148\u9009\u62e9\u5206\u6790\u76ee\u6807\u5e76\u5f00\u53d1\u5206\u6790\u65b9\u6cd5\uff0c\u4e0d\u540c\u7ea7\u522b\u7684\u5173\u6ce8\u533a\u57df\u5b9a\u4e49\u4f1a\u5bfc\u81f4\u4e0d\u540c\u7ed3\u679c\uff0c\u4e14\u5206\u6790\u8fc7\u7a0b\u4f9d\u8d56\u8017\u65f6\u7684\u624b\u52a8\u5de5\u4f5c\u3002", "method": "\u4f7f\u7528\u5206\u5e03\u5f0f\u8868\u793a\u5c06\u8fde\u7eed\u4e24\u4e2a\u6ce8\u89c6\u8868\u793a\u4e3a\u8bed\u6cd5\u5143\u7d20\u95f4\u7684\u8f6c\u6362\uff0c\u4fbf\u4e8e\u91c7\u7528\u591a\u6837\u5316\u7684\u6570\u636e\u5206\u6790\u65b9\u6cd5\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u591f\u66f4\u6709\u6548\u5730\u5206\u6790\u7a0b\u5e8f\u7406\u89e3\u8fc7\u7a0b\u4e2d\u7684\u773c\u52a8\u6570\u636e\uff0c\u63d0\u4f9b\u4e30\u5bcc\u7684\u8bed\u4e49\u89e3\u91ca\u3002", "conclusion": "eye2vec\u901a\u8fc7\u5206\u5e03\u5f0f\u8868\u793a\u7b80\u5316\u4e86\u8f6f\u4ef6\u5f00\u53d1\u8005\u773c\u52a8\u6570\u636e\u7684\u5206\u6790\u8fc7\u7a0b\uff0c\u63d0\u9ad8\u4e86\u5206\u6790\u6548\u7387\u548c\u8bed\u4e49\u4e30\u5bcc\u6027\u3002"}}
{"id": "2510.11813", "categories": ["cs.SE", "cs.CL", "cs.DB"], "pdf": "https://arxiv.org/pdf/2510.11813", "abs": "https://arxiv.org/abs/2510.11813", "authors": ["Marcus Emmanuel Barnes", "Taher A. Ghaleb", "Safwat Hassan"], "title": "Task-Aware Reduction for Scalable LLM-Database Systems", "comment": "Preprint. Accepted for presentation at the Workshop on Language\n  Models and Databases (LMD), co-located with CASCON 2025 (IEEE). The final\n  version will appear in IEEE Xplore", "summary": "Large Language Models (LLMs) are increasingly applied to data-intensive\nworkflows, from database querying to developer observability. Yet the\neffectiveness of these systems is constrained by the volume, verbosity, and\nnoise of real-world text-rich data such as logs, telemetry, and monitoring\nstreams. Feeding such data directly into LLMs is costly, environmentally\nunsustainable, and often misaligned with task objectives. Parallel efforts in\nLLM efficiency have focused on model- or architecture-level optimizations, but\nthe challenge of reducing upstream input verbosity remains underexplored. In\nthis paper, we argue for treating the token budget of an LLM as an attention\nbudget and elevating task-aware text reduction as a first-class design\nprinciple for language -- data systems. We position input-side reduction not as\ncompression, but as attention allocation: prioritizing information most\nrelevant to downstream tasks. We outline open research challenges for building\nbenchmarks, designing adaptive reduction pipelines, and integrating\ntoken-budget--aware preprocessing into database and retrieval systems. Our\nvision is to channel scarce attention resources toward meaningful signals in\nnoisy, data-intensive workflows, enabling scalable, accurate, and sustainable\nLLM--data integration.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5c06LLM\u7684token\u9884\u7b97\u89c6\u4e3a\u6ce8\u610f\u529b\u9884\u7b97\uff0c\u5c06\u4efb\u52a1\u611f\u77e5\u7684\u6587\u672c\u7f29\u51cf\u4f5c\u4e3a\u8bed\u8a00-\u6570\u636e\u7cfb\u7edf\u7684\u6838\u5fc3\u8bbe\u8ba1\u539f\u5219\uff0c\u4ee5\u89e3\u51b3\u6570\u636e\u5bc6\u96c6\u578b\u5de5\u4f5c\u6d41\u4e2d\u6587\u672c\u6570\u636e\u5197\u957f\u3001\u5608\u6742\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u4e2d\u7684\u6587\u672c\u5bc6\u96c6\u578b\u6570\u636e\uff08\u5982\u65e5\u5fd7\u3001\u9065\u6d4b\u6570\u636e\uff09\u901a\u5e38\u5197\u957f\u4e14\u5608\u6742\uff0c\u76f4\u63a5\u8f93\u5165LLM\u6210\u672c\u9ad8\u6602\u3001\u4e0d\u73af\u4fdd\u4e14\u4e0e\u4efb\u52a1\u76ee\u6807\u4e0d\u4e00\u81f4\u3002\u73b0\u6709LLM\u6548\u7387\u4f18\u5316\u4e3b\u8981\u5173\u6ce8\u6a21\u578b\u6216\u67b6\u6784\u5c42\u9762\uff0c\u800c\u8f93\u5165\u4fa7\u7f29\u51cf\u95ee\u9898\u5c1a\u672a\u5145\u5206\u63a2\u7d22\u3002", "method": "\u5c06\u8f93\u5165\u4fa7\u7f29\u51cf\u89c6\u4e3a\u6ce8\u610f\u529b\u5206\u914d\u800c\u975e\u538b\u7f29\uff0c\u4f18\u5148\u4fdd\u7559\u4e0e\u4e0b\u6e38\u4efb\u52a1\u6700\u76f8\u5173\u7684\u4fe1\u606f\u3002\u63d0\u51fa\u6784\u5efa\u57fa\u51c6\u6d4b\u8bd5\u3001\u8bbe\u8ba1\u81ea\u9002\u5e94\u7f29\u51cf\u7ba1\u9053\u3001\u5c06token\u9884\u7b97\u611f\u77e5\u9884\u5904\u7406\u96c6\u6210\u5230\u6570\u636e\u5e93\u548c\u68c0\u7d22\u7cfb\u7edf\u4e2d\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u7814\u7a76\u6846\u67b6\uff0c\u5c06\u6587\u672c\u7f29\u51cf\u4f5c\u4e3aLLM-\u6570\u636e\u96c6\u6210\u7cfb\u7edf\u7684\u6838\u5fc3\u7ec4\u4ef6\uff0c\u4ee5\u66f4\u6709\u6548\u5730\u5229\u7528\u6709\u9650\u7684\u6ce8\u610f\u529b\u8d44\u6e90\u3002", "conclusion": "\u901a\u8fc7\u5c06\u7a00\u7f3a\u7684\u6ce8\u610f\u529b\u8d44\u6e90\u5f15\u5bfc\u5230\u5608\u6742\u6570\u636e\u6d41\u4e2d\u7684\u6709\u610f\u4e49\u4fe1\u53f7\uff0c\u53ef\u4ee5\u5b9e\u73b0\u53ef\u6269\u5c55\u3001\u51c6\u786e\u548c\u53ef\u6301\u7eed\u7684LLM-\u6570\u636e\u96c6\u6210\u3002"}}
{"id": "2510.11838", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.11838", "abs": "https://arxiv.org/abs/2510.11838", "authors": ["Xu Yang", "Jiayuan Zhou", "Michael Pacheco", "Wenhan Zhu", "Pengfei He", "Shaowei Wang", "Kui Liu", "Ruiqi Pan"], "title": "Lingxi: Repository-Level Issue Resolution Framework Enhanced by Procedural Knowledge Guided Scaling", "comment": null, "summary": "Driven by the advancements of Large Language Models (LLMs), LLM-powered\nagents are making significant improvements in software engineering tasks, yet\nstruggle with complex, repository-level issue resolution. Existing agent-based\nmethods have two key limitations. First, they lack of procedural knowledge\n(i.e., how an issue is fixed step-by-step and rationales behind it) to learn\nand leverage for issue resolution. Second, they rely on massive computational\npower to blindly explore the solution space. % To address those limitations, we\npropose Lingxi, an issue resolution framework that leverages procedural\nknowledge extracted from historical issue-fixing data to guide agents in\nsolving repository-level issues. \\ourTool first constructs this knowledge\noffline through a hierarchical abstraction mechanism, enabling agents to learn\nthe how and why behind a fix, not just the final solution. During online\napplication, it employs a knowledge-driven scaling method that leverages the\nprocedural knowledge of similar issues to intelligently analyze the target\nissue from multiple perspectives, in sharp contrast to undirected, brute-force\nexploration. % Lingxi successfully resolves 74.6\\% of bugs on the SWE-bench\nVerified benchmark in Past@1 setting, outperforming five state-of-the-art\ntechniques by a significant margin (5.4\\% to 14.9\\%). Our comprehensive\nablation study confirmed that the success of Lingxi comes directly from its use\nof procedural knowledge. Without it, the performance gains from scaling alone\nis negligible. Our qualitative study further shows that the ``design patterns\n$\\&$ coding practices'' is the most critical knowledge aspect, and that the\nroles of different knowledge aspects switch across different stages (i.e.,\nanalysis, planning, and fixing).", "AI": {"tldr": "Lingxi\u662f\u4e00\u4e2a\u57fa\u4e8e\u5386\u53f2\u95ee\u9898\u4fee\u590d\u6570\u636e\u63d0\u53d6\u8fc7\u7a0b\u6027\u77e5\u8bc6\u7684\u8f6f\u4ef6\u95ee\u9898\u89e3\u51b3\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u5c42\u62bd\u8c61\u673a\u5236\u6784\u5efa\u77e5\u8bc6\uff0c\u6307\u5bfc\u667a\u80fd\u4f53\u89e3\u51b3\u4ed3\u5e93\u7ea7\u522b\u7684\u95ee\u9898\uff0c\u5728SWE-bench\u57fa\u51c6\u4e0a\u8fbe\u523074.6%\u7684\u6210\u529f\u7387\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8eLLM\u7684\u667a\u80fd\u4f53\u5728\u89e3\u51b3\u590d\u6742\u4ed3\u5e93\u7ea7\u522b\u95ee\u9898\u65f6\u5b58\u5728\u4e24\u4e2a\u5173\u952e\u9650\u5236\uff1a\u7f3a\u4e4f\u8fc7\u7a0b\u6027\u77e5\u8bc6\uff08\u95ee\u9898\u4fee\u590d\u7684\u6b65\u9aa4\u548c\u539f\u7406\uff09\u4ee5\u53ca\u4f9d\u8d56\u5927\u91cf\u8ba1\u7b97\u8d44\u6e90\u8fdb\u884c\u76f2\u76ee\u63a2\u7d22\u3002", "method": "Lingxi\u901a\u8fc7\u5206\u5c42\u62bd\u8c61\u673a\u5236\u79bb\u7ebf\u6784\u5efa\u8fc7\u7a0b\u6027\u77e5\u8bc6\uff0c\u8ba9\u667a\u80fd\u4f53\u5b66\u4e60\u4fee\u590d\u7684'\u5982\u4f55'\u548c'\u4e3a\u4ec0\u4e48'\uff1b\u5728\u7ebf\u5e94\u7528\u65f6\u91c7\u7528\u77e5\u8bc6\u9a71\u52a8\u7684\u6269\u5c55\u65b9\u6cd5\uff0c\u5229\u7528\u76f8\u4f3c\u95ee\u9898\u7684\u8fc7\u7a0b\u6027\u77e5\u8bc6\u4ece\u591a\u89d2\u5ea6\u667a\u80fd\u5206\u6790\u76ee\u6807\u95ee\u9898\u3002", "result": "\u5728SWE-bench Verified\u57fa\u51c6\u7684Past@1\u8bbe\u7f6e\u4e0b\uff0cLingxi\u6210\u529f\u89e3\u51b3\u4e8674.6%\u7684\u9519\u8bef\uff0c\u663e\u8457\u4f18\u4e8e\u4e94\u79cd\u6700\u5148\u8fdb\u6280\u672f\uff08\u9886\u51485.4%\u523014.9%\uff09\u3002\u6d88\u878d\u7814\u7a76\u786e\u8ba4\u6027\u80fd\u63d0\u5347\u76f4\u63a5\u6765\u81ea\u8fc7\u7a0b\u6027\u77e5\u8bc6\u7684\u4f7f\u7528\u3002", "conclusion": "\u8fc7\u7a0b\u6027\u77e5\u8bc6\u662fLingxi\u6210\u529f\u7684\u5173\u952e\uff0c\u5176\u4e2d'\u8bbe\u8ba1\u6a21\u5f0f\u548c\u7f16\u7801\u5b9e\u8df5'\u662f\u6700\u91cd\u8981\u7684\u77e5\u8bc6\u65b9\u9762\uff0c\u4e14\u4e0d\u540c\u77e5\u8bc6\u65b9\u9762\u5728\u4e0d\u540c\u9636\u6bb5\uff08\u5206\u6790\u3001\u89c4\u5212\u3001\u4fee\u590d\uff09\u7684\u4f5c\u7528\u4f1a\u5207\u6362\u3002"}}
{"id": "2510.11872", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.11872", "abs": "https://arxiv.org/abs/2510.11872", "authors": ["Alessandro Cornacchia", "Vaastav Anand", "Muhammad Bilal", "Zafar Qazi", "Marco Canini"], "title": "DMAS-Forge: A Framework for Transparent Deployment of AI Applications as Distributed Systems", "comment": "1st Workshop on Systems for Agentic AI (SAA '25)", "summary": "Agentic AI applications increasingly rely on multiple agents with distinct\nroles, specialized tools, and access to memory layers to solve complex tasks --\nclosely resembling service-oriented architectures. Yet, in the rapid evolving\nlandscape of programming frameworks and new protocols, deploying and testing AI\nagents as distributed systems remains a daunting and labor-intensive task. We\npresent DMAS-Forge, a framework designed to close this gap. DMAS-Forge\ndecouples application logic from specific deployment choices, and aims at\ntransparently generating the necessary glue code and configurations to spawn\ndistributed multi-agent applications across diverse deployment scenarios with\nminimal manual effort. We present our vision, design principles, and a\nprototype of DMAS-Forge. Finally, we discuss the opportunities and future work\nfor our approach.", "AI": {"tldr": "DMAS-Forge\u662f\u4e00\u4e2a\u6846\u67b6\uff0c\u65e8\u5728\u7b80\u5316\u5206\u5e03\u5f0f\u591a\u667a\u80fd\u4f53AI\u5e94\u7528\u7684\u90e8\u7f72\u548c\u6d4b\u8bd5\uff0c\u901a\u8fc7\u89e3\u8026\u5e94\u7528\u903b\u8f91\u4e0e\u90e8\u7f72\u9009\u62e9\uff0c\u81ea\u52a8\u751f\u6210\u5fc5\u8981\u7684\u8fde\u63a5\u4ee3\u7801\u548c\u914d\u7f6e\u3002", "motivation": "\u968f\u7740AI\u5e94\u7528\u8d8a\u6765\u8d8a\u4f9d\u8d56\u5177\u6709\u4e0d\u540c\u89d2\u8272\u3001\u4e13\u7528\u5de5\u5177\u548c\u5185\u5b58\u5c42\u7684\u591a\u4e2a\u667a\u80fd\u4f53\u6765\u89e3\u51b3\u590d\u6742\u4efb\u52a1\uff0c\u90e8\u7f72\u548c\u6d4b\u8bd5\u8fd9\u4e9b\u5206\u5e03\u5f0f\u7cfb\u7edf\u4ecd\u7136\u662f\u4e00\u9879\u8270\u5de8\u4e14\u52b3\u52a8\u5bc6\u96c6\u578b\u7684\u4efb\u52a1\u3002", "method": "DMAS-Forge\u6846\u67b6\u901a\u8fc7\u89e3\u8026\u5e94\u7528\u903b\u8f91\u4e0e\u5177\u4f53\u90e8\u7f72\u9009\u62e9\uff0c\u900f\u660e\u5730\u751f\u6210\u5fc5\u8981\u7684\u8fde\u63a5\u4ee3\u7801\u548c\u914d\u7f6e\uff0c\u4ee5\u6700\u5c0f\u7684\u624b\u52a8\u5de5\u4f5c\u5728\u5404\u79cd\u90e8\u7f72\u573a\u666f\u4e2d\u542f\u52a8\u5206\u5e03\u5f0f\u591a\u667a\u80fd\u4f53\u5e94\u7528\u3002", "result": "\u63d0\u51fa\u4e86DMAS-Forge\u7684\u613f\u666f\u3001\u8bbe\u8ba1\u539f\u5219\u548c\u539f\u578b\uff0c\u5c55\u793a\u4e86\u8be5\u6846\u67b6\u5982\u4f55\u7b80\u5316\u5206\u5e03\u5f0f\u591a\u667a\u80fd\u4f53AI\u5e94\u7528\u7684\u90e8\u7f72\u8fc7\u7a0b\u3002", "conclusion": "DMAS-Forge\u4e3a\u5206\u5e03\u5f0f\u591a\u667a\u80fd\u4f53AI\u5e94\u7528\u7684\u90e8\u7f72\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u8ba8\u8bba\u4e86\u8be5\u65b9\u6cd5\u7684\u673a\u9047\u548c\u672a\u6765\u5de5\u4f5c\u65b9\u5411\u3002"}}
{"id": "2510.12642", "categories": ["cs.DB", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.12642", "abs": "https://arxiv.org/abs/2510.12642", "authors": ["Meihui Zhang", "Liming Wang", "Chi Zhang", "Zhaojing Luo"], "title": "Aixel: A Unified, Adaptive and Extensible System for AI-powered Data Analysis", "comment": null, "summary": "A growing trend in modern data analysis is the integration of data management\nwith learning, guided by accuracy, latency, and cost requirements. In practice,\napplications draw data of different formats from many sources. In the\nmeanwhile, the objectives and budgets change over time. Existing systems handle\nthese applications across databases, analysis libraries, and tuning services.\nSuch fragmentation leads to complex user interaction, limited adaptability,\nsuboptimal performance, and poor extensibility across components. To address\nthese challenges, we present Aixel, a unified, adaptive, and extensible system\nfor AI-powered data analysis. The system organizes work across four layers:\napplication, task, model, and data. The task layer provides a declarative\ninterface to capture user intent, which is parsed into an executable operator\nplan. An optimizer compiles and schedules this plan to meet specified goals in\naccuracy, latency, and cost. The task layer coordinates the execution of data\nand model operators, with built-in support for reuse and caching to improve\nefficiency. The model layer offers versioned storage for index, metadata,\ntensors, and model artifacts. It supports adaptive construction, task-aligned\ndrift detection, and safe updates that reuse shared components. The data layer\nprovides unified data management capabilities, including indexing,\nconstraint-aware discovery, task-aligned selection, and comprehensive feature\nmanagement. With the above designed layers, Aixel delivers a user friendly,\nadaptive, efficient, and extensible system.", "AI": {"tldr": "Aixel\u662f\u4e00\u4e2a\u7edf\u4e00\u3001\u81ea\u9002\u5e94\u3001\u53ef\u6269\u5c55\u7684AI\u9a71\u52a8\u6570\u636e\u5206\u6790\u7cfb\u7edf\uff0c\u901a\u8fc7\u56db\u5c42\u67b6\u6784\u89e3\u51b3\u73b0\u6709\u7cfb\u7edf\u5728\u6570\u636e\u96c6\u6210\u3001\u5b66\u4e60\u4f18\u5316\u548c\u6210\u672c\u63a7\u5236\u65b9\u9762\u7684\u788e\u7247\u5316\u95ee\u9898\u3002", "motivation": "\u73b0\u4ee3\u6570\u636e\u5206\u6790\u9700\u8981\u96c6\u6210\u591a\u6e90\u5f02\u6784\u6570\u636e\uff0c\u540c\u65f6\u6ee1\u8db3\u51c6\u786e\u6027\u3001\u5ef6\u8fdf\u548c\u6210\u672c\u8981\u6c42\u3002\u73b0\u6709\u7cfb\u7edf\u5728\u6570\u636e\u5e93\u3001\u5206\u6790\u5e93\u548c\u8c03\u4f18\u670d\u52a1\u4e4b\u95f4\u5206\u6563\uff0c\u5bfc\u81f4\u7528\u6237\u4ea4\u4e92\u590d\u6742\u3001\u9002\u5e94\u6027\u6709\u9650\u3001\u6027\u80fd\u4e0d\u4f73\u548c\u7ec4\u4ef6\u6269\u5c55\u6027\u5dee\u3002", "method": "\u91c7\u7528\u56db\u5c42\u67b6\u6784\uff1a\u5e94\u7528\u5c42\u3001\u4efb\u52a1\u5c42\u3001\u6a21\u578b\u5c42\u548c\u6570\u636e\u5c42\u3002\u4efb\u52a1\u5c42\u63d0\u4f9b\u58f0\u660e\u5f0f\u63a5\u53e3\u6355\u83b7\u7528\u6237\u610f\u56fe\uff0c\u89e3\u6790\u4e3a\u53ef\u6267\u884c\u64cd\u4f5c\u8ba1\u5212\uff1b\u6a21\u578b\u5c42\u63d0\u4f9b\u7248\u672c\u5316\u5b58\u50a8\u548c\u81ea\u9002\u5e94\u6784\u5efa\uff1b\u6570\u636e\u5c42\u63d0\u4f9b\u7edf\u4e00\u6570\u636e\u7ba1\u7406\u80fd\u529b\u3002", "result": "Aixel\u7cfb\u7edf\u5b9e\u73b0\u4e86\u7528\u6237\u53cb\u597d\u3001\u81ea\u9002\u5e94\u3001\u9ad8\u6548\u548c\u53ef\u6269\u5c55\u7684\u6570\u636e\u5206\u6790\u5e73\u53f0\uff0c\u652f\u6301\u91cd\u7528\u3001\u7f13\u5b58\u548c\u7ec4\u4ef6\u5171\u4eab\u4ee5\u63d0\u9ad8\u6548\u7387\u3002", "conclusion": "Aixel\u901a\u8fc7\u7edf\u4e00\u7684\u591a\u5c42\u67b6\u6784\u8bbe\u8ba1\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u6570\u636e\u5206\u6790\u7cfb\u7edf\u7684\u788e\u7247\u5316\u95ee\u9898\uff0c\u4e3aAI\u9a71\u52a8\u7684\u6570\u636e\u5206\u6790\u63d0\u4f9b\u4e86\u66f4\u4f18\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.11938", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2510.11938", "abs": "https://arxiv.org/abs/2510.11938", "authors": ["Yanying Lin", "Shijie Peng", "Chengzhi Lu", "Chengzhong Xu", "Kejiang Ye"], "title": "FlexPipe: Adapting Dynamic LLM Serving Through Inflight Pipeline Refactoring in Fragmented Serverless Clusters", "comment": "EuroSys 26", "summary": "Serving Large Language Models (LLMs) in production faces significant\nchallenges from highly variable request patterns and severe resource\nfragmentation in serverless clusters. Current systems rely on static pipeline\nconfigurations that struggle to adapt to dynamic workload conditions, leading\nto substantial inefficiencies. We present FlexPipe, a novel system that\ndynamically reconfigures pipeline architectures during runtime to address these\nfundamental limitations. FlexPipe decomposes models into fine-grained stages\nand intelligently adjusts pipeline granularity based on real-time request\npattern analysis, implementing three key innovations: fine-grained model\npartitioning with preserved computational graph constraints, inflight pipeline\nrefactoring with consistent cache transitions, and topology-aware resource\nallocation that navigates GPU fragmentation. Comprehensive evaluation on an\n82-GPU cluster demonstrates that FlexPipe achieves up to 8.5x better resource\nefficiency while maintaining 38.3% lower latency compared to state-of-the-art\nsystems, reducing GPU reservation requirements from 75% to 30% of peak\ncapacity.", "AI": {"tldr": "FlexPipe\u662f\u4e00\u4e2a\u52a8\u6001\u91cd\u6784LLM\u670d\u52a1\u7ba1\u9053\u7684\u7cfb\u7edf\uff0c\u901a\u8fc7\u7ec6\u7c92\u5ea6\u6a21\u578b\u5212\u5206\u3001\u8fd0\u884c\u65f6\u7ba1\u9053\u91cd\u6784\u548c\u62d3\u6251\u611f\u77e5\u8d44\u6e90\u5206\u914d\uff0c\u663e\u8457\u63d0\u5347\u8d44\u6e90\u6548\u7387\u5e76\u964d\u4f4e\u5ef6\u8fdf\u3002", "motivation": "\u73b0\u6709LLM\u670d\u52a1\u7cfb\u7edf\u91c7\u7528\u9759\u6001\u7ba1\u9053\u914d\u7f6e\uff0c\u65e0\u6cd5\u9002\u5e94\u52a8\u6001\u5de5\u4f5c\u8d1f\u8f7d\u53d8\u5316\uff0c\u5bfc\u81f4\u8d44\u6e90\u6548\u7387\u4f4e\u4e0b\u548cGPU\u788e\u7247\u5316\u95ee\u9898\u4e25\u91cd\u3002", "method": "\u5c06\u6a21\u578b\u5206\u89e3\u4e3a\u7ec6\u7c92\u5ea6\u9636\u6bb5\uff0c\u57fa\u4e8e\u5b9e\u65f6\u8bf7\u6c42\u6a21\u5f0f\u5206\u6790\u667a\u80fd\u8c03\u6574\u7ba1\u9053\u7c92\u5ea6\uff0c\u5b9e\u73b0\u7ec6\u7c92\u5ea6\u6a21\u578b\u5212\u5206\u3001\u8fd0\u884c\u65f6\u7ba1\u9053\u91cd\u6784\u548c\u62d3\u6251\u611f\u77e5\u8d44\u6e90\u5206\u914d\u3002", "result": "\u572882-GPU\u96c6\u7fa4\u4e0a\u8bc4\u4f30\u663e\u793a\uff0cFlexPipe\u5b9e\u73b08.5\u500d\u8d44\u6e90\u6548\u7387\u63d0\u5347\uff0c\u5ef6\u8fdf\u964d\u4f4e38.3%\uff0cGPU\u9884\u7559\u9700\u6c42\u4ece\u5cf0\u503c\u5bb9\u91cf\u768475%\u964d\u81f330%\u3002", "conclusion": "FlexPipe\u901a\u8fc7\u52a8\u6001\u7ba1\u9053\u91cd\u6784\u6709\u6548\u89e3\u51b3\u4e86LLM\u670d\u52a1\u4e2d\u7684\u8d44\u6e90\u6548\u7387\u95ee\u9898\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u90e8\u7f72\u6210\u672c\u5e76\u63d0\u5347\u4e86\u670d\u52a1\u8d28\u91cf\u3002"}}
{"id": "2510.12011", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.12011", "abs": "https://arxiv.org/abs/2510.12011", "authors": ["Bei Zhou", "Maximilian Balmus", "Cesare Corrado", "Ludovica Cicci", "Shuang Qian", "Steven A. Niederer"], "title": "TorchCor: High-Performance Cardiac Electrophysiology Simulations with the Finite Element Method on GPUs", "comment": null, "summary": "Cardiac electrophysiology (CEP) simulations are increasingly used for\nunderstanding cardiac arrhythmias and guiding clinical decisions. However,\nthese simulations typically require high-performance computing resources with\nnumerous CPU cores, which are often inaccessible to many research groups and\nclinicians. To address this, we present TorchCor, a high-performance Python\nlibrary for CEP simulations using the finite element method on general-purpose\nGPUs. Built on PyTorch, TorchCor significantly accelerates CEP simulations,\nparticularly for large 3D meshes. The accuracy of the solver is verified\nagainst manufactured analytical solutions and the $N$-version benchmark\nproblem. TorchCor is freely available for both academic and commercial use\nwithout restrictions.", "AI": {"tldr": "TorchCor\u662f\u4e00\u4e2a\u57fa\u4e8ePyTorch\u7684\u9ad8\u6027\u80fdPython\u5e93\uff0c\u7528\u4e8e\u5728\u901a\u7528GPU\u4e0a\u8fdb\u884c\u5fc3\u810f\u7535\u751f\u7406\u5b66\u6709\u9650\u5143\u6a21\u62df\uff0c\u663e\u8457\u52a0\u901f\u4e86\u5927\u578b3D\u7f51\u683c\u7684CEP\u6a21\u62df\u3002", "motivation": "\u5fc3\u810f\u7535\u751f\u7406\u5b66\u6a21\u62df\u901a\u5e38\u9700\u8981\u9ad8\u6027\u80fd\u8ba1\u7b97\u8d44\u6e90\uff0c\u4f46\u8bb8\u591a\u7814\u7a76\u56e2\u961f\u548c\u4e34\u5e8a\u533b\u751f\u65e0\u6cd5\u83b7\u5f97\u8fd9\u4e9b\u8d44\u6e90\u3002", "method": "\u57fa\u4e8ePyTorch\u6784\u5efa\uff0c\u4f7f\u7528\u6709\u9650\u5143\u65b9\u6cd5\u5728\u901a\u7528GPU\u4e0a\u8fdb\u884cCEP\u6a21\u62df\u3002", "result": "TorchCor\u663e\u8457\u52a0\u901f\u4e86CEP\u6a21\u62df\uff0c\u7279\u522b\u662f\u5bf9\u4e8e\u5927\u578b3D\u7f51\u683c\uff0c\u5176\u6c42\u89e3\u5668\u7cbe\u5ea6\u901a\u8fc7\u5236\u9020\u5206\u6790\u89e3\u548cN\u7248\u672c\u57fa\u51c6\u95ee\u9898\u9a8c\u8bc1\u3002", "conclusion": "TorchCor\u662f\u4e00\u4e2a\u514d\u8d39\u4e14\u65e0\u4f7f\u7528\u9650\u5236\u7684\u9ad8\u6027\u80fdCEP\u6a21\u62df\u5e93\uff0c\u9002\u7528\u4e8e\u5b66\u672f\u548c\u5546\u4e1a\u7528\u9014\u3002"}}
{"id": "2510.12166", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2510.12166", "abs": "https://arxiv.org/abs/2510.12166", "authors": ["Kenneth Weiss", "Thomas M. Stitt", "Daryl Hawkins", "Olga Pearce", "Stephanie Brink", "Robert N. Rieben"], "title": "Comparing Cross-Platform Performance via Node-to-Node Scaling Studies", "comment": "16 pages; accepted to the International Journal of High Performance\n  Computing Applications (IJHPCA)", "summary": "Due to the increasing diversity of high-performance computing architectures,\nresearchers and practitioners are increasingly interested in comparing a code's\nperformance and scalability across different platforms. However, there is a\nlack of available guidance on how to actually set up and analyze such\ncross-platform studies. In this paper, we contend that the natural base unit of\ncomputing for such studies is a single compute node on each platform and offer\nguidance in setting up, running, and analyzing node-to-node scaling studies. We\npropose templates for presenting scaling results of these studies and provide\nseveral case studies highlighting the benefits of this approach.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4ee5\u5355\u4e2a\u8ba1\u7b97\u8282\u70b9\u4f5c\u4e3a\u8de8\u5e73\u53f0\u6027\u80fd\u6bd4\u8f83\u7684\u57fa\u7840\u5355\u4f4d\uff0c\u5e76\u63d0\u4f9b\u8282\u70b9\u5230\u8282\u70b9\u6269\u5c55\u7814\u7a76\u7684\u8bbe\u7f6e\u3001\u8fd0\u884c\u548c\u5206\u6790\u6307\u5357\u3002", "motivation": "\u7531\u4e8e\u9ad8\u6027\u80fd\u8ba1\u7b97\u67b6\u6784\u65e5\u76ca\u591a\u6837\u5316\uff0c\u7814\u7a76\u4eba\u5458\u9700\u8981\u8de8\u5e73\u53f0\u6bd4\u8f83\u4ee3\u7801\u6027\u80fd\u548c\u53ef\u6269\u5c55\u6027\uff0c\u4f46\u7f3a\u4e4f\u76f8\u5173\u6307\u5bfc\u3002", "method": "\u5c06\u5355\u4e2a\u8ba1\u7b97\u8282\u70b9\u4f5c\u4e3a\u8de8\u5e73\u53f0\u6bd4\u8f83\u7684\u57fa\u7840\u5355\u4f4d\uff0c\u63d0\u4f9b\u8282\u70b9\u5230\u8282\u70b9\u6269\u5c55\u7814\u7a76\u7684\u8bbe\u7f6e\u3001\u8fd0\u884c\u548c\u5206\u6790\u6307\u5357\uff0c\u5305\u62ec\u7ed3\u679c\u5c55\u793a\u6a21\u677f\u3002", "result": "\u901a\u8fc7\u591a\u4e2a\u6848\u4f8b\u7814\u7a76\u5c55\u793a\u4e86\u8fd9\u79cd\u65b9\u6cd5\u7684\u4f18\u52bf\u3002", "conclusion": "\u4ee5\u8282\u70b9\u4e3a\u57fa\u5143\u8fdb\u884c\u8de8\u5e73\u53f0\u6027\u80fd\u6bd4\u8f83\u662f\u6709\u6548\u7684\u65b9\u6cd5\uff0c\u4e3a\u7814\u7a76\u4eba\u5458\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u6307\u5bfc\u6846\u67b6\u3002"}}
{"id": "2510.12082", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.12082", "abs": "https://arxiv.org/abs/2510.12082", "authors": ["Huy Nguyen", "Christoph Treude", "Patanamon Thongtanunam"], "title": "Enhancing Neural Code Representation with Additional Context", "comment": "34 pages, 7 figures, 11 tables", "summary": "Automated program comprehension underpins many software engineering tasks,\nfrom code summarisation to clone detection. Recent deep learning models achieve\nstrong results but typically rely on source code alone, overlooking contextual\ninformation such as version history or structural relationships. This limits\ntheir ability to capture how code evolves and operates. We conduct an empirical\nstudy on how enriching code representations with such contextual signals\naffects neural model performance on key comprehension tasks. Two downstream\ntasks, code clone detection and code summarisation, are evaluated using SeSaMe\n(1,679 Java methods) and CodeSearchNet (63,259 methods). Five representative\nmodels (CodeBERT, GraphCodeBERT, CodeT5, PLBART, ASTNN) are fine-tuned under\ncode-only and context-augmented settings. Results show that context generally\nimproves performance: version history consistently boosts clone detection\n(e.g., CodeT5 +15.92% F1) and summarisation (e.g., GraphCodeBERT +5.56%\nMETEOR), while call-graph effects vary by model and task. Combining multiple\ncontexts yields further gains (up to +21.48% macro-F1). Human evaluation on 100\nJava snippets confirms that context-augmented summaries are significantly\npreferred for Accuracy and Content Adequacy (p <= 0.026; |delta| up to 0.55).\nThese findings highlight the potential of contextual signals to enhance code\ncomprehension and open new directions for optimising contextual encoding in\nneural SE models.", "AI": {"tldr": "\u8be5\u8bba\u6587\u901a\u8fc7\u5b9e\u8bc1\u7814\u7a76\u8bc1\u660e\uff0c\u5728\u4ee3\u7801\u8868\u793a\u4e2d\u878d\u5165\u4e0a\u4e0b\u6587\u4fe1\u606f\uff08\u5982\u7248\u672c\u5386\u53f2\u548c\u8c03\u7528\u56fe\uff09\u80fd\u663e\u8457\u63d0\u5347\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728\u4ee3\u7801\u514b\u9686\u68c0\u6d4b\u548c\u4ee3\u7801\u6458\u8981\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u4e3b\u8981\u4f9d\u8d56\u6e90\u4ee3\u7801\u672c\u8eab\uff0c\u5ffd\u7565\u4e86\u7248\u672c\u5386\u53f2\u548c\u7ed3\u6784\u5173\u7cfb\u7b49\u4e0a\u4e0b\u6587\u4fe1\u606f\uff0c\u9650\u5236\u4e86\u6a21\u578b\u7406\u89e3\u4ee3\u7801\u6f14\u53d8\u548c\u8fd0\u884c\u65b9\u5f0f\u7684\u80fd\u529b\u3002", "method": "\u5728\u4e24\u4e2a\u6570\u636e\u96c6\uff08SeSaMe\u548cCodeSearchNet\uff09\u4e0a\u8bc4\u4f30\u4e94\u4e2a\u4ee3\u8868\u6027\u6a21\u578b\uff08CodeBERT\u3001GraphCodeBERT\u3001CodeT5\u3001PLBART\u3001ASTNN\uff09\uff0c\u6bd4\u8f83\u4ec5\u4f7f\u7528\u4ee3\u7801\u548c\u4f7f\u7528\u4e0a\u4e0b\u6587\u589e\u5f3a\u8bbe\u7f6e\u4e0b\u7684\u6027\u80fd\u3002", "result": "\u4e0a\u4e0b\u6587\u4fe1\u606f\u666e\u904d\u63d0\u5347\u6a21\u578b\u6027\u80fd\uff1a\u7248\u672c\u5386\u53f2\u6301\u7eed\u63d0\u5347\u514b\u9686\u68c0\u6d4b\uff08\u5982CodeT5 F1\u63d0\u534715.92%\uff09\u548c\u4ee3\u7801\u6458\u8981\uff08\u5982GraphCodeBERT METEOR\u63d0\u53475.56%\uff09\uff0c\u8c03\u7528\u56fe\u6548\u679c\u56e0\u6a21\u578b\u548c\u4efb\u52a1\u800c\u5f02\u3002\u591a\u4e0a\u4e0b\u6587\u7ec4\u5408\u5e26\u6765\u66f4\u5927\u589e\u76ca\uff08\u6700\u9ad8\u63d0\u534721.48% macro-F1\uff09\u3002", "conclusion": "\u4e0a\u4e0b\u6587\u4fe1\u53f7\u6709\u6f5c\u529b\u663e\u8457\u589e\u5f3a\u4ee3\u7801\u7406\u89e3\u80fd\u529b\uff0c\u4e3a\u4f18\u5316\u795e\u7ecf\u8f6f\u4ef6\u5de5\u7a0b\u6a21\u578b\u4e2d\u7684\u4e0a\u4e0b\u6587\u7f16\u7801\u5f00\u8f9f\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2510.12196", "categories": ["cs.DC", "8W10"], "pdf": "https://arxiv.org/pdf/2510.12196", "abs": "https://arxiv.org/abs/2510.12196", "authors": ["Petr Samoldekin", "Christian Schulz", "Henning Woydt"], "title": "GPU-Accelerated Algorithms for Process Mapping", "comment": null, "summary": "Process mapping asks to assign vertices of a task graph to processing\nelements of a supercomputer such that the computational workload is balanced\nwhile the communication cost is minimized. Motivated by the recent success of\nGPU-based graph partitioners, we propose two GPU-accelerated algorithms for\nthis optimization problem. The first algorithm employs hierarchical\nmultisection, which partitions the task graph alongside the hierarchy of the\nsupercomputer. The method utilizes GPU-based graph partitioners to accelerate\nthe mapping process. The second algorithm integrates process mapping directly\ninto the modern multilevel graph partitioning pipeline. Vital phases like\ncoarsening and refinement are accelerated by exploiting the parallelism of\nGPUs. In our experiments, both methods achieve speedups exceeding 300 when\ncompared to state-of-the-art CPU-based algorithms. The first algorithm has, on\naverage, about 10 percent greater communication costs and thus remains\ncompetitive to CPU algorithms. The second approach is much faster, with a\ngeometric mean speedup of 77.6 and peak speedup of 598 at the cost of lower\nsolution quality. To our knowledge, these are the first GPU-based algorithms\nfor process mapping.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e24\u79cdGPU\u52a0\u901f\u7684\u8fdb\u7a0b\u6620\u5c04\u7b97\u6cd5\uff0c\u5206\u522b\u91c7\u7528\u5c42\u6b21\u591a\u5206\u5272\u548c\u73b0\u4ee3\u591a\u7ea7\u56fe\u5212\u5206\u6d41\u6c34\u7ebf\uff0c\u76f8\u6bd4CPU\u7b97\u6cd5\u83b7\u5f97\u8d85\u8fc7300\u500d\u7684\u52a0\u901f\u6bd4\u3002", "motivation": "\u53d7GPU\u56fe\u5212\u5206\u5668\u8fd1\u671f\u6210\u529f\u7684\u542f\u53d1\uff0c\u4e3a\u8d85\u7ea7\u8ba1\u7b97\u673a\u4e2d\u7684\u8fdb\u7a0b\u6620\u5c04\u95ee\u9898\u5f00\u53d1GPU\u52a0\u901f\u7b97\u6cd5\uff0c\u4ee5\u5e73\u8861\u8ba1\u7b97\u8d1f\u8f7d\u5e76\u6700\u5c0f\u5316\u901a\u4fe1\u6210\u672c\u3002", "method": "\u7b2c\u4e00\u79cd\u7b97\u6cd5\u91c7\u7528\u5c42\u6b21\u591a\u5206\u5272\uff0c\u6cbf\u8d85\u7ea7\u8ba1\u7b97\u673a\u5c42\u6b21\u7ed3\u6784\u5212\u5206\u4efb\u52a1\u56fe\uff1b\u7b2c\u4e8c\u79cd\u7b97\u6cd5\u5c06\u8fdb\u7a0b\u6620\u5c04\u76f4\u63a5\u96c6\u6210\u5230\u73b0\u4ee3\u591a\u7ea7\u56fe\u5212\u5206\u6d41\u6c34\u7ebf\u4e2d\uff0c\u5229\u7528GPU\u5e76\u884c\u6027\u52a0\u901f\u5173\u952e\u9636\u6bb5\u3002", "result": "\u4e24\u79cd\u65b9\u6cd5\u76f8\u6bd4\u6700\u5148\u8fdb\u7684CPU\u7b97\u6cd5\u83b7\u5f97\u8d85\u8fc7300\u500d\u7684\u52a0\u901f\u6bd4\u3002\u7b2c\u4e00\u79cd\u7b97\u6cd5\u901a\u4fe1\u6210\u672c\u5e73\u5747\u589e\u52a0\u7ea610%\uff0c\u7b2c\u4e8c\u79cd\u7b97\u6cd5\u51e0\u4f55\u5e73\u5747\u52a0\u901f\u6bd4\u4e3a77.6\u500d\uff0c\u5cf0\u503c\u8fbe598\u500d\uff0c\u4f46\u89e3\u8d28\u91cf\u8f83\u4f4e\u3002", "conclusion": "\u8fd9\u662f\u9996\u4e2a\u57fa\u4e8eGPU\u7684\u8fdb\u7a0b\u6620\u5c04\u7b97\u6cd5\uff0c\u5728\u4fdd\u6301\u7ade\u4e89\u529b\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u4e86\u8ba1\u7b97\u6548\u7387\u3002"}}
{"id": "2510.12120", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.12120", "abs": "https://arxiv.org/abs/2510.12120", "authors": ["Zhenyu Mao", "Jacky Keung", "Fengji Zhang", "Shuo Liu", "Yifei Wang", "Jialong Li"], "title": "Towards Engineering Multi-Agent LLMs: A Protocol-Driven Approach", "comment": null, "summary": "The increasing demand for software development has driven interest in\nautomating software engineering (SE) tasks using Large Language Models (LLMs).\nRecent efforts extend LLMs into multi-agent systems (MAS) that emulate\ncollaborative development workflows, but these systems often fail due to three\ncore deficiencies: under-specification, coordination misalignment, and\ninappropriate verification, arising from the absence of foundational SE\nstructuring principles. This paper introduces Software Engineering Multi-Agent\nProtocol (SEMAP), a protocol-layer methodology that instantiates three core SE\ndesign principles for multi-agent LLMs: (1) explicit behavioral contract\nmodeling, (2) structured messaging, and (3) lifecycle-guided execution with\nverification, and is implemented atop Google's Agent-to-Agent (A2A)\ninfrastructure. Empirical evaluation using the Multi-Agent System Failure\nTaxonomy (MAST) framework demonstrates that SEMAP effectively reduces failures\nacross different SE tasks. In code development, it achieves up to a 69.6%\nreduction in total failures for function-level development and 56.7% for\ndeployment-level development. For vulnerability detection, SEMAP reduces\nfailure counts by up to 47.4% on Python tasks and 28.2% on C/C++ tasks.", "AI": {"tldr": "SEMAP\u662f\u4e00\u4e2a\u534f\u8bae\u5c42\u65b9\u6cd5\uff0c\u901a\u8fc7\u4e09\u4e2a\u6838\u5fc3\u8f6f\u4ef6\u5de5\u7a0b\u8bbe\u8ba1\u539f\u5219\u6765\u6539\u8fdb\u591a\u667a\u80fd\u4f53LLM\u7cfb\u7edf\uff1a\u660e\u786e\u884c\u4e3a\u5951\u7ea6\u5efa\u6a21\u3001\u7ed3\u6784\u5316\u6d88\u606f\u4f20\u9012\u3001\u751f\u547d\u5468\u671f\u5f15\u5bfc\u6267\u884c\u4e0e\u9a8c\u8bc1\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u8f6f\u4ef6\u5f00\u53d1\u4efb\u52a1\u4e2d\u7684\u5931\u8d25\u7387\u3002", "motivation": "\u73b0\u6709\u7684\u591a\u667a\u80fd\u4f53LLM\u7cfb\u7edf\u5728\u6a21\u62df\u534f\u4f5c\u5f00\u53d1\u5de5\u4f5c\u6d41\u65f6\u7ecf\u5e38\u5931\u8d25\uff0c\u4e3b\u8981\u7531\u4e8e\u7f3a\u4e4f\u57fa\u7840\u8f6f\u4ef6\u5de5\u7a0b\u7ed3\u6784\u5316\u539f\u5219\u5bfc\u81f4\u7684\u4e09\u4e2a\u6838\u5fc3\u7f3a\u9677\uff1a\u89c4\u8303\u4e0d\u8db3\u3001\u534f\u8c03\u9519\u4f4d\u548c\u4e0d\u9002\u5f53\u7684\u9a8c\u8bc1\u3002", "method": "\u63d0\u51faSEMAP\u534f\u8bae\uff0c\u57fa\u4e8eGoogle\u7684A2A\u57fa\u7840\u8bbe\u65bd\u5b9e\u73b0\u4e09\u4e2a\u6838\u5fc3SE\u8bbe\u8ba1\u539f\u5219\uff1a\u660e\u786e\u884c\u4e3a\u5951\u7ea6\u5efa\u6a21\u3001\u7ed3\u6784\u5316\u6d88\u606f\u4f20\u9012\u3001\u751f\u547d\u5468\u671f\u5f15\u5bfc\u6267\u884c\u4e0e\u9a8c\u8bc1\u3002", "result": "\u5728\u4ee3\u7801\u5f00\u53d1\u4e2d\uff0c\u51fd\u6570\u7ea7\u5f00\u53d1\u603b\u5931\u8d25\u7387\u964d\u4f4e69.6%\uff0c\u90e8\u7f72\u7ea7\u5f00\u53d1\u964d\u4f4e56.7%\uff1b\u5728\u6f0f\u6d1e\u68c0\u6d4b\u4e2d\uff0cPython\u4efb\u52a1\u5931\u8d25\u51cf\u5c1147.4%\uff0cC/C++\u4efb\u52a1\u51cf\u5c1128.2%\u3002", "conclusion": "SEMAP\u901a\u8fc7\u5f15\u5165\u8f6f\u4ef6\u5de5\u7a0b\u7ed3\u6784\u5316\u539f\u5219\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u591a\u667a\u80fd\u4f53LLM\u7cfb\u7edf\u7684\u6838\u5fc3\u7f3a\u9677\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8f6f\u4ef6\u5f00\u53d1\u4efb\u52a1\u7684\u6027\u80fd\u548c\u53ef\u9760\u6027\u3002"}}
{"id": "2510.12274", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2510.12274", "abs": "https://arxiv.org/abs/2510.12274", "authors": ["Hao Jiang", "Meng Qin", "Ruijie Kuai", "Dandan Liang"], "title": "Metronome: Efficient Scheduling for Periodic Traffic Jobs with Network and Priority Awareness", "comment": "16 pages, 16 figures. This work has been submitted to the IEEE for\n  possible publication", "summary": "With the rapid growth in computing power demand, cloud native networks have\nemerged as a promising solution to address the challenges of efficient resource\ncoordination, particularly in coping with the dynamic fluctuations of network\nbandwidth in clusters. We propose Metronome, a network-aware and priority-aware\nscheduling mechanism for cloud native networks. This mechanism is designed to\nsupport jobs that exhibit periodic traffic patterns and dynamic bandwidth\ndemands, particularly in the context of distributed training. Specifically,\nMetronome employs a time-division multiplexing approach that leverages job\ntraffic characteristics to construct an elastic network resource allocation\nmodel, enabling efficient bandwidth sharing across multiple jobs. In addition,\nit incorporates a multi-objective optimization strategy, jointly considering\nlatency and job priorities to achieve globally optimal as well as dynamic\nresource allocation. Finally, Metronome adapts to the dynamic environment by\nmonitoring the cluster and performing reconfiguration operations. Extensive\nexperiments with 13 common machine learning models demonstrate that Metronome\ncan enhance cluster resource utilization while guaranteeing service\nperformance. Compared with the existing Kubernetes scheduling mechanisms across\nmultiple scenarios, Metronome reduces job completion time by up to 19.50% while\nimproving average bandwidth utilization by up to 23.20%.", "AI": {"tldr": "Metronome\u662f\u4e00\u79cd\u9762\u5411\u4e91\u539f\u751f\u7f51\u7edc\u7684\u7f51\u7edc\u611f\u77e5\u548c\u4f18\u5148\u7ea7\u611f\u77e5\u8c03\u5ea6\u673a\u5236\uff0c\u9488\u5bf9\u5177\u6709\u5468\u671f\u6027\u6d41\u91cf\u6a21\u5f0f\u548c\u52a8\u6001\u5e26\u5bbd\u9700\u6c42\u7684\u5206\u5e03\u5f0f\u8bad\u7ec3\u4f5c\u4e1a\uff0c\u901a\u8fc7\u65f6\u5206\u590d\u7528\u548c\u5f39\u6027\u7f51\u7edc\u8d44\u6e90\u5206\u914d\u6a21\u578b\uff0c\u63d0\u5347\u96c6\u7fa4\u8d44\u6e90\u5229\u7528\u7387\u548c\u4f5c\u4e1a\u5b8c\u6210\u6548\u7387\u3002", "motivation": "\u968f\u7740\u8ba1\u7b97\u9700\u6c42\u5feb\u901f\u589e\u957f\uff0c\u4e91\u539f\u751f\u7f51\u7edc\u9700\u8981\u89e3\u51b3\u9ad8\u6548\u8d44\u6e90\u534f\u8c03\u7684\u6311\u6218\uff0c\u7279\u522b\u662f\u5e94\u5bf9\u96c6\u7fa4\u4e2d\u7f51\u7edc\u5e26\u5bbd\u52a8\u6001\u6ce2\u52a8\u7684\u95ee\u9898\u3002\u73b0\u6709\u8c03\u5ea6\u673a\u5236\u96be\u4ee5\u6709\u6548\u5904\u7406\u5206\u5e03\u5f0f\u8bad\u7ec3\u4f5c\u4e1a\u7684\u5468\u671f\u6027\u6d41\u91cf\u7279\u5f81\u548c\u52a8\u6001\u5e26\u5bbd\u9700\u6c42\u3002", "method": "\u91c7\u7528\u65f6\u5206\u590d\u7528\u65b9\u6cd5\uff0c\u5229\u7528\u4f5c\u4e1a\u6d41\u91cf\u7279\u5f81\u6784\u5efa\u5f39\u6027\u7f51\u7edc\u8d44\u6e90\u5206\u914d\u6a21\u578b\uff1b\u7ed3\u5408\u591a\u76ee\u6807\u4f18\u5316\u7b56\u7565\uff0c\u540c\u65f6\u8003\u8651\u5ef6\u8fdf\u548c\u4f5c\u4e1a\u4f18\u5148\u7ea7\uff1b\u901a\u8fc7\u76d1\u63a7\u96c6\u7fa4\u72b6\u6001\u8fdb\u884c\u52a8\u6001\u91cd\u914d\u7f6e\u3002", "result": "\u572813\u4e2a\u5e38\u89c1\u673a\u5668\u5b66\u4e60\u6a21\u578b\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u76f8\u6bd4\u73b0\u6709Kubernetes\u8c03\u5ea6\u673a\u5236\uff0cMetronome\u53ef\u5c06\u4f5c\u4e1a\u5b8c\u6210\u65f6\u95f4\u6700\u591a\u51cf\u5c1119.50%\uff0c\u5e73\u5747\u5e26\u5bbd\u5229\u7528\u7387\u6700\u591a\u63d0\u534723.20%\u3002", "conclusion": "Metronome\u80fd\u591f\u6709\u6548\u63d0\u5347\u96c6\u7fa4\u8d44\u6e90\u5229\u7528\u7387\u5e76\u4fdd\u8bc1\u670d\u52a1\u6027\u80fd\uff0c\u4e3a\u4e91\u539f\u751f\u7f51\u7edc\u4e2d\u5177\u6709\u5468\u671f\u6027\u6d41\u91cf\u7279\u5f81\u7684\u4f5c\u4e1a\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u8c03\u5ea6\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.12186", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.12186", "abs": "https://arxiv.org/abs/2510.12186", "authors": ["Yun Peng", "Kisub Kim", "Linghan Meng", "Kui Liu"], "title": "iCodeReviewer: Improving Secure Code Review with Mixture of Prompts", "comment": null, "summary": "Code review is an essential process to ensure the quality of software that\nidentifies potential software issues at an early stage of software development.\nAmong all software issues, security issues are the most important to identify,\nas they can easily lead to severe software crashes and service disruptions.\nRecent research efforts have been devoted to automated approaches to reduce the\nmanual efforts required in the secure code review process. Despite the\nprogress, current automated approaches on secure code review, including static\nanalysis, deep learning models, and prompting approaches, still face the\nchallenges of limited precision and coverage, and a lack of comprehensive\nevaluation.\n  To mitigate these challenges, we propose iCodeReviewer, which is an automated\nsecure code review approach based on large language models (LLMs).\niCodeReviewer leverages a novel mixture-of-prompts architecture that\nincorporates many prompt experts to improve the coverage of security issues.\nEach prompt expert is a dynamic prompt pipeline to check the existence of a\nspecific security issue. iCodeReviewer also implements an effective routing\nalgorithm to activate only necessary prompt experts based on the code features\nin the input program, reducing the false positives induced by LLM\nhallucination. Experiment results in our internal dataset demonstrate the\neffectiveness of iCodeReviewer in security issue identification and\nlocalization with an F1 of 63.98%. The review comments generated by\niCodeReviewer also achieve a high acceptance rate up to 84% when it is deployed\nin production environments.", "AI": {"tldr": "iCodeReviewer\u662f\u4e00\u79cd\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u81ea\u52a8\u5316\u5b89\u5168\u4ee3\u7801\u5ba1\u67e5\u65b9\u6cd5\uff0c\u901a\u8fc7\u6df7\u5408\u63d0\u793a\u67b6\u6784\u548c\u8def\u7531\u7b97\u6cd5\u63d0\u9ad8\u5b89\u5168\u95ee\u9898\u7684\u8986\u76d6\u7387\u548c\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u81ea\u52a8\u5316\u5b89\u5168\u4ee3\u7801\u5ba1\u67e5\u65b9\u6cd5\uff08\u5982\u9759\u6001\u5206\u6790\u3001\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u548c\u63d0\u793a\u65b9\u6cd5\uff09\u5b58\u5728\u7cbe\u5ea6\u548c\u8986\u76d6\u7387\u6709\u9650\u3001\u7f3a\u4e4f\u5168\u9762\u8bc4\u4f30\u7684\u95ee\u9898\uff0c\u9700\u8981\u66f4\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6df7\u5408\u63d0\u793a\u67b6\u6784\uff0c\u5305\u542b\u591a\u4e2a\u52a8\u6001\u63d0\u793a\u4e13\u5bb6\u7ba1\u9053\u6765\u68c0\u67e5\u7279\u5b9a\u5b89\u5168\u95ee\u9898\uff0c\u5e76\u901a\u8fc7\u8def\u7531\u7b97\u6cd5\u57fa\u4e8e\u4ee3\u7801\u7279\u5f81\u6fc0\u6d3b\u5fc5\u8981\u4e13\u5bb6\u4ee5\u51cf\u5c11\u8bef\u62a5\u3002", "result": "\u5728\u5185\u90e8\u6570\u636e\u96c6\u4e0a\u5b9e\u73b063.98%\u7684F1\u5206\u6570\uff0c\u5728\u751f\u4ea7\u73af\u5883\u4e2d\u751f\u6210\u7684\u5ba1\u67e5\u8bc4\u8bba\u63a5\u53d7\u7387\u9ad8\u8fbe84%\u3002", "conclusion": "iCodeReviewer\u901a\u8fc7\u521b\u65b0\u7684\u6df7\u5408\u63d0\u793a\u67b6\u6784\u548c\u8def\u7531\u7b97\u6cd5\uff0c\u5728\u5b89\u5168\u4ee3\u7801\u5ba1\u67e5\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u80fd\u591f\u6709\u6548\u8bc6\u522b\u548c\u5b9a\u4f4d\u5b89\u5168\u95ee\u9898\u3002"}}
{"id": "2510.12354", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2510.12354", "abs": "https://arxiv.org/abs/2510.12354", "authors": ["Sepideh Masoudi", "Mark Edward Michael Daly", "Jannis Kiesel", "Stefan Tai"], "title": "A Non-Intrusive Framework for Deferred Integration of Cloud Patterns in Energy-Efficient Data-Sharing Pipelines", "comment": null, "summary": "As data mesh architectures gain traction in federated environments,\norganizations are increasingly building consumer-specific data-sharing\npipelines using modular, cloud-native transformation services. Prior work has\nshown that structuring these pipelines with reusable transformation stages\nenhances both scalability and energy efficiency. However, integrating\ntraditional cloud design patterns into such pipelines poses a challenge:\npredefining and embedding patterns can compromise modularity, reduce\nreusability, and conflict with the pipelines dynamic, consumer-driven nature.\nTo address this, we introduce a Kubernetes-based tool that enables the deferred\nand non-intrusive application of selected cloud design patterns without\nrequiring changes to service source code. The tool supports automated pattern\ninjection and collects energy consumption metrics, allowing developers to make\nenergy-aware decisions while preserving the flexible, composable structure of\nreusable data-sharing pipelines.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eKubernetes\u7684\u5de5\u5177\uff0c\u652f\u6301\u5728\u6570\u636e\u5171\u4eab\u7ba1\u9053\u4e2d\u5ef6\u8fdf\u3001\u975e\u4fb5\u5165\u5f0f\u5730\u5e94\u7528\u4e91\u8bbe\u8ba1\u6a21\u5f0f\uff0c\u65e0\u9700\u4fee\u6539\u670d\u52a1\u6e90\u4ee3\u7801\uff0c\u540c\u65f6\u6536\u96c6\u80fd\u8017\u6307\u6807\u4ee5\u652f\u6301\u80fd\u6e90\u611f\u77e5\u51b3\u7b56\u3002", "motivation": "\u5728\u8054\u90a6\u73af\u5883\u4e2d\u6784\u5efa\u6d88\u8d39\u8005\u7279\u5b9a\u7684\u6570\u636e\u5171\u4eab\u7ba1\u9053\u65f6\uff0c\u4f20\u7edf\u4e91\u8bbe\u8ba1\u6a21\u5f0f\u7684\u9884\u5b9a\u4e49\u548c\u5d4c\u5165\u4f1a\u635f\u5bb3\u6a21\u5757\u5316\u3001\u964d\u4f4e\u53ef\u91cd\u7528\u6027\uff0c\u4e0e\u7ba1\u9053\u7684\u52a8\u6001\u3001\u6d88\u8d39\u8005\u9a71\u52a8\u7279\u6027\u51b2\u7a81\u3002", "method": "\u5f00\u53d1\u57fa\u4e8eKubernetes\u7684\u5de5\u5177\uff0c\u652f\u6301\u81ea\u52a8\u5316\u6a21\u5f0f\u6ce8\u5165\uff0c\u65e0\u9700\u4fee\u6539\u670d\u52a1\u6e90\u4ee3\u7801\uff0c\u540c\u65f6\u6536\u96c6\u80fd\u8017\u6307\u6807\u3002", "result": "\u8be5\u5de5\u5177\u80fd\u591f\u5728\u4e0d\u5f71\u54cd\u7ba1\u9053\u7075\u6d3b\u53ef\u7ec4\u5408\u7ed3\u6784\u7684\u524d\u63d0\u4e0b\uff0c\u5b9e\u73b0\u4e91\u8bbe\u8ba1\u6a21\u5f0f\u7684\u5ef6\u8fdf\u548c\u975e\u4fb5\u5165\u5f0f\u5e94\u7528\uff0c\u5e76\u63d0\u4f9b\u80fd\u8017\u6570\u636e\u652f\u6301\u51b3\u7b56\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u89e3\u51b3\u4e86\u5728\u53ef\u91cd\u7528\u6570\u636e\u5171\u4eab\u7ba1\u9053\u4e2d\u96c6\u6210\u4e91\u8bbe\u8ba1\u6a21\u5f0f\u7684\u6311\u6218\uff0c\u5e73\u8861\u4e86\u6a21\u5757\u5316\u3001\u53ef\u91cd\u7528\u6027\u4e0e\u6a21\u5f0f\u5e94\u7528\u7684\u9700\u6c42\uff0c\u540c\u65f6\u652f\u6301\u80fd\u6e90\u6548\u7387\u4f18\u5316\u3002"}}
{"id": "2510.12294", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.12294", "abs": "https://arxiv.org/abs/2510.12294", "authors": ["Gerg\u0151 Balogh", "D\u00e1vid K\u00f3sz\u00f3", "Homayoun Safarpour Motealegh Mahalegi", "L\u00e1szl\u00f3 T\u00f3th", "Bence Szak\u00e1cs", "\u00c1ron B\u00facs\u00fa"], "title": "Show Your Title! A Scoping Review on Verbalization in Software Engineering with LLM-Assisted Screening", "comment": "preprint of a paper under publication in Quality of Information and\n  Communications Technology 2025", "summary": "Understanding how software developers think, make decisions, and behave\nremains a key challenge in software engineering (SE). Verbalization techniques\n(methods that capture spoken or written thought processes) offer a lightweight\nand accessible way to study these cognitive aspects. This paper presents a\nscoping review of research at the intersection of SE and psychology (PSY),\nfocusing on the use of verbal data. To make large-scale interdisciplinary\nreviews feasible, we employed a large language model (LLM)-assisted screening\npipeline using GPT to assess the relevance of over 9,000 papers based solely on\ntitles. We addressed two questions: what themes emerge from\nverbalization-related work in SE, and how effective are LLMs in supporting\ninterdisciplinary review processes? We validated GPT's outputs against human\nreviewers and found high consistency, with a 13\\% disagreement rate. Prominent\nthemes mainly were tied to the craft of SE, while more human-centered topics\nwere underrepresented. The data also suggests that SE frequently draws on PSY\nmethods, whereas the reverse is rare.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7LLM\u8f85\u52a9\u7b5b\u90099000\u591a\u7bc7\u8bba\u6587\uff0c\u7814\u7a76\u4e86\u8f6f\u4ef6\u5de5\u7a0b\u4e0e\u5fc3\u7406\u5b66\u4ea4\u53c9\u9886\u57df\u4e2d\u8a00\u8bed\u6570\u636e\u7684\u4f7f\u7528\u60c5\u51b5\uff0c\u53d1\u73b0SE\u7ecf\u5e38\u501f\u7528PSY\u65b9\u6cd5\uff0c\u4f46\u53cd\u5411\u5f71\u54cd\u5f88\u5c11", "motivation": "\u7406\u89e3\u8f6f\u4ef6\u5f00\u53d1\u8005\u7684\u601d\u7ef4\u3001\u51b3\u7b56\u548c\u884c\u4e3a\u662f\u8f6f\u4ef6\u5de5\u7a0b\u7684\u5173\u952e\u6311\u6218\uff0c\u8a00\u8bed\u5316\u6280\u672f\u63d0\u4f9b\u4e86\u4e00\u79cd\u8f7b\u91cf\u7ea7\u65b9\u6cd5\u6765\u7814\u7a76\u8fd9\u4e9b\u8ba4\u77e5\u65b9\u9762", "method": "\u91c7\u7528GPT\u8f85\u52a9\u7684\u7b5b\u9009\u7ba1\u9053\uff0c\u57fa\u4e8e\u6807\u9898\u8bc4\u4f309000\u591a\u7bc7\u8bba\u6587\u7684\u76f8\u5173\u6027\uff0c\u5e76\u8fdb\u884c\u4eba\u5de5\u9a8c\u8bc1", "result": "GPT\u8f93\u51fa\u4e0e\u4eba\u5de5\u8bc4\u5ba1\u9ad8\u5ea6\u4e00\u81f4\uff0c\u5206\u6b67\u7387\u4ec513%\uff1b\u4e3b\u8981\u4e3b\u9898\u4e0eSE\u5de5\u827a\u76f8\u5173\uff0c\u4eba\u672c\u4e3b\u9898\u8f83\u5c11\uff1bSE\u9891\u7e41\u501f\u7528PSY\u65b9\u6cd5\uff0c\u4f46\u53cd\u5411\u5f71\u54cd\u7f55\u89c1", "conclusion": "LLM\u53ef\u4ee5\u6709\u6548\u652f\u6301\u8de8\u5b66\u79d1\u6587\u732e\u7efc\u8ff0\uff0cSE\u4e0ePSY\u7684\u4ea4\u53c9\u7814\u7a76\u5b58\u5728\u4e0d\u5bf9\u79f0\u6027\uff0c\u9700\u8981\u66f4\u591a\u5173\u6ce8\u4eba\u672c\u4e3b\u9898"}}
{"id": "2510.12436", "categories": ["cs.DC", "cs.PF"], "pdf": "https://arxiv.org/pdf/2510.12436", "abs": "https://arxiv.org/abs/2510.12436", "authors": ["Valentin Seitz", "Jordy Trilaksono", "Marta Garcia-Gasulla"], "title": "TALP-Pages: An easy-to-integrate continuous performance monitoring framework", "comment": null, "summary": "Ensuring good performance is a key aspect in the development of codes that\ntarget HPC machines. As these codes are under active development, the necessity\nto detect performance degradation early in the development process becomes\napparent. In addition, having meaningful insight into application scaling\nbehavior tightly coupled to the development workflow is helpful. In this paper,\nwe introduce TALP-Pages, an easy-to-integrate framework that enables developers\nto get fast and in-repository feedback about their code performance using\nestablished fundamental performance and scaling factors. The framework relies\non TALP, which enables the on-the-fly collection of these metrics. Based on a\nfolder structure suited for CI which contains the files generated by TALP,\nTALP-Pages generates an HTML report with visualizations of the performance\nfactor regression as well as scaling-efficiency tables. We compare TALP-Pages\nto tracing-based tools in terms of overhead and post-processing requirements\nand find that TALP-Pages can produce the scaling-efficiency tables faster and\nunder tighter resource constraints. To showcase the ease of use and\neffectiveness of this approach, we extend the current CI setup of GENE-X with\nonly minimal changes required and showcase the ability to detect and explain a\nperformance improvement.", "AI": {"tldr": "TALP-Pages\u662f\u4e00\u4e2a\u6613\u4e8e\u96c6\u6210\u7684\u6846\u67b6\uff0c\u4e3a\u5f00\u53d1\u8005\u63d0\u4f9b\u4ee3\u7801\u6027\u80fd\u7684\u5feb\u901f\u53cd\u9988\uff0c\u901a\u8fc7\u53ef\u89c6\u5316\u6027\u80fd\u56e0\u5b50\u56de\u5f52\u548c\u6269\u5c55\u6548\u7387\u8868\u6765\u68c0\u6d4b\u6027\u80fd\u9000\u5316\u3002", "motivation": "\u5728HPC\u4ee3\u7801\u5f00\u53d1\u8fc7\u7a0b\u4e2d\uff0c\u9700\u8981\u65e9\u671f\u68c0\u6d4b\u6027\u80fd\u9000\u5316\u5e76\u83b7\u5f97\u5e94\u7528\u6269\u5c55\u884c\u4e3a\u7684\u6d1e\u5bdf\uff0c\u4ee5\u6539\u8fdb\u5f00\u53d1\u5de5\u4f5c\u6d41\u7a0b\u3002", "method": "\u57fa\u4e8eTALP\u5de5\u5177\u5b9e\u65f6\u6536\u96c6\u6027\u80fd\u6307\u6807\uff0c\u901a\u8fc7\u9002\u5408CI\u7684\u6587\u4ef6\u5939\u7ed3\u6784\u751f\u6210HTML\u62a5\u544a\uff0c\u5305\u542b\u6027\u80fd\u56e0\u5b50\u56de\u5f52\u53ef\u89c6\u5316\u548c\u6269\u5c55\u6548\u7387\u8868\u3002", "result": "\u4e0e\u57fa\u4e8e\u8ffd\u8e2a\u7684\u5de5\u5177\u76f8\u6bd4\uff0cTALP-Pages\u5728\u5f00\u9500\u548c\u540e\u5904\u7406\u8981\u6c42\u65b9\u9762\u8868\u73b0\u66f4\u597d\uff0c\u80fd\u66f4\u5feb\u751f\u6210\u6269\u5c55\u6548\u7387\u8868\u4e14\u5728\u66f4\u4e25\u683c\u7684\u8d44\u6e90\u7ea6\u675f\u4e0b\u5de5\u4f5c\u3002", "conclusion": "TALP-Pages\u65b9\u6cd5\u6613\u4e8e\u4f7f\u7528\u4e14\u6709\u6548\uff0c\u901a\u8fc7\u6700\u5c0f\u6539\u52a8\u6269\u5c55GENE-X\u7684CI\u8bbe\u7f6e\uff0c\u80fd\u591f\u68c0\u6d4b\u548c\u89e3\u91ca\u6027\u80fd\u6539\u8fdb\u3002"}}
{"id": "2510.12364", "categories": ["cs.SE", "cs.AI", "cs.HC", "D.2.3"], "pdf": "https://arxiv.org/pdf/2510.12364", "abs": "https://arxiv.org/abs/2510.12364", "authors": ["Kevin Krings", "Nino S. Bohn", "Thomas Ludwig"], "title": "(R)evolution of Programming: Vibe Coding as a Post-Coding Paradigm", "comment": "Workshop Submission at the sixth decennial Aarhus conference in\n  Workshop \"The End of Programming (as we know it) - Envisioning Radical\n  Re-Conceptualizations of Co-Coding with AI\"", "summary": "Recent advancements in generative artificial intelligence (GenAI),\nparticularly large language models, have introduced new possibilities for\nsoftware development practices. In our paper we investigate the emerging Vibe\nCoding (VC) paradigm that emphasizes intuitive, affect-driven, and\nimprovisational interactions between developers and AI systems. Building upon\nthe discourse of End-User Development (EUD), we explore how VC diverges from\nconventional programming approaches such as those supported by tools like\nGitHub Copilot. Through five semi-structured interview sessions with ten\nexperienced software practitioners, we identify five thematic dimensions:\ncreativity, sustainability, the future of programming, collaboration, and\ncriticism. Our analysis conceptualizes VC within the metaphor of co-drifting,\ncontrasting it with the prevalent co-piloting perspective of AI-assisted\ndevelopment. We argue that VC reconfigures the developers role, blurring\nboundaries between professional and non-developers. While VC enables novel\nforms of expression and rapid prototyping, it also introduces challenges\nregarding reproducibility, scalability, and inclusivity. We propose that VC\nrepresents a meaningful shift in programming culture, warranting further\ninvestigation within human-computer interaction (HCI) and software engineering\nresearch.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u65b0\u5174\u7684Vibe Coding\u8303\u5f0f\uff0c\u8fd9\u662f\u4e00\u79cd\u5f3a\u8c03\u5f00\u53d1\u8005\u4e0eAI\u7cfb\u7edf\u4e4b\u95f4\u76f4\u89c9\u3001\u60c5\u611f\u9a71\u52a8\u548c\u5373\u5174\u4ea4\u4e92\u7684\u7f16\u7a0b\u65b9\u6cd5\uff0c\u4e0e\u4f20\u7edfAI\u8f85\u52a9\u5f00\u53d1\u5de5\u5177\u5f62\u6210\u5bf9\u6bd4\u3002", "motivation": "\u63a2\u7d22\u751f\u6210\u5f0fAI\u7279\u522b\u662f\u5927\u8bed\u8a00\u6a21\u578b\u5982\u4f55\u6539\u53d8\u8f6f\u4ef6\u5f00\u53d1\u5b9e\u8df5\uff0c\u7814\u7a76Vibe Coding\u8fd9\u4e00\u65b0\u5174\u8303\u5f0f\u4e0e\u4f20\u7edf\u7684AI\u8f85\u52a9\u7f16\u7a0b\uff08\u5982GitHub Copilot\uff09\u6709\u4f55\u4e0d\u540c\u3002", "method": "\u901a\u8fc7\u5bf910\u540d\u7ecf\u9a8c\u4e30\u5bcc\u7684\u8f6f\u4ef6\u4ece\u4e1a\u8005\u8fdb\u884c5\u6b21\u534a\u7ed3\u6784\u5316\u8bbf\u8c08\uff0c\u8bc6\u522b\u51fa\u4e94\u4e2a\u4e3b\u9898\u7ef4\u5ea6\uff1a\u521b\u9020\u529b\u3001\u53ef\u6301\u7eed\u6027\u3001\u7f16\u7a0b\u672a\u6765\u3001\u534f\u4f5c\u548c\u6279\u8bc4\u3002", "result": "\u5c06Vibe Coding\u6982\u5ff5\u5316\u4e3a\"\u5171\u540c\u6f02\u6d41\"\u7684\u9690\u55bb\uff0c\u4e0e\u4e3b\u6d41\u7684\"\u5171\u540c\u9a7e\u9a76\"\u89c6\u89d2\u5f62\u6210\u5bf9\u6bd4\u3002Vibe Coding\u91cd\u65b0\u914d\u7f6e\u4e86\u5f00\u53d1\u8005\u89d2\u8272\uff0c\u6a21\u7cca\u4e86\u4e13\u4e1a\u4e0e\u975e\u4e13\u4e1a\u5f00\u53d1\u8005\u4e4b\u95f4\u7684\u754c\u9650\u3002", "conclusion": "Vibe Coding\u4ee3\u8868\u4e86\u7f16\u7a0b\u6587\u5316\u7684\u6709\u610f\u4e49\u8f6c\u53d8\uff0c\u867d\u7136\u652f\u6301\u65b0\u9896\u7684\u8868\u8fbe\u5f62\u5f0f\u548c\u5feb\u901f\u539f\u578b\u8bbe\u8ba1\uff0c\u4f46\u4e5f\u5e26\u6765\u4e86\u53ef\u91cd\u590d\u6027\u3001\u53ef\u6269\u5c55\u6027\u548c\u5305\u5bb9\u6027\u65b9\u9762\u7684\u6311\u6218\uff0c\u503c\u5f97\u5728HCI\u548c\u8f6f\u4ef6\u5de5\u7a0b\u9886\u57df\u8fdb\u4e00\u6b65\u7814\u7a76\u3002"}}
{"id": "2510.12597", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2510.12597", "abs": "https://arxiv.org/abs/2510.12597", "authors": ["Ilya Baldin", "Michael Goodrich", "Vardan Gyurjyan", "Graham Heyes", "Derek Howard", "Yatish Kumar", "David Lawrence", "Brad Sawatzky", "Stacey Sheldon", "Carl Timmer"], "title": "Low Latency, High Bandwidth Streaming of Experimental Data with EJFAT", "comment": null, "summary": "Thomas Jefferson National Accelerator Facility (JLab) has partnered with\nEnergy Sciences Network (ESnet) to define and implement an edge to compute\ncluster computational load balancing acceleration architecture. The ESnet-JLab\nFPGA Accelerated Transport (EJFAT) architecture focuses on FPGA acceleration to\naddress compression, fragmentation, UDP packet destination redirection (Network\nAddress Translation (NAT)) and decompression and reassembly.\n  EJFAT seamlessly integrates edge and cluster computing to support direct\nprocessing of streamed experimental data. This will directly benefit the JLab\nscience program as well as data centers of the future that require high\nthroughput and low latency for both time-critical data acquisition systems and\ndata center workflows.\n  The EJFAT project will be presented along with how it is synergistic with\nother DOE activities such as an Integrated Research Infrastructure (IRI), and\nrecent results using data sources at JLab, an EJFAT LB at ESnet, and\ncomputational cluster resources at Lawrence Berkeley National Laboratory\n(LBNL).", "AI": {"tldr": "EJFAT\u67b6\u6784\u901a\u8fc7FPGA\u52a0\u901f\u5b9e\u73b0\u8fb9\u7f18\u5230\u8ba1\u7b97\u96c6\u7fa4\u7684\u8d1f\u8f7d\u5747\u8861\uff0c\u652f\u6301\u5b9e\u9a8c\u6570\u636e\u6d41\u7684\u76f4\u63a5\u5904\u7406\uff0c\u63d0\u5347\u541e\u5410\u91cf\u548c\u964d\u4f4e\u5ef6\u8fdf\u3002", "motivation": "\u89e3\u51b3JLab\u79d1\u5b66\u9879\u76ee\u548c\u6570\u636e\u4e2d\u5fc3\u5bf9\u9ad8\u541e\u5410\u91cf\u3001\u4f4e\u5ef6\u8fdf\u6570\u636e\u5904\u7406\u7684\u9700\u6c42\uff0c\u652f\u6301\u65f6\u95f4\u5173\u952e\u578b\u6570\u636e\u91c7\u96c6\u7cfb\u7edf\u548c\u5de5\u4f5c\u6d41\u3002", "method": "\u91c7\u7528FPGA\u52a0\u901f\u6280\u672f\u5904\u7406\u538b\u7f29\u3001\u5206\u7247\u3001UDP\u5305\u76ee\u6807\u91cd\u5b9a\u5411(NAT)\u3001\u89e3\u538b\u7f29\u548c\u91cd\u7ec4\uff0c\u5b9e\u73b0\u8fb9\u7f18\u4e0e\u96c6\u7fa4\u8ba1\u7b97\u7684\u65e0\u7f1d\u96c6\u6210\u3002", "result": "\u5728JLab\u3001ESnet\u548cLBNL\u7684\u6d4b\u8bd5\u4e2d\u5c55\u793a\u4e86\u67b6\u6784\u7684\u6709\u6548\u6027\uff0c\u5e76\u4e0eDOE\u7684\u96c6\u6210\u7814\u7a76\u57fa\u7840\u8bbe\u65bd(IRI)\u7b49\u6d3b\u52a8\u5f62\u6210\u534f\u540c\u6548\u5e94\u3002", "conclusion": "EJFAT\u67b6\u6784\u4e3a\u672a\u6765\u6570\u636e\u4e2d\u5fc3\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u6570\u636e\u5904\u7406\u89e3\u51b3\u65b9\u6848\uff0c\u7279\u522b\u9002\u7528\u4e8e\u9700\u8981\u9ad8\u541e\u5410\u91cf\u548c\u4f4e\u5ef6\u8fdf\u7684\u79d1\u5b66\u5e94\u7528\u573a\u666f\u3002"}}
{"id": "2510.12397", "categories": ["cs.SE", "cs.DC", "cs.PF"], "pdf": "https://arxiv.org/pdf/2510.12397", "abs": "https://arxiv.org/abs/2510.12397", "authors": ["S\u00f6ren Henning", "Adriano Vogel", "Esteban Perez-Wohlfeil", "Otmar Ertl", "Rick Rabiser"], "title": "Should I Run My Cloud Benchmark on Black Friday?", "comment": "Accepted for the 16th Symposium on Software Performance 2025", "summary": "Benchmarks and performance experiments are frequently conducted in cloud\nenvironments. However, their results are often treated with caution, as the\npresumed high variability of performance in the cloud raises concerns about\nreproducibility and credibility. In a recent study, we empirically quantified\nthe impact of this variability on benchmarking results by repeatedly executing\na stream processing application benchmark at different times of the day over\nseveral months. Our analysis confirms that performance variability is indeed\nobservable at the application level, although it is less pronounced than often\nassumed. The larger scale of our study compared to related work allowed us to\nidentify subtle daily and weekly performance patterns. We now extend this\ninvestigation by examining whether a major global event, such as Black Friday,\naffects the outcomes of performance benchmarks.", "AI": {"tldr": "\u8be5\u7814\u7a76\u6269\u5c55\u4e86\u4e4b\u524d\u5bf9\u4e91\u73af\u5883\u6027\u80fd\u53d8\u5f02\u6027\u7684\u8c03\u67e5\uff0c\u7279\u522b\u5173\u6ce8\u91cd\u5927\u5168\u7403\u4e8b\u4ef6\uff08\u5982\u9ed1\u8272\u661f\u671f\u4e94\uff09\u5bf9\u6027\u80fd\u57fa\u51c6\u6d4b\u8bd5\u7ed3\u679c\u7684\u5f71\u54cd\u3002", "motivation": "\u4e91\u73af\u5883\u4e2d\u57fa\u51c6\u6d4b\u8bd5\u7ed3\u679c\u7684\u53ef\u91cd\u73b0\u6027\u548c\u53ef\u4fe1\u5ea6\u5e38\u56e0\u6027\u80fd\u7684\u9ad8\u53d8\u5f02\u6027\u800c\u53d7\u5230\u8d28\u7591\uff0c\u7814\u7a76\u65e8\u5728\u91cf\u5316\u8fd9\u79cd\u53d8\u5f02\u6027\u5e76\u63a2\u7d22\u91cd\u5927\u4e8b\u4ef6\u7684\u5f71\u54cd\u3002", "method": "\u901a\u8fc7\u5728\u4e0d\u540c\u65f6\u95f4\u6bb5\u91cd\u590d\u6267\u884c\u6d41\u5904\u7406\u5e94\u7528\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5e76\u7279\u522b\u5206\u6790\u9ed1\u8272\u661f\u671f\u4e94\u7b49\u91cd\u5927\u5168\u7403\u4e8b\u4ef6\u671f\u95f4\u7684\u6027\u80fd\u6570\u636e\u3002", "result": "\u786e\u8ba4\u5e94\u7528\u5c42\u9762\u786e\u5b9e\u5b58\u5728\u6027\u80fd\u53d8\u5f02\u6027\uff0c\u4f46\u6bd4\u901a\u5e38\u5047\u8bbe\u7684\u8981\u5c0f\uff1b\u53d1\u73b0\u4e86\u7ec6\u5fae\u7684\u6bcf\u65e5\u548c\u6bcf\u5468\u6027\u80fd\u6a21\u5f0f\uff1b\u6b63\u5728\u8c03\u67e5\u91cd\u5927\u4e8b\u4ef6\u7684\u5f71\u54cd\u3002", "conclusion": "\u4e91\u73af\u5883\u6027\u80fd\u53d8\u5f02\u6027\u786e\u5b9e\u5b58\u5728\u4f46\u88ab\u9ad8\u4f30\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u91cd\u5927\u4e8b\u4ef6\u5bf9\u57fa\u51c6\u6d4b\u8bd5\u7ed3\u679c\u7684\u5177\u4f53\u5f71\u54cd\u3002"}}
{"id": "2510.12705", "categories": ["cs.DC", "cs.MS"], "pdf": "https://arxiv.org/pdf/2510.12705", "abs": "https://arxiv.org/abs/2510.12705", "authors": ["Evelyne Ringoot", "Rabab Alomairy", "Alan Edelman"], "title": "A GPU-resident Memory-Aware Algorithm for Accelerating Bidiagonalization of Banded Matrices", "comment": "13 pages, 7 figures, 3 tables", "summary": "The reduction of a banded matrix to a bidiagonal form is a crucial step in\nthe Singular Value Decomposition (SVD), a cornerstone of scientific computing\nand AI. Despite being a highly parallel algorithm, it was previously believed\nto be unsuitable for GPU computation because it is memory bandwidth-bound.\nRecent developments in GPU hardware, including larger L1 memory per Streaming\nMultiprocessor/Compute Unit, have changed that. We present the first GPU\nalgorithm for reducing a banded matrix to bidiagonal form as part of the\nNextLA.jl open-source software package. Our algorithm is based on previous\nCPU-based multicore parallel cache-efficient bulge chasing algorithms and\nadapted to optimize for GPU throughput. We leverage Julia Language's Array\nabstractions and KernelAbstractions to implement a single hardware- and data\nprecision-agnostic function on NVIDIA, AMD, Intel, and Apple Metal GPUs for\nhalf, single, and double precision, and examine performance optimization across\nhardware architectures and data precision. We also develop a hardware-aware\nperformance model and identify key hyperparameters, such as inner tilewidth and\nblock concurrency, that govern optimal GPU execution for bandwidth-bound\nworkloads. We demonstrate highly parallel bandwidth-bound algorithm on the GPU\ncan outperform CPU-based implementations: the GPU algorithm outperforms\nmultithreaded CPU High-Performance libraries PLASMA and SLATE as of matrix size\n1024 x 1024 and by a factor over 100 for matrices of 32k x 32k. In addition,\nthe performance of the algorithm increases linearly with matrix bandwidth size,\nmaking faster reduction of larger matrix bandwidths now also possible. With\nthis work, we break memory bandwidth barriers, as well as matrix bandwidth\nbarriers, resulting in orders-of-magnitude faster algorithms for the reduction\nof banded matrices to bidiagonal form on the GPU.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u9996\u4e2aGPU\u7b97\u6cd5\uff0c\u7528\u4e8e\u5c06\u5e26\u72b6\u77e9\u9635\u8f6c\u6362\u4e3a\u53cc\u5bf9\u89d2\u5f62\u5f0f\uff0c\u4f5c\u4e3aSVD\u7684\u5173\u952e\u6b65\u9aa4\u3002\u8be5\u7b97\u6cd5\u901a\u8fc7\u4f18\u5316GPU\u541e\u5410\u91cf\uff0c\u5728\u591a\u79cdGPU\u786c\u4ef6\u4e0a\u5b9e\u73b0\u9ad8\u6027\u80fd\uff0c\u663e\u8457\u8d85\u8d8a\u4e86CPU\u5b9e\u73b0\u3002", "motivation": "\u5e26\u72b6\u77e9\u9635\u5230\u53cc\u5bf9\u89d2\u5f62\u5f0f\u7684\u8f6c\u6362\u662fSVD\u8ba1\u7b97\u7684\u5173\u952e\u6b65\u9aa4\uff0c\u4f20\u7edf\u4e0a\u88ab\u8ba4\u4e3a\u4e0d\u9002\u5408GPU\u8ba1\u7b97\uff0c\u56e0\u4e3a\u5b83\u662f\u5185\u5b58\u5e26\u5bbd\u53d7\u9650\u7684\u3002\u4f46\u73b0\u4ee3GPU\u786c\u4ef6\u7684\u53d1\u5c55\uff08\u5982\u66f4\u5927\u7684L1\u5185\u5b58\uff09\u6539\u53d8\u4e86\u8fd9\u4e00\u73b0\u72b6\u3002", "method": "\u57fa\u4e8eCPU\u591a\u6838\u5e76\u884c\u7f13\u5b58\u9ad8\u6548\u51f8\u70b9\u8ffd\u9010\u7b97\u6cd5\uff0c\u9002\u914d\u4f18\u5316GPU\u541e\u5410\u91cf\u3002\u4f7f\u7528Julia\u8bed\u8a00\u7684\u6570\u7ec4\u62bd\u8c61\u548cKernelAbstractions\uff0c\u5b9e\u73b0\u8de8NVIDIA\u3001AMD\u3001Intel\u548cApple Metal GPU\u7684\u786c\u4ef6\u548c\u6570\u636e\u7cbe\u5ea6\u65e0\u5173\u51fd\u6570\u3002\u5f00\u53d1\u786c\u4ef6\u611f\u77e5\u6027\u80fd\u6a21\u578b\uff0c\u8bc6\u522b\u5173\u952e\u8d85\u53c2\u6570\u3002", "result": "GPU\u7b97\u6cd5\u57281024x1024\u77e9\u9635\u5927\u5c0f\u4e0a\u8d85\u8d8a\u591a\u7ebf\u7a0bCPU\u9ad8\u6027\u80fd\u5e93PLASMA\u548cSLATE\uff0c\u572832k x 32k\u77e9\u9635\u4e0a\u6027\u80fd\u63d0\u5347\u8d85\u8fc7100\u500d\u3002\u7b97\u6cd5\u6027\u80fd\u968f\u77e9\u9635\u5e26\u5bbd\u5927\u5c0f\u7ebf\u6027\u589e\u957f\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u7a81\u7834\u4e86\u5185\u5b58\u5e26\u5bbd\u548c\u77e9\u9635\u5e26\u5bbd\u7684\u9650\u5236\uff0c\u5728GPU\u4e0a\u5b9e\u73b0\u4e86\u6570\u91cf\u7ea7\u66f4\u5feb\u7684\u5e26\u72b6\u77e9\u9635\u5230\u53cc\u5bf9\u89d2\u5f62\u5f0f\u7684\u8f6c\u6362\u7b97\u6cd5\u3002"}}
{"id": "2510.12478", "categories": ["cs.SE", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.12478", "abs": "https://arxiv.org/abs/2510.12478", "authors": ["\u00d8ystein Haugen", "Stefan Klikovits", "Martin Arthur Andersen", "Jonathan Beaulieu", "Francis Bordeleau", "Joachim Denil", "Joost Mertens"], "title": "DarTwin made precise by SysMLv2 -- An Experiment", "comment": null, "summary": "The new SysMLv2 adds mechanisms for the built-in specification of\ndomain-specific concepts and language extensions. This feature promises to\nfacilitate the creation of Domain-Specific Languages (DSLs) and interfacing\nwith existing system descriptions and technical designs. In this paper, we\nreview these features and evaluate SysMLv2's capabilities using concrete use\ncases. We develop DarTwin DSL, a DSL that formalizes the existing DarTwin\nnotation for Digital Twin (DT) evolution, through SysMLv2, thereby supposedly\nenabling the wide application of DarTwin's evolution templates using any\nSysMLv2 tool. We demonstrate DarTwin DSL, but also point out limitations in the\ncurrently available tooling of SysMLv2 in terms of graphical notation\ncapabilities. This work contributes to the growing field of Model-Driven\nEngineering (MDE) for DTs and combines it with the release of SysMLv2, thus\nintegrating a systematic approach with DT evolution management in systems\nengineering.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7SysMLv2\u5f00\u53d1\u4e86DarTwin DSL\uff0c\u7528\u4e8e\u6570\u5b57\u5b6a\u751f\u6f14\u5316\u5efa\u6a21\uff0c\u8bc4\u4f30\u4e86SysMLv2\u5728\u9886\u57df\u7279\u5b9a\u8bed\u8a00\u521b\u5efa\u65b9\u9762\u7684\u80fd\u529b\uff0c\u5e76\u6307\u51fa\u4e86\u5f53\u524d\u5de5\u5177\u5728\u56fe\u5f62\u8868\u793a\u65b9\u9762\u7684\u5c40\u9650\u6027\u3002", "motivation": "SysMLv2\u65b0\u589e\u4e86\u5185\u7f6e\u7684\u9886\u57df\u7279\u5b9a\u6982\u5ff5\u548c\u8bed\u8a00\u6269\u5c55\u673a\u5236\uff0c\u8fd9\u6709\u671b\u4fc3\u8fdb\u9886\u57df\u7279\u5b9a\u8bed\u8a00(DSL)\u7684\u521b\u5efa\u4ee5\u53ca\u4e0e\u73b0\u6709\u7cfb\u7edf\u63cf\u8ff0\u548c\u6280\u672f\u8bbe\u8ba1\u7684\u63a5\u53e3\u3002", "method": "\u901a\u8fc7\u5177\u4f53\u7528\u4f8b\u8bc4\u4f30SysMLv2\u7684\u80fd\u529b\uff0c\u5f00\u53d1DarTwin DSL\u6765\u5f62\u5f0f\u5316\u73b0\u6709\u7684DarTwin\u6570\u5b57\u5b6a\u751f\u6f14\u5316\u8868\u793a\u6cd5\uff0c\u5229\u7528SysMLv2\u5b9e\u73b0DarTwin\u6f14\u5316\u6a21\u677f\u7684\u5e7f\u6cdb\u5e94\u7528\u3002", "result": "\u6210\u529f\u6f14\u793a\u4e86DarTwin DSL\uff0c\u4f46\u53d1\u73b0\u5f53\u524dSysMLv2\u5de5\u5177\u5728\u56fe\u5f62\u8868\u793a\u80fd\u529b\u65b9\u9762\u5b58\u5728\u5c40\u9650\u6027\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u5c06\u6a21\u578b\u9a71\u52a8\u5de5\u7a0b(MDE)\u4e0e\u6570\u5b57\u5b6a\u751f\u7ed3\u5408\uff0c\u5229\u7528SysMLv2\u7684\u53d1\u5e03\uff0c\u4e3a\u7cfb\u7edf\u5de5\u7a0b\u4e2d\u7684\u6570\u5b57\u5b6a\u751f\u6f14\u5316\u7ba1\u7406\u63d0\u4f9b\u4e86\u7cfb\u7edf\u5316\u65b9\u6cd5\u3002"}}
{"id": "2510.12487", "categories": ["cs.SE", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.12487", "abs": "https://arxiv.org/abs/2510.12487", "authors": ["Evgeniy Glukhov", "Michele Conti", "Egor Bogomolov", "Yaroslav Golubev", "Alexander Bezzubov"], "title": "Diff-XYZ: A Benchmark for Evaluating Diff Understanding", "comment": null, "summary": "Reliable handling of code diffs is central to agents that edit and refactor\nrepositories at scale. We introduce Diff-XYZ, a compact benchmark for code-diff\nunderstanding with three supervised tasks: apply (old code $+$ diff\n$\\rightarrow$ new code), anti-apply (new code $-$ diff $\\rightarrow$ old code),\nand diff generation (new code $-$ old code $\\rightarrow$ diff). Instances in\nthe benchmark are triples $\\langle \\textit{old code}, \\textit{new code},\n\\textit{diff} \\rangle$ drawn from real commits in CommitPackFT, paired with\nautomatic metrics and a clear evaluation protocol. We use the benchmark to do a\nfocused empirical study of the unified diff format and run a cross-format\ncomparison of different diff representations. Our findings reveal that\ndifferent formats should be used depending on the use case and model size. For\nexample, representing diffs in search-replace format is good for larger models\nin the diff generation scenario, yet not suited well for diff analysis and\nsmaller models. The Diff-XYZ benchmark is a reusable foundation for assessing\nand improving diff handling in LLMs that can aid future development of diff\nformats and models editing code. The dataset is published on HuggingFace Hub:\nhttps://huggingface.co/datasets/JetBrains-Research/diff-xyz.", "AI": {"tldr": "Diff-XYZ\u662f\u4e00\u4e2a\u7528\u4e8e\u4ee3\u7801\u5dee\u5f02\u7406\u89e3\u7684\u7d27\u51d1\u57fa\u51c6\uff0c\u5305\u542b\u4e09\u4e2a\u76d1\u7763\u4efb\u52a1\uff1a\u5e94\u7528\u5dee\u5f02\u3001\u53cd\u5e94\u7528\u5dee\u5f02\u548c\u5dee\u5f02\u751f\u6210\uff0c\u57fa\u4e8e\u771f\u5b9e\u63d0\u4ea4\u6570\u636e\u6784\u5efa\u3002", "motivation": "\u53ef\u9760\u5904\u7406\u4ee3\u7801\u5dee\u5f02\u5bf9\u4e8e\u5927\u89c4\u6a21\u7f16\u8f91\u548c\u91cd\u6784\u4ed3\u5e93\u7684\u667a\u80fd\u4f53\u81f3\u5173\u91cd\u8981\uff0c\u9700\u8981\u8bc4\u4f30\u548c\u6539\u8fdbLLM\u5904\u7406\u4ee3\u7801\u5dee\u5f02\u7684\u80fd\u529b\u3002", "method": "\u6784\u5efa\u5305\u542b<\u65e7\u4ee3\u7801,\u65b0\u4ee3\u7801,\u5dee\u5f02>\u4e09\u5143\u7ec4\u7684\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u4f7f\u7528\u7edf\u4e00\u5dee\u5f02\u683c\u5f0f\uff0c\u5e76\u8fdb\u884c\u8de8\u683c\u5f0f\u6bd4\u8f83\u7814\u7a76\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u4e0d\u540c\u683c\u5f0f\u5e94\u6839\u636e\u4f7f\u7528\u573a\u666f\u548c\u6a21\u578b\u5927\u5c0f\u9009\u62e9\uff0c\u641c\u7d22\u66ff\u6362\u683c\u5f0f\u9002\u5408\u5927\u6a21\u578b\u751f\u6210\u5dee\u5f02\uff0c\u4f46\u4e0d\u9002\u5408\u5dee\u5f02\u5206\u6790\u548c\u5c0f\u6a21\u578b\u3002", "conclusion": "Diff-XYZ\u57fa\u51c6\u4e3a\u8bc4\u4f30\u548c\u6539\u8fdbLLM\u5904\u7406\u4ee3\u7801\u5dee\u5f02\u63d0\u4f9b\u4e86\u53ef\u91cd\u590d\u7684\u57fa\u7840\uff0c\u6709\u52a9\u4e8e\u672a\u6765\u5dee\u5f02\u683c\u5f0f\u548c\u4ee3\u7801\u7f16\u8f91\u6a21\u578b\u7684\u53d1\u5c55\u3002"}}
{"id": "2510.12546", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.12546", "abs": "https://arxiv.org/abs/2510.12546", "authors": ["Hashini Gunatilake", "John Grundy", "Rashina Hoda", "Ingo Mueller"], "title": "The EmpathiSEr: Development and Validation of Software Engineering Oriented Empathy Scales", "comment": null, "summary": "Empathy plays a critical role in software engineering (SE), influencing\ncollaboration, communication, and user-centred design. Although SE research has\nincreasingly recognised empathy as a key human aspect, there remains no\nvalidated instrument specifically designed to measure it within the unique\nsocio-technical contexts of SE. Existing generic empathy scales, while\nwell-established in psychology and healthcare, often rely on language,\nscenarios, and assumptions that are not meaningful or interpretable for\nsoftware practitioners. These scales fail to account for the diverse,\nrole-specific, and domain-bound expressions of empathy in SE, such as\nunderstanding a non-technical user's frustrations or another practitioner's\ntechnical constraints, which differ substantially from empathy in clinical or\neveryday contexts. To address this gap, we developed and validated two\ndomain-specific empathy scales: EmpathiSEr-P, assessing empathy among\npractitioners, and EmpathiSEr-U, capturing practitioner empathy towards users.\nGrounded in a practitioner-informed conceptual framework, the scales encompass\nthree dimensions of empathy: cognitive empathy, affective empathy, and empathic\nresponses. We followed a rigorous, multi-phase methodology, including expert\nevaluation, cognitive interviews, and two practitioner surveys. The resulting\ninstruments represent the first psychometrically validated empathy scales\ntailored to SE, offering researchers and practitioners a tool for assessing\nempathy and designing empathy-enhancing interventions in software teams and\nuser interactions.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e24\u4e2a\u4e13\u95e8\u9488\u5bf9\u8f6f\u4ef6\u5de5\u7a0b\u9886\u57df\u7684\u5171\u60c5\u91cf\u8868\uff1aEmpathiSEr-P\uff08\u6d4b\u91cf\u4ece\u4e1a\u8005\u95f4\u5171\u60c5\uff09\u548cEmpathiSEr-U\uff08\u6d4b\u91cf\u4ece\u4e1a\u8005\u5bf9\u7528\u6237\u7684\u5171\u60c5\uff09\uff0c\u586b\u8865\u4e86\u8f6f\u4ef6\u5de5\u7a0b\u9886\u57df\u7f3a\u4e4f\u9a8c\u8bc1\u5171\u60c5\u6d4b\u91cf\u5de5\u5177\u7684\u7a7a\u7f3a\u3002", "motivation": "\u73b0\u6709\u901a\u7528\u5171\u60c5\u91cf\u8868\u57fa\u4e8e\u5fc3\u7406\u5b66\u548c\u533b\u7597\u9886\u57df\uff0c\u5176\u8bed\u8a00\u3001\u573a\u666f\u548c\u5047\u8bbe\u5728\u8f6f\u4ef6\u5de5\u7a0b\u73af\u5883\u4e2d\u4e0d\u5177\u610f\u4e49\u6216\u96be\u4ee5\u89e3\u91ca\uff0c\u65e0\u6cd5\u6355\u6349\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u89d2\u8272\u7279\u5b9a\u548c\u9886\u57df\u7ea6\u675f\u7684\u5171\u60c5\u8868\u8fbe\u3002", "method": "\u91c7\u7528\u4e25\u8c28\u7684\u591a\u9636\u6bb5\u65b9\u6cd5\uff0c\u5305\u62ec\u4e13\u5bb6\u8bc4\u4f30\u3001\u8ba4\u77e5\u8bbf\u8c08\u548c\u4e24\u6b21\u4ece\u4e1a\u8005\u8c03\u67e5\uff0c\u57fa\u4e8e\u4ece\u4e1a\u8005\u77e5\u60c5\u6982\u5ff5\u6846\u67b6\u5f00\u53d1\u91cf\u8868\uff0c\u6db5\u76d6\u8ba4\u77e5\u5171\u60c5\u3001\u60c5\u611f\u5171\u60c5\u548c\u5171\u60c5\u53cd\u5e94\u4e09\u4e2a\u7ef4\u5ea6\u3002", "result": "\u6210\u529f\u5f00\u53d1\u51fa\u9996\u4e2a\u5fc3\u7406\u6d4b\u91cf\u5b66\u9a8c\u8bc1\u7684\u8f6f\u4ef6\u5de5\u7a0b\u4e13\u7528\u5171\u60c5\u91cf\u8868\uff0c\u4e3a\u8bc4\u4f30\u5171\u60c5\u548c\u8bbe\u8ba1\u5171\u60c5\u589e\u5f3a\u5e72\u9884\u63d0\u4f9b\u4e86\u5de5\u5177\u3002", "conclusion": "\u8fd9\u4e9b\u91cf\u8868\u4e3a\u8f6f\u4ef6\u5de5\u7a0b\u7814\u7a76\u8005\u548c\u4ece\u4e1a\u8005\u63d0\u4f9b\u4e86\u5728\u8f6f\u4ef6\u56e2\u961f\u548c\u7528\u6237\u4e92\u52a8\u4e2d\u8bc4\u4f30\u5171\u60c5\u548c\u8bbe\u8ba1\u5e72\u9884\u63aa\u65bd\u7684\u6709\u6548\u5de5\u5177\u3002"}}
{"id": "2510.12566", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.12566", "abs": "https://arxiv.org/abs/2510.12566", "authors": ["Maja H. Kirkeby", "Timmie Lagermann"], "title": "Evaluating End-User Device Energy Models in Sustainability Reporting of Browser-Based Web Services", "comment": null, "summary": "Sustainability reporting in web-based services increasingly relies on\nsimplified energy and carbon models such as the Danish Agency of Digital\nGovernment's Digst framework and the United Kingdom-based DIMPACT model.\nAlthough these models are widely adopted, their accuracy and precision remain\nunderexplored. This paper presents an empirical study evaluating how well such\nmodels reflect actual energy consumption during realistic user interactions\nwith common website categories. Energy use was measured across shopping,\nbooking, navigation, and news services using predefined user flows executed on\nfour laptop platforms. The results show that the commonly applied\nconstant-power approximation (P * t) can diverge substantially from measured\nenergy, depending on website category, device type, and task characteristics.\nThe findings demonstrate that model deviations are systematic rather than\nrandom and highlight the need for category-aware and device-reflective power\nparameters in reproducible sustainability reporting frameworks.", "AI": {"tldr": "\u8be5\u8bba\u6587\u901a\u8fc7\u5b9e\u8bc1\u7814\u7a76\u8bc4\u4f30\u4e86\u7b80\u5316\u7684\u80fd\u6e90\u548c\u78b3\u6a21\u578b\uff08\u5982Digst\u548cDIMPACT\uff09\u5728\u53cd\u6620\u771f\u5b9e\u7f51\u7ad9\u7528\u6237\u4ea4\u4e92\u80fd\u8017\u65f6\u7684\u51c6\u786e\u6027\uff0c\u53d1\u73b0\u5e38\u7528\u7684\u6052\u5b9a\u529f\u7387\u8fd1\u4f3c\u6cd5\u4e0e\u5b9e\u9645\u6d4b\u91cf\u5b58\u5728\u663e\u8457\u504f\u5dee\u3002", "motivation": "\u5c3d\u7ba1\u7b80\u5316\u7684\u80fd\u6e90\u548c\u78b3\u6a21\u578b\u88ab\u5e7f\u6cdb\u91c7\u7528\uff0c\u4f46\u5176\u51c6\u786e\u6027\u548c\u7cbe\u786e\u6027\u4ecd\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\u3002\u7814\u7a76\u65e8\u5728\u8bc4\u4f30\u8fd9\u4e9b\u6a21\u578b\u5728\u53cd\u6620\u771f\u5b9e\u7528\u6237\u4e0e\u5e38\u89c1\u7f51\u7ad9\u7c7b\u522b\u4ea4\u4e92\u65f6\u7684\u80fd\u8017\u8868\u73b0\u3002", "method": "\u901a\u8fc7\u9884\u5b9a\u4e49\u7528\u6237\u6d41\u7a0b\u5728\u56db\u79cd\u7b14\u8bb0\u672c\u7535\u8111\u5e73\u53f0\u4e0a\u6d4b\u91cf\u8d2d\u7269\u3001\u9884\u8ba2\u3001\u5bfc\u822a\u548c\u65b0\u95fb\u670d\u52a1\u7684\u80fd\u8017\u4f7f\u7528\u60c5\u51b5\u3002", "result": "\u7ed3\u679c\u663e\u793a\u5e38\u7528\u7684\u6052\u5b9a\u529f\u7387\u8fd1\u4f3c\u6cd5\uff08P * t\uff09\u4e0e\u5b9e\u9645\u6d4b\u91cf\u80fd\u8017\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff0c\u5177\u4f53\u53d6\u51b3\u4e8e\u7f51\u7ad9\u7c7b\u522b\u3001\u8bbe\u5907\u7c7b\u578b\u548c\u4efb\u52a1\u7279\u5f81\u3002\u6a21\u578b\u504f\u5dee\u662f\u7cfb\u7edf\u6027\u7684\u800c\u975e\u968f\u673a\u7684\u3002", "conclusion": "\u7814\u7a76\u5f3a\u8c03\u4e86\u5728\u53ef\u91cd\u590d\u7684\u53ef\u6301\u7eed\u6027\u62a5\u544a\u6846\u67b6\u4e2d\u9700\u8981\u91c7\u7528\u7c7b\u522b\u611f\u77e5\u548c\u8bbe\u5907\u53cd\u6620\u7684\u529f\u7387\u53c2\u6570\uff0c\u4ee5\u63d0\u9ad8\u6a21\u578b\u7684\u51c6\u786e\u6027\u3002"}}
{"id": "2510.12616", "categories": ["cs.SE", "cs.MA"], "pdf": "https://arxiv.org/pdf/2510.12616", "abs": "https://arxiv.org/abs/2510.12616", "authors": ["Muhammad Ashfaq", "Ahmed R. Sadik", "Teerath Das", "Muhammad Waseem", "Niko Makitalo", "Tommi Mikkonen"], "title": "Runtime Composition in Dynamic System of Systems: A Systematic Review of Challenges, Solutions, Tools, and Evaluation Methods", "comment": null, "summary": "Context: Modern Systems of Systems (SoSs) increasingly operate in dynamic\nenvironments (e.g., smart cities, autonomous vehicles) where runtime\ncomposition -- the on-the-fly discovery, integration, and coordination of\nconstituent systems (CSs)--is crucial for adaptability. Despite growing\ninterest, the literature lacks a cohesive synthesis of runtime composition in\ndynamic SoSs. Objective: This study synthesizes research on runtime composition\nin dynamic SoSs and identifies core challenges, solution strategies, supporting\ntools, and evaluation methods. Methods: We conducted a Systematic Literature\nReview (SLR), screening 1,774 studies published between 2019 and 2024 and\nselecting 80 primary studies for thematic analysis (TA). Results: Challenges\nfall into four categories: modeling and analysis, resilient operations, system\norchestration, and heterogeneity of CSs. Solutions span seven areas:\nco-simulation and digital twins, semantic ontologies, integration frameworks,\nadaptive architectures, middleware, formal methods, and AI-driven resilience.\nService-oriented frameworks for composition and integration dominate tooling,\nwhile simulation platforms support evaluation. Interoperability across tools,\nlimited cross-toolchain workflows, and the absence of standardized benchmarks\nremain key gaps. Evaluation approaches include simulation-based,\nimplementation-driven, and human-centered studies, which have been applied in\ndomains such as smart cities, healthcare, defense, and industrial automation.\nConclusions: The synthesis reveals tensions, including autonomy versus\ncoordination, the modeling-reality gap, and socio-technical integration. It\ncalls for standardized evaluation metrics, scalable decentralized\narchitectures, and cross-domain frameworks. The analysis aims to guide\nresearchers and practitioners in developing and implementing dynamically\ncomposable SoSs.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u7cfb\u7edf\u6587\u732e\u7efc\u8ff0\u5206\u6790\u4e86\u52a8\u6001\u7cfb\u7edf\u4e4b\u7cfb\u7edf(SoSs)\u4e2d\u7684\u8fd0\u884c\u65f6\u7ec4\u5408\u95ee\u9898\uff0c\u8bc6\u522b\u4e86\u6838\u5fc3\u6311\u6218\u3001\u89e3\u51b3\u65b9\u6848\u3001\u5de5\u5177\u548c\u8bc4\u4f30\u65b9\u6cd5\uff0c\u65e8\u5728\u6307\u5bfc\u7814\u7a76\u4eba\u5458\u548c\u4ece\u4e1a\u8005\u5f00\u53d1\u52a8\u6001\u53ef\u7ec4\u5408\u7684SoSs\u3002", "motivation": "\u73b0\u4ee3\u7cfb\u7edf\u4e4b\u7cfb\u7edf(SoSs)\u5728\u52a8\u6001\u73af\u5883(\u5982\u667a\u6167\u57ce\u5e02\u3001\u81ea\u52a8\u9a7e\u9a76)\u4e2d\u8fd0\u884c\uff0c\u8fd0\u884c\u65f6\u7ec4\u5408\u5bf9\u4e8e\u9002\u5e94\u6027\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u6587\u732e\u7f3a\u4e4f\u5bf9\u6b64\u7684\u7efc\u5408\u5206\u6790\u3002", "method": "\u91c7\u7528\u7cfb\u7edf\u6587\u732e\u7efc\u8ff0(SLR)\u65b9\u6cd5\uff0c\u7b5b\u90092019-2024\u5e74\u95f41,774\u9879\u7814\u7a76\uff0c\u9009\u62e980\u9879\u4e3b\u8981\u7814\u7a76\u8fdb\u884c\u4e3b\u9898\u5206\u6790(TA)\u3002", "result": "\u6311\u6218\u5206\u4e3a\u56db\u7c7b\uff1a\u5efa\u6a21\u4e0e\u5206\u6790\u3001\u5f39\u6027\u64cd\u4f5c\u3001\u7cfb\u7edf\u7f16\u6392\u548cCSs\u5f02\u8d28\u6027\u3002\u89e3\u51b3\u65b9\u6848\u6db5\u76d6\u4e03\u4e2a\u9886\u57df\uff1a\u534f\u540c\u4eff\u771f\u4e0e\u6570\u5b57\u5b6a\u751f\u3001\u8bed\u4e49\u672c\u4f53\u3001\u96c6\u6210\u6846\u67b6\u3001\u81ea\u9002\u5e94\u67b6\u6784\u3001\u4e2d\u95f4\u4ef6\u3001\u5f62\u5f0f\u5316\u65b9\u6cd5\u548cAI\u9a71\u52a8\u7684\u5f39\u6027\u3002", "conclusion": "\u5206\u6790\u63ed\u793a\u4e86\u81ea\u4e3b\u6027\u4e0e\u534f\u8c03\u6027\u3001\u5efa\u6a21-\u73b0\u5b9e\u5dee\u8ddd\u7b49\u5f20\u529b\uff0c\u547c\u5401\u6807\u51c6\u5316\u8bc4\u4f30\u6307\u6807\u3001\u53ef\u6269\u5c55\u7684\u53bb\u4e2d\u5fc3\u5316\u67b6\u6784\u548c\u8de8\u9886\u57df\u6846\u67b6\u3002"}}
{"id": "2510.12702", "categories": ["cs.SE", "cs.AI", "cs.PL"], "pdf": "https://arxiv.org/pdf/2510.12702", "abs": "https://arxiv.org/abs/2510.12702", "authors": ["Cedric Richter", "Heike Wehrheim"], "title": "Beyond Postconditions: Can Large Language Models infer Formal Contracts for Automatic Software Verification?", "comment": "under submission", "summary": "Automatic software verifiers have become increasingly effective at the task\nof checking software against (formal) specifications. Yet, their adoption in\npractice has been hampered by the lack of such specifications in real world\ncode. Large Language Models (LLMs) have shown promise in inferring formal\npostconditions from natural language hints embedded in code such as function\nnames, comments or documentation. Using the generated postconditions as\nspecifications in a subsequent verification, however, often leads verifiers to\nsuggest invalid inputs, hinting at potential issues that ultimately turn out to\nbe false alarms.\n  To address this, we revisit the problem of specification inference from\nnatural language in the context of automatic software verification. In the\nprocess, we introduce NL2Contract, the task of employing LLMs to translate\ninformal natural language into formal functional contracts, consisting of\npostconditions as well as preconditions. We introduce metrics to validate and\ncompare different NL2Contract approaches, using soundness, bug discriminative\npower of the generated contracts and their usability in the context of\nautomatic software verification as key metrics. We evaluate NL2Contract with\ndifferent LLMs and compare it to the task of postcondition generation\nnl2postcond. Our evaluation shows that (1) LLMs are generally effective at\ngenerating functional contracts sound for all possible inputs, (2) the\ngenerated contracts are sufficiently expressive for discriminating buggy from\ncorrect behavior, and (3) verifiers supplied with LLM inferred functional\ncontracts produce fewer false alarms than when provided with postconditions\nalone. Further investigations show that LLM inferred preconditions generally\nalign well with developers intentions which allows us to use automatic software\nverifiers to catch real-world bugs.", "AI": {"tldr": "NL2Contract\u4efb\u52a1\u4f7f\u7528LLM\u5c06\u81ea\u7136\u8bed\u8a00\u8f6c\u6362\u4e3a\u5f62\u5f0f\u5316\u529f\u80fd\u5951\u7ea6\uff08\u5305\u62ec\u524d\u7f6e\u6761\u4ef6\u548c\u540e\u7f6e\u6761\u4ef6\uff09\uff0c\u76f8\u6bd4\u4ec5\u751f\u6210\u540e\u7f6e\u6761\u4ef6\uff0c\u80fd\u663e\u8457\u51cf\u5c11\u81ea\u52a8\u8f6f\u4ef6\u9a8c\u8bc1\u4e2d\u7684\u8bef\u62a5\u3002", "motivation": "\u89e3\u51b3\u81ea\u52a8\u8f6f\u4ef6\u9a8c\u8bc1\u5668\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u56e0\u7f3a\u4e4f\u5f62\u5f0f\u5316\u89c4\u8303\u800c\u53d7\u9650\u7684\u95ee\u9898\uff0c\u4ee5\u53caLLM\u4ec5\u751f\u6210\u540e\u7f6e\u6761\u4ef6\u65f6\u5bfc\u81f4\u7684\u9a8c\u8bc1\u8bef\u62a5\u95ee\u9898\u3002", "method": "\u5f15\u5165NL2Contract\u4efb\u52a1\uff0c\u4f7f\u7528LLM\u4ece\u4ee3\u7801\u4e2d\u7684\u81ea\u7136\u8bed\u8a00\u63d0\u793a\uff08\u5982\u51fd\u6570\u540d\u3001\u6ce8\u91ca\uff09\u63a8\u65ad\u5f62\u5f0f\u5316\u529f\u80fd\u5951\u7ea6\uff0c\u5305\u62ec\u524d\u7f6e\u6761\u4ef6\u548c\u540e\u7f6e\u6761\u4ef6\u3002", "result": "LLM\u80fd\u6709\u6548\u751f\u6210\u5bf9\u6240\u6709\u53ef\u80fd\u8f93\u5165\u90fd\u53ef\u9760\u7684\u529f\u80fd\u5951\u7ea6\uff0c\u751f\u6210\u7684\u5951\u7ea6\u5177\u6709\u8db3\u591f\u7684\u8868\u8fbe\u80fd\u529b\u6765\u533a\u5206\u9519\u8bef\u548c\u6b63\u786e\u884c\u4e3a\uff0c\u4e0e\u4ec5\u4f7f\u7528\u540e\u7f6e\u6761\u4ef6\u76f8\u6bd4\uff0c\u9a8c\u8bc1\u5668\u4ea7\u751f\u7684\u8bef\u62a5\u66f4\u5c11\u3002", "conclusion": "LLM\u63a8\u65ad\u7684\u524d\u7f6e\u6761\u4ef6\u4e0e\u5f00\u53d1\u8005\u610f\u56fe\u9ad8\u5ea6\u4e00\u81f4\uff0c\u4f7f\u5f97\u81ea\u52a8\u8f6f\u4ef6\u9a8c\u8bc1\u5668\u80fd\u591f\u6355\u83b7\u771f\u5b9e\u4e16\u754c\u4e2d\u7684\u9519\u8bef\u3002"}}
