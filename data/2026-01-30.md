<div id=toc></div>

# Table of Contents

- [cs.SE](#cs.SE) [Total: 29]
- [cs.DC](#cs.DC) [Total: 7]


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [1] [A Survey on Large Language Model Impact on Software Evolvability and Maintainability: the Good, the Bad, the Ugly, and the Remedy](https://arxiv.org/abs/2601.20879)
*Bruno Claudino Matias,Savio Freire,Juliana Freitas,Felipe Fronchetti,Kostadin Damevski,Rodrigo Spinola*

Main category: cs.SE

TL;DR: 这篇论文通过系统文献综述分析了LLMs对软件系统可维护性和可演化性的影响，发现LLMs既带来分析性、可测试性等好处，也引入了幻觉、脆弱性等风险，需要负责任地采用。


<details>
  <summary>Details</summary>
Motivation: LLMs已广泛应用于软件工程任务，但现有研究证据分散，对长期软件可维护性和可演化性的影响不明确。需要系统分析LLMs带来的好处、风险和缓解策略。

Method: 采用系统文献综述方法，在ACM DL、IEEE Xplore和Scopus（2020-2024）中筛选出87篇主要研究，通过多研究者校准过程提取定性证据，使用混合主题分析方法，并借助LLM辅助分析工具和人工验证进行综合。

Result: LLMs能改善可分析性、可测试性、代码理解、调试支持和自动修复，但也带来幻觉输出、上下文脆弱性、领域推理有限、性能不稳定和评估缺陷等风险，威胁长期可演化性。

Conclusion: LLMs可以增强软件可维护性和可演化性，但也对长期可持续性构成重大风险。负责任地采用需要保障措施、严格评估和结构化的人工监督。

Abstract: Context. Large Language Models (LLMs) are increasingly embedded in software engineering workflows for tasks including code generation, summarization, repair, and testing. Empirical studies report productivity gains, improved comprehension, and reduced cognitive load. However, evidence remains fragmented, and concerns persist about hallucinations, unstable outputs, methodological limitations, and emerging forms of technical debt. How these mixed effects shape long-term software maintainability and evolvability remains unclear. Objectives. This study systematically examines how LLMs influence the maintainability and evolvability of software systems. We identify which quality attributes are addressed in existing research, the positive impacts LLMs provide, the risks and weaknesses they introduce, and the mitigation strategies proposed in the literature. Method. We conducted a systematic literature review. Searches across ACM DL, IEEE Xplore, and Scopus (2020 to 2024) yielded 87 primary studies. Qualitative evidence was extracted through a calibrated multi-researcher process. Attributes were analyzed descriptively, while impacts, risks, weaknesses, and mitigation strategies were synthesized using a hybrid thematic approach supported by an LLM-assisted analysis tool with human-in-the-loop validation. Results. LLMs provide benefits such as improved analyzability, testability, code comprehension, debugging support, and automated repair. However, they also introduce risks, including hallucinated or incorrect outputs, brittleness to context, limited domain reasoning, unstable performance, and flaws in current evaluations, which threaten long-term evolvability. Conclusion. LLMs can strengthen maintainability and evolvability, but they also pose nontrivial risks to long-term sustainability. Responsible adoption requires safeguards, rigorous evaluation, and structured human oversight.

</details>


### [2] [DevOps-Gym: Benchmarking AI Agents in Software DevOps Cycle](https://arxiv.org/abs/2601.20882)
*Yuheng Tang,Kaijie Zhu,Bonan Ruan,Chuqi Zhang,Michael Yang,Hongwei Li,Suyue Guo,Tianneng Shi,Zekun Li,Christopher Kruegel,Giovanni Vigna,Dawn Song,William Yang Wang,Lun Wang,Yangruibo Ding,Zhenkai Liang,Wenbo Guo*

Main category: cs.SE

TL;DR: DevOps-Gym：首个端到端AI代理DevOps基准测试，包含700+真实任务，评估显示当前AI在问题解决、测试生成等核心DevOps工作流上仍有局限


<details>
  <summary>Details</summary>
Motivation: 尽管AI在代码生成和软件问题解决方面表现出色，但在完整软件DevOps周期（开发、部署、管理）中的能力仍未知。现有基准测试关注孤立问题，缺乏DevOps环境和工具接口

Method: 提出DevOps-Gym基准测试，包含构建配置、监控、问题解决和测试生成四大核心工作流。采用半自动化数据收集机制，从30+个Java和Go项目中收集700+真实任务，确保任务覆盖率和质量

Result: 评估最先进模型和代理发现基本局限性：在Java和Go的问题解决和测试生成方面表现不佳，无法处理监控、构建配置等新任务

Conclusion: 结果表明需要开展重要研究以实现AI代理自动化完整DevOps周期，DevOps-Gym为评估AI在真实DevOps环境中的能力提供了首个端到端基准

Abstract: Even though demonstrating extraordinary capabilities in code generation and software issue resolving, AI agents' capabilities in the full software DevOps cycle are still unknown. Different from pure code generation, handling the DevOps cycle in real-world software, including developing, deploying, and managing, requires analyzing large-scale projects, understanding dynamic program behaviors, leveraging domain-specific tools, and making sequential decisions. However, existing benchmarks focus on isolated problems and lack environments and tool interfaces for DevOps. We introduce DevOps-Gym, the first end-to-end benchmark for evaluating AI agents across core DevOps workflows: build and configuration, monitoring, issue resolving, and test generation. DevOps-Gym includes 700+ real-world tasks collected from 30+ projects in Java and Go. We develop a semi-automated data collection mechanism with rigorous and non-trivial expert efforts in ensuring the task coverage and quality. Our evaluation of state-of-the-art models and agents reveals fundamental limitations: they struggle with issue resolving and test generation in Java and Go, and remain unable to handle new tasks such as monitoring and build and configuration. These results highlight the need for essential research in automating the full DevOps cycle with AI agents.

</details>


### [3] [IDE-Bench: Evaluating Large Language Models as IDE Agents on Real-World Software Engineering Tasks](https://arxiv.org/abs/2601.20886)
*Spencer Mateega,Jeff Yang,Tiana Costello,Shaurya Jadhav,Nicole Tian,Agustin Garcinuño*

Main category: cs.SE

TL;DR: IDE-Bench是一个通过IDE原生工具接口评估AI IDE代理在真实世界软件工程任务中的综合框架，使用Docker化测试环境，包含80个从未发布仓库的任务，涵盖多种编程语言和全栈场景。


<details>
  <summary>Details</summary>
Motivation: 现有评估方法通常基于原始终端执行，无法准确评估AI IDE代理在实际IDE环境中的表现。需要创建一个能够模拟真实IDE工具生态系统的评估框架，特别是在防止训练数据污染的情况下评估代理作为工程协作伙伴的能力。

Method: 开发了Docker化的测试环境，提供结构化工具生态系统，包括代码库搜索、结构化文件编辑和全栈应用测试工具。创建了80个任务，涵盖8个从未发布的仓库，支持C/C++、Java和MERN技术栈，包含功能实现、bug修复、重构和性能优化等真实开发场景。

Result: IDE-Bench是首个在多语言、全栈环境中系统地将代理报告意图与成功项目级修改相关联的基准测试，完全避免了训练数据污染问题，能够准确评估AI IDE代理作为工程协作伙伴的实际能力。

Conclusion: 该框架为评估AI IDE代理提供了真实、全面的测试环境，填补了现有评估方法的空白，特别在防止数据污染和多语言全栈场景评估方面具有创新性，能够更好地反映代理在实际软件开发中的表现。

Abstract: IDE-Bench is a comprehensive framework for evaluating AI IDE agents on real-world software engineering tasks through an IDE-native tool interface. We present a Dockerized test harness that goes beyond raw terminal execution, granting models a structured tool ecosystem that represents AI-native IDEs like Cursor and Windsurf. By providing high-level abstractions for codebase search, structured file editing, and tools for testing full-stack applications, IDE-Bench evaluates an agent's ability to act as a true engineering collaborator. For evaluation and to prevent training data contamination, we created 80 tasks across eight never-published repositories spanning C/C++, Java, and MERN stacks, representing modern tech stack production scenarios, including feature implementation, bug fixing, refactoring, and performance optimization that mirror daily developer workflows in private codebases. Our benchmark is the first to systematically correlate agent-reported intent with successful project-level modifications in a multi-language, full-stack environment on completely uncontaminated code.

</details>


### [4] [Another Systematic Review? A Critical Analysis of Systematic Literature Reviews on Agile Effort and Cost Estimation](https://arxiv.org/abs/2601.20893)
*Henry Edison,Nauman Ali*

Main category: cs.SE

TL;DR: 该研究分析了软件工程领域系统文献综述(SLR)重复现象，通过分析敏捷开发工作量估算主题的18篇SLR，识别了作者为重复研究辩护的常见模式，并提出改进建议。


<details>
  <summary>Details</summary>
Motivation: 软件工程研究中SLR日益普遍，但存在大量重复和重叠研究，作者往往不充分检查已有SLR，导致研究资源浪费。需要理解作者如何为重复SLR辩护，并提出改进方案。

Method: 选取敏捷软件开发工作量估算这一狭窄但研究充分的主题，对18篇已发表SLR进行定性内容分析，识别常见辩护模式，并结合引用数据、发表年份、发表渠道和SLR质量进行综合解读。

Result: 发现常见的辩护模式包括：声称覆盖范围存在空白、先前研究存在方法学局限、先前SLR时间过时、技术和方法快速发展需要更新综合。这些模式揭示了SLR重复现象的原因。

Conclusion: 通过对狭窄主题的深入分析，为软件工程SLR研究提供洞见。强调需要在设计和评审指南以及会议期刊政策中，要求识别现有SLR并充分论证新SLR的必要性，以减少重复工作并提高领域进展速度。

Abstract: Background: Systematic literature reviews (SLRs) have become prevalent in software engineering research. Several researchers may conduct SLRs on similar topics without a prospective register for SLR protocols. However, even ignoring these unavoidable duplications of effort in the simultaneous conduct of SLRs, the proliferation of overlapping and often repetitive SLRs indicates that researchers are not extensively checking for existing SLRs on a topic. Given how effort-intensive it is to design, conduct, and report an SLR, the situation is less than ideal for software engineering research. Aim: To understand how authors justify additional SLRs on a topic. Method: To illustrate the issue and develop suggestions for improvement to address this issue, we have intentionally picked a sufficiently narrow but well-researched topic, i.e., effort estimation in Agile software development. We identify common justification patterns through a qualitative content analysis of 18 published SLRs. We further consider the citation data, publication years, publication venues, and the quality of the SLRs when interpreting the results. Results: The common justification patterns include authors claiming gaps in coverage, methodological limitations in prior studies, temporal obsolescence of previous SLRs, or rapid technological and methodological advancements necessitating updated syntheses. Conclusion: Our in-depth analysis of SLRs on a fairly narrow topic provides insights into SLRs in software engineering in general. By emphasizing the need for identifying existing SLRs and for justifying the undertaking of further SLRs, both in design and review guidelines and as a policy of conferences and journals, we can reduce the likelihood of duplication of effort and increase the rate of progress in the field.

</details>


### [5] [Leveraging Generative AI for Enhancing Domain-Driven Software Design](https://arxiv.org/abs/2601.20909)
*Götz-Henrik Wiegand,Filip Stepniak,Patrick Baier*

Main category: cs.SE

TL;DR: 使用生成式AI部分自动化领域驱动设计中的元模型生成，通过微调Code Llama模型在消费级GPU上生成语法正确的JSON对象，提高设计效率。


<details>
  <summary>Details</summary>
Motivation: 传统DDD中元模型需要系统设计师手动创建，过程耗时且资源密集。研究旨在探索使用生成式AI自动化部分元模型生成过程，特别是生成领域特定的JSON对象，以简化设计流程并降低资源需求。

Method: 使用真实世界DDD项目数据训练模型，采用4位量化的Code Llama模型在消费级GPU上进行微调，结合低秩适应（LoRA）技术。通过简单提示生成领域特定的JSON对象。

Result: 模型在有限硬件条件下表现出高性能，能够生成语法正确的JSON对象，且需要最少的后处理。展示了将生成式AI融入DDD流程的可行性。

Conclusion: 生成式AI可以显著提高DDD过程的效率，减少资源需求，为AI驱动的软件开发奠定基础，展示了在资源受限环境中实现高质量AI辅助设计的可能性。

Abstract: Domain-Driven Design (DDD) is a key framework for developing customer-oriented software, focusing on the precise modeling of an application's domain. Traditionally, metamodels that describe these domains are created manually by system designers, forming the basis for iterative software development. This paper explores the partial automation of metamodel generation using generative AI, particularly for producing domain-specific JSON objects. By training a model on real-world DDD project data, we demonstrate that generative AI can produce syntactically correct JSON objects based on simple prompts, offering significant potential for streamlining the design process. To address resource constraints, the AI model was fine-tuned on a consumer-grade GPU using a 4-bit quantized version of Code Llama and Low-Rank Adaptation (LoRA). Despite limited hardware, the model achieved high performance, generating accurate JSON objects with minimal post-processing. This research illustrates the viability of incorporating generative AI into the DDD process, improving efficiency and reducing resource requirements, while also laying the groundwork for further advancements in AI-driven software development.

</details>


### [6] [Infusion of Blockchain to Establish Trustworthiness in AI Supported Software Evolution: A Systematic Literature Review](https://arxiv.org/abs/2601.20918)
*Mohammad Naserameri,Juergen Rilling*

Main category: cs.SE

TL;DR: 区块链与AI结合提升软件工程可信度，但仅有31%研究明确关注可信性，需开发可衡量的可信框架


<details>
  <summary>Details</summary>
Motivation: 区块链和AI在软件工程中增强可信度的潜力日益受到关注，特别是在支持软件演化任务方面。研究者希望通过系统文献综述了解区块链如何增强AI驱动的软件工程工具和流程的可信度。

Method: 采用预定义协议的系统文献综述方法，设定明确的资格标准以确保透明度、可重复性和最小化偏差，综合研究区块链在AI驱动的软件工程工具和流程中增强可信度的应用。

Result: 大多数研究关注AI在软件工程中的集成，仅31%明确解决可信度问题。综述突出了六项近期研究探索基于区块链的方法来增强AI辅助软件工程任务的可靠性、透明度和问责制。

Conclusion: 区块链通过确保数据不可变性、模型透明度和生命周期问责制来增强可信度，包括基于区块链共识的联邦学习和私有数据验证。然而，可信度定义不一致和有限的真实世界测试仍是主要挑战。未来工作需要开发可衡量、可重复的可信框架，以建立可靠、安全、合规的AI驱动软件工程生态系统，包括涉及大语言模型的应用。

Abstract: Context: Blockchain and AI are increasingly explored to enhance trustworthiness in software engineering (SE), particularly in supporting software evolution tasks. Method: We conducted a systematic literature review (SLR) using a predefined protocol with clear eligibility criteria to ensure transparency, reproducibility, and minimized bias, synthesizing research on blockchain-enabled trust in AI-driven SE tools and processes. Results: Most studies focus on integrating AI in SE, with only 31% explicitly addressing trustworthiness. Our review highlights six recent studies exploring blockchain-based approaches to reinforce reliability, transparency, and accountability in AI-assisted SE tasks. Conclusion: Blockchain enhances trust by ensuring data immutability, model transparency, and lifecycle accountability, including federated learning with blockchain consensus and private data verification. However, inconsistent definitions of trust and limited real-world testing remain major challenges. Future work must develop measurable, reproducible trust frameworks to enable reliable, secure, and compliant AI-driven SE ecosystems, including applications involving large language models.

</details>


### [7] [Operationalizing Research Software for Supply Chain Security](https://arxiv.org/abs/2601.20980)
*Kelechi G. Kalu,Soham Rattan,Taylor R. Schorlemmer,George K. Thiruvathukal,Jeffrey C. Carver,James C. Davis*

Main category: cs.SE

TL;DR: 提出一个面向研究软件供应链（RSSC）的分类法，用于统一实证研究中研究软件的定义和操作边界，并通过应用OpenSSF Scorecard展示该分类法在安全分析中的必要性。


<details>
  <summary>Details</summary>
Motivation: 现有研究软件实证研究难以比较，因为文献中对"研究软件"的定义不一致。受研究软件供应链（RSSC）及其安全风险的驱动，需要建立明确的分类法来统一研究范围。

Method: 1. 对近期仓库挖掘和数据集构建研究进行针对性范围综述；2. 提取每项工作的定义、纳入标准、分析单元和识别启发式方法；3. 综合这些信息形成统一分类法和映射关系；4. 在Research Software Encyclopedia（RSE）的大型社区策划语料库上操作化分类法；5. 应用OpenSSF Scorecard进行初步安全分析。

Result: 开发了一个统一的RSSC分类法、标注数据集、标注代码本和可复现的标注流程。安全分析显示，不同分类簇之间的仓库中心安全信号存在差异，证明基于分类法的分层对于解释RSSC安全测量是必要的。

Conclusion: 提出的RSSC分类法为研究软件安全实证研究提供了统一的操作框架，能够解决现有研究中的不一致性问题，并为安全风险评估提供更准确的解释基础。

Abstract: Empirical studies of research software are hard to compare because the literature operationalizes ``research software'' inconsistently. Motivated by the research software supply chain (RSSC) and its security risks, we introduce an RSSC-oriented taxonomy that makes scope and operational boundaries explicit for empirical research software security studies.
  We conduct a targeted scoping review of recent repository mining and dataset construction studies, extracting each work's definition, inclusion criteria, unit of analysis, and identification heuristics. We synthesize these into a harmonized taxonomy and a mapping that translates prior approaches into shared taxonomy dimensions. We operationalize the taxonomy on a large community-curated corpus from the Research Software Encyclopedia (RSE), producing an annotated dataset, a labeling codebook, and a reproducible labeling pipeline. Finally, we apply OpenSSF Scorecard as a preliminary security analysis to show how repository-centric security signals differ across taxonomy-defined clusters and why taxonomy-aware stratification is necessary for interpreting RSSC security measurements.

</details>


### [8] [Towards Comprehensive Benchmarking Infrastructure for LLMs In Software Engineering](https://arxiv.org/abs/2601.21070)
*Daniel Rodriguez-Cardenas,Xiaochang Li,Marcos Macedo,Antonio Mastropaolo,Dipin Khati,Yuan Tian,Huajie Shao,Denys Poshyvanyk*

Main category: cs.SE

TL;DR: 论文分析了当前代码大语言模型评估的局限性，提出了BEHELM基准测试框架来解决软件工程场景下的评估问题。


<details>
  <summary>Details</summary>
Motivation: 当前代码大语言模型发展迅速，但评估能力滞后。现有基准测试存在任务狭窄、指标单一、缺乏软件工程上下文、数据污染等问题，无法全面评估模型的鲁棒性、可解释性、公平性、效率和实际可用性。

Method: 通过深入调查现有基准测试和社区研讨会收集见解，识别了三个核心障碍：缺乏软件工程丰富数据集、过度依赖机器学习中心指标、缺少标准化可复现数据管道。基于这些发现，提出了BEHELM基准测试基础设施。

Result: BEHELM是一个统一的基准测试框架，将软件场景规范与多指标评估相结合，提供结构化方法来评估模型在不同任务、语言、输入输出粒度和关键质量维度上的表现。

Conclusion: BEHELM旨在减少构建基准测试的开销，同时实现对软件工程中LLM的公平、现实和面向未来的评估，推动代码大语言模型评估的标准化和全面化。

Abstract: Large language models for code are advancing fast, yet our ability to evaluate them lags behind. Current benchmarks focus on narrow tasks and single metrics, which hide critical gaps in robustness, interpretability, fairness, efficiency, and real-world usability. They also suffer from inconsistent data engineering practices, limited software engineering context, and widespread contamination issues. To understand these problems and chart a path forward, we combined an in-depth survey of existing benchmarks with insights gathered from a dedicated community workshop. We identified three core barriers to reliable evaluation: the absence of software-engineering-rich datasets, overreliance on ML-centric metrics, and the lack of standardized, reproducible data pipelines. Building on these findings, we introduce BEHELM, a holistic benchmarking infrastructure that unifies software-scenario specification with multi-metric evaluation. BEHELM provides a structured way to assess models across tasks, languages, input and output granularities, and key quality dimensions. Our goal is to reduce the overhead currently required to construct benchmarks while enabling a fair, realistic, and future-proof assessment of LLMs in software engineering.

</details>


### [9] [The Quiet Contributions: Insights into AI-Generated Silent Pull Requests](https://arxiv.org/abs/2601.21102)
*S M Mahedy Hasan,Md Fazle Rabbi,Minhaz Zibran*

Main category: cs.SE

TL;DR: 首个关于"沉默"AI生成PR的实证研究：分析无评论讨论的AI PR对代码复杂度、质量和安全的影响，探究其被接受/拒绝的原因


<details>
  <summary>Details</summary>
Motivation: AI生成的"沉默"PR（无任何评论讨论）难以理解其被接受或拒绝的原因，需要实证研究来揭示其影响和决策依据

Method: 从AIDev公共数据集中选取5个AI代理向流行Python仓库提交的4,762个沉默PR，定量分析其对代码复杂度、质量问题和安全漏洞的影响

Result: 研究发现沉默AI PR对代码复杂度、质量和安全的影响，这些发现可能暗示了PR被接受或拒绝的原因

Conclusion: 通过分析沉默AI PR对代码质量的影响，可以更好地理解其被接受或拒绝的潜在原因，为AI辅助开发提供实证依据

Abstract: We present the first empirical study of AI-generated pull requests that are 'silent,' meaning no comments or discussions accompany them. This absence of any comments or discussions associated with such silent AI pull requests (SPRs) poses a unique challenge in understanding the rationale for their acceptance or rejection. Hence, we quantitatively study 4,762 SPRs of five AI agents made to popular Python repositories drawn from the AIDev public dataset. We examine SPRs impact on code complexity, other quality issues, and security vulnerabilities, especially to determine whether these insights can hint at the rationale for acceptance or rejection of SPRs.

</details>


### [10] [AI-Assisted Engineering Should Track the Epistemic Status and Temporal Validity of Architectural Decisions](https://arxiv.org/abs/2601.21116)
*Sankalp Gilda,Shlok Gilda*

Main category: cs.SE

TL;DR: 论文提出"第一原则框架"（FPF），用于在AI辅助软件工程中追踪架构决策的认知状态和时间有效性，防止LLM生成决策过快导致验证滞后的问题。


<details>
  <summary>Details</summary>
Motivation: LLM编码助手生成决策的速度远超团队验证能力，但现有框架无法区分推测与已验证知识，无法防止信任膨胀，也无法检测证据过期，导致AI辅助工程存在风险。

Method: 提出三个核心要求：1）认知分层分离未验证假设与经验验证主张；2）基于Gödel t-范数的保守保证聚合防止弱证据膨胀置信度；3）自动化证据衰减追踪。将要求形式化为FPF框架，基于模糊逻辑定义聚合语义，提出五个不变性公理。

Result: 对两个内部项目的回顾性审计发现，20-25%的架构决策在两个月内证据过时，验证了时间问责的必要性。框架能有效识别和管理决策的认知状态。

Conclusion: AI辅助软件工程需要明确的认知状态和时间有效性追踪机制。FPF框架为解决这一问题提供了理论基础，未来研究方向包括可学习聚合算子、联邦证据共享和基于SMT的主张验证。

Abstract: This position paper argues that AI-assisted software engineering requires explicit mechanisms for tracking the epistemic status and temporal validity of architectural decisions. LLM coding assistants generate decisions faster than teams can validate them, yet no widely-adopted framework distinguishes conjecture from verified knowledge, prevents trust inflation through conservative aggregation, or detects when evidence expires. We propose three requirements for responsible AI-assisted engineering: (1) epistemic layers that separate unverified hypotheses from empirically validated claims, (2) conservative assurance aggregation grounded in the Gödel t-norm that prevents weak evidence from inflating confidence, and (3) automated evidence decay tracking that surfaces stale assumptions before they cause failures. We formalize these requirements as the First Principles Framework (FPF), ground its aggregation semantics in fuzzy logic, and define a quintet of invariants that any valid aggregation operator must satisfy. Our retrospective audit applying FPF criteria to two internal projects found that 20-25% of architectural decisions had stale evidence within two months, validating the need for temporal accountability. We outline research directions including learnable aggregation operators, federated evidence sharing, and SMT-based claim validation.

</details>


### [11] [From Logic to Toolchains: An Empirical Study of Bugs in the TypeScript Ecosystem](https://arxiv.org/abs/2601.21186)
*TianYi Tang,Saba Alimadadi,Nick Sumner*

Main category: cs.SE

TL;DR: 对16个TypeScript项目的633个bug进行大规模实证研究，发现故障类型主要不是逻辑或语法错误，而是工具配置、API误用和异步错误处理问题，这些与构建复杂度和依赖异质性密切相关。


<details>
  <summary>Details</summary>
Motivation: TypeScript已成为现代Web开发的流行语言，但其对软件故障的影响尚不清楚。需要了解TypeScript项目中实际故障的类型和分布，以及项目特征如何影响故障模式。

Method: 分析16个流行的开源TypeScript项目的633个bug报告，构建故障类型分类法，量化其普遍性，并将其与项目大小、领域和依赖组成等特征关联。

Result: 故障景观主要由工具配置故障、API误用和异步错误处理问题主导，而非逻辑或语法错误。这些类别与构建复杂度和依赖异质性强烈相关，表明现代故障常出现在集成和编排边界而非算法逻辑内部。与JavaScript研究的纵向比较显示，TypeScript的静态类型减少了传统运行时和类型错误，但将脆弱性转移到了构建系统和工具链。

Conclusion: 语言设计和生态系统演化会重塑大规模软件系统的故障特征。TypeScript的静态类型改变了故障分布，突出了工具链和集成问题的重要性。这些发现为理解现代软件开发中的故障模式提供了新见解。

Abstract: TypeScript has rapidly become a popular language for modern web development, yet its effect on software faults remains poorly understood. This paper presents the first large-scale empirical study of bugs in real-world TypeScript projects. We analyze 633 bug reports from 16 popular open-source repositories to construct a taxonomy of fault types, quantify their prevalence, and relate them to project characteristics such as size, domain, and dependency composition. Our results reveal a fault landscape dominated not by logic or syntax errors but by tooling and configuration faults, API misuses, and asynchronous error-handling issues. We show that these categories correlate strongly with build complexity and dependency heterogeneity, indicating that modern failures often arise at integration and orchestration boundaries rather than within algorithmic logic. A longitudinal comparison with JavaScript studies shows that while static typing in TypeScript has reduced traditional runtime and type errors, it has shifted fragility toward build systems and toolchains. These findings offer new insight into how language design and ecosystem evolution reshape the fault profiles of large-scale software systems.

</details>


### [12] [Human-Agent versus Human Pull Requests: A Testing-Focused Characterization and Comparison](https://arxiv.org/abs/2601.21194)
*Roberto Milanese,Francesco Salzano,Angelica Spina,Antonio Vitale,Remo Pareschi,Fausto Fasano,Mattia Fazzini*

Main category: cs.SE

TL;DR: 对比人类-智能体协作PR与纯人类PR在软件测试方面的差异：测试频率相似但测试范围更大，测试类型分布不同但质量无显著差异


<details>
  <summary>Details</summary>
Motivation: 尽管AI编码助手在软件开发中日益普及，但人类与智能体协作在软件测试方面的作用仍不明确。本研究旨在实证分析人类-智能体协作PR与纯人类PR在测试实践上的差异。

Method: 使用AIDev数据集，对比分析6,582个人类-智能体协作PR和3,122个纯人类PR，从三个维度进行比较：(1)测试频率和范围，(2)测试相关变更类型（代码-测试协同演化 vs 测试专注），(3)测试质量（通过测试异味衡量）。

Result: 1. 包含测试的可能性相似（HAPRs 42.9% vs HPRs 40.0%），但HAPRs测试范围更大，测试与源代码行数比例几乎是HPRs的两倍；
2. 测试专注任务分布相似，但HAPRs在协同演化中更可能添加新测试（OR=1.79），而HPRs更倾向于修改现有测试；
3. 虽然某些测试异味类别存在统计差异，但效应量可忽略，表明测试质量无实际差异。

Conclusion: 人类-智能体协作显著改变了测试实践：测试范围扩大，测试创建策略从修改现有测试转向添加新测试，但测试质量保持相当。这为理解AI助手如何影响软件开发中的测试行为提供了首个实证特征描述。

Abstract: AI-based coding agents are increasingly integrated into software development workflows, collaborating with developers to create pull requests (PRs). Despite their growing adoption, the role of human-agent collaboration in software testing remains poorly understood. This paper presents an empirical study of 6,582 human-agent PRs (HAPRs) and 3,122 human PRs (HPRs) from the AIDev dataset. We compare HAPRs and HPRs along three dimensions: (i) testing frequency and extent, (ii) types of testing-related changes (code-and-test co-evolution vs. test-focused), and (iii) testing quality, measured by test smells. Our findings reveal that, although the likelihood of including tests is comparable (42.9% for HAPRs vs. 40.0% for HPRs), HAPRs exhibit a larger extent of testing, nearly doubling the test-to-source line ratio found in HPRs. While test-focused task distributions are comparable, HAPRs are more likely to add new tests during co-evolution (OR=1.79), whereas HPRs prioritize modifying existing tests. Finally, although some test smell categories differ statistically, negligible effect sizes suggest no meaningful differences in quality. These insights provide the first characterization of how human-agent collaboration shapes testing practices.

</details>


### [13] [CovAgent: Overcoming the 30% Curse of Mobile Application Coverage with Agentic AI and Dynamic Instrumentation](https://arxiv.org/abs/2601.21253)
*Wei Minn,Biniam Fisseha Demissie,Yan Naing Tun,Jiakun Liu,Mariano Ceccato,Lwin Khin Shar,David Lo*

Main category: cs.SE

TL;DR: CovAgent：一种基于智能AI代理的Android应用UI测试增强框架，通过分析Smali代码和组件转换图，推理并满足活动激活条件，显著提升测试覆盖率


<details>
  <summary>Details</summary>
Motivation: 现有Android应用UI测试技术覆盖率有限（通常低于30%），主要由于无法生成复杂用户输入、设备配置和外部资源激活条件不满足、以及难以通过GUI访问的代码路径

Method: 提出CovAgent框架：1）AI代理分析反编译的Smali代码和组件转换图，推理阻止访问活动的未满足激活条件；2）另一个代理生成动态插桩脚本以满足活动转换所需的激活条件；3）与现有模糊测试方法结合使用

Result: 相比现有最佳方法LLMDroid，活动覆盖率提升101.1%；相比Fastbot和APE分别提升116.3%和179.7%；在类、方法和行覆盖率等其他指标上也优于所有基线方法

Conclusion: CovAgent通过智能AI代理有效解决了Android应用UI测试中的覆盖率瓶颈问题，展示了智能AI在自动化应用测试领域的巨大潜力，为提升测试效果提供了新思路

Abstract: Automated GUI testing is crucial for ensuring the quality and reliability of Android apps. However, the efficacy of existing UI testing techniques is often limited, especially in terms of coverage. Recent studies, including the state-of-the-art, struggle to achieve more than 30% activity coverage in real-world apps. This limited coverage can be attributed to a combination of factors such as failing to generate complex user inputs, unsatisfied activation conditions regarding device configurations and external resources, and hard-to-reach code paths that are not easily accessible through the GUI. To overcome these limitations, we propose CovAgent, a novel agentic AI-powered approach to enhance Android app UI testing. Our fuzzer-agnostic framework comprises an AI agent that inspects the app's decompiled Smali code and component transition graph, and reasons about unsatisfied activation conditions within the app code logic that prevent access to the activities that are unreachable by standard and widely adopted GUI fuzzers. Then, another agent generates dynamic instrumentation scripts that satisfy activation conditions required for successful transitions to those activities. We found that augmenting existing fuzzing approaches with our framework achieves a significant improvement in test coverage over the state-of-the-art, LLMDroid, and other baselines such as Fastbot and APE (e.g., 101.1%, 116.3% and 179.7% higher activity coverage, respectively). CovAgent also outperforms all the baselines in other metrics such as class, method, and line coverage. We also conduct investigations into components within CovAgent to reveal further insights regarding the efficacy of Agentic AI in the field of automated app testing such as the agentic activation condition inference accuracy, and agentic activity-launching success rate.

</details>


### [14] [The Role of Social Identity in Shaping Biases Against Minorities in Software Organizations](https://arxiv.org/abs/2601.21259)
*Sayma Sultana,London Cavaletto,Bianca Trinkenreich,Amiangshu Bosu*

Main category: cs.SE

TL;DR: 该研究应用社会认同理论调查软件工程领域的系统性职场偏见，发现职业发展和任务选择偏见最为普遍，女性遭受偏见风险是男性的三倍以上，边缘化族裔群体更易遭受身份攻击。


<details>
  <summary>Details</summary>
Motivation: 虽然系统性职场偏见在其他非计算领域已有充分记录，但其对软件工程师的具体影响仍知之甚少。本研究旨在填补这一空白，通过社会认同理论框架来理解软件工程领域的偏见现象。

Method: 采用基于情景的问卷调查方法，量化四种偏见形式的普遍性：职业发展不足、刻板任务选择、不友好环境和身份攻击。识别受影响最严重的人口群体，评估偏见后果，并探究偏见行为的动机。

Result: 职业发展和任务选择偏见是最普遍的偏见形式，超过三分之二的受害者多次经历这些偏见。女性遭受职业发展偏见、任务选择偏见和不友好环境的可能性是男性的三倍以上。边缘化族裔背景的个体更容易遭受身份攻击。年龄、工作经验、组织规模和地理位置也是偏见受害的重要预测因素。

Conclusion: 软件工程领域存在严重的系统性职场偏见，需要针对不同人口群体的特定需求制定干预措施。研究强调了超越性别和种族的多元因素在理解职场偏见中的重要性。

Abstract: While systemic workplace bias is well-documented in non-computing fields, its specific impact on software engineers remains poorly understood. This study addresses that gap by applying Social Identity Theory (SIT) to investigate four distinct forms of bias: lack of career development, stereotyped task selection, unwelcoming environments, and identity attacks. Using a vignette-based survey, we quantified the prevalence of these biases, identified the demographics most affected, assessed their consequences, and explored the motivations behind biased actions. Our results show that career development and task selection biases are the most prevalent forms, with over two-thirds of victims experiencing them multiple times. Women were more than three times as likely as men to face career development bias, task selection bias, and an unwelcoming environment. In parallel, individuals from marginalized ethnic backgrounds were disproportionately targeted by identity attacks. Our analysis also confirms that, beyond gender and race, factors such as age, years of experience, organization size, and geographic location are significant predictors of bias victimization.

</details>


### [15] [More Code, Less Reuse: Investigating Code Quality and Reviewer Sentiment towards AI-generated Pull Requests](https://arxiv.org/abs/2601.21276)
*Haoming Huang,Pongchai Jaisri,Shota Shimizu,Lingfeng Chen,Sota Nakashima,Gema Rodríguez-Pérez*

Main category: cs.SE

TL;DR: 研究评估LLM代理在代码生成中对代码质量和可维护性的影响，发现AI生成的代码冗余度高但评审者情绪更中性/积极，导致技术债务的无声积累。


<details>
  <summary>Details</summary>
Motivation: 现有指标仅衡量通过率，无法反映LLM代理对长期可维护性和可读性的影响，也无法捕捉人类对PR的直观评价。需要更全面地评估LLM在代码生成中的特性。

Method: 基于代码指标评估PR中的代码质量和可维护性，从人类和LLM生成两个角度分析开发者对PR的反应，包括情感分析。

Result: LLM代理经常忽视代码复用机会，导致比人类开发者更高的冗余度。但评审者对AI生成代码表达更中性或积极情绪，表明AI代码的表面合理性掩盖了冗余问题。

Conclusion: AI代码的表面合理性掩盖了冗余问题，导致在实际开发环境中技术债务的无声积累。研究为改进人-AI协作提供了见解。

Abstract: Large Language Model (LLM) Agents are advancing quickly, with the increasing leveraging of LLM Agents to assist in development tasks such as code generation. While LLM Agents accelerate code generation, studies indicate they may introduce adverse effects on development. However, existing metrics solely measure pass rates, failing to reflect impacts on long-term maintainability and readability, and failing to capture human intuitive evaluations of PR. To increase the comprehensiveness of this problem, we investigate and evaluate the characteristics of LLM to know the pull requests' characteristics beyond the pass rate. We observe the code quality and maintainability within PRs based on code metrics to evaluate objective characteristics and developers' reactions to the pull requests from both humans and LLM's generation. Evaluation results indicate that LLM Agents frequently disregard code reuse opportunities, resulting in higher levels of redundancy compared to human developers. In contrast to the quality issues, our emotions analysis reveals that reviewers tend to express more neutral or positive emotions towards AI-generated contributions than human ones. This disconnect suggests that the surface-level plausibility of AI code masks redundancy, leading to the silent accumulation of technical debt in real-world development environments. Our research provides insights for improving human-AI collaboration.

</details>


### [16] [Detecting Multiple Semantic Concerns in Tangled Code Commits](https://arxiv.org/abs/2601.21298)
*Beomsu Koh,Neil Walkinshaw,Donghwan Shin*

Main category: cs.SE

TL;DR: 本文研究使用小型语言模型检测代码提交中的多个关注点，将多关注点检测构建为多标签分类问题，并通过实验证明包含提交信息可显著提升检测准确率。


<details>
  <summary>Details</summary>
Motivation: 实际开发中，开发者经常将多个关注点（如添加功能、修复bug等）捆绑在同一个代码提交中，形成"纠缠提交"，这模糊了提交意图并增加了维护难度。现有研究虽然使用语言模型捕获提交意图，但未解决涉及多个关注点的纠缠提交问题。

Method: 将多关注点检测构建为多标签分类问题，基于真实数据构建人工纠缠提交的受控数据集。使用小型语言模型进行实证研究，考察微调、关注点数量、提交信息包含、头部保留截断等因素在实用token预算限制下的影响。

Result: 微调的140亿参数小型语言模型在单关注点提交检测上与最先进的大型语言模型竞争力相当，最多可处理三个关注点。包含提交信息可将检测准确率提升高达44%（以汉明损失衡量），且延迟开销可忽略，证明提交信息是重要的语义线索。

Conclusion: 小型语言模型可用于检测代码提交中的多个关注点，包含提交信息能显著提升检测性能，这为处理纠缠提交提供了实用解决方案，有助于改善代码维护和理解。

Abstract: Code commits in a version control system (e.g., Git) should be atomic, i.e., focused on a single goal, such as adding a feature or fixing a bug. In practice, however, developers often bundle multiple concerns into tangled commits, obscuring intent and complicating maintenance. Recent studies have used Conventional Commits Specification (CCS) and Language Models (LMs) to capture commit intent, demonstrating that Small Language Models (SLMs) can approach the performance of Large Language Models (LLMs) while maintaining efficiency and privacy. However, they do not address tangled commits involving multiple concerns, leaving the feasibility of using LMs for multi-concern detection unresolved. In this paper, we frame multi-concern detection in tangled commits as a multi-label classification problem and construct a controlled dataset of artificially tangled commits based on real-world data. We then present an empirical study using SLMs to detect multiple semantic concerns in tangled commits, examining the effects of fine-tuning, concern count, commit-message inclusion, and header-preserving truncation under practical token-budget limits. Our results show that a fine-tuned 14B-parameter SLM is competitive with a state-of-the-art LLM for single-concern commits and remains usable for up to three concerns. In particular, including commit messages improves detection accuracy by up to 44% (in terms of Hamming Loss) with negligible latency overhead, establishing them as important semantic cues.

</details>


### [17] [Developers in the Age of AI: Adoption, Policy, and Diffusion of AI Software Engineering Tools](https://arxiv.org/abs/2601.21305)
*Mark Looi,Julianne Quinn*

Main category: cs.SE

TL;DR: 研究147位专业开发者使用AI工具的模式，发现频繁广泛使用AI工具与感知生产力和代码质量正相关，形成良性采纳循环。开发者分为三类（热衷者、务实者、谨慎者），组织采纳遵循创新扩散过程。安全担忧是采纳障碍，测试工具采纳滞后于编码工具。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI快速进入软件开发领域，需要实证研究AI工具对开发实践的影响，了解开发者的使用模式、感知效果、生产力和质量结果，以及开发者对AI增强开发的准备情况。

Method: 研究147位专业开发者的使用模式，通过调查分析AI工具使用的感知相关性、生产力和质量结果，以及未来采纳意向。识别开发者原型并分析组织采纳过程。

Result: 发现频繁广泛使用AI工具与感知生产力和代码质量正相关，形成良性采纳循环。没有证据支持质量悖论。开发者分为三类原型，组织采纳遵循创新扩散过程。安全担忧是采纳障碍，测试工具采纳滞后（测试差距）。

Conclusion: AI工具在软件开发中形成良性采纳循环，频繁使用驱动生产力和质量提升。组织采纳遵循创新扩散模式，政策本身不预测个人使用意向，而是成熟度的标志。需要解决安全担忧和测试工具采纳滞后问题。

Abstract: The rapid advance of Generative AI into software development prompts this empirical investigation of perceptual effects on practice. We study the usage patterns of 147 professional developers, examining perceived correlates of AI tools use, the resulting productivity and quality outcomes, and developer readiness for emerging AI-enhanced development. We describe a virtuous adoption cycle where frequent and broad AI tools use are the strongest correlates of both Perceived Productivity (PP) and quality, with frequency strongest. The study finds no perceptual support for the Quality Paradox and shows that PP is positively correlated with Perceived Code Quality (PQ) improvement. Developers thus report both productivity and quality gains. High current usage, breadth of application, frequent use of AI tools for testing, and ease of use correlate strongly with future intended adoption, though security concerns remain a moderate and statistically significant barrier to adoption. Moreover, AI testing tools' adoption lags that of coding tools, opening a Testing Gap. We identify three developer archetypes (Enthusiasts, Pragmatists, Cautious) that align with an innovation diffusion process wherein the virtuous adoption cycle serves as the individual engine of progression. Our findings reveal that organizational adoption of AI tools follows such a process: Enthusiasts push ahead with tools, creating organizational success that converts Pragmatists. The Cautious are held in organizational stasis: without early adopter examples, they don't enter the virtuous adoption cycle, never accumulate the usage frequency that drives intent, and never attain high efficacy. Policy itself does not predict individuals' intent to increase usage but functions as a marker of maturity, formalizing the successful diffusion of adoption by Enthusiasts while acting as a gateway that the Cautious group has yet to reach.

</details>


### [18] [Predicting Developer Acceptance of AI-Generated Code Suggestions](https://arxiv.org/abs/2601.21379)
*Jing Jiang,Liehao Li,Jinyun Hou,Xin Tan,Li Zhang*

Main category: cs.SE

TL;DR: 论文通过分析66,329个工业开发者-AI交互数据，识别了代码建议被接受的特征差异，并提出了CSAP预测模型，准确率达0.973，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前AI辅助编程工具常因提供不受欢迎的建议而中断开发者工作流，但缺乏对开发者接受AI生成代码建议的定量分析，主要因为细粒度交互数据通常是专有的。

Method: 使用大型科技公司的66,329个工业开发者-AI交互数据进行实证研究，分析被接受和被拒绝代码建议的特征差异，并基于发现构建CSAP（代码建议接受预测）模型。

Result: 发现被接受的建议具有显著更高的开发者和项目历史接受计数和比率、更长的生成间隔、更短的前置代码上下文以及更旧的IDE版本。CSAP在非平衡数据集上准确率达0.973，在平衡数据集上达0.922，相对改进显著。

Conclusion: 针对性个性化是过滤预测会被拒绝的代码建议、减少开发者中断的有效方法。这是首个基于大规模工业数据的代码建议接受定量研究，为AI辅助编程开辟了重要研究方向。

Abstract: AI-assisted programming tools are widely adopted, yet their practical utility is often undermined by undesired suggestions that interrupt developer workflows and cause frustration. While existing research has explored developer-AI interactions when programming qualitatively, a significant gap remains in quantitative analysis of developers' acceptance of AI-generated code suggestions, partly because the necessary fine-grained interaction data is often proprietary. To bridge this gap, this paper conducts an empirical study using 66,329 industrial developer-AI interactions from a large technology company. We analyze features that are significantly different between accepted code suggestions and rejected ones. We find that accepted suggestions are characterized by significantly higher historical acceptance counts and ratios for both developers and projects, longer generation intervals, shorter preceding code context in the project, and older IDE versions. Based on these findings, we introduce CSAP (Code Suggestion Acceptance Prediction) to predict whether a developer will accept the code suggestion before it is displayed. Our evaluation of CSAP shows that it achieves the accuracy of 0.973 and 0.922 on imbalanced and balanced dataset respectively. Compared to a large language model baseline and an in-production industrial filter, CSAP relatively improves the accuracy by 12.6\% and 69.5\% on imbalanced dataset, and improves the accuracy by 87.0\% and 140.1\% on balanced dataset. Our results demonstrate that targeted personalization is a powerful approach for filtering out code suggestions with predicted rejection and reduce developer interruption. To the best of our knowledge, it is the first quantitative study of code suggestion acceptance on large-scale industrial data, and this work also sheds light on an important research direction of AI-assisted programming.

</details>


### [19] [Adaptive Confidence Gating in Multi-Agent Collaboration for Efficient and Optimized Code Generation](https://arxiv.org/abs/2601.21469)
*Haoji Zhang,Yuzhe Li,Zhenqiang Liu,Chenyang Liu,Shenyang Zhang,Yi Zhou*

Main category: cs.SE

TL;DR: DebateCoder是一个多智能体协作框架，通过角色扮演协议提升小型语言模型在代码生成中的推理能力，在资源受限环境中实现高效高质量的自动化软件工程。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在代码生成方面取得突破，但小型语言模型在处理复杂逻辑需求时经常遇到推理瓶颈和失败循环。需要在资源受限环境中提升小型语言模型的推理能力。

Method: 提出DebateCoder多智能体协作框架，包含三个角色：用户代理、技术代理和质量保证代理。采用自适应置信门控机制（95%阈值）平衡准确性和推理效率，引入多轮审议模块和评审引导的分析调试循环。

Result: 在HumanEval和MBPP基准测试中，DebateCoder在HumanEval上达到70.12%的Pass@1，优于MapCoder，同时减少约35%的API开销。

Conclusion: 协作协议可以缓解小参数模型的局限性，为高质量自动化软件工程提供可扩展、高效的方法。

Abstract: While Large Language Models (LLMs) have catalyzed breakthroughs in automated code generation, Small Language Models (SLMs) often encounter reasoning bottlenecks and failure loops when addressing complex logical requirements. To overcome these challenges, we propose DebateCoder, a multi-agent collaborative framework designed to improve the reasoning ability of SLMs (e.g., Pangu-1B) in resource-constrained environments. DebateCoder uses a structured role-playing protocol with three agents: User Agent (A_UA), Technical Agent (A_TA), and Quality Assurance Agent (A_QA). It also includes an Adaptive Confidence Gating mechanism with a 95% threshold to balance accuracy and inference efficiency. In addition, we introduce a multi-turn deliberation module and a reviewer-guided analytical debugging loop for orthogonal pre-generation debate and post-generation refinement. Experiments on HumanEval and MBPP show that DebateCoder achieves 70.12% Pass@1 on HumanEval, outperforming MapCoder while reducing API overhead by about 35%. These results indicate that collaborative protocols can mitigate limitations of small-parameter models and provide a scalable, efficient approach to high-quality automated software engineering.

</details>


### [20] [Chasing Elusive Memory Bugs in GPU Programs](https://arxiv.org/abs/2601.21552)
*Anubhab Ghosh,Ajay Nayak,Dhananjay Rao Thallikar Shyam,Arkaprava Basu*

Main category: cs.SE

TL;DR: SCuBA：首个编译时静态分析工具，通过分析CPU和GPU代码中的语义关系来检测输入依赖型和分配内越界访问，相比运行时工具能发现更多隐蔽的内存安全漏洞。


<details>
  <summary>Details</summary>
Motivation: GPU程序中的内存安全漏洞（如越界访问）会威胁GPU加速软件的安全性和可靠性。现有检测工具依赖运行时技术，只能检测到实际触发的漏洞，无法发现输入依赖型越界访问和分配内越界访问。

Method: SCuBA通过分析CPU代码（负责内存分配）和GPU代码（负责内存访问）之间的语义关系，将这些关系表达为约束条件，使用SAT求解器检查是否存在任何输入会导致越界访问。同时分析GPU代码以追踪内存分配的逻辑分区，检测分配内越界访问。

Result: 相比NVIDIA的Compute Sanitizer在20个程序中漏报45个隐蔽内存漏洞，SCuBA实现了零漏报且无误报，显著优于现有运行时检测工具。

Conclusion: SCuBA是首个编译时静态分析工具，能够有效检测GPU程序中输入依赖型和分配内越界访问，填补了现有运行时检测工具的空白，提高了GPU程序的内存安全性。

Abstract: Memory safety bugs, such as out-of-bound accesses (OOB) in GPU programs, can compromise the security and reliability of GPU-accelerated software. We report the existence of input-dependent OOBs in the wild that manifest only under specific inputs. All existing tools to detect OOBs in GPU programs rely on runtime techniques that require an OOB to manifest for detection. Thus, input-dependent OOBs elude them. We also discover intra-allocation OOBs that arise in the presence of logical partitioning of a memory allocation into multiple data structures. Existing techniques are oblivious to the possibility of such OOBs.
  We make a key observation that the presence (or absence) of semantic relations among program variables, which determines the size of allocations (CPU code) and those calculating offsets into memory allocations (GPU code), helps identify the absence (or presence) of OOBs. We build SCuBA, a first-of-its-kind compile-time technique that analyzes CPU and GPU code to capture such semantic relations (if present). It uses a SAT solver to check if an OOB access is possible under any input, given the captured relations expressed as constraints. It further analyzes GPU code to track logical partitioning of memory allocations for detecting intra-allocation OOB. Compared to NVIDIA's Compute Sanitizer that misses 45 elusive memory bugs across 20 programs, SCuBA misses none with no false alarms.

</details>


### [21] [Multi-objective Integer Linear Programming approach for Automatic Software Cognitive Complexity Reduction](https://arxiv.org/abs/2601.21565)
*Adriana Novoa-Hurtado,Rubén Saborido,Francisco Chicano,Manuel Giménez-Medina*

Main category: cs.SE

TL;DR: 提出多目标整数线性规划模型，通过提取方法重构来降低代码认知复杂度，平衡代码行数和认知复杂度


<details>
  <summary>Details</summary>
Motivation: 清晰简洁的代码对于可维护性至关重要，需要降低代码复杂度以避免错误和漏洞。提取方法重构是减少代码理解工作量的主要手段，但存在多个评价标准，需要多目标优化方法。

Method: 使用SonarSource定义的认知复杂度度量，将代码提取问题建模为多目标整数线性规划问题，平衡代码行数和认知复杂度，并开发了多种算法进行验证。

Result: 开发了参数化解决软件认知复杂度降低问题的工具，能够生成一组降低代码认知复杂度的解决方案。

Conclusion: 提出的多目标优化模型和工具能够有效降低代码认知复杂度，提高软件可维护性，通过提取方法重构实现代码简化。

Abstract: Clear and concise code is necessary to ensure maintainability, so it is crucial that the software is as simple as possible to understand, to avoid bugs and, above all, vulnerabilities. There are many ways to enhance software without changing its functionality, considering the extract method refactoring the primary process to reduce the effort required for code comprehension. The cognitive complexity measure employed in this work is the one defined by SonarSource, which is a company that develops well-known applications for static code analysis. This extraction problem can be modeled as a combinatorial optimization problem. The main difficulty arises from the existence of different criteria for evaluating the solutions obtained, requiring the formulation of the code extraction problem as a multi-objective optimization problem using alternative methods. We propose a multi-objective integer linear programming model to obtain a set of solutions that reduce the cognitive complexity of a given piece of code, such as balancing the number of lines of code and its cognitive complexity. In addition, several algorithms have been developed to validate the model. These algorithms have been integrated into a tool that enables the parameterised resolution of the problem of reducing software cognitive complexity.

</details>


### [22] [Is My RPC Response Reliable? Detecting RPC Bugs in Ethereum Blockchain Client under Context](https://arxiv.org/abs/2601.21593)
*Zhijie Zhong,Yuhong Nan,Mingxi Ye,Qing Xue,Jiashui Wang,Xinlei Ying,Long Liu,Zibin Zheng*

Main category: cs.SE

TL;DR: EthCRAFT：一种针对以太坊客户端RPC漏洞的上下文感知模糊测试工具，通过生成区块链状态上下文和RPC调用来检测上下文相关的RPC漏洞


<details>
  <summary>Details</summary>
Motivation: 现有区块链客户端RPC漏洞检测主要关注生成RPC方法调用，但许多报告的RPC漏洞需要在特定区块链上下文中才能触发。目前缺乏生成适当上下文来触发这些上下文相关漏洞的研究。

Method: 1. 探索区块链客户端的状态转换程序空间，生成各种交易来构建上下文
2. 设计上下文感知的RPC方法调用生成方法
3. 使用5个不同客户端实现的响应作为交叉参考预言机来检测RPC漏洞

Result: 1. 在从以太坊客户端GitHub问题收集的真实RPC漏洞上评估，EthCRAFT优于现有客户端RPC检测器，能检测更多RPC漏洞
2. 在主要以太坊客户端中发现了6个新漏洞并报告给开发者
3. 其中一个漏洞修复已被写入客户端的重大变更更新
4. 三个漏洞报告获得了以太坊基金会的漏洞赏金

Conclusion: EthCRAFT通过上下文感知的方法有效检测区块链客户端RPC漏洞，证明了考虑区块链上下文对于RPC漏洞检测的重要性，并成功发现了多个实际漏洞。

Abstract: Blockchain clients are fundamental software for running blockchain nodes. They provide users with various RPC (Remote Procedure Call) interfaces to interact with the blockchain. These RPC methods are expected to follow the same specification across different blockchain nodes, providing users with seamless interaction. However, there have been continuous reports on various RPC bugs that can cause unexpected responses or even Denial of Service weakness. Existing studies on blockchain RPC bug detection mainly focus on generating the RPC method calls for testing blockchain clients. However, a wide range of the reported RPC bugs are triggered in various blockchain contexts. To the best of our knowledge, little attention is paid to generating proper contexts that can trigger these context-dependent RPC bugs.
  In this work, we propose EthCRAFT, a Context-aware RPC Analysis and Fuzzing Tool for client RPC bug detection. EthCRAFT first proposes to explore the state transition program space of blockchain clients and generate various transactions to construct the context. EthCRAFT then designs a context-aware RPC method call generation method to send RPC calls to the blockchain clients. The responses of 5 different client implementations are used as cross-referring oracles to detect the RPC bugs. We evaluate EthCRAFT on real-world RPC bugs collected from the GitHub issues of Ethereum client implementations. Experiment results show that EthCRAFT outperforms existing client RPC detectors by detecting more RPC bugs. Moreover, EthCRAFT has found six new bugs in major Ethereum clients and reported them to the developers. One of the bug fixes has been written into breaking changes in the client's updates. Three of our bug reports have been offered a vulnerability bounty by the Ethereum Foundation.

</details>


### [23] [Age Matters: Analyzing Age-Related Discussions in App Reviews](https://arxiv.org/abs/2601.21605)
*Shashiwadana Nirmania,Garima Sharma,Hourieh Khalajzadeh,Mojtaba Shahin*

Main category: cs.SE

TL;DR: 该研究通过分析Google Play商店的4,163条应用评论，使用机器学习模型自动检测年龄相关讨论，并识别出用户对移动应用年龄包容性的六大关注主题。


<details>
  <summary>Details</summary>
Motivation: 尽管移动应用在日常生活中日益重要，但不同年龄用户面临独特挑战（如年轻用户接触不当内容、老年用户因视力认知问题难以使用）。现有应用在满足各年龄段需求方面存在不足，且开发者对用户年龄相关问题的理解有限，阻碍了有效解决方案的实施。

Method: 从Google Play商店手动收集4,163条应用评论，识别出1,429条年龄相关评论和2,734条非年龄相关评论。使用八种机器学习、深度学习和大型语言模型自动检测年龄讨论，其中RoBERTa表现最佳。对年龄相关评论进行定性分析。

Result: RoBERTa模型在检测年龄讨论方面表现最佳，精确率达到92.46%。定性分析揭示了反映用户关注的六大主导主题，为理解不同年龄用户的需求提供了深入见解。

Conclusion: 通过分析应用评论中的年龄讨论，研究揭示了移动应用在满足不同年龄用户需求方面的具体挑战和关注点，为开发者创建更年龄包容的应用提供了实证基础和实践指导。

Abstract: In recent years, mobile applications have become indispensable tools for managing various aspects of life. From enhancing productivity to providing personalized entertainment, mobile apps have revolutionized people's daily routines. Despite this rapid growth and popularity, gaps remain in how these apps address the needs of users from different age groups. Users of varying ages face distinct challenges when interacting with mobile apps, from younger users dealing with inappropriate content to older users having difficulty with usability due to age-related vision and cognition impairments. Although there have been initiatives to create age-inclusive apps, a limited understanding of user perspectives on age-related issues may hinder developers from recognizing specific challenges and implementing effective solutions. In this study, we explore age discussions in app reviews to gain insights into how mobile apps should cater to users across different age groups.We manually curated a dataset of 4,163 app reviews from the Google Play Store and identified 1,429 age-related reviews and 2,734 non-age-related reviews. We employed eight machine learning, deep learning, and large language models to automatically detect age discussions, with RoBERTa performing the best, achieving a precision of 92.46%. Additionally, a qualitative analysis of the 1,429 age-related reviews uncovers six dominant themes reflecting user concerns.

</details>


### [24] [AtPatch: Debugging Transformers via Hot-Fixing Over-Attention](https://arxiv.org/abs/2601.21695)
*Shihao Weng,Yang Feng,Jincheng Li,Yining Yin,Xiaofei Xie,Jia Liu*

Main category: cs.SE

TL;DR: AtPatch是一种动态重分布注意力图的热修复方法，通过检测异常注意力列并用良性注意力替换，有效缓解后门攻击和不公平性，同时保持模型原有功能。


<details>
  <summary>Details</summary>
Motivation: 现有基于Transformer的深度神经网络容易受到后门攻击和不公平性影响，表现为异常注意力模式（过度关注后门触发器或受保护属性）。现有的神经元编辑缓解策略往往缺乏灵活性，容易扭曲特征表示，且难以处理此类情况。

Method: AtPatch采用热修复方法，在模型推理过程中动态重分布注意力图：1）提取模型推理过程中的注意力图；2）使用预训练检测器识别异常列并用统一的良性注意力替换；3）重新缩放其他列以减轻过度关注的影响；4）将重分布后的注意力图返回给模型继续推理。如果没有检测到异常列，则直接返回原始注意力图。

Result: 实验结果表明，与现有方法相比，AtPatch能更有效地缓解后门攻击和不公平性，同时更好地保持模型的原始功能。其即时处理特性使其无需修改模型参数或重新训练，更适合已部署模型。

Conclusion: AtPatch通过选择性重分布注意力图，在缓解后门攻击和不公平性的同时，更好地保留了模型原有功能，为已部署模型提供了一种灵活有效的热修复解决方案。

Abstract: Transformer-based deep neural networks (DNNs) affected by backdoor attacks and unfairness typically exhibit anomalous attention patterns, leading to over-attend to backdoor triggers or protected attributes. Existing neuron-editing mitigation strategies often struggle to handle such situation and most of them lack flexibility and tend to distort feature representations. Motivated by such over-attention phenomenon and software engineering paradigms such as delta debugging and hot patching, we propose AtPatch, a hot-fix method that dynamically redistributes attention maps during model inference. Specifically, for a given input, AtPatch first extracts the attention map from the model's inference process. Then, it uses a pre-trained detector to identify anomalous columns and replace them with unified benign attention. Then, AtPatch rescales other columns to mitigate the impact of over-attention. Finally, AtPatch returns the redistributed attention map to the model for continued inference. Notably, if the detector does not report any anomalous columns, AtPatch directly returns the original attention map to the model. Unlike existing techniques, AtPatch selectively redistributes the attention map, making it better at preserving the model's original functionality. Furthermore, AtPatch's on-the-fly nature allows it to work without modifying model parameters or retraining, making it better suited for deployed models. We conducted extensive experiments to validate AtPatch. Experimental results show that, compared to existing methods, AtPatch can more effectively mitigate backdoor attacks and unfairness while better preserving the model's original functionality.

</details>


### [25] [Migrating Esope to Fortran 2008 using model transformations](https://arxiv.org/abs/2601.21755)
*Younoussa Sow,Nicolas Anquetil,Léandre Brault,Stéphane Ducasse*

Main category: cs.SE

TL;DR: 开发自动化工具将带有Esope专有扩展的FORTRAN 77代码迁移到Fortran 2008，保持代码可读性和抽象级别


<details>
  <summary>Details</summary>
Motivation: FORTRAN 77等遗留编程语言仍在工业应用中扮演重要角色，但维护和现代化这些语言面临挑战，特别是当存在专有扩展时。专有扩展的语义通常基于旧上下文（遗留语言限制、领域逻辑等），使得迁移到新标准如Fortran 2008更加困难。

Method: 采用模型驱动工程方法，通过转换生成目标模型，然后从该模型导出易于阅读的Fortran 2008源代码。工具支持将带有Esope专有扩展的FORTRAN 77代码转换为Fortran 2008，同时保持代码可读性和Esope提供的抽象级别。

Result: 开发了一个能够自动迁移FORTRAN 77+Esope代码到Fortran 2008的工具。该方法支持生成易于阅读的代码，同时保持原有的抽象级别。

Conclusion: 提出的方法能够有效解决遗留FORTRAN代码的现代化问题，特别是在存在专有扩展的情况下。论文讨论了该方法的优势、限制和维护性考虑，并提供了关于其可扩展性和适应演化需求的见解。

Abstract: Legacy programming languages such as FORTRAN 77 still play a vital role in many industrial applications. Maintaining and modernizing these languages is challenging, especially when migrating to newer standards such as Fortran 2008. This is exacerbated in the presence of legacy proprietary extensions on such legacy languages, because their semantics are often based on old context (limits of legacy language, domain logic,...). This paper presents an approach for automatically migrating FORTRAN 77 with a proprietary extension, named Esope, to Fortran 2008. We introduce a tool that converts Esope source code to Fortran 2008. While supporting readability of the generated code, we want to maintain the level of abstraction provided by Esope. Our method uses model-driven engineering techniques, with transformations to generate a target model from which we export easy-to-read Fortran 2008 source code. We discuss the advantages, limitations, and maintainability considerations of our approach and provide insights into its scalability and adaptability to evolving requirements.

</details>


### [26] [Towards A Sustainable Future for Peer Review in Software Engineering](https://arxiv.org/abs/2601.21761)
*Esteban Parra,Sonia Haiduc,Preetha Chatterjee,Ramtin Ehsani,Polina Iaremchuk*

Main category: cs.SE

TL;DR: 软件工程社区面临评审资源不足的问题，作者提出通过吸引培训新评审者、激励更多社区成员参与、谨慎整合AI工具来构建更可扩展、包容和弹性的同行评审体系


<details>
  <summary>Details</summary>
Motivation: 软件工程领域论文投稿量快速增长，但合格评审者数量不足，这种失衡可能制约和负面影响SE研究社区的长期发展，需要解决评审资源短缺问题

Method: 提出未来SE研究格局的愿景，包含三个主要机制：1)吸引和培训新评审者，2)激励更多社区成员担任评审者，3)谨慎整合AI工具支持高质量评审过程

Result: 提出了一个更可扩展、包容和弹性的同行评审流程框架，旨在通过多管齐下的方法解决评审资源不足的挑战

Conclusion: 需要构建一个能够应对投稿量增长的可持续同行评审生态系统，通过社区参与和技术辅助相结合的方式确保软件工程研究的质量评估

Abstract: Peer review is the main mechanism by which the software engineering community assesses the quality of scientific results. However, the rapid growth of paper submissions in software engineering venues has outpaced the availability of qualified reviewers, creating a growing imbalance that risks constraining and negatively impacting the long-term growth of the Software Engineering (SE) research community. Our vision of the Future of the SE research landscape involves a more scalable, inclusive, and resilient peer review process that incorporates additional mechanisms for: 1) attracting and training newcomers to serve as high-quality reviewers, 2) incentivizing more community members to serve as peer reviewers, and 3) cautiously integrating AI tools to support a high-quality review process.

</details>


### [27] [Assessing the Business Process Modeling Competences of Large Language Models](https://arxiv.org/abs/2601.21787)
*Chantale Lauer,Peter Pfeiffer,Alexander Rombach,Nijat Mehdiyev*

Main category: cs.SE

TL;DR: 本文提出了BEF4LLM框架，用于系统评估LLM生成的BPMN模型质量，发现LLM在语法和实用质量方面表现优异，但在语义质量和有效性方面仍落后于人类专家。


<details>
  <summary>Details</summary>
Motivation: BPMN建模需要领域知识和建模技能，耗时且复杂。虽然LLM在从自然语言生成BPMN模型方面展现出潜力，但缺乏系统性的评估方法。现有方法要么使用LLM作为评判者，要么没有考虑既定的模型质量维度。

Method: 提出了BEF4LLM评估框架，包含四个质量维度：语法质量、实用质量、语义质量和有效性。使用该框架对开源LLM进行全面分析，并将其性能与人类建模专家进行基准比较。

Result: LLM在语法和实用质量方面表现出色，而人类在语义方面表现更好；但得分差异相对较小，表明LLM具有竞争潜力，尽管在有效性和语义质量方面仍面临挑战。

Conclusion: 研究揭示了LLM在BPMN建模中的当前优势和局限性，为未来模型开发和微调提供了指导。解决这些领域的问题对于推进LLM在业务流程建模中的实际部署至关重要。

Abstract: The creation of Business Process Model and Notation (BPMN) models is a complex and time-consuming task requiring both domain knowledge and proficiency in modeling conventions. Recent advances in large language models (LLMs) have significantly expanded the possibilities for generating BPMN models directly from natural language, building upon earlier text-to-process methods with enhanced capabilities in handling complex descriptions. However, there is a lack of systematic evaluations of LLM-generated process models. Current efforts either use LLM-as-a-judge approaches or do not consider established dimensions of model quality. To this end, we introduce BEF4LLM, a novel LLM evaluation framework comprising four perspectives: syntactic quality, pragmatic quality, semantic quality, and validity. Using BEF4LLM, we conduct a comprehensive analysis of open-source LLMs and benchmark their performance against human modeling experts. Results indicate that LLMs excel in syntactic and pragmatic quality, while humans outperform in semantic aspects; however, the differences in scores are relatively modest, highlighting LLMs' competitive potential despite challenges in validity and semantic quality. The insights highlight current strengths and limitations of using LLMs for BPMN modeling and guide future model development and fine-tuning. Addressing these areas is essential for advancing the practical deployment of LLMs in business process modeling.

</details>


### [28] [Folklore in Software Engineering: A Definition and Conceptual Foundations](https://arxiv.org/abs/2601.21814)
*Eduard Enoiu,Jean Malm,Gregory Gay*

Main category: cs.SE

TL;DR: 该论文探讨软件工程中的民间传说概念，通过文献综述和访谈研究，定义了软件工程民间传说的特征和作用，并提出了一个工作定义。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探索软件工程领域中存在的民间传说现象，包括叙事、神话、仪式、幽默和非正式知识，这些内容在开发社区中传播但缺乏系统研究。研究者希望明确这一概念，为后续的民族志研究和反思实践提供基础。

Method: 采用混合研究方法：1）文献综述和主题分析，收集和分析软件工程民间传说的典型案例（如缺陷分布信念、10倍效率开发者传说、技术债务等）；2）对瑞典12名工业从业者进行半结构化访谈，了解这些叙事在实际工作中的识别、传播和影响。

Result: 研究提出了软件工程民间传说的一个工作定义：在职业民间群体中非正式传播、传统性和涌现性的叙事和启发式方法，这些内容塑造身份认同、价值观和集体知识。研究发现这些民间传说在软件工程实践中普遍存在，并具有叙事形式、象征意义、职业相关性和知识领域联系等特征。

Conclusion: 明确软件工程民间传说的概念为后续的民族志和民间传说研究提供了基础，也为反思实践创造了条件。这有助于保存有效的上下文启发式方法，同时挑战无益的民间传说，促进更健康的软件工程文化。

Abstract: We explore the concept of folklore within software engineering, drawing from folklore studies to define and characterize narratives, myths, rituals, humor, and informal knowledge that circulate within software development communities. Using a literature review and thematic analysis, we curated exemplar folklore items (e.g., beliefs about where defects occur, the 10x developer legend, and technical debt). We analyzed their narrative form, symbolic meaning, occupational relevance, and links to knowledge areas in software engineering. To ground these concepts in practice, we conducted semi-structured interviews with 12 industrial practitioners in Sweden to explore how such narratives are recognized or transmitted within their daily work and how they affect it. Synthesizing these results, we propose a working definition of software engineering folklore as informally transmitted, traditional, and emergent narratives and heuristics enacted within occupational folk groups that shape identity, values, and collective knowledge. We argue that making the concept of software engineering folklore explicit provides a foundation for subsequent ethnography and folklore studies and for reflective practice that can preserve context-effective heuristics while challenging unhelpful folklore.

</details>


### [29] [SWE-Replay: Efficient Test-Time Scaling for Software Engineering Agents](https://arxiv.org/abs/2601.22129)
*Yifeng Ding,Lingming Zhang*

Main category: cs.SE

TL;DR: SWE-Replay：一种高效且可泛化的测试时扩展技术，通过重用先前轨迹而非从头采样，在软件工程任务中降低计算成本并提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有测试时扩展方法（如重复采样轨迹）计算成本高，而基于价值代理的方法存在模型校准问题和泛化性不足，无法适应现代代理使用自定义bash脚本作为工具的情况。

Method: SWE-Replay通过重用先前试验的轨迹，在关键中间步骤动态选择从头探索或利用存档经验进行分支，选择依据是仓库探索的潜力和推理重要性，而非外部LLM质量估计。

Result: 在SWE-Bench Verified上，SWE-Replay相比朴素扩展方法，成本降低高达17.4%，性能提升高达3.8%。在SWE-Bench Pro和Multilingual上的进一步验证证明了其泛化能力。

Conclusion: SWE-Replay为软件工程代理的高效测试时扩展提供了稳健基础，无需依赖可能嘈杂的价值估计，实现了成本降低与性能提升的双重优势。

Abstract: Test-time scaling has been widely adopted to enhance the capabilities of Large Language Model (LLM) agents in software engineering (SWE) tasks. However, the standard approach of repeatedly sampling trajectories from scratch is computationally expensive. While recent methods have attempted to mitigate costs using specialized value agents, they can suffer from model miscalibration and fail to generalize to modern agents that synthesize custom bash scripts as tools. In this paper, we introduce SWE-Replay, the first efficient and generalizable test-time scaling technique for modern agents without reliance on potentially noisy value estimates. SWE-Replay optimizes the scaling process by recycling trajectories from prior trials, dynamically choosing to either explore from scratch or exploit archived experience by branching at critical intermediate steps. This selection of intermediate steps is driven by the potential and reasoning significance of repository exploration, rather than external LLM-based quality estimates. Our evaluation shows that, on SWE-Bench Verified, SWE-Replay consistently outperforms naive scaling, reducing costs by up to 17.4% while maintaining or even improving performance by up to 3.8%. Further evaluation on SWE-Bench Pro and Multilingual validates the generalizability of SWE-Replay, establishing it as a robust foundation for efficient test-time scaling of software engineering agents.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [30] [Ira: Efficient Transaction Replay for Distributed Systems](https://arxiv.org/abs/2601.21286)
*Adithya Bhat,Harshal Bhadreshkumar Shah,Mohsen Minaei*

Main category: cs.DC

TL;DR: Ira框架通过传输紧凑的提示信息来加速主备复制中的备份重放，在以太坊案例中实现了25倍的中位数加速


<details>
  <summary>Details</summary>
Motivation: 在主备复制中，共识延迟受限于备份节点重放主节点提议交易的时间。主节点已经执行过交易，拥有未来访问模式的知识，这正是最优重放所需的信息。

Method: 提出Ira框架，通过传输紧凑的提示信息加速备份重放。具体实现Ira-L协议，主节点提供包含以太坊区块中使用的键工作集和每个键一字节元数据的提示，备份使用这些提示进行高效区块重放。

Result: 提示信息紧凑，每个区块中位数增加47KB压缩数据（约5%区块负载）。主节点有28.6%的墙钟时间开销，但提示的直接成本仅为执行时间的10.9%。备份端实现中位数每区块25倍加速，16个预取线程下总重放时间从6.5小时降至16分钟（23.6倍墙钟时间加速）。

Conclusion: Ira框架通过利用主节点的未来访问模式知识，传输紧凑提示信息，显著加速了主备复制中的备份重放，在以太坊案例中证明了其有效性。

Abstract: In primary-backup replication, consensus latency is bounded by the time for backup nodes to replay (re-execute) transactions proposed by the primary. In this work, we present Ira, a framework to accelerate backup replay by transmitting compact \emph{hints} alongside transaction batches. Our key insight is that the primary, having already executed transactions, possesses knowledge of future access patterns which is exactly the information needed for optimal replay.
  We use Ethereum for our case study and present a concrete protocol, Ira-L, within our framework to improve cache management of Ethereum block execution. The primaries implementing Ira-L provide hints that consist of the working set of keys used in an Ethereum block and one byte of metadata per key indicating the table to read from, and backups use these hints for efficient block replay.
  We evaluated Ira-L against the state-of-the-art Ethereum client reth over two weeks of Ethereum mainnet activity ($100,800$ blocks containing over $24$ million transactions). Our hints are compact, adding a median of $47$ KB compressed per block ($\sim5\%$ of block payload). We observe that the sequential hint generation and block execution imposes a $28.6\%$ wall-time overhead on the primary, though the direct cost from hints is $10.9\%$ of execution time; all of which can be pipelined and parallelized in production deployments. On the backup side, we observe that Ira-L achieves a median per-block speedup of $25\times$ over baseline reth. With $16$ prefetch threads, aggregate replay time drops from $6.5$ hours to $16$ minutes ($23.6\times$ wall-time speedup).

</details>


### [31] [Self-Adaptive Probabilistic Skyline Query Processing in Distributed Edge Computing via Deep Reinforcement Learning](https://arxiv.org/abs/2601.21855)
*Chuan-Chi Lai*

Main category: cs.DC

TL;DR: SA-PSKY：一种用于边缘-云协同系统的自适应概率天际线查询框架，通过深度强化学习动态优化过滤阈值，显著降低通信开销和响应时间。


<details>
  <summary>Details</summary>
Motivation: 在万物互联时代，边缘传感器数据爆炸式增长使得概率天际线查询处理面临严峻挑战。传统分布式方法依赖静态阈值过滤，无法适应边缘计算环境的高度动态性和异构性，导致通信瓶颈或计算延迟问题。

Method: 提出SA-PSKY自适应框架，将动态阈值调整问题形式化为连续马尔可夫决策过程，利用深度确定性策略梯度智能体实时优化过滤强度。框架智能分析多维系统状态，包括数据到达率、不确定性分布和瞬时资源可用性。

Result: 综合实验评估表明，SA-PSKY始终优于最先进的静态和启发式基线方法。具体而言，通信开销降低高达60%，总响应时间减少40%，并在不同数据分布下保持鲁棒的可扩展性。

Conclusion: SA-PSKY通过深度强化学习实现自适应阈值调整，有效解决了边缘计算环境中资源冲突问题，为分布式概率天际线查询处理提供了高效解决方案。

Abstract: In the era of the Internet of Everything (IoE), the exponential growth of sensor-generated data at the network edge renders efficient Probabilistic Skyline Query (PSKY) processing a critical challenge. Traditional distributed PSKY methodologies predominantly rely on pre-defined static thresholds to filter local candidates. However, these rigid approaches are fundamentally ill-suited for the highly volatile and heterogeneous nature of edge computing environments, often leading to either severe communication bottlenecks or excessive local computational latency. To resolve this resource conflict, this paper presents SA-PSKY, a novel Self-Adaptive framework designed for distributed edge-cloud collaborative systems. We formalize the dynamic threshold adjustment problem as a continuous Markov Decision Process (MDP) and leverage a Deep Deterministic Policy Gradient (DDPG) agent to autonomously optimize filtering intensities in real-time. By intelligently analyzing multi-dimensional system states, including data arrival rates, uncertainty distributions, and instantaneous resource availability, our framework effectively minimizes a joint objective function of computation and communication costs. Comprehensive experimental evaluations demonstrate that SA-PSKY consistently outperforms state-of-the-art static and heuristic baselines. Specifically, it achieves a reduction of up to 60\% in communication overhead and 40\% in total response time, while ensuring robust scalability across diverse data distributions.

</details>


### [32] [Deep Reinforcement Learning for Fault-Adaptive Routing in Eisenstein-Jacobi Interconnection Topologies](https://arxiv.org/abs/2601.21090)
*Mohammad Walid Charrwi,Zaid Hussain*

Main category: cs.DC

TL;DR: 在故障EJ网络中，强化学习路由策略在可达性和吞吐量方面接近理论最优的Dijkstra算法，显著优于贪婪自适应路由，实现了效率与最优性之间的平衡。


<details>
  <summary>Details</summary>
Motivation: 随着多核架构密度增加，需要高性能且容错的互连网络。EJ网络具有优越的拓扑特性，但在故障条件下传统路由启发式方法面临挑战，需要评估不同路由范式在故障环境中的表现。

Method: 评估三种路由范式：确定性贪婪自适应路由、理论最优的Dijkstra算法，以及基于强化学习的方法。RL方法使用多目标奖励函数，惩罚故障邻近性并奖励路径效率，学习在集群故障环境中导航。

Result: 在9个故障节点条件下：贪婪路由有效可达性和数据包投递率降至10%；Dijkstra算法证明52-54%是拓扑最优值；RL代理实现94%有效可达性和91%数据包投递率。吞吐量评估显示RL在所有负载下维持90%以上归一化吞吐量，在拥塞时甚至优于Dijkstra。

Conclusion: 基于RL的自适应策略是实用解决方案，在不需要全局拓扑知识或最优算法计算开销的情况下，弥合了贪婪路由效率与Dijkstra最优性之间的差距，为故障易发互连网络提供鲁棒的自愈通信。

Abstract: The increasing density of many-core architectures necessitates interconnection networks that are both high-performance and fault-resilient. Eisenstein-Jacobi (EJ) networks, with their symmetric 6-regular topology, offer superior topological properties but challenge traditional routing heuristics under fault conditions. This paper evaluates three routing paradigms in faulty EJ environments: deterministic Greedy Adaptive Routing, theoretically optimal Dijkstra's algorithm, and a reinforcement learning (RL)-based approach. Using a multi-objective reward function to penalize fault proximity and reward path efficiency, the RL agent learns to navigate around clustered failures that typically induce dead-ends in greedy geometric routing. Dijkstra's algorithm establishes the theoretical performance ceiling by computing globally optimal paths with complete topology knowledge, revealing the true connectivity limits of faulty networks. Quantitative analysis at nine faulty nodes shows greedy routing catastrophically degrades to 10% effective reachability and packet delivery, while Dijkstra proves 52-54% represents the topological optimum. The RL agent achieves 94% effective reachability and 91% packet delivery, making it suitable for distributed deployment. Furthermore, throughput evaluations demonstrate that RL sustains over 90% normalized throughput across all loads, actually outperforming Dijkstra under congestion through implicit load balancing strategies. These results establish RL-based adaptive policies as a practical solution that bridges the gap between greedy's efficiency and Dijkstra's optimality, providing robust, self-healing communication in fault-prone interconnection networks without requiring the global topology knowledge or computational overhead of optimal algorithms.

</details>


### [33] [Maxwait: A Generalized Mechanism for Distributed Time-Sensitive Systems](https://arxiv.org/abs/2601.21146)
*Francesco Paladino,Shulu Li,Edward A. Lee*

Main category: cs.DC

TL;DR: maxwait是一种简单但通用的协调机制，能在分布式时间敏感系统中明确配置可用性与一致性的权衡，涵盖多种经典分布式系统方法并支持实时行为。


<details>
  <summary>Details</summary>
Motivation: 分布式时间敏感系统需要在通信延迟和同步不确定性的情况下，平衡时序要求（可用性）和一致性。现有方法往往无法明确配置这种权衡。

Method: 提出maxwait协调机制，作为Lingua Franca协调语言的扩展实现。该机制在通信延迟有界时强制执行逻辑时间一致性，在边界被违反时提供结构化故障处理。

Result: maxwait机制能够涵盖PTIDES、Chandy-and-Misra（含/不含空消息）、Jefferson's Time-Warp、Lamport时间故障检测等经典方法，并能实现LET、发布订阅、actor、CRDTs、带future的RPC等常见分布式模式。

Conclusion: maxwait在单一语义框架内为现有机制提供了更好的时序控制、有界时间故障检测和更强的确定性选项，适用于分布式网络物理应用中的实时行为。

Abstract: Distributed time-sensitive systems must balance timing requirements (availability) and consistency in the presence of communication delays and synchronization uncertainty. This paper presents maxwait, a simple coordination mechanism with surprising generality that makes these tradeoffs explicit and configurable. We demonstrate that this mechanism subsumes classical distributed system methods such as PTIDES, Chandy-and-Misra with or without null messages, Jefferson's Time-Warp, and Lamport's time-based fault detection, while enabling real-time behavior in distributed cyber-physical applications. The mechanism can also realize many commonly used distributed system patterns, including logical execution time (LET), publish and subscribe, actors, conflict-free replicated data types (CRDTs), and remote procedure calls with futures. More importantly, it adds to these mechanisms better control over timing, bounded time fault detection, and the option of making them more deterministic, all within a single semantic framework. Implemented as an extension of the Lingua Franca coordination language, maxwait enforces logical-time consistency when communication latencies are bounded and provides structured fault handling when bounds are violated.

</details>


### [34] [ZipMoE: Efficient On-Device MoE Serving via Lossless Compression and Cache-Affinity Scheduling](https://arxiv.org/abs/2601.21198)
*Yuchen Yang,Yaru Zhao,Pu Yang,Shaowei Wang,Zhi-Hua Zhou*

Main category: cs.DC

TL;DR: ZipMoE：一种高效的语义无损边缘设备MoE服务系统，通过缓存调度协同设计将I/O瓶颈转变为计算中心工作流，显著降低推理延迟并提高吞吐量


<details>
  <summary>Details</summary>
Motivation: MoE架构虽然增强了大型语言模型的表达能力，但其巨大的内存占用严重阻碍了在资源受限边缘设备上的实际部署，尤其是在需要保持模型行为而不依赖有损量化的情况下

Method: ZipMoE利用边缘设备硬件特性与MoE参数统计冗余之间的协同作用，通过具有性能保证的缓存调度协同设计，将边缘设备MoE推理范式从I/O瓶颈转变为计算中心工作流

Result: 在代表性边缘计算平台上使用开源MoE模型和真实工作负载的评估显示，ZipMoE相比最先进系统实现了高达72.77%的推理延迟降低和高达6.76倍的吞吐量提升

Conclusion: ZipMoE通过创新的缓存调度协同设计，有效解决了边缘设备上MoE模型部署的内存瓶颈问题，实现了高效且语义无损的推理服务

Abstract: While Mixture-of-Experts (MoE) architectures substantially bolster the expressive power of large-language models, their prohibitive memory footprint severely impedes the practical deployment on resource-constrained edge devices, especially when model behavior must be preserved without relying on lossy quantization. In this paper, we present ZipMoE, an efficient and semantically lossless on-device MoE serving system. ZipMoE exploits the synergy between the hardware properties of edge devices and the statistical redundancy inherent to MoE parameters via a caching-scheduling co-design with provable performance guarantee. Fundamentally, our design shifts the paradigm of on-device MoE inference from an I/O-bound bottleneck to a compute-centric workflow that enables efficient parallelization. We implement a prototype of ZipMoE and conduct extensive experiments on representative edge computing platforms using popular open-source MoE models and real-world workloads. Our evaluation reveals that ZipMoE achieves up to $72.77\%$ inference latency reduction and up to $6.76\times$ higher throughput than the state-of-the-art systems.

</details>


### [35] [EWSJF: An Adaptive Scheduler with Hybrid Partitioning for Mixed-Workload LLM Inference](https://arxiv.org/abs/2601.21758)
*Bronislav Sidik,Chaya Levi,Joseph Kampeas*

Main category: cs.DC

TL;DR: EWSJF是一个用于大语言模型服务的自适应请求级调度器，通过实时学习工作负载结构，在混合工作负载（短延迟敏感查询和长批量请求）下显著提升吞吐量和公平性。


<details>
  <summary>Details</summary>
Motivation: 在混合工作负载下服务大语言模型存在基本调度挑战：标准的先到先服务策略会导致严重的队头阻塞，造成高尾延迟和硬件利用率不足。需要一种能够同时改善公平性和吞吐量的调度方案。

Method: EWSJF包含四个组件：1) Refine-and-Prune无监督分区算法发现性能同质请求组；2) Dynamic Queue Routing将请求分配到这些组；3) Density-Weighted Scoring上下文感知优先级函数平衡紧急性和公平性；4) Bayesian Meta-Optimization基于实时性能反馈持续调优评分和分区参数。

Result: 在vLLM中实现EWSJF，相比FCFS，端到端吞吐量提升超过30%，短请求的平均首令牌时间减少高达4倍。

Conclusion: 自适应、基于学习的请求调度是高效响应式LLM服务的关键缺失层，EWSJF证明了这种方法的有效性。

Abstract: Serving Large Language Models (LLMs) under mixed workloads--short, latency-sensitive interactive queries alongside long, throughput-oriented batch requests--poses a fundamental scheduling challenge. Standard First-Come, First-Served (FCFS) policies suffer from severe head-of-line blocking, leading to high tail latency and underutilized hardware. We introduce EWSJF (Effective Workload-based Shortest Job First), an adaptive request-level scheduler that learns workload structure in real time to jointly improve fairness and throughput. EWSJF operates upstream of execution-level schedulers and integrates four components: (1) Refine-and-Prune, an unsupervised partitioning algorithm that discovers performance-homogeneous request groups; (2) Dynamic Queue Routing for assigning requests to these groups; (3) Density-Weighted Scoring, a context-aware prioritization function balancing urgency and fairness; and (4) Bayesian Meta-Optimization, which continuously tunes scoring and partitioning parameters based on live performance feedback. Implemented in vLLM, EWSJF improves end-to-end throughput by over 30% and reduces average Time-To-First-Token for short requests by up to 4x compared to FCFS. These results demonstrate that adaptive, learning-based request scheduling is a critical missing layer for efficient and responsive LLM serving. Implementation available at https://anonymous.4open.science/r/vllm_0110-32D8.

</details>


### [36] [Belief Propagation Converges to Gaussian Distributions in Sparsely-Connected Factor Graphs](https://arxiv.org/abs/2601.21935)
*Tom Yates,Yuzhou Cheng,Ignacio Alzugaray,Danyal Akarca,Pedro A. M. Mediano,Andrew J. Davison*

Main category: cs.DC

TL;DR: 论文证明了在满足四个关键假设的稀疏连接因子图中，即使是非高斯问题，BP算法的变量信念也会收敛到高斯分布，并通过立体深度估计实验验证了该理论。


<details>
  <summary>Details</summary>
Motivation: 高斯信念传播（GBP）在实践中表现出色，即使处理非高斯问题时也常被使用，但缺乏理论保证。本文旨在为GBP在高度非高斯、稀疏连接的因子图中的有效性提供理论依据。

Method: 利用中心极限定理（CLT）从数学上证明，在满足四个关键假设的复杂环状因子图中，BP算法的变量信念会收敛到高斯分布。并通过立体深度估计任务进行实验验证。

Result: 理论证明在满足假设的稀疏连接因子图中，变量信念确实会收敛到高斯分布。实验结果显示，在立体深度估计任务中，仅需几次BP迭代后变量信念就变得接近高斯分布。

Conclusion: 为GBP在非高斯问题中的有效性提供了理论支持，解释了为什么GBP在实践中表现良好，即使处理非高斯分布时也能有效工作。

Abstract: Belief Propagation (BP) is a powerful algorithm for distributed inference in probabilistic graphical models, however it quickly becomes infeasible for practical compute and memory budgets. Many efficient, non-parametric forms of BP have been developed, but the most popular is Gaussian Belief Propagation (GBP), a variant that assumes all distributions are locally Gaussian. GBP is widely used due to its efficiency and empirically strong performance in applications like computer vision or sensor networks - even when modelling non-Gaussian problems. In this paper, we seek to provide a theoretical guarantee for when Gaussian approximations are valid in highly non-Gaussian, sparsely-connected factor graphs performing BP (common in spatial AI). We leverage the Central Limit Theorem (CLT) to prove mathematically that variables' beliefs under BP converge to a Gaussian distribution in complex, loopy factor graphs obeying our 4 key assumptions. We then confirm experimentally that variable beliefs become increasingly Gaussian after just a few BP iterations in a stereo depth estimation task.

</details>
