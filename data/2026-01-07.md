<div id=toc></div>

# Table of Contents

- [cs.DB](#cs.DB) [Total: 3]
- [cs.SE](#cs.SE) [Total: 20]
- [cs.DC](#cs.DC) [Total: 2]


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [1] [Case Count Metric for Comparative Analysis of Entity Resolution Results](https://arxiv.org/abs/2601.02824)
*John R. Talburt,Muzakkiruddin Ahmed Mohammed,Mert Can Cakmak,Onais Khan Mohammed,Mahboob Khan Mohammed,Khizer Syed,Leon Claasssens*

Main category: cs.DB

TL;DR: 开发了一个名为CCMS的系统，用于在真实链接未知的情况下，系统比较和分析两个不同ER聚类过程对同一数据集的结果，通过四种转换场景统计聚类变化情况。


<details>
  <summary>Details</summary>
Motivation: 在真实链接信息未知的情况下，需要一种系统方法来比较和评估不同实体解析（ER）聚类过程的结果差异，以理解一个聚类过程如何改变另一个聚类过程的输出。

Method: 开发了案例计数度量系统（CCMS），该系统基于四种转换场景（保持不变、合并、分割、重叠）统计第一个过程产生的聚类在第二个过程中的变化情况，并提供分析模式来详细检查这些变化。

Result: CCMS能够系统性地量化和分析两个ER聚类过程之间的差异，提供详细的转换统计，并在大学和工业研究中得到成功应用。

Conclusion: CCMS为在真实链接未知的情况下评估ER聚类过程提供了一种有效的系统方法，能够帮助研究人员理解和比较不同聚类算法的性能差异。

Abstract: This paper describes a new process and software system, the Case Count Metric System (CCMS), for systematically comparing and analyzing the outcomes of two different ER clustering processes acting on the same dataset when the true linking (labeling) is not known. The CCMS produces a set of counts that describe how the clusters produced by the first process are transformed by the second process based on four possible transformation scenarios. The transformations are that a cluster formed in the first process either remains unchanged, merges into a larger cluster, is partitioned into smaller clusters, or otherwise overlaps with multiple clusters formed in the second process. The CCMS produces a count for each of these cases, accounting for every cluster formed in the first process. In addition, when run in analysis mode, the CCMS program can assist the user in evaluating these changes by displaying the details for all changes or only for certain types of changes. The paper includes a detailed description of the CCMS process and program and examples of how the CCMS has been applied in university and industry research.

</details>


### [2] [Accurate Table Question Answering with Accessible LLMs](https://arxiv.org/abs/2601.03137)
*Yangfan Jiang,Fei Wei,Ergute Bao,Yaliang Li,Bolin Ding,Yin Yang,Xiaokui Xiao*

Main category: cs.DB

TL;DR: Orchestra：一种多智能体方法，通过将复杂表格问答任务分解为多个简单子任务，让小型开源LLM也能实现高质量的表格问答，显著降低成本。


<details>
  <summary>Details</summary>
Motivation: 现有表格问答系统依赖大型商业LLM，API访问成本高昂。小型开源LLM虽然成本低，但能力较弱，无法处理现有方法中复杂的提示工程，导致性能显著下降。

Method: 提出Orchestra多智能体方法，协调多个LLM智能体，每个智能体负责相对简单的子任务，通过结构化分层工作流程解决复杂表格问答问题，降低每个智能体面临的提示复杂度。

Result: 在多个TQA基准测试中，Orchestra即使使用中小型模型也能取得强劲性能。例如，使用Qwen2.5-14B在WikiTQ上达到72.1%准确率，接近GPT-4的75.3%；使用更大的Qwen、Llama或DeepSeek模型时，在所有基准测试中都超越了现有方法，创造了新的SOTA结果。

Conclusion: Orchestra通过多智能体协作方法，有效解锁了小型开源LLM在表格问答任务中的潜力，实现了高质量、低成本的解决方案，为资源受限环境下的表格问答提供了可行路径。

Abstract: Given a table T in a database and a question Q in natural language, the table question answering (TQA) task aims to return an accurate answer to Q based on the content of T. Recent state-of-the-art solutions leverage large language models (LLMs) to obtain high-quality answers. However, most rely on proprietary, large-scale LLMs with costly API access, posing a significant financial barrier. This paper instead focuses on TQA with smaller, open-weight LLMs that can run on a desktop or laptop. This setting is challenging, as such LLMs typically have weaker capabilities than large proprietary models, leading to substantial performance degradation with existing methods.
  We observe that a key reason for this degradation is that prior approaches often require the LLM to solve a highly sophisticated task using long, complex prompts, which exceed the capabilities of small open-weight LLMs. Motivated by this observation, we present Orchestra, a multi-agent approach that unlocks the potential of accessible LLMs for high-quality, cost-effective TQA. Orchestra coordinates a group of LLM agents, each responsible for a relatively simple task, through a structured, layered workflow to solve complex TQA problems -- akin to an orchestra. By reducing the prompt complexity faced by each agent, Orchestra significantly improves output reliability.
  We implement Orchestra on top of AgentScope, an open-source multi-agent framework, and evaluate it on multiple TQA benchmarks using a wide range of open-weight LLMs. Experimental results show that Orchestra achieves strong performance even with small- to medium-sized models. For example, with Qwen2.5-14B, Orchestra reaches 72.1% accuracy on WikiTQ, approaching the best prior result of 75.3% achieved with GPT-4; with larger Qwen, Llama, or DeepSeek models, Orchestra outperforms all prior methods and establishes new state-of-the-art results across all benchmarks.

</details>


### [3] [SpANNS: Optimizing Approximate Nearest Neighbor Search for Sparse Vectors Using Near Memory Processing](https://arxiv.org/abs/2601.03229)
*Tianqi Zhang,Flavio Ponzina,Tajana Rosing*

Main category: cs.DB

TL;DR: SpANNS是一个基于CXL Type-2近内存处理架构的稀疏近似最近邻搜索系统，通过混合倒排索引和查询管理优化，相比CPU基线实现15.2-21.6倍的加速。


<details>
  <summary>Details</summary>
Motivation: 稀疏ANNS目前受限于CPU实现，而混合检索系统（稀疏+稠密嵌入）已成为信息检索标准流程，需要更高效的稀疏向量搜索解决方案。

Method: 提出SpANNS近内存处理架构，采用CXL Type-2平台，结合混合倒排索引、高效查询管理和运行时优化。专用控制器处理查询解析和聚类过滤，计算增强DIMM在数据附近执行索引遍历和距离计算。

Result: 相比最先进的CPU基线，SpANNS实现了15.2倍到21.6倍的执行速度提升，为稀疏向量搜索提供了可扩展的高效解决方案。

Conclusion: SpANNS通过近内存处理架构有效解决了稀疏ANNS的性能瓶颈，为混合检索系统中的稀疏向量搜索提供了硬件加速方案，显著提升了搜索效率。

Abstract: Approximate Nearest Neighbor Search (ANNS) is a fundamental operation in vector databases, enabling efficient similarity search in high-dimensional spaces. While dense ANNS has been optimized using specialized hardware accelerators, sparse ANNS remains limited by CPU-based implementations, hindering scalability. This limitation is increasingly critical as hybrid retrieval systems, combining sparse and dense embeddings, become standard in Information Retrieval (IR) pipelines. We propose SpANNS, a near-memory processing architecture for sparse ANNS. SpANNS combines a hybrid inverted index with efficient query management and runtime optimizations. The architecture is built on a CXL Type-2 near-memory platform, where a specialized controller manages query parsing and cluster filtering, while compute-enabled DIMMs perform index traversal and distance computations close to the data. It achieves 15.2x to 21.6x faster execution over the state-of-the-art CPU baselines, offering scalable and efficient solutions for sparse vector search.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [4] [ProSoftArena: Benchmarking Hierarchical Capabilities of Multimodal Agents in Professional Software Environments](https://arxiv.org/abs/2601.02399)
*Jiaxin Ai,Yukang Feng,Fanrui Zhang,Jianwen Sun,Zizhen Li,Chuanhao Li,Yifan Chang,Wenxiao Wu,Ruoxi Wang,Mingliang Zhai,Kaipeng Zhang*

Main category: cs.SE

TL;DR: ProSoftArena是一个专门用于评估专业软件环境中多模态智能体的基准测试平台，包含436个跨6个学科、13个专业应用的真实工作任务，通过执行评估和人工参与范式进行可靠测试。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试主要局限于浏览器和基础桌面应用，无法覆盖真实世界中占据主导地位的专业软件工作流程，这限制了多模态智能体在科学和工业实践中的应用评估。

Method: 1) 建立首个针对专业软件使用的智能体能力层次结构；2) 构建包含436个真实工作任务的基准测试；3) 开发可执行的真实计算机环境与基于执行的评估框架；4) 独特地整合人工参与评估范式。

Result: 实验显示，即使在L2级别任务上，表现最佳的智能体成功率也仅为24.4%，在L3多软件工作流程上完全失败。深入分析为当前智能体局限性和更有效的设计原则提供了有价值的见解。

Conclusion: ProSoftArena填补了专业软件环境中多模态智能体评估的空白，为构建更强大的专业软件智能体铺平了道路，揭示了当前智能体在复杂专业工作流程中的显著局限性。

Abstract: Multimodal agents are making rapid progress on general computer-use tasks, yet existing benchmarks remain largely confined to browsers and basic desktop applications, falling short in professional software workflows that dominate real-world scientific and industrial practice. To close this gap, we introduce ProSoftArena, a benchmark and platform specifically for evaluating multimodal agents in professional software environments. We establish the first capability hierarchy tailored to agent use of professional software and construct a benchmark of 436 realistic work and research tasks spanning 6 disciplines and 13 core professional applications. To ensure reliable and reproducible assessment, we build an executable real-computer environment with an execution-based evaluation framework and uniquely incorporate a human-in-the-loop evaluation paradigm. Extensive experiments show that even the best-performing agent attains only a 24.4\% success rate on L2 tasks and completely fails on L3 multi-software workflow. In-depth analysis further provides valuable insights for addressing current agent limitations and more effective design principles, paving the way to build more capable agents in professional software settings. This project is available at: https://prosoftarena.github.io.

</details>


### [5] [The Vibe-Check Protocol: Quantifying Cognitive Offloading in AI Programming](https://arxiv.org/abs/2601.02410)
*Aizierjiang Aiersilan*

Main category: cs.SE

TL;DR: 论文提出Vibe-Check Protocol (VCP)框架，通过三个量化指标评估"Vibe Coding"（AI辅助编程）在软件工程教育中的效果，旨在确定其促进真正掌握与引入技术债务的边界。


<details>
  <summary>Details</summary>
Motivation: 随着LLM在软件工程教育中的整合，"Vibe Coding"（开发者用自然语言表达意图，AI代理实现）范式兴起。虽然支持者认为这能现代化教学，强调概念设计而非语法记忆，但实证证据显示对技能保留和深度概念理解存在担忧。需要系统评估这种教育方法的利弊。

Method: 提出Vibe-Check Protocol (VCP)系统基准测试框架，包含三个量化指标：1) Cold Start Refactor (M_CSR) 评估技能衰退；2) Hallucination Trap Detection (M_HT) 基于信号检测理论评估错误识别能力；3) Explainability Gap (E_gap) 量化代码复杂性与概念理解之间的差距。通过受控比较评估AI加速与认知卸载对学生成果的影响差异。

Result: 论文提出的是理论框架和方法论，尚未报告具体实验结果。VCP框架旨在为教育者提供量化基础，确定Vibe Coding的最佳教学边界。

Conclusion: 需要系统评估Vibe Coding在软件工程教育中的真正价值，区分AI辅助加速学习与认知卸载的不同效果。VCP框架为识别Vibe Coding促进真正掌握与引入隐藏技术债务和表面能力的场景提供了方法论基础。

Abstract: The integration of Large Language Models (LLMs) into software engineering education has driven the emergence of ``Vibe Coding,'' a paradigm where developers articulate high-level intent through natural language and delegate implementation to AI agents. While proponents argue this approach modernizes pedagogy by emphasizing conceptual design over syntactic memorization, accumulating empirical evidence raises concerns regarding skill retention and deep conceptual understanding. This paper proposes a theoretical framework to investigate the research question: \textit{Is Vibe Coding a better way to learn software engineering?} We posit a divergence in student outcomes between those leveraging AI for acceleration versus those using it for cognitive offloading. To evaluate these educational trade-offs, we propose the \textbf{Vibe-Check Protocol (VCP)}, a systematic benchmarking framework incorporating three quantitative metrics: the \textit{Cold Start Refactor} ($M_{CSR}$) for modeling skill decay; \textit{Hallucination Trap Detection} ($M_{HT}$) based on signal detection theory to evaluate error identification; and the \textit{Explainability Gap} ($E_{gap}$) for quantifying the divergence between code complexity and conceptual comprehension. Through controlled comparisons, VCP aims to provide a quantitative basis for educators to determine the optimal pedagogical boundary: identifying contexts where Vibe Coding fosters genuine mastery and contexts where it introduces hidden technical debt and superficial competence.

</details>


### [6] [Talks that Builds: Exploring Communication factors for the Success of Emerging Professional in Product Teams](https://arxiv.org/abs/2601.02421)
*Nyan Lin Zaw*

Main category: cs.SE

TL;DR: 研究填补了年轻专业人士（18-27岁）产品团队成功因素的研究空白，发现好奇心、地理位置接近、文档和资源获取等新因素影响团队成功


<details>
  <summary>Details</summary>
Motivation: 现有组织沟通研究主要关注27岁以上、有5年以上经验的成熟专业人士，缺乏对年轻新兴专业人士（18-27岁）产品团队的研究。本研究旨在填补这一空白，探索影响年轻团队成功的因素。

Method: 研究考察年轻产品团队（成员年龄18-27岁），通过分析团队开发的产品的成功率，探索影响团队成功的因素。研究识别了哪些传统因素仍然适用，哪些变得不那么相关，并发现了新的影响因素。

Result: 研究发现一些传统因素仍然适用，但其他因素变得不那么相关。研究识别出新的成功影响因素，包括好奇心、地理位置接近、文档质量和资源获取。这些新因素显著影响团队生产力和项目成果。

Conclusion: 本研究填补了年轻专业人士产品团队成功因素的研究空白，揭示了好奇心、地理位置接近、文档和资源获取等新因素如何塑造团队生产力和项目成果，为理解年轻团队动态提供了新视角。

Abstract: This paper recognizes that most organizational communication study focuses on established professionals aged above 27 with more than five years of experience. In contrast, this study examines product teams with younger emerging professionals aged 18-27 and explores which factors influence their success. While some established factors still apply, others become less relevant, and new ones such as curiosity, locational proximity, documentation, access to resources were identified in the study. Overall, this study fills a gap in the literature on how these newer factors shape team productivity and project outcomes based on the success rate of the product the team developed.

</details>


### [7] [WebCoderBench: Benchmarking Web Application Generation with Comprehensive and Interpretable Evaluation Metrics](https://arxiv.org/abs/2601.02430)
*Chenxu Liu,Yingjie Fu,Wei Yang,Ying Zhang,Tao Xie*

Main category: cs.SE

TL;DR: WebCoderBench是首个真实世界收集、可泛化且可解释的网页应用生成基准，包含1,572个真实用户需求，提供24个细粒度评估指标，实验显示目前没有模型在所有指标上占主导地位。


<details>
  <summary>Details</summary>
Motivation: 当前LLM在网页应用代码生成领域缺乏合适的基准，现有方法需要真实用户需求、不依赖参考实现或测试用例的可泛化评估指标，以及可解释的评估结果。

Method: 收集1,572个真实用户需求，涵盖多种模态和表达风格；设计24个细粒度评估指标覆盖9个维度，结合基于规则和LLM作为评判者的方法；采用人类偏好对齐的权重分配以获得可解释的综合评分。

Result: 在12个代表性LLM和2个基于LLM的代理上实验表明，没有模型在所有评估指标上占主导地位，为LLM开发者提供了针对性优化的机会。

Conclusion: WebCoderBench填补了网页应用生成基准的空白，提供了真实、可泛化、可解释的评估框架，揭示了当前LLM在该领域的优化空间。

Abstract: Web applications (web apps) have become a key arena for large language models (LLMs) to demonstrate their code generation capabilities and commercial potential. However, building a benchmark for LLM-generated web apps remains challenging due to the need for real-world user requirements, generalizable evaluation metrics without relying on ground-truth implementations or test cases, and interpretable evaluation results. To address these challenges, we introduce WebCoderBench, the first real-world-collected, generalizable, and interpretable benchmark for web app generation. WebCoderBench comprises 1,572 real user requirements, covering diverse modalities and expression styles that reflect realistic user intentions. WebCoderBench provides 24 fine-grained evaluation metrics across 9 perspectives, combining rule-based and LLM-as-a-judge paradigm for fully automated, objective, and general evaluation. Moreover, WebCoderBench adopts human-preference-aligned weights over metrics to yield interpretable overall scores. Experiments across 12 representative LLMs and 2 LLM-based agents show that there exists no dominant model across all evaluation metrics, offering an opportunity for LLM developers to optimize their models in a targeted manner for a more powerful version.

</details>


### [8] [Focus on What Matters: Fisher-Guided Adaptive Multimodal Fusion for Vulnerability Detection](https://arxiv.org/abs/2601.02438)
*Yun Bian,Yi Chen,HaiQuan Wang,ShiHao Li,Zhe Cui*

Main category: cs.SE

TL;DR: TaCCS-DFA是一个用于软件漏洞检测的多模态融合框架，通过Fisher信息进行任务导向的互补融合，动态调整图模态贡献，在多个数据集上取得显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有多模态方法通常假设添加模态必然带来额外信息，但实际上序列和图表示可能存在冗余，且图模态质量波动会稀释主导模态的判别信号，需要更智能的融合策略。

Method: 提出TaCCS-DFA框架：1）使用Fisher信息作为几何度量，识别对分类决策敏感的特征方向；2）在线估计低秩主Fisher子空间，将跨模态注意力限制在任务敏感方向；3）自适应门控机制动态调整每个样本的图模态贡献以抑制噪声传播。

Result: 在BigVul、Devign和ReVeal数据集上表现优异：以CodeT5为骨干，在高度不平衡的BigVul数据集上F1分数达到87.80%，比强基线Vul-LMGNNs提升6.3个百分点，同时保持低校准误差和计算开销。

Conclusion: 通过任务导向的互补融合和自适应门控，TaCCS-DFA有效解决了多模态冗余和噪声问题，在软件漏洞检测任务中实现了更稳健和高效的多模态表示学习。

Abstract: Software vulnerability detection is a critical task for securing software systems and can be formulated as a binary classification problem: given a code snippet, determine whether it contains a vulnerability. Existing multimodal approaches typically fuse Natural Code Sequence (NCS) representations from pretrained language models with Code Property Graph (CPG) representations from graph neural networks, often under the implicit assumption that adding a modality necessarily yields extra information. In practice, sequence and graph representations can be redundant, and fluctuations in the quality of the graph modality can dilute the discriminative signal of the dominant modality. To address this, we propose TaCCS-DFA, a framework that introduces Fisher information as a geometric measure of how sensitive feature directions are to the classification decision, enabling task-oriented complementary fusion. TaCCS-DFA online estimates a low-rank principal Fisher subspace and restricts cross-modal attention to task-sensitive directions, thereby retrieving structural features from CPG that complement the sequence modality; meanwhile, an adaptive gating mechanism dynamically adjusts the contribution of the graph modality for each sample to suppress noise propagation. Our analysis shows that, under an isotropic perturbation assumption, the proposed mechanism admits a tighter risk bound than conventional full-spectrum attention. Experiments on BigVul, Devign, and ReVeal show that TaCCS-DFA achieves strong performance across multiple backbones. With CodeT5 as the backbone, TaCCS-DFA reaches an F1 score of 87.80\% on the highly imbalanced BigVul dataset, improving over a strong baseline Vul-LMGNNs by 6.3 percentage points while maintaining low calibration error and computational overhead.

</details>


### [9] [The Rise of Agentic Testing: Multi-Agent Systems for Robust Software Quality Assurance](https://arxiv.org/abs/2601.02454)
*Saba Naqvi,Mohammad Baqar,Nawaz Ali Mohammad*

Main category: cs.SE

TL;DR: 论文提出了一种基于多智能体的闭环测试框架，通过执行感知反馈和迭代优化，显著减少无效测试并提高覆盖率


<details>
  <summary>Details</summary>
Motivation: 当前基于AI的测试生成器存在静态、单次输出的问题，缺乏执行感知反馈，导致产生无效、冗余或不可执行的测试用例

Method: 采用多智能体协作框架：测试生成智能体、执行分析智能体和评审优化智能体，通过沙箱执行、详细失败报告和迭代修复，形成闭环自校正系统

Result: 在微服务应用中实现：无效测试减少60%，覆盖率提升30%，显著降低人工工作量，优于单模型基线方法

Conclusion: 多智能体、反馈驱动的闭环测试能够将软件测试演变为自主、持续学习的质量保证生态系统，实现自修复、高可靠性的代码库

Abstract: Software testing has progressed toward intelligent automation, yet current AI-based test generators still suffer from static, single-shot outputs that frequently produce invalid, redundant, or non-executable tests due to the lack of execution aware feedback. This paper introduces an agentic multi-model testing framework a closed-loop, self-correcting system in which a Test Generation Agent, an Execution and Analysis Agent, and a Review and Optimization Agent collaboratively generate, execute, analyze, and refine tests until convergence. By using sandboxed execution, detailed failure reporting, and iterative regeneration or patching of failing tests, the framework autonomously improves test quality and expands coverage. Integrated into a CI/CD-compatible pipeline, it leverages reinforcement signals from coverage metrics and execution outcomes to guide refinement. Empirical evaluations on microservice based applications show up to a 60% reduction in invalid tests, 30% coverage improvement, and significantly reduced human effort compared to single-model baselines demonstrating that multi-agent, feedback-driven loops can evolve software testing into an autonomous, continuously learning quality assurance ecosystem for self-healing, high-reliability codebases.

</details>


### [10] [Enhancing Debugging Skills with AI-Powered Assistance: A Real-Time Tool for Debugging Support](https://arxiv.org/abs/2601.02504)
*Elizaveta Artser,Daniil Karol,Anna Potriasaeva,Aleksei Rostovskii,Katsiaryna Dzialets,Ekaterina Koshchenko,Xiaotian Su,April Yi Wang,Anastasiia Birillo*

Main category: cs.SE

TL;DR: AI驱动的IDE调试助手，通过RAG、程序切片和启发式方法提供实时调试支持，减少LLM调用并提高准确性


<details>
  <summary>Details</summary>
Motivation: 调试是编程教育和软件开发中的关键技能，但在计算机科学课程中经常被忽视，需要工具来帮助学生和开发者提高调试能力

Method: 在IDE中集成AI驱动的调试助手，使用RAG（检索增强生成）与LLMs、程序切片技术和自定义启发式方法，提供代码分析、断点建议和上下文提示

Result: 通过三级评估（技术分析、用户体验研究和课堂测试）验证了该工具在调试教学中的潜力，能够减少LLM调用次数并提高调试准确性

Conclusion: AI驱动的调试助手有潜力改善编程教育和软件开发中的调试教学，通过智能辅助提高学习效率和调试技能

Abstract: Debugging is a crucial skill in programming education and software development, yet it is often overlooked in CS curricula. To address this, we introduce an AI-powered debugging assistant integrated into an IDE. It offers real-time support by analyzing code, suggesting breakpoints, and providing contextual hints. Using RAG with LLMs, program slicing, and custom heuristics, it enhances efficiency by minimizing LLM calls and improving accuracy. A three-level evaluation - technical analysis, UX study, and classroom tests - highlights its potential for teaching debugging.

</details>


### [11] [Green LLM Techniques in Action: How Effective Are Existing Techniques for Improving the Energy Efficiency of LLM-Based Applications in Industry?](https://arxiv.org/abs/2601.02512)
*Pelin Rabia Kuran,Rumbidzai Chitakunye,Vincenzo Stoico,Ilja Heitlager,Justus Bogner*

Main category: cs.SE

TL;DR: 研究分析了四种技术（大小模型协作、提示优化、量化、批处理）在工业LLM应用中的节能效果，发现提示优化和2位量化能显著节能但损害准确性，只有大小模型协作能有效节能且不严重影响其他质量指标。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在工业规模部署时能耗巨大，虽然已有多种节能技术提出，但缺乏在真实工业LLM应用中的实证研究，需要填补这一空白。

Method: 在荷兰IT服务公司Schuberg Philis的聊天机器人应用中，选择了四种技术（大小模型协作、提示优化、量化、批处理），创建了八个变体进行实验，评估它们对能耗、准确性和响应时间的影响。

Result: 提示优化和2位量化技术能显著降低能耗（最高达90%），但严重损害了准确性，在实际中不可接受。只有通过Nvidia的NPCC提示复杂度分类器的大小模型协作技术，能在不显著损害其他质量指标的情况下实现显著节能。

Conclusion: 降低LLM应用的能耗在实践中并不困难，但实现能效提升（即在不损害其他质量的情况下节能）仍然具有挑战性。大小模型协作是当前最可行的节能方案，研究为工业实践提供了实用见解。

Abstract: The rapid adoption of large language models (LLMs) has raised concerns about their substantial energy consumption, especially when deployed at industry scale. While several techniques have been proposed to address this, limited empirical evidence exists regarding the effectiveness of applying them to LLM-based industry applications. To fill this gap, we analyzed a chatbot application in an industrial context at Schuberg Philis, a Dutch IT services company. We then selected four techniques, namely Small and Large Model Collaboration, Prompt Optimization, Quantization, and Batching, applied them to the application in eight variations, and then conducted experiments to study their impact on energy consumption, accuracy, and response time compared to the unoptimized baseline.
  Our results show that several techniques, such as Prompt Optimization and 2-bit Quantization, managed to reduce energy use significantly, sometimes by up to 90%. However, these techniques especially impacted accuracy negatively, to a degree that is not acceptable in practice. The only technique that achieved significant and strong energy reductions without harming the other qualities substantially was Small and Large Model Collaboration via Nvidia's Prompt Task and Complexity Classifier (NPCC) with prompt complexity thresholds. This highlights that reducing the energy consumption of LLM-based applications is not difficult in practice. However, improving their energy efficiency, i.e., reducing energy use without harming other qualities, remains challenging. Our study provides practical insights to move towards this goal.

</details>


### [12] [On the Effectiveness of Proposed Techniques to Reduce Energy Consumption in RAG Systems: A Controlled Experiment](https://arxiv.org/abs/2601.02522)
*Zhinuan,Guo,Chushu Gao,Justus Bogner*

Main category: cs.SE

TL;DR: 本文通过实验研究了五种降低RAG系统能耗的技术，发现提高相似度检索阈值和减小嵌入尺寸能显著降低能耗和延迟且不影响准确性，而其他技术虽然节能但会降低准确性。


<details>
  <summary>Details</summary>
Motivation: 随着机器学习（特别是RAG系统）能耗需求的增长，其环境可持续性引发担忧。虽然已有研究提出绿色ML技术，但这些技术在RAG系统中的实证评估仍很缺乏。

Method: 使用合作方Software Improvement Group开发的类生产RAG系统，通过控制实验评估五种节能技术：提高相似度检索阈值、减小嵌入尺寸、应用向量索引、使用BM25S重排序器。在CRAG数据集上进行了9种配置、超过200小时的试验。

Result: 某些技术（如提高检索阈值、减小嵌入尺寸、应用向量索引、使用BM25S重排序器）能显著降低能耗，最高达60%。但部分技术（如索引策略）会导致准确性下降达30%。最优检索阈值和减小嵌入尺寸能在不影响准确性的情况下显著降低能耗和延迟。

Conclusion: 这是首个关于RAG系统节能设计技术的全面实证研究，为开发者和研究人员构建可持续RAG应用提供了指导。最优检索阈值和减小嵌入尺寸是真正节能的技术选择。

Abstract: The rising energy demands of machine learning (ML), e.g., implemented in popular variants like retrieval-augmented generation (RAG) systems, have raised significant concerns about their environmental sustainability. While previous research has proposed green tactics for ML-enabled systems, their empirical evaluation within RAG systems remains largely unexplored. This study presents a controlled experiment investigating five practical techniques aimed at reducing energy consumption in RAG systems. Using a production-like RAG system developed at our collaboration partner, the Software Improvement Group, we evaluated the impact of these techniques on energy consumption, latency, and accuracy.
  Through a total of 9 configurations spanning over 200 hours of trials using the CRAG dataset, we reveal that techniques such as increasing similarity retrieval thresholds, reducing embedding sizes, applying vector indexing, and using a BM25S reranker can significantly reduce energy usage, up to 60% in some cases. However, several techniques also led to unacceptable accuracy decreases, e.g., by up to 30% for the indexing strategies. Notably, finding an optimal retrieval threshold and reducing embedding size substantially reduced energy consumption and latency with no loss in accuracy, making these two techniques truly energy-efficient. We present the first comprehensive, empirical study on energy-efficient design techniques for RAG systems, providing guidance for developers and researchers aiming to build sustainable RAG applications.

</details>


### [13] [PerspectiveCoach: Exploring LLMs for Developer Reflection](https://arxiv.org/abs/2601.02559)
*Lauren Olson,Emitzá Guzmán,Florian Kunneman*

Main category: cs.SE

TL;DR: PerspectiveCoach是一个基于大语言模型的对话工具，通过结构化视角训练帮助开发者反思软件设计对边缘化群体的影响，研究表明它能提升自我意识、拓宽视角并改善伦理表达。


<details>
  <summary>Details</summary>
Motivation: 尽管软件开发的伦理挑战日益受到关注，但从业者仍缺乏结构化工具来批判性地参与边缘化用户的真实体验。需要帮助开发者反思软件设计决策如何影响边缘化社区。

Method: 开发了PerspectiveCoach——基于大语言模型的对话工具，通过结构化视角训练引导开发者。进行了对照研究：18名前端开发者（性别平衡）使用该工具处理在线性别骚扰的真实案例，分析工具如何支持伦理推理和用户视角参与。同时进行了人-人研究作为对照。

Result: 定性分析显示：参与者自我意识增强、视角拓宽、伦理表达更细致。文本相似性分析表明，人-PerspectiveCoach研究中参与者的复述保真度随尝试次数提高，能捕捉用户关注点的表层和语义层面。但人-PerspectiveCoach的复述基线低于人-人对话，反映了非人际和人际视角训练的情境差异。参与者对工具的可用性和相关性评价很高。

Conclusion: 这项工作为基于大语言模型的终端用户视角训练提供了探索性设计，支持批判性伦理自我反思。提供了实证见解（如增强适应性、关注多元性），表明此类工具能帮助从业者构建更具包容性和社会响应性的技术。

Abstract: Despite growing awareness of ethical challenges in software development, practitioners still lack structured tools that help them critically engage with the lived experiences of marginalized users. This paper presents PerspectiveCoach, a large language model (LLM)-powered conversational tool designed to guide developers through structured perspective-taking exercises and deepen critical reflection on how software design decisions affect marginalized communities. Through a controlled study with 18 front-end developers (balanced by sex), who interacted with the tool using a real case of online gender-based harassment, we examine how PerspectiveCoach supports ethical reasoning and engagement with user perspectives. Qualitative analysis revealed increased self-awareness, broadened perspectives, and more nuanced ethical articulation, while a complementary human-human study contextualized these findings. Text similarity analyses demonstrated that participants in the human-PerspectiveCoach study improved the fidelity of their restatements over multiple attempts, capturing both surface-level and semantic aspects of user concerns. However, human-PerspectiveCoach's restatements had a lower baseline than the human-human conversations, highlighting contextual differences in impersonal and interpersonal perspective-taking. Across the study, participants rated the tool highly for usability and relevance. This work contributes an exploratory design for LLM-powered end-user perspective-taking that supports critical, ethical self-reflection and offers empirical insights (i.e., enhancing adaptivity, centering plurality) into how such tools can help practitioners build more inclusive and socially responsive technologies.

</details>


### [14] [Compressed code: the hidden effects of quantization and distillation on programming tokens](https://arxiv.org/abs/2601.02563)
*Viacheslav Siniaev,Iaroslav Chelombitko,Aleksey Komissarov*

Main category: cs.SE

TL;DR: 该论文通过分析LLM中编程语言的token表示，研究了压缩模型中的token级机制，提出了冷启动概率分析方法，并评估了不同优化技术对代码生成质量的影响。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在代码生成方面表现出色，但其token级机制，特别是在压缩模型中，仍未得到充分探索。需要理解编程语言在LLM tokenizer中的编码方式，以及不同优化技术如何影响token级表示和代码生成质量。

Method: 1. 系统分析编程语言token表示，通过词汇分布和关键词覆盖模式来表征编程语言在LLM tokenizer中的编码方式；2. 引入新颖的冷启动概率分析方法，无需显式提示即可洞察模型行为；3. 全面评估量化、蒸馏、模型缩放和任务特定微调等不同优化技术对token级表示和代码生成质量的影响。

Result: 通过全面的概率分布分析和评估指标，实验揭示了token级行为的关键洞察，并为在各种优化约束下保持代码生成质量提供了经验验证的指导原则。

Conclusion: 这些发现不仅推进了对LLM代码生成的理论理解，还为在生产环境中实施优化模型提供了实用指导。

Abstract: Large Language Models (LLMs) have demonstrated exceptional code generation capabilities, yet their token-level mechanisms remain underexplored, particularly in compressed models. Through systematic analysis of programming language token representations, we characterize how programming languages are encoded in LLM tokenizers by analyzing their vocabulary distribution and keyword coverage patterns. We introduce a novel cold-start probability analysis method that provides insights into model behavior without requiring explicit prompts. Additionally, we present a comprehensive evaluation of how different model optimization techniques - including quantization, distillation, model scaling, and task-specific fine-tuning - affect token-level representations and code generation quality. Our experiments, supported by comprehensive probability distribution analysis and evaluation metrics, reveal critical insights into token-level behavior and provide empirically-validated guidelines for maintaining code generation quality under various optimization constraints. These findings advance both theoretical understanding of LLM code generation and practical implementation of optimized models in production environments.

</details>


### [15] [State of the Quantum Software Engineering Ecosystem](https://arxiv.org/abs/2601.02601)
*Nazanin Siavash,Armin Moin*

Main category: cs.SE

TL;DR: 该研究使用GPT-5分析量子软件工程生态系统现状，识别学术界和工业界中在该领域取得显著成果的活跃机构和企业


<details>
  <summary>Details</summary>
Motivation: 研究量子软件工程生态系统的当前状态，特别关注学术界和工业界的成就、活动和参与，尤其是成功的创业企业。旨在了解该领域的发展现状和关键参与者。

Method: 采用新颖的研究方法，利用最先进的人工智能技术——大型语言模型（特别是GPT-5），通过ChatGPT工具进行分析。通过识别在量子软件工程领域高度活跃且取得显著成果的机构和公司，这些成果通过同行评审出版物或风险资本市场融资来证明。

Result: 论文未提供具体结果，但研究方法表明将识别出在量子软件工程领域具有显著成就的机构和公司，包括学术机构和成功获得风险投资的企业。

Conclusion: 该研究展示了利用先进AI技术（GPT-5）分析新兴技术领域生态系统的创新方法，为理解量子软件工程的发展现状和关键参与者提供了新的研究途径。

Abstract: We study the current state of the Quantum Software Engineering (QSE) ecosystem, focusing on the achievements, activities, and engagements from academia and industry, with a special focus on successful entrepreneurial endeavors in this arena. Our research methodology is a novel one, featuring the state-of-the-art in Artificial Intelligence (AI), namely Large Language Models (LLMs), especially Generative Pretrained Transformers (GPT). We use one of such models, namely the OpenAI GPT-5 model, through the ChatGPT tool. The goal is to identify institutions and companies that are highly active and have achieved distinguished results in QSE, evidenced by peer-reviewed publications or raised capital in the venture capital market.

</details>


### [16] [TAAF: A Trace Abstraction and Analysis Framework Synergizing Knowledge Graphs and LLMs](https://arxiv.org/abs/2601.02632)
*Alireza Ezaz,Ghazal Khodabandeh,Majid Babaei,Naser Ezzati-Jivan*

Main category: cs.SE

TL;DR: TAAF框架结合时间索引知识图谱和LLM，将原始执行轨迹数据转化为可操作的洞察，显著提升轨迹分析准确率


<details>
  <summary>Details</summary>
Motivation: 操作系统内核或大型应用（如Chrome、MySQL）的执行轨迹数据量巨大且难以分析，现有工具依赖预定义分析，自定义洞察需要编写容易出错且耗时的领域特定脚本

Method: 提出TAAF框架，结合时间索引、知识图谱和大型语言模型：1）从轨迹事件构建时间索引知识图谱，捕捉线程、CPU、系统资源等实体关系；2）使用LLM解释查询特定子图来回答自然语言问题

Result: 引入TraceQA-100基准测试（100个基于真实内核轨迹的问题），实验显示TAAF在三个LLM和多种时间设置下，答案准确率提升高达31.2%，在多跳和因果推理任务中表现尤其突出

Conclusion: TAAF减少了手动检查和深度系统专业知识的需求，分析了图基础推理的优势和局限性，为下一代轨迹分析工具奠定了基础

Abstract: Execution traces are a critical source of information for understanding, debugging, and optimizing complex software systems. However, traces from OS kernels or large-scale applications like Chrome or MySQL are massive and difficult to analyze. Existing tools rely on predefined analyses, and custom insights often require writing domain-specific scripts, which is an error-prone and time-consuming task. This paper introduces TAAF (Trace Abstraction and Analysis Framework), a novel approach that combines time-indexing, knowledge graphs (KGs), and large language models (LLMs) to transform raw trace data into actionable insights. TAAF constructs a time-indexed KG from trace events to capture relationships among entities such as threads, CPUs, and system resources. An LLM then interprets query-specific subgraphs to answer natural-language questions, reducing the need for manual inspection and deep system expertise. To evaluate TAAF, we introduce TraceQA-100, a benchmark of 100 questions grounded in real kernel traces. Experiments across three LLMs and multiple temporal settings show that TAAF improves answer accuracy by up to 31.2%, particularly in multi-hop and causal reasoning tasks. We further analyze where graph-grounded reasoning helps and where limitations remain, offering a foundation for next-generation trace analysis tools.

</details>


### [17] [Enterprise Identity Integration for AI-Assisted Developer Services: Architecture, Implementation, and Case Study](https://arxiv.org/abs/2601.02698)
*Manideep Reddy Chinthareddy*

Main category: cs.SE

TL;DR: 本文提出了一种将OAuth 2.0和OpenID Connect集成到MCP开发者环境中的企业级身份验证架构，以解决AI辅助开发工具在企业环境中的身份管理和访问控制问题。


<details>
  <summary>Details</summary>
Motivation: 随着AI辅助开发服务在现代IDE中的普及，企业需要确保这些工具符合现有的身份管理、访问控制和治理要求。MCP协议虽然能让AI助手获取结构化内部上下文，但其授权模型过于简单，且缺乏企业SSO集成指导。

Method: 提出了一种实践架构，将OAuth 2.0和OpenID Connect集成到MCP开发者环境中。具体包括：IDE扩展获取和呈现令牌、MCP服务器通过身份提供商验证令牌、使用范围和声明实施最小权限访问。通过Visual Studio Code、Python MCP服务器和OIDC兼容的身份提供商构建了原型实现。

Result: 原型验证了方案的可行性，并通过案例研究评估了认证延迟、令牌验证开销、运维考虑因素和AI特定风险。该架构为组织采用AI辅助开发工具提供了可部署的模式，同时保持了身份保证和可审计性。

Conclusion: 该研究提供了一种实用的企业级解决方案，使组织能够在采用AI辅助开发工具的同时，满足身份管理、访问控制和治理要求，填补了MCP在企业身份验证集成方面的空白。

Abstract: AI-assisted developer services are increasingly embedded in modern IDEs, yet enterprises must ensure these tools operate within existing identity, access control, and governance requirements. The Model Context Protocol (MCP) enables AI assistants to retrieve structured internal context, but its specification provides only a minimal authorization model and lacks guidance on integrating enterprise SSO. This article presents a practical architecture that incorporates OAuth 2.0 and OpenID Connect (OIDC) into MCP-enabled developer environments. It describes how IDE extensions obtain and present tokens, how MCP servers validate them through an identity provider, and how scopes and claims can enforce least-privilege access. A prototype implementation using Visual Studio Code, a Python-based MCP server, and an OIDC-compliant IdP demonstrates feasibility. A case study evaluates authentication latency, token-validation overhead, operational considerations, and AI-specific risks. The approach provides a deployable pattern for organizations adopting AI-assisted developer tools while maintaining identity assurance and auditability.

</details>


### [18] [Agentic Memory Enhanced Recursive Reasoning for Root Cause Localization in Microservices](https://arxiv.org/abs/2601.02732)
*Lingzhe Zhang,Tong Jia,Yunpeng Zhai,Leyi Pan,Chiming Duan,Minghua He,Mengxi Jia,Ying Li*

Main category: cs.SE

TL;DR: AMER-RCL：一种基于智能体记忆增强的递归推理框架，用于微服务系统中的根因定位，通过递归推理和多智能体协作提高准确性，利用智能体记忆减少冗余推理降低延迟。


<details>
  <summary>Details</summary>
Motivation: 随着微服务系统日益复杂，故障频发，现有根因定位方法存在局限性：传统图基和深度学习方法依赖预定义模式难以适应动态环境，而基于LLM的方法存在浅层症状推理和缺乏跨告警重用的问题，导致准确性不足和延迟高。

Method: AMER-RCL框架包含两个核心组件：1）递归推理RCL引擎，采用多智能体框架对每个告警进行递归推理，逐步细化候选原因；2）智能体记忆，在时间窗口内增量积累和重用先前告警的推理结果，减少冗余探索并降低推理延迟。

Result: 实验结果表明，AMER-RCL在定位准确性和推理效率方面均优于现有最先进方法。

Conclusion: 通过模拟SRE专家的递归、多维扩展和跨模态推理特性，AMER-RCL框架能够有效解决微服务系统中根因定位的准确性和效率问题，为复杂系统的可靠性保障提供了新思路。

Abstract: As contemporary microservice systems become increasingly popular and complex-often comprising hundreds or even thousands of fine-grained, interdependent subsystems-they are experiencing more frequent failures. Ensuring system reliability thus demands accurate root cause localization. While many traditional graph-based and deep learning approaches have been explored for this task, they often rely heavily on pre-defined schemas that struggle to adapt to evolving operational contexts. Consequently, a number of LLM-based methods have recently been proposed. However, these methods still face two major limitations: shallow, symptom-centric reasoning that undermines accuracy, and a lack of cross-alert reuse that leads to redundant reasoning and high latency. In this paper, we conduct a comprehensive study of how Site Reliability Engineers (SREs) localize the root causes of failures, drawing insights from professionals across multiple organizations. Our investigation reveals that expert root cause analysis exhibits three key characteristics: recursiveness, multi-dimensional expansion, and cross-modal reasoning. Motivated by these findings, we introduce AMER-RCL, an agentic memory enhanced recursive reasoning framework for root cause localization in microservices. AMER-RCL employs the Recursive Reasoning RCL engine, a multi-agent framework that performs recursive reasoning on each alert to progressively refine candidate causes, while Agentic Memory incrementally accumulates and reuses reasoning from prior alerts within a time window to reduce redundant exploration and lower inference latency. Experimental results demonstrate that AMER-RCL consistently outperforms state-of-the-art methods in both localization accuracy and inference efficiency.

</details>


### [19] [Hypothesize-Then-Verify: Speculative Root Cause Analysis for Microservices with Pathwise Parallelism](https://arxiv.org/abs/2601.02736)
*Lingzhe Zhang,Tong Jia,Yunpeng Zhai,Leyi Pan,Chiming Duan,Minghua He,Pei Xiao,Ying Li*

Main category: cs.SE

TL;DR: SpecRCA：基于推测推理的微服务根因分析框架，采用"假设-验证"范式，通过假设草稿模块快速生成候选根因，并行验证器高效验证，在准确性和效率上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 微服务系统已成为云原生企业应用的支柱，但其内在复杂性和动态运行时交互不可避免地导致异常。现有基于大语言模型（LLM）的根因分析方法存在两个关键限制：探索多样性有限影响准确性，依赖大规模LLM导致推理速度慢。

Method: 提出SpecRCA框架，采用"假设-验证"范式：1）假设草稿模块快速生成候选根因；2）并行根因验证器高效验证候选根因。该框架减少对大规模LLM的依赖，提高探索多样性。

Result: 在AIOps 2022数据集上的初步实验表明，SpecRCA在准确性和效率方面优于现有方法，展示了其在复杂微服务环境中作为可扩展、可解释根因分析解决方案的潜力。

Conclusion: SpecRCA通过创新的推测推理方法克服了现有LLM基方法的局限性，为微服务系统提供了一种实用、高效且可解释的根因分析解决方案，有望提升云原生应用的可靠性。

Abstract: Microservice systems have become the backbone of cloud-native enterprise applications due to their resource elasticity, loosely coupled architecture, and lightweight deployment. Yet, the intrinsic complexity and dynamic runtime interactions of such systems inevitably give rise to anomalies. Ensuring system reliability therefore hinges on effective root cause analysis (RCA), which entails not only localizing the source of anomalies but also characterizing the underlying failures in a timely and interpretable manner. Recent advances in intelligent RCA techniques, particularly those powered by large language models (LLMs), have demonstrated promising capabilities, as LLMs reduce reliance on handcrafted features while offering cross-platform adaptability, task generalization, and flexibility. However, existing LLM-based methods still suffer from two critical limitations: (a) limited exploration diversity, which undermines accuracy, and (b) heavy dependence on large-scale LLMs, which results in slow inference. To overcome these challenges, we propose SpecRCA, a speculative root cause analysis framework for microservices that adopts a \textit{hypothesize-then-verify} paradigm. SpecRCA first leverages a hypothesis drafting module to rapidly generate candidate root causes, and then employs a parallel root cause verifier to efficiently validate them. Preliminary experiments on the AIOps 2022 dataset demonstrate that SpecRCA achieves superior accuracy and efficiency compared to existing approaches, highlighting its potential as a practical solution for scalable and interpretable RCA in complex microservice environments.

</details>


### [20] [CodeMEM: AST-Guided Adaptive Memory for Repository-Level Iterative Code Generation](https://arxiv.org/abs/2601.02868)
*Peiding Wang,Li Zhang,Fang Liu,Chongyang Tao,Yinghao Zhu*

Main category: cs.SE

TL;DR: CodeMEM：基于AST的动态内存管理系统，用于仓库级迭代代码生成，通过AST引导的LLM操作维护代码上下文，减少遗忘和重复错误，提升开发效率


<details>
  <summary>Details</summary>
Motivation: 现有LLM在仓库级代码生成中面临上下文维护困难：随着交互进行，仓库上下文需要持续更新，同时扩大的会话历史增加认知负担，导致遗忘和已解决错误的重复出现。现有基于自然语言的内存管理方法存在局限性。

Method: 提出CodeMEM系统，包含两个核心组件：1) Code Context Memory：通过AST引导的LLM操作动态维护和更新仓库上下文；2) Code Session Memory：构建以代码为中心的交互历史表示，通过AST分析显式检测和缓解遗忘问题。

Result: 在CodeIF-Bench和CoderEval基准测试中达到最先进性能：指令遵循率提升12.2%（当前轮次）和11.5%（会话级别），交互轮次减少2-3轮，同时保持有竞争力的推理延迟和token效率。

Conclusion: CodeMEM通过AST引导的动态内存管理有效解决了仓库级代码生成中的上下文维护和遗忘问题，显著提升了LLM在迭代开发中的效率和准确性。

Abstract: Large language models (LLMs) substantially enhance developer productivity in repository-level code generation through interactive collaboration. However, as interactions progress, repository context must be continuously preserved and updated to integrate newly validated information. Meanwhile, the expanding session history increases cognitive burden, often leading to forgetting and the reintroduction of previously resolved errors. Existing memory management approaches show promise but remain limited by natural language-centric representations. To overcome these limitations, we propose CodeMEM, an AST-guided dynamic memory management system tailored for repository-level iterative code generation. Specifically, CodeMEM introduces the Code Context Memory component that dynamically maintains and updates repository context through AST-guided LLM operations, along with the Code Session Memory that constructs a code-centric representation of interaction history and explicitly detects and mitigates forgetting through AST-based analysis. Experimental results on the instruction-following benchmark CodeIF-Bench and the code generation benchmark CoderEval demonstrate that CodeMEM achieves state-of-the-art performance, improving instruction following by 12.2% for the current turn and 11.5% for the session level, and reducing interaction rounds by 2-3, while maintaining competitive inference latency and token efficiency.

</details>


### [21] [Few-shot learning for security bug report identification](https://arxiv.org/abs/2601.02971)
*Muhammad Laiq*

Main category: cs.SE

TL;DR: 提出基于少样本学习的SetFit框架，用于在标注数据稀缺的情况下有效识别安全漏洞报告，相比传统机器学习方法表现更优。


<details>
  <summary>Details</summary>
Motivation: 安全漏洞报告需要及时识别以降低软件系统风险，但传统机器学习方法依赖大量标注数据，而实际中安全漏洞报告数据集往往稀缺，导致模型性能差且实际应用受限。

Method: 采用SetFit少样本学习框架，结合句子转换器和对比学习，通过参数高效微调，在少量标注的漏洞报告数据集上进行训练。

Result: 该方法在评估的所有数据集上均优于传统机器学习基线方法，最佳AUC达到0.865，展示了SetFit在识别安全漏洞报告方面的有效性。

Conclusion: 基于SetFit的少样本学习为安全漏洞报告识别提供了有前景的替代方案，能够在标注数据稀缺的情况下高效开发模型，适合实际应用场景。

Abstract: Security bug reports require prompt identification to minimize the window of vulnerability in software systems. Traditional machine learning (ML) techniques for classifying bug reports to identify security bug reports rely heavily on large amounts of labeled data. However, datasets for security bug reports are often scarce in practice, leading to poor model performance and limited applicability in real-world settings. In this study, we propose a few-shot learning-based technique to effectively identify security bug reports using limited labeled data. We employ SetFit, a state-of-the-art few-shot learning framework that combines sentence transformers with contrastive learning and parameter-efficient fine-tuning. The model is trained on a small labeled dataset of bug reports and is evaluated on its ability to classify these reports as either security-related or non-security-related. Our approach achieves an AUC of 0.865, at best, outperforming traditional ML techniques (baselines) for all of the evaluated datasets. This highlights the potential of SetFit to effectively identify security bug reports. SetFit-based few-shot learning offers a promising alternative to traditional ML techniques to identify security bug reports. The approach enables efficient model development with minimal annotation effort, making it highly suitable for scenarios where labeled data is scarce.

</details>


### [22] [A Dataset of Low-Rated Applications from the Amazon Appstore for User Feedback Analysis](https://arxiv.org/abs/2601.03009)
*Nek Dil Khan,Javed Ali Khan,Darvesh Khan,Jianqiang Li,Mumrez Khan,Shah Fahad Khan*

Main category: cs.SE

TL;DR: 该研究创建了一个来自亚马逊软件应用商店64个低评分应用的79,821条用户评论数据集，其中6,000条评论被手动标注为六大问题类别，为基于机器学习的用户反馈自动分类提供资源。


<details>
  <summary>Details</summary>
Motivation: 当前研究多关注高评分应用，而低评分应用往往被忽视，但它们可能揭示阻碍用户体验的关键问题。为理解低评分应用的常见问题并改进软件质量，需要专门的数据集来支持相关研究。

Method: 从亚马逊软件应用商店收集64个低评分应用的79,821条用户评论，创建原始数据集。进一步手动标注其中6,000条评论，将其分类为六大问题类别：UI/UX、功能特性、兼容性与设备特定性、性能与稳定性、客户支持与响应性、安全与隐私问题。

Result: 创建了包含原始和标注版本的低评分应用用户反馈数据集，为研究人员和开发者提供了理解低评分应用常见问题的工具。该数据集支持机器学习方法开发，可自动分类用户反馈到不同问题类型。

Conclusion: 该数据集为基于用户反馈改进软件质量的数据驱动解决方案奠定了基础，使软件供应商和研究人员能够探索软件演化相关活动，包括缺失功能、讽刺语气和相关情绪分析，从而更好地理解应用评分较低的原因。

Abstract: In todays digital landscape, end-user feedback plays a crucial role in the evolution of software applications, particularly in addressing issues that hinder user experience. While much research has focused on high-rated applications, low-rated applications often remain unexplored, despite their potential to reveal valuable insights. This study introduces a novel dataset curated from 64 low-rated applications sourced from the Amazon Software Appstore (ASA), containing 79,821 user reviews. The dataset is designed to capture the most frequent issues identified by users, which are critical for improving software quality. To further enhance the dataset utility, a subset of 6000 reviews was manually annotated to classify them into six district issue categories: user interface (UI) and user experience (UX), functionality and features, compatibility and device specificity, performance and stability, customer support and responsiveness, and security and privacy issues. This annotated dataset is a valuable resource for developing machine learning-based approaches aiming to automate the classification of user feedback into various issue types. Making both the annotated and raw datasets publicly available provides researchers and developers with a crucial tool to understand common issues in low-rated apps and inform software improvements. The comprehensive analysis and availability of this dataset lay the groundwork for data-derived solutions to improve software quality based on user feedback. Additionally, the dataset can provide opportunities for software vendors and researchers to explore various software evolution-related activities, including frequently missing features, sarcasm, and associated emotions, which will help better understand the reasons for comparatively low app ratings.

</details>


### [23] [NavAI: A Generalizable LLM Framework for Navigation Tasks in Virtual Reality Environments](https://arxiv.org/abs/2601.03251)
*Xue Qin,Matthew DiGiovanni*

Main category: cs.SE

TL;DR: NavAI是一个基于大语言模型的通用VR导航框架，支持跨不同VR应用的基本动作和复杂目标导向任务，在目标导向任务中达到89%的成功率。


<details>
  <summary>Details</summary>
Motivation: 现有导航技术主要专注于360度图像数据集和3D模拟器中的路径优化，无法直接应用于沉浸式VR环境，需要开发适用于VR的通用导航框架。

Method: 提出NavAI，一个基于大语言模型（LLM）的通用导航框架，支持跨不同VR应用的基本动作和复杂目标导向任务。在三个不同的VR环境中通过目标导向和探索性任务进行评估。

Result: NavAI在目标导向任务中达到89%的成功率，表现出高准确性。分析揭示了完全依赖LLM的局限性，特别是在需要动态目标评估的场景中。

Conclusion: NavAI是一个有效的VR导航框架，但完全依赖LLM存在局限性，特别是在动态目标评估方面。论文讨论了实验中的局限性，并为未来研究方向提供了见解。

Abstract: Navigation is one of the fundamental tasks for automated exploration in Virtual Reality (VR). Existing technologies primarily focus on path optimization in 360-degree image datasets and 3D simulators, which cannot be directly applied to immersive VR environments. To address this gap, we present NavAI, a generalizable large language model (LLM)-based navigation framework that supports both basic actions and complex goal-directed tasks across diverse VR applications. We evaluate NavAI in three distinct VR environments through goal-oriented and exploratory tasks. Results show that it achieves high accuracy, with an 89% success rate in goal-oriented tasks. Our analysis also highlights current limitations of relying entirely on LLMs, particularly in scenarios that require dynamic goal assessment. Finally, we discuss the limitations observed during the experiments and offer insights for future research directions.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [24] [Proceedings of the 1st International Workshop on Low Carbon Computing (LOCO 2024)](https://arxiv.org/abs/2601.02898)
*Wim Vanderbauwhede,Lauritz Thamsen,José Cano*

Main category: cs.DC

TL;DR: LOCO 2024是第一届低碳计算国际研讨会论文集


<details>
  <summary>Details</summary>
Motivation: 随着计算技术能耗和碳排放问题日益突出，需要专门讨论低碳计算的研究平台

Method: 通过国际研讨会形式汇集相关研究，包括论文征集、同行评审和会议交流

Result: 成功举办了第一届低碳计算国际研讨会并出版了论文集

Conclusion: LOCO 2024为低碳计算领域建立了重要的学术交流平台，推动了该领域的研究发展

Abstract: This is the proceedings of the 1st International Workshop on Low Carbon Computing (LOCO 2024).

</details>


### [25] [Software-Defined Agentic Serving](https://arxiv.org/abs/2601.03197)
*Saurabh Agarwal,Marco Laju,Jayanth Srinivasa,Myungjin Lee,Aditya Akella*

Main category: cs.DC

TL;DR: 提出基于SDN（软件定义网络）启发的可编程、系统感知的智能体服务框架，以应对复杂多智能体LLM管道中的动态服务条件挑战


<details>
  <summary>Details</summary>
Motivation: 随着多智能体LLM管道日益复杂，现有服务范式无法适应动态服务条件。现有服务系统静态编码参数，缺乏对运行时状态的适应性

Method: 提出SDN启发的智能体服务框架，通过可编程方式基于运行时状态控制通信关键属性，实现系统感知的服务架构

Result: 该架构能够实现服务效率高、响应性强的智能体系统，为高级意图驱动的智能体服务铺平道路

Conclusion: 智能体服务系统应具备可编程性和系统感知能力，SDN启发的框架为解决复杂多智能体LLM管道动态服务问题提供了有效方案

Abstract: As multi-agent LLM pipelines grow in complexity, existing serving paradigms fail to adapt to the dynamic serving conditions. We argue that agentic serving systems should be programmable and system-aware, unlike existing serving which statically encode the parameters. In this work, we propose a new SDN-inspired agentic serving framework that helps control the key attributes of communication based on runtime state. This architecture enables serving-efficient, responsive agent systems and paves the way for high-level intent-driven agentic serving.

</details>
