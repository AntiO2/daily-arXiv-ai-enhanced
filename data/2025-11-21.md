<div id=toc></div>

# Table of Contents

- [cs.DC](#cs.DC) [Total: 8]
- [cs.DB](#cs.DB) [Total: 5]
- [cs.SE](#cs.SE) [Total: 12]


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [1] [A Scalable NorthPole System with End-to-End Vertical Integration for Low-Latency and Energy-Efficient LLM Inference](https://arxiv.org/abs/2511.15950)
*Michael V. DeBole,Rathinakumar Appuswamy,Neil McGlohon,Brian Taba,Steven K. Esser,Filipp Akopyan,John V. Arthur,Arnon Amir,Alexander Andreopoulos,Peter J. Carlson,Andrew S. Cassidy,Pallab Datta,Myron D. Flickner,Rajamohan Gandhasri,Guillaume J. Garreau,Megumi Ito,Jennifer L. Klamo,Jeffrey A. Kusnitz,Nathaniel J. McClatchey,Jeffrey L. McKinstry,Tapan K. Nayak,Carlos Ortega Otero,Hartmut Penner,William P. Risk,Jun Sawada,Jay Sivagnaname,Daniel F. Smith,Rafael Sousa,Ignacio Terrizzano,Takanori Ueda,Trent Gray-Donald,David Cox,Dharmendra S. Modha*

Main category: cs.DC

TL;DR: 一个集成了288张NorthPole神经推理加速卡的研究原型系统，提供可扩展的云端推理服务，支持多种模型规模和上下文长度。


<details>
  <summary>Details</summary>
Motivation: 为企业在现有数据中心环境中部署AI应用提供可扩展、高效且节能的推理服务解决方案。

Method: 采用垂直集成的端到端系统架构，结合离线训练算法、高性能运行时堆栈和容器化推理流水线。

Result: 系统提供115 peta-ops计算能力，3.7 PB/s内存带宽，功耗仅30kW，可同时运行3个80亿参数模型实例，支持28个用户，每用户令牌延迟2.8ms。

Conclusion: 该系统具有可扩展性、模块化和可重构性，适合在企业AI应用中部署代理工作流。

Abstract: A vertically integrated, end-to-end, research prototype system combines 288 NorthPole neural inference accelerator cards, offline training algorithms, a high-performance runtime stack, and a containerized inference pipeline to deliver a scalable and efficient cloud inference service. The system delivers 115 peta-ops at 4-bit integer precision and 3.7 PB/s of memory bandwidth across 18 2U servers, while consuming only 30 kW of power and weighing 730 kg in a 0.67 m^2 42U rack footprint. The system can run 3 simultaneous instances of the 8-billion-parameter open-source IBM Granite-3.3-8b-instruct model at 2,048 context length with 28 simultaneous users and a per-user inter-token latency of 2.8 ms. The system is scalable, modular, and reconfigurable, supporting various model sizes and context lengths, and is ideal for deploying agentic workflows for enterprise AI applications in existing data center (cloud, on-prem) environments. For example, the system can support 18 instances of a 3-billion-parameter model or a single instance of a 70-billion-parameter model.

</details>


### [2] [Optimizing Communication in Byzantine Agreement Protocols with Slim-HBBFT](https://arxiv.org/abs/2511.15957)
*Nasit S Sony,Xianzhong Ding*

Main category: cs.DC

TL;DR: Slim-HBBFT是一个原子广播协议，通过只考虑部分节点的请求，将通信复杂度降低了O(n)倍，核心设计是优先可证明广播协议。


<details>
  <summary>Details</summary>
Motivation: 传统异步拜占庭协议需要广播所有节点的请求，成本高昂。当请求重复时，这种投资不合理。

Method: 使用优先可证明广播协议，只为选定的节点生成广播证明，设计Slim-HBBFT原子广播协议。

Result: 协议通信复杂度降低了O(n)倍，满足异步公共子集协议的安全属性。

Conclusion: Slim-HBBFT在保持安全性的同时显著降低了通信开销，适用于请求重复的场景。

Abstract: Byzantine agreement protocols in asynchronous networks have received renewed interest because they do not rely on network behavior to achieve termination. Conventional asynchronous Byzantine agreement protocols require every party to broadcast its requests (e.g., transactions), and at the end of the protocol, parties agree on one party's request. If parties agree on one party's requests while exchanging every party's request, the protocol becomes expensive. These protocols are used to design an atomic broadcast (ABC) protocol where parties agree on $\langle n-f \rangle$ parties' requests (assuming $n=3f+1$, where $n$ is the total number of parties, and $f$ is the number of Byzantine parties). Although the parties agree on a subset of requests in the ABC protocol, if the requests do not vary (are duplicated), investing in a costly protocol is not justified. We propose Slim-HBBFT, an atomic broadcast protocol that considers requests from a fraction of $n$ parties and improves communication complexity by a factor of $O(n)$. At the core of our design is a prioritized provable-broadcast (P-PB) protocol that generates proof of broadcast only for selected parties. We use the P-PB protocol to design the Slim-HBBFT atomic broadcast protocol. Additionally, we conduct a comprehensive security analysis to demonstrate that Slim-HBBFT satisfies the properties of the Asynchronous Common Subset protocol, ensuring robust security and reliability.

</details>


### [3] [Efficient Chromosome Parallelization for Precision Medicine Genomic Workflows](https://arxiv.org/abs/2511.15977)
*Daniel Mas Montserrat,Ray Verma,Míriam Barrabés,Francisco M. de la Vega,Carlos D. Bustamante,Alexander G. Ioannidis*

Main category: cs.DC

TL;DR: 提出了多种自适应RAM高效并行化染色体级生物信息学工作流的机制，包括符号回归模型估计内存消耗、动态调度器预测RAM使用并优化任务打包、静态调度器优化染色体处理顺序，以减少内存溢出并提高执行效率。


<details>
  <summary>Details</summary>
Motivation: 大规模基因组工作流在精准医学中处理数十到数百GB的数据集，导致高内存峰值、密集磁盘I/O和内存不足错误。静态资源分配方法难以处理每个染色体RAM需求的变异性，导致资源利用率差和运行时间长。

Method: 1. 开发符号回归模型估计每个染色体的内存消耗，引入插值偏置以保守地最小化过度分配；2. 提出动态调度器使用多项式回归模型自适应预测RAM使用，将任务打包视为背包问题来优化批处理作业；3. 提出静态调度器优化染色体处理顺序以最小化峰值内存同时保持吞吐量。

Result: 在模拟和真实基因组流程中的评估显示，所提方法提供了减少内存溢出和平衡线程间负载的新机制，实现了更快的端到端执行。

Conclusion: 这些方法展示了优化大规模基因组工作流的潜力，通过自适应资源管理提高效率和可靠性。

Abstract: Large-scale genomic workflows used in precision medicine can process datasets spanning tens to hundreds of gigabytes per sample, leading to high memory spikes, intensive disk I/O, and task failures due to out-of-memory errors. Simple static resource allocation methods struggle to handle the variability in per-chromosome RAM demands, resulting in poor resource utilization and long runtimes. In this work, we propose multiple mechanisms for adaptive, RAM-efficient parallelization of chromosome-level bioinformatics workflows. First, we develop a symbolic regression model that estimates per-chromosome memory consumption for a given task and introduces an interpolating bias to conservatively minimize over-allocation. Second, we present a dynamic scheduler that adaptively predicts RAM usage with a polynomial regression model, treating task packing as a Knapsack problem to optimally batch jobs based on predicted memory requirements. Additionally, we present a static scheduler that optimizes chromosome processing order to minimize peak memory while preserving throughput. Our proposed methods, evaluated on simulations and real-world genomic pipelines, provide new mechanisms to reduce memory overruns and balance load across threads. We thereby achieve faster end-to-end execution, showcasing the potential to optimize large-scale genomic workflows.

</details>


### [4] [Can Asymmetric Tile Buffering Be Beneficial?](https://arxiv.org/abs/2511.16041)
*Chengyue Wang,Wesley Pang,Xinrui Wu,Gregory Jun,Luis Romero,Endri Taka,Diana Marculescu,Tony Nowatzki,Pranathi Vasireddy,Joseph Melber,Deming Chen,Jason Cong*

Main category: cs.DC

TL;DR: 提出了非对称瓦片缓冲（ATB）技术，通过解耦输入和输出操作数的缓冲瓦片维度，显著提升GEMM性能。在AMD XDNA2 AIE上实现了4.54倍加速，达到24.6 TFLOPS。


<details>
  <summary>Details</summary>
Motivation: 传统对称瓦片缓冲方法限制了GEMM计算效率，需要一种更灵活的瓦片缓冲策略来提升算术强度。

Method: 开发了非对称瓦片缓冲（ATB）技术，解耦输入和输出操作数的缓冲瓦片维度，并建立了包含ATB收益和开销的性能模型。

Result: 在AMD XDNA2 AIE上实现了最高4.54倍加速，混合精度BFP16-BF16 GEMM性能从4.8 TFLOPS提升到24.6 TFLOPS，创下新纪录。

Conclusion: ATB是一种简单而强大的技术，能够显著提升GEMM性能，为现代AI工作负载提供了更高效的矩阵乘法解决方案。

Abstract: General matrix multiplication (GEMM) is the computational backbone of modern AI workloads, and its efficiency is critically dependent on effective tiling strategies. Conventional approaches employ symmetric tile buffering, where the buffered tile size of the input $A$ along the dimension $M$ matches the output tile size of $C$.
  In this paper, we introduce asymmetric tile buffering (ATB), a simple but powerful technique that decouples the buffered tile dimensions of the input and output operands. We show, for the first time, that ATB is both practical and highly beneficial. To explain this effect, we develop a performance model that incorporates both the benefits of ATB (higher arithmetic intensity) and its overheads (higher kernel switching costs), providing insight into how to select effective ATB tiling factors. As a case study, we apply ATB to AMD's latest XDNA2 AI Engine (AIE), achieving up to a 4.54x speedup, from 4.8 to 24.6 TFLOPS on mixed-precision BFP16--BF16 GEMM, establishing a new performance record for XDNA2 AIE.

</details>


### [5] [Mitigating Shared Storage Congestion Using Control Theory](https://arxiv.org/abs/2511.16177)
*Thomas Collignon,Kouds Halitim,Raphaël Bleuse,Sophie Cerf,Bogdan Robu,Éric Rutten,Lionel Seinturier,Alexandre van Kempen*

Main category: cs.DC

TL;DR: 提出基于控制理论的自适应方法，通过动态调节客户端I/O速率来缓解HPC系统中的I/O拥塞，提高性能稳定性


<details>
  <summary>Details</summary>
Motivation: 传统I/O栈优化方法通常针对特定工作负载且需要专业知识，难以通用化；共享HPC环境中资源拥塞会导致性能不可预测，造成减速和超时

Method: 基于控制理论的自适应方法，利用少量运行时系统负载指标动态调节客户端I/O速率，在多节点集群中实现控制器

Result: 实验表明该方法有效缓解I/O拥塞，总运行时间减少高达20%，降低尾部延迟，同时保持稳定性能

Conclusion: 基于控制理论的自适应I/O速率调节方法能够有效解决HPC系统中的I/O拥塞问题，提高系统性能和稳定性

Abstract: Efficient data access in High-Performance Computing (HPC) systems is essential to the performance of intensive computing tasks. Traditional optimizations of the I/O stack aim to improve peak performance but are often workload specific and require deep expertise, making them difficult to generalize or re-use. In shared HPC environments, resource congestion can lead to unpredictable performance, causing slowdowns and timeouts. To address these challenges, we propose a self-adaptive approach based on Control Theory to dynamically regulate client-side I/O rates. Our approach leverages a small set of runtime system load metrics to reduce congestion and enhance performance stability. We implement a controller in a multi-node cluster and evaluate it on a real testbed under a representative workload. Experimental results demonstrate that our method effectively mitigates I/O congestion, reducing total runtime by up to 20% and lowering tail latency, while maintaining stable performance.

</details>


### [6] [Fast LLM Post-training via Decoupled and Best-of-N Speculation](https://arxiv.org/abs/2511.16193)
*Rongxin Cheng,Kai Zhou,Xingda Wei,Siyuan Liu,Mingcong Han,Mingjing Ai,Yeju Zhou,Baoquan Zhong,Wencong Xiao,Xin Liu,Rong Chen,Haibo Chen*

Main category: cs.DC

TL;DR: SpecActor通过动态解耦推测和动态Best-of-N推测方法，在LLM后训练阶段实现了1.3-1.7倍的rollout加速。


<details>
  <summary>Details</summary>
Motivation: LLM后训练中rollout阶段占用了大量时间，而推测解码虽然能加速生成过程，但在大批次训练配置下效率不高，且最佳推测方法难以预先确定。

Method: 提出了动态解耦推测执行方法最大化GPU计算效率，以及动态Best-of-N推测方法根据rollout进度选择和组合不同的推测方法。

Result: SpecActor比常见的后训练基线快1.3-1.7倍，比简单采用推测解码的rollout快1.3-1.5倍。

Conclusion: SpecActor有效解决了推测解码在大批次训练配置下的效率问题，显著提升了LLM后训练中rollout阶段的性能。

Abstract: Rollout dominates the training time in large language model (LLM) post-training, where the trained model is used to generate tokens given a batch of prompts. SpecActor achieves fast rollout with speculative decoding that deploys a fast path (e.g., a smaller model) to accelerate the unparallelizable generation, while the correctness is guaranteed by fast parallel verification of the outputs with the original model. SpecActor addresses two foundational challenges in speculative rollout by (1) a \emph{dynamic decoupled speculation} execution method that maximizes the GPU computational efficiency to realize speedup for large-batch execution -- a configuration common in training but unfriendly to speculative execution and (2) a \emph{dynamic Best-of-N speculation} method that selects and combines different drafting methods according to the rollout progress. It substantially improves the speculation accuracy even when the best drafting method is unknown a priori, meanwhile without requiring adding extra computation resources. {\sys} is {1.3--1.7}\,$\times$ faster than common post-training baselines, and is {1.3--1.5}\,$\times$ faster compared to naively adopting speculative decoding for rollout.

</details>


### [7] [Optimizing Federated Learning in the Era of LLMs: Message Quantization and Streaming](https://arxiv.org/abs/2511.16450)
*Ziyue Xu,Zhihong Zhang,Holger R. Roth,Chester Chen,Yan Cheng,Andrew Feng*

Main category: cs.DC

TL;DR: 本文介绍了NVIDIA FLARE如何通过消息量化和容器/文件流技术来解决联邦学习中大语言模型面临的通信开销和本地资源限制问题。


<details>
  <summary>Details</summary>
Motivation: 联邦学习在分布式数据源上训练机器学习模型时能保护数据隐私，但面临通信开销和本地资源限制的挑战，特别是在处理数十亿参数的大语言模型时，这些模型的庞大规模加剧了内存和通信限制。

Method: 通过消息量化和容器/文件流两种关键技术：量化减少消息大小，流式传输实现高效内存管理，提高可扩展性和与现有工作流的集成。

Result: 这些改进显著增强了联邦学习与大语言模型的鲁棒性和效率，确保在真实联邦学习场景中实现更好的性能。

Conclusion: NVIDIA FLARE的先进通信能力通过量化和流式传输技术有效解决了联邦学习中大语言模型的通信和内存限制问题，提升了实际部署的可行性。

Abstract: Federated Learning (FL) offers a promising solution for training machine learning models across distributed data sources while preserving data privacy. However, FL faces critical challenges related to communication overhead and local resource constraints, especially in the era of Large Language Models (LLMs) with billions of parameters. The sheer size of these models exacerbates both memory and communication constraints, making efficient transmission and processing essential for practical deployment. NVIDIA FLARE, an open-source SDK for federated learning, addresses these challenges by introducing advanced communication capabilities. Building upon existing solutions for large object streaming, we enhance FL workflows for LLMs through two key techniques: message quantization and container/file streaming. Quantization reduces message size, while streaming enables efficient memory management, improving scalability and integration with existing workflows. These advancements significantly enhance the robustness and efficiency of FL with LLMs, ensuring better performance in real-world federated learning scenarios.

</details>


### [8] [Distributed MIS Algorithms for Rational Agents using Games](https://arxiv.org/abs/2511.16533)
*Nithin Salevemula,Shreyas Pai*

Main category: cs.DC

TL;DR: 该论文研究了在分布式网络中计算最大独立集的问题，其中节点是理性智能体，其收益取决于是否加入MIS。提出了两种基于效用模型的算法，通过邻居节点间的成对交互生成随机性，确保在理性行为下仍能打破对称性。


<details>
  <summary>Details</summary>
Motivation: 传统分布式算法假设节点遵循协议，但在理性设置中，节点可能为了最大化期望效用而偏离协议。标准MIS算法依赖诚实随机性或唯一标识符，但理性智能体可能操纵随机性，仅依赖标识符可能导致不公平，使某些节点加入MIS的概率为零而缺乏参与动机。

Method: 提出了两种算法，基于效用模型，智能体寻求局部正确解同时对所选解有偏好。算法中的随机性通过邻居节点间的成对交互生成，视为简单博弈，其中单个节点无法单方面影响结果。这允许在保持与理性行为兼容的同时打破对称性。

Result: 证明了在算法执行的每个阶段，给定任何历史，假设其他节点遵循算法，没有智能体可以通过单边偏离增加其期望效用。这提供了比颤抖手完美均衡更强的保证。当所有节点遵循协议时，每个节点都有正概率加入MIS，最终输出是正确的MIS。在温和附加假设下，两种算法都以高概率在O(log n)轮内终止。

Conclusion: 提出的算法在理性分布式设置中解决了MIS计算问题，通过成对交互生成随机性，确保了算法的激励兼容性、公平性和效率，为理性环境下的分布式计算提供了新思路。

Abstract: We study the problem of computing a Maximal Independent Set (MIS) in distributed networks where each node is a rational agent whose payoff depends on whether it joins the MIS. Classical distributed algorithms assume that nodes follow the prescribed protocol, but this assumption fails when nodes are strategic and may deviate if doing so increases their expected utility.
  Standard MIS algorithms rely on honest randomness or unique identifiers to break symmetry. In rational settings, however, agents may manipulate randomness, and relying solely on identifiers can create unfairness, giving some nodes zero probability of joining the MIS and thus no incentive to participate. To address these issues, we propose two algorithms based on a utility model in which agents seek locally correct solutions while also having preferences over which solution is chosen. Randomness in our algorithms is generated through pairwise interactions between neighboring nodes, viewed as simple games in which no single node can unilaterally affect the outcome. This allows symmetry breaking while remaining compatible with rational behavior.
  For both algorithms, we prove that at every stage of the execution, given any history, no agent can increase its expected utility through a unilateral deviation, assuming others follow the algorithm. This gives a stronger guarantee than Trembling-Hand Perfect Equilibrium. When all nodes follow the protocol, every node has a positive probability of joining the MIS, and the final output is a correct MIS. Under mild additional assumptions, both algorithms terminate in $O(\log n)$ rounds with high probability.

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [9] [AskDB: An LLM Agent for Natural Language Interaction with Relational Databases](https://arxiv.org/abs/2511.16131)
*Xuan-Quang Phan,Tan-Ha Mai,Thai-Duy Dinh,Minh-Thuan Nguyen,Lam-Son Lê*

Main category: cs.DB

TL;DR: AskDB是一个基于Gemini 2大语言模型的智能代理，通过自然语言统一支持SQL数据库的数据分析和行政操作，集成了动态模式感知提示和任务分解框架。


<details>
  <summary>Details</summary>
Motivation: 现有系统通常只解决自然语言查询或狭窄的数据库管理方面，缺乏统一的智能接口来支持通用数据库交互，特别是对于不同专业水平的用户来说，编写复杂分析查询或执行管理任务仍然具有挑战性。

Method: 基于Gemini 2构建，集成了两个关键创新：动态模式感知提示机制有效整合数据库元数据，以及任务分解框架使代理能够规划和执行多步骤操作。

Result: 在广泛使用的Text-to-SQL基准和精心策划的DBA任务集上评估，在分析和行政场景中都表现出强大的性能。

Conclusion: AskDB作为关系数据库系统的统一智能代理具有巨大潜力，为终端用户提供直观且易于访问的体验。

Abstract: Interacting with relational databases remains challenging for users across different expertise levels, particularly when composing complex analytical queries or performing administrative tasks. Existing systems typically address either natural language querying or narrow aspects of database administration, lacking a unified and intelligent interface for general-purpose database interaction. We introduce AskDB, a large language model powered agent designed to bridge this gap by supporting both data analysis and administrative operations over SQL databases through natural language. Built on Gemini 2, AskDB integrates two key innovations: a dynamic schema-aware prompting mechanism that effectively incorporates database metadata, and a task decomposition framework that enables the agent to plan and execute multi-step actions. These capabilities allow AskDB to autonomously debug derived SQL, retrieve contextual information via real-time web search, and adaptively refine its responses. We evaluate AskDB on a widely used Text-to-SQL benchmark and a curated set of DBA tasks, demonstrating strong performance in both analytical and administrative scenarios. Our results highlight the potential of AskDB as a unified and intelligent agent for relational database systems, offering an intuitive and accessible experience for end users.

</details>


### [10] [Benchmarking Table Extraction from Heterogeneous Scientific Extraction Documents](https://arxiv.org/abs/2511.16134)
*Marijan Soric,Cécile Gracianne,Ioana Manolescu,Pierre Senellart*

Main category: cs.DB

TL;DR: 提出了一个新的端到端表格提取基准测试，包含37k样本的新数据集，评估了多种表格提取方法，发现当前方法在异质数据处理、鲁棒性和可解释性方面存在不足。


<details>
  <summary>Details</summary>
Motivation: 现有的表格提取工具方法多样，用户难以选择合适的工具，需要系统性的评估基准来比较不同方法的性能。

Method: 设计了严格的评估流程，包含表格提取各子任务的评分和端到端评估，使用两个新的异质数据集（共37k样本）和现有数据集进行测试。

Result: 测试了现成库、软件工具、大型视觉语言模型和计算机视觉方法，结果显示表格提取仍然具有挑战性，现有方法在面对异质数据时泛化能力不足。

Conclusion: 表格提取仍是一个未解决的问题，当前方法在泛化性、鲁棒性和可解释性方面存在局限，需要进一步改进。

Abstract: Table Extraction (TE) consists in extracting tables from PDF documents, in a structured format which can be automatically processed. While numerous TE tools exist, the variety of methods and techniques makes it difficult for users to choose an appropriate one. We propose a novel benchmark for assessing end-to-end TE methods (from PDF to the final table). We contribute an analysis of TE evaluation metrics, and the design of a rigorous evaluation process, which allows scoring each TE sub-task as well as end-to-end TE, and captures model uncertainty. Along with a prior dataset, our benchmark comprises two new heterogeneous datasets of 37k samples. We run our benchmark on diverse models, including off-the-shelf libraries, software tools, large vision language models, and approaches based on computer vision. The results demonstrate that TE remains challenging: current methods suffer from a lack of generalizability when facing heterogeneous data, and from limitations in robustness and interpretability.

</details>


### [11] [On 10x Better Scalability: KV Stores Scale Up KV Cache](https://arxiv.org/abs/2511.16138)
*Weiping Yu,Ye Jiarui,He Mengke,Junfeng Liu,Siqiang Luo*

Main category: cs.DB

TL;DR: SGLANG-LSM是一个基于LSM-tree架构的KV缓存管理系统，通过分层设计解决现有磁盘KV缓存系统的扩展性问题，显著提升缓存命中率和降低首token延迟。


<details>
  <summary>Details</summary>
Motivation: 现有基于磁盘的KV缓存系统使用文件对象布局，存在文件系统元数据开销、I/O效率低和空间局部性差等严重扩展性瓶颈。

Method: 采用三层协调组件：前缀保持存储引擎维护token序列局部性，自适应控制器动态优化LSM-tree配置，运行时服务提供批处理和自动资源管理。

Result: 在大规模动态工作负载评估中，相比最先进系统，缓存命中率提升高达143%，首token延迟降低高达24%。

Conclusion: 这是首次将数据库存储架构系统性地应用于大规模LLM缓存管理，展示了LSM-tree在KV缓存管理中的有效性。

Abstract: Large language models (LLMs) rely on Key-Value (KV) cache to reduce time- to-first-token (TTFT) latency, but existing disk-based KV cache systems using file-per-object layouts suffer from severe scalability bottlenecks due to file system metadata overhead, I/O inefficiency, and poor spatial locality. This paper presents SGLANG-LSM, a database-inspired system that leverages Log-Structured Merge- tree (LSM-tree) architectures for scalable KV cache management. SGLANG-LSM implements a layered system design with three coordinated components: (1) a prefix-preserving storage engine that maintains token sequence locality while efficiently storing large KV cache tensors through key-value separation, (2) an adaptive controller that dynamically optimizes LSM-tree configurations based on shifting workload characteristics, and (3) runtime services including batch opera- tions and automatic resource management for production deployment. Evaluation on large-scale dynamic workloads demonstrates that SGLANG-LSM significantly improves cache hits by up to 143% and reduces TTFT by up to 24% compared to state-of-the-art systems, representing the first systematic application of database storage architectures to large-scale LLM cache management.

</details>


### [12] [From Patents to Dataset: Scraping for Oxide Glass Compositions and Properties](https://arxiv.org/abs/2511.16366)
*Gustavo Laranja Thomaello,Thomaz Yeiden Busnardo Aguena,Eric Trevelato Costa,Rafael Baságlia Rosante,Thiago Rodrigo Ramos,Daiane Aparecida Zuanetti,Edgar Dutra Zanotto*

Main category: cs.DB

TL;DR: 使用网络爬虫技术从专利表格中提取玻璃成分和性能数据，构建数据库用于机器学习模型开发新型玻璃


<details>
  <summary>Details</summary>
Motivation: 现有玻璃数据库信息有限，需要扩展数据量和多样性来支持机器学习模型开发新型玻璃

Method: 采用网络爬虫技术提取专利表格中的玻璃成分和性能数据，进行数据清洗和结构化处理

Result: 成功提取了5,696个液相温度数据、4,298个折射率数据和1,771个阿贝数数据，将现有数据库分别扩展了10.4%、6.6%和4.9%

Conclusion: 新提取的数据不仅增加了数据量，更重要的是扩展了成分和性能的多样性，特别是增加了钛、镁、锆、铌、铁、锡和钇氧化物的含量

Abstract: In this work, we present web scraping techniques to extract in- formation from patent tables, clean and structure them for future use in predictive machine learning models to develop new glasses. We extracted compositions and three properties relevant to the development of new glasses and structured them into a database to be used together with information from other available datasets. We also analyzed the consistency of the information obtained and what it adds to the existing databases. The extracted liquidus temperatures comprise 5,696 compositions; the second subset includes 4,298 refractive indexes and, finally, 1,771 compositions with Abbe numbers. The extraction performed here increases the available information by approximately 10.4% for liquidus temperature, 6.6% for refractive index, and 4.9% for Abbe number. The impact extends beyond quantity: the newly extracted data introduce compositions with property values that are more diverse than those in existing databases, thereby expanding the accessible compositional and property space for glass modeling applications. We emphasize that the compositions of the new database contain relatively more titanium, magnesium, zirconium, niobium, iron, tin, and yttrium oxides than those of the existing bases.

</details>


### [13] [[Experiment, Analysis, and Benchmark] Systematic Evaluation of Plan-based Adaptive Query Processing](https://arxiv.org/abs/2511.16455)
*Pei Mu,Anderson Chaves Carniel,Antonio Barbalace,Amir Shaikhha*

Main category: cs.DB

TL;DR: 本文首次全面分析了基于计划的AQP策略，发现在磁盘数据库和内存数据库中性能提升的来源不同：PostgreSQL主要来自查询计划重排序，而DuckDB主要来自基数估计精炼。


<details>
  <summary>Details</summary>
Motivation: 不可靠的基数估计仍然是数据库管理系统中的关键性能瓶颈。虽然基于计划的自适应查询处理策略通过子计划执行反馈来改进基数估计，但其在不同存储架构下的实际改进原因尚未被探索。

Method: 在磁盘数据库(PostgreSQL)和内存数据库(DuckDB)上实现并评估了最先进的基于计划AQP策略，使用两个基准测试进行对比分析。

Result: 基于计划的AQP在两种环境中都提供了整体加速，但改进来源显著不同：PostgreSQL中性能提升主要来自查询计划重排序而非基数更新机制；DuckDB中基数精炼对大多数查询带来了显著性能改进。

Conclusion: 这些发现为研究人员提供了关于基于计划AQP何时以及为何有效的关键见解，并指导数据库系统开发者在实现努力与性能改进之间进行权衡。

Abstract: Unreliable cardinality estimation remains a critical performance bottleneck in database management systems (DBMSs). Adaptive Query Processing (AQP) strategies address this limitation by providing a more robust query execution mechanism. Specifically, plan-based AQP achieves this by incrementally refining cardinality using feedback from the execution of sub-plans. However, the actual reason behind the improvements of plan-based AQP, especially across different storage architectures (on-disk vs. in-memory DBMSs), remains unexplored.
  This paper presents the first comprehensive analysis of state-of-the-art plan-based AQP. We implement and evaluate this strategy on both on-disk and in-memory DBMSs across two benchmarks. Our key findings reveal that while plan-based AQP provides overall speedups in both environments, the sources of improvement differ significantly. In the on-disk DBMS, PostgreSQL, performance gains primarily come from the query plan reorderings, but not the cardinality updating mechanism; in fact, updating cardinalities introduces measurable overhead. Conversely, in the in-memory DBMS, DuckDB, cardinality refinement drives significant performance improvements for most queries. We also observe significant performance benefits of the plan-based AQP compared to a state-of-the-art related-based AQP method. These observations provide crucial insights for researchers on when and why plan-based AQP is effective, and ultimately guide database system developers on the tradeoffs between the implementation effort and performance improvements.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [14] [Technique to Baseline QE Artefact Generation Aligned to Quality Metrics](https://arxiv.org/abs/2511.15733)
*Eitan Farchi,Kiran Nayak,Papia Ghosh Majumdar,Saritha Route*

Main category: cs.SE

TL;DR: 提出了一种系统性方法来基准化和评估LLM生成的质量工程产物，通过可量化指标确保自动化生成的质量


<details>
  <summary>Details</summary>
Motivation: LLM在质量工程中自动生成需求、测试用例等产物，但确保这些输出质量仍具挑战性

Method: 结合LLM驱动生成、反向生成和基于评分标准的迭代优化技术，评估清晰度、完整性、一致性和可测试性

Result: 在12个项目中的实验结果显示，反向生成的产物能够超越低质量输入，并在输入质量高时保持高标准

Conclusion: 该框架实现了可扩展、可靠的质量工程产物验证，在自动化与责任之间架起桥梁

Abstract: Large Language Models (LLMs) are transforming Quality Engineering (QE) by automating the generation of artefacts such as requirements, test cases, and Behavior Driven Development (BDD) scenarios. However, ensuring the quality of these outputs remains a challenge. This paper presents a systematic technique to baseline and evaluate QE artefacts using quantifiable metrics. The approach combines LLM-driven generation, reverse generation , and iterative refinement guided by rubrics technique for clarity, completeness, consistency, and testability. Experimental results across 12 projects show that reverse-generated artefacts can outperform low-quality inputs and maintain high standards when inputs are strong. The framework enables scalable, reliable QE artefact validation, bridging automation with accountability.

</details>


### [15] [Rethinking Kernel Program Repair: Benchmarking and Enhancing LLMs with RGym](https://arxiv.org/abs/2511.15757)
*Kareem Shehada,Yifan Wu,Wyatt D. Feng,Adithya Iyer,Gryphon Kumfert,Yangruibo Ding,Zhiyun Qian*

Main category: cs.SE

TL;DR: RGym是一个轻量级、平台无关的Linux内核自动程序修复评估框架，在本地硬件上运行，通过专门的定位技术实现43.36%的修复成功率，成本低于每错误0.20美元。


<details>
  <summary>Details</summary>
Motivation: 现有APR基准主要关注用户空间应用，忽略了内核空间调试和修复的复杂性。Linux内核由于其单体结构、并发性和低级硬件交互而带来独特挑战，现有方法成功率低或依赖昂贵复杂的基础设施。

Method: 基于RGym框架构建简单有效的APR流水线，利用专门的定位技术（如调用栈和归咎提交）来克服KGym中不切实际的oracle使用，在143个已验证错误的数据集上进行测试。

Result: 使用GPT-5 Thinking实现了高达43.36%的通过率，每错误成本低于0.20美元。消融研究分析了定位策略、提示结构和模型选择的贡献，并证明基于反馈的重试可以显著提高成功率。

Conclusion: RGym提供了一个轻量级、成本效益高的Linux内核APR解决方案，通过专门的定位技术和反馈机制显著提高了修复成功率，同时降低了基础设施成本。

Abstract: Large Language Models (LLMs) have revolutionized automated program repair (APR) but current benchmarks like SWE-Bench predominantly focus on userspace applications and overlook the complexities of kernel-space debugging and repair. The Linux kernel poses unique challenges due to its monolithic structure, concurrency, and low-level hardware interactions. Prior efforts such as KGym and CrashFixer have highlighted the difficulty of APR in this domain, reporting low success rates or relying on costly and complex pipelines and pricey cloud infrastructure. In this work, we introduce RGym, a lightweight, platform-agnostic APR evaluation framework for the Linux kernel designed to operate on local commodity hardware. Built on RGym, we propose a simple yet effective APR pipeline leveraging specialized localization techniques (e.g., call stacks and blamed commits) to overcome the unrealistic usage of oracles in KGym. We test on a filtered and verified dataset of 143 bugs. Our method achieves up to a 43.36% pass rate with GPT-5 Thinking while maintaining a cost of under $0.20 per bug. We further conduct an ablation study to analyze contributions from our proposed localization strategy, prompt structure, and model choice, and demonstrate that feedback-based retries can significantly enhance success rates.

</details>


### [16] [A Causal Perspective on Measuring, Explaining and Mitigating Smells in \llm-Generated Code](https://arxiv.org/abs/2511.15817)
*Alejandro Velasco,Daniel Rodriguez-Cardenas,Dipin Khati,David N. Palacio,Luftar Rahman Alif,Denys Poshyvanyk*

Main category: cs.SE

TL;DR: 本文系统性地测量、解释和缓解LLM生成代码中的代码异味倾向，提出了PSC指标作为结构质量的信号，并分析了生成策略、模型大小、架构和提示设计对代码质量的影响。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM在软件工程中应用广泛，但其生成的代码存在结构质量问题，经常复制不良编码实践，引入代码异味。目前缺乏对这些问题的系统理解。

Method: 基于概率性指标PSC（Propensity Smelly Score）来估计生成特定异味类型的可能性，将其作为因果分析工具，研究生成策略、模型大小、架构和提示设计对代码结构质量的影响。

Result: 发现提示设计和架构选择在异味倾向中起决定性作用，提出了实际缓解策略来减少异味发生。用户研究显示PSC能帮助开发者解释模型行为和评估代码质量。

Conclusion: 本研究为将质量感知评估整合到LLM代码生成评估和部署中奠定了基础，证明了异味倾向信号可以支持人类判断。

Abstract: Recent advances in large language models (LLMs) have accelerated their adoption in software engineering contexts. However, concerns persist about the structural quality of the code they produce. In particular, LLMs often replicate poor coding practices, introducing code smells (i.e., patterns that hinder readability, maintainability, or design integrity). Although prior research has examined the detection or repair of smells, we still lack a clear understanding of how and when these issues emerge in generated code.
  This paper addresses this gap by systematically measuring, explaining and mitigating smell propensity in LLM-generated code. We build on the Propensity Smelly Score (PSC), a probabilistic metric that estimates the likelihood of generating particular smell types, and establish its robustness as a signal of structural quality. Using PSC as an instrument for causal analysis, we identify how generation strategy, model size, model architecture and prompt formulation shape the structural properties of generated code. Our findings show that prompt design and architectural choices play a decisive role in smell propensity and motivate practical mitigation strategies that reduce its occurrence. A user study further demonstrates that PSC helps developers interpret model behavior and assess code quality, providing evidence that smell propensity signals can support human judgement. Taken together, our work lays the groundwork for integrating quality-aware assessments into the evaluation and deployment of LLMs for code.

</details>


### [17] [AI-Enabled Orchestration of Event-Driven Business Processes in Workday ERP for Healthcare Enterprises](https://arxiv.org/abs/2511.15852)
*Monu Sharma*

Main category: cs.SE

TL;DR: 提出在Workday ERP中集成AI驱动的事件驱动编排框架，通过机器学习触发器和异常检测来优化医疗机构的财务和供应链工作流程


<details>
  <summary>Details</summary>
Motivation: 传统ERP系统的工作流逻辑缺乏适应性，难以管理事件驱动和数据密集的医疗环境，需要更智能的解决方案

Method: 开发AI驱动的事件驱动编排框架，采用机器学习触发器、异常检测和流程挖掘分析，自动响应库存耗尽、付款延迟等运营事件

Result: 多组织案例分析显示在流程效率、成本可视性和决策准确性方面取得了可衡量的改进

Conclusion: 将AI能力嵌入Workday的事件驱动架构可增强运营弹性、治理和可扩展性，为医疗企业的下一代自动化策略提供参考

Abstract: The adoption of cloud-based Enterprise Resource Planning (ERP) platforms such as Workday has transformed healthcare operations by integrating financial, supply-chain, and workforce processes into a unified ecosystem. However, traditional workflow logic in ERP systems often lacks the adaptability required to manage event-driven and data-intensive healthcare environments.
  This study proposes an AI-enabled event-driven orchestration framework within Workday ERP that intelligently synchronizes financial and supply-chain workflows across distributed healthcare entities. The framework employs machine-learning triggers, anomaly detection, and process mining analytics to anticipate and automate responses to operational events such as inventory depletion, payment delays, or patient demand fluctuations. A multi-organization case analysis demonstrates measurable gains in process efficiency, cost visibility, and decision accuracy.
  Results confirm that embedding AI capabilities into Workday's event-based architecture enhances operational resilience, governance, and scalability. The proposed model contributes to the broader understanding of intelligent ERP integration and establishes a reference for next-generation automation strategies in healthcare enterprises.

</details>


### [18] [RE for AI in Practice: Managing Data Annotation Requirements for AI Autonomous Driving Systems](https://arxiv.org/abs/2511.15859)
*Hina Saeeda,Mazen Mohamad,Eric Knauss,Jennifer Horkoff,Ali Nouri*

Main category: cs.SE

TL;DR: 本研究探讨自动驾驶AI感知系统中数据标注要求的重要性、实践挑战和改进方法，通过19个半结构化访谈揭示了标注要求与系统性能的关键关联。


<details>
  <summary>Details</summary>
Motivation: 高质量数据标注要求对开发安全可靠的自动驾驶AI感知系统至关重要，但目前其制定和管理缺乏系统性研究，导致不一致性、安全风险和监管问题。

Method: 对来自6家国际公司和4个研究机构的参与者进行19个半结构化访谈，采用主题分析方法识别关键挑战和最佳实践。

Result: 识别出五大挑战：模糊性、边缘案例复杂性、需求演变、不一致性和资源约束；三大最佳实践类别：确保伦理标准合规、改进标注要求指南、嵌入式质量保证。揭示了标注要求、标注实践、数据质量和AI系统性能之间的关键关联。

Conclusion: 本研究首次提供基于实证的标注要求改进指南，为提升标注质量、监管合规性和系统可靠性提供可行见解，同时为软件工程和需求工程在AI领域的发展做出贡献。

Abstract: High-quality data annotation requirements are crucial for the development of safe and reliable AI-enabled perception systems (AIePS) in autonomous driving. Although these requirements play a vital role in reducing bias and enhancing performance, their formulation and management remain underexplored, leading to inconsistencies, safety risks, and regulatory concerns. Our study investigates how annotation requirements are defined and used in practice, the challenges in ensuring their quality, practitioner-recommended improvements, and their impact on AIePS development and performance. We conducted $19$ semi-structured interviews with participants from six international companies and four research organisations. Our thematic analysis reveals five main key challenges: ambiguity, edge case complexity, evolving requirements, inconsistencies, and resource constraints and three main categories of best practices, including ensuring compliance with ethical standards, improving data annotation requirements guidelines, and embedded quality assurance for data annotation requirements. We also uncover critical interrelationships between annotation requirements, annotation practices, annotated data quality, and AIePS performance and development, showing how requirement flaws propagate through the AIePS development pipeline. To the best of our knowledge, this study is the first to offer empirically grounded guidance on improving annotation requirements, offering actionable insights to enhance annotation quality, regulatory compliance, and system reliability. It also contributes to the emerging fields of Software Engineering (SE for AI) and Requirements Engineering (RE for AI) by bridging the gap between RE and AI in a timely and much-needed manner.

</details>


### [19] [InfCode: Adversarial Iterative Refinement of Tests and Patches for Reliable Software Issue Resolution](https://arxiv.org/abs/2511.16004)
*KeFan Li,Mengfei Wang,Hengzhi Zhang,Zhichao Li,Yuan Yuan,Mu Li,Xiang Gao,Hailong Sun,Chunming Hu,Weifeng Lv*

Main category: cs.SE

TL;DR: InfCode是一个对抗性多智能体框架，通过测试生成器和代码补丁生成器的对抗性交互，迭代优化测试和补丁，实现仓库级软件问题的自动修复。


<details>
  <summary>Details</summary>
Motivation: 现有基于智能体和流水线的方法依赖不充分的测试，导致补丁可能通过验证但未能真正修复缺陷，需要更好的仓库级推理和验证机制。

Method: 使用对抗性多智能体框架，包含测试补丁生成器、代码补丁生成器和选择器，在容器化环境中进行迭代优化和验证。

Result: 在SWE-bench Lite和SWE-bench Verified基准测试中，使用DeepSeek-V3和Claude 4.5 Sonnet等模型，InfCode持续优于强基线，在SWE-bench Verified上达到79.4%的性能，创下新纪录。

Conclusion: InfCode通过对抗性多智能体框架有效解决了仓库级软件问题修复的挑战，实现了最先进的性能，并已开源发布。

Abstract: Large language models have advanced software engineering automation, yet resolving real-world software issues remains difficult because it requires repository-level reasoning, accurate diagnostics, and strong verification signals. Existing agent-based and pipeline-based methods often rely on insufficient tests, which can lead to patches that satisfy verification but fail to fix the underlying defect. We present InfCode, an adversarial multi-agent framework for automated repository-level issue resolution. InfCode iteratively refines both tests and patches through adversarial interaction between a Test Patch Generator and a Code Patch Generator, while a Selector agent identifies the most reliable fix. The framework runs inside a containerized environment that supports realistic repository inspection, modification, and validation. Experiments on SWE-bench Lite and SWE-bench Verified using models such as DeepSeek-V3 and Claude 4.5 Sonnet show that InfCode consistently outperforms strong baselines. It achieves 79.4% performance on SWE-bench Verified, establishing a new state-of-the-art. We have released InfCode as an open-source project at https://github.com/Tokfinity/InfCode.

</details>


### [20] [InfCode-C++: Intent-Guided Semantic Retrieval and AST-Structured Search for C++ Issue Resolution](https://arxiv.org/abs/2511.16005)
*Qingao Dong,Mengfei Wang,Hengzhi Zhang,Zhichao Li,Yuan Yuan,Mu Li,Xiang Gao,Hailong Sun,Chunming Hu,Weifeng Lv*

Main category: cs.SE

TL;DR: INFCODE-C++是首个面向C++的自主问题解决系统，通过语义代码意图检索和确定性AST结构化查询相结合，在MultiSWE-bench-CPP基准测试中达到25.58%的解决率，比之前最佳代理提升10.85个百分点。


<details>
  <summary>Details</summary>
Motivation: 现有LLM代理主要针对Python设计，在C++项目中表现不佳，因为C++的重载标识符、嵌套命名空间、模板实例化和深层控制流结构使得上下文检索和故障定位更加困难。

Method: 结合两种互补的检索机制：语义代码意图检索和确定性AST结构化查询，构建准确的语言感知上下文进行修复。

Result: 在MultiSWE-bench-CPP基准测试中达到25.58%的解决率，比之前最强代理提升10.85个百分点，是MSWE-agent性能的两倍多。

Conclusion: INFCODE-C++强调了在多语言软件代理中语言感知推理的必要性，为未来在复杂静态类型生态系统中进行可扩展的LLM驱动修复研究奠定了基础。

Abstract: Large language model (LLM) agents have recently shown strong performance on repository-level issue resolution, but existing systems are almost exclusively designed for Python and rely heavily on lexical retrieval and shallow code navigation. These approaches transfer poorly to C++ projects, where overloaded identifiers, nested namespaces, template instantiations, and deep control-flow structures make context retrieval and fault localization substantially more difficult. As a result, state-of-the-art Python-oriented agents show a drastic performance drop on the C++ subset of MultiSWE-bench. We introduce INFCODE-C++, the first C++-aware autonomous system for end-to-end issue resolution. The system combines two complementary retrieval mechanisms -- semantic code-intent retrieval and deterministic AST-structured querying -- to construct accurate, language-aware context for repair.These components enable precise localization and robust patch synthesis in large, statically typed C++ repositories. Evaluated on the \texttt{MultiSWE-bench-CPP} benchmark, INFCODE-C++ achieves a resolution rate of 25.58\%, outperforming the strongest prior agent by 10.85 percentage points and more than doubling the performance of MSWE-agent. Ablation and behavioral studies further demonstrate the critical role of semantic retrieval, structural analysis, and accurate reproduction in C++ issue resolution. INFCODE-C++ highlights the need for language-aware reasoning in multi-language software agents and establishes a foundation for future research on scalable, LLM-driven repair for complex, statically typed ecosystems.

</details>


### [21] [The Future of Development Environments with AI Foundation Models: NII Shonan Meeting 222 Report](https://arxiv.org/abs/2511.16092)
*Xing Hu,Raula Gaikovina Kula,Christoph Treude*

Main category: cs.SE

TL;DR: 33名专家在Shonan Meeting 222上讨论了生成式AI对集成开发环境的影响，探讨了挑战和机遇。


<details>
  <summary>Details</summary>
Motivation: 探索生成式AI在代码生成、测试、代码审查和程序修复等任务中的卓越表现如何改变IDE中的人机交互，提高抽象层次。

Method: 组织33名来自软件工程、人工智能和人机交互领域的专家进行讨论会议。

Result: 专家们识别了生成式AI对IDE的影响，包括挑战和机遇，形成了会议报告。

Conclusion: 生成式AI有潜力通过提高抽象层次来改变IDE中的人机交互方式，需要进一步研究相关挑战和机遇。

Abstract: Generative Artificial Intelligence (GenAI) models are achieving remarkable performance in various tasks, including code generation, testing, code review, and program repair. The ability to increase the level of abstraction away from writing code has the potential to change the Human-AI interaction within the integrated development environment (IDE). To explore the impact of GenAI on IDEs, 33 experts from the Software Engineering, Artificial Intelligence, and Human-Computer Interaction domains gathered to discuss challenges and opportunities at Shonan Meeting 222. This is the report

</details>


### [22] [Domain-constrained Synthesis of Inconsistent Key Aspects in Textual Vulnerability Descriptions](https://arxiv.org/abs/2511.16123)
*Linyi Han,Shidong Pan,Zhenchang Xing,Sofonias Yitagesu,Xiaowang Zhang,Zhiyong Feng,Jiamou Sun,Qing Huang*

Main category: cs.SE

TL;DR: 提出基于领域约束LLM的文本漏洞描述合成框架，通过提取、自评估和融合三阶段统一不同来源的漏洞描述关键方面，提升合成性能30%以上。


<details>
  <summary>Details</summary>
Motivation: 不同漏洞库中的文本漏洞描述存在关键方面不一致问题，现有方法丢弃有价值信息且无法合成全面表示，需要统一不同来源的漏洞描述。

Method: 三阶段框架：1)基于规则模板的提取确保捕获关键细节；2)使用领域特定锚词评估语义变异性；3)利用信息熵调和不一致并优先相关细节。

Result: 关键方面增强的F1分数从0.82提升到0.87，理解和效率提升超过30%，开发的可视化工具Digest Labels显著提升可用性。

Conclusion: 该框架有效解决了文本漏洞描述的不一致问题，提高了漏洞理解的全面性和效率，实用工具得到人类评估验证。

Abstract: Textual Vulnerability Descriptions (TVDs) are crucial for security analysts to understand and address software vulnerabilities. However, the key aspect inconsistencies in TVDs from different repositories pose challenges for achieving a comprehensive understanding of vulnerabilities. Existing approaches aim to mitigate inconsistencies by aligning TVDs with external knowledge bases, but they often discard valuable information and fail to synthesize comprehensive representations. In this paper, we propose a domain-constrained LLM-based synthesis framework for unifying key aspects of TVDs. Our framework consists of three stages: 1) Extraction, guided by rule-based templates to ensure all critical details are captured; 2) Self-evaluation, using domain-specific anchor words to assess semantic variability across sources; and 3) Fusion, leveraging information entropy to reconcile inconsistencies and prioritize relevant details. This framework improves synthesis performance, increasing the F1 score for key aspect augmentation from 0.82 to 0.87, while enhancing comprehension and efficiency by over 30\%. We further develop Digest Labels, a practical tool for visualizing TVDs, which human evaluations show significantly boosts usability.

</details>


### [23] [Beyond Code Similarity: Benchmarking the Plausibility, Efficiency, and Complexity of LLM-Generated Smart Contracts](https://arxiv.org/abs/2511.16224)
*Francesco Salzano,Simone Scalabrino,Rocco Oliveto,Simone Scalabrino*

Main category: cs.SE

TL;DR: LLM生成的Solidity智能合约虽然语义相似度高，但功能正确性低（仅20-26%），生成的代码更简单但缺乏验证逻辑，检索增强生成能显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 评估LLM在智能合约代码生成中的可靠性，特别是针对gas消耗、安全性和确定性等独特约束。

Method: 对4个最先进模型进行零样本和检索增强生成测试，使用代码相似度、语义嵌入、自动化测试、gas分析、复杂度分析等多维度评估500个真实函数。

Result: LLM生成的代码语义相似度高但功能正确性低，代码更简单且gas消耗更低（因省略验证逻辑），检索增强生成将功能正确性提升至45%。

Conclusion: 语义相似性与功能可行性存在显著差距，检索增强生成是有效增强手段，但要实现生产就绪的代码生成仍需专家验证。

Abstract: Smart Contracts are critical components of blockchain ecosystems, with Solidity as the dominant programming language. While LLMs excel at general-purpose code generation, the unique constraints of Smart Contracts, such as gas consumption, security, and determinism, raise open questions about the reliability of LLM-generated Solidity code. Existing studies lack a comprehensive evaluation of these critical functional and non-functional properties. We benchmark four state-of-the-art models under zero-shot and retrieval-augmented generation settings across 500 real-world functions. Our multi-faceted assessment employs code similarity metrics, semantic embeddings, automated test execution, gas profiling, and cognitive and cyclomatic complexity analysis. Results show that while LLMs produce code with high semantic similarity to real contracts, their functional correctness is low: only 20% to 26% of zero-shot generations behave identically to ground-truth implementations under testing. The generated code is consistently simpler, with significantly lower complexity and gas consumption, often due to omitted validation logic. Retrieval-Augmented Generation markedly improves performance, boosting functional correctness by up to 45% and yielding more concise and efficient code. Our findings reveal a significant gap between semantic similarity and functional plausibility in LLM-generated Smart Contracts. We conclude that while RAG is a powerful enhancer, achieving robust, production-ready code generation remains a substantial challenge, necessitating careful expert validation.

</details>


### [24] [Data Annotation Quality Problems in AI-Enabled Perception System Development](https://arxiv.org/abs/2511.16410)
*Hina Saeeda,Tommy Johansson,Mazen Mohamad,Eric Knauss*

Main category: cs.SE

TL;DR: 本研究通过多组织案例研究开发了一个包含18种标注错误类型的分类法，涵盖完整性、准确性和一致性三个数据质量维度，为构建可信的AI感知系统提供了共享词汇、诊断工具和行动指南。


<details>
  <summary>Details</summary>
Motivation: 数据标注在自动驾驶AI感知系统开发中至关重要但容易出错，行业缺乏关于标注错误如何在多组织汽车供应链中出现和传播的实证见解。

Method: 采用多组织案例研究，涉及6家公司和4个研究机构，基于19次半结构化访谈（20位专家，50小时转录）和六阶段主题分析。

Result: 开发了包含18种重复出现的标注错误类型的分类法，分为完整性、准确性和一致性三个维度，经行业从业者验证具有实用性。

Conclusion: 通过将标注质量概念化为生命周期和供应链问题，本研究为SE4AI提供了共享词汇、诊断工具集和可操作指导，有助于构建可信的AI感知系统。

Abstract: Data annotation is essential but highly error-prone in the development of AI-enabled perception systems (AIePS) for automated driving, and its quality directly influences model performance, safety, and reliability. However, the industry lacks empirical insights into how annotation errors emerge and spread across the multi-organisational automotive supply chain. This study addresses this gap through a multi-organisation case study involving six companies and four research institutes across Europe and the UK. Based on 19 semi-structured interviews with 20 experts (50 hours of transcripts) and a six-phase thematic analysis, we develop a taxonomy of 18 recurring annotation error types across three data-quality dimensions: completeness (e.g., attribute omission, missing feedback loops, edge-case omissions, selection bias), accuracy (e.g., mislabelling, bounding-box inaccuracies, granularity mismatches, bias-driven errors), and consistency (e.g., inter-annotator disagreement, ambiguous instructions, misaligned hand-offs, cross-modality inconsistencies). The taxonomy was validated with industry practitioners, who reported its usefulness for root-cause analysis, supplier quality reviews, onboarding, and improving annotation guidelines. They described it as a failure-mode catalogue similar to FMEA. By conceptualising annotation quality as a lifecycle and supply-chain issue, this study contributes to SE4AI by offering a shared vocabulary, diagnostic toolset, and actionable guidance for building trustworthy AI-enabled perception systems.

</details>


### [25] [Green Resilience of Cyber-Physical Systems: Doctoral Dissertation](https://arxiv.org/abs/2511.16593)
*Diaeddin Rimawi*

Main category: cs.SE

TL;DR: 该研究提出了GResilience框架，通过多目标优化、博弈论决策和强化学习来平衡在线协作AI系统的弹性与绿色性，实现性能恢复同时减少能耗。


<details>
  <summary>Details</summary>
Motivation: 在线协作AI系统容易受到干扰事件影响性能，决策者需要在恢复性能与限制能耗之间取得平衡，解决弹性与绿色性之间的权衡问题。

Method: 将OL-CAIS行为建模为三种运行状态：稳定、干扰和最终状态；开发GResilience框架，提供三种恢复策略：多目标优化（单代理）、博弈论决策（双代理）和强化学习（RL代理）；设计量化弹性和绿色性的测量框架。

Result: 弹性模型能捕捉干扰期间的性能转换；GResilience策略通过缩短恢复时间、稳定性能和减少人类依赖来改善绿色恢复；RL代理策略效果最佳，但CO2排放略有增加；容器化执行可将CO2排放减半。

Conclusion: 该研究提供了确保OL-CAIS绿色恢复的模型、指标和策略，能够有效平衡系统弹性与能源效率。

Abstract: Cyber-physical systems (CPS) combine computational and physical components. Online Collaborative AI System (OL-CAIS) is a type of CPS that learn online in collaboration with humans to achieve a common goal, which makes it vulnerable to disruptive events that degrade performance. Decision-makers must therefore restore performance while limiting energy impact, creating a trade-off between resilience and greenness. This research addresses how to balance these two properties in OL-CAIS. It aims to model resilience for automatic state detection, develop agent-based policies that optimize the greenness-resilience trade-off, and understand catastrophic forgetting to maintain performance consistency. We model OL-CAIS behavior through three operational states: steady, disruptive, and final. To support recovery during disruptions, we introduce the GResilience framework, which provides recovery strategies through multi-objective optimization (one-agent), game-theoretic decision-making (two-agent), and reinforcement learning (RL-agent). We also design a measurement framework to quantify resilience and greenness. Empirical evaluation uses real and simulated experiments with a collaborative robot learning object classification from human demonstrations. Results show that the resilience model captures performance transitions during disruptions, and that GResilience policies improve green recovery by shortening recovery time, stabilizing performance, and reducing human dependency. RL-agent policies achieve the strongest results, although with a marginal increase in CO2 emissions. We also observe catastrophic forgetting after repeated disruptions, while our policies help maintain steadiness. A comparison with containerized execution shows that containerization cuts CO2 emissions by half. Overall, this research provides models, metrics, and policies that ensure the green recovery of OL-CAIS.

</details>
