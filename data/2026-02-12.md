<div id=toc></div>

# Table of Contents

- [cs.DB](#cs.DB) [Total: 3]
- [cs.SE](#cs.SE) [Total: 10]
- [cs.DC](#cs.DC) [Total: 7]


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [1] [Making Databases Faster with LLM Evolutionary Sampling](https://arxiv.org/abs/2602.10387)
*Mehmet Hamza Erol,Xiangpeng Hao,Federico Bianchi,Ciro Greco,Jacopo Tagliabue,James Zou*

Main category: cs.DB

TL;DR: 使用LLM进行查询优化，通过进化搜索改进物理执行计划，在DataFusion引擎上实现最高4.78倍加速


<details>
  <summary>Details</summary>
Motivation: 传统基于成本的查询优化器依赖预定义启发式和统计模型，改进这些启发式需要大量工程工作，且无法考虑查询和模式中的语义相关性，可能错过更好的物理执行计划

Method: 使用DBPlanBench框架暴露DataFusion引擎的物理执行计划，通过紧凑序列化表示让LLM提出局部编辑建议，然后应用进化搜索迭代改进候选方案

Result: 在某些查询上获得最高4.78倍加速，并展示了从小数据库到大数据库的优化迁移工作流，证明在小数据库上发现的优化能有效迁移到更大数据库

Conclusion: LLM能够利用语义知识识别和应用非显而易见的优化（如最小化中间基数的连接顺序），为查询优化提供了新的有效方法

Abstract: Traditional query optimization relies on cost-based optimizers that estimate execution cost (e.g., runtime, memory, and I/O) using predefined heuristics and statistical models. Improving these heuristics requires substantial engineering effort, and even when implemented, these heuristics often cannot take into account semantic correlations in queries and schemas that could enable better physical plans. Using our DBPlanBench harness for the DataFusion engine, we expose the physical plan through a compact serialized representation and let the LLM propose localized edits that can be applied and executed. We then apply an evolutionary search over these edits to refine candidates across iterations. Our key insight is that LLMs can leverage semantic knowledge to identify and apply non-obvious optimizations, such as join orderings that minimize intermediate cardinalities. We obtain up to 4.78$\times$ speedups on some queries and we demonstrate a small-to-large workflow in which optimizations found on small databases transfer effectively to larger databases.

</details>


### [2] [Benchmarking Large Language Models for Knowledge Graph Validation](https://arxiv.org/abs/2602.10748)
*Farzad Shami,Stefano Marchesin,Gianmaria Silvello*

Main category: cs.DB

TL;DR: FactCheck是一个评估大语言模型在知识图谱事实验证任务上性能的基准，涵盖内部知识、RAG外部证据和多模型共识三个维度，发现LLMs在真实场景中仍不够稳定可靠。


<details>
  <summary>Details</summary>
Motivation: 知识图谱的事实准确性对许多应用至关重要，但大规模手动验证不现实，现有自动化方法也不成熟。大语言模型具有语义理解和知识访问能力，但其在KG事实验证中的适用性和有效性尚未充分探索，需要系统评估。

Method: 提出FactCheck基准，从三个维度评估LLMs：1) 模型内部知识；2) 通过检索增强生成(RAG)的外部证据；3) 多模型共识策略的聚合知识。在三个真实KG上评估开源和商业LLMs，并提供包含200万+文档的RAG数据集和交互式分析平台。

Result: 实验表明：1) LLMs虽有潜力但不够稳定可靠，不适合真实KG验证场景；2) RAG方法性能波动，改进不一致且计算成本高；3) 多模型共识策略不总是优于单个模型，没有通用解决方案。

Conclusion: LLMs在KG事实验证中仍有局限性，需要FactCheck这样的基准来系统评估和推动该关键任务的发展。当前方法尚未找到稳定可靠的解决方案，强调了进一步研究的必要性。

Abstract: Knowledge Graphs (KGs) store structured factual knowledge by linking entities through relationships, crucial for many applications. These applications depend on the KG's factual accuracy, so verifying facts is essential, yet challenging. Expert manual verification is ideal but impractical on a large scale. Automated methods show promise but are not ready for real-world KGs. Large Language Models (LLMs) offer potential with their semantic understanding and knowledge access, yet their suitability and effectiveness for KG fact validation remain largely unexplored.
  In this paper, we introduce FactCheck, a benchmark designed to evaluate LLMs for KG fact validation across three key dimensions: (1) LLMs internal knowledge; (2) external evidence via Retrieval-Augmented Generation (RAG); and (3) aggregated knowledge employing a multi-model consensus strategy. We evaluated open-source and commercial LLMs on three diverse real-world KGs. FactCheck also includes a RAG dataset with 2+ million documents tailored for KG fact validation. Additionally, we offer an interactive exploration platform for analyzing verification decisions.
  The experimental analyses demonstrate that while LLMs yield promising results, they are still not sufficiently stable and reliable to be used in real-world KG validation scenarios. Integrating external evidence through RAG methods yields fluctuating performance, providing inconsistent improvements over more streamlined approaches -- at higher computational costs. Similarly, strategies based on multi-model consensus do not consistently outperform individual models, underscoring the lack of a one-fits-all solution. These findings further emphasize the need for a benchmark like FactCheck to systematically evaluate and drive progress on this difficult yet crucial task.

</details>


### [3] [GraphSeek: Next-Generation Graph Analytics with LLMs](https://arxiv.org/abs/2602.11052)
*Maciej Besta,Łukasz Jarmocik,Orest Hrycyna,Shachar Klaiman,Konrad Mączka,Robert Gerstenberger,Jürgen Müller,Piotr Nyczyk,Hubert Niewiadomski,Torsten Hoefler*

Main category: cs.DB

TL;DR: GraphSeek：首个LLM增强的图分析框架，通过语义目录规划实现自然语言到复杂属性图查询的高效转换，显著提升任务成功率和令牌效率


<details>
  <summary>Details</summary>
Motivation: 图数据在各领域应用广泛但使用门槛高，现有LLM无法有效处理工业级规模、高度异构、结构复杂且动态演化的属性图，需要新的解决方案来降低图分析的使用门槛

Method: 提出新颖的抽象层，通过语义目录描述图模式和操作，将LLM规划（语义平面）与确定性查询执行（执行平面）分离，避免直接从自然语言生成易错的图查询

Result: GraphSeek框架相比增强版LangChain实现显著更高的成功率（86%），在小上下文LLM下也能获得令牌效率和任务效果的双重提升

Conclusion: GraphSeek为下一代可负担、易访问的图分析指明了方向，通过统一LLM推理与数据库级执行，有效处理大规模复杂属性图

Abstract: Graphs are foundational across domains but remain hard to use without deep expertise. LLMs promise accessible natural language (NL) graph analytics, yet they fail to process industry-scale property graphs effectively and efficiently: such datasets are large, highly heterogeneous, structurally complex, and evolve dynamically. To address this, we devise a novel abstraction for complex multi-query analytics over such graphs. Its key idea is to replace brittle generation of graph queries directly from NL with planning over a Semantic Catalog that describes both the graph schema and the graph operations. Concretely, this induces a clean separation between a Semantic Plane for LLM planning and broader reasoning, and an Execution Plane for deterministic, database-grade query execution over the full dataset and tool implementations. This design yields substantial gains in both token efficiency and task effectiveness even with small-context LLMs. We use this abstraction as the basis of the first LLM-enhanced graph analytics framework called GraphSeek. GraphSeek achieves substantially higher success rates (e.g., 86% over enhanced LangChain) and points toward the next generation of affordable and accessible graph analytics that unify LLM reasoning with database-grade execution over large and complex property graphs.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [4] [From Prompt-Response to Goal-Directed Systems: The Evolution of Agentic AI Software Architecture](https://arxiv.org/abs/2602.10479)
*Mamdouh Alenezi*

Main category: cs.SE

TL;DR: 该论文探讨了Agentic AI从静态生成模型向自主目标导向系统的架构转变，提出了LLM智能体的参考架构、多智能体拓扑分类和企业级部署清单，分析了行业平台发展趋势。


<details>
  <summary>Details</summary>
Motivation: 研究Agentic AI从提示驱动的生成模型向具有自主感知、规划、行动和适应能力的智能系统的架构转变，连接传统智能体理论与现代LLM方法，为生产级部署提供框架。

Method: 通过分析行业平台（Kore.ai、Salesforce Agentforce、TrueFoundry、ZenML、LangChain），提出三方面贡献：1）基于类型化工具接口分离认知与执行的参考架构；2）多智能体拓扑分类及故障模式缓解方法；3）包含治理、可观测性和可复现性的企业级检查清单。

Result: 识别出行业向标准化智能体循环、注册表和可审计控制机制的趋同趋势，认为Agentic AI发展将类似Web服务的成熟过程，需要共享协议、类型化契约和分层治理结构。

Conclusion: Agentic AI正处于向可扩展、可组合自主系统发展的关键阶段，但可验证性、互操作性和安全自主性等挑战仍需未来研究和实际部署中解决。

Abstract: Agentic AI denotes an architectural transition from stateless, prompt-driven generative models toward goal-directed systems capable of autonomous perception, planning, action, and adaptation through iterative control loops. This paper examines this transition by connecting foundational intelligent agent theories, including reactive, deliberative, and Belief-Desire-Intention models, with contemporary LLM-centric approaches such as tool invocation, memory-augmented reasoning, and multi-agent coordination. The paper presents three primary contributions: (i) a reference architecture for production-grade LLM agents that separates cognitive reasoning from execution using typed tool interfaces; (ii) a taxonomy of multi-agent topologies, together with their associated failure modes and mitigation approaches; and (iii) an enterprise hardening checklist that incorporates governance, observability, and reproducibility considerations. Through an analysis of emerging industry platforms, including Kore.ai, Salesforce Agentforce, TrueFoundry, ZenML, and LangChain, the study identifies a convergence toward standardized agent loops, registries, and auditable control mechanisms. It is argued that the subsequent phase of agentic AI development will parallel the maturation of web services, relying on shared protocols, typed contracts, and layered governance structures to support scalable and composable autonomy. The persistent challenges related to verifiability, interoperability, and safe autonomy remain key areas for future research and practical deployment.

</details>


### [5] [Consistency Meets Verification: Enhancing Test Generation Quality in Large Language Models Without Ground-Truth Solutions](https://arxiv.org/abs/2602.10522)
*Hamed Taherkhani,Alireza DaghighFarsoodeh,Mohammad Chowdhury,Hung Viet Pham,Hadi Hemmati*

Main category: cs.SE

TL;DR: ConVerTest：无需真实代码即可生成可靠测试的两阶段管道，通过自一致性、验证链和双重执行协议提升测试有效性、覆盖率和变异分数


<details>
  <summary>Details</summary>
Motivation: 现有LLM测试生成方法依赖真实代码进行验证，存在bug传播风险，且在测试驱动开发中适用性有限，需要无需先验代码实现即可生成可靠测试的方法

Method: 两阶段管道：1）自一致性通过多数投票生成收敛测试用例；2）验证链进行迭代、推理引导的代码精炼；3）双重执行协议通过共识交叉验证代码和测试

Result: 在BIGCODEBENCH和LBPP基准测试中，ConVerTest将测试有效性、行覆盖率和变异分数分别提升高达39%、28%和18%，优于基线方法

Conclusion: ConVerTest是缓解幻觉、增强自主软件测试代理可靠性的稳健解决方案，为无需先验代码实现的可靠测试生成提供了有效方法

Abstract: Large Language Models (LLMs) have significantly advanced automated test generation, yet existing methods often rely on ground-truth code for verification, risking bug propagation and limiting applicability in test-driven development. We present ConVerTest, a novel two-stage pipeline for synthesizing reliable tests without requiring prior code implementations. ConVerTest integrates three core strategies: (i) Self-Consistency(SC) to generate convergent test cases via majority voting; (ii) Chain-of-Verification (CoVe) for iterative, reasoning-guided code refinement; and (iii) a Dual Execution Agreement to crossvalidate code and tests through consensus. Experiments on BIGCODEBENCH and LESS BASIC PYTHON PROBLEMS (LBPP) benchmarks demonstrate that ConVerTest improves test validity, line coverage, and mutation scores by up to 39%, 28%, and 18% respectively over baselines. Our findings highlight ConVerTest as a robust solution for mitigating hallucinations and enhancing the reliability of autonomous software testing agents.

</details>


### [6] [Theory of Troubleshooting: The Developer's Cognitive Experience of Overcoming Confusion](https://arxiv.org/abs/2602.10540)
*Arty Starr,Margaret-Anne Storey*

Main category: cs.SE

TL;DR: 本文基于认知科学提出了一个故障排除理论，解释软件开发者在排查问题时的认知挑战和项目风险，通过访谈27位专业开发者构建了该理论。


<details>
  <summary>Details</summary>
Motivation: 故障排除是软件开发中特别耗费精力的部分，对注意力、工作记忆和心理建模有持续需求，但缺乏从认知科学角度系统理解这一过程的理论框架。

Method: 采用建构主义扎根理论方法，访谈27位专业开发者关于他们的故障排除经验，基于实证数据构建理论框架。

Result: 提出了一个基于认知科学的故障排除理论，解释了故障排除如何消耗认知资源并导致认知疲劳，揭示了困惑体验的神经和注意力动态机制。

Conclusion: 该理论为理解故障排除的困难、疲劳和可持续性风险提供了认知基础，对开发者体验研究和工业实践都有实际意义。

Abstract: This paper introduces a Theory of Troubleshooting that is rooted in cognitive science. This theory helps software developers explain the challenges they face and the project risks that emerge as troubleshooting becomes difficult. We define troubleshooting as the cognitive problem-solving process of identifying, understanding, and constructing a mental model of the cause of an unexpected system behavior, and consider the cognitive process of troubleshooting to be an integral part of the activity of debugging. Troubleshooting is a particularly intense and draining aspect of software work, placing sustained demands on attention, working memory, and mental modeling. By surfacing and naming the confusion experience inherent in troubleshooting in terms of neurological and attentional dynamics, our theory explains how prolonged troubleshooting can deplete cognitive resources and lead to cognitive fatigue. In the study presented in this paper, we interview 27 professional developers about their troubleshooting experiences, and follow a Constructivist Grounded Theory approach to construct a theory grounded in empirical data. Our theory contributes to research on Developer Experience by providing a cognitive foundation for understanding troubleshooting difficulty, fatigue, and sustainability risk--and offers practical implications for both research and industry.

</details>


### [7] [ISD-Agent-Bench: A Comprehensive Benchmark for Evaluating LLM-based Instructional Design Agents](https://arxiv.org/abs/2602.10620)
*YoungHoon Jeon,Suwan Kim,Haein Son,Sookbun Lee,Yeil Jeong,Unggi Lee*

Main category: cs.SE

TL;DR: ISD-Agent-Bench：一个包含25,795个场景的基准测试，用于评估LLM在教学设计中的自动化能力，结合经典ISD理论与现代推理方法表现最佳


<details>
  <summary>Details</summary>
Motivation: 当前LLM代理在自动化教学设计方面有潜力，但缺乏标准化基准评估，且存在LLM作为评判者的偏见风险

Method: 通过上下文矩阵框架生成25,795个场景，结合51个上下文变量和33个ADDIE子步骤；采用多评判协议使用不同提供商的LLM确保可靠性；比较基于经典ISD理论（ADDIE、Dick & Carey、快速原型）的代理与现有方法

Result: 在1,017个测试场景中，结合经典ISD框架与现代ReAct推理的代理表现最佳，超越纯理论代理和纯技术方法；理论质量与基准表现强相关，理论代理在问题中心设计和目标评估对齐方面优势显著

Conclusion: 经典ISD理论与现代LLM推理的结合为自动化教学设计提供了最佳方案，ISD-Agent-Bench为系统化LLM-based ISD研究奠定了基础

Abstract: Large Language Model (LLM) agents have shown promising potential in automating Instructional Systems Design (ISD), a systematic approach to developing educational programs. However, evaluating these agents remains challenging due to the lack of standardized benchmarks and the risk of LLM-as-judge bias. We present ISD-Agent-Bench, a comprehensive benchmark comprising 25,795 scenarios generated via a Context Matrix framework that combines 51 contextual variables across 5 categories with 33 ISD sub-steps derived from the ADDIE model. To ensure evaluation reliability, we employ a multi-judge protocol using diverse LLMs from different providers, achieving high inter-judge reliability. We compare existing ISD agents with novel agents grounded in classical ISD theories such as ADDIE, Dick \& Carey, and Rapid Prototyping ISD. Experiments on 1,017 test scenarios demonstrate that integrating classical ISD frameworks with modern ReAct-style reasoning achieves the highest performance, outperforming both pure theory-based agents and technique-only approaches. Further analysis reveals that theoretical quality strongly correlates with benchmark performance, with theory-based agents showing significant advantages in problem-centered design and objective-assessment alignment. Our work provides a foundation for systematic LLM-based ISD research.

</details>


### [8] [Assessing Vision-Language Models for Perception in Autonomous Underwater Robotic Software](https://arxiv.org/abs/2602.10655)
*Muhammad Yousaf,Aitor Arrieta,Shaukat Ali,Paolo Arcaini,Shuai Wang*

Main category: cs.SE

TL;DR: 本文对视觉语言模型在水下机器人软件中的感知模块进行实证评估，分析其在检测水下垃圾时的性能、不确定性及其关系，为软件工程师选择合适模型提供依据。


<details>
  <summary>Details</summary>
Motivation: 水下机器人面临低能见度和恶劣环境条件，深度学习模型依赖稀缺且有噪声的标注数据，可能影响感知模块的可信度。视觉语言模型具有泛化到未见对象和在噪声条件下保持鲁棒性的潜力，但其在水下环境中的性能和不确定性尚未从软件工程角度得到充分研究。

Method: 对基于视觉语言模型的感知模块进行实证评估，通过计算性能、不确定性以及它们之间的关系，评估其检测水下垃圾的能力。

Result: 研究提供了视觉语言模型在水下环境中的性能、不确定性及其关系的评估结果，但具体数据未在摘要中给出。

Conclusion: 该研究为软件工程师选择适合水下机器人软件的视觉语言模型提供了实证依据，有助于评估感知模块在具有挑战性的水下环境中的可信度。

Abstract: Autonomous Underwater Robots (AURs) operate in challenging underwater environments, including low visibility and harsh water conditions. Such conditions present challenges for software engineers developing perception modules for the AUR software. To successfully carry out these tasks, deep learning has been incorporated into the AUR software to support its operations. However, the unique challenges of underwater environments pose difficulties for deep learning models, which often rely on labeled data that is scarce and noisy. This may undermine the trustworthiness of AUR software that relies on perception modules. Vision-Language Models (VLMs) offer promising solutions for AUR software as they generalize to unseen objects and remain robust in noisy conditions by inferring information from contextual cues. Despite this potential, their performance and uncertainty in underwater environments remain understudied from a software engineering perspective. Motivated by the needs of an industrial partner in assurance and risk management for maritime systems to assess the potential use of VLMs in this context, we present an empirical evaluation of VLM-based perception modules within the AUR software. We assess their ability to detect underwater trash by computing performance, uncertainty, and their relationship, to enable software engineers to select appropriate VLMs for their AUR software.

</details>


### [9] [Hidden Licensing Risks in the LLMware Ecosystem](https://arxiv.org/abs/2602.10758)
*Bo Wang,Yueyang Chen,Jieke Shi,Minghui Li,Yunbo Lyu,Yinan Wu,Youfang Lin,Zhou Yang*

Main category: cs.SE

TL;DR: 研究分析了LLMware（集成LLM的软件系统）中的许可证问题，构建了大规模数据集，发现许可证分布与传统OSS不同，现有检测方法效果有限，提出了基于LLM的代理框架LiAgent，显著提升了许可证兼容性检测性能。


<details>
  <summary>Details</summary>
Motivation: LLMware（集成大语言模型的软件系统）形成了跨越开源软件、模型和数据集的复杂供应链，但这些交织依赖关系中的许可证问题尚未得到充分研究，需要系统性分析其风险。

Method: 1. 从GitHub和Hugging Face收集大规模LLMware供应链数据集（12,180个OSS仓库、3,988个LLM、708个数据集）；2. 分析许可证分布特征；3. 研究许可证相关讨论；4. 评估现有检测方法；5. 提出基于LLM的代理框架LiAgent进行生态系统级许可证兼容性分析。

Result: 1. LLMware许可证分布与传统OSS生态系统显著不同；2. 许可证选择和维护是主要关注点（占84%）；3. 现有检测方法F1分数仅58%和76%；4. LiAgent框架达到87%的F1分数，提升14个百分点；5. 检测到60个不兼容问题，11个被开发者确认，其中两个冲突模型下载量分别超过1.07亿和500万次。

Conclusion: LLMware生态系统面临独特的许可证挑战，现有检测方法不足，提出的LiAgent框架能有效识别许可证冲突，有助于支持LLMware生态系统的可持续发展，需要制定相应建议和规范。

Abstract: Large Language Models (LLMs) are increasingly integrated into software systems, giving rise to a new class of systems referred to as LLMware. Beyond traditional source-code components, LLMware embeds or interacts with LLMs that depend on other models and datasets, forming complex supply chains across open-source software (OSS), models, and datasets. However, licensing issues emerging from these intertwined dependencies remain largely unexplored. Leveraging GitHub and Hugging Face, we curate a large-scale dataset capturing LLMware supply chains, including 12,180 OSS repositories, 3,988 LLMs, and 708 datasets. Our analysis reveals that license distributions in LLMware differ substantially from traditional OSS ecosystems. We further examine license-related discussions and find that license selection and maintenance are the dominant concerns, accounting for 84% of cases. To understand incompatibility risks, we analyze license conflicts along supply chains and evaluate state-of-the-art detection approaches, which achieve only 58% and 76% F1 scores in this setting. Motivated by these limitations, we propose LiAgent, an LLM-based agent framework for ecosystem-level license compatibility analysis. LiAgent achieves an F1 score of 87%, improving performance by 14 percentage points over prior methods. We reported 60 incompatibility issues detected by LiAgent, 11 of which have been confirmed by developers. Notably, two conflicted LLMs have over 107 million and 5 million downloads on Hugging Face, respectively, indicating potentially widespread downstream impact. We conclude with implications and recommendations to support the sustainable growth of the LLMware ecosystem.

</details>


### [10] [VulReaD: Knowledge-Graph-guided Software Vulnerability Reasoning and Detection](https://arxiv.org/abs/2602.10787)
*Samal Mukhtar,Yinghua Yao,Zhu Sun,Mustafa Mustafa,Yew Soon Ong,Youcheng Sun*

Main category: cs.SE

TL;DR: VulReaD：基于知识图谱指导的漏洞推理与检测方法，通过安全知识图谱和教师LLM生成CWE一致的对比推理监督，提升漏洞检测的准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 当前软件漏洞检测主要关注二元分类，缺乏与CWE类别的语义一致性解释。需要超越二元分类，实现CWE级别的推理和检测。

Method: 1. 使用安全知识图谱作为语义骨干；2. 利用强大的教师LLM生成CWE一致的对比推理监督；3. 通过ORPO优化学生模型，鼓励符合分类学的推理，抑制无支持的说明。

Result: 在三个真实数据集上，VulReaD相比最先进基线：二元F1提升8-10%，多类分类提升30%宏F1和18%微F1。LLM在二元检测中优于深度学习基线，KG指导的推理增强了CWE覆盖和可解释性。

Conclusion: VulReaD通过知识图谱引导的推理方法，显著提升了漏洞检测的准确性和CWE级别的解释能力，为软件漏洞检测提供了更有效的解决方案。

Abstract: Software vulnerability detection (SVD) is a critical challenge in modern systems. Large language models (LLMs) offer natural-language explanations alongside predictions, but most work focuses on binary evaluation, and explanations often lack semantic consistency with Common Weakness Enumeration (CWE) categories. We propose VulReaD, a knowledge-graph-guided approach for vulnerability reasoning and detection that moves beyond binary classification toward CWE-level reasoning. VulReaD leverages a security knowledge graph (KG) as a semantic backbone and uses a strong teacher LLM to generate CWE-consistent contrastive reasoning supervision, enabling student model training without manual annotations. Students are fine-tuned with Odds Ratio Preference Optimization (ORPO) to encourage taxonomy-aligned reasoning while suppressing unsupported explanations. Across three real-world datasets, VulReaD improves binary F1 by 8-10% and multi-class classification by 30% Macro-F1 and 18% Micro-F1 compared to state-of-the-art baselines. Results show that LLMs outperform deep learning baselines in binary detection and that KG-guided reasoning enhances CWE coverage and interpretability.

</details>


### [11] [PELLI: Framework to effectively integrate LLMs for quality software generation](https://arxiv.org/abs/2602.10808)
*Rasmus Krebs,Somnath Mazumdar*

Main category: cs.SE

TL;DR: 本文提出PELLI框架，通过迭代分析评估LLM生成的代码质量，重点关注可维护性、性能和可靠性三个非功能性需求，发现GPT-4T和Gemini表现略优，提示设计影响代码质量。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注可靠性指标且仅比较少数LLM（如Codex和ChatGPT），缺乏对代码质量的全面评估。需要建立系统框架来评估LLM生成的代码质量，促进LLM与人类开发者的有效协作。

Method: 提出PELLI（Programmatic Excellence via LLM Iteration）框架，基于迭代分析过程确保高质量代码变更。对5个流行LLM进行综合评估，生成三个非功能性需求（可维护性、性能、可靠性）的量化指标，在三个应用领域遵循Python编码标准进行测试。

Result: GPT-4T和Gemini在三个非功能性需求上表现略优；提示设计显著影响整体代码质量；不同应用领域在不同指标上表现有高有低，同一指标在不同提示下也有差异。

Conclusion: PELLI框架可作为开发者在遵循质量标准的同时利用LLM的实用指南，促进LLM技术在现实应用中的发展，帮助利益相关者了解LLM的优势和改进方向。

Abstract: Recent studies have revealed that when LLMs are appropriately prompted and configured, they demonstrate mixed results. Such results often meet or exceed the baseline performance. However, these comparisons have two primary issues. First, they mostly considered only reliability as a comparison metric and selected a few LLMs (such as Codex and ChatGPT) for comparision. This paper proposes a comprehensive code quality assessment framework called Programmatic Excellence via LLM Iteration (PELLI). PELLI is an iterative analysis-based process that upholds high-quality code changes. We extended the state-of-the-art by performing a comprehensive evaluation that generates quantitative metrics for analyzing three primary nonfunctional requirements (such as maintainability, performance, and reliability) while selecting five popular LLMs. For PELLI's applicability, we selected three application domains while following Python coding standards. Following this framework, practitioners can ensure harmonious integration between LLMs and human developers, ensuring that their potential is fully realized. PELLI can serve as a practical guide for developers aiming to leverage LLMs while adhering to recognized quality standards. This study's outcomes are crucial for advancing LLM technologies in real-world applications, providing stakeholders with a clear understanding of where these LLMs excel and where they require further refinement. Overall, based on three nonfunctional requirements, we have found that GPT-4T and Gemini performed slightly better. We also found that prompt design can influence the overall code quality. In addition, each application domain demonstrated high and low scores across various metrics, and even within the same metrics across different prompts.

</details>


### [12] [Deriving and Validating Requirements Engineering Principles for Large-Scale Agile Development: An Industrial Longitudinal Study](https://arxiv.org/abs/2602.10972)
*Hina Saeeda,Mijin Kim,Eric Knauss,Jesper Thyssen,Jesper Ørting,Jesper Lysemose Korsgaard,Niels Jørgen Strøm*

Main category: cs.SE

TL;DR: 通过5年纵向案例研究，为大规模敏捷组织提出6个可转移的需求工程原则，包括架构上下文、利益相关者驱动验证、轻量级文档演化等。


<details>
  <summary>Details</summary>
Motivation: 大规模敏捷系统开发中缺乏统一的需求工程流程和高级指导原则，导致需求管理困难，需要建立可扩展的实践基础。

Method: 采用5年纵向案例研究，收集超过25个冲刺、320次周会、7个跨公司研讨会的定性数据，通过主题分析得出原则，并由3家跨国公司专家验证。

Result: 识别出6个关键需求工程原则：架构上下文、利益相关者驱动验证与对齐、轻量级文档演化、委托需求管理、组织角色职责、需求共享理解。

Conclusion: 研究为大规模敏捷组织提供了可扩展、可适应的需求实践基础，经过多公司验证具有实际应用价值。

Abstract: In large scale agile systems development, the lack of a unified requirements engineering (RE) process is a major challenge, exacerbated by the absence of high level guiding principles for effective requirements management. To address this challenge, we conducted a five year longitudinal case study with Grundfos AB, in collaboration with the Software Centre in Sweden. RE principles were first derived through qualitative data collection spanning more than 25 sprints, approximately 320 weekly synchronisation meetings, and seven cross-company, company-specific workshops between 2019 and 2024. These activities engaged practitioners from diverse roles, representing several hundred developers across domains. In late 2024, five in depth focus groups with senior leaders at Grundfos provided retrospective validation of the principles and assessed their strategic impact. We aim to (1) empirically examine RE principles in large scale agile system development, (2) explore their benefits in practice within the case company, and (3) identify a set of transferable RE principles for large scale contexts. Using thematic analysis, six key RE principles architectural context, stakeholder-driven validation and alignment, requirements practices in large-scale agile organisations. evolution with lightweight documentation, delegated requirements management, organisational roles and responsibilities, and a shared understanding of requirements are derived. The study was further validated through crosscompany expert evaluation with three additional multinational organisations (Bosch, Ericsson, and Volvo Cars), which are directly responsible for largescale requirements management. Together, these efforts provide a scalable and adaptable foundation for improving requirements practices in largescale agile organisations.

</details>


### [13] [FeatureBench: Benchmarking Agentic Coding for Complex Feature Development](https://arxiv.org/abs/2602.10975)
*Qixing Zhou,Jiacheng Zhang,Haiyang Wang,Rui Hao,Jiahe Wang,Minghao Han,Yuxue Yang,Shuzhe Wu,Feiyang Pan,Lue Fan,Dandan Tu,Zhaoxiang Zhang*

Main category: cs.SE

TL;DR: FeatureBench是一个评估LLM代理在端到端、面向功能软件开发中编码能力的基准测试，通过自动化方法从代码仓库提取任务，并采用基于执行的评估协议。


<details>
  <summary>Details</summary>
Motivation: 现有代理编码基准测试任务范围有限（如单个PR内的bug修复），依赖非执行性评估，且缺乏自动更新评估覆盖的方法。需要评估LLM代理在真实软件开发场景中的能力边界。

Method: 提出可扩展的测试驱动方法，通过依赖图从单元测试自动识别功能级编码任务（跨多个提交和PR），构建可执行环境，确保功能分离后其他功能正常运行。

Result: 从24个开源仓库收集了200个挑战性评估任务和3825个可执行环境。Claude 4.5 Opus在SWE-bench上达到74.4%解决率，但在FeatureBench上仅成功11.0%，显示新挑战。

Conclusion: FeatureBench填补了代理编码评估的空白，提供自动扩展和更新的能力，其构建环境的可验证性对代理训练也有价值，为推进代理编码能力提供了新机会。

Abstract: Agents powered by large language models (LLMs) are increasingly adopted in the software industry, contributing code as collaborators or even autonomous developers. As their presence grows, it becomes important to assess the current boundaries of their coding abilities. Existing agentic coding benchmarks, however, cover a limited task scope, e.g., bug fixing within a single pull request (PR), and often rely on non-executable evaluations or lack an automated approach for continually updating the evaluation coverage. To address such issues, we propose FeatureBench, a benchmark designed to evaluate agentic coding performance in end-to-end, feature-oriented software development. FeatureBench incorporates an execution-based evaluation protocol and a scalable test-driven method that automatically derives tasks from code repositories with minimal human effort. By tracing from unit tests along a dependency graph, our approach can identify feature-level coding tasks spanning multiple commits and PRs scattered across the development timeline, while ensuring the proper functioning of other features after the separation. Using this framework, we curated 200 challenging evaluation tasks and 3825 executable environments from 24 open-source repositories in the first version of our benchmark. Empirical evaluation reveals that the state-of-the-art agentic model, such as Claude 4.5 Opus, which achieves a 74.4% resolved rate on SWE-bench, succeeds on only 11.0% of tasks, opening new opportunities for advancing agentic coding. Moreover, benefiting from our automated task collection toolkit, FeatureBench can be easily scaled and updated over time to mitigate data leakage. The inherent verifiability of constructed environments also makes our method potentially valuable for agent training.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [14] [KORAL: Knowledge Graph Guided LLM Reasoning for SSD Operational Analysis](https://arxiv.org/abs/2602.10246)
*Mayur Akewar,Sandeep Madireddy,Dongsheng Luo,Janki Bhimani*

Main category: cs.DC

TL;DR: KORAL是一个结合大型语言模型和知识图谱的推理框架，用于分析固态硬盘的性能和可靠性问题，能够从碎片化遥测数据生成可查询的知识图谱，提供专家级诊断和建议。


<details>
  <summary>Details</summary>
Motivation: 固态硬盘的性能和可靠性诊断困难，因为数据碎片化且时间不连续，现有方法需要大量数据集和专家输入，但只能提供有限见解。性能下降不仅来自工作负载变化和架构演进，还受温度、湿度、振动等环境因素影响。

Method: 提出KORAL框架，将大型语言模型与结构化知识图谱结合：1）从碎片化遥测数据生成数据知识图谱；2）整合文献知识图谱（包含文献、报告和跟踪记录中的知识）；3）两个图谱共同指导LLM生成基于证据、可解释的分析。

Result: 使用真实生产跟踪数据评估显示，KORAL能够提供专家级诊断和推荐，支持基于证据的解释，提高推理透明度，指导操作员决策，减少人工工作量，并提供可操作的见解来改善服务质量。

Conclusion: KORAL是首个结合LLM和KG进行全谱SSD推理（包括描述性、预测性、规范性分析和假设分析）的端到端系统。发布了SSD特定知识图谱以推进基于知识的存储系统分析的可重复研究。

Abstract: Solid State Drives (SSDs) are critical to datacenters, consumer platforms, and mission-critical systems. Yet diagnosing their performance and reliability is difficult because data are fragmented and time-disjoint, and existing methods demand large datasets and expert input while offering only limited insights. Degradation arises not only from shifting workloads and evolving architectures but also from environmental factors such as temperature, humidity, and vibration. We present KORAL, a knowledge driven reasoning framework that integrates Large Language Models (LLMs) with a structured Knowledge Graph (KG) to generate insights into SSD operations. Unlike traditional approaches that require extensive expert input and large datasets, KORAL generates a Data KG from fragmented telemetry and integrates a Literature KG that already organizes knowledge from literature, reports, and traces. This turns unstructured sources into a queryable graph and telemetry into structured knowledge, and both the Graphs guide the LLM to deliver evidence-based, explainable analysis aligned with the domain vocabulary and constraints. Evaluation using real production traces shows that the KORAL delivers expert-level diagnosis and recommendations, supported by grounded explanations that improve reasoning transparency, guide operator decisions, reduce manual effort, and provide actionable insights to improve service quality. To our knowledge, this is the first end-to-end system that combines LLMs and KGs for full-spectrum SSD reasoning including Descriptive, Predictive, Prescriptive, and What-if analysis. We release the generated SSD-specific KG to advance reproducible research in knowledge-based storage system analysis. GitHub Repository: https://github.com/Damrl-lab/KORAL

</details>


### [15] [Execution-Centric Characterization of FP8 Matrix Cores, Asynchronous Execution, and Structured Sparsity on AMD MI300A](https://arxiv.org/abs/2602.10262)
*Aaron Jarmusch,Connor Vitz,Sunita Chandrasekaran*

Main category: cs.DC

TL;DR: 对AMD MI300A APU中FP8矩阵运算、异步计算引擎并发和结构化稀疏性的执行特性进行微基准测试分析，为统一节点上的调度决策提供实用指导


<details>
  <summary>Details</summary>
Motivation: AMD MI300A APU集成了CDNA3 GPU、高带宽内存和先进加速器特性（FP8矩阵核心、异步计算引擎、2:4结构化稀疏性），这些特性被现代HPC和HPC-AI工作负载日益依赖，但其执行特性和系统级影响尚未被充分理解

Method: 使用针对性微基准测试对MI300A进行执行中心化表征，量化占用率阈值、公平性、并发执行下的吞吐量权衡以及上下文相关的稀疏性优势，并评估代表性案例研究（transformer风格、并发和混合精度内核）

Result: 提供了FP8矩阵执行、ACE并发和结构化稀疏性的详细执行特性分析，展示了这些效应如何转化为应用级性能和可预测性

Conclusion: 研究结果为MI300A类统一节点上的占用率感知调度、并发决策和稀疏性启用提供了实用指导

Abstract: The AMD MI300A APU integrates CDNA3 GPUs with high-bandwidth memory and advanced accelerator features: FP8 matrix cores, asynchronous compute engines (ACE), and 2:4 structured sparsity. These capabilities are increasingly relied upon by modern HPC and HPC-AI workloads, yet their execution characteristics and system-level implications remain insufficiently understood. In this paper, we present an execution-centric characterization of FP8 matrix execution, ACE concurrency, and structured sparsity on MI300A using targeted microbenchmarks. We quantify occupancy thresholds, fairness, throughput trade-offs under concurrent execution, and context-dependent sparsity benefits. We evaluate representative case studies - transformer-style, concurrent, and mixed-precision kernels - to show how these effects translate into application-level performance and predictability. Our results provide practical guidance for occupancy-aware scheduling, concurrency decisions, and sparsity enablement on MI300A-class unified nodes.

</details>


### [16] [Flash-SD-KDE: Accelerating SD-KDE with Tensor Cores](https://arxiv.org/abs/2602.10378)
*Elliot L. Epstein,Rajat Vadiraj Dwaraknath,John Winnicki*

Main category: cs.DC

TL;DR: Flash-SD-KDE通过重新组织计算结构利用Tensor Cores加速GPU实现，使基于得分的去偏核密度估计在之前不可行的规模上变得实用


<details>
  <summary>Details</summary>
Motivation: SD-KDE虽然比经典KDE有更好的渐近收敛速度，但由于使用经验得分函数，实际计算速度显著较慢，限制了其在大规模应用中的实用性

Method: 重新组织SD-KDE计算以暴露矩阵乘法结构，从而利用GPU的Tensor Cores进行加速，实现Flash-SD-KDE算法

Result: 在32k样本16维问题上，比强SD-KDE GPU基线快47倍，比scikit-learn的KDE快3300倍；在1M样本16维任务上，131k个查询仅需2.3秒

Conclusion: 通过GPU加速的Flash-SD-KDE使基于得分的去偏密度估计在之前不可行的规模上变得实用，显著提升了计算效率

Abstract: Score-debiased kernel density estimation (SD-KDE) achieves improved asymptotic convergence rates over classical KDE, but its use of an empirical score has made it significantly slower in practice. We show that by re-ordering the SD-KDE computation to expose matrix-multiplication structure, Tensor Cores can be used to accelerate the GPU implementation. On a 32k-sample 16-dimensional problem, our approach runs up to $47\times$ faster than a strong SD-KDE GPU baseline and $3{,}300\times$ faster than scikit-learn's KDE. On a larger 1M-sample 16-dimensional task evaluated on 131k queries, Flash-SD-KDE completes in $2.3$ s on a single GPU, making score-debiased density estimation practical at previously infeasible scales.

</details>


### [17] [Computing Least Fixed Points with Overwrite Semantics in Parallel and Distributed Systems](https://arxiv.org/abs/2602.10486)
*Vijay K. Garg,Rohan Garg*

Main category: cs.DC

TL;DR: 提出并行和分布式计算中多单调膨胀函数最小不动点的计算方法，证明三种同步条件下的收敛定理，适用于覆盖语义而非连接操作


<details>
  <summary>Details</summary>
Motivation: 经典Knaster-Tarski定理处理单函数顺序迭代，但现代计算系统需要并行执行、覆盖语义、非原子更新和过时读取，需要新的理论框架

Method: 使用坐标覆盖而非连接合并，在三种渐进放松的同步条件下证明收敛：(1)公平调度的交错语义，(2)仅当值变化时更新的并行执行，(3)有界过时和i-局部性的分布式执行

Result: 首次为基于覆盖的并行更新提供精确的最小不动点收敛保证，无需连接操作或收缩假设，适用于传递闭包、稳定婚姻、最短路径和公平分配等应用

Conclusion: 建立了覆盖语义下并行和分布式不动点计算的理论基础，为现代计算系统提供了新的收敛保证框架，区别于传统的连接合并和收缩方法

Abstract: We present methods to compute least fixed points of multiple monotone inflationary functions in parallel and distributed settings. While the classic Knaster-Tarski theorem addresses a single function with sequential iteration, modern computing systems require parallel execution with overwrite semantics, non-atomic updates, and stale reads. We prove three convergence theorems under progressively relaxed synchronization: (1) Interleaving semantics with fair scheduling, (2) Parallel execution with update-only-on-change semantics (processes write only on those coordinates whose values change), and (3) Distributed execution with bounded staleness (updates propagate within $T$ rounds) and $i$-locality (each process modifies only its own component).
  Our approach differs from prior work in fundamental ways: Cousot-Cousot's chaotic iteration uses join-based merges that preserve information. Instead, we use coordinate-wise overwriting. Bertsekas's asynchronous methods assume contractions. We use coordinate-wise overwriting with structural constraints (locality, bounded staleness) instead. Applications include parallel and distributed algorithms for the transitive closure, stable marriage, shortest paths, and fair division with subsidy problems. Our results provide the first exact least-fixed-point convergence guarantees for overwrite-based parallel updates without join operations or contraction assumptions.

</details>


### [18] [BOute: Cost-Efficient LLM Serving with Heterogeneous LLMs and GPUs via Multi-Objective Bayesian Optimization](https://arxiv.org/abs/2602.10729)
*Youhe Jiang,Fangcheng Fu,Eiko Yoneki*

Main category: cs.DC

TL;DR: BOute是一个质量感知调度系统，通过联合优化异构模型路由和GPU部署策略，实现成本高效的LLM服务。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型部署快速增长，需要成本高效的服务系统。现有方法分别从算法角度（异构查询路由）和系统角度（异构GPU部署）优化，但缺乏算法-系统协同设计来最大化整体性能。

Method: 采用多目标贝叶斯优化框架，联合优化路由策略和模型部署配置，在保证响应质量的前提下最大化系统成本效率。

Result: 在相同成本预算和质量要求下，BOute比现有最优LLM服务系统性能提升最高157%，平均59%；或在保持相同性能目标下降低服务成本15%-61%（平均38%）。

Conclusion: BOute通过算法-系统协同设计有效解决了成本高效LLM服务中的复杂管理问题，验证了联合优化异构模型和GPU能力的重要性。

Abstract: The rapid growth of large language model (LLM) deployments has made cost-efficient serving systems essential. Recent efforts to enhance system cost-efficiency adopt two main perspectives: (i) An algorithmic perspective that exploits heterogeneous model capabilities to route simpler queries to lower-cost models and complex queries to higher-cost models (i.e., heterogeneous query routing); and (ii) a systems perspective that utilizes heterogeneous GPU resources as cost-effective alternatives to homogeneous high-end GPUs (i.e., heterogeneous model deployment). However, algorithm-system co-design for cost-efficient LLM serving necessitates sophisticated management: (i) Determining optimal query routing strategies under latency and quality requirements, (ii) configuring model deployment across heterogeneous GPUs with appropriate resource allocation and parallelism strategies, and (iii) co-optimizing routing and deployment decisions to maximize overall system performance. To address these challenges, we present BOute, a quality-aware scheduling system that jointly exploits heterogeneous model and GPU capabilities for cost-efficient LLM serving. BOute employs a multi-objective Bayesian optimization (MOBO) framework to co-optimize the routing strategy and model deployment, thereby maximizing the cost-efficiency of the serving system while guaranteeing response quality. Evaluation results demonstrate that BOute outperforms state-of-the-art LLM serving systems by up to 157% and 59% on average under identical cost budgets and quality requirements, or reducing serving costs by 15%-61% (38% on average) while maintaining the same performance targets, validating its effectiveness in achieving cost-efficient LLM serving.

</details>


### [19] [Fine-Tuning GPT-5 for GPU Kernel Generation](https://arxiv.org/abs/2602.11000)
*Ali Tehrani,Yahya Emara,Essam Wissam,Wojciech Paluch,Waleed Atallah,Łukasz Dudziak,Mohamed S. Abdelfattah*

Main category: cs.DC

TL;DR: 本文提出Makora环境与工具，通过强化学习微调前沿模型GPT-5用于Triton GPU代码生成，显著提升内核正确性和性能，超越传统监督学习方法。


<details>
  <summary>Details</summary>
Motivation: GPU内核开发对AI系统扩展至关重要，但面临硬件架构复杂和优化专业知识需求高的挑战。虽然LLM在通用代码生成方面表现良好，但在GPU代码生成中面临高质量标注数据稀缺、编译器偏见和硬件代际泛化有限等问题，使得监督微调方法不可扩展。

Method: 提出Makora环境和工具集，采用强化学习方法微调前沿模型GPT-5，专注于Triton GPU代码生成。该方法避免了监督学习对大量标注数据的依赖，通过精心选择训练问题和构建鲁棒评估环境来优化模型。

Result: 单次尝试设置中，微调模型将内核正确率从43.7%提升至77.0%（+33.3个百分点），超越TorchInductor的问题比例从14.8%提升至21.8%（+7个百分点）。在完整编码代理中，能解决扩展KernelBench套件中97.4%的问题，在72.9%的问题上超越PyTorch TorchInductor编译器，几何平均加速比达2.12倍。

Conclusion: 针对性的强化学习后训练能够解锁LLM在高度专业化技术领域的能力，为传统监督学习受数据可用性限制的场景开辟了新途径，推动了AI辅助加速器编程的发展。

Abstract: Developing efficient GPU kernels is essential for scaling modern AI systems, yet it remains a complex task due to intricate hardware architectures and the need for specialized optimization expertise. Although Large Language Models (LLMs) demonstrate strong capabilities in general sequential code generation, they face significant challenges in GPU code generation because of the scarcity of high-quality labeled training data, compiler biases when generating synthetic solutions, and limited generalization across hardware generations. This precludes supervised fine-tuning (SFT) as a scalable methodology for improving current LLMs. In contrast, reinforcement learning (RL) offers a data-efficient and adaptive alternative but requires access to relevant tools, careful selection of training problems, and a robust evaluation environment. We present Makora's environment and tools for reinforcement learning finetuning of frontier models and report our results from fine-tuning GPT-5 for Triton code generation. In the single-attempt setting, our fine-tuned model improves kernel correctness from 43.7% to 77.0% (+33.3 percentage points) and increases the fraction of problems outperforming TorchInductor from 14.8% to 21.8% (+7 percentage points) compared to baseline GPT-5, while exceeding prior state-of-the-art models on KernelBench. When integrated into a full coding agent, it is able to solve up to 97.4% of problems in an expanded KernelBench suite, outperforming the PyTorch TorchInductor compiler on 72.9% of problems with a geometric mean speedup of 2.12x. Our work demonstrates that targeted post-training with reinforcement learning can unlock LLM capabilities in highly specialized technical domains where traditional supervised learning is limited by data availability, opening new pathways for AI-assisted accelerator programming.

</details>


### [20] [Min-Sum Uniform Coverage Problem by Autonomous Mobile Robots](https://arxiv.org/abs/2602.11125)
*Animesh Maiti,Abhinav Chakraborty,Bibhuti Das,Subhash Bhagat,Krishnendu Mukhopadhyaya*

Main category: cs.DC

TL;DR: 研究移动机器人在线段和圆上的最小总移动距离均匀覆盖问题，提出确定性分布式算法实现最优成本覆盖


<details>
  <summary>Details</summary>
Motivation: 研究在有限线段和圆上，一群移动机器人如何协调运动以达到均匀间隔配置，同时最小化所有机器人移动的总距离。机器人具有自主性、匿名性、相同性、同质性，在非刚性运动控制的公平异步调度器下运行，且无持久记忆和显式通信能力。

Method: 在线段设置中，提出确定性分布式算法实现均匀覆盖并最小化总移动距离。在圆设置中，首先刻画所有确定性不可解初始配置，然后为其余配置提供确定性分布式算法实现均匀覆盖并最小化总移动距离。

Result: 在线段设置中，算法实现了最小总移动成本的均匀覆盖。在圆设置中，刻画了确定性不可解配置，并为可解配置提供了实现最小总移动距离的算法。

Conclusion: 这些结果刻画了无记忆机器人最小和覆盖问题的确定性可解性，并在可解时实现了最优成本，为移动机器人的均匀覆盖问题提供了完整的理论解决方案。

Abstract: We study the \textit{min-sum uniform coverage} problem for a swarm of $n$ mobile robots on a given finite line segment and on a circle having finite positive radius, where the circle is given as an input. The robots must coordinate their movements to reach a uniformly spaced configuration that minimizes the total distance traveled by all robots. The robots are autonomous, anonymous, identical, and homogeneous, and operate under the \textit{Look-Compute-Move} (LCM) model with \textit{non-rigid} motion controlled by a fair asynchronous scheduler. They are oblivious and silent, possessing neither persistent memory nor a means of explicit communication. In the \textbf{line-segment setting}, the \textit{min-sum uniform coverage} problem requires placing the robots at uniformly spaced points along the segment so as to minimize the total distance traveled by all robots. In the \textbf{circle setting} for this problem, the robots have to arrange themselves uniformly around the given circle to form a regular $n$-gon. There is no fixed orientation or designated starting vertex, and the goal is to minimize the total distance traveled by all the robots. We present a deterministic distributed algorithm that achieves uniform coverage in the line-segment setting with minimum total movement cost. For the circle setting, we characterize all initial configurations for which the \textit{min-sum uniform coverage} problem is deterministically unsolvable under the considered robot model. For all the other remaining configurations, we provide a deterministic distributed algorithm that achieves uniform coverage while minimizing the total distance traveled. These results characterize the deterministic solvability of min-sum coverage for oblivious robots and achieve optimal cost whenever solvable.

</details>
