<div id=toc></div>

# Table of Contents

- [cs.DB](#cs.DB) [Total: 2]
- [cs.DC](#cs.DC) [Total: 11]
- [cs.SE](#cs.SE) [Total: 11]


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [1] [PANDAExpress: a Simpler and Faster PANDA Algorithm](https://arxiv.org/abs/2512.10217)
*Mahmoud Abo Khamis,Hung Q. Ngo,Dan Suciu*

Main category: cs.DB

TL;DR: PANDAExpress改进PANDA算法，通过新的概率不等式和动态超平面分割方案，消除了polylog(N)因子，在保持通用性的同时达到与专用算法相当的运行时间。


<details>
  <summary>Details</summary>
Motivation: PANDA算法虽然通用强大，但存在较大的polylog(N)因子，使其在实际应用中不实用，无法达到专用算法的性能。本文旨在解决这一弱点。

Method: 1. 提出新的概率不等式来上界DDRs在任意度约束下的输出大小；2. 基于该证明开发PANDAExpress算法，使用动态构建的任意超平面分割（而非PANDA的轴平行超平面），根据数据偏斜统计进行自适应划分。

Result: PANDAExpress消除了PANDA中的polylog(N)因子，在保持处理任意度约束、自由变量、CQs和DDRs等通用性的同时，达到了与复杂专用算法相当的运行时间。

Conclusion: PANDAExpress解决了PANDA的主要性能弱点，在保持算法通用性和强大功能的同时，实现了与最优专用算法相当的性能，使通用查询处理框架变得实用。

Abstract: PANDA is a powerful generic algorithm for answering conjunctive queries (CQs) and disjunctive datalog rules (DDRs) given input degree constraints. In the special case where degree constraints are cardinality constraints and the query is Boolean, PANDA runs in $\tilde O (N^{subw})$-time, where $N$ is the input size, and $subw$ is the submodular width of the query, a notion introduced by Daniel Marx (JACM 2013). When specialized to certain classes of sub-graph pattern finding problems, the $\tilde O(N^{subw})$ runtime matches the optimal runtime possible, modulo some conjectures in fine-grained complexity (Bringmann and Gorbachev (STOC 25)). The PANDA framework is much more general, as it handles arbitrary input degree constraints, which capture common statistics and integrity constraints used in relational database management systems, it works for queries with free variables, and for both CQs and DDRs.
  The key weakness of PANDA is the large $polylog(N)$-factor hidden in the $\tilde O(\cdot)$ notation. This makes PANDA completely impractical, and fall short of what is achievable with specialized algorithms. This paper resolves this weakness with two novel ideas. First, we prove a new probabilistic inequality that upper-bounds the output size of DDRs under arbitrary degree constraints. Second, the proof of this inequality directly leads to a new algorithm named PANDAExpress that is both simpler and faster than PANDA. The novel feature of PANDAExpress is a new partitioning scheme that uses arbitrary hyperplane cuts instead of axis-parallel hyperplanes used in PANDA. These hyperplanes are dynamically constructed based on data-skewness statistics carefully tracked throughout the algorithm's execution. As a result, PANDAExpress removes the $polylog(N)$-factor from the runtime of PANDA, matching the runtimes of intricate specialized algorithms, while retaining all its generality and power.

</details>


### [2] [Efficient Hypergraph Pattern Matching via Match-and-Filter and Intersection Constraint](https://arxiv.org/abs/2512.10621)
*Siwoo Song,Wonseok Shin,Kunsoo Park,Giuseppe F. Italiano,Zhengyi Yang,Wenjie Zhang*

Main category: cs.DB

TL;DR: 提出了一种新的超图模式匹配算法，通过引入交集约束、候选超边空间和匹配-过滤框架，显著提升了查询处理性能。


<details>
  <summary>Details</summary>
Motivation: 超图能够建模涉及多个顶点的复杂关系，超图模式匹配是寻找查询超图在数据超图中所有同构嵌入的基本问题。现有算法在处理复杂超图模式匹配时效率不足，需要更高效的解决方案。

Method: 1. 引入交集约束作为有效嵌入的必要充分条件，加速验证过程；2. 设计候选超边空间数据结构存储查询超边与数据超边之间的潜在映射；3. 提出匹配-过滤框架，在回溯过程中交替进行匹配和过滤操作，仅保留兼容的候选映射。

Result: 在真实世界数据集上的实验结果表明，该算法在查询处理时间方面显著优于现有最先进算法，性能提升可达数量级。

Conclusion: 提出的超图模式匹配算法通过创新的约束条件、数据结构和框架设计，实现了高效的超图模式匹配，为处理复杂关系数据提供了有效的解决方案。

Abstract: A hypergraph is a generalization of a graph, in which a hyperedge can connect multiple vertices, modeling complex relationships involving multiple vertices simultaneously. Hypergraph pattern matching, which is to find all isomorphic embeddings of a query hypergraph in a data hypergraph, is one of the fundamental problems. In this paper, we present a novel algorithm for hypergraph pattern matching by introducing (1) the intersection constraint, a necessary and sufficient condition for valid embeddings, which significantly speeds up the verification process, (2) the candidate hyperedge space, a data structure that stores potential mappings between hyperedges in the query hypergraph and the data hypergraph, and (3) the Match-and-Filter framework, which interleaves matching and filtering operations to maintain only compatible candidates in the candidate hyperedge space during backtracking. Experimental results on real-world datasets demonstrate that our algorithm significantly outperforms the state-of-the-art algorithms, by up to orders of magnitude in terms of query processing time.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [3] [A study of the spectrum resource leasing method based on ERC4907 extension](https://arxiv.org/abs/2512.09942)
*Zhiming Liang,Bin Chen,Litao Ye,Chen Sun,Shuo Wang,Zhe Peng*

Main category: cs.DC

TL;DR: M-ERC4907扩展了ERC4907标准，支持多时间段批量配置和多用户同时授权，解决了单用户单时间段授权的限制，显著降低了链上交易和Gas消耗。


<details>
  <summary>Details</summary>
Motivation: ERC4907标准虽然支持可租赁NFT，但仅限于单用户、单时间段授权，这在去中心化多时间段调度场景中严重限制了其适用性和效率。

Method: 提出M-ERC4907扩展方法，引入支持多时间段批量配置和多用户同时授权的新功能，消除ERC4907的严格顺序授权约束。

Result: 在Remix开发平台上的实验结果显示，M-ERC4907方法显著减少了链上交易和总体Gas消耗，提升了可扩展性和资源分配效率。

Conclusion: M-ERC4907扩展方法有效解决了ERC4907在多时间段调度场景中的限制，通过批量配置和并行授权机制提高了NFT租赁系统的效率和可扩展性。

Abstract: The ERC4907 standard enables rentable Non-Fungible Tokens (NFTs) but is limited to single-user, single-time-slot authorization, which severely limits its applicability and efficiency in decentralized multi-slot scheduling scenarios. To address this limitation, this paper proposes Multi-slot ERC4907 (M-ERC4907) extension method. The M-ERC4907 method introduces novel functionalities to support the batch configuration of multiple time slots and simultaneous authorization of multiple users, thereby effectively eliminating the rigid sequential authorization constraint of ERC4907. The experiment was conducted on the Remix development platform. Experimental results show that the M-ERC4907 method significantly reduces on-chain transactions and overall Gas consumption, leading to enhanced scalability and resource allocation efficiency.

</details>


### [4] [ELANA: A Simple Energy and Latency Analyzer for LLMs](https://arxiv.org/abs/2512.09946)
*Hung-Yueh Chiang,Bokun Wang,Diana Marculescu*

Main category: cs.DC

TL;DR: ELANA是一个开源的轻量级LLM性能分析工具，用于评估模型大小、KV缓存、延迟和能耗，支持Hugging Face所有公开模型，适用于多GPU和边缘GPU平台。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在从移动边缘设备到云GPU集群的各种硬件平台上的延迟和功耗是主要约束，需要基准测试工具来优化模型部署效率和下一代模型开发。

Method: 开发了一个轻量级、学术友好的性能分析工具ELANA，支持分析模型大小、KV缓存大小、预填充延迟(TTFT)、生成延迟(TPOT)、端到端延迟(TTLT)，支持Hugging Face所有公开模型，提供命令行界面和可选的能耗日志记录。

Result: 开源了ELANA分析工具，支持多GPU和边缘GPU平台，完全兼容Hugging Face API，可轻松定制或适配压缩或低比特模型，适合高效LLM研究或小规模概念验证。

Conclusion: ELANA是一个简单实用的LLM性能分析工具，有助于优化模型部署效率和促进高效LLM研究，特别适合学术研究和小规模概念验证。

Abstract: The latency and power consumption of large language models (LLMs) are major constraints when serving them across a wide spectrum of hardware platforms, from mobile edge devices to cloud GPU clusters. Benchmarking is crucial for optimizing efficiency in both model deployment and next-generation model development. To address this need, we open-source a simple profiling tool, \textbf{ELANA}, for evaluating LLMs. ELANA is designed as a lightweight, academic-friendly profiler for analyzing model size, key-value (KV) cache size, prefilling latency (Time-to-first-token, TTFT), generation latency (Time-per-output-token, TPOT), and end-to-end latency (Time-to-last-token, TTLT) of LLMs on both multi-GPU and edge GPU platforms. It supports all publicly available models on Hugging Face and offers a simple command-line interface, along with optional energy consumption logging. Moreover, ELANA is fully compatible with popular Hugging Face APIs and can be easily customized or adapted to compressed or low bit-width models, making it ideal for research on efficient LLMs or for small-scale proof-of-concept studies. We release the ELANA profiling tool at: https://github.com/enyac-group/Elana.

</details>


### [5] [CloudFix: Automated Policy Repair for Cloud Access Control Policies Using Large Language Models](https://arxiv.org/abs/2512.09957)
*Bethel Hall,Owen Ungaro,William Eiers*

Main category: cs.DC

TL;DR: CloudFix：首个结合形式化方法与LLM的云访问控制策略自动修复框架，通过故障定位和LLM生成修复方案，显著提升策略修复准确率。


<details>
  <summary>Details</summary>
Motivation: 云访问控制策略的手动编写和更新容易出错且耗时，可能导致安全漏洞。现有符号分析方法在云环境下的泛化能力有限，而LLM在访问控制策略修复方面的应用尚未探索。

Method: CloudFix结合形式化方法与LLM：首先使用基于形式化方法的故障定位识别策略中的错误语句，然后利用LLM生成潜在修复方案，最后通过SMT求解器验证修复的正确性。

Result: 在包含282个真实AWS访问控制策略的数据集上测试，CloudFix在不同请求规模下均优于基线实现，显著提高了修复准确率。

Conclusion: CloudFix是首个利用LLM进行策略修复的框架，展示了LLM在访问控制领域的有效性，实现了云访问控制策略的高效自动化修复。

Abstract: Access control policies are vital for securing modern cloud computing, where organizations must manage access to sensitive data across thousands of users in distributed system settings. Cloud administrators typically write and update policies manually, which can be an error-prone and time-consuming process and can potentially lead to security vulnerabilities. Existing approaches based on symbolic analysis have demon- strated success in automated debugging and repairing access control policies; however, their generalizability is limited in the context of cloud-based access control. Conversely, Large Language Models (LLMs) have been utilized for automated program repair; however, their applicability to repairing cloud access control policies remains unexplored. In this work, we introduce CloudFix, the first automated policy repair framework for cloud access control that combines formal methods with LLMs. Given an access control policy and a specification of allowed and denied access requests, CloudFix employs Formal Methods-based Fault Localization to identify faulty statements in the policy and leverages LLMs to generate potential repairs, which are then verified using SMT solvers. To evaluate CloudFix, we curated a dataset of 282 real-world AWS access control policies extracted from forum posts and augmented them with synthetically generated request sets based on real scenarios. Our experimental results show that CloudFix improves repair accuracy over a Baseline implementation across varying request sizes. Our work is the first to leverage LLMs for policy repair, showcasing the effectiveness of LLMs for access control and enabling efficient and automated repair of cloud access control policies. We make our tool Cloudfix and AWS dataset publicly available.

</details>


### [6] [TDC-Cache: A Trustworthy Decentralized Cooperative Caching Framework for Web3.0](https://arxiv.org/abs/2512.09961)
*Jinyu Chen,Long Shi,Taotao Wang,Jiaheng Wang,Wei Zhang*

Main category: cs.DC

TL;DR: 提出TDC-Cache框架，结合DRL-DC和PoCL共识，解决Web3.0去中心化缓存中的效率和安全问题


<details>
  <summary>Details</summary>
Motivation: Web3.0从中心化转向去中心化结构，赋予用户数据自主权，但面临冗余数据复制导致的效率问题和数据不一致带来的安全漏洞

Method: 开发TDC-Cache两层架构：DON层作为可信中介平台；提出DRL-DC基于深度强化学习动态优化分布式预言机缓存策略；开发PoCL共识机制维护缓存决策一致性

Result: 相比现有方法，平均访问延迟降低20%，缓存命中率最高提升18%，平均共识成功率提高10%

Conclusion: 本文首次探索Web3.0去中心化缓存框架和策略，TDC-Cache能有效提升缓存效率并增强系统对抗性威胁的韧性

Abstract: The rapid growth of Web3.0 is transforming the Internet from a centralized structure to decentralized, which empowers users with unprecedented self-sovereignty over their own data. However, in the context of decentralized data access within Web3.0, it is imperative to cope with efficiency concerns caused by the replication of redundant data, as well as security vulnerabilities caused by data inconsistency. To address these challenges, we develop a Trustworthy Decentralized Cooperative Caching (TDC-Cache) framework for Web3.0 to ensure efficient caching and enhance system resilience against adversarial threats. This framework features a two-layer architecture, wherein the Decentralized Oracle Network (DON) layer serves as a trusted intermediary platform for decentralized caching, bridging the contents from decentralized storage and the content requests from users. In light of the complexity of Web3.0 network topologies and data flows, we propose a Deep Reinforcement Learning-Based Decentralized Caching (DRL-DC) for TDC-Cache to dynamically optimize caching strategies of distributed oracles. Furthermore, we develop a Proof of Cooperative Learning (PoCL) consensus to maintain the consistency of decentralized caching decisions within DON. Experimental results show that, compared with existing approaches, the proposed framework reduces average access latency by 20%, increases the cache hit rate by at most 18%, and improves the average success consensus rate by 10%. Overall, this paper serves as a first foray into the investigation of decentralized caching framework and strategy for Web3.0.

</details>


### [7] [GoodSpeed: Optimizing Fair Goodput with Adaptive Speculative Decoding in Distributed Edge Inference](https://arxiv.org/abs/2512.09963)
*Phuong Tran,Tzu-Hao Liu,Long Tan Le,Tung-Anh Nguyen,Van Quan La,Eason Yu,Han Shu,Choong Seon Hong,Nguyen H. Tran*

Main category: cs.DC

TL;DR: GOODSPEED是一个分布式推理框架，通过自适应推测解码优化LLM推理的好吞吐量，在异构草稿服务器间实现比例公平的资源分配。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型的高计算需求给实时推理带来挑战，特别是在多用户服务器推测解码和资源受限环境中。现有推测解码技术难以同时保证高好吞吐量（有效接受令牌率）和在多个草稿服务器间的公平性。

Method: GOODSPEED采用中心验证服务器协调一组异构草稿服务器的架构。草稿服务器运行小型语言模型生成推测令牌，验证服务器并行处理所有草稿服务器的输出。框架包含梯度调度算法，动态分配令牌验证任务，通过最大化对数效用函数确保服务器间的比例公平。

Result: 通过严格的流体样本路径分析，GOODSPEED在稳态条件下收敛到最优好吞吐量分配，在动态工作负载下保持接近最优性能且有界误差。该框架为分布式LLM推理系统提供了可扩展、公平且高效的解决方案。

Conclusion: GOODSPEED通过自适应推测解码和公平资源分配，解决了多服务器环境中LLM推理的好吞吐量和公平性挑战，为分布式推理系统提供了有效的优化框架。

Abstract: Large language models (LLMs) have revolutionized natural language processing, yet their high computational demands pose significant challenges for real-time inference, especially in multi-user server speculative decoding and resource-constrained environments. Speculative decoding has emerged as a promising technique to accelerate LLM inference by using lightweight draft models to generate candidate tokens, which are subsequently verified by a larger, more accurate model. However, ensuring both high goodput (the effective rate of accepted tokens) and fairness across multiple draft servers cooperating with a central verification server remains an open challenge. This paper introduces GOODSPEED, a novel distributed inference framework that optimizes goodput through adaptive speculative decoding. GOODSPEED employs a central verification server that coordinates a set of heterogeneous draft servers, each running a small language model to generate speculative tokens. To manage resource allocation effectively, GOODSPEED incorporates a gradient scheduling algorithm that dynamically assigns token verification tasks, maximizing a logarithmic utility function to ensure proportional fairness across servers. By processing speculative outputs from all draft servers in parallel, the framework enables efficient collaboration between the verification server and distributed draft generators, streamlining both latency and throughput. Through rigorous fluid sample path analysis, we show that GOODSPEED converges to the optimal goodput allocation in steady-state conditions and maintains near-optimal performance with provably bounded error under dynamic workloads. These results demonstrate that GOODSPEED provides a scalable, fair and efficient solution for multi- in distributed LLM inference systems.

</details>


### [8] [Design Space Exploration of DMA based Finer-Grain Compute Communication Overlap](https://arxiv.org/abs/2512.10236)
*Shagnik Pal,Shaizeen Aga,Suchita Pati,Mahzabeen Islam,Lizy K. John*

Main category: cs.DC

TL;DR: FiCCO提出细粒度计算-通信重叠技术，通过比分片级更深一层的重叠，为更广泛的网络拓扑和细粒度数据流解锁重叠机会，并通过GPU DMA卸载通信减少争用，实现最高1.6倍加速。


<details>
  <summary>Details</summary>
Motivation: 当前分布式ML训练和推理中，分片并行技术普遍存在数据依赖的通信-计算操作，通信暴露导致性能损失高达理想性能的1.7倍。现有工作主要在分片级别进行粗粒度重叠，但存在局限性。

Method: 提出FiCCO（细粒度计算-通信重叠）技术：1）分析ML操作分解导致的效率损失；2）设计FiCCO调度方案的设计空间；3）将调度方案与相应的效率特征叠加；4）设计启发式方法为不同ML操作选择定制调度；5）使用GPU DMA引擎卸载通信以减少争用。

Result: 在真实ML部署场景中评估，提出的定制调度方案实现最高1.6倍加速，启发式方法在81%的未见场景中提供准确指导。

Conclusion: FiCCO通过细粒度重叠扩展了执行调度的设计空间，结合效率损失分析和GPU DMA卸载，能够为不同ML操作选择最优调度方案，显著提升分布式ML系统的性能。

Abstract: As both ML training and inference are increasingly distributed, parallelization techniques that shard (divide) ML model across GPUs of a distributed system, are often deployed. With such techniques, there is a high prevalence of data-dependent communication and computation operations where communication is exposed, leaving as high as 1.7x ideal performance on the table. Prior works harness the fact that ML model state and inputs are already sharded, and employ careful overlap of individual computation/communication shards. While such coarse-grain overlap is promising, in this work, we instead make a case for finer-grain compute-communication overlap which we term FiCCO, where we argue for finer-granularity, one-level deeper overlap than at shard-level, to unlock compute/communication overlap for a wider set of network topologies, finer-grain dataflow and more. We show that FiCCO opens up a wider design space of execution schedules than possible at shard-level alone. At the same time, decomposition of ML operations into smaller operations (done in both shard-based and finer-grain techniques) causes operation-level inefficiency losses. To balance the two, we first present a detailed characterization of these inefficiency losses, then present a design space of FiCCO schedules, and finally overlay the schedules with concomitant inefficiency signatures. Doing so helps us design heuristics that frameworks and runtimes can harness to select bespoke FiCCO schedules based on the nature of underlying ML operations. Finally, to further minimize contention inefficiencies inherent with operation overlap, we offload communication to GPU DMA engines. We evaluate several scenarios from realistic ML deployments and demonstrate that our proposed bespoke schedules deliver up to 1.6x speedup and our heuristics provide accurate guidance in 81% of unseen scenarios.

</details>


### [9] [Hybrid Learning and Optimization-Based Dynamic Scheduling for DL Workloads on Heterogeneous GPU Clusters](https://arxiv.org/abs/2512.10271)
*Shruti Dongare,Redwan Ibne Seraj Khan,Hadeel Albahar,Nannan Zhao,Diego Melendez Maita,Ali R. Butt*

Main category: cs.DC

TL;DR: RLTune是一个基于强化学习的深度学习作业调度框架，能在异构GPU集群上动态优化作业优先级和资源分配，无需作业级分析即可提升系统性能。


<details>
  <summary>Details</summary>
Motivation: 现代云平台承载大规模深度学习工作负载，但GPU集群异构性增强和应用特性不透明给现有调度器带来挑战。传统方法依赖离线分析或应用特定假设，难以适应动态环境。

Method: RLTune结合强化学习驱动的优先级排序和基于混合整数线性规划（MILP）的作业到节点映射。RL组件动态确定作业优先级，MILP优化资源分配，共同优化系统目标如作业完成时间、排队延迟和资源利用率。

Result: 基于微软Philly、Helios和阿里巴巴的大规模生产轨迹训练，RLTune将GPU利用率提升高达20%，排队延迟降低高达81%，作业完成时间缩短高达70%。

Conclusion: RLTune无需作业级分析即可跨多样化工作负载泛化，为云提供商提供了可大规模部署的高效、公平、可持续的深度学习工作负载管理解决方案。

Abstract: Modern cloud platforms increasingly host large-scale deep learning (DL) workloads, demanding high-throughput, low-latency GPU scheduling. However, the growing heterogeneity of GPU clusters and limited visibility into application characteristics pose major challenges for existing schedulers, which often rely on offline profiling or application-specific assumptions. We present RLTune, an application-agnostic reinforcement learning (RL)-based scheduling framework that dynamically prioritizes and allocates DL jobs on heterogeneous GPU clusters. RLTune integrates RL-driven prioritization with MILP-based job-to-node mapping to optimize system-wide objectives such as job completion time (JCT), queueing delay, and resource utilization. Trained on large-scale production traces from Microsoft Philly, Helios, and Alibaba, RLTune improves GPU utilization by up to 20%, reduces queueing delay by up to 81%, and shortens JCT by as much as 70 percent. Unlike prior approaches, RLTune generalizes across diverse workloads without requiring per-job profiling, making it practical for cloud providers to deploy at scale for more efficient, fair, and sustainable DL workload management.

</details>


### [10] [High-Dimensional Data Processing: Benchmarking Machine Learning and Deep Learning Architectures in Local and Distributed Environments](https://arxiv.org/abs/2512.10312)
*Julian Rodriguez,Piotr Lopez,Emiliano Lerma,Rafael Medrano,Jacobo Hernandez*

Main category: cs.DC

TL;DR: 该文档报告了大数据课程中实施的实践和方法序列，包括Epsilon数据集处理、文本分析分类、电影特征分析以及Apache Spark分布式集群的技术实现。


<details>
  <summary>Details</summary>
Motivation: 该文档旨在记录大数据课程中的实践流程和方法论，展示从数据处理到分布式计算集群搭建的完整学习路径，为大数据技术应用提供实际案例参考。

Method: 采用分阶段方法：1) 通过小组和个人策略处理Epsilon数据集；2) 使用RestMex进行文本分析和分类；3) 使用IMDb进行电影特征分析；4) 在Linux系统上使用Scala语言实现Apache Spark分布式计算集群。

Result: 文档详细记录了完整的大数据处理工作流程，包括数据集处理、文本分析、电影特征分析的技术实现，以及分布式计算集群的成功搭建和配置。

Conclusion: 该课程实践展示了大数据处理的全流程方法，从基础数据处理到高级分布式计算，为大数据技术学习和应用提供了系统的实践框架和实现方案。

Abstract: This document reports the sequence of practices and methodologies implemented during the Big Data course. It details the workflow beginning with the processing of the Epsilon dataset through group and individual strategies, followed by text analysis and classification with RestMex and movie feature analysis with IMDb. Finally, it describes the technical implementation of a distributed computing cluster with Apache Spark on Linux using Scala.

</details>


### [11] [Making Wide Stripes Practical: Cascaded Parity LRCs for Efficient Repair and High Reliability](https://arxiv.org/abs/2512.10425)
*Fan Yu,Guodong Li,Si Wu,Weijun Fang,Sihuang Hu*

Main category: cs.DC

TL;DR: 提出CP-LRCs（级联奇偶校验LRCs），通过在局部奇偶校验块之间嵌入结构化依赖关系，解决宽条带LRCs中修复成本高和可靠性下降的问题。


<details>
  <summary>Details</summary>
Motivation: 宽条带纠删码在大型存储系统中被广泛采用以降低存储开销，但现有的局部可修复码（LRCs）存在结构限制：扩大的局部组增加单节点修复成本，多节点故障频繁触发昂贵的全局修复，可靠性急剧下降。根本原因是局部和全局奇偶校验块独立设计，无法在修复过程中协同工作。

Method: 提出级联奇偶校验LRCs（CP-LRCs），通过在所有局部奇偶校验块上分解全局奇偶校验块，在奇偶校验块之间嵌入结构化依赖关系，形成级联奇偶校验组。提供通用的系数生成框架，开发利用级联特性的修复算法，并实例化为CP-Azure和CP-Uniform两种实现。

Result: 在阿里云上的评估显示，CP-LRCs相比现有方法，单节点故障修复时间减少高达41%，双节点故障修复时间减少26%。同时保持了MDS级别的容错能力。

Conclusion: CP-LRCs通过奇偶校验块之间的结构化依赖关系，解决了宽条带LRCs的关键限制，实现了低带宽的单节点和多节点修复，同时保持高可靠性，为大规模存储系统提供了有效的解决方案。

Abstract: Erasure coding with wide stripes is increasingly adopted to reduce storage overhead in large-scale storage systems. However, existing Locally Repairable Codes (LRCs) exhibit structural limitations in this setting: inflated local groups increase single-node repair cost, multi-node failures frequently trigger expensive global repair, and reliability degrades sharply. We identify a key root cause: local and global parity blocks are designed independently, preventing them from cooperating during repair. We present Cascaded Parity LRCs (CP-LRCs), a new family of wide stripe LRCs that embed structured dependency between parity blocks by decomposing a global parity block across all local parity blocks. This creates a cascaded parity group that preserves MDS-level fault tolerance while enabling low-bandwidth single-node and multi-node repairs. We provide a general coefficient-generation framework, develop repair algorithms exploiting cascading, and instantiate the design with CP-Azure and CP-Uniform. Evaluations on Alibaba Cloud show reductions in repair time of up to 41% for single-node failures and 26% for two-node failures.

</details>


### [12] [Clustered Federated Learning with Hierarchical Knowledge Distillation](https://arxiv.org/abs/2512.10443)
*Sabtain Ahmad,Meerzhan Kanatbekova,Ivona Brandic,Atakan Aral*

Main category: cs.DC

TL;DR: CFLHKD：一种基于层次聚类联邦学习和知识蒸馏的新型个性化方案，通过双层聚合和集群间知识共享，提升异构IoT环境下的模型性能


<details>
  <summary>Details</summary>
Motivation: 传统聚类联邦学习存在碎片化学习问题，每个集群独立训练全局模型，无法利用集群间的集体洞察。需要一种既能保持集群个性化，又能促进集群间知识共享的方法。

Method: 提出CFLHKD方案，采用层次聚类联邦学习框架，通过双层聚合（边缘集群特定模型和云端统一全局模型）和多教师知识蒸馏技术，实现集群间知识共享同时保持集群个性化。

Result: 在标准基准数据集上的广泛评估表明，CFLHKD在集群特定模型和全局模型准确率上均优于代表性基线方法，性能提升达到3.32-7.57%。

Conclusion: CFLHKD通过层次聚类联邦学习和知识蒸馏，有效解决了传统CFL的碎片化学习问题，实现了集群间知识共享与个性化的平衡，显著提升了模型性能。

Abstract: Clustered Federated Learning (CFL) has emerged as a powerful approach for addressing data heterogeneity and ensuring privacy in large distributed IoT environments. By clustering clients and training cluster-specific models, CFL enables personalized models tailored to groups of heterogeneous clients. However, conventional CFL approaches suffer from fragmented learning for training independent global models for each cluster and fail to take advantage of collective cluster insights. This paper advocates a shift to hierarchical CFL, allowing bi-level aggregation to train cluster-specific models at the edge and a unified global model at the cloud. This shift improves training efficiency yet might introduce communication challenges. To this end, we propose CFLHKD, a novel personalization scheme for integrating hierarchical cluster knowledge into CFL. Built upon multi-teacher knowledge distillation, CFLHKD enables inter-cluster knowledge sharing while preserving cluster-specific personalization. CFLHKD adopts a bi-level aggregation to bridge the gap between local and global learning. Extensive evaluations of standard benchmark datasets demonstrate that CFLHKD outperforms representative baselines in cluster-specific and global model accuracy and achieves a performance improvement of 3.32-7.57\%.

</details>


### [13] [ESS: An Offload-Centric Latent-Cache Management Architecture for DeepSeek-V3.2-Exp](https://arxiv.org/abs/2512.10576)
*Xinhang Chen,Chao Zhang,Jiahuan He,Wei Liu,Jianming Zhang,Wenlong Zhou,Xiao Li,Pai Zeng,Shiyong Li,Yuanpan Qian,Dong Li,Zhaogeng Li*

Main category: cs.DC

TL;DR: ESS系统通过将Latent-Cache卸载到CPU内存，解决了DeepSeek-V3.2-Exp在长上下文推理中的GPU内存瓶颈，显著提升了解码阶段吞吐量。


<details>
  <summary>Details</summary>
Motivation: DeepSeek-V3.2-Exp虽然通过稀疏注意力机制降低了长上下文推理延迟，但解码阶段的PD解耦仍然是主要瓶颈。瓶颈源于Latent-Cache随序列长度线性增长与GPU内存容量有限的冲突，这限制了批处理大小并抑制了解码阶段吞吐量。

Method: 提出ESS（Extended Sparse Server）系统，采用卸载为中心的设计，选择性地将Latent-Cache卸载到CPU内存，同时将延迟关键组件保留在GPU上。通过释放GPU内存，ESS使批处理大小扩展与GPU内存约束解耦。

Result: 高保真模拟显示，ESS在32K上下文长度下提供69.4%的吞吐量提升，在128K上下文长度下提供高达123%的吞吐量提升，证明了其对大上下文推理工作负载的有效性。

Conclusion: ESS是长上下文LLM服务的实用且可扩展的解决方案，通过优化内存管理显著提升解码阶段吞吐量，降低实际部署成本。

Abstract: DeepSeek-V3.2-Exp introduces a sparse attention mechanism that significantly reduces inference latency in long-context scenarios. Although the overall throughput has improved greatly, the Decode-stage of PD disaggregation remains to be a major bottleneck. This bottleneck primarily stems from the conflict between linear growth of Latent-Cache with sequence length and the limited GPU memory capacity, which constrains the feasible batch-size and thereby suppresses Decode-stage throughput.
  To address this challenge, we propose ESS (Extended Sparse Server), an offload-centric system design tailored for DeepSeek-V3.2-Exp. ESS selectively offloads Latent-Cache to CPU memory while preserving latency-critical components on GPU. By freeing up GPU memory, ESS effectively decoupling batch-size scaling from GPU memory constraints. This design significantly improves Decode-stage throughput, thereby reducing deployment costs in real-world settings.
  Our high-fidelity simulations show that ESS delivers 69.4\% throughput improvement at 32K context length and up to 123\% throughput improvement at 128K, demonstrating its effectiveness for large-context inference workloads. These results highlight ESS as a practical and scalable solution for long-context LLM serving.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [14] [Search-based Software Testing Driven by Domain Knowledge: Reflections and New Perspectives](https://arxiv.org/abs/2512.10079)
*Federico Formica,Mark Lawford,Claudio Menghi*

Main category: cs.SE

TL;DR: 本文回顾了基于搜索的软件测试（SBST）中集成领域知识的最新实验结果，突出展示了大胆且意外的发现，为未来研究提供新视角。


<details>
  <summary>Details</summary>
Motivation: SBST能自动生成测试用例，但缺乏工程师的领域知识。虽然已有技术尝试将领域知识集成到SBST框架中，但需要重新审视这些方法的有效性，基于最新实验结果探索新的研究方向。

Method: 通过回顾和分析最近关于SBST中集成领域知识的实验结果，重点关注那些大胆且意外的发现，对现有技术进行批判性反思。

Result: 论文突出了SBST集成领域知识实验中的意外结果，这些发现挑战了传统认知，为重新评估现有方法提供了实证基础。

Conclusion: 需要从新视角重新审视领域知识驱动的SBST技术，基于实验发现提出新的研究方向，推动该领域进一步发展。

Abstract: Search-based Software Testing (SBST) can automatically generate test cases to search for requirements violations. Unlike manual test case development, it can generate a substantial number of test cases in a limited time. However, SBST does not possess the domain knowledge of engineers. Several techniques have been proposed to integrate engineers' domain knowledge within existing SBST frameworks. This paper will reflect on recent experimental results by highlighting bold and unexpected results. It will help re-examine SBST techniques driven by domain knowledge from a new perspective, suggesting new directions for future research.

</details>


### [15] [ATLAS: Automated Toolkit for Large-Scale Verified Code Synthesis](https://arxiv.org/abs/2512.10173)
*Mantas Baksys,Stefan Zetzsche,Olivier Bouissou,Remi Delmas,Soonho Kong*

Main category: cs.SE

TL;DR: ATLAS通过自动生成带验证的Dafny程序解决LLM程序验证训练数据稀缺问题，显著提升模型性能


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在程序验证方面有潜力，但缺乏已验证代码的训练数据阻碍了进展。需要解决数据瓶颈问题。

Method: ATLAS是一个自动化流水线，能够大规模合成已验证的Dafny程序，包括规范、实现和证明。通过将合成过程分解为多个专门任务，从每个验证程序中提取多个训练示例。

Result: 生成了2.7K个已验证程序，提取了超过19K个训练示例（平均每个程序超过7个）。在Qwen 2.5 7B Coder上微调后，在DafnyBench上提升23个百分点，在DafnySynthesis上提升50个百分点。

Conclusion: 合成的已验证代码能有效增强LLM的形式验证能力，为解决程序验证训练数据稀缺问题提供了有效途径。

Abstract: Large language models have shown potential for program verification, but progress is hindered by the scarcity of verified code for training. We present ATLAS, an automated pipeline that synthesizes verified programs at scale to address this data bottleneck. ATLAS generates complete Dafny programs with specifications, implementations, and proofs, producing 2.7K verified programs from which we extract over 19K training examples--more than 7 per verified program--by decomposing the synthesis process into multiple specialized tasks. Fine-tuning Qwen 2.5 7B Coder on this dataset produces substantial gains: +23 percentage points on DafnyBench and +50 percentage points on DafnySynthesis. These results demonstrate that synthetic verified code can effectively enhance LLM capabilities for formal verification.

</details>


### [16] [Does SWE-Bench-Verified Test Agent Ability or Model Memory?](https://arxiv.org/abs/2512.10218)
*Thanosan Prathifkumar,Noble Saji Mathews,Meiyappan Nagappan*

Main category: cs.SE

TL;DR: 研究发现SWE-Bench-Verified基准测试可能因训练数据污染导致模型表现虚高，不能真实反映解决实际软件问题的能力


<details>
  <summary>Details</summary>
Motivation: SWE-Bench-Verified作为评估LLMs解决GitHub问题的基准测试，可能存在训练数据污染问题，导致分数反映的是训练记忆而非实际解决问题的能力

Method: 测试两个在基准测试中表现优异的Claude模型，让它们仅凭问题文本定位相关文件，然后加上文件路径信息，并在BeetleBox和SWE-rebench上进行相同测试

Result: 模型在SWE-Bench-Verified上的表现比在其他基准上好3倍，定位编辑文件的能力强6倍，表明模型可能在训练中见过这些任务，基准分数不能反映真实能力

Conclusion: 依赖旧基准测试存在风险，应转向考虑数据污染问题的新数据集，避免误导性评估和选择偏向特定模型而非优秀代理设计

Abstract: SWE-Bench-Verified, a dataset comprising 500 issues, serves as a de facto benchmark for evaluating various large language models (LLMs) on their ability to resolve GitHub issues. But this benchmark may overlap with model training data. If that is true, scores may reflect training recall, not issue-solving skill. To study this, we test two Claude models that frequently appear in top-performing agents submitted to the benchmark. We ask them to find relevant files using only issue text, and then issue text plus file paths. We then run the same setup on BeetleBox and SWE-rebench. Despite both benchmarks involving popular open-source Python projects, models performed 3 times better on SWE-Bench-Verified. They were also 6 times better at finding edited files, without any additional context about the projects themselves. This gap suggests the models may have seen many SWE-Bench-Verified tasks during training. As a result, scores on this benchmark may not reflect an agent's ability to handle real software issues, yet it continues to be used in ways that can misrepresent progress and lead to choices that favour agents that use certain models over strong agent design. Our setup tests the localization step with minimal context to the extent that the task should be logically impossible to solve. Our results show the risk of relying on older popular benchmarks and support the shift toward newer datasets built with contamination in mind.

</details>


### [17] [Studying and Automating Issue Resolution for Software Quality](https://arxiv.org/abs/2512.10238)
*Antu Saha*

Main category: cs.SE

TL;DR: 该研究通过三个方向提升软件问题解决效率：1) 利用LLM增强问题报告质量；2) 实证分析传统与AI辅助开发工作流；3) 自动化问题定位和解决方案识别任务。


<details>
  <summary>Details</summary>
Motivation: 软件开发中问题解决面临三大挑战：低质量问题报告、对实际工作流理解有限、缺乏自动化支持。这些问题影响了软件质量和维护效率。

Method: 采用三管齐下的方法：1) 利用LLM推理和应用特定信息提升问题报告质量；2) 实证分析传统和AI增强系统中的开发者工作流；3) 结合ML、DL和LLM技术自动化问题定位和解决方案识别。

Result: 研究提供了实证洞察、实用工具和自动化方法，能够支持更可维护和高质量的软件系统，推进AI驱动的问题解决能力。

Conclusion: 通过综合方法提升问题报告质量、理解开发工作流并自动化认知密集型任务，该研究为AI驱动的软件问题解决提供了系统性解决方案，有助于构建更高质量的软件系统。

Abstract: Effective issue resolution is crucial for maintaining software quality. Yet developers frequently encounter challenges such as low-quality issue reports, limited understanding of real-world workflows, and a lack of automated support. This research aims to address these challenges through three complementary directions. First, we enhance issue report quality by proposing techniques that leverage LLM reasoning and application-specific information. Second, we empirically characterize developer workflows in both traditional and AI-augmented systems. Third, we automate cognitively demanding resolution tasks, including buggy UI localization and solution identification, through ML, DL, and LLM-based approaches. Together, our work delivers empirical insights, practical tools, and automated methods to advance AI-driven issue resolution, supporting more maintainable and high-quality software systems.

</details>


### [18] [Cross-modal Retrieval Models for Stripped Binary Analysis](https://arxiv.org/abs/2512.10393)
*Guoqiang Chen,Lingyun Ying,Ziyang Song,Daguang Liu,Qiang Wang,Zhiqi Wang,Li Hu,Shaoyin Cheng,Weiming Zhang,Nenghai Yu*

Main category: cs.SE

TL;DR: BinSeek：首个用于剥离二进制代码分析的两阶段跨模态检索框架，通过嵌入模型和重排序模型实现二进制代码与自然语言描述的高效匹配


<details>
  <summary>Details</summary>
Motivation: 现有LLM代理在二进制代码分析中面临挑战：从数千个剥离符号信息的二进制函数中检索相关代码非常困难，这不同于源代码检索，因为缺乏符号信息

Method: 提出两阶段检索框架：1) BinSeekEmbedding在大规模数据集上训练，学习二进制代码与自然语言描述的语义相关性；2) BinSeek-Reranker通过上下文增强仔细判断候选代码与描述的相关性。使用LLM数据合成管道自动化训练数据构建

Result: BinSeek实现了最先进的性能，在Rec@3指标上超越同规模模型31.42%，在MRR@3上超越27.17%，甚至领先参数规模大16倍的先进通用模型

Conclusion: BinSeek是首个专门针对剥离二进制代码分析的两阶段跨模态检索框架，通过创新的数据合成和模型设计，显著提升了二进制代码检索的准确性和效率，为未来研究提供了基准

Abstract: LLM-agent based binary code analysis has demonstrated significant potential across a wide range of software security scenarios, including vulnerability detection, malware analysis, etc. In agent workflow, however, retrieving the positive from thousands of stripped binary functions based on user query remains under-studied and challenging, as the absence of symbolic information distinguishes it from source code retrieval. In this paper, we introduce, BinSeek, the first two-stage cross-modal retrieval framework for stripped binary code analysis. It consists of two models: BinSeekEmbedding is trained on large-scale dataset to learn the semantic relevance of the binary code and the natural language description, furthermore, BinSeek-Reranker learns to carefully judge the relevance of the candidate code to the description with context augmentation. To this end, we built an LLM-based data synthesis pipeline to automate training construction, also deriving a domain benchmark for future research. Our evaluation results show that BinSeek achieved the state-of-the-art performance, surpassing the the same scale models by 31.42% in Rec@3 and 27.17% in MRR@3, as well as leading the advanced general-purpose models that have 16 times larger parameters.

</details>


### [19] [How to Trick Your AI TA: A Systematic Study of Academic Jailbreaking in LLM Code Evaluation](https://arxiv.org/abs/2512.10415)
*Devanshu Sahoo,Vasudev Majhi,Arjun Neekhra,Yash Sinha,Murari Mandal,Dhruv Kumar*

Main category: cs.SE

TL;DR: 首次大规模研究学术环境中LLM代码评估器的越狱攻击，提出学术越狱概念，创建25K对抗性提交数据集，评估6个LLM的脆弱性


<details>
  <summary>Details</summary>
Motivation: LLM作为代码自动评估器在学术环境中日益普及，但学生可能使用对抗性提示策略诱导误判以获取不正当学术优势，需要研究其可靠性和安全性

Method: 系统性地将20多种越狱策略适配到学术代码评估场景，创建包含25K对抗性提交的数据集，定义三个越狱指标（越狱成功率、分数膨胀、危害性），在6个LLM上进行全面评估

Result: 发现这些模型存在显著脆弱性，特别是对说服性和角色扮演类攻击（越狱成功率高达97%），为下一代鲁棒的LLM学术代码评估器奠定基础

Conclusion: 学术越狱攻击对LLM代码评估器构成严重威胁，需要开发更鲁棒的评估系统，提出的数据集和基准套件为未来研究提供了重要基础

Abstract: The use of Large Language Models (LLMs) as automatic judges for code evaluation is becoming increasingly prevalent in academic environments. But their reliability can be compromised by students who may employ adversarial prompting strategies in order to induce misgrading and secure undeserved academic advantages. In this paper, we present the first large-scale study of jailbreaking LLM-based automated code evaluators in academic context. Our contributions are: (i) We systematically adapt 20+ jailbreaking strategies for jailbreaking AI code evaluators in the academic context, defining a new class of attacks termed academic jailbreaking. (ii) We release a poisoned dataset of 25K adversarial student submissions, specifically designed for the academic code-evaluation setting, sourced from diverse real-world coursework and paired with rubrics and human-graded references, and (iii) In order to capture the multidimensional impact of academic jailbreaking, we systematically adapt and define three jailbreaking metrics (Jailbreak Success Rate, Score Inflation, and Harmfulness). (iv) We comprehensively evalulate the academic jailbreaking attacks using six LLMs. We find that these models exhibit significant vulnerability, particularly to persuasive and role-play-based attacks (up to 97% JSR). Our adversarial dataset and benchmark suite lay the groundwork for next-generation robust LLM-based evaluators in academic code assessment.

</details>


### [20] [UniCoR: Modality Collaboration for Robust Cross-Language Hybrid Code Retrieval](https://arxiv.org/abs/2512.10452)
*Yang Yang,Li Kuang,Jiakun Liu,Zhongxin Liu,Yingjie Xia,David Lo*

Main category: cs.SE

TL;DR: UniCoR：一种自监督的统一代码表示学习框架，通过多视角对比学习和分布一致性学习，解决混合查询代码检索中的语义理解不足、模态融合低效和跨语言泛化弱的问题。


<details>
  <summary>Details</summary>
Motivation: 现有代码检索方法在混合查询（自然语言+代码片段）和跨语言场景中存在三个主要挑战：1）语义理解不足；2）混合检索中的模态融合低效；3）跨语言场景泛化能力弱。需要一种能有效利用混合查询并具备跨语言泛化能力的代码表示学习方法。

Method: 提出UniCoR自监督框架：1）多视角监督对比学习模块，从代码-代码、自然语言-代码、自然语言-自然语言多个视角对齐表示，增强语义理解和模态融合；2）表示分布一致性学习模块，显式对齐不同编程语言的特征分布，实现语言无关的表示学习。

Result: 在经验基准和大规模基准上的实验表明，UniCoR优于所有基线模型，MRR平均提升8.64%，MAP平均提升11.54%。在混合代码检索中表现稳定，在跨语言场景中具备良好的泛化能力。

Conclusion: UniCoR通过统一的自监督学习框架，有效解决了混合查询代码检索中的关键挑战，在语义理解、模态融合和跨语言泛化方面取得了显著改进，为代码检索提供了更鲁棒的解决方案。

Abstract: Effective code retrieval is indispensable and it has become an important paradigm to search code in hybrid mode using both natural language and code snippets. Nevertheless, it remains unclear whether existing approaches can effectively leverage such hybrid queries, particularly in cross-language contexts. We conduct a comprehensive empirical study of representative code models and reveal three challenges: (1) insufficient semantic understanding; (2) inefficient fusion in hybrid code retrieval; and (3) weak generalization in cross-language scenarios. To address these challenges, we propose UniCoR, a novel self-supervised framework that learns Unified Code Representations framework designed to learn unified and robust code representations. Firstly, we design a multi-perspective supervised contrastive learning module to enhance semantic understanding and modality fusion. It aligns representations from multiple perspectives, including code-to-code, natural language-to-code, and natural language-to-natural language, enforcing the model to capture a semantic essence among modalities. Secondly, we introduce a representation distribution consistency learning module to improve cross-language generalization, which explicitly aligns the feature distributions of different programming languages, enabling language-agnostic representation learning. Extensive experiments on both empirical benchmark and large-scale benchmark show that UniCoR outperforms all baseline models, achieving an average improvement of 8.64% in MRR and 11.54% in MAP over the best-performing baseline. Furthermore, UniCoR exhibits stability in hybrid code retrieval and generalization capability in cross-language scenarios.

</details>


### [21] [Decoding Human-LLM Collaboration in Coding: An Empirical Study of Multi-Turn Conversations in the Wild](https://arxiv.org/abs/2512.10493)
*Binquan Zhang,Li Zhang,Haoyuan Zhang,Fang Liu,Song Wang,Bo Shen,An Fu,Lin Shi*

Main category: cs.SE

TL;DR: 该论文通过分析LMSYS-Chat-1M和WildChat数据集，实证研究了人类与LLM在编程协作中的交互机制、指令遵循能力和用户满意度，发现任务类型影响交互模式，bug修复和代码重构对LLM更具挑战性，不同任务类型用户满意度差异显著。


<details>
  <summary>Details</summary>
Motivation: 虽然已有LMSYS-Chat-1M和WildChat等数据集记录真实用户-LLM对话，但很少有研究系统探索编程场景中人类-LLM协作机制。用户在实际交互中经历了怎样的曲折路径？LLM遵循指令的能力如何？用户满意度如何？这些问题尚未得到充分研究。

Method: 使用LMSYS-Chat-1M和WildChat数据集进行实证分析，探索人类-LLM协作机制、LLM指令遵循能力和人类满意度。通过分析多轮对话数据，识别不同编程任务类型下的交互模式。

Result: 1) 任务类型塑造交互模式：代码质量优化偏好线性模式，设计驱动任务倾向树状结构，查询任务偏好星型模式；2) Bug修复和代码重构对LLM指令遵循更具挑战性，不遵循率显著高于信息查询；3) 代码质量优化和需求驱动开发任务用户满意度较低，而结构化知识查询和算法设计满意度较高。

Conclusion: 研究结果为改进LLM界面和提升编程协作中的用户满意度提供了建议，同时为自适应对话系统的未来研究指明了方向。这项工作拓宽了对人类-LLM协同作用的理解，支持更有效的AI辅助开发。

Abstract: Large language models (LLMs) are increasingly acting as dynamic conversational interfaces, supporting multi-turn interactions that mimic human-like conversation and facilitate complex tasks like coding. While datasets such as LMSYS-Chat-1M and WildChat capture real-world user-LLM conversations, few studies systematically explore the mechanisms of human-LLM collaboration in coding scenarios. What tortuous paths do users experience during the interaction process? How well do the LLMs follow instructions? Are users satisfied? In this paper, we conduct an empirical analysis on human-LLM coding collaboration using LMSYS-Chat-1M and WildChat datasets to explore the human-LLM collaboration mechanism, LLMs' instruction following ability, and human satisfaction. This study yields interesting findings: 1) Task types shape interaction patterns(linear, star and tree), with code quality optimization favoring linear patterns, design-driven tasks leaning toward tree structures, and queries preferring star patterns; 2) Bug fixing and code refactoring pose greater challenges to LLMs' instruction following, with non-compliance rates notably higher than in information querying; 3) Code quality optimization and requirements-driven development tasks show lower user satisfaction, whereas structured knowledge queries and algorithm designs yield higher levels. These insights offer recommendations for improving LLM interfaces and user satisfaction in coding collaborations, while highlighting avenues for future research on adaptive dialogue systems. We believe this work broadens understanding of human-LLM synergies and supports more effective AI-assisted development.

</details>


### [22] [Analyzing developer discussions on EU and US privacy legislation compliance in GitHub repositories](https://arxiv.org/abs/2512.10618)
*Georgia M. Kapitsaki,Maria Papoutsoglou,Christoph Treude,Ioanna Theophilou*

Main category: cs.SE

TL;DR: 分析GitHub上32,820个开源软件issue，研究开发者如何讨论隐私法规（GDPR/CCPA）合规问题，构建包含6个集群24个类别的分类法


<details>
  <summary>Details</summary>
Motivation: GDPR和CCPA等隐私法规改变了软件开发方式，但缺乏开源软件开发者如何讨论合规问题的实证证据。GitHub上有大量开发者issue数据，但缺乏对隐私法规合规讨论的系统分析。

Method: 从GitHub仓库挖掘32,820个issue，自动分析识别法律用户权利和原则，手动分析1,186个issue样本，根据关注问题类型进行分类。

Result: 创建了包含6个集群24个类别的分类法：功能/缺陷、同意相关、文档、数据存储/共享、适应性、通用合规。发现开发者主要关注特定用户权利（删除权、选择退出权、访问权），讨论集中在用户同意、用户权利功能、缺陷和cookie管理。

Conclusion: 分类法帮助开发者优先处理合规问题，教育界可调整课程培养隐私法规意识，研究界可识别支持隐私法规合规的改进领域。

Abstract: Context: Privacy legislation has impacted the way software systems are developed, prompting practitioners to update their implementations. Specifically, the EU General Data Protection Regulation (GDPR) and the California Consumer Privacy Act (CCPA) have forced the community to focus on users' data privacy. Despite the vast amount of data on developer issues available in GitHub repositories, there is a lack of empirical evidence on the issues developers of Open Source Software discuss to comply with privacy legislation. Method: In this work, we examine such discussions by mining and analyzing 32,820 issues from GitHub repositories. We partially analyzed the dataset automatically to identify law user rights and principles indicated, and manually analyzed a sample of 1,186 issues based on the type of concern addressed. Results: We devised 24 discussion categories placed in six clusters: features/bugs, consent-related, documentation, data storing/sharing, adaptability, and general compliance. Our results show that developers mainly focus on specific user rights from the legislation (right to erasure, right to opt-out, right to access), addressing other rights less frequently, while most discussions concern user consent, user rights functionality, bugs and cookies management. Conclusion: The created taxonomy can help practitioners understand which issues are discussed for law compliance, so that they ensure they address them first in their systems. In addition, the educational community can reshape curricula to better educate future engineers on the privacy law concerns raised, and the research community can identify gaps and areas for improvement to support and accelerate data privacy law compliance.

</details>


### [23] [PACIFIC: a framework for generating benchmarks to check Precise Automatically Checked Instruction Following In Code](https://arxiv.org/abs/2512.10713)
*Itay Dreyfuss,Antonio Abu Nassar,Samuel Ackerman,Axel Ben David,Rami Katan,Orna Raz,Marcel Zalmanovici*

Main category: cs.SE

TL;DR: PACIFIC是一个自动生成基准测试的框架，用于评估LLM在代码任务中的顺序指令遵循和代码干运行能力，可控制难度并避免训练数据污染。


<details>
  <summary>Details</summary>
Motivation: 现有方法常依赖工具使用或代理行为，难以评估LLM内在的代码推理能力。需要一种能隔离评估LLM逐步推理代码行为（干运行）和指令遵循能力的方法，同时避免训练数据污染问题。

Method: 提出PACIFIC框架，自动生成具有明确预期输出的基准测试变体，通过简单输出比较进行可靠评估。框架可控制基准难度，轻松生成新颖变体以缓解数据污染。

Result: 验证框架生成了涵盖不同难度级别的基准测试套件，评估多个SOTA LLM。结果显示PACIFIC能产生越来越具挑战性的基准，有效区分不同模型的指令遵循和干运行能力。

Conclusion: PACIFIC提供了一个可扩展、抗污染的方法论，用于评估LLM在代码相关任务中的核心能力，特别是顺序指令遵循和代码干运行能力。

Abstract: Large Language Model (LLM)-based code assistants have emerged as a powerful application of generative AI, demonstrating impressive capabilities in code generation and comprehension. A key requirement for these systems is their ability to accurately follow user instructions. We present Precise Automatically Checked Instruction Following In Code (PACIFIC), a novel framework designed to automatically generate benchmarks that rigorously assess sequential instruction-following and code dry-running capabilities in LLMs, while allowing control over benchmark difficulty. PACIFIC produces benchmark variants with clearly defined expected outputs, enabling straightforward and reliable evaluation through simple output comparisons. In contrast to existing approaches that often rely on tool usage or agentic behavior, our work isolates and evaluates the LLM's intrinsic ability to reason through code behavior step-by-step without execution (dry running) and to follow instructions. Furthermore, our framework mitigates training data contamination by facilitating effortless generation of novel benchmark variations. We validate our framework by generating a suite of benchmarks spanning a range of difficulty levels and evaluating multiple state-of-the-art LLMs. Our results demonstrate that PACIFIC can produce increasingly challenging benchmarks that effectively differentiate instruction-following and dry running capabilities, even among advanced models. Overall, our framework offers a scalable, contamination-resilient methodology for assessing core competencies of LLMs in code-related tasks.

</details>


### [24] [Zorya: Automated Concolic Execution of Single-Threaded Go Binaries](https://arxiv.org/abs/2512.10799)
*Karolina Gorna,Nicolas Iooss,Yannick Seurin,Rida Khatoun*

Main category: cs.SE

TL;DR: Zorya是一个针对Go二进制文件的符号执行框架，通过将Go二进制转换为Ghidra的P-Code中间表示，并添加多层过滤机制，专注于panic相关路径的检测，显著提高了漏洞检测效率和覆盖率。


<details>
  <summary>Details</summary>
Motivation: Go语言在关键基础设施中的广泛应用增加了系统化漏洞检测的需求，但现有符号执行工具在处理Go二进制文件时面临运行时复杂性和可扩展性挑战，无法有效检测漏洞。

Method: 基于Zorya框架，将Go二进制转换为Ghidra的P-Code中间表示，添加了具体未执行路径的bug检测和多层过滤机制，专注于panic相关路径的符号推理。采用函数模式分析，从函数级别而非main函数开始分析，大幅提升效率。

Result: 在五个Go漏洞上的评估显示：panic可达性门控实现了1.8-3.9倍的速度提升，过滤了33-70%的分支；Zorya检测到了所有panic，而现有工具最多只能检测两个；函数模式分析使复杂程序的分析速度比从main开始快约两个数量级。

Conclusion: 这项研究表明，专门的符号执行方法可以在具有运行时安全检查的语言生态系统中实现实用的漏洞检测，为Go等语言的安全分析提供了有效解决方案。

Abstract: Go's adoption in critical infrastructure intensifies the need for systematic vulnerability detection, yet existing symbolic execution tools struggle with Go binaries due to runtime complexity and scalability challenges. In this work, we build upon Zorya, a concolic execution framework that translates Go binaries to Ghidra's P-Code intermediate representation to address these challenges. We added the detection of bugs in concretely not taken paths and a multi-layer filtering mechanism to concentrate symbolic reasoning on panic-relevant paths. Evaluation on five Go vulnerabilities demonstrates that panic-reachability gating achieves 1.8-3.9x speedups when filtering 33-70% of branches, and that Zorya detects all panics while existing tools detect at most two. Function-mode analysis proved essential for complex programs, running roughly two orders of magnitude faster than starting from main. This work establishes that specialized concolic execution can achieve practical vulnerability detection in language ecosystems with runtime safety checks.

</details>
