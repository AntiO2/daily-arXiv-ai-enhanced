<div id=toc></div>

# Table of Contents

- [cs.DC](#cs.DC) [Total: 2]
- [cs.DB](#cs.DB) [Total: 1]


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [1] [AI/ML Model Cards in Edge AI Cyberinfrastructure: towards Agentic AI](https://arxiv.org/abs/2511.21661)
*Beth Plale,Neelesh Karthikeyan,Isuru Gamage,Joe Stubbs,Sachith Withana*

Main category: cs.DC

TL;DR: 该研究评估了在Patra模型卡系统中采用模型上下文协议(MCP)作为接口的效益与权衡，比较了MCP与REST接口的开销，并探讨了MCP在动态模型卡环境中的适用性。


<details>
  <summary>Details</summary>
Motivation: 传统AI/ML模型卡在训练时进行一次性评估，无法反映模型在实际使用过程中的动态表现。研究旨在通过Patra模型卡系统探索模型卡作为动态对象的价值。

Method: 在ICICLE AI Institute软件生态系统中嵌入Patra模型卡，采用模型上下文协议(MCP)作为接口，与REST接口进行定量比较，并定性分析MCP在动态模型卡环境中的适用性。

Result: 定量评估显示MCP相比REST接口存在一定开销，但核心价值在于MCP支持的活动会话功能，这为动态模型卡的使用提供了更好的适应性。

Conclusion: MCP作为Patra模型卡服务器的接口，虽然在性能上存在开销，但在支持动态模型卡的实时使用场景方面具有显著优势，适合需要持续监控和更新模型使用情况的场景。

Abstract: AI/ML model cards can contain a benchmarked evaluation of an AI/ML model against intended use but a one time assessment during model training does not get at how and where a model is actually used over its lifetime. Through Patra Model Cards embedded in the ICICLE AI Institute software ecosystem we study model cards as dynamic objects. The study reported here assesses the benefits and tradeoffs of adopting the Model Context Protocol (MCP) as an interface to the Patra Model Card server. Quantitative assessment shows the overhead of MCP as compared to a REST interface. The core question however is of active sessions enabled by MCP; this is a qualitative question of fit and use in the context of dynamic model cards that we address as well.

</details>


### [2] [Diagonal Scaling: A Multi-Dimensional Resource Model and Optimization Framework for Distributed Databases](https://arxiv.org/abs/2511.21612)
*Shahir Abdullah,Syed Rohit Zaman*

Main category: cs.DC

TL;DR: 提出了一种二维的扩展平面模型，将水平扩展和垂直扩展结合起来，通过对角线缩放策略优化云数据库的性能和成本。


<details>
  <summary>Details</summary>
Motivation: 现代云数据库将扩展视为二元决策（水平扩展或垂直扩展），这种一维视图限制了性能优化，因为数据库性能、成本和协调开销是水平弹性和节点资源共同作用的结果。

Method: 提出了扩展平面模型，将分布式数据库配置表示为点(H,V)，其中H是节点数，V是资源向量。开发了DIAGONALSCALE算法，在扩展平面中评估水平、垂直和对角线移动，选择满足SLA约束的最优配置。

Result: 对角线缩放相比纯水平或纯垂直自动扩展，可将p95延迟降低高达40%，每查询成本降低高达37%，重新平衡次数减少2-5倍。

Conclusion: 研究结果强调了多维扩展模型的必要性，为下一代云数据库系统的自动扩展提供了基础。

Abstract: Modern cloud databases present scaling as a binary decision: scale-out by adding nodes or scale-up by increasing per-node resources. This one-dimensional view is limiting because database performance, cost, and coordination overhead emerge from the joint interaction of horizontal elasticity and per-node CPU, memory, network bandwidth, and storage IOPS. As a result, systems often overreact to load spikes, underreact to memory pressure, or oscillate between suboptimal states. We introduce the Scaling Plane, a two-dimensional model in which each distributed database configuration is represented as a point (H, V), with H denoting node count and V a vector of resources. Over this plane, we define smooth approximations of latency, throughput, coordination overhead, and monetary cost, providing a unified view of performance trade-offs. We show analytically and empirically that optimal scaling trajectories frequently lie along diagonal paths: sequences of joint horizontal and vertical adjustments that simultaneously exploit cluster parallelism and per-node improvements. To compute such actions, we propose DIAGONALSCALE, a discrete local-search algorithm that evaluates horizontal, vertical, and diagonal moves in the Scaling Plane and selects the configuration minimizing a multi-objective function subject to SLA constraints. Using synthetic surfaces, microbenchmarks, and experiments on distributed SQL and KV systems, we demonstrate that diagonal scaling reduces p95 latency by up to 40 percent, lowers cost-per-query by up to 37 percent, and reduces rebalancing by 2 to 5 times compared to horizontal-only and vertical-only autoscaling. Our results highlight the need for multi-dimensional scaling models and provide a foundation for next-generation autoscaling in cloud database systems.

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [3] [Beyond Accuracy: An Empirical Study of Uncertainty Estimation in Imputation](https://arxiv.org/abs/2511.21607)
*Zarin Tahia Hossain,Mostafa Milani*

Main category: cs.DB

TL;DR: 系统评估了不同插补方法的不确定性校准性能，发现准确性高的模型不一定能提供可靠的不确定性估计


<details>
  <summary>Details</summary>
Motivation: 现代插补方法在表示和量化不确定性方面存在差异，但这些不确定性估计的可靠性和校准性仍缺乏系统研究

Method: 比较了三大类代表性方法：统计方法（MICE、SoftImpute）、分布对齐方法（OT-Impute）和深度生成方法（GAIN、MIWAE、TabCSDI），通过多轮变异性、条件采样和预测分布建模三种途径估计不确定性，使用校准曲线和期望校准误差（ECE）进行评估

Result: 准确性和校准性往往不一致：高重建精度的模型不一定能产生可靠的不确定性，分析了方法在准确性、校准性和运行时间之间的权衡

Conclusion: 识别了稳定配置，为数据清理和下游机器学习流程中选择具有不确定性意识的插补方法提供了指导原则

Abstract: Handling missing data is a central challenge in data-driven analysis. Modern imputation methods not only aim for accurate reconstruction but also differ in how they represent and quantify uncertainty. Yet, the reliability and calibration of these uncertainty estimates remain poorly understood. This paper presents a systematic empirical study of uncertainty in imputation, comparing representative methods from three major families: statistical (MICE, SoftImpute), distribution alignment (OT-Impute), and deep generative (GAIN, MIWAE, TabCSDI). Experiments span multiple datasets, missingness mechanisms (MCAR, MAR, MNAR), and missingness rates. Uncertainty is estimated through three complementary routes: multi-run variability, conditional sampling, and predictive-distribution modeling, and evaluated using calibration curves and the Expected Calibration Error (ECE). Results show that accuracy and calibration are often misaligned: models with high reconstruction accuracy do not necessarily yield reliable uncertainty. We analyze method-specific trade-offs among accuracy, calibration, and runtime, identify stable configurations, and offer guidelines for selecting uncertainty-aware imputers in data cleaning and downstream machine learning pipelines.

</details>
