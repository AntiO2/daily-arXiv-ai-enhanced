{"id": "2510.18029", "categories": ["cs.DB", "cs.AI", "H.2.3"], "pdf": "https://arxiv.org/pdf/2510.18029", "abs": "https://arxiv.org/abs/2510.18029", "authors": ["Aymane Hassini"], "title": "DynaQuery: A Self-Adapting Framework for Querying Structured and Multimodal Data", "comment": "15 pages, 2 figures, 10 tables. Source code and experimental\n  artifacts are available at: https://github.com/aymanehassini/DynaQuery . The\n  'DynaQuery-Eval-5K' benchmark, introduced in this work, is also publicly\n  available at:\n  https://www.kaggle.com/datasets/aymanehassini/dynaquery-eval-5k-benchmark", "summary": "The rise of Large Language Models (LLMs) has accelerated the long-standing\ngoal of enabling natural language querying over complex, hybrid databases. Yet,\nthis ambition exposes a dual challenge: reasoning jointly over structured,\nmulti-relational schemas and the semantic content of linked unstructured\nassets. To overcome this, we present DynaQuery - a unified, self-adapting\nframework that serves as a practical blueprint for next-generation \"Unbound\nDatabases.\" At the heart of DynaQuery lies the Schema Introspection and Linking\nEngine (SILE), a novel systems primitive that elevates schema linking to a\nfirst-class query planning phase. We conduct a rigorous, multi-benchmark\nempirical evaluation of this structure-aware architecture against the prevalent\nunstructured Retrieval-Augmented Generation (RAG) paradigm. Our results\ndemonstrate that the unstructured retrieval paradigm is architecturally\nsusceptible to catastrophic contextual failures, such as SCHEMA_HALLUCINATION,\nleading to unreliable query generation. In contrast, our SILE-based design\nestablishes a substantially more robust foundation, nearly eliminating this\nfailure mode. Moreover, end-to-end validation on a complex, newly curated\nbenchmark uncovers a key generalization principle: the transition from pure\nschema-awareness to holistic semantics-awareness. Taken together, our findings\nprovide a validated architectural basis for developing natural language\ndatabase interfaces that are robust, adaptable, and predictably consistent.", "AI": {"tldr": "DynaQuery\u662f\u4e00\u4e2a\u7edf\u4e00\u7684\u3001\u81ea\u9002\u5e94\u7684\u6846\u67b6\uff0c\u901a\u8fc7Schema Introspection and Linking Engine (SILE)\u89e3\u51b3LLM\u5728\u6df7\u5408\u6570\u636e\u5e93\u81ea\u7136\u8bed\u8a00\u67e5\u8be2\u4e2d\u7684\u7ed3\u6784\u5316\u548c\u975e\u7ed3\u6784\u5316\u6570\u636e\u8054\u5408\u63a8\u7406\u6311\u6218\uff0c\u76f8\u6bd4\u4f20\u7edfRAG\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u67e5\u8be2\u53ef\u9760\u6027\u3002", "motivation": "\u89e3\u51b3LLM\u5728\u590d\u6742\u6df7\u5408\u6570\u636e\u5e93\u81ea\u7136\u8bed\u8a00\u67e5\u8be2\u4e2d\u9762\u4e34\u7684\u6311\u6218\uff1a\u9700\u8981\u540c\u65f6\u63a8\u7406\u7ed3\u6784\u5316\u591a\u5173\u7cfb\u6a21\u5f0f\u4e0e\u94fe\u63a5\u7684\u975e\u7ed3\u6784\u5316\u8d44\u4ea7\u8bed\u4e49\u5185\u5bb9\u3002", "method": "\u63d0\u51faDynaQuery\u6846\u67b6\uff0c\u5176\u6838\u5fc3\u662fSchema Introspection and Linking Engine (SILE)\uff0c\u5c06\u6a21\u5f0f\u94fe\u63a5\u63d0\u5347\u4e3a\u67e5\u8be2\u89c4\u5212\u7684\u4e00\u7b49\u516c\u6c11\u9636\u6bb5\uff0c\u91c7\u7528\u7ed3\u6784\u611f\u77e5\u67b6\u6784\u3002", "result": "\u76f8\u6bd4\u975e\u7ed3\u6784\u5316RAG\u8303\u5f0f\uff0cSILE\u8bbe\u8ba1\u663e\u8457\u66f4\u9c81\u68d2\uff0c\u51e0\u4e4e\u6d88\u9664\u4e86SCHEMA_HALLUCINATION\u7b49\u707e\u96be\u6027\u4e0a\u4e0b\u6587\u6545\u969c\uff1b\u5728\u590d\u6742\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u9a8c\u8bc1\u4e86\u4ece\u7eaf\u6a21\u5f0f\u611f\u77e5\u5230\u6574\u4f53\u8bed\u4e49\u611f\u77e5\u7684\u6cdb\u5316\u539f\u5219\u3002", "conclusion": "\u7814\u7a76\u4e3a\u5f00\u53d1\u9c81\u68d2\u3001\u81ea\u9002\u5e94\u4e14\u53ef\u9884\u6d4b\u4e00\u81f4\u7684\u81ea\u7136\u8bed\u8a00\u6570\u636e\u5e93\u63a5\u53e3\u63d0\u4f9b\u4e86\u7ecf\u8fc7\u9a8c\u8bc1\u7684\u67b6\u6784\u57fa\u7840\u3002"}}
{"id": "2510.17839", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.17839", "abs": "https://arxiv.org/abs/2510.17839", "authors": ["Johannes Schneider", "Rene Abraham"], "title": "AI Exchange Platforms", "comment": null, "summary": "The rapid integration of Artificial Intelligence (AI) into organizational\ntechnology frameworks has transformed how organizations engage with AI-driven\nmodels, influencing both operational performance and strategic innovation. With\nthe advent of foundation models, the importance of structured platforms for AI\nmodel exchange has become paramount for organizational efficacy and\nadaptability. However, a comprehensive framework to categorize and understand\nthese platforms remains underexplored. To address this gap, our taxonomy\nprovides a structured approach to categorize AI exchange platforms, examining\nkey dimensions and characteristics, as well as revealing interesting\ninteraction patterns between public research institutions and organizations:\nSome platforms leverage peer review as a mechanism for quality control, and\nprovide mechanisms for online testing, deploying, and customization of models.\nOur paper is beneficial to practitioners seeking to understand challenges and\nopportunities that arise from AI exchange platforms. For academics, the\ntaxonomy serves as a foundation for further research into the evolution,\nimpact, and best practices associated with AI model sharing and utilization in\ndifferent contexts. Additionally, our study provides insights into the evolving\nrole of AI in various industries, highlighting the importance of adaptability\nand innovation in platform design. This paper serves as a critical resource for\nunderstanding the dynamic interplay between technology, business models, and\nuser engagement in the rapidly growing domain of AI model exchanges pointing\nalso towards possible future evolution.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2aAI\u6a21\u578b\u4ea4\u6362\u5e73\u53f0\u7684\u5206\u7c7b\u6846\u67b6\uff0c\u5206\u6790\u4e86\u5e73\u53f0\u7684\u5173\u952e\u7ef4\u5ea6\u548c\u7279\u5f81\uff0c\u63ed\u793a\u4e86\u7814\u7a76\u673a\u6784\u4e0e\u7ec4\u7ec7\u4e4b\u95f4\u7684\u4e92\u52a8\u6a21\u5f0f\uff0c\u4e3a\u4ece\u4e1a\u8005\u548c\u5b66\u8005\u63d0\u4f9b\u4e86\u7406\u89e3AI\u4ea4\u6362\u5e73\u53f0\u6311\u6218\u4e0e\u673a\u9047\u7684\u57fa\u7840\u3002", "motivation": "\u968f\u7740\u57fa\u7840\u6a21\u578b\u7684\u5174\u8d77\uff0cAI\u6a21\u578b\u4ea4\u6362\u5e73\u53f0\u5bf9\u7ec4\u7ec7\u6548\u80fd\u548c\u9002\u5e94\u6027\u53d8\u5f97\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u76ee\u524d\u7f3a\u4e4f\u5bf9\u8fd9\u4e9b\u5e73\u53f0\u8fdb\u884c\u7cfb\u7edf\u5206\u7c7b\u548c\u7406\u89e3\u7684\u7efc\u5408\u6846\u67b6\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u5206\u7c7b\u6cd5\u6765\u7cfb\u7edf\u5316\u5730\u5206\u7c7bAI\u4ea4\u6362\u5e73\u53f0\uff0c\u8003\u5bdf\u5173\u952e\u7ef4\u5ea6\u548c\u7279\u5f81\uff0c\u5e76\u5206\u6790\u516c\u5171\u7814\u7a76\u673a\u6784\u4e0e\u7ec4\u7ec7\u4e4b\u95f4\u7684\u4e92\u52a8\u6a21\u5f0f\u3002", "result": "\u8bc6\u522b\u4e86\u5e73\u53f0\u5229\u7528\u540c\u884c\u8bc4\u5ba1\u8fdb\u884c\u8d28\u91cf\u63a7\u5236\u7684\u5173\u952e\u7279\u5f81\uff0c\u4ee5\u53ca\u63d0\u4f9b\u5728\u7ebf\u6d4b\u8bd5\u3001\u90e8\u7f72\u548c\u6a21\u578b\u5b9a\u5236\u5316\u673a\u5236\u7684\u529f\u80fd\uff0c\u63ed\u793a\u4e86\u4e0d\u540c\u5229\u76ca\u76f8\u5173\u8005\u4e4b\u95f4\u7684\u534f\u4f5c\u6a21\u5f0f\u3002", "conclusion": "\u8be5\u5206\u7c7b\u6cd5\u4e3a\u7406\u89e3AI\u6a21\u578b\u4ea4\u6362\u5e73\u53f0\u63d0\u4f9b\u4e86\u7ed3\u6784\u5316\u65b9\u6cd5\uff0c\u4e3a\u4ece\u4e1a\u8005\u63d0\u4f9b\u4e86\u5b9e\u8df5\u6307\u5bfc\uff0c\u4e3a\u5b66\u8005\u63d0\u4f9b\u4e86\u8fdb\u4e00\u6b65\u7814\u7a76\u7684\u57fa\u7840\uff0c\u5e76\u5f3a\u8c03\u4e86\u5e73\u53f0\u8bbe\u8ba1\u4e2d\u9002\u5e94\u6027\u548c\u521b\u65b0\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2510.17852", "categories": ["cs.DC", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.17852", "abs": "https://arxiv.org/abs/2510.17852", "authors": ["Yuze Sun", "Wentao Luo", "Yanfei Xiang", "Jiancheng Pan", "Jiahao Li", "Quan Zhang", "Xiaomeng Huang"], "title": "Deploying Atmospheric and Oceanic AI Models on Chinese Hardware and Framework: Migration Strategies, Performance Optimization and Analysis", "comment": null, "summary": "With the growing role of artificial intelligence in climate and weather\nresearch, efficient model training and inference are in high demand. Current\nmodels like FourCastNet and AI-GOMS depend heavily on GPUs, limiting hardware\nindependence, especially for Chinese domestic hardware and frameworks. To\naddress this issue, we present a framework for migrating large-scale\natmospheric and oceanic models from PyTorch to MindSpore and optimizing for\nChinese chips, and evaluating their performance against GPUs. The framework\nfocuses on software-hardware adaptation, memory optimization, and parallelism.\nFurthermore, the model's performance is evaluated across multiple metrics,\nincluding training speed, inference speed, model accuracy, and energy\nefficiency, with comparisons against GPU-based implementations. Experimental\nresults demonstrate that the migration and optimization process preserves the\nmodels' original accuracy while significantly reducing system dependencies and\nimproving operational efficiency by leveraging Chinese chips as a viable\nalternative for scientific computing. This work provides valuable insights and\npractical guidance for leveraging Chinese domestic chips and frameworks in\natmospheric and oceanic AI model development, offering a pathway toward greater\ntechnological independence.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u5c06\u5927\u6c14\u548c\u6d77\u6d0bAI\u6a21\u578b\u4ecePyTorch\u8fc1\u79fb\u5230MindSpore\u5e76\u9488\u5bf9\u4e2d\u56fd\u82af\u7247\u4f18\u5316\u7684\u6846\u67b6\uff0c\u65e8\u5728\u51cf\u5c11\u5bf9GPU\u7684\u4f9d\u8d56\uff0c\u63d0\u5347\u786c\u4ef6\u72ec\u7acb\u6027\u3002", "motivation": "\u5f53\u524dAI\u6c14\u5019\u548c\u5929\u6c14\u7814\u7a76\u6a21\u578b\uff08\u5982FourCastNet\u548cAI-GOMS\uff09\u4e25\u91cd\u4f9d\u8d56GPU\uff0c\u9650\u5236\u4e86\u786c\u4ef6\u72ec\u7acb\u6027\uff0c\u7279\u522b\u662f\u5bf9\u4e2d\u56fd\u56fd\u4ea7\u786c\u4ef6\u548c\u6846\u67b6\u7684\u652f\u6301\u4e0d\u8db3\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u8fc1\u79fb\u6846\u67b6\uff0c\u4e13\u6ce8\u4e8e\u8f6f\u786c\u4ef6\u9002\u914d\u3001\u5185\u5b58\u4f18\u5316\u548c\u5e76\u884c\u5316\uff0c\u5c06\u6a21\u578b\u4ecePyTorch\u8fc1\u79fb\u5230MindSpore\u5e76\u9488\u5bf9\u4e2d\u56fd\u82af\u7247\u8fdb\u884c\u4f18\u5316\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8fc1\u79fb\u548c\u4f18\u5316\u8fc7\u7a0b\u4fdd\u6301\u4e86\u6a21\u578b\u7684\u539f\u59cb\u7cbe\u5ea6\uff0c\u540c\u65f6\u663e\u8457\u964d\u4f4e\u4e86\u7cfb\u7edf\u4f9d\u8d56\u6027\uff0c\u5e76\u5229\u7528\u4e2d\u56fd\u82af\u7247\u63d0\u9ad8\u4e86\u8fd0\u884c\u6548\u7387\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3a\u5728\u5927\u6c14\u548c\u6d77\u6d0bAI\u6a21\u578b\u5f00\u53d1\u4e2d\u5229\u7528\u4e2d\u56fd\u56fd\u4ea7\u82af\u7247\u548c\u6846\u67b6\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u89c1\u89e3\u548c\u5b9e\u8df5\u6307\u5bfc\uff0c\u4e3a\u5b9e\u73b0\u66f4\u5927\u7684\u6280\u672f\u72ec\u7acb\u6027\u63d0\u4f9b\u4e86\u9014\u5f84\u3002"}}
{"id": "2510.17842", "categories": ["cs.SE", "cs.HC"], "pdf": "https://arxiv.org/pdf/2510.17842", "abs": "https://arxiv.org/abs/2510.17842", "authors": ["Vinay Bamil"], "title": "Vibe Coding: Toward an AI-Native Paradigm for Semantic and Intent-Driven Programming", "comment": "10 pages, 1 figure, 2 tables", "summary": "Recent advances in large language models have enabled developers to generate\nsoftware by conversing with artificial intelligence systems rather than writing\ncode directly. This paper introduces vibe coding, an emerging AI-native\nprogramming paradigm in which a developer specifies high-level functional\nintent along with qualitative descriptors of the desired \"vibe\" (tone, style,\nor emotional resonance). An intelligent agent then transforms those\nspecifications into executable software. We formalize the definition of vibe\ncoding and propose a reference architecture that includes an intent parser, a\nsemantic embedding engine, an agentic code generator, and an interactive\nfeedback loop. A hypothetical implementation is described. We compare vibe\ncoding with declarative, functional, and prompt-based programming, and we\ndiscuss its implications for software engineering, human-AI collaboration, and\nresponsible AI practice. Finally, we examine reported productivity gains and\ndemocratizing effects, review recent studies that highlight vulnerabilities and\npotential slowdowns, identify key challenges such as alignment,\nreproducibility, bias, explainability, maintainability, and security, and\noutline future directions and open research questions.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86vibe coding\u8fd9\u4e00\u65b0\u5174\u7684AI\u539f\u751f\u7f16\u7a0b\u8303\u5f0f\uff0c\u5f00\u53d1\u8005\u901a\u8fc7\u6307\u5b9a\u9ad8\u7ea7\u529f\u80fd\u610f\u56fe\u548c\u5b9a\u6027\u63cf\u8ff0\u6765\u751f\u6210\u8f6f\u4ef6\uff0c\u5e76\u63d0\u51fa\u4e86\u53c2\u8003\u67b6\u6784\u548c\u5b9e\u73b0\u65b9\u6848\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u7684\u53d1\u5c55\uff0c\u5f00\u53d1\u8005\u53ef\u4ee5\u901a\u8fc7\u4e0eAI\u7cfb\u7edf\u5bf9\u8bdd\u800c\u975e\u76f4\u63a5\u7f16\u5199\u4ee3\u7801\u6765\u751f\u6210\u8f6f\u4ef6\uff0c\u8fd9\u50ac\u751f\u4e86\u65b0\u7684\u7f16\u7a0b\u8303\u5f0f\u9700\u6c42\u3002", "method": "\u63d0\u51fa\u4e86vibe coding\u7684\u5b9a\u4e49\u548c\u53c2\u8003\u67b6\u6784\uff0c\u5305\u62ec\u610f\u56fe\u89e3\u6790\u5668\u3001\u8bed\u4e49\u5d4c\u5165\u5f15\u64ce\u3001\u667a\u80fd\u4ee3\u7801\u751f\u6210\u5668\u548c\u4ea4\u4e92\u53cd\u9988\u5faa\u73af\uff0c\u5e76\u63cf\u8ff0\u4e86\u5047\u8bbe\u5b9e\u73b0\u65b9\u6848\u3002", "result": "\u4e0e\u58f0\u660e\u5f0f\u3001\u51fd\u6570\u5f0f\u548c\u57fa\u4e8e\u63d0\u793a\u7684\u7f16\u7a0b\u8fdb\u884c\u4e86\u6bd4\u8f83\uff0c\u5206\u6790\u4e86\u5176\u5bf9\u8f6f\u4ef6\u5de5\u7a0b\u3001\u4eba\u673a\u534f\u4f5c\u548c\u8d1f\u8d23\u4efbAI\u5b9e\u8df5\u7684\u5f71\u54cd\uff0c\u5e76\u8ba8\u8bba\u4e86\u751f\u4ea7\u7387\u7684\u63d0\u5347\u548c\u6c11\u4e3b\u5316\u6548\u5e94\u3002", "conclusion": "\u8bc6\u522b\u4e86\u5bf9\u9f50\u3001\u53ef\u590d\u73b0\u6027\u3001\u504f\u89c1\u3001\u53ef\u89e3\u91ca\u6027\u3001\u53ef\u7ef4\u62a4\u6027\u548c\u5b89\u5168\u6027\u7b49\u5173\u952e\u6311\u6218\uff0c\u5e76\u6982\u8ff0\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\u548c\u5f00\u653e\u6027\u95ee\u9898\u3002"}}
{"id": "2510.18152", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2510.18152", "abs": "https://arxiv.org/abs/2510.18152", "authors": ["Zhuoyu Yao", "Yue Wang", "Songyang Zhang", "Yingshu Li", "Zhipeng Cai", "Zhi Tian"], "title": "Efficient Multi-Worker Selection based Distributed Swarm Learning via Analog Aggregation", "comment": "5 pages, 4 figures, conference", "summary": "Recent advances in distributed learning systems have introduced effective\nsolutions for implementing collaborative artificial intelligence techniques in\nwireless communication networks. Federated learning approaches provide a\nmodel-aggregation mechanism among edge devices to achieve collaborative\ntraining, while ensuring data security, communication efficiency, and sharing\ncomputational overheads. On the other hand, limited transmission resources and\ncomplex communication environments remain significant bottlenecks to the\nefficient collaborations among edge devices, particularly within large-scale\nnetworks. To address such issues, this paper proposes an over-the-air (OTA)\nanalog aggregation method designed for the distributed swarm learning (DSL),\ntermed DSL-OTA, aiming to enhance communication efficiency, enable effective\ncooperation, and ensure privacy preserving. Incorporating multi-worker\nselection strategy with over-the-air aggregation not only makes the standard\nDSL based on single best worker contributing to global model update to become\nmore federated, but also secures the aggregation from potential risks of data\nleakage. Our theoretical analyses verify the advantages of the proposed DSL-OTA\nalgorithm in terms of fast convergence rate and low communication costs.\nSimulation results reveal that our DSL-OTA outperforms the other existing\nmethods by achieving better learning performance under both homogeneous and\nheterogeneous dataset settings.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u5206\u5e03\u5f0f\u7fa4\u5b66\u4e60(DSL)\u7684\u7a7a\u4e2d\u6a21\u62df\u805a\u5408\u65b9\u6cd5DSL-OTA\uff0c\u901a\u8fc7\u591a\u5de5\u4f5c\u8005\u9009\u62e9\u7b56\u7565\u548c\u7a7a\u4e2d\u805a\u5408\u63d0\u9ad8\u901a\u4fe1\u6548\u7387\u3001\u5b9e\u73b0\u6709\u6548\u534f\u4f5c\u5e76\u786e\u4fdd\u9690\u79c1\u4fdd\u62a4\u3002", "motivation": "\u5206\u5e03\u5f0f\u5b66\u4e60\u7cfb\u7edf\u4e2d\uff0c\u6709\u9650\u7684\u4f20\u8f93\u8d44\u6e90\u548c\u590d\u6742\u901a\u4fe1\u73af\u5883\u963b\u788d\u4e86\u8fb9\u7f18\u8bbe\u5907\u95f4\u7684\u9ad8\u6548\u534f\u4f5c\uff0c\u7279\u522b\u662f\u5728\u5927\u89c4\u6a21\u7f51\u7edc\u4e2d\u3002\u9700\u8981\u89e3\u51b3\u901a\u4fe1\u6548\u7387\u548c\u9690\u79c1\u4fdd\u62a4\u95ee\u9898\u3002", "method": "\u63d0\u51faDSL-OTA\u65b9\u6cd5\uff0c\u7ed3\u5408\u591a\u5de5\u4f5c\u8005\u9009\u62e9\u7b56\u7565\u548c\u7a7a\u4e2d\u6a21\u62df\u805a\u5408\uff0c\u4f7f\u6807\u51c6DSL\u4ece\u5355\u4e00\u6700\u4f73\u5de5\u4f5c\u8005\u8d21\u732e\u53d8\u5f97\u66f4\u52a0\u8054\u90a6\u5316\uff0c\u540c\u65f6\u4fdd\u62a4\u805a\u5408\u8fc7\u7a0b\u514d\u53d7\u6570\u636e\u6cc4\u9732\u98ce\u9669\u3002", "result": "\u7406\u8bba\u5206\u6790\u9a8c\u8bc1\u4e86DSL-OTA\u5728\u5feb\u901f\u6536\u655b\u7387\u548c\u4f4e\u901a\u4fe1\u6210\u672c\u65b9\u9762\u7684\u4f18\u52bf\u3002\u4eff\u771f\u7ed3\u679c\u663e\u793a\uff0c\u5728\u5747\u5300\u548c\u975e\u5747\u5300\u6570\u636e\u96c6\u8bbe\u7f6e\u4e0b\uff0cDSL-OTA\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u5b66\u4e60\u6027\u80fd\u3002", "conclusion": "DSL-OTA\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u5206\u5e03\u5f0f\u5b66\u4e60\u4e2d\u7684\u901a\u4fe1\u6548\u7387\u548c\u9690\u79c1\u4fdd\u62a4\u95ee\u9898\uff0c\u5728\u7406\u8bba\u548c\u5b9e\u8df5\u4e2d\u90fd\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\u3002"}}
{"id": "2510.17865", "categories": ["cs.SE", "cs.LO"], "pdf": "https://arxiv.org/pdf/2510.17865", "abs": "https://arxiv.org/abs/2510.17865", "authors": ["Rene Davila", "Everardo Barcenas", "Rocio Aldeco-Perez"], "title": "Smart Contracts Formal Verification: A Systematic Literature Review", "comment": "in Spanish language", "summary": "Formal verification entails testing software to ensure it operates as\nspecified. Smart contracts are self-executing contracts with the terms of the\nagreement directly written into lines of code. They run on blockchain platforms\nand automatically enforce and execute the terms of an agreement when meeting\npredefined conditions. However, Smart Contracts, as software models, often\ncontain notable errors in their operation or specifications. This observation\nprompts us to conduct a focused study examining related works published across\nvarious sources. These publications detail specifications, verification tools,\nand relevant experiments. Subsequently, this survey proposes an alternative\nformal verification based on description logic.", "AI": {"tldr": "\u672c\u6587\u5bf9\u667a\u80fd\u5408\u7ea6\u7684\u5f62\u5f0f\u5316\u9a8c\u8bc1\u65b9\u6cd5\u8fdb\u884c\u4e86\u7efc\u8ff0\u7814\u7a76\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u63cf\u8ff0\u903b\u8f91\u7684\u66ff\u4ee3\u6027\u5f62\u5f0f\u5316\u9a8c\u8bc1\u65b9\u6cd5\u3002", "motivation": "\u667a\u80fd\u5408\u7ea6\u4f5c\u4e3a\u5728\u533a\u5757\u94fe\u5e73\u53f0\u4e0a\u8fd0\u884c\u7684\u81ea\u52a8\u6267\u884c\u5408\u7ea6\uff0c\u7ecf\u5e38\u5728\u5176\u64cd\u4f5c\u6216\u89c4\u8303\u4e2d\u5b58\u5728\u663e\u8457\u9519\u8bef\uff0c\u8fd9\u4fc3\u4f7f\u6211\u4eec\u7814\u7a76\u76f8\u5173\u7684\u5f62\u5f0f\u5316\u9a8c\u8bc1\u65b9\u6cd5\u3002", "method": "\u901a\u8fc7\u5ba1\u67e5\u5404\u79cd\u6765\u6e90\u53d1\u8868\u7684\u76f8\u5173\u5de5\u4f5c\uff0c\u8be6\u7ec6\u5206\u6790\u89c4\u8303\u3001\u9a8c\u8bc1\u5de5\u5177\u548c\u76f8\u5173\u5b9e\u9a8c\uff0c\u7136\u540e\u63d0\u51fa\u57fa\u4e8e\u63cf\u8ff0\u903b\u8f91\u7684\u5f62\u5f0f\u5316\u9a8c\u8bc1\u66ff\u4ee3\u65b9\u6848\u3002", "result": "\u5bf9\u73b0\u6709\u667a\u80fd\u5408\u7ea6\u5f62\u5f0f\u5316\u9a8c\u8bc1\u65b9\u6cd5\u7684\u7cfb\u7edf\u7efc\u8ff0\uff0c\u8bc6\u522b\u4e86\u5f53\u524d\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002", "conclusion": "\u57fa\u4e8e\u63cf\u8ff0\u903b\u8f91\u7684\u5f62\u5f0f\u5316\u9a8c\u8bc1\u65b9\u6cd5\u4e3a\u667a\u80fd\u5408\u7ea6\u9a8c\u8bc1\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u80fd\u591f\u66f4\u597d\u5730\u5904\u7406\u5408\u7ea6\u89c4\u8303\u548c\u64cd\u4f5c\u4e2d\u7684\u9519\u8bef\u3002"}}
{"id": "2510.18300", "categories": ["cs.DC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.18300", "abs": "https://arxiv.org/abs/2510.18300", "authors": ["Ankur Lahiry", "Ayush Pokharel", "Banooqa Banday", "Seth Ockerman", "Amal Gueroudji", "Mohammad Zaeed", "Tanzima Z. Islam", "Line Pouchard"], "title": "A Distributed Framework for Causal Modeling of Performance Variability in GPU Traces", "comment": null, "summary": "Large-scale GPU traces play a critical role in identifying performance\nbottlenecks within heterogeneous High-Performance Computing (HPC)\narchitectures. However, the sheer volume and complexity of a single trace of\ndata make performance analysis both computationally expensive and\ntime-consuming. To address this challenge, we present an end-to-end parallel\nperformance analysis framework designed to handle multiple large-scale GPU\ntraces efficiently. Our proposed framework partitions and processes trace data\nconcurrently and employs causal graph methods and parallel coordinating chart\nto expose performance variability and dependencies across execution flows.\nExperimental results demonstrate a 67% improvement in terms of scalability,\nhighlighting the effectiveness of our pipeline for analyzing multiple traces\nindependently.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u7aef\u5230\u7aef\u7684\u5e76\u884c\u6027\u80fd\u5206\u6790\u6846\u67b6\uff0c\u7528\u4e8e\u9ad8\u6548\u5904\u7406\u591a\u4e2a\u5927\u89c4\u6a21GPU\u8ddf\u8e2a\u6570\u636e\uff0c\u901a\u8fc7\u5e76\u884c\u5904\u7406\u548c\u56e0\u679c\u56fe\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u53ef\u6269\u5c55\u6027\u3002", "motivation": "\u5927\u89c4\u6a21GPU\u8ddf\u8e2a\u6570\u636e\u5bf9\u4e8e\u8bc6\u522b\u5f02\u6784\u9ad8\u6027\u80fd\u8ba1\u7b97\u67b6\u6784\u4e2d\u7684\u6027\u80fd\u74f6\u9888\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5355\u4e2a\u8ddf\u8e2a\u6570\u636e\u7684\u5e9e\u5927\u4f53\u79ef\u548c\u590d\u6742\u6027\u4f7f\u5f97\u6027\u80fd\u5206\u6790\u8ba1\u7b97\u6210\u672c\u9ad8\u6602\u4e14\u8017\u65f6\u3002", "method": "\u91c7\u7528\u7aef\u5230\u7aef\u5e76\u884c\u6027\u80fd\u5206\u6790\u6846\u67b6\uff0c\u5bf9\u8ddf\u8e2a\u6570\u636e\u8fdb\u884c\u5206\u533a\u548c\u5e76\u53d1\u5904\u7406\uff0c\u5e76\u8fd0\u7528\u56e0\u679c\u56fe\u65b9\u6cd5\u548c\u5e76\u884c\u534f\u8c03\u56fe\u8868\u6765\u63ed\u793a\u6267\u884c\u6d41\u4e2d\u7684\u6027\u80fd\u53d8\u5f02\u6027\u548c\u4f9d\u8d56\u5173\u7cfb\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u5728\u53ef\u6269\u5c55\u6027\u65b9\u9762\u5b9e\u73b0\u4e8667%\u7684\u63d0\u5347\uff0c\u8bc1\u660e\u4e86\u8be5\u6d41\u6c34\u7ebf\u5728\u72ec\u7acb\u5206\u6790\u591a\u4e2a\u8ddf\u8e2a\u6570\u636e\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u5e76\u884c\u6027\u80fd\u5206\u6790\u6846\u67b6\u80fd\u591f\u9ad8\u6548\u5904\u7406\u5927\u89c4\u6a21GPU\u8ddf\u8e2a\u6570\u636e\uff0c\u663e\u8457\u63d0\u5347\u5206\u6790\u6548\u7387\uff0c\u4e3a\u5f02\u6784HPC\u67b6\u6784\u7684\u6027\u80fd\u4f18\u5316\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\u3002"}}
{"id": "2510.17868", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.17868", "abs": "https://arxiv.org/abs/2510.17868", "authors": ["Xinyue Zheng", "Haowei Lin", "Shaofei Cai", "Zilong Zheng", "Yitao Liang"], "title": "UniCode: A Framework for Generating High Quality Competitive Coding Problems", "comment": null, "summary": "The reliance of competitive coding benchmarks on static, human-authored\nproblems creates significant challenges, including data contamination and\nlimited scalability. To address these issues, we introduce UniCode, a novel\nframework that automatically generates high-quality algorithmic problems\nalongside robust, contamination-resistant test cases. Inspired by biological\nevolution that creates better and diverse offspring, our framework leverages\nLarge Language Models (LLMs) to systematically diversify problems through three\nstrategies: single problem extension, same-type fusion, and cross-type fusion.\nA key innovation is our stress-driven test case synthesis pipeline, which\ngenerates reliable test suites without requiring a canonical ground-truth\nsolution. This pipeline combines brute-force grounding for small-scale inputs\nwith a consensus-based validation mechanism for large-scale inputs to ensure\nhigh correctness and coverage. We demonstrate effectiveness of our framework by\ncurating a benchmark of 492 problems and evaluating 19 state-of-the-art LLMs.\nThe results reveal that UniCode is highly challenging and discriminative, with\nthe top-performing model, o4-mini, achieving a pass rate of only 70.3%. Our\nframework provides a scalable and reliable solution for generating dynamic\nevaluation datasets in coding domain.", "AI": {"tldr": "UniCode\u662f\u4e00\u4e2a\u81ea\u52a8\u751f\u6210\u9ad8\u8d28\u91cf\u7b97\u6cd5\u95ee\u9898\u548c\u6297\u6c61\u67d3\u6d4b\u8bd5\u7528\u4f8b\u7684\u6846\u67b6\uff0c\u901a\u8fc7LLM\u4f7f\u7528\u4e09\u79cd\u7b56\u7565\u591a\u6837\u5316\u95ee\u9898\u751f\u6210\uff0c\u5e76\u91c7\u7528\u538b\u529b\u9a71\u52a8\u7684\u6d4b\u8bd5\u7528\u4f8b\u5408\u6210\u7ba1\u9053\u786e\u4fdd\u53ef\u9760\u6027\u3002", "motivation": "\u89e3\u51b3\u4f20\u7edf\u7f16\u7a0b\u57fa\u51c6\u6d4b\u8bd5\u4f9d\u8d56\u9759\u6001\u4eba\u5de5\u7f16\u5199\u95ee\u9898\u5bfc\u81f4\u7684\u6570\u636e\u6c61\u67d3\u548c\u53ef\u6269\u5c55\u6027\u9650\u5236\u95ee\u9898\u3002", "method": "\u5229\u7528LLM\u901a\u8fc7\u5355\u95ee\u9898\u6269\u5c55\u3001\u540c\u7c7b\u578b\u878d\u5408\u548c\u8de8\u7c7b\u578b\u878d\u5408\u4e09\u79cd\u7b56\u7565\u591a\u6837\u5316\u95ee\u9898\u751f\u6210\uff1b\u91c7\u7528\u538b\u529b\u9a71\u52a8\u6d4b\u8bd5\u7528\u4f8b\u5408\u6210\u7ba1\u9053\uff0c\u7ed3\u5408\u5c0f\u89c4\u6a21\u8f93\u5165\u7684\u66b4\u529b\u57fa\u7840\u9a8c\u8bc1\u548c\u5927\u89c4\u6a21\u8f93\u5165\u7684\u5171\u8bc6\u9a8c\u8bc1\u673a\u5236\u3002", "result": "\u6784\u5efa\u4e86\u5305\u542b492\u4e2a\u95ee\u9898\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u8bc4\u4f3019\u4e2a\u6700\u5148\u8fdbLLM\uff0c\u5176\u4e2d\u8868\u73b0\u6700\u597d\u7684o4-mini\u6a21\u578b\u4ec5\u8fbe\u523070.3%\u7684\u901a\u8fc7\u7387\u3002", "conclusion": "UniCode\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u4e14\u53ef\u9760\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u7528\u4e8e\u5728\u7f16\u7a0b\u9886\u57df\u751f\u6210\u52a8\u6001\u8bc4\u4f30\u6570\u636e\u96c6\u3002"}}
{"id": "2510.18544", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2510.18544", "abs": "https://arxiv.org/abs/2510.18544", "authors": ["Pan Zhou", "Yiming Lei", "Ling Liu", "Xiaoqiong Xu", "Ying Cai", "Daji Ergu", "Hongfang Yu", "Yueyue Dai"], "title": "SLICE: SLO-Driven Scheduling for LLM Inference on Edge Computing Devices", "comment": null, "summary": "Large Language Models (LLMs), as the foundational architecture for\nnext-generation interactive AI applications, not only power intelligent\ndialogue systems but also drive the evolution of embodied intelligence on edge\ndevices, including humanoid robots, smart vehicles, and other scenarios. The\napplications running on these edge devices impose differentiated Service Level\nObjectives (SLO) requirements on LLM services, specifically manifested as\ndistinct constraints on Time to First Token (TTFT) and Time Per Output Token\n(TPOT) as well as end-to-end latency. Notably, edge devices typically handle\nreal-time tasks that are extremely sensitive to latency, such as machine\ncontrol and navigation planning. However, existing scheduling service systems\nstill prioritize maximizing output token throughput as the sole optimization\nobjective, failing to adequately address the diversity of SLO requirements.\nThis ultimately results in persistently high violation rates for end-to-end\nlatency or TPOT related SLOs.\n  This paper proposes SLICE, an innovative scheduling solution designed for\nedge computing scenarios with differentiated SLO requirements. By combining a\nutility-maximizing request scheduling algorithm with a dynamic iterative\ncontrol mechanism for generation rates, SLICE significantly improves LLM\ninference service SLO attainment. Experimental results demonstrate that\ncompared to state-of-the-art solutions Orca and FastServe, SLICE achieves up to\n35x higher SLO attainment and 3.4x advantage in task completion time than the\nother two solutions.", "AI": {"tldr": "SLICE\u662f\u4e00\u79cd\u9488\u5bf9\u8fb9\u7f18\u8ba1\u7b97\u573a\u666f\u7684\u521b\u65b0\u8c03\u5ea6\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u7ed3\u5408\u6548\u7528\u6700\u5927\u5316\u8bf7\u6c42\u8c03\u5ea6\u7b97\u6cd5\u548c\u52a8\u6001\u8fed\u4ee3\u751f\u6210\u901f\u7387\u63a7\u5236\u673a\u5236\uff0c\u663e\u8457\u63d0\u9ad8\u4e86LLM\u63a8\u7406\u670d\u52a1\u7684SLO\u8fbe\u6210\u7387\u3002", "motivation": "\u73b0\u6709\u8c03\u5ea6\u670d\u52a1\u7cfb\u7edf\u4ecd\u4ee5\u6700\u5927\u5316\u8f93\u51fatoken\u541e\u5410\u91cf\u4e3a\u552f\u4e00\u4f18\u5316\u76ee\u6807\uff0c\u65e0\u6cd5\u5145\u5206\u5e94\u5bf9SLO\u8981\u6c42\u7684\u591a\u6837\u6027\uff0c\u5bfc\u81f4\u7aef\u5230\u7aef\u5ef6\u8fdf\u6216TPOT\u76f8\u5173SLO\u7684\u8fdd\u89c4\u7387\u6301\u7eed\u5c45\u9ad8\u3002", "method": "\u7ed3\u5408\u6548\u7528\u6700\u5927\u5316\u8bf7\u6c42\u8c03\u5ea6\u7b97\u6cd5\u4e0e\u751f\u6210\u901f\u7387\u7684\u52a8\u6001\u8fed\u4ee3\u63a7\u5236\u673a\u5236", "result": "\u76f8\u6bd4\u6700\u5148\u8fdb\u89e3\u51b3\u65b9\u6848Orca\u548cFastServe\uff0cSLICE\u5b9e\u73b0\u4e86\u9ad8\u8fbe35\u500d\u7684SLO\u8fbe\u6210\u7387\u63d0\u5347\u548c3.4\u500d\u7684\u4efb\u52a1\u5b8c\u6210\u65f6\u95f4\u4f18\u52bf", "conclusion": "SLICE\u80fd\u591f\u6709\u6548\u6ee1\u8db3\u8fb9\u7f18\u8bbe\u5907\u5bf9LLM\u670d\u52a1\u7684\u5dee\u5f02\u5316SLO\u8981\u6c42\uff0c\u663e\u8457\u6539\u5584\u63a8\u7406\u670d\u52a1\u7684\u6027\u80fd\u8868\u73b0"}}
{"id": "2510.17874", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.17874", "abs": "https://arxiv.org/abs/2510.17874", "authors": ["Jason Tsay", "Zidane Wright", "Gaodan Fang", "Kiran Kate", "Saurabh Jha", "Yara Rizk"], "title": "Repairing Tool Calls Using Post-tool Execution Reflection and RAG", "comment": null, "summary": "Agentic systems interact with external systems by calling tools such as\nPython functions, REST API endpoints, or command line tools such as kubectl in\nKubernetes. These tool calls often fail for various syntactic and semantic\nreasons. Some less obvious semantic errors can only be identified and resolved\nafter analyzing the tool's response. To repair these errors, we develop a\npost-tool execution reflection component that combines large language model\n(LLM)-based reflection with domain-specific retrieval-augmented generation\n(RAG) using documents describing both the specific tool being called and\ntroubleshooting documents related to the tool. For this paper, we focus on the\nuse case of the kubectl command line tool to manage Kubernetes, a platform for\norchestrating cluster applications. Through a larger empirical study and a\nsmaller manual evaluation, we find that our RAG-based reflection will repair\nkubectl commands such that they are both more likely to successfully execute\n(pass rate) for 55% of our models evaluated and 36% more likely to correctly\nanswer the user query on average. We find that troubleshooting documents\nimprove pass rate compared to official documentation by an average of 10%.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u540e\u5de5\u5177\u6267\u884c\u53cd\u601d\u7ec4\u4ef6\uff0c\u7ed3\u5408LLM\u53cd\u601d\u548c\u9886\u57df\u7279\u5b9a\u7684RAG\uff0c\u4f7f\u7528\u5de5\u5177\u6587\u6863\u548c\u6545\u969c\u6392\u9664\u6587\u6863\u6765\u4fee\u590dkubectl\u547d\u4ee4\u6267\u884c\u4e2d\u7684\u8bed\u4e49\u9519\u8bef\u3002", "motivation": "\u4ee3\u7406\u7cfb\u7edf\u8c03\u7528\u5de5\u5177\u65f6\u7ecf\u5e38\u56e0\u5404\u79cd\u8bed\u6cd5\u548c\u8bed\u4e49\u539f\u56e0\u5931\u8d25\uff0c\u4e00\u4e9b\u8bed\u4e49\u9519\u8bef\u53ea\u80fd\u5728\u5206\u6790\u5de5\u5177\u54cd\u5e94\u540e\u624d\u80fd\u8bc6\u522b\u548c\u89e3\u51b3\u3002", "method": "\u7ed3\u5408LLM\u53cd\u601d\u548c\u9886\u57df\u7279\u5b9a\u7684\u68c0\u7d22\u589e\u5f3a\u751f\u6210(RAG)\uff0c\u4f7f\u7528kubectl\u5de5\u5177\u6587\u6863\u548c\u6545\u969c\u6392\u9664\u6587\u6863\u6765\u4fee\u590d\u547d\u4ee4\u9519\u8bef\u3002", "result": "RAG\u53cd\u601d\u4fee\u590d\u4e86kubectl\u547d\u4ee4\uff0c\u4f7f\u6267\u884c\u6210\u529f\u7387\u63d0\u9ad855%\uff0c\u6b63\u786e\u56de\u7b54\u7528\u6237\u67e5\u8be2\u7684\u53ef\u80fd\u6027\u5e73\u5747\u63d0\u9ad836%\u3002\u6545\u969c\u6392\u9664\u6587\u6863\u6bd4\u5b98\u65b9\u6587\u6863\u5e73\u5747\u63d0\u9ad810%\u7684\u6210\u529f\u7387\u3002", "conclusion": "\u7ed3\u5408LLM\u53cd\u601d\u548c\u9886\u57df\u7279\u5b9aRAG\u7684\u65b9\u6cd5\u80fd\u6709\u6548\u4fee\u590d\u5de5\u5177\u8c03\u7528\u4e2d\u7684\u8bed\u4e49\u9519\u8bef\uff0c\u663e\u8457\u63d0\u9ad8\u547d\u4ee4\u6267\u884c\u6210\u529f\u7387\u548c\u95ee\u9898\u89e3\u51b3\u51c6\u786e\u6027\u3002"}}
{"id": "2510.18586", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2510.18586", "abs": "https://arxiv.org/abs/2510.18586", "authors": ["Zhuohang Bian", "Feiyang Wu", "Teng Ma", "Youwei Zhuo"], "title": "Tokencake: A KV-Cache-centric Serving Framework for LLM-based Multi-Agent Applications", "comment": null, "summary": "Large Language Models (LLMs) are increasingly deployed in complex multi-agent\napplications that use external function calls. This workload creates severe\nperformance challenges for the KV Cache: space contention leads to the eviction\nof critical agents' caches and time underutilization leaves the cache of agents\nstalled on long-running tool calls idling in GPU memory. We present Tokencake,\na KV-Cache-centric serving framework that co-optimizes scheduling and memory\nmanagement with an agent-aware design. Tokencake's Space Scheduler uses dynamic\nmemory partitioning to shield critical agents from contention, while its Time\nScheduler employs a proactive offload and predictive upload mechanism to\nrepurpose GPU memory during function call stalls. Our evaluation on\nrepresentative multi-agent benchmarks shows that Tokencake can reduce\nend-to-end latency by over 47.06%, improve effective GPU memory utilization by\nup to 16.9% compared to vLLM.", "AI": {"tldr": "Tokencake\u662f\u4e00\u4e2a\u9488\u5bf9\u591a\u667a\u80fd\u4f53\u5e94\u7528\u7684KV\u7f13\u5b58\u4f18\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u7a7a\u95f4\u8c03\u5ea6\u548c\u65f6\u95f4\u8c03\u5ea6\u89e3\u51b3\u7f13\u5b58\u4e89\u7528\u548cGPU\u5185\u5b58\u5229\u7528\u7387\u4f4e\u7684\u95ee\u9898\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u591a\u667a\u80fd\u4f53\u5e94\u7528\u4e2d\u9762\u4e34KV\u7f13\u5b58\u7684\u6027\u80fd\u6311\u6218\uff1a\u7a7a\u95f4\u4e89\u7528\u5bfc\u81f4\u5173\u952e\u667a\u80fd\u4f53\u7f13\u5b58\u88ab\u9a71\u9010\uff0c\u65f6\u95f4\u5229\u7528\u7387\u4f4e\u5bfc\u81f4\u7b49\u5f85\u5916\u90e8\u51fd\u6570\u8c03\u7528\u7684\u667a\u80fd\u4f53\u7f13\u5b58\u95f2\u7f6e\u3002", "method": "\u91c7\u7528\u667a\u80fd\u4f53\u611f\u77e5\u8bbe\u8ba1\uff0c\u7a7a\u95f4\u8c03\u5ea6\u5668\u4f7f\u7528\u52a8\u6001\u5185\u5b58\u5206\u533a\u4fdd\u62a4\u5173\u952e\u667a\u80fd\u4f53\uff0c\u65f6\u95f4\u8c03\u5ea6\u5668\u4f7f\u7528\u4e3b\u52a8\u5378\u8f7d\u548c\u9884\u6d4b\u6027\u4e0a\u4f20\u673a\u5236\u5728\u51fd\u6570\u8c03\u7528\u505c\u6ede\u671f\u95f4\u91cd\u65b0\u5229\u7528GPU\u5185\u5b58\u3002", "result": "\u5728\u4ee3\u8868\u6027\u591a\u667a\u80fd\u4f53\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u76f8\u6bd4vLLM\uff0cTokencake\u80fd\u5c06\u7aef\u5230\u7aef\u5ef6\u8fdf\u964d\u4f4e\u8d85\u8fc747.06%\uff0cGPU\u5185\u5b58\u6709\u6548\u5229\u7528\u7387\u63d0\u5347\u9ad8\u8fbe16.9%\u3002", "conclusion": "Tokencake\u901a\u8fc7\u534f\u540c\u4f18\u5316\u8c03\u5ea6\u548c\u5185\u5b58\u7ba1\u7406\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u591a\u667a\u80fd\u4f53\u5e94\u7528\u4e2dKV\u7f13\u5b58\u7684\u6027\u80fd\u74f6\u9888\u95ee\u9898\u3002"}}
{"id": "2510.17891", "categories": ["cs.SE", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.17891", "abs": "https://arxiv.org/abs/2510.17891", "authors": ["Jiin Woo", "Shaowei Zhu", "Allen Nie", "Zhen Jia", "Yida Wang", "Youngsuk Park"], "title": "TritonRL: Training LLMs to Think and Code Triton Without Cheating", "comment": null, "summary": "With the rapid evolution of large language models (LLMs), the demand for\nautomated, high-performance system kernels has emerged as a key enabler for\naccelerating development and deployment. We introduce TritonRL, a\ndomain-specialized LLM for Triton kernel generation, trained with a novel\ntraining framework that enables robust and automated kernel synthesis. Unlike\ngeneral-purpose programming languages, Triton kernel generation faces unique\nchallenges due to data scarcity and incomplete evaluation criteria, vulnerable\nto reward hacking. Our approach addresses these challenges end-to-end by\ndistilling Triton-specific knowledge through supervised fine-tuning on curated\ndatasets, and further improving code quality via reinforcement learning (RL)\nwith robust, verifiable rewards and hierarchical reward assignment. Our RL\nframework robustly detects reward hacking and guides both reasoning traces and\ncode tokens through fine-grained verification and hierarchical reward\ndecomposition, enabling the model to generate high-quality Triton kernels that\ncan truly replace existing modules. With robust and fine-grained evaluation,\nour experiments on KernelBench demonstrate that TritonRL achieves\nstate-of-the-art correctness and speedup, surpassing all other Triton-specific\nmodels and underscoring the effectiveness of our RL-based training paradigm.", "AI": {"tldr": "TritonRL\u662f\u4e00\u4e2a\u4e13\u95e8\u7528\u4e8eTriton\u5185\u6838\u751f\u6210\u7684\u9886\u57df\u4e13\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u901a\u8fc7\u76d1\u7763\u5fae\u8c03\u548c\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u6846\u67b6\uff0c\u80fd\u591f\u751f\u6210\u9ad8\u8d28\u91cf\u7684\u53ef\u66ff\u4ee3\u73b0\u6709\u6a21\u5757\u7684Triton\u5185\u6838\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5feb\u901f\u53d1\u5c55\uff0c\u5bf9\u81ea\u52a8\u5316\u9ad8\u6027\u80fd\u7cfb\u7edf\u5185\u6838\u7684\u9700\u6c42\u6210\u4e3a\u52a0\u901f\u5f00\u53d1\u548c\u90e8\u7f72\u7684\u5173\u952e\u63a8\u52a8\u56e0\u7d20\u3002Triton\u5185\u6838\u751f\u6210\u9762\u4e34\u6570\u636e\u7a00\u7f3a\u548c\u8bc4\u4f30\u6807\u51c6\u4e0d\u5b8c\u6574\u7b49\u72ec\u7279\u6311\u6218\uff0c\u5bb9\u6613\u53d7\u5230\u5956\u52b1\u653b\u51fb\u3002", "method": "\u901a\u8fc7\u76d1\u7763\u5fae\u8c03\u5728\u7cbe\u9009\u6570\u636e\u96c6\u4e0a\u84b8\u998fTriton\u7279\u5b9a\u77e5\u8bc6\uff0c\u7136\u540e\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u6539\u8fdb\u4ee3\u7801\u8d28\u91cf\uff0c\u4f7f\u7528\u7a33\u5065\u53ef\u9a8c\u8bc1\u7684\u5956\u52b1\u548c\u5206\u5c42\u5956\u52b1\u5206\u914d\uff0c\u901a\u8fc7\u7ec6\u7c92\u5ea6\u9a8c\u8bc1\u548c\u5206\u5c42\u5956\u52b1\u5206\u89e3\u6307\u5bfc\u63a8\u7406\u8f68\u8ff9\u548c\u4ee3\u7801\u6807\u8bb0\u3002", "result": "\u5728KernelBench\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cTritonRL\u5728\u6b63\u786e\u6027\u548c\u52a0\u901f\u65b9\u9762\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u6c34\u5e73\uff0c\u8d85\u8d8a\u4e86\u6240\u6709\u5176\u4ed6Triton\u4e13\u7528\u6a21\u578b\u3002", "conclusion": "\u8be5\u7814\u7a76\u8bc1\u660e\u4e86\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u8bad\u7ec3\u8303\u5f0f\u7684\u6709\u6548\u6027\uff0c\u80fd\u591f\u751f\u6210\u771f\u6b63\u53ef\u66ff\u4ee3\u73b0\u6709\u6a21\u5757\u7684\u9ad8\u8d28\u91cfTriton\u5185\u6838\u3002"}}
{"id": "2510.18592", "categories": ["cs.DC", "cs.DS"], "pdf": "https://arxiv.org/pdf/2510.18592", "abs": "https://arxiv.org/abs/2510.18592", "authors": ["Yuval Gil", "Merav Parter"], "title": "Distributed Interactive Proofs for Planarity with Log-Star Communication", "comment": "To appear in SODA 26", "summary": "We provide new communication-efficient distributed interactive proofs for\nplanarity. The notion of a \\emph{distributed interactive proof (DIP)} was\nintroduced by Kol, Oshman, and Saxena (PODC 2018). In a DIP, the \\emph{prover}\nis a single centralized entity whose goal is to prove a certain claim regarding\nan input graph $G$. To do so, the prover communicates with a distributed\n\\emph{verifier} that operates concurrently on all $n$ nodes of $G$. A DIP is\nmeasured by the amount of prover-verifier communication it requires. Namely,\nthe goal is to design a DIP with a small number of interaction rounds and a\nsmall \\emph{proof size}, i.e., a small amount of communication per round. Our\nmain result is an $O(\\log ^{*}n)$-round DIP protocol for embedded planarity and\nplanarity with a proof size of $O(1)$ and $O(\\lceil\\log \\Delta/\\log\n^{*}n\\rceil)$, respectively. In fact, this result can be generalized as\nfollows. For any $1\\leq r\\leq \\log^{*}n$, there exists an $O(r)$-round protocol\nfor embedded planarity and planarity with a proof size of $O(\\log ^{(r)}n)$ and\n$O(\\log ^{(r)}n+\\log \\Delta /r)$, respectively.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u65b0\u7684\u901a\u4fe1\u9ad8\u6548\u7684\u5206\u5e03\u5f0f\u4ea4\u4e92\u8bc1\u660e\u534f\u8bae\u7528\u4e8e\u5e73\u9762\u6027\u9a8c\u8bc1\uff0c\u5b9e\u73b0\u4e86O(log* n)\u8f6e\u4ea4\u4e92\u548cO(1)\u8bc1\u660e\u5927\u5c0f\u7684\u5d4c\u5165\u5f0f\u5e73\u9762\u6027\u9a8c\u8bc1\u3002", "motivation": "\u5206\u5e03\u5f0f\u4ea4\u4e92\u8bc1\u660e(DIP)\u7531Kol\u7b49\u4eba\u5f15\u5165\uff0c\u65e8\u5728\u901a\u8fc7\u96c6\u4e2d\u5f0f\u8bc1\u660e\u8005\u4e0e\u5206\u5e03\u5f0f\u9a8c\u8bc1\u8005\u4e4b\u95f4\u7684\u9ad8\u6548\u901a\u4fe1\u6765\u9a8c\u8bc1\u56fe\u7684\u6027\u8d28\uff0c\u76ee\u6807\u662f\u51cf\u5c11\u4ea4\u4e92\u8f6e\u6b21\u548c\u8bc1\u660e\u5927\u5c0f\u3002", "method": "\u8bbe\u8ba1\u4e86\u591a\u8f6e\u4ea4\u4e92\u534f\u8bae\uff0c\u5bf9\u4e8e\u5d4c\u5165\u5f0f\u5e73\u9762\u6027\u548c\u4e00\u822c\u5e73\u9762\u6027\u9a8c\u8bc1\uff0c\u5206\u522b\u5b9e\u73b0\u4e86O(log* n)\u8f6e\u4ea4\u4e92\u548cO(1)\u6216O(\u2308log \u0394/log* n\u2309)\u7684\u8bc1\u660e\u5927\u5c0f\uff0c\u5e76\u53ef\u63a8\u5e7f\u5230\u4efb\u610f1\u2264r\u2264log* n\u8f6e\u6b21\u3002", "result": "\u5b9e\u73b0\u4e86\u5d4c\u5165\u5f0f\u5e73\u9762\u6027\u7684O(log* n)\u8f6eDIP\u534f\u8bae\uff0c\u8bc1\u660e\u5927\u5c0f\u4e3aO(1)\uff1b\u4e00\u822c\u5e73\u9762\u6027\u7684\u8bc1\u660e\u5927\u5c0f\u4e3aO(\u2308log \u0394/log* n\u2309)\u3002\u534f\u8bae\u53ef\u7075\u6d3b\u8c03\u6574\u8f6e\u6b21\u4e0e\u8bc1\u660e\u5927\u5c0f\u7684\u6743\u8861\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u663e\u8457\u6539\u8fdb\u4e86\u5e73\u9762\u6027\u9a8c\u8bc1\u7684\u5206\u5e03\u5f0f\u4ea4\u4e92\u8bc1\u660e\u6548\u7387\uff0c\u4e3a\u56fe\u6027\u8d28\u9a8c\u8bc1\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u7684\u901a\u4fe1\u534f\u8bae\u6846\u67b6\u3002"}}
{"id": "2510.17894", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.17894", "abs": "https://arxiv.org/abs/2510.17894", "authors": ["Yunhan Qiao", "Md Istiak Hossain Shihab", "Christopher Hundhausen"], "title": "A Systematic Literature Review of the Use of GenAI Assistants for Code Comprehension: Implications for Computing Education Research and Practice", "comment": null, "summary": "The ability to comprehend code has long been recognized as an essential skill\nin software engineering. As programmers lean more heavily on generative\nartificial intelligence (GenAI) assistants to develop code solutions, it is\nbecoming increasingly important for programmers to comprehend GenAI solutions\nso that they can verify their appropriateness and properly integrate them into\nexisting code. At the same time, GenAI tools are increasingly being enlisted to\nprovide programmers with tailored explanations of code written both by GenAI\nand humans. Thus, in computing education, GenAI presents new challenges and\nopportunities for learners who are trying to comprehend computer programs. To\nprovide computing educators with evidence-based guidance on the use of GenAI to\nfacilitate code comprehension and to identify directions for future research,\nwe present a systematic literature review (SLR) of state-of-the-art approaches\nand tools that leverage GenAI to enhance code comprehension. Our SLR focuses on\n31 studies published between 2022 and 2024. Despite their potential, GenAI\nassistants often yield inaccurate or unclear explanations, and novice\nprogrammers frequently struggle to craft effective prompts, thereby impeding\ntheir ability to leverage GenAI to aid code comprehension. Our review\nclassifies GenAI-based approaches and tools, identifies methods used to study\nthem, and summarizes the empirical evaluations of their effectiveness. We\nconsider the implications of our findings for computing education research and\npractice, and identify directions for future research.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u901a\u8fc7\u7cfb\u7edf\u6587\u732e\u7efc\u8ff0\u5206\u6790\u4e862022-2024\u5e74\u95f431\u9879\u7814\u7a76\uff0c\u63a2\u8ba8\u4e86GenAI\u5728\u4ee3\u7801\u7406\u89e3\u4e2d\u7684\u5e94\u7528\uff0c\u53d1\u73b0\u867d\u7136GenAI\u5de5\u5177\u6709\u6f5c\u529b\uff0c\u4f46\u5e38\u4ea7\u751f\u4e0d\u51c6\u786e\u6216\u6a21\u7cca\u7684\u89e3\u91ca\uff0c\u4e14\u65b0\u624b\u7a0b\u5e8f\u5458\u96be\u4ee5\u8bbe\u8ba1\u6709\u6548\u63d0\u793a\u3002", "motivation": "\u968f\u7740\u7a0b\u5e8f\u5458\u8d8a\u6765\u8d8a\u591a\u5730\u4f9d\u8d56GenAI\u52a9\u624b\u5f00\u53d1\u4ee3\u7801\u89e3\u51b3\u65b9\u6848\uff0c\u7406\u89e3GenAI\u751f\u6210\u7684\u4ee3\u7801\u53d8\u5f97\u81f3\u5173\u91cd\u8981\uff0c\u540c\u65f6GenAI\u5de5\u5177\u4e5f\u88ab\u7528\u4e8e\u63d0\u4f9b\u4ee3\u7801\u89e3\u91ca\u3002\u5728\u8ba1\u7b97\u6559\u80b2\u4e2d\uff0cGenAI\u4e3a\u5b66\u4e60\u8005\u7406\u89e3\u7a0b\u5e8f\u5e26\u6765\u4e86\u65b0\u7684\u6311\u6218\u548c\u673a\u9047\u3002", "method": "\u91c7\u7528\u7cfb\u7edf\u6587\u732e\u7efc\u8ff0\u65b9\u6cd5\uff0c\u5bf92022-2024\u5e74\u95f4\u53d1\u8868\u768431\u9879\u7814\u7a76\u8fdb\u884c\u5206\u6790\uff0c\u5206\u7c7b\u57fa\u4e8eGenAI\u7684\u65b9\u6cd5\u548c\u5de5\u5177\uff0c\u8bc6\u522b\u7814\u7a76\u65b9\u6cd5\uff0c\u5e76\u603b\u7ed3\u5176\u6709\u6548\u6027\u7684\u5b9e\u8bc1\u8bc4\u4f30\u3002", "result": "\u7814\u7a76\u53d1\u73b0GenAI\u52a9\u624b\u7ecf\u5e38\u4ea7\u751f\u4e0d\u51c6\u786e\u6216\u4e0d\u6e05\u695a\u7684\u89e3\u91ca\uff0c\u65b0\u624b\u7a0b\u5e8f\u5458\u5728\u5236\u4f5c\u6709\u6548\u63d0\u793a\u65b9\u9762\u5b58\u5728\u56f0\u96be\uff0c\u8fd9\u963b\u788d\u4e86\u4ed6\u4eec\u5229\u7528GenAI\u8f85\u52a9\u4ee3\u7801\u7406\u89e3\u7684\u80fd\u529b\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u4e3a\u8ba1\u7b97\u6559\u80b2\u5de5\u4f5c\u8005\u63d0\u4f9b\u4e86\u57fa\u4e8e\u8bc1\u636e\u7684\u6307\u5bfc\uff0c\u4ee5\u4f7f\u7528GenAI\u4fc3\u8fdb\u4ee3\u7801\u7406\u89e3\uff0c\u5e76\u786e\u5b9a\u4e86\u672a\u6765\u7814\u7a76\u7684\u65b9\u5411\u3002"}}
{"id": "2510.18640", "categories": ["cs.DC", "cs.SE"], "pdf": "https://arxiv.org/pdf/2510.18640", "abs": "https://arxiv.org/abs/2510.18640", "authors": ["Nils Japke", "Sebastian Koch", "Helmut Lukasczyk", "David Bermbach"], "title": "Towards an Optimized Benchmarking Platform for CI/CD Pipelines", "comment": "Published in 2025 IEEE International Conference on Cloud Engineering\n  (IC2E)", "summary": "Performance regressions in large-scale software systems can lead to\nsubstantial resource inefficiencies, making their early detection critical.\nFrequent benchmarking is essential for identifying these regressions and\nmaintaining service-level agreements (SLAs). Performance benchmarks, however,\nare resource-intensive and time-consuming, which is a major challenge for\nintegration into Continuous Integration / Continuous Deployment (CI/CD)\npipelines. Although numerous benchmark optimization techniques have been\nproposed to accelerate benchmark execution, there is currently no practical\nsystem that integrates these optimizations seamlessly into real-world CI/CD\npipelines. In this vision paper, we argue that the field of benchmark\noptimization remains under-explored in key areas that hinder its broader\nadoption. We identify three central challenges to enabling frequent and\nefficient benchmarking: (a) the composability of benchmark optimization\nstrategies, (b) automated evaluation of benchmarking results, and (c) the\nusability and complexity of applying these strategies as part of CI/CD systems\nin practice. We also introduce a conceptual cloud-based benchmarking framework\nhandling these challenges transparently. By presenting these open problems, we\naim to stimulate research toward making performance regression detection in\nCI/CD systems more practical and effective.", "AI": {"tldr": "\u6027\u80fd\u57fa\u51c6\u6d4b\u8bd5\u4f18\u5316\u5728CI/CD\u7cfb\u7edf\u4e2d\u7684\u5b9e\u9645\u5e94\u7528\u9762\u4e34\u4e09\u5927\u6311\u6218\uff1a\u4f18\u5316\u7b56\u7565\u7684\u53ef\u7ec4\u5408\u6027\u3001\u81ea\u52a8\u5316\u8bc4\u4f30\u4ee5\u53ca\u5b9e\u9645\u5e94\u7528\u590d\u6742\u6027\uff0c\u9700\u8981\u7814\u7a76\u89e3\u51b3\u4ee5\u63d0\u5347\u6027\u80fd\u56de\u5f52\u68c0\u6d4b\u7684\u5b9e\u7528\u6027\u3002", "motivation": "\u5927\u89c4\u6a21\u8f6f\u4ef6\u7cfb\u7edf\u4e2d\u7684\u6027\u80fd\u56de\u5f52\u4f1a\u5bfc\u81f4\u4e25\u91cd\u7684\u8d44\u6e90\u6548\u7387\u95ee\u9898\uff0c\u4f46\u9891\u7e41\u7684\u57fa\u51c6\u6d4b\u8bd5\u5728CI/CD\u6d41\u6c34\u7ebf\u4e2d\u9762\u4e34\u8d44\u6e90\u5bc6\u96c6\u548c\u65f6\u95f4\u6d88\u8017\u7684\u6311\u6218\uff0c\u73b0\u6709\u4f18\u5316\u6280\u672f\u7f3a\u4e4f\u5b9e\u9645\u96c6\u6210\u65b9\u6848\u3002", "method": "\u8bc6\u522b\u4e86\u4e09\u4e2a\u6838\u5fc3\u6311\u6218\uff1a\u57fa\u51c6\u6d4b\u8bd5\u4f18\u5316\u7b56\u7565\u7684\u53ef\u7ec4\u5408\u6027\u3001\u57fa\u51c6\u6d4b\u8bd5\u7ed3\u679c\u7684\u81ea\u52a8\u5316\u8bc4\u4f30\u3001\u4ee5\u53ca\u5728\u5b9e\u9645CI/CD\u7cfb\u7edf\u4e2d\u5e94\u7528\u8fd9\u4e9b\u7b56\u7565\u7684\u53ef\u7528\u6027\u548c\u590d\u6742\u6027\u3002\u63d0\u51fa\u4e86\u4e00\u4e2a\u6982\u5ff5\u6027\u7684\u4e91\u57fa\u51c6\u6d4b\u8bd5\u6846\u67b6\u6765\u5904\u7406\u8fd9\u4e9b\u6311\u6218\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u6982\u5ff5\u6846\u67b6\uff0c\u4f46\u5c1a\u672a\u5b9e\u73b0\u5177\u4f53\u7cfb\u7edf\u3002\u4e3b\u8981\u8d21\u732e\u662f\u660e\u786e\u4e86\u963b\u788d\u57fa\u51c6\u6d4b\u8bd5\u4f18\u5316\u6280\u672f\u5e7f\u6cdb\u91c7\u7528\u7684\u5173\u952e\u95ee\u9898\u9886\u57df\u3002", "conclusion": "\u57fa\u51c6\u6d4b\u8bd5\u4f18\u5316\u9886\u57df\u5728\u5173\u952e\u65b9\u9762\u4ecd\u672a\u88ab\u5145\u5206\u63a2\u7d22\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u6765\u89e3\u51b3\u5df2\u8bc6\u522b\u7684\u6311\u6218\uff0c\u4f7fCI/CD\u7cfb\u7edf\u4e2d\u7684\u6027\u80fd\u56de\u5f52\u68c0\u6d4b\u66f4\u52a0\u5b9e\u7528\u548c\u6709\u6548\u3002"}}
{"id": "2510.17925", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.17925", "abs": "https://arxiv.org/abs/2510.17925", "authors": ["George Ma", "Anurag Koul", "Qi Chen", "Yawen Wu", "Sachit Kuhar", "Yu Yu", "Aritra Sengupta", "Varun Kumar", "Murali Krishna Ramanathan"], "title": "SpecAgent: A Speculative Retrieval and Forecasting Agent for Code Completion", "comment": null, "summary": "Large Language Models (LLMs) excel at code-related tasks but often struggle\nin realistic software repositories, where project-specific APIs and cross-file\ndependencies are crucial. Retrieval-augmented methods mitigate this by\ninjecting repository context at inference time. The low inference-time latency\nbudget affects either retrieval quality or the added latency adversely impacts\nuser experience. We address this limitation with SpecAgent, an agent that\nimproves both latency and code-generation quality by proactively exploring\nrepository files during indexing and constructing speculative context that\nanticipates future edits in each file. This indexing-time asynchrony allows\nthorough context computation, masking latency, and the speculative nature of\nthe context improves code-generation quality. Additionally, we identify the\nproblem of future context leakage in existing benchmarks, which can inflate\nreported performance. To address this, we construct a synthetic, leakage-free\nbenchmark that enables a more realistic evaluation of our agent against\nbaselines. Experiments show that SpecAgent consistently achieves absolute gains\nof 9-11% (48-58% relative) compared to the best-performing baselines, while\nsignificantly reducing inference latency.", "AI": {"tldr": "SpecAgent\u901a\u8fc7\u7d22\u5f15\u65f6\u5f02\u6b65\u63a2\u7d22\u4ed3\u5e93\u6587\u4ef6\u6784\u5efa\u63a8\u6d4b\u6027\u4e0a\u4e0b\u6587\uff0c\u5728\u964d\u4f4e\u63a8\u7406\u5ef6\u8fdf\u7684\u540c\u65f6\u63d0\u5347\u4ee3\u7801\u751f\u6210\u8d28\u91cf\uff0c\u76f8\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u83b7\u5f979-11%\u7684\u7edd\u5bf9\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u771f\u5b9e\u8f6f\u4ef6\u4ed3\u5e93\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u56e0\u4e3a\u9879\u76ee\u7279\u5b9aAPI\u548c\u8de8\u6587\u4ef6\u4f9d\u8d56\u5173\u7cfb\u81f3\u5173\u91cd\u8981\u3002\u68c0\u7d22\u589e\u5f3a\u65b9\u6cd5\u5728\u63a8\u7406\u65f6\u6ce8\u5165\u4ed3\u5e93\u4e0a\u4e0b\u6587\uff0c\u4f46\u4f4e\u5ef6\u8fdf\u9884\u7b97\u4f1a\u5f71\u54cd\u68c0\u7d22\u8d28\u91cf\u6216\u7528\u6237\u4f53\u9a8c\u3002", "method": "SpecAgent\u5728\u7d22\u5f15\u65f6\u4e3b\u52a8\u63a2\u7d22\u4ed3\u5e93\u6587\u4ef6\uff0c\u6784\u5efa\u63a8\u6d4b\u6027\u4e0a\u4e0b\u6587\u6765\u9884\u6d4b\u6bcf\u4e2a\u6587\u4ef6\u4e2d\u7684\u672a\u6765\u7f16\u8f91\u3002\u8fd9\u79cd\u7d22\u5f15\u65f6\u5f02\u6b65\u6027\u5141\u8bb8\u5145\u5206\u8ba1\u7b97\u4e0a\u4e0b\u6587\uff0c\u63a9\u76d6\u5ef6\u8fdf\uff0c\u63a8\u6d4b\u6027\u4e0a\u4e0b\u6587\u63d0\u5347\u4ee3\u7801\u751f\u6210\u8d28\u91cf\u3002", "result": "\u5b9e\u9a8c\u663e\u793aSpecAgent\u76f8\u6bd4\u6700\u4f73\u57fa\u7ebf\u65b9\u6cd5\u83b7\u5f979-11%\u7684\u7edd\u5bf9\u6027\u80fd\u63d0\u5347\uff0848-58%\u76f8\u5bf9\u63d0\u5347\uff09\uff0c\u540c\u65f6\u663e\u8457\u964d\u4f4e\u63a8\u7406\u5ef6\u8fdf\u3002", "conclusion": "SpecAgent\u901a\u8fc7\u7d22\u5f15\u65f6\u5f02\u6b65\u6784\u5efa\u63a8\u6d4b\u6027\u4e0a\u4e0b\u6587\u7684\u65b9\u6cd5\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u4ee3\u7801\u751f\u6210\u4e2d\u7684\u5ef6\u8fdf\u548c\u8d28\u91cf\u6743\u8861\u95ee\u9898\uff0c\u5e76\u5728\u65e0\u6cc4\u6f0f\u57fa\u51c6\u4e0a\u9a8c\u8bc1\u4e86\u5176\u4f18\u8d8a\u6027\u80fd\u3002"}}
{"id": "2510.18838", "categories": ["cs.DC", "physics.comp-ph", "physics.plasm-ph"], "pdf": "https://arxiv.org/pdf/2510.18838", "abs": "https://arxiv.org/abs/2510.18838", "authors": ["Jacob S. Merson", "Cameron W. Smith", "Mark S. Shephard", "Fuad Hasan", "Abhiyan Paudel", "Angel Castillo-Crooke", "Joyal Mathew", "Mohammad Elahi"], "title": "PCMS: Parallel Coupler For Multimodel Simulations", "comment": null, "summary": "This paper presents the Parallel Coupler for Multimodel Simulations (PCMS), a\nnew GPU accelerated generalized coupling framework for coupling simulation\ncodes on leadership class supercomputers. PCMS includes distributed control and\nfield mapping methods for up to five dimensions. For field mapping PCMS can\nutilize discretization and field information to accommodate physics\nconstraints. PCMS is demonstrated with a coupling of the gyrokinetic\nmicroturbulence code XGC with a Monte Carlo neutral transport code DEGAS2 and\nwith a 5D distribution function coupling of an energetic particle transport\ncode (GNET) to a gyrokinetic microturbulence code (GTC). Weak scaling is also\ndemonstrated on up to 2,080 GPUs of Frontier with a weak scaling efficiency of\n85%.", "AI": {"tldr": "PCMS\u662f\u4e00\u4e2a\u65b0\u7684GPU\u52a0\u901f\u901a\u7528\u8026\u5408\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u8d85\u7ea7\u8ba1\u7b97\u673a\u4e0a\u8026\u5408\u6a21\u62df\u4ee3\u7801\uff0c\u652f\u6301\u4e94\u7ef4\u5206\u5e03\u5f0f\u63a7\u5236\u548c\u573a\u6620\u5c04\u65b9\u6cd5\uff0c\u5728Frontier\u8d85\u7ea7\u8ba1\u7b97\u673a\u76842080\u4e2aGPU\u4e0a\u5c55\u793a\u4e8685%\u7684\u5f31\u6269\u5c55\u6548\u7387\u3002", "motivation": "\u5f00\u53d1\u4e00\u4e2a\u80fd\u591f\u5728\u9886\u5bfc\u7ea7\u8d85\u7ea7\u8ba1\u7b97\u673a\u4e0a\u9ad8\u6548\u8026\u5408\u4e0d\u540c\u6a21\u62df\u4ee3\u7801\u7684\u901a\u7528\u6846\u67b6\uff0c\u4ee5\u652f\u6301\u590d\u6742\u7684\u591a\u7269\u7406\u573a\u6a21\u62df\u9700\u6c42\u3002", "method": "PCMS\u6846\u67b6\u5305\u62ec\u5206\u5e03\u5f0f\u63a7\u5236\u548c\u573a\u6620\u5c04\u65b9\u6cd5\uff0c\u652f\u6301\u591a\u8fbe\u4e94\u7ef4\u7684\u8026\u5408\uff0c\u80fd\u591f\u5229\u7528\u79bb\u6563\u5316\u548c\u573a\u4fe1\u606f\u6765\u9002\u5e94\u7269\u7406\u7ea6\u675f\uff0c\u5e76\u901a\u8fc7GPU\u52a0\u901f\u63d0\u9ad8\u6027\u80fd\u3002", "result": "\u6210\u529f\u6f14\u793a\u4e86XGC\u4e0eDEGAS2\u7684\u8026\u5408\uff0c\u4ee5\u53caGNET\u4e0eGTC\u7684\u4e94\u7ef4\u5206\u5e03\u51fd\u6570\u8026\u5408\uff0c\u5728Frontier\u76842080\u4e2aGPU\u4e0a\u5b9e\u73b0\u4e8685%\u7684\u5f31\u6269\u5c55\u6548\u7387\u3002", "conclusion": "PCMS\u662f\u4e00\u4e2a\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u7684\u8026\u5408\u6846\u67b6\uff0c\u80fd\u591f\u652f\u6301\u590d\u6742\u7684\u591a\u6a21\u578b\u6a21\u62df\uff0c\u5728\u9886\u5bfc\u7ea7\u8d85\u7ea7\u8ba1\u7b97\u673a\u4e0a\u8868\u73b0\u51fa\u826f\u597d\u7684\u6027\u80fd\u3002"}}
{"id": "2510.17932", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.17932", "abs": "https://arxiv.org/abs/2510.17932", "authors": ["Jiahao Tang", "Henry Hengyuan Zhao", "Lijian Wu", "Yifei Tao", "Dongxing Mao", "Yang Wan", "Jingru Tan", "Min Zeng", "Min Li", "Alex Jinpeng Wang"], "title": "From Charts to Code: A Hierarchical Benchmark for Multimodal Models", "comment": null, "summary": "We introduce Chart2Code, a new benchmark for evaluating the chart\nunderstanding and code generation capabilities of large multimodal models\n(LMMs). Chart2Code is explicitly designed from a user-driven perspective,\ncapturing diverse real-world scenarios and progressively increasing task\ndifficulty. It consists of three levels: Level 1 (Chart Reproduction)\nreproduces charts from a reference figure and user query; Level 2 (Chart\nEditing) involves complex modifications such as changing chart types or adding\nelements; and Level 3 (Long-Table to Chart Generation) requires models to\ntransform long, information-dense tables into faithful charts following user\ninstructions. To our knowledge, this is the first hierarchical benchmark that\nreflects practical chart2code usage while systematically scaling task\ncomplexity. In total, Chart2Code contains 2,023 tasks across 22 chart types,\npaired with multi-level evaluation metrics that assess both code correctness\nand the visual fidelity of rendered charts. We benchmark 25 state-of-the-art\n(SoTA) LMMs, including both proprietary and the latest open-source models such\nas GPT-5, Qwen2.5-VL, InternVL3/3.5, MiMo-VL, and Seed-1.6-VL. Experimental\nresults demonstrate that even the SoTA model GPT-5 averages only 0.57 on\ncode-based evaluation and 0.22 on chart-quality assessment across the editing\ntasks, underscoring the difficulty of Chart2Code. We anticipate this benchmark\nwill drive advances in multimodal reasoning and foster the development of more\nrobust and general-purpose LMMs. Our code and data are available on Chart2Code.", "AI": {"tldr": "Chart2Code\u662f\u4e00\u4e2a\u65b0\u7684\u591a\u6a21\u6001\u6a21\u578b\u8bc4\u4f30\u57fa\u51c6\uff0c\u4e13\u6ce8\u4e8e\u56fe\u8868\u7406\u89e3\u548c\u4ee3\u7801\u751f\u6210\u80fd\u529b\uff0c\u5305\u542b\u4e09\u4e2a\u96be\u5ea6\u9012\u589e\u7684\u4efb\u52a1\u7ea7\u522b\u548c2023\u4e2a\u4efb\u52a1\uff0c\u8bc4\u4f3025\u4e2a\u6700\u5148\u8fdb\u6a21\u578b\u3002", "motivation": "\u4ece\u7528\u6237\u9a71\u52a8\u89d2\u5ea6\u8bbe\u8ba1\uff0c\u6355\u6349\u771f\u5b9e\u4e16\u754c\u573a\u666f\uff0c\u7cfb\u7edf\u6027\u5730\u589e\u52a0\u4efb\u52a1\u96be\u5ea6\uff0c\u586b\u8865\u73b0\u6709\u57fa\u51c6\u5728\u56fe\u8868\u5230\u4ee3\u7801\u8f6c\u6362\u8bc4\u4f30\u65b9\u9762\u7684\u7a7a\u767d\u3002", "method": "\u6784\u5efa\u5305\u542b\u4e09\u4e2a\u5c42\u6b21\u7684\u4efb\u52a1\uff1a\u56fe\u8868\u590d\u5236\u3001\u56fe\u8868\u7f16\u8f91\u548c\u957f\u8868\u683c\u5230\u56fe\u8868\u751f\u6210\uff0c\u6db5\u76d622\u79cd\u56fe\u8868\u7c7b\u578b\uff0c\u4f7f\u7528\u591a\u7ea7\u8bc4\u4f30\u6307\u6807\u8bc4\u4f30\u4ee3\u7801\u6b63\u786e\u6027\u548c\u89c6\u89c9\u4fdd\u771f\u5ea6\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u5373\u4f7f\u662f\u5f53\u524d\u6700\u5148\u8fdb\u7684GPT-5\u6a21\u578b\u5728\u7f16\u8f91\u4efb\u52a1\u4e0a\u7684\u5e73\u5747\u5f97\u5206\u4e5f\u4ec5\u4e3a0.57\uff08\u57fa\u4e8e\u4ee3\u7801\uff09\u548c0.22\uff08\u57fa\u4e8e\u56fe\u8868\u8d28\u91cf\uff09\uff0c\u8868\u660e\u8be5\u57fa\u51c6\u5177\u6709\u6311\u6218\u6027\u3002", "conclusion": "Chart2Code\u57fa\u51c6\u5c06\u63a8\u52a8\u591a\u6a21\u6001\u63a8\u7406\u7684\u53d1\u5c55\uff0c\u4fc3\u8fdb\u66f4\u9c81\u68d2\u548c\u901a\u7528\u7684\u591a\u6a21\u6001\u6a21\u578b\u7684\u5f00\u53d1\u3002"}}
{"id": "2510.18013", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.18013", "abs": "https://arxiv.org/abs/2510.18013", "authors": ["Yiran Wang", "Jos\u00e9 Antonio Hern\u00e1ndez L\u00f3pez", "Ulf Nilsson", "D\u00e1niel Varr\u00f3"], "title": "JunoBench: A Benchmark Dataset of Crashes in Python Machine Learning Jupyter Notebooks", "comment": null, "summary": "Jupyter notebooks are widely used for machine learning (ML) prototyping. Yet\nfew debugging tools are designed for ML code in notebooks, potentially due to\nthe lack of benchmarks. We introduce JunoBench, the first benchmark dataset of\nreal-world crashes in Python-based ML notebooks. JunoBench has 111 curated and\nreproducible crashes from public Kaggle notebooks, each paired with a\nverifiable fix, ranging over popular ML libraries, including TensorFlow/Keras,\nPyTorch, Scikit-learn, Pandas, and NumPy, as well as notebook-specific\nout-of-order execution issue. To support reproducibility and ease of use,\nJunoBench offers a unified execution environment where crashes and fixes can be\nreliably reproduced. By providing realistic crashes and their resolutions,\nJunoBench facilitates bug detection, localization, and repair tailored to the\ninteractive and iterative nature of notebook-based ML development.", "AI": {"tldr": "JunoBench\u662f\u9996\u4e2a\u9488\u5bf9Python\u673a\u5668\u5b66\u4e60\u7b14\u8bb0\u672c\u4e2d\u771f\u5b9e\u5d29\u6e83\u7684\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u5305\u542b111\u4e2a\u6765\u81eaKaggle\u7b14\u8bb0\u672c\u7684\u7ecf\u8fc7\u6574\u7406\u4e14\u53ef\u590d\u73b0\u7684\u5d29\u6e83\u6848\u4f8b\uff0c\u6bcf\u4e2a\u6848\u4f8b\u90fd\u914d\u6709\u53ef\u9a8c\u8bc1\u7684\u4fee\u590d\u65b9\u6848\uff0c\u6db5\u76d6\u4e3b\u6d41ML\u5e93\u548c\u7b14\u8bb0\u672c\u7279\u6709\u7684\u6267\u884c\u987a\u5e8f\u95ee\u9898\u3002", "motivation": "\u673a\u5668\u5b66\u4e60\u7b14\u8bb0\u672c\uff08\u5982Jupyter\uff09\u5e7f\u6cdb\u7528\u4e8e\u539f\u578b\u5f00\u53d1\uff0c\u4f46\u7f3a\u4e4f\u4e13\u95e8\u9488\u5bf9ML\u4ee3\u7801\u7684\u8c03\u8bd5\u5de5\u5177\uff0c\u4e3b\u8981\u539f\u56e0\u662f\u7f3a\u4e4f\u76f8\u5173\u57fa\u51c6\u6570\u636e\u96c6\u3002", "method": "\u4ece\u516c\u5f00Kaggle\u7b14\u8bb0\u672c\u4e2d\u6536\u96c6\u771f\u5b9e\u5d29\u6e83\u6848\u4f8b\uff0c\u8fdb\u884c\u6574\u7406\u548c\u9a8c\u8bc1\uff0c\u4e3a\u6bcf\u4e2a\u5d29\u6e83\u63d0\u4f9b\u53ef\u590d\u73b0\u7684\u4fee\u590d\u65b9\u6848\uff0c\u5e76\u6784\u5efa\u7edf\u4e00\u7684\u6267\u884c\u73af\u5883\u4ee5\u786e\u4fdd\u53ef\u590d\u73b0\u6027\u3002", "result": "\u521b\u5efa\u4e86\u5305\u542b111\u4e2a\u5d29\u6e83\u6848\u4f8b\u7684JunoBench\u6570\u636e\u96c6\uff0c\u6db5\u76d6TensorFlow/Keras\u3001PyTorch\u3001Scikit-learn\u3001Pandas\u3001NumPy\u7b49\u4e3b\u6d41ML\u5e93\uff0c\u4ee5\u53ca\u7b14\u8bb0\u672c\u7279\u6709\u7684\u6267\u884c\u987a\u5e8f\u95ee\u9898\u3002", "conclusion": "JunoBench\u901a\u8fc7\u63d0\u4f9b\u771f\u5b9e\u7684\u5d29\u6e83\u6848\u4f8b\u53ca\u5176\u89e3\u51b3\u65b9\u6848\uff0c\u4e3a\u57fa\u4e8e\u7b14\u8bb0\u672c\u7684\u4ea4\u4e92\u5f0fML\u5f00\u53d1\u4e2d\u7684\u9519\u8bef\u68c0\u6d4b\u3001\u5b9a\u4f4d\u548c\u4fee\u590d\u63d0\u4f9b\u4e86\u6709\u529b\u652f\u6301\u3002"}}
{"id": "2510.18017", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.18017", "abs": "https://arxiv.org/abs/2510.18017", "authors": ["Mariana Crisostomo Martins", "Lucas Elias Cardoso Rocha", "Lucas Cordeiro Romao", "Taciana Novo Kudo", "Marcos Kalinowski", "Renato de Freitas Bulcao-Neto"], "title": "DIP-AI: A Discovery Framework for AI Innovation Projects", "comment": "Submitted and accepted at SBQS25 - Brazilian Symposium on Software\n  Quality. Presentation from November 4th to 7th, 2025 in Sao Jose dos Campos,\n  SP", "summary": "Despite the increasing development of Artificial Intelligence (AI) systems,\nRequirements Engineering (RE) activities face challenges in this new\ndata-intensive paradigm. We identified a lack of support for problem discovery\nwithin AI innovation projects. To address this, we propose and evaluate DIP-AI,\na discovery framework tailored to guide early-stage exploration in such\ninitiatives. Based on a literature review, our solution proposal combines\nelements of ISO 12207, 5338, and Design Thinking to support the discovery of AI\ninnovation projects, aiming at promoting higher quality deliveries and\nstakeholder satisfaction. We evaluated DIP-AI in an industry-academia\ncollaboration (IAC) case study of an AI innovation project, in which\nparticipants applied DIP-AI to the discovery phase in practice and provided\ntheir perceptions about the approach's problem discovery capability,\nacceptance, and suggestions. The results indicate that DIP-AI is relevant and\nuseful, particularly in facilitating problem discovery in AI projects. This\nresearch contributes to academia by sharing DIP-AI as a framework for AI\nproblem discovery. For industry, we discuss the use of this framework in a real\nIAC program that develops AI innovation projects.", "AI": {"tldr": "\u63d0\u51fa\u4e86DIP-AI\u6846\u67b6\uff0c\u4e13\u95e8\u7528\u4e8e\u6307\u5bfcAI\u521b\u65b0\u9879\u76ee\u7684\u65e9\u671f\u63a2\u7d22\u9636\u6bb5\uff0c\u5e2e\u52a9\u53d1\u73b0\u95ee\u9898\u548c\u9700\u6c42\uff0c\u65e8\u5728\u63d0\u9ad8\u4ea4\u4ed8\u8d28\u91cf\u548c\u5229\u76ca\u76f8\u5173\u8005\u6ee1\u610f\u5ea6\u3002", "motivation": "\u968f\u7740AI\u7cfb\u7edf\u7684\u53d1\u5c55\uff0c\u9700\u6c42\u5de5\u7a0b\u6d3b\u52a8\u5728\u6570\u636e\u5bc6\u96c6\u578b\u8303\u5f0f\u4e0b\u9762\u4e34\u6311\u6218\uff0c\u7279\u522b\u662f\u5728\u95ee\u9898\u53d1\u73b0\u65b9\u9762\u7f3a\u4e4f\u652f\u6301\u3002", "method": "\u57fa\u4e8e\u6587\u732e\u7efc\u8ff0\uff0c\u7ed3\u5408ISO 12207\u30015338\u548c\u8bbe\u8ba1\u601d\u7ef4\u5143\u7d20\uff0c\u63d0\u51fa\u4e86DIP-AI\u53d1\u73b0\u6846\u67b6\uff0c\u5e76\u5728\u4ea7\u4e1a-\u5b66\u672f\u5408\u4f5c\u7684AI\u521b\u65b0\u9879\u76ee\u6848\u4f8b\u7814\u7a76\u4e2d\u8fdb\u884c\u4e86\u8bc4\u4f30\u3002", "result": "\u8bc4\u4f30\u7ed3\u679c\u8868\u660eDIP-AI\u5177\u6709\u76f8\u5173\u6027\u548c\u5b9e\u7528\u6027\uff0c\u7279\u522b\u662f\u5728\u4fc3\u8fdbAI\u9879\u76ee\u95ee\u9898\u53d1\u73b0\u65b9\u9762\u8868\u73b0\u826f\u597d\u3002", "conclusion": "DIP-AI\u6846\u67b6\u4e3aAI\u95ee\u9898\u53d1\u73b0\u63d0\u4f9b\u4e86\u6709\u6548\u652f\u6301\uff0c\u5bf9\u5b66\u672f\u754c\u548c\u4ea7\u4e1a\u754c\u90fd\u6709\u91cd\u8981\u8d21\u732e\u3002"}}
{"id": "2510.18096", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.18096", "abs": "https://arxiv.org/abs/2510.18096", "authors": ["Esrat Ebtida Sakib", "MD Ahnaf Akib", "Md Muktadir Mazumder", "Maliha Noushin Raida", "Md. Mohsinul Kabir"], "title": "A Benchmark Dataset And LLMs Comparison For NFR Classification With Explainable AI", "comment": null, "summary": "Non-Functional Requirements (NFRs) play a critical role in determining the\noverall quality and user satisfaction of software systems. Accurately\nidentifying and classifying NFRs is essential to ensure that software meets\nperformance, usability, and reliability expectations. However, manual\nidentification of NFRs from documentation is time-consuming and prone to\nerrors, necessitating automated solutions. Before implementing any automated\nsolution, a robust and comprehensive dataset is essential. To build such a\ndataset, we collected NFRs from various Project Charters and Open Source\nSoftware Documentation. This enhanced the technical depth and usability of an\nalready existing NFR dataset. We categorized NFRs into sub-classes and\nidentified needs using widely used Large Language Models to facilitate\nautomation. After classifying the NFRs, we compared the classification results\nof the selected LLMs: RoBERTa, CodeBERT, Gemma-2, Phi-3, Mistral-8B, and\nLlama-3.1-8B using various evaluation metrics, including precision, recall,\nF1-score, and lime scores. Among these models, Gemma-2 achieved the best\nresults with a precision of 0.87, recall of 0.89, and F1-score of 0.88,\nalongside a lime hit score of 78 out of 80. Phi-3 closely followed with a\nprecision of 0.85, recall of 0.87, F1-score of 0.86, and the highest lime hit\nscore of 79. By improving the contextual foundation, this integration enhanced\nthe model's comprehension of technical aspects and user requirements.", "AI": {"tldr": "\u8be5\u8bba\u6587\u901a\u8fc7\u589e\u5f3a\u73b0\u6709NFR\u6570\u636e\u96c6\uff0c\u4f7f\u7528\u591a\u79cd\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5bf9\u975e\u529f\u80fd\u6027\u9700\u6c42\u8fdb\u884c\u5206\u7c7b\u6bd4\u8f83\uff0c\u5176\u4e2dGemma-2\u548cPhi-3\u8868\u73b0\u6700\u4f73\u3002", "motivation": "\u624b\u52a8\u8bc6\u522b\u975e\u529f\u80fd\u6027\u9700\u6c42\u8017\u65f6\u4e14\u6613\u9519\uff0c\u9700\u8981\u81ea\u52a8\u5316\u89e3\u51b3\u65b9\u6848\uff0c\u800c\u6784\u5efa\u9ad8\u8d28\u91cf\u6570\u636e\u96c6\u662f\u5b9e\u73b0\u81ea\u52a8\u5316\u7684\u524d\u63d0\u3002", "method": "\u4ece\u9879\u76ee\u7ae0\u7a0b\u548c\u5f00\u6e90\u8f6f\u4ef6\u6587\u6863\u6536\u96c6NFR\u6570\u636e\uff0c\u4f7f\u7528RoBERTa\u3001CodeBERT\u3001Gemma-2\u3001Phi-3\u3001Mistral-8B\u548cLlama-3.1-8B\u7b49LLM\u8fdb\u884c\u5206\u7c7b\uff0c\u5e76\u6bd4\u8f83\u5176\u6027\u80fd\u3002", "result": "Gemma-2\u8868\u73b0\u6700\u4f73\uff08\u7cbe\u786e\u73870.87\uff0c\u53ec\u56de\u73870.89\uff0cF1\u5206\u65700.88\uff09\uff0cPhi-3\u7d27\u968f\u5176\u540e\uff08\u7cbe\u786e\u73870.85\uff0c\u53ec\u56de\u73870.87\uff0cF1\u5206\u65700.86\uff09\u3002", "conclusion": "\u901a\u8fc7\u6539\u8fdb\u4e0a\u4e0b\u6587\u57fa\u7840\uff0c\u589e\u5f3a\u4e86\u6a21\u578b\u5bf9\u6280\u672f\u65b9\u9762\u548c\u7528\u6237\u9700\u6c42\u7684\u7406\u89e3\uff0cGemma-2\u548cPhi-3\u5728NFR\u5206\u7c7b\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\u3002"}}
{"id": "2510.18131", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.18131", "abs": "https://arxiv.org/abs/2510.18131", "authors": ["Chengquan Guo", "Yuzhou Nie", "Chulin Xie", "Zinan Lin", "Wenbo Guo", "Bo Li"], "title": "BlueCodeAgent: A Blue Teaming Agent Enabled by Automated Red Teaming for CodeGen AI", "comment": null, "summary": "As large language models (LLMs) are increasingly used for code generation,\nconcerns over the security risks have grown substantially. Early research has\nprimarily focused on red teaming, which aims to uncover and evaluate\nvulnerabilities and risks of CodeGen models. However, progress on the blue\nteaming side remains limited, as developing defense requires effective semantic\nunderstanding to differentiate the unsafe from the safe. To fill in this gap,\nwe propose BlueCodeAgent, an end-to-end blue teaming agent enabled by automated\nred teaming. Our framework integrates both sides: red teaming generates diverse\nrisky instances, while the blue teaming agent leverages these to detect\npreviously seen and unseen risk scenarios through constitution and code\nanalysis with agentic integration for multi-level defense. Our evaluation\nacross three representative code-related tasks--bias instruction detection,\nmalicious instruction detection, and vulnerable code detection--shows that\nBlueCodeAgent achieves significant gains over the base models and safety\nprompt-based defenses. In particular, for vulnerable code detection tasks,\nBlueCodeAgent integrates dynamic analysis to effectively reduce false\npositives, a challenging problem as base models tend to be over-conservative,\nmisclassifying safe code as unsafe. Overall, BlueCodeAgent achieves an average\n12.7\\% F1 score improvement across four datasets in three tasks, attributed to\nits ability to summarize actionable constitutions that enhance context-aware\nrisk detection. We demonstrate that the red teaming benefits the blue teaming\nby continuously identifying new vulnerabilities to enhance defense performance.", "AI": {"tldr": "BlueCodeAgent\u662f\u4e00\u4e2a\u7aef\u5230\u7aef\u7684\u84dd\u961f\u4ee3\u7406\uff0c\u901a\u8fc7\u81ea\u52a8\u5316\u7ea2\u961f\u751f\u6210\u591a\u6837\u5316\u98ce\u9669\u5b9e\u4f8b\uff0c\u7ed3\u5408\u5baa\u6cd5\u548c\u4ee3\u7801\u5206\u6790\u8fdb\u884c\u591a\u5c42\u6b21\u9632\u5fa1\uff0c\u5728\u4ee3\u7801\u76f8\u5173\u5b89\u5168\u4efb\u52a1\u4e2d\u663e\u8457\u63d0\u5347\u68c0\u6d4b\u6027\u80fd\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u8d8a\u6765\u8d8a\u591a\u5730\u7528\u4e8e\u4ee3\u7801\u751f\u6210\uff0c\u5b89\u5168\u98ce\u9669\u62c5\u5fe7\u65e5\u76ca\u589e\u957f\u3002\u76ee\u524d\u7814\u7a76\u4e3b\u8981\u96c6\u4e2d\u5728\u7ea2\u961f\u6d4b\u8bd5\u4e0a\uff0c\u800c\u84dd\u961f\u9632\u5fa1\u65b9\u9762\u8fdb\u5c55\u6709\u9650\uff0c\u9700\u8981\u6709\u6548\u7684\u8bed\u4e49\u7406\u89e3\u6765\u533a\u5206\u5b89\u5168\u4e0e\u4e0d\u5b89\u5168\u4ee3\u7801\u3002", "method": "\u63d0\u51faBlueCodeAgent\u6846\u67b6\uff0c\u96c6\u6210\u7ea2\u961f\u548c\u84dd\u961f\uff1a\u7ea2\u961f\u751f\u6210\u591a\u6837\u5316\u98ce\u9669\u5b9e\u4f8b\uff0c\u84dd\u961f\u4ee3\u7406\u5229\u7528\u8fd9\u4e9b\u5b9e\u4f8b\u901a\u8fc7\u5baa\u6cd5\u548c\u4ee3\u7801\u5206\u6790\u68c0\u6d4b\u5df2\u77e5\u548c\u672a\u77e5\u98ce\u9669\u573a\u666f\uff0c\u5e76\u96c6\u6210\u52a8\u6001\u5206\u6790\u51cf\u5c11\u8bef\u62a5\u3002", "result": "\u5728\u4e09\u4e2a\u4ee3\u8868\u6027\u4ee3\u7801\u76f8\u5173\u4efb\u52a1\uff08\u504f\u89c1\u6307\u4ee4\u68c0\u6d4b\u3001\u6076\u610f\u6307\u4ee4\u68c0\u6d4b\u3001\u6f0f\u6d1e\u4ee3\u7801\u68c0\u6d4b\uff09\u4e2d\uff0cBlueCodeAgent\u76f8\u6bd4\u57fa\u7840\u6a21\u578b\u548c\u57fa\u4e8e\u5b89\u5168\u63d0\u793a\u7684\u9632\u5fa1\u65b9\u6cd5\u53d6\u5f97\u663e\u8457\u63d0\u5347\uff0c\u5728\u4e09\u4e2a\u4efb\u52a1\u7684\u56db\u4e2a\u6570\u636e\u96c6\u4e0a\u5e73\u5747F1\u5206\u6570\u63d0\u9ad812.7%\u3002", "conclusion": "\u7ea2\u961f\u6d4b\u8bd5\u901a\u8fc7\u6301\u7eed\u8bc6\u522b\u65b0\u6f0f\u6d1e\u6765\u589e\u5f3a\u84dd\u961f\u9632\u5fa1\u6027\u80fd\uff0cBlueCodeAgent\u80fd\u591f\u603b\u7ed3\u53ef\u64cd\u4f5c\u7684\u5baa\u6cd5\u6765\u589e\u5f3a\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u98ce\u9669\u68c0\u6d4b\u80fd\u529b\u3002"}}
{"id": "2510.18270", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.18270", "abs": "https://arxiv.org/abs/2510.18270", "authors": ["Yang Chen", "Toufique Ahmed", "Reyhaneh Jabbarvand", "Martin Hirzel"], "title": "When Old Meets New: Evaluating the Impact of Regression Tests on SWE Issue Resolution", "comment": null, "summary": "Test suites in real-world projects are often large and achieve high code\ncoverage, yet they remain insufficient for detecting all bugs. The abundance of\nunresolved issues in open-source project trackers highlights this gap. While\nregression tests are typically designed to ensure past functionality is\npreserved in the new version, they can also serve a complementary purpose:\ndebugging the current version. Specifically, regression tests can (1) enhance\nthe generation of reproduction tests for newly reported issues, and (2)\nvalidate that patches do not regress existing functionality. We present\nTestPrune, a fully automated technique that leverages issue tracker reports and\nstrategically reuses regression tests for both bug reproduction and patch\nvalidation.\n  A key contribution of TestPrune is its ability to automatically minimize the\nregression suite to a small, highly relevant subset of tests. Due to the\npredominance of LLM-based debugging techniques, this minimization is essential\nas large test suites exceed context limits, introduce noise, and inflate\ninference costs. TestPrune can be plugged into any agentic bug repair pipeline\nand orthogonally improve overall performance. As a proof of concept, we show\nthat TestPrune leads to a 6.2%-9.0% relative increase in issue reproduction\nrate within the Otter framework and a 9.4% - 12.9% relative increase in issue\nresolution rate within the Agentless framework on SWE-Bench Lite and SWE-Bench\nVerified benchmarks, capturing fixes that were correctly produced by agents but\nnot submitted as final patches. Compared to the benefits, the cost overhead of\nusing TestPrune is minimal, i.e., \\$0.02 and \\$0.05 per SWE-Bench instance,\nusing GPT-4o and Claude-3.7-Sonnet models, respectively.", "AI": {"tldr": "TestPrune\u662f\u4e00\u79cd\u81ea\u52a8\u5316\u6280\u672f\uff0c\u901a\u8fc7\u5229\u7528\u95ee\u9898\u8ddf\u8e2a\u62a5\u544a\u548c\u6218\u7565\u6027\u5730\u91cd\u7528\u56de\u5f52\u6d4b\u8bd5\u6765\u8fdb\u884cbug\u590d\u73b0\u548c\u8865\u4e01\u9a8c\u8bc1\uff0c\u80fd\u591f\u663e\u8457\u63d0\u9ad8\u95ee\u9898\u590d\u73b0\u7387\u548c\u89e3\u51b3\u7387\u3002", "motivation": "\u73b0\u5b9e\u9879\u76ee\u4e2d\u7684\u6d4b\u8bd5\u5957\u4ef6\u867d\u7136\u5e9e\u5927\u4e14\u8986\u76d6\u7387\u9ad8\uff0c\u4f46\u4ecd\u65e0\u6cd5\u68c0\u6d4b\u6240\u6709bug\u3002\u56de\u5f52\u6d4b\u8bd5\u9664\u4e86\u786e\u4fdd\u529f\u80fd\u4fdd\u7559\u5916\uff0c\u8fd8\u53ef\u7528\u4e8e\u8c03\u8bd5\u5f53\u524d\u7248\u672c\uff0c\u7279\u522b\u662f\u589e\u5f3a\u65b0\u62a5\u544a\u95ee\u9898\u7684\u590d\u73b0\u6d4b\u8bd5\u751f\u6210\u548c\u9a8c\u8bc1\u8865\u4e01\u4e0d\u56de\u5f52\u73b0\u6709\u529f\u80fd\u3002", "method": "TestPrune\u80fd\u591f\u81ea\u52a8\u5c06\u56de\u5f52\u6d4b\u8bd5\u5957\u4ef6\u6700\u5c0f\u5316\u4e3a\u5c0f\u578b\u3001\u9ad8\u5ea6\u76f8\u5173\u7684\u6d4b\u8bd5\u5b50\u96c6\uff0c\u53ef\u96c6\u6210\u5230\u4efb\u4f55\u57fa\u4e8e\u4ee3\u7406\u7684bug\u4fee\u590d\u6d41\u7a0b\u4e2d\uff0c\u6b63\u4ea4\u63d0\u5347\u6574\u4f53\u6027\u80fd\u3002", "result": "\u5728Otter\u6846\u67b6\u4e2d\uff0cTestPrune\u4f7f\u95ee\u9898\u590d\u73b0\u7387\u76f8\u5bf9\u63d0\u9ad86.2%-9.0%\uff1b\u5728Agentless\u6846\u67b6\u4e2d\uff0c\u95ee\u9898\u89e3\u51b3\u7387\u76f8\u5bf9\u63d0\u9ad89.4%-12.9%\u3002\u4f7f\u7528\u6210\u672c\u6781\u4f4e\uff0c\u6bcf\u4e2aSWE-Bench\u5b9e\u4f8b\u4ec5\u9700$0.02-$0.05\u3002", "conclusion": "TestPrune\u901a\u8fc7\u667a\u80fd\u91cd\u7528\u56de\u5f52\u6d4b\u8bd5\uff0c\u6709\u6548\u63d0\u5347\u4e86bug\u4fee\u590d\u6d41\u7a0b\u7684\u6027\u80fd\uff0c\u4e14\u6210\u672c\u6548\u76ca\u663e\u8457\uff0c\u7279\u522b\u9002\u7528\u4e8eLLM\u9a71\u52a8\u7684\u8c03\u8bd5\u73af\u5883\u3002"}}
{"id": "2510.18292", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.18292", "abs": "https://arxiv.org/abs/2510.18292", "authors": ["Hala Abdelkader", "Mohamed Abdelrazek", "Priya Rani", "Rajesh Vasa", "Jean-Guy Schneider"], "title": "Ensuring Robustness in ML-enabled Software Systems: A User Survey", "comment": null, "summary": "Ensuring robustness in ML-enabled software systems requires addressing\ncritical challenges, such as silent failures, out-of-distribution (OOD) data,\nand adversarial attacks. Traditional software engineering practices, which rely\non predefined logic, are insufficient for ML components that depend on data and\nprobabilistic decision-making. To address these challenges, we propose the\nML-On-Rails protocol, a unified framework designed to enhance the robustness\nand trustworthiness of ML-enabled systems in production. This protocol\nintegrates key safeguards such as OOD detection, adversarial attack detection,\ninput validation, and explainability. It also includes a model-to-software\ncommunication framework using HTTP status codes to enhance transparency in\nreporting model outcomes and errors. To align our approach with real-world\nchallenges, we conducted a practitioner survey, which revealed major robustness\nissues, gaps in current solutions, and highlighted how a standardised protocol\nsuch as ML-On-Rails can improve system robustness. Our findings highlight the\nneed for more support and resources for engineers working with ML systems.\nFinally, we outline future directions for refining the proposed protocol,\nleveraging insights from the survey and real-world applications to continually\nenhance its effectiveness.", "AI": {"tldr": "\u63d0\u51faML-On-Rails\u534f\u8bae\uff0c\u4e00\u4e2a\u7edf\u4e00\u6846\u67b6\u6765\u589e\u5f3a\u751f\u4ea7\u73af\u5883\u4e2dML\u7cfb\u7edf\u7684\u9c81\u68d2\u6027\u548c\u53ef\u4fe1\u5ea6\uff0c\u5305\u542bOOD\u68c0\u6d4b\u3001\u5bf9\u6297\u653b\u51fb\u68c0\u6d4b\u3001\u8f93\u5165\u9a8c\u8bc1\u548c\u53ef\u89e3\u91ca\u6027\u7b49\u5b89\u5168\u63aa\u65bd\u3002", "motivation": "\u4f20\u7edf\u8f6f\u4ef6\u5de5\u7a0b\u65b9\u6cd5\u65e0\u6cd5\u5e94\u5bf9ML\u7ec4\u4ef6\u7684\u7279\u6b8a\u6311\u6218\uff0c\u5982\u9759\u9ed8\u6545\u969c\u3001\u5206\u5e03\u5916\u6570\u636e\u548c\u5bf9\u6297\u653b\u51fb\uff0c\u9700\u8981\u4e13\u95e8\u6846\u67b6\u6765\u786e\u4fddML\u7cfb\u7edf\u7684\u9c81\u68d2\u6027\u3002", "method": "\u5f00\u53d1ML-On-Rails\u534f\u8bae\uff0c\u96c6\u6210\u591a\u79cd\u5b89\u5168\u63aa\u65bd\uff0c\u4f7f\u7528HTTP\u72b6\u6001\u7801\u8fdb\u884c\u6a21\u578b-\u8f6f\u4ef6\u901a\u4fe1\uff0c\u5e76\u901a\u8fc7\u4ece\u4e1a\u8005\u8c03\u67e5\u9a8c\u8bc1\u65b9\u6cd5\u6709\u6548\u6027\u3002", "result": "\u8c03\u67e5\u63ed\u793a\u4e86\u5f53\u524dML\u7cfb\u7edf\u7684\u4e3b\u8981\u9c81\u68d2\u6027\u95ee\u9898\uff0c\u8868\u660e\u6807\u51c6\u5316\u534f\u8bae\u5982ML-On-Rails\u53ef\u4ee5\u663e\u8457\u6539\u5584\u7cfb\u7edf\u9c81\u68d2\u6027\u3002", "conclusion": "\u9700\u8981\u4e3aML\u7cfb\u7edf\u5de5\u7a0b\u5e08\u63d0\u4f9b\u66f4\u591a\u652f\u6301\u548c\u8d44\u6e90\uff0c\u672a\u6765\u5c06\u7ee7\u7eed\u5b8c\u5584\u8be5\u534f\u8bae\u4ee5\u63d0\u5347\u5176\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2510.18327", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.18327", "abs": "https://arxiv.org/abs/2510.18327", "authors": ["Yunkun Wang", "Yue Zhang", "Guochang Li", "Chen Zhi", "Binhua Li", "Fei Huang", "Yongbin Li", "Shuiguang Deng"], "title": "InspectCoder: Dynamic Analysis-Enabled Self Repair through interactive LLM-Debugger Collaboration", "comment": null, "summary": "Large Language Models (LLMs) frequently generate buggy code with complex\nlogic errors that are challenging to diagnose. While existing LLM-based\nself-repair approaches conduct intensive static semantic analysis or reply on\nsuperficial execution logs, they miss the in-depth runtime behaviors that often\nexpose bug root causes-lacking the interactive dynamic analysis capabilities\nthat make human debugging effective. We present InspectCoder, the first agentic\nprogram repair system that empowers LLMs to actively conduct dynamic analysis\nvia interactive debugger control. Our dual-agent framework enables strategic\nbreakpoint placement, targeted state inspection, and incremental runtime\nexperimentation within stateful debugger sessions. Unlike existing methods that\nfollow fixed log collection procedures, InspectCoder adaptively inspects and\nperturbs relevant intermediate states at runtime, and leverages immediate\nprocess rewards from debugger feedback to guide multi-step reasoning,\ntransforming LLM debugging paradigm from blind trial-and-error into systematic\nroot cause diagnosis. We conduct comprehensive experiments on two challenging\nself-repair benchmarks: BigCodeBench-R and LiveCodeBench-R. InspectCoder\nachieves 5.10%-60.37% relative improvements in repair accuracy over the\nstrongest baseline, while delivering 1.67x-2.24x superior bug-fix efficiency\nrespectively. We also contribute InspectWare, an open-source middleware that\nabstracts debugger complexities and maintains stateful debugging sessions\nacross mainstream Python testing frameworks. Our work provides actionable\ninsight into the interactive LLM-debugger systems, demonstrating the\nsignificant potential of LLM-driven dynamic analysis for automated software\nengineering.", "AI": {"tldr": "InspectCoder\u662f\u9996\u4e2a\u57fa\u4e8eLLM\u7684\u4ee3\u7406\u5f0f\u7a0b\u5e8f\u4fee\u590d\u7cfb\u7edf\uff0c\u901a\u8fc7\u4ea4\u4e92\u5f0f\u8c03\u8bd5\u5668\u63a7\u5236\u5b9e\u73b0\u52a8\u6001\u5206\u6790\uff0c\u663e\u8457\u63d0\u5347\u4ee3\u7801\u4fee\u590d\u51c6\u786e\u7387\u548c\u6548\u7387\u3002", "motivation": "\u73b0\u6709LLM\u81ea\u6211\u4fee\u590d\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u9759\u6001\u8bed\u4e49\u5206\u6790\u6216\u8868\u9762\u6267\u884c\u65e5\u5fd7\uff0c\u7f3a\u4e4f\u6df1\u5165\u8fd0\u884c\u65f6\u884c\u4e3a\u5206\u6790\uff0c\u65e0\u6cd5\u6709\u6548\u8bca\u65ad\u590d\u6742\u903b\u8f91\u9519\u8bef\u7684\u6839\u672c\u539f\u56e0\u3002", "method": "\u91c7\u7528\u53cc\u4ee3\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u4ea4\u4e92\u5f0f\u8c03\u8bd5\u5668\u63a7\u5236\u5b9e\u73b0\u6218\u7565\u6027\u65ad\u70b9\u8bbe\u7f6e\u3001\u76ee\u6807\u72b6\u6001\u68c0\u67e5\u548c\u589e\u91cf\u8fd0\u884c\u65f6\u5b9e\u9a8c\uff0c\u5c06LLM\u8c03\u8bd5\u4ece\u76f2\u76ee\u8bd5\u9519\u8f6c\u53d8\u4e3a\u7cfb\u7edf\u6027\u6839\u672c\u539f\u56e0\u8bca\u65ad\u3002", "result": "\u5728\u4e24\u4e2a\u6311\u6218\u6027\u81ea\u4fee\u590d\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u4fee\u590d\u51c6\u786e\u7387\u76f8\u5bf9\u6700\u5f3a\u57fa\u7ebf\u63d0\u53475.10%-60.37%\uff0cbug\u4fee\u590d\u6548\u7387\u63d0\u53471.67x-2.24x\u3002", "conclusion": "LLM\u9a71\u52a8\u7684\u52a8\u6001\u5206\u6790\u5728\u81ea\u52a8\u5316\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u5177\u6709\u5de8\u5927\u6f5c\u529b\uff0c\u4ea4\u4e92\u5f0fLLM-\u8c03\u8bd5\u5668\u7cfb\u7edf\u4e3a\u7a0b\u5e8f\u4fee\u590d\u63d0\u4f9b\u4e86\u65b0\u7684\u6709\u6548\u9014\u5f84\u3002"}}
{"id": "2510.18430", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.18430", "abs": "https://arxiv.org/abs/2510.18430", "authors": ["Tasha Settewong", "Youmei Fan", "Raula Gaikovina Kula", "Kenichi Matsumoto"], "title": "Human to Document, AI to Code: Three Case Studies of Comparing GenAI for Notebook Competitions", "comment": null, "summary": "Computational notebooks have become the preferred tool of choice for data\nscientists and practitioners to perform analyses and share results. Notebooks\nuniquely combine scripts with documentation. With the emergence of generative\nAI (GenAI) technologies, it is increasingly important, especially in\ncompetitive settings, to distinguish the characteristics of human-written\nversus GenAI.\n  In this study, we present three case studies to explore potential strengths\nof both humans and GenAI through the coding and documenting activities in\nnotebooks. We first characterize differences between 25 code and documentation\nfeatures in human-written, medal-winning Kaggle notebooks. We find that gold\nmedalists are primarily distinguished by longer and more detailed\ndocumentation. Second, we analyze the distinctions between human-written and\nGenAI notebooks. Our results show that while GenAI notebooks tend to achieve\nhigher code quality (as measured by metrics like code smells and technical\ndebt), human-written notebooks display greater structural diversity,\ncomplexity, and innovative approaches to problem-solving. Based on these\nresults, we envision the work as groundwork that highlight four agendas to\nfurther investigate how GenAI could be utilized in notebooks that maximizes the\npotential collaboration between human and AI.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u4e09\u4e2a\u6848\u4f8b\u7814\u7a76\u5206\u6790\u4e86\u4eba\u7c7b\u7f16\u5199\u4e0eGenAI\u751f\u6210\u7684\u8ba1\u7b97\u7b14\u8bb0\u672c\u5728\u4ee3\u7801\u548c\u6587\u6863\u7279\u5f81\u4e0a\u7684\u5dee\u5f02\uff0c\u53d1\u73b0\u4eba\u7c7b\u7b14\u8bb0\u672c\u5728\u7ed3\u6784\u591a\u6837\u6027\u548c\u521b\u65b0\u6027\u65b9\u9762\u8868\u73b0\u66f4\u597d\uff0c\u800cGenAI\u5728\u4ee3\u7801\u8d28\u91cf\u65b9\u9762\u66f4\u4f18\u3002", "motivation": "\u968f\u7740\u751f\u6210\u5f0fAI\u6280\u672f\u7684\u51fa\u73b0\uff0c\u5728\u7ade\u4e89\u73af\u5883\u4e2d\u533a\u5206\u4eba\u7c7b\u7f16\u5199\u4e0eGenAI\u751f\u6210\u7b14\u8bb0\u672c\u7684\u7279\u5f81\u53d8\u5f97\u8d8a\u6765\u8d8a\u91cd\u8981\uff0c\u7279\u522b\u662f\u5728\u6570\u636e\u79d1\u5b66\u9886\u57df\u3002", "method": "\u901a\u8fc7\u5206\u679025\u4e2a\u4ee3\u7801\u548c\u6587\u6863\u7279\u5f81\uff0c\u6bd4\u8f83\u4e86\u4eba\u7c7b\u7f16\u5199\u7684Kaggle\u83b7\u5956\u7b14\u8bb0\u672c\u4e0eGenAI\u751f\u6210\u7b14\u8bb0\u672c\u7684\u5dee\u5f02\u3002", "result": "\u91d1\u724c\u5f97\u4e3b\u4e3b\u8981\u901a\u8fc7\u66f4\u957f\u66f4\u8be6\u7ec6\u7684\u6587\u6863\u6765\u533a\u5206\uff1bGenAI\u7b14\u8bb0\u672c\u4ee3\u7801\u8d28\u91cf\u66f4\u9ad8\uff0c\u4f46\u4eba\u7c7b\u7b14\u8bb0\u672c\u5728\u7ed3\u6784\u591a\u6837\u6027\u3001\u590d\u6742\u6027\u548c\u521b\u65b0\u6027\u65b9\u9762\u8868\u73b0\u66f4\u597d\u3002", "conclusion": "\u672c\u7814\u7a76\u4e3a\u63a2\u7d22\u5982\u4f55\u6700\u5927\u5316\u4eba\u7c7b\u4e0eAI\u5728\u7b14\u8bb0\u672c\u4e2d\u7684\u534f\u4f5c\u6f5c\u529b\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u63d0\u51fa\u4e86\u56db\u4e2a\u8fdb\u4e00\u6b65\u7814\u7a76\u8bae\u7a0b\u3002"}}
{"id": "2510.18448", "categories": ["cs.SE", "cs.CR"], "pdf": "https://arxiv.org/pdf/2510.18448", "abs": "https://arxiv.org/abs/2510.18448", "authors": ["Wenjing Dang", "Kaixuan Li", "Sen Chen", "Zhenwei Zhuo", "Lyuye Zhang", "Zheli Liu"], "title": "Real-World Usability of Vulnerability Proof-of-Concepts: A Comprehensive Study", "comment": null, "summary": "The Proof-of-Concept (PoC) for a vulnerability is crucial in validating its\nexistence, mitigating false positives, and illustrating the severity of the\nsecurity threat it poses. However, research on PoCs significantly lags behind\nstudies focusing on vulnerability data. This discrepancy can be directly\nattributed to several challenges, including the dispersion of real-world PoCs\nacross multiple platforms, the diversity in writing styles, and the difficulty\nassociated with PoC reproduction. To fill this gap, we conduct the first\nlarge-scale study on PoCs in the wild, assessing their report availability,\ncompleteness, reproducibility. Specifically, 1) to investigate PoC reports\navailability for CVE vulnerability, we collected an extensive dataset of\n470,921 PoCs and their reports from 13 platforms, representing the broadest\ncollection of publicly available PoCs to date. 2) To assess the completeness of\nPoC report at a fine-grained level, we proposed a component extraction method,\nwhich combines pattern-matching techniques with a fine-tuned BERT-NER model to\nextract 9 key components from PoC reports. 3) To evaluate the effectiveness of\nPoCs, we recruited 8 participants to manually reproduce 150 sampled\nvulnerabilities with 32 vulnerability types based on PoC reports, enabling an\nin-depth analysis of PoC reproducibility and the factors influencing it. Our\nfindings reveal that 78.9% of CVE vulnerabilities lack available PoCs, and\nexisting PoC reports typically miss about 30% of the essential components\nrequired for effective vulnerability understanding and reproduction, with\nvarious reasons identified for the failure to reproduce vulnerabilities using\navailable PoC reports. Finally, we proposed actionable strategies for\nstakeholders to enhance the overall usability of vulnerability PoCs in\nstrengthening software security.", "AI": {"tldr": "\u8be5\u8bba\u6587\u9996\u6b21\u5bf9\u771f\u5b9e\u73af\u5883\u4e2d\u7684\u6f0f\u6d1e\u6982\u5ff5\u9a8c\u8bc1(PoC)\u8fdb\u884c\u4e86\u5927\u89c4\u6a21\u7814\u7a76\uff0c\u8bc4\u4f30\u4e86PoC\u62a5\u544a\u7684\u53ef\u7528\u6027\u3001\u5b8c\u6574\u6027\u548c\u53ef\u590d\u73b0\u6027\uff0c\u63ed\u793a\u4e8678.9%\u7684CVE\u6f0f\u6d1e\u7f3a\u4e4f\u53ef\u7528PoC\uff0c\u73b0\u6709PoC\u62a5\u544a\u7f3a\u5931\u7ea630%\u5173\u952e\u7ec4\u4ef6\uff0c\u5e76\u63d0\u51fa\u4e86\u6539\u8fdb\u7b56\u7565\u3002", "motivation": "\u6982\u5ff5\u9a8c\u8bc1\u5bf9\u9a8c\u8bc1\u6f0f\u6d1e\u5b58\u5728\u3001\u51cf\u5c11\u8bef\u62a5\u548c\u5c55\u793a\u5b89\u5168\u5a01\u80c1\u4e25\u91cd\u6027\u81f3\u5173\u91cd\u8981\uff0c\u4f46PoC\u7814\u7a76\u8fdc\u843d\u540e\u4e8e\u6f0f\u6d1e\u6570\u636e\u7814\u7a76\uff0c\u4e3b\u8981\u6311\u6218\u5305\u62ecPoC\u5206\u6563\u5728\u4e0d\u540c\u5e73\u53f0\u3001\u5199\u4f5c\u98ce\u683c\u591a\u6837\u4ee5\u53ca\u590d\u73b0\u56f0\u96be\u3002", "method": "1) \u4ece13\u4e2a\u5e73\u53f0\u6536\u96c6470,921\u4e2aPoC\u53ca\u5176\u62a5\u544a\uff1b2) \u63d0\u51fa\u7ed3\u5408\u6a21\u5f0f\u5339\u914d\u548c\u5fae\u8c03BERT-NER\u6a21\u578b\u7684\u7ec4\u4ef6\u63d0\u53d6\u65b9\u6cd5\uff0c\u4ecePoC\u62a5\u544a\u4e2d\u63d0\u53d69\u4e2a\u5173\u952e\u7ec4\u4ef6\uff1b3) \u62db\u52df8\u540d\u53c2\u4e0e\u8005\u624b\u52a8\u590d\u73b0150\u4e2a\u91c7\u6837\u6f0f\u6d1e\uff0c\u5206\u6790PoC\u53ef\u590d\u73b0\u6027\u53ca\u5f71\u54cd\u56e0\u7d20\u3002", "result": "\u7814\u7a76\u53d1\u73b078.9%\u7684CVE\u6f0f\u6d1e\u7f3a\u4e4f\u53ef\u7528PoC\uff0c\u73b0\u6709PoC\u62a5\u544a\u901a\u5e38\u7f3a\u5931\u7ea630%\u7406\u89e3\u6f0f\u6d1e\u548c\u590d\u73b0\u6240\u9700\u7684\u5173\u952e\u7ec4\u4ef6\uff0c\u5e76\u8bc6\u522b\u4e86\u4f7f\u7528\u53ef\u7528PoC\u62a5\u544a\u590d\u73b0\u6f0f\u6d1e\u5931\u8d25\u7684\u5404\u79cd\u539f\u56e0\u3002", "conclusion": "\u6700\u540e\u63d0\u51fa\u4e86\u5229\u76ca\u76f8\u5173\u8005\u53ef\u91c7\u53d6\u7684\u884c\u52a8\u7b56\u7565\uff0c\u4ee5\u589e\u5f3a\u6f0f\u6d1ePoC\u5728\u52a0\u5f3a\u8f6f\u4ef6\u5b89\u5168\u65b9\u9762\u7684\u6574\u4f53\u53ef\u7528\u6027\u3002"}}
{"id": "2510.18456", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.18456", "abs": "https://arxiv.org/abs/2510.18456", "authors": ["Cristina Martinez Montes", "Robert Feldt", "Cristina Miguel Martos", "Sofia Ouhbi", "Shweta Premanandan", "Daniel Graziotin"], "title": "Large Language Models in Thematic Analysis: Prompt Engineering, Evaluation, and Guidelines for Qualitative Software Engineering Research", "comment": null, "summary": "As artificial intelligence advances, large language models (LLMs) are\nentering qualitative research workflows, yet no reproducible methods exist for\nintegrating them into established approaches like thematic analysis (TA), one\nof the most common qualitative methods in software engineering research.\nMoreover, existing studies lack systematic evaluation of LLM-generated\nqualitative outputs against established quality criteria. We designed and\niteratively refined prompts for Phases 2-5 of Braun and Clarke's reflexive TA,\nthen tested outputs from multiple LLMs against codes and themes produced by\nexperienced researchers. Using 15 interviews on software engineers' well-being,\nwe conducted blind evaluations with four expert evaluators who applied rubrics\nderived directly from Braun and Clarke's quality criteria. Evaluators preferred\nLLM-generated codes 61% of the time, finding them analytically useful for\nanswering the research question. However, evaluators also identified\nlimitations: LLMs fragmented data unnecessarily, missed latent interpretations,\nand sometimes produced themes with unclear boundaries. Our contributions are\nthreefold. First, a reproducible approach integrating refined, documented\nprompts with an evaluation framework to operationalize Braun and Clarke's\nreflexive TA. Second, an empirical comparison of LLM- and human-generated codes\nand themes in software engineering data. Third, guidelines for integrating LLMs\ninto qualitative analysis while preserving methodological rigour, clarifying\nwhen and how LLMs can assist effectively and when human interpretation remains\nessential.", "AI": {"tldr": "\u672c\u7814\u7a76\u5f00\u53d1\u4e86\u4e00\u79cd\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u6574\u5408\u5230\u4e3b\u9898\u5206\u6790\u4e2d\u7684\u53ef\u91cd\u590d\u65b9\u6cd5\uff0c\u901a\u8fc7\u7cfb\u7edf\u8bc4\u4f30\u53d1\u73b0LLM\u751f\u6210\u7684\u4ee3\u7801\u572861%\u7684\u60c5\u51b5\u4e0b\u4f18\u4e8e\u4eba\u5de5\u4ee3\u7801\uff0c\u4f46\u4e5f\u5b58\u5728\u6570\u636e\u788e\u7247\u5316\u3001\u9057\u6f0f\u6f5c\u5728\u89e3\u91ca\u7b49\u5c40\u9650\u6027\u3002", "motivation": "\u968f\u7740AI\u53d1\u5c55\uff0c\u5927\u8bed\u8a00\u6a21\u578b\u5f00\u59cb\u8fdb\u5165\u8d28\u6027\u7814\u7a76\u6d41\u7a0b\uff0c\u4f46\u7f3a\u4e4f\u5c06\u5176\u6574\u5408\u5230\u4e3b\u9898\u5206\u6790\u7b49\u6210\u719f\u65b9\u6cd5\u4e2d\u7684\u53ef\u91cd\u590d\u65b9\u6cd5\uff0c\u4e14\u73b0\u6709\u7814\u7a76\u7f3a\u4e4f\u5bf9LLM\u751f\u6210\u8d28\u6027\u8f93\u51fa\u7684\u7cfb\u7edf\u6027\u8d28\u91cf\u8bc4\u4f30\u3002", "method": "\u8bbe\u8ba1\u5e76\u8fed\u4ee3\u4f18\u5316\u4e86Braun\u548cClarke\u53cd\u601d\u6027\u4e3b\u9898\u5206\u6790\u7b2c2-5\u9636\u6bb5\u7684\u63d0\u793a\u8bcd\uff0c\u4f7f\u752815\u4e2a\u8f6f\u4ef6\u5de5\u7a0b\u5e08\u798f\u7949\u8bbf\u8c08\u6570\u636e\uff0c\u901a\u8fc7\u56db\u4f4d\u4e13\u5bb6\u8bc4\u4f30\u5458\u5bf9\u591a\u4e2aLLM\u8f93\u51fa\u4e0e\u6709\u7ecf\u9a8c\u7814\u7a76\u8005\u751f\u6210\u7684\u4ee3\u7801\u548c\u4e3b\u9898\u8fdb\u884c\u76f2\u8bc4\u3002", "result": "\u8bc4\u4f30\u8005\u572861%\u7684\u60c5\u51b5\u4e0b\u66f4\u504f\u597dLLM\u751f\u6210\u7684\u4ee3\u7801\uff0c\u8ba4\u4e3a\u5176\u5206\u6790\u4ef7\u503c\u66f4\u9ad8\uff0c\u4f46\u4e5f\u53d1\u73b0LLM\u5b58\u5728\u4e0d\u5fc5\u8981\u7684\u6570\u636e\u788e\u7247\u5316\u3001\u9057\u6f0f\u6f5c\u5728\u89e3\u91ca\u3001\u4e3b\u9898\u8fb9\u754c\u4e0d\u6e05\u7b49\u95ee\u9898\u3002", "conclusion": "\u63d0\u51fa\u4e86\u6574\u5408\u4f18\u5316\u63d0\u793a\u8bcd\u4e0e\u8bc4\u4f30\u6846\u67b6\u7684\u53ef\u91cd\u590d\u65b9\u6cd5\uff0c\u63d0\u4f9b\u4e86\u5728\u8f6f\u4ef6\u5de5\u7a0b\u6570\u636e\u4e2dLLM\u4e0e\u4eba\u5de5\u751f\u6210\u4ee3\u7801\u548c\u4e3b\u9898\u7684\u5b9e\u8bc1\u6bd4\u8f83\uff0c\u5e76\u5236\u5b9a\u4e86\u5728\u4fdd\u6301\u65b9\u6cd5\u4e25\u8c28\u6027\u7684\u524d\u63d0\u4e0b\u5c06LLM\u6574\u5408\u5230\u8d28\u6027\u5206\u6790\u7684\u6307\u5357\u3002"}}
{"id": "2510.18471", "categories": ["cs.SE", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.18471", "abs": "https://arxiv.org/abs/2510.18471", "authors": ["Xue Jiang", "Yihong Dong", "Mengyang Liu", "Hongyi Deng", "Tian Wang", "Yongding Tao", "Rongyu Cao", "Binhua Li", "Zhi Jin", "Wenpin Jiao", "Fei Huang", "Yongbin Li", "Ge Li"], "title": "CodeRL+: Improving Code Generation via Reinforcement with Execution Semantics Alignment", "comment": null, "summary": "While Large Language Models (LLMs) excel at code generation by learning from\nvast code corpora, a fundamental semantic gap remains between their training on\ntextual patterns and the goal of functional correctness, which is governed by\nformal execution semantics. Reinforcement Learning with Verifiable Rewards\n(RLVR) approaches attempt to bridge this gap using outcome rewards from\nexecuting test cases. However, solely relying on binary pass/fail signals is\ninefficient for establishing a well-aligned connection between the textual\nrepresentation of code and its execution semantics, especially for subtle\nlogical errors within the code. In this paper, we propose CodeRL+, a novel\napproach that integrates execution semantics alignment into the RLVR training\npipeline for code generation. CodeRL+ enables the model to infer variable-level\nexecution trajectory, providing a direct learning signal of execution\nsemantics. CodeRL+ can construct execution semantics alignment directly using\nexisting on-policy rollouts and integrates seamlessly with various RL\nalgorithms. Extensive experiments demonstrate that CodeRL+ outperforms\npost-training baselines (including RLVR and Distillation), achieving a 4.6%\naverage relative improvement in pass@1. CodeRL+ generalizes effectively to\nother coding tasks, yielding 15.5% and 4.4% higher accuracy on code-reasoning\nand test-output-generation benchmarks, respectively. CodeRL+ shows strong\napplicability across diverse RL algorithms and LLMs. Furthermore, probe\nanalyses provide compelling evidence that CodeRL+ strengthens the alignment\nbetween code's textual representations and its underlying execution semantics.", "AI": {"tldr": "CodeRL+\u662f\u4e00\u79cd\u65b0\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u6574\u5408\u6267\u884c\u8bed\u4e49\u5bf9\u9f50\u6765\u6539\u8fdb\u4ee3\u7801\u751f\u6210\uff0c\u76f8\u6bd4\u4ec5\u4f9d\u8d56\u6d4b\u8bd5\u7528\u4f8b\u7ed3\u679c\u7684RLVR\u65b9\u6cd5\uff0c\u80fd\u66f4\u6709\u6548\u5730\u5b66\u4e60\u4ee3\u7801\u7684\u6267\u884c\u8bed\u4e49\u3002", "motivation": "\u73b0\u6709LLM\u5728\u4ee3\u7801\u751f\u6210\u65f6\u5b58\u5728\u8bed\u4e49\u9e3f\u6c9f\uff0c\u4ec5\u4f9d\u8d56\u6d4b\u8bd5\u7528\u4f8b\u7684\u4e8c\u5143\u901a\u8fc7/\u5931\u8d25\u4fe1\u53f7\u6548\u7387\u4f4e\u4e0b\uff0c\u96be\u4ee5\u5904\u7406\u4ee3\u7801\u4e2d\u7684\u7ec6\u5fae\u903b\u8f91\u9519\u8bef\u3002", "method": "\u63d0\u51faCodeRL+\u65b9\u6cd5\uff0c\u901a\u8fc7\u63a8\u65ad\u53d8\u91cf\u7ea7\u6267\u884c\u8f68\u8ff9\u6765\u63d0\u4f9b\u6267\u884c\u8bed\u4e49\u7684\u76f4\u63a5\u5b66\u4e60\u4fe1\u53f7\uff0c\u53ef\u76f4\u63a5\u5229\u7528\u73b0\u6709\u7b56\u7565rollouts\uff0c\u5e76\u80fd\u4e0e\u5404\u79cdRL\u7b97\u6cd5\u65e0\u7f1d\u96c6\u6210\u3002", "result": "CodeRL+\u5728pass@1\u4e0a\u5b9e\u73b04.6%\u7684\u76f8\u5bf9\u63d0\u5347\uff0c\u5728\u4ee3\u7801\u63a8\u7406\u548c\u6d4b\u8bd5\u8f93\u51fa\u751f\u6210\u4efb\u52a1\u4e0a\u5206\u522b\u83b7\u5f9715.5%\u548c4.4%\u7684\u51c6\u786e\u7387\u63d0\u5347\uff0c\u4e14\u9002\u7528\u4e8e\u4e0d\u540cRL\u7b97\u6cd5\u548cLLM\u3002", "conclusion": "CodeRL+\u6709\u6548\u52a0\u5f3a\u4e86\u4ee3\u7801\u6587\u672c\u8868\u793a\u4e0e\u5e95\u5c42\u6267\u884c\u8bed\u4e49\u4e4b\u95f4\u7684\u5bf9\u9f50\uff0c\u4e3a\u4ee3\u7801\u751f\u6210\u63d0\u4f9b\u4e86\u66f4\u6709\u6548\u7684\u8bad\u7ec3\u65b9\u6cd5\u3002"}}
{"id": "2510.18509", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.18509", "abs": "https://arxiv.org/abs/2510.18509", "authors": ["Valtteri Ala-Salmi", "Zeeshan Rasheed", "Abdul Malik Sami", "Muhammad Waseem", "Kai-Kristian Kemell", "Jussi Rasku", "Mika Saari", "Pekka Abrahamsson"], "title": "VAPU: System for Autonomous Legacy Code Modernization", "comment": "Table 13, figure 2", "summary": "In this study, we present a solution for the modernization of legacy\napplications, an area of code generation where LLM-based multi-agent systems\nare proving essential for complex multi-phased tasks. Legacy applications often\ncontain deprecated components that create compatibility, security, and\nreliability risks, but high resource costs make companies hesitate to update.\nWe take a step forward to integrate an LLM-based multi-agent system as part of\na legacy web application update to provide a cost-effective solution to update\nlegacy applications autonomously. We propose a multi-agent system named a\nVerifying Agent Pipeline Updater (VAPU), which is designed to update code files\nin phases while simulating different roles in a software development team. In\nour previous study, we evaluated the system for legacy version updates by using\nsix legacy web application view files by resulting errors and accomplished\nrequirements. This study extends the previous evaluation of a multi-agent\npipeline system by extending the evaluation of VAPU from a single LLM to five\nLLMs and using the temperature parameter in both 0 to 1 settings. Additionally,\nwe tested the system with 20 open-source Python GitHub projects. The results of\nthe evaluation were compared to Zero-Shot Learning (ZSL) and One-Shot Learning\n(OSL) prompts. The extended evaluation of VAPU showed that particularly in a\nlow-temperature VAPU can get similar level of error count compared to the\nZSL/OSL prompts but with a higher level of fulfilled requirements, depending on\nthe LLM. VAPU showed up to 22.5% increase in the succeeding Python file update\nrequirements compared to ZSL/OSL prompts. The study indicates that an LLM-based\nmulti-agent system is a capable solution to update components of a legacy\napplication autonomously.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eLLM\u7684\u591a\u4ee3\u7406\u7cfb\u7edfVAPU\uff0c\u7528\u4e8e\u81ea\u4e3b\u66f4\u65b0\u9057\u7559\u5e94\u7528\u7a0b\u5e8f\u4ee3\u7801\uff0c\u76f8\u6bd4\u96f6\u6837\u672c\u548c\u5355\u6837\u672c\u5b66\u4e60\uff0c\u5728\u4f4e\u6e29\u5ea6\u8bbe\u7f6e\u4e0b\u80fd\u5b9e\u73b0\u76f8\u4f3c\u9519\u8bef\u6570\u4f46\u66f4\u9ad8\u9700\u6c42\u6ee1\u8db3\u7387\uff0cPython\u6587\u4ef6\u66f4\u65b0\u6210\u529f\u7387\u63d0\u5347\u8fbe22.5%\u3002", "motivation": "\u9057\u7559\u5e94\u7528\u7a0b\u5e8f\u5305\u542b\u8fc7\u65f6\u7ec4\u4ef6\uff0c\u5e26\u6765\u517c\u5bb9\u6027\u3001\u5b89\u5168\u6027\u548c\u53ef\u9760\u6027\u98ce\u9669\uff0c\u4f46\u9ad8\u8d44\u6e90\u6210\u672c\u4f7f\u4f01\u4e1a\u4e0d\u613f\u66f4\u65b0\u3002\u9700\u8981\u6210\u672c\u6548\u76ca\u9ad8\u7684\u81ea\u4e3b\u66f4\u65b0\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u8bbe\u8ba1\u540d\u4e3aVAPU\u7684\u591a\u4ee3\u7406\u7cfb\u7edf\uff0c\u6a21\u62df\u8f6f\u4ef6\u5f00\u53d1\u56e2\u961f\u4e0d\u540c\u89d2\u8272\uff0c\u5206\u9636\u6bb5\u66f4\u65b0\u4ee3\u7801\u6587\u4ef6\u3002\u6269\u5c55\u8bc4\u4f30\u4ece\u5355LLM\u5230\u4e94\u4e2aLLM\uff0c\u6d4b\u8bd5\u6e29\u5ea6\u53c2\u65700-1\u8bbe\u7f6e\uff0c\u4f7f\u752820\u4e2a\u5f00\u6e90Python\u9879\u76ee\u3002", "result": "\u5728\u4f4e\u6e29\u5ea6\u8bbe\u7f6e\u4e0b\uff0cVAPU\u4e0eZSL/OSL\u63d0\u793a\u76f8\u6bd4\u9519\u8bef\u6570\u76f8\u4f3c\u4f46\u9700\u6c42\u6ee1\u8db3\u7387\u66f4\u9ad8\uff0cPython\u6587\u4ef6\u66f4\u65b0\u9700\u6c42\u6210\u529f\u7387\u63d0\u5347\u8fbe22.5%\u3002", "conclusion": "\u57fa\u4e8eLLM\u7684\u591a\u4ee3\u7406\u7cfb\u7edf\u662f\u81ea\u4e3b\u66f4\u65b0\u9057\u7559\u5e94\u7528\u7a0b\u5e8f\u7ec4\u4ef6\u7684\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.18519", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.18519", "abs": "https://arxiv.org/abs/2510.18519", "authors": ["Md Arafat Hossain", "Jun Han", "Muhammad Ashad Kabir", "Steve Versteeg", "Jean-Guy Schneider", "Jiaojiao Jiang"], "title": "Mining Service Behavior for Stateful Service Emulation", "comment": "19 pages", "summary": "Enterprise software systems are increasingly integrating with diverse\nservices to meet expanding business demands. Testing these highly\ninterconnected systems presents a challenge due to the need for access to the\nconnected services. Service virtualization has emerged as a widely used\ntechnique to derive service models from recorded interactions, for service\nresponse generation during system testing. Various methods have been proposed\nto emulate actual service behavior based on these interactions, but most fail\nto account for the service's state, which reduces the accuracy of service\nemulation and the realism of the testing environment, especially when dealing\nwith stateful services. This paper proposes an approach to deriving service\nmodels from service interactions, which enhance the accuracy of response\ngeneration by considering service state. This is achieved by uncovering\ncontextual dependencies among interaction messages and analyzing the\nrelationships between message data values. The approach is evaluated using\ninteraction traces collected from both stateful and stateless services, and the\nresults reveal notable enhancements in accuracy and efficiency over existing\napproaches in service response generation.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u8003\u8651\u670d\u52a1\u72b6\u6001\u7684\u670d\u52a1\u5efa\u6a21\u65b9\u6cd5\uff0c\u901a\u8fc7\u5206\u6790\u4ea4\u4e92\u6d88\u606f\u95f4\u7684\u4e0a\u4e0b\u6587\u4f9d\u8d56\u5173\u7cfb\u548c\u6570\u636e\u503c\u5173\u7cfb\uff0c\u63d0\u9ad8\u72b6\u6001\u5316\u670d\u52a1\u54cd\u5e94\u751f\u6210\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u670d\u52a1\u865a\u62df\u5316\u65b9\u6cd5\u5927\u591a\u5ffd\u7565\u670d\u52a1\u72b6\u6001\uff0c\u5bfc\u81f4\u670d\u52a1\u4eff\u771f\u51c6\u786e\u6027\u4e0d\u8db3\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u72b6\u6001\u5316\u670d\u52a1\u65f6\u6d4b\u8bd5\u73af\u5883\u771f\u5b9e\u6027\u964d\u4f4e\u3002", "method": "\u4ece\u670d\u52a1\u4ea4\u4e92\u4e2d\u63a8\u5bfc\u670d\u52a1\u6a21\u578b\uff0c\u901a\u8fc7\u63ed\u793a\u4ea4\u4e92\u6d88\u606f\u95f4\u7684\u4e0a\u4e0b\u6587\u4f9d\u8d56\u5173\u7cfb\u548c\u5206\u6790\u6d88\u606f\u6570\u636e\u503c\u4e4b\u95f4\u7684\u5173\u7cfb\u6765\u8003\u8651\u670d\u52a1\u72b6\u6001\u3002", "result": "\u4f7f\u7528\u72b6\u6001\u5316\u548c\u65e0\u72b6\u6001\u670d\u52a1\u7684\u4ea4\u4e92\u8f68\u8ff9\u8fdb\u884c\u8bc4\u4f30\uff0c\u7ed3\u679c\u663e\u793a\u5728\u670d\u52a1\u54cd\u5e94\u751f\u6210\u65b9\u9762\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u5728\u51c6\u786e\u6027\u548c\u6548\u7387\u4e0a\u6709\u663e\u8457\u63d0\u5347\u3002", "conclusion": "\u8003\u8651\u670d\u52a1\u72b6\u6001\u7684\u670d\u52a1\u5efa\u6a21\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u63d0\u9ad8\u670d\u52a1\u865a\u62df\u5316\u7684\u51c6\u786e\u6027\u548c\u6d4b\u8bd5\u73af\u5883\u7684\u771f\u5b9e\u6027\u3002"}}
{"id": "2510.18534", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.18534", "abs": "https://arxiv.org/abs/2510.18534", "authors": ["Uraz Odyurt", "Richard Loendersloot", "Tiedo Tinga"], "title": "Demonstrators for Industrial Cyber-Physical System Research: A Requirements Hierarchy Driven by Software-Intensive Design", "comment": null, "summary": "One of the challenges apparent in the organisation of research projects is\nthe uncertainties around the subject of demonstrators. A precise and detailed\nelicitation of the coverage for project demonstrators is often an afterthought\nand not sufficiently detailed during proposal writing. This practice leads to\ncontinuous confusion and a mismatch between targeted and achievable\ndemonstration of results, hindering progress. The reliance on the TRL scale as\na loose descriptor does not help either. We propose a demonstrator requirements\nelaboration framework aiming to evaluate the feasibility of targeted\ndemonstrations, making realistic adjustments, and assist in describing\nrequirements. In doing so, we define 5 hierarchical levels of demonstration,\nclearly connected to expectations, e.g., work package interaction, and also\nconnected to the project's industrial use-cases. The considered application\nscope in this paper is the domain of software-intensive systems and industrial\ncyber-physical systems. A complete validation is not accessible, as it would\nrequire application of our framework at the start of a project and observing\nthe results at the end, taking 4-5 years. Nonetheless, we have applied it to\ntwo research projects from our portfolio, one at the early and another at the\nfinal stages, revealing its effectiveness.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u6f14\u793a\u5668\u9700\u6c42\u7ec6\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u5b9a\u4e495\u4e2a\u5c42\u6b21\u5316\u7684\u6f14\u793a\u7ea7\u522b\u6765\u8bc4\u4f30\u76ee\u6807\u6f14\u793a\u7684\u53ef\u884c\u6027\uff0c\u8fdb\u884c\u73b0\u5b9e\u8c03\u6574\uff0c\u5e76\u5e2e\u52a9\u63cf\u8ff0\u9700\u6c42\u3002", "motivation": "\u7814\u7a76\u9879\u76ee\u4e2d\u6f14\u793a\u5668\u8986\u76d6\u8303\u56f4\u7684\u4e0d\u786e\u5b9a\u6027\u5bfc\u81f4\u76ee\u6807\u4e0e\u53ef\u5b9e\u73b0\u7684\u6f14\u793a\u7ed3\u679c\u4e4b\u95f4\u5b58\u5728\u4e0d\u5339\u914d\uff0c\u963b\u788d\u9879\u76ee\u8fdb\u5c55\u3002TRL\u91cf\u8868\u4f5c\u4e3a\u677e\u6563\u63cf\u8ff0\u7b26\u65e0\u6cd5\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u5b9a\u4e495\u4e2a\u5c42\u6b21\u5316\u7684\u6f14\u793a\u7ea7\u522b\uff0c\u660e\u786e\u4e0e\u671f\u671b\uff08\u5982\u5de5\u4f5c\u5305\u4ea4\u4e92\uff09\u548c\u9879\u76ee\u5de5\u4e1a\u7528\u4f8b\u76f8\u5173\u8054\u3002\u5728\u8f6f\u4ef6\u5bc6\u96c6\u578b\u7cfb\u7edf\u548c\u5de5\u4e1a\u4fe1\u606f\u7269\u7406\u7cfb\u7edf\u9886\u57df\u5e94\u7528\u8be5\u6846\u67b6\u3002", "result": "\u5728\u4e24\u4e2a\u7814\u7a76\u9879\u76ee\u4e2d\u8fdb\u884c\u4e86\u5e94\u7528\u9a8c\u8bc1\uff08\u4e00\u4e2a\u5728\u65e9\u671f\u9636\u6bb5\uff0c\u4e00\u4e2a\u5728\u6700\u7ec8\u9636\u6bb5\uff09\uff0c\u663e\u793a\u4e86\u8be5\u6846\u67b6\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u6f14\u793a\u5668\u9700\u6c42\u7ec6\u5316\u6846\u67b6\u80fd\u591f\u5e2e\u52a9\u8bc4\u4f30\u6f14\u793a\u53ef\u884c\u6027\u3001\u8fdb\u884c\u73b0\u5b9e\u8c03\u6574\uff0c\u5e76\u6709\u6548\u63cf\u8ff0\u9700\u6c42\uff0c\u5c3d\u7ba1\u5b8c\u6574\u7684\u9a8c\u8bc1\u9700\u89814-5\u5e74\u7684\u9879\u76ee\u5468\u671f\u3002"}}
{"id": "2510.18557", "categories": ["cs.SE", "quant-ph"], "pdf": "https://arxiv.org/pdf/2510.18557", "abs": "https://arxiv.org/abs/2510.18557", "authors": ["Jianjun Zhao"], "title": "When Abstraction Breaks Physics: Rethinking Modular Design in Quantum Software", "comment": "Accepted at the NIER track of the 40th IEEE/ACM International\n  Conference on Automated Software Engineering (ASE 2025)", "summary": "Abstraction is a fundamental principle in classical software engineering,\nwhich enables modularity, reusability, and scalability. However, quantum\nprograms adhere to fundamentally different semantics, such as unitarity,\nentanglement, the no-cloning theorem, and the destructive nature of\nmeasurement, which introduce challenges to the safe use of classical\nabstraction mechanisms. This paper identifies a fundamental conflict in quantum\nsoftware engineering: abstraction practices that are syntactically valid may\nviolate the physical constraints of quantum computation. We present three\nclasses of failure cases where naive abstraction breaks quantum semantics and\npropose a set of design principles for physically sound abstraction mechanisms.\nWe further propose research directions, including quantum-specific type\nsystems, effect annotations, and contract-based module design. Our goal is to\ninitiate a systematic rethinking of abstraction in quantum software\nengineering, based on quantum semantics and considering engineering\nscalability.", "AI": {"tldr": "\u91cf\u5b50\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u7684\u62bd\u8c61\u673a\u5236\u5b58\u5728\u6839\u672c\u51b2\u7a81\uff1a\u8bed\u6cd5\u6709\u6548\u7684\u62bd\u8c61\u53ef\u80fd\u8fdd\u53cd\u91cf\u5b50\u8ba1\u7b97\u7684\u7269\u7406\u7ea6\u675f\u3002\u672c\u6587\u8bc6\u522b\u4e86\u4e09\u79cd\u5931\u8d25\u6848\u4f8b\uff0c\u63d0\u51fa\u4e86\u7269\u7406\u5b89\u5168\u62bd\u8c61\u7684\u8bbe\u8ba1\u539f\u5219\u548c\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u7ecf\u5178\u8f6f\u4ef6\u5de5\u7a0b\u7684\u62bd\u8c61\u539f\u5219\uff08\u6a21\u5757\u5316\u3001\u53ef\u91cd\u7528\u6027\u3001\u53ef\u6269\u5c55\u6027\uff09\u5728\u91cf\u5b50\u7a0b\u5e8f\u4e2d\u9762\u4e34\u6311\u6218\uff0c\u56e0\u4e3a\u91cf\u5b50\u8bed\u4e49\uff08\u5e7a\u6b63\u6027\u3001\u7ea0\u7f20\u3001\u4e0d\u53ef\u514b\u9686\u5b9a\u7406\u3001\u6d4b\u91cf\u7684\u7834\u574f\u6027\uff09\u4e0e\u7ecf\u5178\u62bd\u8c61\u673a\u5236\u5b58\u5728\u51b2\u7a81\u3002", "method": "\u8bc6\u522b\u4e86\u4e09\u79cd\u62bd\u8c61\u7834\u574f\u91cf\u5b50\u8bed\u4e49\u7684\u5931\u8d25\u6848\u4f8b\uff0c\u63d0\u51fa\u4e86\u7269\u7406\u5b89\u5168\u62bd\u8c61\u673a\u5236\u7684\u8bbe\u8ba1\u539f\u5219\uff0c\u5305\u62ec\u91cf\u5b50\u7279\u5b9a\u7c7b\u578b\u7cfb\u7edf\u3001\u6548\u679c\u6ce8\u91ca\u548c\u57fa\u4e8e\u5951\u7ea6\u7684\u6a21\u5757\u8bbe\u8ba1\u3002", "result": "\u5c55\u793a\u4e86\u7ecf\u5178\u62bd\u8c61\u673a\u5236\u5728\u91cf\u5b50\u8ba1\u7b97\u4e2d\u7684\u5c40\u9650\u6027\uff0c\u63d0\u51fa\u4e86\u786e\u4fdd\u91cf\u5b50\u8bed\u4e49\u5b8c\u6574\u6027\u7684\u62bd\u8c61\u8bbe\u8ba1\u6846\u67b6\u3002", "conclusion": "\u9700\u8981\u57fa\u4e8e\u91cf\u5b50\u8bed\u4e49\u91cd\u65b0\u601d\u8003\u91cf\u5b50\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u7684\u62bd\u8c61\u673a\u5236\uff0c\u8003\u8651\u5de5\u7a0b\u53ef\u6269\u5c55\u6027\uff0c\u4e3a\u91cf\u5b50\u7f16\u7a0b\u8bed\u8a00\u548c\u5de5\u5177\u7684\u5f00\u53d1\u63d0\u4f9b\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2510.18560", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.18560", "abs": "https://arxiv.org/abs/2510.18560", "authors": ["Chunyang Li", "Yilun Zheng", "Xinting Huang", "Tianqing Fang", "Jiahao Xu", "Yangqiu Song", "Lihui Chen", "Han Hu"], "title": "WebDevJudge: Evaluating (M)LLMs as Critiques for Web Development Quality", "comment": null, "summary": "The paradigm of LLM-as-a-judge is emerging as a scalable and efficient\nalternative to human evaluation, demonstrating strong performance on\nwell-defined tasks. However, its reliability in open-ended tasks with dynamic\nenvironments and complex interactions remains unexplored. To bridge the gap, we\nintroduce WebDevJudge, a systematic benchmark for assessing LLM-as-a-judge\nperformance in web development, with support for both non-interactive\nevaluation based on static observations and continuous interactive evaluation\nwith a dynamic web environment. WebDevJudge comprises human preference labels\nover paired web implementations, annotated with structured and query-grounded\nrubrics to ensure high-quality ground truth. Using this benchmark, we\ncomprehensively evaluate various evaluators, including LLMs, MLLMs, and agentic\nworkflows. We systematically investigate the impact of different paradigms and\nguidance mechanisms. Our experiments reveal a significant gap between LLM\njudges and human experts. In-depth analysis indicates this gap stems from\nfundamental model limitations, including failures in recognizing functional\nequivalence, verifying task feasibility, and mitigating bias. Overall,\nWebDevJudge presents a significant challenge to LLM-as-a-judge, offering\ninsights to guide future research toward developing more reliable and capable\nautomated evaluators for complicated scenarios. Code and data are available at\nhttps://github.com/lcy2723/WebDevJudge.", "AI": {"tldr": "WebDevJudge\u662f\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30LLM\u4f5c\u4e3a\u8bc4\u5224\u8005\u5728\u7f51\u9875\u5f00\u53d1\u4efb\u52a1\u4e2d\u6027\u80fd\u7684\u7cfb\u7edf\u57fa\u51c6\uff0c\u63ed\u793a\u4e86LLM\u8bc4\u5224\u8005\u4e0e\u4eba\u7c7b\u4e13\u5bb6\u4e4b\u95f4\u5b58\u5728\u663e\u8457\u5dee\u8ddd\u3002", "motivation": "LLM\u4f5c\u4e3a\u8bc4\u5224\u8005\u8303\u5f0f\u5728\u5b9a\u4e49\u660e\u786e\u7684\u4efb\u52a1\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u52a8\u6001\u73af\u5883\u548c\u590d\u6742\u4ea4\u4e92\u7684\u5f00\u653e\u5f0f\u4efb\u52a1\u4e2d\u7684\u53ef\u9760\u6027\u5c1a\u672a\u63a2\u7d22\u3002", "method": "\u6784\u5efaWebDevJudge\u57fa\u51c6\uff0c\u5305\u542b\u57fa\u4e8e\u9759\u6001\u89c2\u5bdf\u7684\u975e\u4ea4\u4e92\u5f0f\u8bc4\u4f30\u548c\u52a8\u6001\u7f51\u9875\u73af\u5883\u7684\u8fde\u7eed\u4ea4\u4e92\u5f0f\u8bc4\u4f30\uff0c\u4f7f\u7528\u7ed3\u6784\u5316\u4e14\u57fa\u4e8e\u67e5\u8be2\u7684\u8bc4\u5206\u6807\u51c6\u6807\u6ce8\u4eba\u7c7b\u504f\u597d\u6807\u7b7e\u3002", "result": "\u5b9e\u9a8c\u53d1\u73b0LLM\u8bc4\u5224\u8005\u4e0e\u4eba\u7c7b\u4e13\u5bb6\u5b58\u5728\u663e\u8457\u5dee\u8ddd\uff0c\u4e3b\u8981\u6e90\u4e8e\u6a21\u578b\u5728\u8bc6\u522b\u529f\u80fd\u7b49\u4ef7\u6027\u3001\u9a8c\u8bc1\u4efb\u52a1\u53ef\u884c\u6027\u4ee5\u53ca\u51cf\u5c11\u504f\u89c1\u65b9\u9762\u7684\u6839\u672c\u5c40\u9650\u6027\u3002", "conclusion": "WebDevJudge\u5bf9LLM\u4f5c\u4e3a\u8bc4\u5224\u8005\u8303\u5f0f\u63d0\u51fa\u4e86\u91cd\u5927\u6311\u6218\uff0c\u4e3a\u672a\u6765\u5f00\u53d1\u66f4\u53ef\u9760\u7684\u590d\u6742\u573a\u666f\u81ea\u52a8\u5316\u8bc4\u4f30\u5668\u63d0\u4f9b\u4e86\u6307\u5bfc\u3002"}}
{"id": "2510.18590", "categories": ["cs.SE", "cs.HC", "D.2.2; D.2.11; K.6.3"], "pdf": "https://arxiv.org/pdf/2510.18590", "abs": "https://arxiv.org/abs/2510.18590", "authors": ["Antonio Lamanna"], "title": "A Structured Evaluation Framework for Low-Code Platform Selection: A Multi-Criteria Decision Model for Enterprise Digital Transformation", "comment": "15 pages, 1 figure. PDF-only submission (XeLaTeX)", "summary": "The rapid adoption of Low-Code Development Platforms (LCDPs) has created a\ncritical need for systematic evaluation methodologies that enable organizations\nto make informed platform selection decisions. This paper presents a\ncomprehensive evaluation framework based on five key criteria: Business Process\nOrchestration, UI/UX Customization, Integration and Interoperability,\nGovernance and Security, and AI-Enhanced Automation. We propose a weighted\nscoring model that allows organizations to quantitatively assess and compare\ndifferent low-code platforms based on their specific requirements and strategic\npriorities. The framework addresses the gap between marketing-driven platform\ncomparisons and rigorous, context-specific evaluation methodologies. Through\nempirical validation in enterprise environments, we demonstrate how this\nstructured approach can significantly improve decision-making outcomes and\nreduce the risk of platform lock-in or inadequate solution selection.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u4e94\u4e2a\u5173\u952e\u6807\u51c6\u7684\u4f4e\u4ee3\u7801\u5f00\u53d1\u5e73\u53f0\u7efc\u5408\u8bc4\u4f30\u6846\u67b6\uff0c\u5305\u542b\u52a0\u6743\u8bc4\u5206\u6a21\u578b\uff0c\u5e2e\u52a9\u4f01\u4e1a\u6839\u636e\u7279\u5b9a\u9700\u6c42\u5b9a\u91cf\u8bc4\u4f30\u548c\u6bd4\u8f83\u4e0d\u540c\u5e73\u53f0\u3002", "motivation": "\u4f4e\u4ee3\u7801\u5f00\u53d1\u5e73\u53f0\u7684\u5feb\u901f\u666e\u53ca\u4ea7\u751f\u4e86\u5bf9\u7cfb\u7edf\u5316\u8bc4\u4f30\u65b9\u6cd5\u7684\u9700\u6c42\uff0c\u4ee5\u5e2e\u52a9\u4f01\u4e1a\u505a\u51fa\u660e\u667a\u7684\u5e73\u53f0\u9009\u62e9\u51b3\u7b56\uff0c\u586b\u8865\u8425\u9500\u9a71\u52a8\u6bd4\u8f83\u4e0e\u4e25\u8c28\u8bc4\u4f30\u65b9\u6cd5\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002", "method": "\u57fa\u4e8e\u4e94\u4e2a\u5173\u952e\u6807\u51c6\uff08\u4e1a\u52a1\u6d41\u7a0b\u7f16\u6392\u3001UI/UX\u5b9a\u5236\u3001\u96c6\u6210\u4e0e\u4e92\u64cd\u4f5c\u6027\u3001\u6cbb\u7406\u4e0e\u5b89\u5168\u3001AI\u589e\u5f3a\u81ea\u52a8\u5316\uff09\u6784\u5efa\u8bc4\u4f30\u6846\u67b6\uff0c\u91c7\u7528\u52a0\u6743\u8bc4\u5206\u6a21\u578b\u8fdb\u884c\u5b9a\u91cf\u8bc4\u4f30\u3002", "result": "\u5728\u4f01\u4e1a\u73af\u5883\u4e2d\u8fdb\u884c\u5b9e\u8bc1\u9a8c\u8bc1\uff0c\u8bc1\u660e\u8fd9\u79cd\u7ed3\u6784\u5316\u65b9\u6cd5\u80fd\u663e\u8457\u6539\u5584\u51b3\u7b56\u7ed3\u679c\uff0c\u964d\u4f4e\u5e73\u53f0\u9501\u5b9a\u6216\u9009\u62e9\u4e0d\u5f53\u89e3\u51b3\u65b9\u6848\u7684\u98ce\u9669\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u7ec4\u7ec7\u63d0\u4f9b\u4e86\u7cfb\u7edf\u5316\u7684\u4f4e\u4ee3\u7801\u5e73\u53f0\u8bc4\u4f30\u65b9\u6cd5\uff0c\u652f\u6301\u57fa\u4e8e\u7279\u5b9a\u9700\u6c42\u548c\u6218\u7565\u4f18\u5148\u7ea7\u7684\u5b9a\u91cf\u6bd4\u8f83\uff0c\u6709\u52a9\u4e8e\u4f18\u5316\u5e73\u53f0\u9009\u62e9\u51b3\u7b56\u3002"}}
{"id": "2510.18596", "categories": ["cs.SE", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.18596", "abs": "https://arxiv.org/abs/2510.18596", "authors": ["Haojia Lin", "Xiaoyu Tan", "Yulei Qin", "Zihan Xu", "Yuchen Shi", "Zongyi Li", "Gang Li", "Shaofei Cai", "Siqi Cai", "Chaoyou Fu", "Ke Li", "Xing Sun"], "title": "CUARewardBench: A Benchmark for Evaluating Reward Models on Computer-using Agent", "comment": "24 pages, 6 figures", "summary": "Computer-using agents (CUAs) enable task completion through natural\ninteraction with operating systems and software interfaces. While script-based\nverifiers are widely adopted for evaluation, they suffer from limited\nscalability and inability to provide step-wise assessment. Reward models offer\npromising alternatives, but their effectiveness on CUA evaluation remains\nlargely underexplored. To address this gap, we present CUARewardBench,\ncomprising four key contributions: (1) First-ever Comprehensive CUA Reward\nBenchmark: We introduce the first benchmark for evaluating both outcome reward\nmodels (ORM) and process reward models (PRM) on CUA tasks, enabling systematic\nassessment across trajectory-level and step-level evaluation. (2) Diverse,\nPractical and Reliable Dataset: CUARewardBench encompasses trajectories from 10\nsoftware categories and 7 agent architectures with varying performance levels\n(25.9%-50.8% success rates). All trajectories are expertly annotated through\ncarefully designed protocols, with rigorous quality control to ensure\nreliability and practical applicability. (3) Comprehensive Analysis and\nInsights: Through extensive experiments across 7 vision-language models and 3\nprompt templates, we reveal critical limitations of current CUA RMs, including\ninsufficient visual reasoning capabilities, knowledge deficiencies, and the\nsuperiority of general VLMs over specialized CUA models for reward evaluation.\n(4) Unanimous Prompt Ensemble (UPE): Based on the insights from our\ncomprehensive analysis, we propose UPE, a novel ensemble method that\nsignificantly enhances reward model reliability through strict unanimous voting\nand strategic prompt-template configurations. UPE achieves 89.8% precision and\n93.3% NPV for ORM, and 81.7% precision and 85.1% NPV for PRM, substantially\noutperforming single VLMs and traditional ensemble approaches.", "AI": {"tldr": "\u63d0\u51fa\u4e86CUARewardBench\uff0c\u8fd9\u662f\u9996\u4e2a\u7528\u4e8e\u8bc4\u4f30\u8ba1\u7b97\u673a\u4f7f\u7528\u4ee3\u7406\uff08CUA\uff09\u5956\u52b1\u6a21\u578b\u7684\u57fa\u51c6\uff0c\u5305\u542b\u8f68\u8ff9\u7ea7\u548c\u6b65\u9aa4\u7ea7\u8bc4\u4f30\uff0c\u5e76\u901a\u8fc7Unanimous Prompt Ensemble\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u5956\u52b1\u6a21\u578b\u7684\u53ef\u9760\u6027\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8e\u811a\u672c\u7684\u9a8c\u8bc1\u5668\u5728\u8bc4\u4f30CUA\u65f6\u5b58\u5728\u53ef\u6269\u5c55\u6027\u5dee\u548c\u65e0\u6cd5\u63d0\u4f9b\u9010\u6b65\u8bc4\u4f30\u7684\u95ee\u9898\uff0c\u800c\u5956\u52b1\u6a21\u578b\u4f5c\u4e3a\u66ff\u4ee3\u65b9\u6848\u7684\u6f5c\u529b\u5c1a\u672a\u5145\u5206\u63a2\u7d22\u3002", "method": "\u6784\u5efa\u4e86\u5305\u542b10\u4e2a\u8f6f\u4ef6\u7c7b\u522b\u548c7\u79cd\u4ee3\u7406\u67b6\u6784\u7684\u591a\u6837\u5316\u6570\u636e\u96c6\uff0c\u8bbe\u8ba1\u4e86\u4e13\u5bb6\u6807\u6ce8\u534f\u8bae\uff0c\u5e76\u63d0\u51fa\u4e86Unanimous Prompt Ensemble\uff08UPE\uff09\u96c6\u6210\u65b9\u6cd5\uff0c\u901a\u8fc7\u4e25\u683c\u7684\u4e00\u81f4\u6295\u7968\u548c\u7b56\u7565\u6027\u63d0\u793a\u6a21\u677f\u914d\u7f6e\u6765\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002", "result": "UPE\u65b9\u6cd5\u5728\u7ed3\u679c\u5956\u52b1\u6a21\u578b\uff08ORM\uff09\u4e0a\u8fbe\u523089.8%\u7cbe\u786e\u5ea6\u548c93.3%\u8d1f\u9884\u6d4b\u503c\uff0c\u5728\u8fc7\u7a0b\u5956\u52b1\u6a21\u578b\uff08PRM\uff09\u4e0a\u8fbe\u523081.7%\u7cbe\u786e\u5ea6\u548c85.1%\u8d1f\u9884\u6d4b\u503c\uff0c\u663e\u8457\u4f18\u4e8e\u5355\u4e00\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u548c\u4f20\u7edf\u96c6\u6210\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u7814\u7a76\u63ed\u793a\u4e86\u5f53\u524dCUA\u5956\u52b1\u6a21\u578b\u7684\u5173\u952e\u5c40\u9650\u6027\uff0c\u8bc1\u660e\u4e86\u901a\u7528\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u5956\u52b1\u8bc4\u4f30\u4e2d\u4f18\u4e8e\u4e13\u95e8\u7684CUA\u6a21\u578b\uff0c\u5e76\u901a\u8fc7UPE\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u5956\u52b1\u6a21\u578b\u7684\u53ef\u9760\u6027\u3002"}}
{"id": "2510.18711", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.18711", "abs": "https://arxiv.org/abs/2510.18711", "authors": ["Bertha Ngereja", "Magne J\u00f8rgensen"], "title": "An overview of the use of alternative funding and contracting approaches relevant for agile software development: A systematic review of real-life experiences", "comment": "48 pages, 6 tables, 6 figures and 3 appendices", "summary": "Agile software development emphasizes flexibility and iterative processes,\nwhich may conflict with the more linear, rigid, and time-consuming traditional\nfunding and contracting approaches. This review synthesizes real-life\nexperiences of using alternative (non-traditional) contracting and funding\napproaches. The focus is on identifying approaches that align better with agile\nprinciples and understanding the motivations, benefits, and challenges these\nalternatives present. A systematic literature review was conducted in SCOPUS,\nWeb of Science, and Google Scholar, where we identified 38 relevant\npeer-reviewed empirical studies from private and public sector contexts. Four\nalternative funding and four alternative contracting approaches were\nidentified. Organizations were motivated to adopt these alternative approaches\nbecause traditional approaches often proved too rigid, conflicted with agile\nprinciples, hindered effective client-contractor collaboration, and limited\nprofitability. The benefits of these alternatives included higher client\nsatisfaction, reduced contractor risk, and more efficient resource utilization.\nAdopting alternative funding and contracting approaches may promote flexibility\nand efficiency in agile projects but also presents cultural and structural\nchallenges, increases the risk of scope creep and analysis paralysis, and\nrequires additional effort in terms of time and resources. The context of the\norganization matters highly in selecting a suitable approach, such as the\norganizational readiness in terms of its leaders, people, and systems. Thus,\ninstead of wholly adopting alternative approaches and introducing changes\nabruptly, organizations may benefit from starting with hybrid approaches that\nbalance flexibility and control and progressively transition to fully flexible\napproaches tailored to their needs", "AI": {"tldr": "\u8fd9\u7bc7\u7efc\u8ff0\u7814\u7a76\u4e86\u654f\u6377\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u66ff\u4ee3\u6027\u5408\u540c\u4e0e\u8d44\u91d1\u65b9\u6cd5\uff0c\u8bc6\u522b\u4e864\u79cd\u66ff\u4ee3\u8d44\u91d1\u65b9\u6cd5\u548c4\u79cd\u66ff\u4ee3\u5408\u540c\u65b9\u6cd5\uff0c\u5206\u6790\u4e86\u91c7\u7528\u8fd9\u4e9b\u65b9\u6cd5\u7684\u52a8\u673a\u3001\u6536\u76ca\u548c\u6311\u6218\u3002", "motivation": "\u4f20\u7edf\u8d44\u91d1\u548c\u5408\u540c\u65b9\u6cd5\u8fc7\u4e8e\u521a\u6027\uff0c\u4e0e\u654f\u6377\u539f\u5219\u51b2\u7a81\uff0c\u963b\u788d\u5ba2\u6237-\u627f\u5305\u5546\u534f\u4f5c\uff0c\u9650\u5236\u76c8\u5229\u80fd\u529b\uff0c\u56e0\u6b64\u9700\u8981\u5bfb\u627e\u66f4\u7075\u6d3b\u7684\u66ff\u4ee3\u65b9\u6cd5\u3002", "method": "\u5728SCOPUS\u3001Web of Science\u548cGoogle Scholar\u4e2d\u8fdb\u884c\u4e86\u7cfb\u7edf\u6587\u732e\u7efc\u8ff0\uff0c\u8bc6\u522b\u4e8638\u7bc7\u76f8\u5173\u5b9e\u8bc1\u7814\u7a76\uff0c\u6db5\u76d6\u79c1\u4eba\u548c\u516c\u5171\u90e8\u95e8\u80cc\u666f\u3002", "result": "\u8bc6\u522b\u4e864\u79cd\u66ff\u4ee3\u8d44\u91d1\u65b9\u6cd5\u548c4\u79cd\u66ff\u4ee3\u5408\u540c\u65b9\u6cd5\u3002\u91c7\u7528\u8fd9\u4e9b\u65b9\u6cd5\u7684\u597d\u5904\u5305\u62ec\u63d0\u9ad8\u5ba2\u6237\u6ee1\u610f\u5ea6\u3001\u964d\u4f4e\u627f\u5305\u5546\u98ce\u9669\u3001\u66f4\u9ad8\u6548\u7684\u8d44\u6e90\u5229\u7528\u3002\u6311\u6218\u5305\u62ec\u6587\u5316\u7ed3\u6784\u969c\u788d\u3001\u8303\u56f4\u8513\u5ef6\u98ce\u9669\u3001\u9700\u8981\u989d\u5916\u65f6\u95f4\u548c\u8d44\u6e90\u6295\u5165\u3002", "conclusion": "\u7ec4\u7ec7\u5e94\u91c7\u7528\u6df7\u5408\u65b9\u6cd5\u5e73\u8861\u7075\u6d3b\u6027\u548c\u63a7\u5236\uff0c\u9010\u6b65\u8fc7\u6e21\u5230\u5b8c\u5168\u7075\u6d3b\u7684\u65b9\u6cd5\uff0c\u7ec4\u7ec7\u80cc\u666f\u5728\u9009\u62e9\u5408\u9002\u65b9\u6cd5\u65f6\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2510.18719", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.18719", "abs": "https://arxiv.org/abs/2510.18719", "authors": ["Chengwen Du", "Tao Chen"], "title": "Causally Perturbed Fairness Testing", "comment": "accepted by TOSEM", "summary": "To mitigate unfair and unethical discrimination over sensitive features\n(e.g., gender, age, or race), fairness testing plays an integral role in\nengineering systems that leverage AI models to handle tabular data. A key\nchallenge therein is how to effectively reveal fairness bugs under an\nintractable sample size using perturbation. Much current work has been focusing\non designing the test sample generators, ignoring the valuable knowledge about\ndata characteristics that can help guide the perturbation and hence limiting\ntheir full potential. In this paper, we seek to bridge such a gap by proposing\na generic framework of causally perturbed fairness testing, dubbed CausalFT.\nThrough causal inference, the key idea of CausalFT is to extract the most\ndirectly and causally relevant non-sensitive feature to its sensitive\ncounterpart, which can jointly influence the prediction of the label. Such a\ncausal relationship is then seamlessly injected into the perturbation to guide\na test sample generator. Unlike existing generator-level work, CausalFT serves\nas a higher-level framework that can be paired with diverse base generators.\nExtensive experiments on 1296 cases confirm that CausalFT can considerably\nimprove arbitrary base generators in revealing fairness bugs over 93% of the\ncases with acceptable extra runtime overhead. Compared with a state-of-the-art\napproach that ranks the non-sensitive features solely based on correlation,\nCausalFT performs significantly better on 64% cases while being much more\nefficient. Further, CausalFT can better improve bias resilience in nearly all\ncases.", "AI": {"tldr": "CausalFT\u662f\u4e00\u4e2a\u57fa\u4e8e\u56e0\u679c\u63a8\u7406\u7684\u516c\u5e73\u6027\u6d4b\u8bd5\u6846\u67b6\uff0c\u901a\u8fc7\u63d0\u53d6\u4e0e\u654f\u611f\u7279\u5f81\u56e0\u679c\u76f8\u5173\u7684\u975e\u654f\u611f\u7279\u5f81\u6765\u6307\u5bfc\u6d4b\u8bd5\u6837\u672c\u751f\u6210\uff0c\u663e\u8457\u63d0\u5347\u73b0\u6709\u6d4b\u8bd5\u751f\u6210\u5668\u7684\u516c\u5e73\u6027\u7f3a\u9677\u68c0\u6d4b\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u516c\u5e73\u6027\u6d4b\u8bd5\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u6d4b\u8bd5\u6837\u672c\u751f\u6210\u5668\u7684\u8bbe\u8ba1\uff0c\u800c\u5ffd\u7565\u4e86\u6570\u636e\u7279\u5f81\u7684\u77e5\u8bc6\uff0c\u8fd9\u4e9b\u77e5\u8bc6\u53ef\u4ee5\u5e2e\u52a9\u6307\u5bfc\u6270\u52a8\u8fc7\u7a0b\uff0c\u4ece\u800c\u9650\u5236\u4e86\u5b83\u4eec\u7684\u6f5c\u529b\u3002", "method": "\u901a\u8fc7\u56e0\u679c\u63a8\u7406\u63d0\u53d6\u4e0e\u654f\u611f\u7279\u5f81\u6700\u76f4\u63a5\u56e0\u679c\u76f8\u5173\u7684\u975e\u654f\u611f\u7279\u5f81\uff0c\u5e76\u5c06\u8fd9\u79cd\u56e0\u679c\u5173\u7cfb\u6ce8\u5165\u5230\u6270\u52a8\u8fc7\u7a0b\u4e2d\uff0c\u6307\u5bfc\u6d4b\u8bd5\u6837\u672c\u751f\u6210\u5668\u3002", "result": "\u57281296\u4e2a\u6d4b\u8bd5\u6848\u4f8b\u4e2d\uff0cCausalFT\u80fd\u572893%\u7684\u60c5\u51b5\u4e0b\u663e\u8457\u63d0\u5347\u4efb\u610f\u57fa\u7840\u751f\u6210\u5668\u7684\u516c\u5e73\u6027\u7f3a\u9677\u68c0\u6d4b\u80fd\u529b\uff0c\u4e14\u989d\u5916\u8fd0\u884c\u65f6\u95f4\u5f00\u9500\u53ef\u63a5\u53d7\u3002\u4e0e\u57fa\u4e8e\u76f8\u5173\u6027\u7684\u65b9\u6cd5\u76f8\u6bd4\uff0c\u572864%\u7684\u60c5\u51b5\u4e0b\u8868\u73b0\u66f4\u597d\u4e14\u66f4\u9ad8\u6548\u3002", "conclusion": "CausalFT\u4f5c\u4e3a\u4e00\u4e2a\u9ad8\u5c42\u6846\u67b6\uff0c\u80fd\u591f\u6709\u6548\u63d0\u5347\u516c\u5e73\u6027\u6d4b\u8bd5\u7684\u6548\u679c\uff0c\u5e76\u589e\u5f3a\u6a21\u578b\u7684\u504f\u5dee\u62b5\u6297\u80fd\u529b\u3002"}}
{"id": "2510.18787", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.18787", "abs": "https://arxiv.org/abs/2510.18787", "authors": ["Quim Motger", "Carlota Catot", "Xavier Franch"], "title": "ShaRE your Data! Characterizing Datasets for LLM-based Requirements Engineering", "comment": "Under review", "summary": "[Context] Large Language Models (LLMs) rely on domain-specific datasets to\nachieve robust performance across training and inference stages. However, in\nRequirements Engineering (RE), data scarcity remains a persistent limitation\nreported in surveys and mapping studies. [Question/Problem] Although there are\nmultiple datasets supporting LLM-based RE tasks (LLM4RE), they are fragmented\nand poorly characterized, limiting reuse and comparability. This research\naddresses the limited visibility and characterization of datasets used in\nLLM4RE. We investigate which public datasets are employed, how they can be\nsystematically characterized, and which RE tasks and dataset descriptors remain\nunder-represented. [Ideas/Results] To address this, we conduct a systematic\nmapping study to identify and analyse datasets used in LLM4RE research. A total\nof 62 publicly available datasets are referenced across 43 primary studies.\nEach dataset is characterized along descriptors such as artifact type,\ngranularity, RE stage, task, domain, and language. Preliminary findings show\nmultiple research gaps, including limited coverage for elicitation tasks,\nscarce datasets for management activities beyond traceability, and limited\nmultilingual availability. [Contribution] This research preview offers a public\ncatalogue and structured characterization scheme to support dataset selection,\ncomparison, and reuse in LLM4RE research. Future work will extend the scope to\ngrey literature, as well as integration with open dataset and benchmark\nrepositories.", "AI": {"tldr": "\u672c\u6587\u5bf9LLM\u5728\u9700\u6c42\u5de5\u7a0b\u4e2d\u4f7f\u7528\u7684\u6570\u636e\u96c6\u8fdb\u884c\u4e86\u7cfb\u7edf\u6027\u6620\u5c04\u7814\u7a76\uff0c\u8bc6\u522b\u4e8662\u4e2a\u516c\u5f00\u6570\u636e\u96c6\uff0c\u53d1\u73b0\u6570\u636e\u96c6\u788e\u7247\u5316\u3001\u8868\u5f81\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u4e86\u5206\u7c7b\u6846\u67b6\u548c\u516c\u5171\u76ee\u5f55\u3002", "motivation": "\u9700\u6c42\u5de5\u7a0b\u9886\u57df\u5b58\u5728\u6570\u636e\u7a00\u7f3a\u95ee\u9898\uff0c\u73b0\u6709\u7684LLM4RE\u6570\u636e\u96c6\u5206\u6563\u4e14\u7f3a\u4e4f\u7cfb\u7edf\u8868\u5f81\uff0c\u9650\u5236\u4e86\u6570\u636e\u96c6\u7684\u590d\u7528\u548c\u6bd4\u8f83\u3002", "method": "\u901a\u8fc7\u7cfb\u7edf\u6027\u6620\u5c04\u7814\u7a76\uff0c\u8bc6\u522b\u548c\u5206\u6790LLM4RE\u7814\u7a76\u4e2d\u4f7f\u7528\u7684\u6570\u636e\u96c6\uff0c\u6309\u5de5\u4ef6\u7c7b\u578b\u3001\u7c92\u5ea6\u3001RE\u9636\u6bb5\u3001\u4efb\u52a1\u3001\u9886\u57df\u548c\u8bed\u8a00\u7b49\u63cf\u8ff0\u7b26\u8fdb\u884c\u5206\u7c7b\u3002", "result": "\u4ece43\u9879\u4e3b\u8981\u7814\u7a76\u4e2d\u8bc6\u522b\u51fa62\u4e2a\u516c\u5f00\u6570\u636e\u96c6\uff0c\u53d1\u73b0\u5b58\u5728\u7814\u7a76\u7a7a\u767d\uff1a\u9700\u6c42\u83b7\u53d6\u4efb\u52a1\u8986\u76d6\u6709\u9650\u3001\u7ba1\u7406\u6d3b\u52a8\u6570\u636e\u96c6\u7a00\u7f3a\u3001\u591a\u8bed\u8a00\u53ef\u7528\u6027\u4e0d\u8db3\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u4f9b\u4e86\u6570\u636e\u96c6\u76ee\u5f55\u548c\u7ed3\u6784\u5316\u8868\u5f81\u65b9\u6848\uff0c\u652f\u6301LLM4RE\u7814\u7a76\u4e2d\u7684\u6570\u636e\u9009\u62e9\u3001\u6bd4\u8f83\u548c\u590d\u7528\uff0c\u672a\u6765\u5c06\u6269\u5c55\u81f3\u7070\u8272\u6587\u732e\u5e76\u4e0e\u5f00\u653e\u6570\u636e\u96c6\u5e93\u96c6\u6210\u3002"}}
{"id": "2510.18799", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.18799", "abs": "https://arxiv.org/abs/2510.18799", "authors": ["Max Tiessler", "Quim Motger"], "title": "FeClustRE: Hierarchical Clustering and Semantic Tagging of App Features from User Reviews", "comment": "Under review", "summary": "[Context and motivation.] Extracting features from mobile app reviews is\nincreasingly important for multiple requirements engineering (RE) tasks.\nHowever, existing methods struggle to turn noisy, ambiguous feedback into\ninterpretable insights. [Question/problem.] Syntactic approaches lack semantic\ndepth, while large language models (LLMs) often miss fine-grained features or\nfail to structure them coherently. In addition, existing methods output flat\nlists of features without semantic organization, limiting interpretation and\ncomparability. Consequently, current feature extraction approaches do not\nprovide structured, meaningful representations of app features. As a result,\npractitioners face fragmented information that hinder requirement analysis,\nprioritization, and cross-app comparison, among other use cases. [Principal\nideas/results.] In this context, we propose FeClustRE, a framework integrating\nhybrid feature extraction, hierarchical clustering with auto-tuning and\nLLM-based semantic labelling. FeClustRE combines syntactic parsing with LLM\nenrichment, organizes features into clusters, and automatically generates\nmeaningful taxonomy labels. We evaluate FeClustRE on public benchmarks for\nextraction correctness and on a sample study of generative AI assistant app\nreviews for clustering quality, semantic coherence, and interpretability.\n[Contribution.] Overall, FeClustRE delivers (1) a hybrid framework for feature\nextraction and taxonomy generation, (2) an auto-tuning mechanism with a\ncomprehensive evaluation methodology, and (3) open-source and replicable\nimplementation. These contributions bridge user feedback and feature\nunderstanding, enabling deeper insights into current and emerging requirements.", "AI": {"tldr": "FeClustRE\u662f\u4e00\u4e2a\u4ece\u79fb\u52a8\u5e94\u7528\u8bc4\u8bba\u4e2d\u63d0\u53d6\u7279\u5f81\u5e76\u751f\u6210\u5c42\u6b21\u5316\u5206\u7c7b\u7684\u6846\u67b6\uff0c\u7ed3\u5408\u4e86\u8bed\u6cd5\u89e3\u6790\u3001LLM\u589e\u5f3a\u3001\u81ea\u52a8\u8c03\u4f18\u7684\u5c42\u6b21\u805a\u7c7b\u548c\u8bed\u4e49\u6807\u6ce8\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u7279\u5f81\u63d0\u53d6\u548c\u7ed3\u6784\u5316\u65b9\u9762\u7684\u4e0d\u8db3\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u5c06\u5608\u6742\u3001\u6a21\u7cca\u7684\u7528\u6237\u53cd\u9988\u8f6c\u5316\u4e3a\u53ef\u89e3\u91ca\u7684\u89c1\u89e3\uff0c\u8bed\u6cd5\u65b9\u6cd5\u7f3a\u4e4f\u8bed\u4e49\u6df1\u5ea6\uff0c\u800cLLM\u65b9\u6cd5\u5f80\u5f80\u9057\u6f0f\u7ec6\u7c92\u5ea6\u7279\u5f81\u6216\u65e0\u6cd5\u8fdb\u884c\u8fde\u8d2f\u7684\u7ed3\u6784\u5316\u7ec4\u7ec7\uff0c\u5bfc\u81f4\u7279\u5f81\u63d0\u53d6\u7ed3\u679c\u7f3a\u4e4f\u7ed3\u6784\u5316\u3001\u6709\u610f\u4e49\u7684\u8868\u793a\u3002", "method": "FeClustRE\u6574\u5408\u4e86\u6df7\u5408\u7279\u5f81\u63d0\u53d6\u3001\u81ea\u52a8\u8c03\u4f18\u7684\u5c42\u6b21\u805a\u7c7b\u548c\u57fa\u4e8eLLM\u7684\u8bed\u4e49\u6807\u6ce8\u3002\u5b83\u7ed3\u5408\u8bed\u6cd5\u89e3\u6790\u4e0eLLM\u589e\u5f3a\uff0c\u5c06\u7279\u5f81\u7ec4\u7ec7\u6210\u7c07\uff0c\u5e76\u81ea\u52a8\u751f\u6210\u6709\u610f\u4e49\u7684\u5206\u7c7b\u6807\u7b7e\u3002", "result": "\u5728\u516c\u5171\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8bc4\u4f30\u4e86\u63d0\u53d6\u6b63\u786e\u6027\uff0c\u5728\u751f\u6210\u5f0fAI\u52a9\u624b\u5e94\u7528\u8bc4\u8bba\u6837\u672c\u7814\u7a76\u4e2d\u8bc4\u4f30\u4e86\u805a\u7c7b\u8d28\u91cf\u3001\u8bed\u4e49\u8fde\u8d2f\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002", "conclusion": "FeClustRE\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6df7\u5408\u7279\u5f81\u63d0\u53d6\u548c\u5206\u7c7b\u751f\u6210\u7684\u6846\u67b6\uff0c\u5177\u6709\u81ea\u52a8\u8c03\u4f18\u673a\u5236\u548c\u5168\u9762\u7684\u8bc4\u4f30\u65b9\u6cd5\uff0c\u5f00\u6e90\u5b9e\u73b0\u53ef\u590d\u73b0\uff0c\u8fde\u63a5\u4e86\u7528\u6237\u53cd\u9988\u548c\u7279\u5f81\u7406\u89e3\uff0c\u652f\u6301\u5bf9\u5f53\u524d\u548c\u65b0\u5174\u9700\u6c42\u7684\u6df1\u5165\u6d1e\u5bdf\u3002"}}
{"id": "2510.18861", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.18861", "abs": "https://arxiv.org/abs/2510.18861", "authors": ["Pedro Lu\u00eds Fonseca", "Bruno Lima", "Jo\u00e3o Pascoal Faria"], "title": "Streamlining Acceptance Test Generation for Mobile Applications Through Large Language Models: An Industrial Case Study", "comment": null, "summary": "Mobile acceptance testing remains a bottleneck in modern software\ndevelopment, particularly for cross-platform mobile development using\nframeworks like Flutter. While developers increasingly rely on automated\ntesting tools, creating and maintaining acceptance test artifacts still demands\nsignificant manual effort. To help tackle this issue, we introduce AToMIC, an\nautomated framework leveraging specialized Large Language Models to generate\nGherkin scenarios, Page Objects, and executable UI test scripts directly from\nrequirements (JIRA tickets) and recent code changes. Applied to BMW's MyBMW\napp, covering 13 real-world issues in a 170+ screen codebase, AToMIC produced\nexecutable test artifacts in under five minutes per feature on standard\nhardware. The generated artifacts were of high quality: 93.3% of Gherkin\nscenarios were syntactically correct upon generation, 78.8% of PageObjects ran\nwithout manual edits, and 100% of generated UI tests executed successfully. In\na survey, all practitioners reported time savings (often a full developer-day\nper feature) and strong confidence in adopting the approach. These results\nconfirm AToMIC as a scalable, practical solution for streamlining acceptance\ntest creation and maintenance in industrial mobile projects.", "AI": {"tldr": "AToMIC\u662f\u4e00\u4e2a\u81ea\u52a8\u5316\u6846\u67b6\uff0c\u4f7f\u7528\u4e13\u7528\u5927\u8bed\u8a00\u6a21\u578b\u4ece\u9700\u6c42\u6587\u6863\u548c\u4ee3\u7801\u53d8\u66f4\u4e2d\u81ea\u52a8\u751f\u6210Gherkin\u573a\u666f\u3001\u9875\u9762\u5bf9\u8c61\u548c\u53ef\u6267\u884c\u7684UI\u6d4b\u8bd5\u811a\u672c\uff0c\u663e\u8457\u63d0\u5347\u4e86\u79fb\u52a8\u5e94\u7528\u9a8c\u6536\u6d4b\u8bd5\u7684\u6548\u7387\u3002", "motivation": "\u79fb\u52a8\u5e94\u7528\u9a8c\u6536\u6d4b\u8bd5\u5728\u73b0\u4ee3\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u4ecd\u662f\u74f6\u9888\uff0c\u7279\u522b\u662f\u5728\u4f7f\u7528Flutter\u7b49\u8de8\u5e73\u53f0\u6846\u67b6\u65f6\u3002\u867d\u7136\u5f00\u53d1\u8005\u8d8a\u6765\u8d8a\u4f9d\u8d56\u81ea\u52a8\u5316\u6d4b\u8bd5\u5de5\u5177\uff0c\u4f46\u521b\u5efa\u548c\u7ef4\u62a4\u9a8c\u6536\u6d4b\u8bd5\u5de5\u4ef6\u4ecd\u9700\u5927\u91cf\u4eba\u5de5\u5de5\u4f5c\u3002", "method": "\u5f15\u5165AToMIC\u6846\u67b6\uff0c\u5229\u7528\u4e13\u7528\u5927\u8bed\u8a00\u6a21\u578b\u76f4\u63a5\u4ece\u9700\u6c42\uff08JIRA\u5de5\u5355\uff09\u548c\u8fd1\u671f\u4ee3\u7801\u53d8\u66f4\u751f\u6210Gherkin\u573a\u666f\u3001\u9875\u9762\u5bf9\u8c61\u548c\u53ef\u6267\u884c\u7684UI\u6d4b\u8bd5\u811a\u672c\u3002", "result": "\u5728\u5b9d\u9a6cMyBMW\u5e94\u7528\u4e2d\u6d4b\u8bd5\uff0c\u8986\u76d613\u4e2a\u771f\u5b9e\u95ee\u9898\uff0c\u5728170+\u5c4f\u5e55\u7684\u4ee3\u7801\u5e93\u4e2d\uff0cAToMIC\u5728\u6807\u51c6\u786c\u4ef6\u4e0a\u6bcf\u529f\u80fd\u4e0d\u52305\u5206\u949f\u751f\u6210\u53ef\u6267\u884c\u6d4b\u8bd5\u5de5\u4ef6\u3002\u751f\u6210\u7684\u5de5\u4ef6\u8d28\u91cf\u9ad8\uff1a93.3%\u7684Gherkin\u573a\u666f\u5728\u751f\u6210\u65f6\u8bed\u6cd5\u6b63\u786e\uff0c78.8%\u7684\u9875\u9762\u5bf9\u8c61\u65e0\u9700\u624b\u52a8\u7f16\u8f91\u5373\u53ef\u8fd0\u884c\uff0c100%\u751f\u6210\u7684UI\u6d4b\u8bd5\u6210\u529f\u6267\u884c\u3002", "conclusion": "AToMIC\u662f\u4e00\u4e2a\u53ef\u6269\u5c55\u3001\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u7b80\u5316\u5de5\u4e1a\u79fb\u52a8\u9879\u76ee\u4e2d\u9a8c\u6536\u6d4b\u8bd5\u7684\u521b\u5efa\u548c\u7ef4\u62a4\uff0c\u6240\u6709\u5b9e\u8df5\u8005\u90fd\u62a5\u544a\u4e86\u65f6\u95f4\u8282\u7701\uff08\u901a\u5e38\u6bcf\u4e2a\u529f\u80fd\u8282\u7701\u4e00\u4e2a\u5b8c\u6574\u5f00\u53d1\u65e5\uff09\u5e76\u5bf9\u91c7\u7528\u8be5\u65b9\u6cd5\u6709\u5f3a\u70c8\u4fe1\u5fc3\u3002"}}
{"id": "2510.18863", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.18863", "abs": "https://arxiv.org/abs/2510.18863", "authors": ["Yanlin Wang", "Rongyi Ou", "Yanli Wang", "Mingwei Liu", "Jiachi Chen", "Ensheng Shi", "Xilin Liu", "Yuchi Ma", "Zibin Zheng"], "title": "EffiReasonTrans: RL-Optimized Reasoning for Code Translation", "comment": null, "summary": "Code translation is a crucial task in software development and maintenance.\nWhile recent advancements in large language models (LLMs) have improved\nautomated code translation accuracy, these gains often come at the cost of\nincreased inference latency, hindering real-world development workflows that\ninvolve human-in-the-loop inspection. To address this trade-off, we propose\nEffiReasonTrans, a training framework designed to improve translation accuracy\nwhile balancing inference latency. We first construct a high-quality\nreasoning-augmented dataset by prompting a stronger language model,\nDeepSeek-R1, to generate intermediate reasoning and target translations. Each\n(source code, reasoning, target code) triplet undergoes automated syntax and\nfunctionality checks to ensure reliability. Based on this dataset, we employ a\ntwo-stage training strategy: supervised fine-tuning on reasoning-augmented\nsamples, followed by reinforcement learning to further enhance accuracy and\nbalance inference latency. We evaluate EffiReasonTrans on six translation\npairs. Experimental results show that it consistently improves translation\naccuracy (up to +49.2% CA and +27.8% CodeBLEU compared to the base model) while\nreducing the number of generated tokens (up to -19.3%) and lowering inference\nlatency in most cases (up to -29.0%). Ablation studies further confirm the\ncomplementary benefits of the two-stage training framework. Additionally,\nEffiReasonTrans demonstrates improved translation accuracy when integrated into\nagent-based frameworks. Our code and data are available at\nhttps://github.com/DeepSoftwareAnalytics/EffiReasonTrans.", "AI": {"tldr": "EffiReasonTrans\u662f\u4e00\u4e2a\u4ee3\u7801\u7ffb\u8bd1\u8bad\u7ec3\u6846\u67b6\uff0c\u901a\u8fc7\u6784\u5efa\u63a8\u7406\u589e\u5f3a\u6570\u636e\u96c6\u548c\u4e24\u9636\u6bb5\u8bad\u7ec3\u7b56\u7565\uff0c\u5728\u63d0\u5347\u7ffb\u8bd1\u51c6\u786e\u6027\u7684\u540c\u65f6\u5e73\u8861\u63a8\u7406\u5ef6\u8fdf\u3002", "motivation": "\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4ee3\u7801\u7ffb\u8bd1\u4e2d\u51c6\u786e\u6027\u63d0\u5347\u4e0e\u63a8\u7406\u5ef6\u8fdf\u589e\u52a0\u4e4b\u95f4\u7684\u77db\u76fe\uff0c\u6ee1\u8db3\u5b9e\u9645\u5f00\u53d1\u5de5\u4f5c\u6d41\u4e2d\u9700\u8981\u4eba\u5de5\u68c0\u67e5\u7684\u9700\u6c42\u3002", "method": "1) \u4f7f\u7528\u66f4\u5f3a\u7684\u8bed\u8a00\u6a21\u578bDeepSeek-R1\u6784\u5efa\u63a8\u7406\u589e\u5f3a\u6570\u636e\u96c6\uff1b2) \u91c7\u7528\u4e24\u9636\u6bb5\u8bad\u7ec3\uff1a\u76d1\u7763\u5fae\u8c03+\u5f3a\u5316\u5b66\u4e60\uff1b3) \u81ea\u52a8\u5316\u8bed\u6cd5\u548c\u529f\u80fd\u68c0\u67e5\u786e\u4fdd\u6570\u636e\u8d28\u91cf\u3002", "result": "\u57286\u4e2a\u7ffb\u8bd1\u5bf9\u4e0a\uff0c\u7ffb\u8bd1\u51c6\u786e\u6027\u663e\u8457\u63d0\u5347\uff08\u6700\u9ad8+49.2% CA\u548c+27.8% CodeBLEU\uff09\uff0c\u751f\u6210token\u6570\u91cf\u51cf\u5c11\uff08\u6700\u9ad8-19.3%\uff09\uff0c\u63a8\u7406\u5ef6\u8fdf\u964d\u4f4e\uff08\u6700\u9ad8-29.0%\uff09\u3002", "conclusion": "EffiReasonTrans\u6846\u67b6\u6709\u6548\u5e73\u8861\u4e86\u4ee3\u7801\u7ffb\u8bd1\u7684\u51c6\u786e\u6027\u548c\u6548\u7387\uff0c\u5728\u57fa\u4e8e\u4ee3\u7406\u7684\u6846\u67b6\u4e2d\u4e5f\u8868\u73b0\u51fa\u6539\u8fdb\u7684\u7ffb\u8bd1\u51c6\u786e\u6027\u3002"}}
