<div id=toc></div>

# Table of Contents

- [cs.DC](#cs.DC) [Total: 4]
- [cs.DB](#cs.DB) [Total: 5]
- [cs.SE](#cs.SE) [Total: 6]


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [1] [Distributed Semi-Speculative Parallel Anisotropic Mesh Adaptation](https://arxiv.org/abs/2602.15204)
*Kevin Garner,Polykarpos Thomadakis,Nikos Chrisochoides*

Main category: cs.DC

TL;DR: 提出一种避免集体通信和全局同步的分布式内存各向异性网格自适应方法，通过分离网格生成与性能优化，实现高达10亿元素的大规模网格生成。


<details>
  <summary>Details</summary>
Motivation: 传统HPC网格自适应方法依赖集体通信和全局同步，限制了可扩展性。需要设计一种能充分利用新兴HPC架构并发性的分布式内存方法。

Method: 采用分离架构：多核cc-NUMA共享内存网格生成软件负责计算，并行运行时系统管理性能。先在单节点上分解初始网格并自适应接口元素，然后将子域分发到集群节点，自适应内部元素时冻结已适应的接口元素以保持网格一致性。

Result: 该方法能生成高达约10亿元素的网格，在质量和性能上与现有最先进的HPC网格软件相当，展示了良好的可扩展性。

Conclusion: 通过分离关注点和利用推测执行模型，实现了无需集体通信和全局同步的高效分布式内存网格自适应，为大规模HPC应用提供了可行的解决方案。

Abstract: This paper presents a distributed memory method for anisotropic mesh adaptation that is designed to avoid the use of collective communication and global synchronization techniques. In the presented method, meshing functionality is separated from performance aspects by utilizing a separate entity for each - a multicore cc-NUMA-based (shared memory) mesh generation software and a parallel runtime system that is designed to help applications leverage the concurrency offered by emerging high-performance computing (HPC) architectures. First, an initial mesh is decomposed and its interface elements (subdomain boundaries) are adapted on a single multicore node (shared memory). Subdomains are then distributed among the nodes of an HPC cluster so that their interior elements are adapted while interface elements (already adapted) remain frozen to maintain mesh conformity. Lessons are presented regarding some re-designs of the shared memory software and how its speculative execution model is utilized by the distributed memory method to achieve good performance. The presented method is shown to generate meshes (of up to approximately 1 billion elements) with comparable quality and performance to existing state-of-the-art HPC meshing software.

</details>


### [2] [Co-Design and Evaluation of a CPU-Free MPI GPU Communication Abstraction and Implementation](https://arxiv.org/abs/2602.15356)
*Patrick G. Bridges,Derek Schafer,Jack Lange,James B. White,Anthony Skjellum,Evan Suggs,Thomas Hines,Purushotham Bangalore,Matthew G. F. Dosanjh,Whit Schonbein*

Main category: cs.DC

TL;DR: 提出基于MPI的GPU通信API，实现无需CPU参与的高性能GPU通信，在Frontier超级计算机上展示显著性能提升


<details>
  <summary>Details</summary>
Motivation: 现有GPU通信API要么依赖CPU参与通信，要么给程序员带来沉重的同步负担，这影响了GPU在ML和HPC应用中的通信效率

Method: 设计并实现基于MPI的GPU通信API，利用HPE Slingshot 11网卡功能，构建CPU-free通信机制，并在Cabana/Kokkos性能可移植框架中实现gather/scatter halo交换原语

Result: 在Frontier和Tuolumne超级计算机上与Cray MPICH对比，中等消息延迟降低50%，在8,192个GPU上运行halo交换基准测试时获得28%的加速提升

Conclusion: 提出的MPI-based GPU通信API能够实现易用、高性能、无需CPU参与的通信，显著提升GPU通信效率和应用程序性能

Abstract: Removing the CPU from the communication fast path is essential to efficient GPU-based ML and HPC application performance. However, existing GPU communication APIs either continue to rely on the CPU for communication or rely on APIs that place significant synchronization burdens on programmers. In this paper we describe the design, implementation, and evaluation of an MPI-based GPU communication API enabling easy-to-use, high-performance, CPU-free communication. This API builds on previously proposed MPI extensions and leverages HPE Slingshot 11 network card capabilities. We demonstrate the utility and performance of the API by showing how the API naturally enables CPU-free gather/scatter halo exchange communication primitives in the Cabana/Kokkos performance portability framework, and through a performance comparison with Cray MPICH on the Frontier and Tuolumne supercomputers. Results from this evaluation show up to a 50% reduction in medium message latency in simple GPU ping-pong exchanges and a 28% speedup improvement when strong scaling a halo-exchange benchmark to 8,192 GPUs of the Frontier supercomputer.

</details>


### [3] [FlashMem: Supporting Modern DNN Workloads on Mobile with GPU Memory Hierarchy Optimizations](https://arxiv.org/abs/2602.15379)
*Zhihao Shu,Md Musfiqur Rahman Sanim,Hangyu Zheng,Kunxiong Zhu,Miao Yin,Gagan Agrawal,Wei Niu*

Main category: cs.DC

TL;DR: FlashMem是一个内存流框架，通过动态流式加载模型权重而非完全预加载，显著减少移动GPU上的内存占用并降低推理延迟，支持大规模DNN和多DNN工作负载。


<details>
  <summary>Details</summary>
Motivation: 现代深度神经网络规模庞大且复杂，在移动GPU上进行推理面临内存和计算资源有限的挑战。现有DNN加速框架采用权重预加载策略，将所有模型参数在执行前加载到内存中，这种方法对于包含超大模型和可能需要连续执行多个不同模型的现代DNN工作负载来说不够充分。

Method: FlashMem采用内存流框架，通过静态确定模型加载调度和动态按需流式传输权重，利用2.5D纹理内存来最小化数据转换并提高执行效率，而不是完全预加载权重。

Result: 在11个模型上的实验结果表明，与现有框架相比，FlashMem实现了2.0倍到8.4倍的内存减少和1.7倍到75.0倍的加速，能够在资源受限的移动GPU上高效执行大规模模型并支持多DNN工作负载。

Conclusion: FlashMem通过创新的内存流方法有效解决了移动GPU上大规模DNN推理的内存和延迟问题，为资源受限设备上的现代神经网络部署提供了可行的解决方案。

Abstract: The increasing size and complexity of modern deep neural networks (DNNs) pose significant challenges for on-device inference on mobile GPUs, with limited memory and computational resources. Existing DNN acceleration frameworks primarily deploy a weight preloading strategy, where all model parameters are loaded into memory before execution on mobile GPUs. We posit that this approach is not adequate for modern DNN workloads that comprise very large model(s) and possibly execution of several distinct models in succession. In this work, we introduce FlashMem, a memory streaming framework designed to efficiently execute large-scale modern DNNs and multi-DNN workloads while minimizing memory consumption and reducing inference latency. Instead of fully preloading weights, FlashMem statically determines model loading schedules and dynamically streams them on demand, leveraging 2.5D texture memory to minimize data transformations and improve execution efficiency. Experimental results on 11 models demonstrate that FlashMem achieves 2.0x to 8.4x memory reduction and 1.7x to 75.0x speedup compared to existing frameworks, enabling efficient execution of large-scale models and multi-DNN support on resource-constrained mobile GPUs.

</details>


### [4] [Service Orchestration in the Computing Continuum: Structural Challenges and Vision](https://arxiv.org/abs/2602.15794)
*Boris Sedlak,Víctor Casamayor Pujol,Ildefons Magrans de Abril,Praveen Kumar Donta,Adel N. Toosi,Schahram Dustdar*

Main category: cs.DC

TL;DR: 本文分析了计算连续体（CC）中服务编排的结构性问题，提出了自主服务编排的理想解决方案，并以主动推理为例说明如何实现自组织服务，最后指出了该领域的研究挑战和路线图。


<details>
  <summary>Details</summary>
Motivation: 计算连续体整合了从边缘到云的不同处理层，以优化服务质量。然而，相比中心化架构，异构和动态的基础设施增加了服务编排的复杂性，需要研究新的解决方案。

Method: 首先总结计算连续体的结构性问题，然后设想自主服务编排的理想解决方案。以主动推理（来自神经科学的概念）为例，展示如何支持自组织服务持续解释环境以优化服务质量。

Result: 目前没有现有解决方案能够完全实现作者的愿景，服务编排研究面临多个结构性挑战，最重要的是需要提供标准化的模拟和评估环境来比较不同编排机制的性能。

Conclusion: 这些挑战共同勾勒出计算连续体中实现弹性和可扩展服务编排的研究路线图，为未来研究提供了明确方向。

Abstract: The Computing Continuum (CC) integrates different layers of processing infrastructure, from Edge to Cloud, to optimize service quality through ubiquitous and reliable computation. Compared to central architectures, however, heterogeneous and dynamic infrastructure increases the complexity for service orchestration. To guide research, this article first summarizes structural problems of the CC, and then, envisions an ideal solution for autonomous service orchestration across the CC. As one instantiation, we show how Active Inference, a concept from neuroscience, can support self-organizing services in continuously interpreting their environment to optimize service quality. Still, we conclude that no existing solution achieves our vision, but that research on service orchestration faces several structural challenges. Most notably: provide standardized simulation and evaluation environments for comparing the performance of orchestration mechanisms. Together, the challenges outline a research roadmap toward resilient and scalable service orchestration in the CC.

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [5] [Crane: An Accurate and Scalable Neural Sketch for Graph Stream Summarization](https://arxiv.org/abs/2602.15360)
*Boyan Wang,Zhuochen Fan,Dayu Wang,Fangcheng Fu,Zeyu Luan,Lei Zou,Qing Li,Tong Yang*

Main category: cs.DB

TL;DR: Crane提出了一种用于图流摘要的分层神经草图架构，通过分层携带机制减少频繁项与稀有项之间的干扰，在有限内存下显著提升统计估计精度。


<details>
  <summary>Details</summary>
Motivation: 图流数据规模庞大且动态变化，传统手工草图方法在有限内存约束下难以准确统计。虽然神经草图方法提高了适应性和准确性，但在有限内存下，频繁项会压制稀有项，阻碍神经网络恢复准确统计。

Method: Crane采用分层神经草图架构：1）分层携带机制自动将频繁项提升到更高内存层，减少同层内频繁项与稀有项的干扰；2）自适应内存扩展策略在顶层占用超过阈值时动态添加新层，适应不同数据规模。

Result: 在20K到60M边的多种数据集上的实验表明，Crane相比最先进方法将估计误差降低了约10倍。

Conclusion: Crane通过分层架构有效解决了图流摘要中频繁项压制稀有项的问题，在有限内存下实现了更准确的统计估计，具有良好的可扩展性和实际部署适应性。

Abstract: Graph streams are rapidly evolving sequences of edges that convey continuously changing relationships among entities, playing a crucial role in domains such as networking, finance, and cybersecurity. Their massive scale and high dynamism make obtaining accurate statistics challenging with limited memory constraints. Traditional methods summarize graph streams through hand-crafted sketches, while recent studies have begun to replace these sketches with neural counterparts to improve adaptability and accuracy. However, this shift faces a major challenge: under limited memory, dominant frequent items tend to overshadow rare ones, hindering the neural network's ability to recover accurate statistics. To address this, we propose Crane, a hierarchical neural sketch architecture for graph stream summarization. Crane uses a hierarchical carry mechanism that automatically elevates frequent items to higher memory layers, reducing interference between frequent and infrequent items within the same layer. To better accommodate real-world deployment, Crane further adopts an adaptive memory expansion strategy that dynamically adds new layers once the occupancy of the top layer exceeds a threshold, enabling scalability across diverse data magnitudes. Extensive experiments on various datasets ranging from 20K to 60M edges demonstrate that Crane reduces estimation error by roughly 10x compared to state-of-the-art methods.

</details>


### [6] [Efficient Approximate Nearest Neighbor Search under Multi-Attribute Range Filter](https://arxiv.org/abs/2602.15488)
*Yuanhang Yu,Dawei Cheng,Ying Zhang,Lu Qin,Wenjie Zhang,Xuemin Lin*

Main category: cs.DB

TL;DR: KHI：一种结合属性空间划分树和HNSW图的多属性范围过滤近似最近邻搜索索引，显著提升查询性能


<details>
  <summary>Details</summary>
Motivation: 现实应用中查询常涉及多个数值属性的约束（多属性范围过滤近似最近邻搜索RFANNS），现有单属性RFANNS索引难以有效扩展到多属性场景

Method: 提出KHI索引，结合属性空间划分树（使用偏斜感知分割规则控制树高为O(log n)）和节点上附加的HNSW图，通过树路由和HNSW贪婪搜索回答查询

Result: 在四个真实数据集上，KHI相比最先进RFANNS基线平均提升QPS 2.46倍，在困难数据集上最高提升16.22倍，对小选择性、大k值和高谓词基数情况提升更显著

Conclusion: KHI为多属性RFANNS问题提供高效解决方案，在保持高召回率的同时显著提升查询吞吐量

Abstract: Nearest neighbor search on high-dimensional vectors is fundamental in modern AI and database systems. In many real-world applications, queries involve constraints on multiple numeric attributes, giving rise to range-filtering approximate nearest neighbor search (RFANNS). While there exist RFANNS indexes for single-attribute range predicates, extending them to the multi-attribute setting is nontrivial and often ineffective. In this paper, we propose KHI, an index for multi-attribute RFANNS that combines an attribute-space partitioning tree with HNSW graphs attached to tree nodes. A skew-aware splitting rule bounds the tree height by $O(\log n)$, and queries are answered by routing through the tree and running greedy search on the HNSW graphs. Experiments on four real-world datasets show that KHI consistently achieves high query throughput while maintaining high recall. Compared with the state-of-the-art RFANNS baseline, KHI improves QPS by $2.46\times$ on average and up to $16.22\times$ on the hard dataset, with larger gains for smaller selectivity, larger $k$, and higher predicate cardinality.

</details>


### [7] [A universal LLM Framework for General Query Refinements](https://arxiv.org/abs/2602.15681)
*Eldar Hacohen,Yuval Moskovitch,Amit Somech*

Main category: cs.DB

TL;DR: OmniTune是一个通用的SQL查询优化框架，使用LLM基于提示的优化(OPRO)来精炼任意SQL查询，通过两步骤探索有前景的精炼子空间并采样候选方案。


<details>
  <summary>Details</summary>
Motivation: 现有SQL查询精炼研究通常针对受限的查询类别或约束，缺乏处理任意SQL查询和复杂约束的通用解决方案。

Method: 采用基于LLM的提示优化(OPRO)框架，通过两步骤方案：1)探索有前景的精炼子空间；2)在子空间内采样候选方案，并使用简洁的历史和天际线摘要提供有效反馈。

Result: 在综合基准测试中，OmniTune既能处理先前研究的精炼任务，也能处理超出现有解决方案范围的更复杂场景。

Conclusion: OmniTune提供了一个通用的SQL查询精炼框架，能够处理各种查询和约束类型，超越了现有方法的局限性。

Abstract: Numerous studies have explored the SQL query refinement problem, where the objective is to minimally modify an input query so that it satisfies a specified set of constraints. However, these works typically target restricted classes of queries or constraints. We present OmniTune, a general framework for refining arbitrary SQL queries using LLM-based optimization by prompting (OPRO). OmniTune employs a two-step OPRO scheme that explores promising refinement subspaces and samples candidates within them, supported by concise history and skyline summaries for effective feedback.
  Experiments on a comprehensive benchmark demonstrate that OmniTune handles both previously studied refinement tasks and more complex scenarios beyond the scope of existing solutions.

</details>


### [8] [Hierarchical Decomposition of Separable Workflow-Nets](https://arxiv.org/abs/2602.15739)
*Humam Kourani,Gyunam Park,Wil M. P. van der Aalst*

Main category: cs.DB

TL;DR: 提出一种将安全可靠的工作流网（WF-nets）转换为POWL 2.0模型的新算法，利用选择图捕获广义决策和循环模式，证明了算法的正确性和完备性，并通过大规模评估验证了其可扩展性和表达能力。


<details>
  <summary>Details</summary>
Motivation: POWL 2.0作为一种新兴的过程建模语言，具有强大的质量保证和高表达能力，但需要与现有工作流网（WF-nets）等成熟表示法兼容。为了弥合POWL的理论优势与实际兼容性需求之间的差距，需要稳健的模型转换方法。

Method: 提出一种新颖算法，递归识别WF-net中的结构模式并将其转换为POWL表示。与之前需要分别检测互斥选择和循环的方法不同，新算法利用选择图捕获广义的决策和循环模式。算法在可分离WF-nets类上具有完备性。

Result: 算法在大规模过程模型上展示了高可扩展性。在1,493个工业和合成过程模型的基准测试中，算法成功转换了所有模型，表明POWL 2.0的表达能力足以捕获现实世界业务流程中的复杂逻辑。

Conclusion: 该工作为POWL在实际过程分析和改进应用中的更广泛采用铺平了道路。通过提供从WF-nets到POWL 2.0的可靠转换，促进了POWL与现有过程建模实践的集成。

Abstract: The Partially Ordered Workflow Language (POWL) has recently emerged as a process modeling notation, offering strong quality guarantees and high expressiveness. While early versions of POWL relied on strict block-structured operators for choices and loops, the language has recently evolved into POWL 2.0, introducing choice graphs to enable the modeling of non-block-structured decisions and cycles. To bridge the gap between the theoretical advantages of POWL and the practical need for compatibility with established notations, robust model transformations are required. This paper presents a novel algorithm for transforming safe and sound workflow nets (WF-nets) into equivalent POWL 2.0 models. The algorithm recursively identifies structural patterns within the WF-net and translates them into their POWL representation. Unlike the previous approach that required separate detection strategies for exclusive choices and loops, our new algorithm utilizes choice graphs to capture generalized decision and cyclic patterns. We formally prove the correctness of our approach, showing that the generated POWL model preserves the language of the input WF-net. Furthermore, we prove the completeness of our algorithm on the class of separable WF-nets, which corresponds to nets constructed via the hierarchical nesting of state machines and marked graphs. We evaluate our algorithm on large-scale process models to demonstrate its high scalability. Furthermore, to test its practical expressiveness, we applied it to a benchmark of 1,493 industrial and synthetic process models. Our algorithm successfully transformed all models in this benchmark, suggesting that POWL 2.0's expressive power is generally sufficient to capture the complex logic found in real-world business processes. This work paves the way for broader adoption of POWL in practical process analysis and improvement applications.

</details>


### [9] [Efficient Densest Flow Queries in Transaction Flow Networks (Complete Version)](https://arxiv.org/abs/2602.15773)
*Jiaxin Jiang,Yunxiang Zhao,Lyu Xu,Byron Choi,Bingsheng He,Shixuan Sun,Jia Chen*

Main category: cs.DB

TL;DR: 论文提出S-T最密流查询（SDMF）用于检测交易网络中的欺诈活动，开发了高效的CONAN算法，并在Grab的欺诈检测系统中成功应用。


<details>
  <summary>Details</summary>
Motivation: Grab等数字支付平台面临日益复杂的欺诈模式，传统欺诈检测依赖识别交易网络中的密集流，需要更有效的解决方案来检测欺诈活动。

Method: 提出S-T最密流查询（SDMF），开发CONAN算法（基于分治策略），引入近似流剥离算法优化性能，处理大规模交易网络。

Result: CONAN算法比基线方法快三个数量级，能更有效地识别最密流，已成功集成到Grab的欺诈检测系统中，显著提升了欺诈识别能力。

Conclusion: SDMF查询和CONAN算法为交易网络欺诈检测提供了高效解决方案，在实际工业场景中验证了其有效性和可扩展性。

Abstract: Transaction flow networks are crucial in detecting illicit activities such as wash trading, credit card fraud, cashback arbitrage fraud, and money laundering. \revise{Our collaborator, Grab, a leader in digital payments in Southeast Asia, faces increasingly sophisticated fraud patterns in its transaction flow networks. In industry settings such as Grab's fraud detection pipeline, identifying fraudulent activities heavily relies on detecting dense flows within transaction networks. Motivated by this practical foundation,} we propose the \emph{\(S\)-\(T\) densest flow} (\SDMF{}) query. Given a transaction flow network \( G \), a source set \( \Src \), a sink set \( \Dst \), and a size threshold \( k \), the query outputs subsets \( \Src' \subseteq \Src \) and \( \Dst' \subseteq \Dst \) such that the maximum flow from \( \Src' \) to \( \Dst' \) is densest, with \(|\Src' \cup \Dst'| \geq k\). Recognizing the NP-hardness of the \SDMF{} query, we develop an efficient divide-and-conquer algorithm, CONAN. \revise{Driven by industry needs for scalable and efficient solutions}, we introduce an approximate flow-peeling algorithm to optimize the performance of CONAN, enhancing its efficiency in processing large transaction networks. \revise{Our approach has been integrated into Grab's fraud detection scenario, resulting in significant improvements in identifying fraudulent activities.} Experiments show that CONAN outperforms baseline methods by up to three orders of magnitude in runtime and more effectively identifies the densest flows. We showcase CONAN's applications in fraud detection on transaction flow networks from our industry partner, Grab, and on non-fungible tokens (NFTs).

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [10] [CircuChain: Disentangling Competence and Compliance in LLM Circuit Analysis](https://arxiv.org/abs/2602.15037)
*Mayank Ravishankara*

Main category: cs.SE

TL;DR: CircuChain是一个诊断基准，用于在电路分析中区分指令遵循能力和物理推理能力，发现最强模型物理推理近乎完美但指令遵循差，而较弱模型物理推理差但指令遵循好。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在工程领域接近专家水平，在用户指定约束下的可靠推理变得至关重要。当前不清楚前沿模型是真正应用基本原理推理，还是依赖与明确指令冲突的训练先验。

Method: CircuChain基准包含五个典型电路拓扑的Control/Trap问题对，系统变化符号约定、电流方向和极性定义。采用多阶段验证流程，结合符号求解器、SPICE仿真和基于LLM的错误分类法。

Result: 观察到一致的"遵循-能力分歧"：最强模型物理推理近乎完美，但在Trap条件下违反约定率高；较弱模型物理保真度低但指令遵循更好。模型能力增强不保证约束对齐改善。

Conclusion: 需要新的评估框架来强调数学严格领域下的指令遵循。CircuChain提供了这样的框架，为工程教育和AI对齐研究提供了可操作的见解。

Abstract: As large language models (LLMs) advance toward expert-level performance in engineering domains, reliable reasoning under user-specified constraints becomes critical. In circuit analysis, for example, a numerically correct solution is insufficient if it violates established methodological conventions such as mesh directionality or polarity assignments, errors that can propagate in safety-critical systems. Yet it remains unclear whether frontier models truly apply first-principles reasoning or rely on entrenched training priors that conflict with explicit instructions. We introduce CircuChain, a diagnostic benchmark designed to disentangle instruction compliance from physical reasoning competence in electrical circuit analysis. CircuChain consists of counterbalanced Control/Trap problem pairs across five canonical circuit topologies, augmented with systematic variations in sign conventions, current orientations, and polarity definitions. A multi-stage verification pipeline, combining symbolic solvers, SPICE simulation, and an LLM-based error taxonomy, enables fine-grained attribution of failures to convention errors, physics errors, arithmetic mistakes, or hallucinations. Across 100 tasks per model, we observe a consistent Compliance-Competence Divergence. The strongest model evaluated exhibits near-perfect physical reasoning but a high rate of convention violations when Trap conditions deliberately invert natural sign patterns. Conversely, weaker models display lower physical fidelity yet superior adherence to explicit instructions. These results suggest that increased model capability does not guarantee improved constraint alignment and highlight the need for new evaluation frameworks that stress instruction-following under mathematically rigid domains. CircuChain provides one such framework and offers actionable insights for both engineering education and AI alignment research.

</details>


### [11] [The Agentic Automation Canvas: a structured framework for agentic AI project design](https://arxiv.org/abs/2602.15090)
*Sebastian Lobentanzer*

Main category: cs.SE

TL;DR: 提出了Agentic Automation Canvas (AAC)框架，用于前瞻性设计自主智能系统，通过语义网兼容的元数据模式和隐私保护的Web应用实现机器可读、可互操作的项目契约。


<details>
  <summary>Details</summary>
Motivation: 自主智能代理在各领域快速部署，但缺乏结构化设计、治理和前瞻性评估的方法论。现有AI文档实践（如Model Cards、Datasheets）要么是回顾性的，要么缺乏机器可读性和互操作性。

Method: 开发了Agentic Automation Canvas (AAC)框架，包含六个维度：定义与范围、用户期望与量化效益指标、开发者可行性评估、治理阶段、数据访问与敏感性、结果。实现为语义网兼容的元数据模式，包含受控词汇表和Schema.org、W3C DCAT等本体映射，通过隐私保护的客户端Web应用提供实时验证。

Result: AAC框架能够生成FAIR兼容的RO-Crates，创建版本化、可共享、机器可互操作的项目契约。已应用于研究、临床和机构设置中的多样化用例，并作为开源代码和交互式Web表单提供。

Conclusion: AAC为自主智能系统的结构化设计、治理和前瞻性评估提供了系统化方法，填补了现有AI文档实践的空白，促进了用户与开发者之间的沟通和互操作性。

Abstract: Agentic AI prototypes are being deployed across domains with increasing speed, yet no methodology for their structured design, governance, and prospective evaluation has been established. Existing AI documentation practices and guidelines - Model Cards, Datasheets, or NIST AI RMF - are either retrospective or lack machine-readability and interoperability. We present the Agentic Automation Canvas (AAC), a structured framework for the prospective design of agentic systems and a tool to facilitate communication between their users and developers. The AAC captures six dimensions of an automation project: definition and scope; user expectations with quantified benefit metrics; developer feasibility assessments; governance staging; data access and sensitivity; and outcomes. The framework is implemented as a semantic web-compatible metadata schema with controlled vocabulary and mappings to established ontologies such as Schema.org and W3C DCAT. It is made accessible through a privacy-preserving, fully client-side web application with real-time validation. Completed canvases export as FAIR-compliant RO-Crates, yielding versioned, shareable, and machine-interoperable project contracts between users and developers. We describe the schema design, benefit quantification model, and prospective application to diverse use cases from research, clinical, and institutional settings. The AAC and its web application are available as open-source code and interactive web form at https://aac.slolab.ai

</details>


### [12] [An Empirical Study on the Effects of System Prompts in Instruction-Tuned Models for Code Generation](https://arxiv.org/abs/2602.15228)
*Zaiyu Cheng,Antonio Mastropaolo*

Main category: cs.SE

TL;DR: 系统提示对代码生成模型的影响研究：发现提示约束特异性不总是提升正确性，few-shot示例可能损害大模型性能，Java比Python对提示变化更敏感。


<details>
  <summary>Details</summary>
Motivation: 尽管指令调优语言模型在代码生成方面取得了显著进展，但系统提示对通用ILMs和专用CLMs的影响尚未得到充分探索。研究者希望系统评估系统提示的详细程度、模型规模、提示策略和编程语言等因素如何影响代码助手性能。

Method: 采用系统化评估方法，在360种配置下进行实验：涵盖4个模型、5种系统提示、3种提示策略、2种编程语言（Python和Java）和2种温度设置。通过控制变量法分析各因素对代码生成正确性的影响。

Result: 1. 增加系统提示的约束特异性并不总是提高正确性，提示效果取决于配置，可能帮助或阻碍性能；2. 对于大型代码专用模型，few-shot示例可能比zero-shot生成表现更差；3. 编程语言影响显著，Java对系统提示变化的敏感性远高于Python。

Conclusion: 系统提示对代码生成模型的影响复杂且配置依赖，需要针对具体任务、模型和编程语言进行定制化提示工程。传统few-shot策略可能不适用于大型代码模型，不同编程语言需要不同的提示策略。

Abstract: Instruction-tuned Language Models (ILMs) have become essential components of modern AI systems, demonstrating exceptional versatility across natural language and reasoning tasks. Among their most impactful applications is code generation, where ILMs -- commonly referred to as Code Language Models (CLMs) -- translate human intent into executable programs. While progress has been driven by advances in scaling and training methodologies, one critical aspect remains underexplored: the impact of system prompts on both general-purpose ILMs and specialized CLMs for code generation. We systematically evaluate how system prompts of varying instructional detail, along with model scale, prompting strategy, and programming language, affect code assistant. Our experimental setting spans 360 configurations across four models, five system prompts, three prompting strategies, two languages, and two temperature settings. We find that (1) increasing system-prompt constraint specificity does not monotonically improve correctness -- prompt effectiveness is configuration-dependent and can help or hinder based on alignment with task requirements and decoding context; (2) for larger code-specialized models, few-shot examples can degrade performance relative to zero-shot generation, contrary to conventional wisdom; and (3) programming language matters, with Java exhibiting significantly greater sensitivity to system prompt variations than Python, suggesting language-specific prompt engineering strategies may be necessary.

</details>


### [13] [GenAI for Systems: Recurring Challenges and Design Principles from Software to Silicon](https://arxiv.org/abs/2602.15241)
*Arya Tschand,Chenyu Wang,Zishen Wan,Andrew Cheng,Ioana Cristescu,Kevin He,Howard Huang,Alexander Ingare,Akseli Kangaslahti,Sara Kangaslahti,Theo Lebryk,Hongjin Lin,Jeffrey Jian Ma,Alexandru Meterez,Clara Mohri,Depen Morwani,Sunny Qin,Roy Rinberg,Paula Rodriguez-Diaz,Alyssa Mia Taliotis,Pernille Undrum Fathi,Rosie Zhao,Todd Zhou,Vijay Janapa Reddi*

Main category: cs.SE

TL;DR: 论文从跨栈视角分析生成式AI在计算系统设计中的应用，识别出五个重复出现的挑战和五个有效的设计原则，并提出了共享工程方法论的需求。


<details>
  <summary>Details</summary>
Motivation: 生成式AI正在重塑计算系统的设计、优化和构建方式，但目前研究在软件、架构和芯片设计社区之间是碎片化的。需要从跨栈视角理解生成式模型如何应用于从代码生成到硬件设计的各个层面，并识别共同的模式和挑战。

Method: 采用跨栈分析方法，审查了涵盖计算栈三个层次、11个应用领域的275多篇论文。通过分析不同层次中反复出现的结构性问题，识别出共同的挑战和设计原则，并构建了挑战-原则映射图作为诊断和设计工具。

Result: 研究发现五个重复出现的挑战：反馈循环危机、隐性知识问题、信任与验证、跨边界协同设计、从确定性到动态性的转变。同时识别出五个有效的设计原则：采用混合方法、设计持续反馈机制、按角色分离关注点、方法匹配问题结构、基于数十年系统知识构建。这些原则在不同层次中独立出现并证明有效。

Conclusion: 该领域需要共享的工程方法论，包括通用词汇表、跨层基准测试和系统化设计实践，以便进展能够在不同社区间积累而非在每个社区中重新发现。从跨层视角可以识别出仅在该视角下可见的开放研究问题。

Abstract: Generative AI is reshaping how computing systems are designed, optimized, and built, yet research remains fragmented across software, architecture, and chip design communities. This paper takes a cross-stack perspective, examining how generative models are being applied from code generation and distributed runtimes through hardware design space exploration to RTL synthesis, physical layout, and verification. Rather than reviewing each layer in isolation, we analyze how the same structural difficulties and effective responses recur across the stack. Our central finding is one of convergence. Despite the diversity of domains and tools, the field keeps encountering five recurring challenges (the feedback loop crisis, the tacit knowledge problem, trust and validation, co-design across boundaries, and the shift from determinism to dynamism) and keeps arriving at five design principles that independently emerge as effective responses (embracing hybrid approaches, designing for continuous feedback, separating concerns by role, matching methods to problem structure, and building on decades of systems knowledge). We organize these into a challenge--principle map that serves as a diagnostic and design aid, showing which principles have proven effective for which challenges across layers. Through concrete cross-stack examples, we show how systems navigate this map as they mature, and argue that the field needs shared engineering methodology, including common vocabularies, cross-layer benchmarks, and systematic design practices, so that progress compounds across communities rather than being rediscovered in each one. Our analysis covers more than 275 papers spanning eleven application areas across three layers of the computing stack, and distills open research questions that become visible only from a cross-layer vantage point.

</details>


### [14] [SACS: A Code Smell Dataset using Semi-automatic Generation Approach](https://arxiv.org/abs/2602.15342)
*Hanyu Zhang,Tomoji Kishi*

Main category: cs.SE

TL;DR: 提出半自动方法生成高质量代码异味数据集SACS，包含三种常见代码异味，每种超过10,000个标注样本


<details>
  <summary>Details</summary>
Motivation: 代码异味研究面临高质量数据集缺乏的挑战，手动构建成本高，自动生成质量不可靠，需要平衡效率与质量

Method: 采用半自动方法：先应用自动生成规则产生候选样本，然后用多指标分组为自动接受组和人工审核组，建立结构化审核指南和标注工具支持人工验证

Result: 创建了开源代码异味数据集SACS，涵盖Long Method、Large Class、Feature Envy三种代码异味，每类超过10,000个标注样本

Conclusion: SACS数据集为代码异味检测和自动重构研究提供了大规模公开基准，半自动方法平衡了数据质量与生成效率

Abstract: Code smell is a great challenge in software refactoring, which indicates latent design or implementation flaws that may degrade the software maintainability and evolution. Over the past of decades, the research on code smell has received extensive attention. Especially the researches applied machine learning-technique have become a popular topic in recent studies. However, one of the biggest challenges to apply machine learning-technique is the lack of high-quality code smell datasets. Manually constructing such datasets is extremely labor-intensive, as identifying code smells requires substantial development expertise and considerable time investment. In contrast, automatically generated datasets, while scalable, frequently exhibit reduced label reliability and compromised data quality. To overcome this challenge, in this study, we explore a semi-automatic approach to generate a code smell dataset with high quality data samples. Specifically, we first applied a set of automatic generation rules to produce candidate smelly samples. We then employed multiple metrics to group the data samples into an automatically accepted group and a manually reviewed group, enabling reviewers to concentrate their efforts on ambiguous samples. Furthermore, we established structured review guidelines and developed a annotation tool to support the manual validation process. Based on the proposed semi-automatic generation approach, we created an open-source code smell dataset, SACS, covering three widely studied code smells: Long Method, Large Class, and Feature Envy. Each code smell category includes over 10,000 labeled samples. This dataset could provide a large-scale and publicly available benchmark to facilitate future studies on code smell detection and automated refactoring.

</details>


### [15] [A Differential Fuzzing-Based Evaluation of Functional Equivalence in LLM-Generated Code Refactorings](https://arxiv.org/abs/2602.15761)
*Simantika Bhattacharjee Dristi,Matthew B. Dwyer*

Main category: cs.SE

TL;DR: 使用差分模糊测试评估LLM代码重构的功能等价性，发现19-35%的重构存在语义改变，21%的错误重构未被现有测试集发现


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在自动化代码重构中的广泛应用，评估LLM生成重构与原始实现之间的功能等价性变得至关重要。现有方法通常依赖预定义测试用例评估正确性，但这种方法存在局限性。

Method: 采用差分模糊测试方法检查LLM生成代码重构的功能等价性。该方法无需预定义测试用例，通过自动生成数千个测试输入并执行比较，探索更大的输入空间。在三个数据集和两种重构类型上对六个LLM进行了大规模评估。

Result: LLM显示出显著改变程序语义的趋势，产生19-35%功能不等价的重构。实验进一步表明，约21%的这些不等价重构在三个评估数据集的现有测试套件中未被检测到。

Conclusion: 依赖现有测试可能会高估LLM生成代码重构的功能等价性，这些重构仍然容易出现语义偏差。差分模糊测试提供了更全面的评估方法。

Abstract: With the rapid adoption of large language models (LLMs) in automated code refactoring, assessing and ensuring functional equivalence between LLM-generated refactoring and the original implementation becomes critical. While prior work typically relies on predefined test cases to evaluate correctness, in this work, we leverage differential fuzzing to check functional equivalence in LLM-generated code refactorings. Unlike test-based evaluation, a differential fuzzing-based equivalence checker needs no predefined test cases and can explore a much larger input space by executing and comparing thousands of automatically generated test inputs. In a large-scale evaluation of six LLMs (CodeLlama, Codestral, StarChat2, Qwen-2.5, Olmo-3, and GPT-4o) across three datasets and two refactoring types, we find that LLMs show a non-trivial tendency to alter program semantics, producing 19-35% functionally non-equivalent refactorings. Our experiments further demonstrate that about 21% of these non-equivalent refactorings remain undetected by the existing test suites of the three evaluated datasets. Collectively, the findings of this study imply that reliance on existing tests might overestimate functional equivalence in LLM-generated code refactorings, which remain prone to semantic divergence.

</details>
