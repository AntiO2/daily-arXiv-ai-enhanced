<div id=toc></div>

# Table of Contents

- [cs.DB](#cs.DB) [Total: 2]
- [cs.SE](#cs.SE) [Total: 10]
- [cs.DC](#cs.DC) [Total: 4]


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [1] [Time and Relations into Focus: Ontological Foundations of Object-Centric Event Data](https://arxiv.org/abs/2512.14425)
*Hosna Hooshyar,Mattia Fumagalli,Marco Montali,Giancarlo Guizzardi*

Main category: cs.DB

TL;DR: 提出基于本体论基础的gOCED元模型，解决对象中心过程挖掘中现有数据模型的模糊性和表达能力不足问题


<details>
  <summary>Details</summary>
Motivation: 传统案例中心事件数据模型无法处理多对象交互的复杂性，现有对象中心事件数据模型存在模糊性，缺乏对时间和动态关系的全面支持

Method: 采用三步法：1)分析现有OCED元模型的关键问题；2)基于gUFO本体论增强OCED核心模型；3)提出新的gOCED元模型

Result: gOCED元模型覆盖现有元模型特性并保持简洁性，同时扩展了必要功能以解决文献中报告的模糊性和表达能力问题

Conclusion: 通过将对象中心事件数据建立在坚实本体论基础上，gOCED提供了更清晰、表达能力更强的元模型，为对象中心过程挖掘奠定基础

Abstract: Object-centric process mining is a new branch of process mining where events are associated with multiple objects, and where object-to-object interactions are essential to understand the process dynamics. Traditional event data models, also called case-centric, are unable to cope with the complexity introduced by these more refined relationships. Several models have been made to move from case-centric to Object-Centric Event Data (OCED), trying to retain simplicity as much as possible. Still, these suffer from inherent ambiguities, and lack a comprehensive support of essential dimensions related to time and (dynamic) relations. In this work, we propose to fill this gap by leveraging a well-founded ontology of events and bringing ontological foundations to OCED, with a three-step approach. First, we start from key open issues reported in the literature regarding current OCED metamodels, and witness their ambiguity and expressiveness limitations on illustrative and representative examples proposed therein. Second, we consider the OCED Core Model, currently proposed as the basis for defining a new standard for object-centric event data, and we enhance it by grounding it on a lightweight version of UFO-B called gUFO, a well-known foundational ontology tailored to the representation of objects, events, time, and their (dynamic) relations. This results in a new metamodel, which we call gOCED. The third contribution then shows how gOCED at once covers the features of existing metamodels preserving their simplicity, and extends them with the essential features needed to overcome the ambiguity and expressiveness issues reported in the literature.

</details>


### [2] [Beyond Text-to-SQL: Autonomous Research-Driven Database Exploration with DAR](https://arxiv.org/abs/2512.14622)
*Ostap Vykhopen,Viktoria Skorik,Maxim Tereschenko,Veronika Solopova*

Main category: cs.DB

TL;DR: DAR是一个多智能体系统，能在无需人工查询的情况下自主进行端到端数据库研究，比专业分析师快32倍。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型数据库查询系统大多是被动的，依赖用户明确提示，缺乏主动探索数据的能力。需要从查询驱动转向自主研究驱动的数据库探索。

Method: DAR采用三层多智能体架构：初始化层（意图推断和元数据提取）、执行层（SQL和AI查询合成与迭代验证）、合成层（带质量控制报告生成）。所有推理直接在BigQuery中使用原生生成式AI函数执行。

Result: 在真实资产事件数据集上，DAR在16分钟内完成完整分析任务，而专业分析师需要8.5小时（快约32倍），能产生有用的模式洞察和基于证据的建议。

Conclusion: DAR在快速探索性分析方面表现出色，将数据库交互从查询驱动转向云数据仓库内的自主研究驱动探索，但人类专家在深度上下文解释方面仍有优势。

Abstract: Large language models can already query databases, yet most existing systems remain reactive: they rely on explicit user prompts and do not actively explore data. We introduce DAR (Data Agnostic Researcher), a multi-agent system that performs end-to-end database research without human-initiated queries. DAR orchestrates specialized AI agents across three layers: initialization (intent inference and metadata extraction), execution (SQL and AI-based query synthesis with iterative validation), and synthesis (report generation with built-in quality control). All reasoning is executed directly inside BigQuery using native generative AI functions, eliminating data movement and preserving data governance. On a realistic asset-incident dataset, DAR completes the full analytical task in 16 minutes, compared to 8.5 hours for a professional analyst (approximately 32x times faster), while producing useful pattern-based insights and evidence-grounded recommendations. Although human experts continue to offer deeper contextual interpretation, DAR excels at rapid exploratory analysis. Overall, this work shifts database interaction from query-driven assistance toward autonomous, research-driven exploration within cloud data warehouses.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [3] [Practitioner Insights on Fairness Requirements in the AI Development Life Cycle: An Interview Study](https://arxiv.org/abs/2512.13830)
*Chaima Boufaied,Thanh Nguyen,Ronnie de Souza Santos*

Main category: cs.SE

TL;DR: 该研究通过26个半结构化访谈调查了AI公平性在软件工程实践中的现状，发现虽然从业者认识到公平性维度，但实践不一致且常被降级处理，存在知识缺口。


<details>
  <summary>Details</summary>
Motivation: 随着AI/ML和LLM在各领域的广泛应用，模型常作为黑箱运行，可能对不同人口群体产生不公平影响。传统上AI模型主要关注有效性，但近年来公平性问题日益受到关注。研究旨在从软件工程角度了解AI公平性需求在软件开发周期中的实际应用情况。

Method: 采用定性研究方法，对来自23个国家、不同应用领域和背景的从业者进行26个半结构化访谈。研究评估参与者对AI/ML软件公平性的认识及其在软件开发生命周期(SDLC)中的应用，从将公平性关注转化为需求到早期评估。通过主题定性分析研究公平性的实施、验证、评估等关键维度，以及与其他优先事项(如功能完整性和交付期限)的权衡。

Result: 研究发现，虽然参与者认识到AI公平性的各个维度，但实践存在不一致性，公平性常被降级处理，且存在明显的知识缺口。这表明需要与相关利益相关者就明确定义、上下文适当的公平性定义、相应评估指标和正式化流程达成一致，以更好地将公平性整合到AI/ML项目中。

Conclusion: 当前AI公平性实践存在显著差距，需要建立标准化的公平性定义、评估指标和正式流程，以系统性地将公平性要求整合到AI/ML软件开发过程中，确保公平性不被其他开发优先级所忽视。

Abstract: Nowadays, Artificial Intelligence (AI), particularly Machine Learning (ML) and Large Language Models (LLMs), is widely applied across various contexts. However, the corresponding models often operate as black boxes, leading them to unintentionally act unfairly towards different demographic groups. This has led to a growing focus on fairness in AI software recently, alongside the traditional focus on the effectiveness of AI models. Through 26 semi-structured interviews with practitioners from different application domains and with varied backgrounds across 23 countries, we conducted research on fairness requirements in AI from software engineering perspective. Our study assesses the participants' awareness of fairness in AI / ML software and its application within the Software Development Life Cycle (SDLC), from translating fairness concerns into requirements to assessing their arising early in the SDLC. It also examines fairness through the key assessment dimensions of implementation, validation, evaluation, and how it is balanced with trade-offs involving other priorities, such as addressing all the software functionalities and meeting critical delivery deadlines. Findings of our thematic qualitative analysis show that while our participants recognize the aforementioned AI fairness dimensions, practices are inconsistent, and fairness is often deprioritized with noticeable knowledge gaps. This highlights the need for agreement with relevant stakeholders on well-defined, contextually appropriate fairness definitions, the corresponding evaluation metrics, and formalized processes to better integrate fairness into AI/ML projects.

</details>


### [4] [Verification-Guided Context Optimization for Tool Calling via Hierarchical LLMs-as-Editors](https://arxiv.org/abs/2512.13860)
*Henger Li,Shuangjie You,Flavio Di Palo,Yiyue Qian,Ayush Jain*

Main category: cs.SE

TL;DR: VGCO框架使用LLM作为编辑器自动优化工具文档和知识库上下文，解决工具调用中因文档与LLM理解不匹配导致的准确性问题，在工业大规模工具调用场景中显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 当前工具调用依赖的文档和知识库上下文是为人类用户设计的，与LLM的信息理解方式存在偏差，导致工具调用效果不佳。工业场景中数百个功能重叠的工具进一步加剧了可扩展性、可变性和模糊性问题。

Method: VGCO框架包含两个阶段：1) 评估阶段收集实际失败案例，识别工具与上下文之间的不匹配；2) 优化阶段通过离线学习进行分层编辑，采用结构感知的上下文优化。LLM编辑器具有分层结构、状态感知、动作特定和验证引导的特点。

Result: VGCO在单轮大规模工具调用问题上显著提升了准确性、鲁棒性和泛化能力，相比之前强调多轮推理的工作有显著改进。

Conclusion: VGCO通过LLM作为编辑器自动优化工具相关文档和知识库上下文，有效解决了工业场景中大规模工具调用的文档与LLM理解不匹配问题，为工具调用系统提供了实用的改进框架。

Abstract: Tool calling enables large language models (LLMs) to interact with external environments through tool invocation, providing a practical way to overcome the limitations of pretraining. However, the effectiveness of tool use depends heavily on the quality of the associated documentation and knowledge base context. These materials are usually written for human users and are often misaligned with how LLMs interpret information. This problem is even more pronounced in industrial settings, where hundreds of tools with overlapping functionality create challenges in scalability, variability, and ambiguity. We propose Verification-Guided Context Optimization (VGCO), a framework that uses LLMs as editors to automatically refine tool-related documentation and knowledge base context. VGCO works in two stages. First, Evaluation collects real-world failure cases and identifies mismatches between tools and their context. Second, Optimization performs hierarchical editing through offline learning with structure-aware, in-context optimization. The novelty of our LLM editors has three main aspects. First, they use a hierarchical structure that naturally integrates into the tool-calling workflow. Second, they are state-aware, action-specific, and verification-guided, which constrains the search space and enables efficient, targeted improvements. Third, they enable cost-efficient sub-task specialization, either by prompt engineering large editor models or by post-training smaller editor models. Unlike prior work that emphasizes multi-turn reasoning, VGCO focuses on the single-turn, large-scale tool-calling problem and achieves significant improvements in accuracy, robustness, and generalization across LLMs.

</details>


### [5] [Context Branching for LLM Conversations: A Version Control Approach to Exploratory Programming](https://arxiv.org/abs/2512.13914)
*Bhargav Chickmagalur Nanjundappa,Spandan Maaheshwari*

Main category: cs.SE

TL;DR: ContextBranch：一个为LLM对话引入版本控制语义的系统，通过分支、切换等操作管理探索性编程中的多轮对话，防止上下文污染


<details>
  <summary>Details</summary>
Motivation: LLM在多轮对话中性能显著下降（平均39%），特别是在探索性编程任务中，用户需要在不同方案间探索而不污染对话上下文。现有方案要么继续使用被污染的上下文，要么重新开始丢失所有积累的上下文。

Method: 提出ContextBranch系统，提供四个核心原语：checkpoint（检查点）、branch（分支）、switch（切换）和inject（注入），允许用户捕获对话状态、在隔离环境中探索替代方案，并选择性合并见解。

Result: 在30个软件工程场景的实验中，分支对话相比线性对话获得更高质量响应，在复杂场景中改进尤其显著。分支将上下文大小减少58.1%（从31.0条消息降至13.0条），消除了不相关的探索性内容。

Conclusion: 对话分支是AI辅助探索性工作的基本原语，隔离机制能有效防止在探索替代方案时的上下文污染问题。

Abstract: Large Language Models (LLMs) have become integral to software engineering workflows, yet their effectiveness degrades significantly in multi-turn conversations. Recent studies demonstrate an average 39% performance drop when instructions are delivered across multiple turns, with models making premature assumptions and failing to course correct (Laban et al., 2025). This degradation is particularly problematic in exploratory programming tasks where developers need to investigate alternative approaches without committing to a single path. Current solutions force users into a false dichotomy: continue in a context-polluted conversation where the LLM becomes increasingly confused, or start fresh and lose all accumulated context.
  We present ContextBranch, a conversation management system that applies version control semantics to LLM interactions. ContextBranch provides four core primitives--checkpoint, branch, switch, and inject--enabling users to capture conversation state, explore alternatives in isolation, and selectively merge insights. We evaluate ContextBranch through a controlled experiment with 30 software engineering scenarios featuring intentionally polluting explorations. Branched conversations achieved higher response quality compared to linear conversations, with large improvements in focus and context awareness. Benefits were concentrated in complex scenarios involving conceptually distant explorations. Branching reduced context size by 58.1% (31.0 to 13.0 messages), eliminating irrelevant exploratory content. Our work establishes conversation branching as a fundamental primitive for AI-assisted exploratory work, demonstrating that isolation prevents context pollution when exploring alternatives.

</details>


### [6] [Professional Software Developers Don't Vibe, They Control: AI Agent Use for Coding in 2025](https://arxiv.org/abs/2512.14012)
*Ruanqianqian Huang,Avery Reyna,Sorin Lerner,Haijun Xia,Brian Hempel*

Main category: cs.SE

TL;DR: 经验丰富的开发者将AI代理视为生产力提升工具，但会保持对软件设计和实现的控制权，通过专业知识来引导代理行为，确保软件质量。


<details>
  <summary>Details</summary>
Motivation: 研究AI代理在专业软件开发中的实际角色，了解经验丰富的开发者如何使用代理，包括他们的动机、策略、任务适用性和情感态度。

Method: 通过实地观察（N=13）和定性调查（N=99）的混合方法，收集经验丰富的开发者在实际软件开发中使用AI代理的数据。

Result: 经验丰富的开发者重视代理作为生产力提升工具，但坚持保持对软件设计和实现的控制权，利用专业知识控制代理行为以确保软件质量。他们对将代理融入软件开发持积极态度，因为相信自己能弥补代理的局限性。

Conclusion: 研究揭示了软件开发最佳实践在有效使用代理中的价值，指出了代理可能适合的任务类型，并为未来更好的代理界面和使用指南提供了方向。

Abstract: The rise of AI agents is transforming how software can be built. The promise of agents is that developers might write code quicker, delegate multiple tasks to different agents, and even write a full piece of software purely out of natural language. In reality, what roles agents play in professional software development remains in question. This paper investigates how experienced developers use agents in building software, including their motivations, strategies, task suitability, and sentiments. Through field observations (N=13) and qualitative surveys (N=99), we find that while experienced developers value agents as a productivity boost, they retain their agency in software design and implementation out of insistence on fundamental software quality attributes, employing strategies for controlling agent behavior leveraging their expertise. In addition, experienced developers feel overall positive about incorporating agents into software development given their confidence in complementing the agents' limitations. Our results shed light on the value of software development best practices in effective use of agents, suggest the kinds of tasks for which agents may be suitable, and point towards future opportunities for better agentic interfaces and agentic use guidelines.

</details>


### [7] [PerfCoder: Large Language Models for Interpretable Code Performance Optimization](https://arxiv.org/abs/2512.14018)
*Jiuding Yang,Shengyao Lu,Hongxuan Liu,Shayan Shirahmad Gale Bagi,Zahra Fazel,Tomasz Czajkowski,Di Niu*

Main category: cs.SE

TL;DR: PerfCoder是一个专门为生成高性能代码设计的LLM家族，通过可解释的定制优化从源代码生成性能增强代码，在代码性能基准测试中超越了所有现有模型。


<details>
  <summary>Details</summary>
Motivation: 当前LLM在自动代码生成方面取得了显著进展，但在生成高性能代码方面仍有局限，这是现实世界软件系统的关键需求。现有LLM不仅面临数据稀缺问题，更重要的是缺乏指导可解释和有效性能改进的监督。

Method: PerfCoder通过以下方法构建：1）在精心策划的真实世界优化轨迹数据集上进行微调，这些数据包含人类可读的注释；2）使用运行时测量进行强化微调进行偏好对齐；3）能够提出输入特定的改进策略并直接应用，无需依赖迭代优化。

Result: 在PIE代码性能基准测试中，PerfCoder在运行时加速和有效优化率方面超越了所有现有模型。此外，PerfCoder能够生成源代码的可解释反馈，当在规划器-优化器协作工作流中作为更大LLM的输入时，可以进一步提升结果，将32B模型和GPT-5的性能提升到新水平。

Conclusion: 性能优化不能仅通过模型规模实现，而是需要优化策略意识。PerfCoder展示了通过专门设计的监督和偏好对齐，LLM能够生成高性能代码并提供可解释的优化反馈，为代码性能优化开辟了新途径。

Abstract: Large language models (LLMs) have achieved remarkable progress in automatic code generation, yet their ability to produce high-performance code remains limited--a critical requirement in real-world software systems. We argue that current LLMs struggle not only due to data scarcity but, more importantly, because they lack supervision that guides interpretable and effective performance improvements. In this work, we introduce PerfCoder, a family of LLMs specifically designed to generate performance-enhanced code from source code via interpretable, customized optimizations. PerfCoder is fine-tuned on a curated collection of real-world optimization trajectories with human-readable annotations, and preference-aligned by reinforcement fine-tuning using runtime measurements, enabling it to propose input-specific improvement strategies and apply them directly without relying on iterative refinement. On the PIE code performance benchmark, PerfCoder surpasses all existing models in both runtime speedup and effective optimization rate, demonstrating that performance optimization cannot be achieved by scale alone but requires optimization stratetgy awareness. In addition, PerfCoder can generate interpretable feedback about the source code, which, when provided as input to a larger LLM in a planner-and-optimizer cooperative workflow, can further improve outcomes. Specifically, we elevate the performance of 32B models and GPT-5 to new levels on code optimization, substantially surpassing their original performance.

</details>


### [8] [PentestEval: Benchmarking LLM-based Penetration Testing with Modular and Stage-Level Design](https://arxiv.org/abs/2512.14233)
*Ruozhao Yang,Mingfei Cheng,Gelei Deng,Tianwei Zhang,Junjie Wang,Xiaofei Xie*

Main category: cs.SE

TL;DR: PentestEval是首个全面的LLM渗透测试评估基准，将流程分解为6个阶段，通过346个任务评估9个主流LLM，发现整体性能较弱（成功率仅31%），现有LLM系统存在类似局限，强调需要更强的结构化推理能力。


<details>
  <summary>Details</summary>
Motivation: 传统渗透测试工作流高度依赖人工、难以扩展，现有LLM应用采用简单提示而缺乏任务分解和领域适应，导致不可靠的黑盒行为和有限的能力洞察，需要建立细粒度评估基准。

Method: 提出PentestEval基准，将渗透测试分解为6个阶段：信息收集、弱点收集与过滤、攻击决策、漏洞利用生成与修订；集成专家标注的真实数据和全自动评估流程，覆盖12个真实漏洞场景中的346个任务。

Result: 评估9个主流LLM发现整体性能较弱，端到端管道成功率仅31%；现有LLM系统（PentestGPT、PentestAgent、VulnBot）存在类似局限，自主代理几乎完全失败；模块化方法能提升各阶段性能并改善整体表现。

Conclusion: 自主渗透测试需要更强的结构化推理能力，模块化能增强各阶段性能；PentestEval为未来细粒度、阶段级评估研究提供了基础基准，推动更可靠的LLM自动化发展。

Abstract: Penetration testing is essential for assessing and strengthening system security against real-world threats, yet traditional workflows remain highly manual, expertise-intensive, and difficult to scale. Although recent advances in Large Language Models (LLMs) offer promising opportunities for automation, existing applications rely on simplistic prompting without task decomposition or domain adaptation, resulting in unreliable black-box behavior and limited insight into model capabilities across penetration testing stages. To address this gap, we introduce PentestEval, the first comprehensive benchmark for evaluating LLMs across six decomposed penetration testing stages: Information Collection, Weakness Gathering and Filtering, Attack Decision-Making, Exploit Generation and Revision. PentestEval integrates expert-annotated ground truth with a fully automated evaluation pipeline across 346 tasks covering all stages in 12 realistic vulnerable scenarios. Our stage-level evaluation of 9 widely used LLMs reveals generally weak performance and distinct limitations across the stages of penetration-testing workflow. End-to-end pipelines reach only 31% success rate, and existing LLM-powered systems such as PentestGPT, PentestAgent, and VulnBot exhibit similar limitations, with autonomous agents failing almost entirely. These findings highlight that autonomous penetration testing demands stronger structured reasoning, where modularization enhances each individual stage and improves overall performance. PentestEval provides the foundational benchmark needed for future research on fine-grained, stage-level evaluation, paving the way toward more reliable LLM-based automation.

</details>


### [9] [Aligning Security Compliance and DevOps: A Longitudinal Study](https://arxiv.org/abs/2512.14453)
*Fabiola Moyón,Florian Angermeir,Daniel Mendez,Tony Gorschek,Markus Voggenreiter,Pierre-Louis Bonvin*

Main category: cs.SE

TL;DR: 本文提出RefA框架，将安全合规标准（IEC 62443-4-1）整合到DevOps流程中，支持关键基础设施产品开发团队在敏捷转型中保持安全合规。


<details>
  <summary>Details</summary>
Motivation: 企业采用敏捷和DevOps方法开发软件密集型产品时，传统线性安全标准合规流程面临挑战，特别是在关键基础设施领域。需要支持企业在向DevOps转型过程中保持安全合规。

Method: 基于IEC 62443-4-1标准开发RefA框架（安全合规DevOps生命周期规范模型），在西门子AG进行纵向研究，包含多个子研究（概念、验证和初步采用阶段）。

Result: RefA框架能够将安全合规知识有效传递给产品开发团队，支持跨职能团队具备交付合规产品所需的所有技能，实现敏捷目标。

Conclusion: RefA框架为专业人员（不仅是安全专家）提供了在实施DevOps流程时保持安全合规的实用工具，特别适用于关键基础设施产品的开发。

Abstract: Companies adopt agile methodologies and DevOps to facilitate efficient development and deployment of software-intensive products. This, in turn, introduces challenges in relation to security standard compliance traditionally following a more linear workflow. This is especially a challenge for the engineering of products and services associated with critical infrastructures. To support companies in their transition towards DevOps, this paper presents an adaptation of DevOps according to security regulations and standards. We report on our longitudinal study at Siemens AG, consisting of several individual sub-studies in the inception, validation, and initial adoption of our framework based on RefA as well as the implications for practice. RefA is a prescriptive model of a security compliant DevOps lifecycle based on the IEC 62443-4-1 standard. The overall framework is aimed at professionals, not only security experts, being able to use it on implementing DevOps processes while remaining compliant with security norms. We demonstrate how RefA facilitates the transfer of security compliance knowledge to product development teams. This knowledge transfer supports the agility aim of ensuring that cross-functional teams have all the skills needed to deliver the compliant products.

</details>


### [10] [Teralizer: Semantics-Based Test Generalization from Conventional Unit Tests to Property-Based Tests](https://arxiv.org/abs/2512.14475)
*Johann Glock,Clemens Bauer,Martin Pinzger*

Main category: cs.SE

TL;DR: Teralizer：将Java单元测试自动转换为基于属性的测试的工具，通过符号分析从实现中提取规范


<details>
  <summary>Details</summary>
Motivation: 传统单元测试只验证单个输入输出对，无法覆盖执行路径中的大部分输入。基于属性的测试虽然能生成多个输入，但需要大量手动工作定义属性和约束。

Method: 提出语义驱动的方法，通过单路径符号分析从实现中自动提取规范，将单元测试转换为基于属性的测试。开发了Teralizer原型，将JUnit测试转换为jqwik测试。

Result: 在三个数据集上评估：EvoSuite生成的测试改进突变分数1-4个百分点；成熟的开发者编写测试仅改进0.05-0.07个百分点；632个真实Java项目中只有1.7%完成转换，失败主要由于符号分析的类型支持限制和静态分析限制。

Conclusion: Teralizer展示了自动测试转换的潜力，但实际应用仍面临挑战。提供了未来工作路线图，包括解决符号分析的类型支持和静态分析限制等研究工程挑战。

Abstract: Conventional unit tests validate single input-output pairs, leaving most inputs of an execution path untested. Property-based testing addresses this shortcoming by generating multiple inputs satisfying properties but requires significant manual effort to define properties and their constraints. We propose a semantics-based approach that automatically transforms unit tests into property-based tests by extracting specifications from implementations via single-path symbolic analysis. We demonstrate this approach through Teralizer, a prototype for Java that transforms JUnit tests into property-based jqwik tests. Unlike prior work that generalizes from input-output examples, Teralizer derives specifications from program semantics.
  We evaluated Teralizer on three progressively challenging datasets. On EvoSuite-generated tests for EqBench and Apache Commons utilities, Teralizer improved mutation scores by 1-4 percentage points. Generalization of mature developer-written tests from Apache Commons utilities showed only 0.05-0.07 percentage points improvement. Analysis of 632 real-world Java projects from RepoReapers highlights applicability barriers: only 1.7% of projects completed the generalization pipeline, with failures primarily due to type support limitations in symbolic analysis and static analysis limitations in our prototype. Based on the results, we provide a roadmap for future work, identifying research and engineering challenges that need to be tackled to advance the field of test generalization.
  Artifacts available at: https://doi.org/10.5281/zenodo.17950381

</details>


### [11] [MoT: A Model-Driven Low-Code Approach for Simplifying Cloud-of-Things Application Development](https://arxiv.org/abs/2512.14613)
*Cristiano Welter,Kleinner Farias*

Main category: cs.SE

TL;DR: 本文提出Model of Things (MoT)，一种基于模型的低代码方法，用于简化云物联网(CoT)应用开发，通过定制UML配置文件降低技术门槛。


<details>
  <summary>Details</summary>
Motivation: 云物联网(CoT)应用开发面临挑战：需要大量技术专业知识，缺乏标准化、模型驱动的方法论，现有方法无法确保互操作性、自动化和效率。

Method: 提出MoT方法，结合低代码原则，为物联网和云服务设计定制UML配置文件。通过案例研究和TAM问卷进行评估。

Result: MoT被证实可行，能简化CoT应用开发和部署。用户即使物联网经验有限也能使用，感知易用性和有用性高，能降低复杂性并加速开发。

Conclusion: MoT为CoT应用开发提供了有前景的模型驱动解决方案，通过降低入门门槛和促进自动化，提高了效率和灵活性，推动了CoT技术的更广泛采用。

Abstract: The integration of cloud computing and the Internet of Things (IoT) is essential for scalable, intelligent systems. However, developing cloud-of-things (CoT) applications remains challenging. It requires significant technical expertise and lacks standardized, model-driven methodologies. Current approaches fail to ensure interoperability, automation, and efficiency. This study introduces the Model of Things (MoT), a model-based approach that incorporates low-code principles to simplify CoT development. MoT reduces technical barriers by providing a custom UML profile designed for IoT and cloud services. To evaluate MoT, we conducted a case study and a Technology Acceptance Model (TAM) questionnaire. The results confirmed MoT's feasibility, demonstrating that it streamlines CoT application development and deployment. Users found MoT accessible, even with limited IoT experience, and reported high perceived ease of use and usefulness. Qualitative feedback highlighted MoT's ability to reduce complexity and speed up development. MoT offers a promising, model-driven solution for CoT application development. By lowering entry barriers and promoting automation, it enhances both efficiency and flexibility. This study represents a step toward a more user-friendly framework, enabling broader adoption of CoT technologies.

</details>


### [12] [Reconsidering Conversational Norms in LLM Chatbots for Sustainable AI](https://arxiv.org/abs/2512.14673)
*Ronnie de Souza Santos,Cleyton Magalhães,Italo Santos*

Main category: cs.SE

TL;DR: 本文认为用户交互行为是影响LLM系统环境足迹的关键但被忽视的因素，提出了四个维度的问题，并呼吁重新设计聊天机器人交互以提升可持续性。


<details>
  <summary>Details</summary>
Motivation: 随着LLM聊天机器人在技术、教育和分析领域的广泛应用，其可持续性问题日益突出。现有研究主要关注模型架构、硬件效率和部署基础设施，但忽视了用户交互行为本身对LLM系统能源消耗的影响。本文旨在揭示交互层行为作为塑造LLM系统环境影响的关键但被忽视的因素。

Method: 这是一篇愿景论文，通过理论分析和框架构建，从四个维度探讨用户交互行为如何影响LLM系统的能源消耗：1）扩展对话模式增加令牌生成和推理计算成本；2）即时响应期望限制能源感知调度和工作负载整合机会；3）日常用户习惯累积运营需求但很少被量化；4）上下文积累影响内存需求并降低长对话效率。

Result: 论文识别出用户交互行为对LLM系统环境影响的四个关键维度，揭示了当前LLM系统设计中可持续性考虑的不足，特别是交互设计层面的缺失。

Conclusion: 解决这些挑战需要重新思考聊天机器人交互的设计和概念化，采用新的视角，认识到可持续性部分取决于用户与LLM系统互动的对话规范。需要将可持续性考虑融入交互设计，而不仅仅是技术优化。

Abstract: LLM based chatbots have become central interfaces in technical, educational, and analytical domains, supporting tasks such as code reasoning, problem solving, and information exploration. As these systems scale, sustainability concerns have intensified, with most assessments focusing on model architecture, hardware efficiency, and deployment infrastructure. However, existing mitigation efforts largely overlook how user interaction practices themselves shape the energy profile of LLM based systems. In this vision paper, we argue that interaction level behavior appears to be an underexamined factor shaping the environmental impact of LLM based systems, and we present this issue across four dimensions. First, extended conversational patterns increase token production and raise the computational cost of inference. Second, expectations of instant responses limit opportunities for energy aware scheduling and workload consolidation. Third, everyday user habits contribute to cumulative operational demand in ways that are rarely quantified. Fourth, the accumulation of context affects memory requirements and reduces the efficiency of long running dialogues. Addressing these challenges requires rethinking how chatbot interactions are designed and conceptualized, and adopting perspectives that recognize sustainability as partly dependent on the conversational norms through which users engage with LLM based systems.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [13] [Real-Time Service Subscription and Adaptive Offloading Control in Vehicular Edge Computing](https://arxiv.org/abs/2512.14002)
*Chuanchao Gao,Arvind Easwaran*

Main category: cs.DC

TL;DR: 提出SARound算法，将VEC中任务卸载与资源分配问题的近似比从1/6提升到1/4，并设计在线服务订阅框架，通过仿真验证性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 车载边缘计算中，时间关键型应用的任务卸载和资源分配面临网络带宽有限、计算资源受限、任务截止时间严格以及网络条件快速变化等挑战，需要高效解决方案。

Method: 1) 将问题建模为带截止时间的任务卸载与资源分配问题(DOAP)；2) 提出基于线性规划舍入和局部比率技术的SARound近似算法；3) 设计在线服务订阅和卸载控制框架应对动态网络条件；4) 开发VecSim仿真器集成OMNeT++和Simu5G。

Result: SARound算法将DOAP问题的最佳已知近似比从1/6提升到1/4，在基于真实出租车轨迹数据和目标检测应用的实验中，始终优于现有基线方法，同时保持运行时效率。

Conclusion: 提出的SARound算法和在线框架有效解决了VEC中任务卸载和资源分配的挑战，显著提升了系统性能，为智能交通系统中的实时应用提供了实用解决方案。

Abstract: Vehicular Edge Computing (VEC) has emerged as a promising paradigm for enhancing the computational efficiency and service quality in intelligent transportation systems by enabling vehicles to wirelessly offload computation-intensive tasks to nearby Roadside Units. However, efficient task offloading and resource allocation for time-critical applications in VEC remain challenging due to constrained network bandwidth and computational resources, stringent task deadlines, and rapidly changing network conditions. To address these challenges, we formulate a Deadline-Constrained Task Offloading and Resource Allocation Problem (DOAP), denoted as $\mathbf{P}$, in VEC with both bandwidth and computational resource constraints, aiming to maximize the total vehicle utility. To solve $\mathbf{P}$, we propose $\mathtt{SARound}$, an approximation algorithm based on Linear Program rounding and local-ratio techniques, that improves the best-known approximation ratio for DOAP from $\frac{1}{6}$ to $\frac{1}{4}$. Additionally, we design an online service subscription and offloading control framework to address the challenges of short task deadlines and rapidly changing wireless network conditions. To validate our approach, we develop a comprehensive VEC simulator, VecSim, using the open-source simulation libraries OMNeT++ and Simu5G. VecSim integrates our designed framework to manage the full life-cycle of real-time vehicular tasks. Experimental results, based on profiled object detection applications and real-world taxi trace data, show that $\mathtt{SARound}$ consistently outperforms state-of-the-art baselines under varying network conditions while maintaining runtime efficiency.

</details>


### [14] [A Hybrid Reactive-Proactive Auto-scaling Algorithm for SLA-Constrained Edge Computing](https://arxiv.org/abs/2512.14290)
*Suhrid Gupta,Muhammed Tawfiqul Islam,Rajkumar Buyya*

Main category: cs.DC

TL;DR: 提出一种结合机器学习的混合自动扩缩算法，用于边缘计算环境，相比现有方案将SLA违反率从23%降至6%


<details>
  <summary>Details</summary>
Motivation: 边缘计算通过微服务架构实现低延迟应用，但需要满足严格的SLA要求。现有自动扩缩算法存在性能问题和配置复杂性，无法保证SLA合规性

Method: 提出混合自动扩缩算法：结合基于机器学习的主动扩缩器（预测资源需求）和反应式扩缩器（基于当前资源利用率和SLA约束进行即时调整），并集成到Kubernetes中

Result: 在边缘环境中通过真实应用进行广泛实验，现有方案的SLA违反率高达23%，而提出的混合方案仅6%，显著提升了SLA合规性

Conclusion: 提出的混合自动扩缩算法能有效确保边缘计算应用的SLA合规性，相比现有方案有显著改进，为边缘计算环境提供了可靠的资源管理解决方案

Abstract: Edge computing decentralizes computing resources, allowing for novel applications in domains such as the Internet of Things (IoT) in healthcare and agriculture by reducing latency and improving performance. This decentralization is achieved through the implementation of microservice architectures, which require low latencies to meet stringent service level agreements (SLA) such as performance, reliability, and availability metrics. While cloud computing offers the large data storage and computation resources necessary to handle peak demands, a hybrid cloud and edge environment is required to ensure SLA compliance. This is achieved by sophisticated orchestration strategies such as Kubernetes, which help facilitate resource management. The orchestration strategies alone do not guarantee SLA adherence due to the inherent delay of scaling resources. Existing auto-scaling algorithms have been proposed to address these challenges, but they suffer from performance issues and configuration complexity. In this paper, a novel auto-scaling algorithm is proposed for SLA-constrained edge computing applications. This approach combines a Machine Learning (ML) based proactive auto-scaling algorithm, capable of predicting incoming resource requests to forecast demand, with a reactive autoscaler which considers current resource utilization and SLA constraints for immediate adjustments. The algorithm is integrated into Kubernetes as an extension, and its performance is evaluated through extensive experiments in an edge environment with real applications. The results demonstrate that existing solutions have an SLA violation rate of up to 23%, whereas the proposed hybrid solution outperforms the baselines with an SLA violation rate of only 6%, ensuring stable SLA compliance across various applications.

</details>


### [15] [Performance and Stability of Barrier Mode Parallel Systems with Heterogeneous and Redundant Jobs](https://arxiv.org/abs/2512.14445)
*Brenton Walker,Markus Fidler*

Main category: cs.DC

TL;DR: 分析屏障同步机制在并行计算中对系统稳定性和性能的影响，特别针对Apache Spark的屏障执行模式，研究屏障导致的空闲时间和性能开销。


<details>
  <summary>Details</summary>
Motivation: 在并行计算中，屏障同步机制（如Apache Spark的屏障执行模式）会导致工作节点出现空闲期，降低系统稳定性和性能。需要量化分析这种影响，为优化并行计算系统提供理论依据。

Method: 1) 分析(s,k,l)屏障系统的稳定性，其中作业在k个任务中完成l个后可以离开；2) 推导混合屏障系统的性能界限，处理有屏障和无屏障的混合作业；3) 针对纯1-屏障情况，将理论界限和仿真结果与独立Spark系统的基准数据对比；4) 研究实际系统中的开销分布，归因于双事件和轮询驱动的调度机制；5) 为此类开销建立模型并通过仿真验证。

Result: 1) 建立了屏障系统稳定性和性能的理论分析框架；2) 推导了混合屏障系统的性能界限；3) 验证了理论模型与实际Spark系统的一致性；4) 识别了屏障执行模式的主要开销来源（双事件和轮询驱动调度机制）；5) 建立了开销模型并通过仿真验证。

Conclusion: 屏障同步机制确实会显著影响并行计算系统的稳定性和性能，导致工作节点空闲和额外开销。通过理论分析和建模可以量化这种影响，为优化屏障执行模式提供指导。实际系统中的开销主要来源于调度机制的设计选择。

Abstract: In some models of parallel computation, jobs are split into smaller tasks and can be executed completely asynchronously. In other situations the parallel tasks have constraints that require them to synchronize their start and possibly departure times. This is true of many parallelized machine learning workloads, and the popular Apache Spark processing engine has recently added support for Barrier Execution Mode, which allows users to add such barriers to their jobs. These barriers necessarily result in idle periods on some of the workers, which reduces their stability and performance, compared to equivalent workloads with no barriers.
  In this paper we will consider and analyze the stability and performance penalties resulting from barriers. We include an analysis of the stability of $(s,k,l)$ barrier systems that allow jobs to depart after $l$ out of $k$ of their tasks complete. We also derive and evaluate performance bounds for hybrid barrier systems servicing a mix of jobs, both with and without barriers, and with varying degrees of parallelism. For the purely 1-barrier case we compare the bounds and simulation results to benchmark data from a standalone Spark system. We study the overhead in the real system, and based on its distribution we attribute it to the dual event and polling-driven mechanism used to schedule barrier-mode jobs. We develop a model for this type of overhead and validate it against the real system through simulation.

</details>


### [16] [PruneX: A Hierarchical Communication-Efficient System for Distributed CNN Training with Structured Pruning](https://arxiv.org/abs/2512.14628)
*Alireza Olama,Andreas Lundell,Izzat El Hajj,Johan Lilius,Jerker Björkqvist*

Main category: cs.DC

TL;DR: PruneX是一个分布式数据并行训练系统，通过协同设计剪枝算法与集群层次结构来减少节点间通信带宽使用，在64个GPU上实现6.75倍强扩展加速


<details>
  <summary>Details</summary>
Motivation: 在多节点GPU集群上进行大规模分布式训练时，节点间通信带宽日益成为瓶颈。传统的剪枝感知分布式训练系统通常无法有效减少通信开销，因为非结构化稀疏性无法被高度优化的密集集体原语有效利用

Method: 提出PruneX系统，采用分层结构化ADMM（H-SADMM）算法，在节点间同步前强制执行节点级结构化稀疏性，实现动态缓冲区压缩，消除零值传输和索引开销。系统采用领导者-跟随者执行模型，分离节点内和节点间进程组，在带宽受限链路上对压缩张量执行密集集体操作，同时将完全同步限制在高带宽节点内互连上

Result: 在ResNet架构上的64个GPU评估显示，PruneX将节点间通信量减少约60%，实现6.75倍强扩展加速，优于密集基线（5.81倍）和Top-K梯度压缩（3.71倍）

Conclusion: PruneX通过协同设计剪枝算法与集群层次结构，有效减少了分布式训练中的节点间通信开销，实现了显著的性能提升，为解决大规模分布式训练中的通信瓶颈提供了有效方案

Abstract: Inter-node communication bandwidth increasingly constrains distributed training at scale on multi-node GPU clusters. While compact models are the ultimate deployment target, conventional pruning-aware distributed training systems typically fail to reduce communication overhead because unstructured sparsity cannot be efficiently exploited by highly optimized dense collective primitives. We present PruneX, a distributed data-parallel training system that co-designs pruning algorithms with cluster hierarchy to reduce inter-node bandwidth usage. PruneX introduces the Hierarchical Structured ADMM (H-SADMM) algorithm, which enforces node-level structured sparsity before inter-node synchronization, enabling dynamic buffer compaction that eliminates both zero-valued transmissions and indexing overhead. The system adopts a leader-follower execution model with separated intra-node and inter-node process groups, performing dense collectives on compacted tensors over bandwidth-limited links while confining full synchronization to high-bandwidth intra-node interconnects. Evaluation on ResNet architectures across 64 GPUs demonstrates that PruneX reduces inter-node communication volume by approximately 60% and achieves 6.75x strong scaling speedup, outperforming the dense baseline (5.81x) and Top-K gradient compression (3.71x) on the Puhti supercomputer at CSC - IT Center for Science (Finland).

</details>
