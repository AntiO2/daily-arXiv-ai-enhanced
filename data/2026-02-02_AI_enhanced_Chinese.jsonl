{"id": "2601.22438", "categories": ["cs.DC", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.22438", "abs": "https://arxiv.org/abs/2601.22438", "authors": ["Shangshu Qian", "Kipling Liu", "P. C. Sruthi", "Lin Tan", "Yongle Zhang"], "title": "Towards Resiliency in Large Language Model Serving with KevlarFlow", "comment": null, "summary": "Large Language Model (LLM) serving systems remain fundamentally fragile, where frequent hardware faults in hyperscale clusters trigger disproportionate service outages in the software stack. Current recovery mechanisms are prohibitively slow, often requiring up to 10 minutes to reinitialize resources and reload massive model weights. We introduce KevlarFlow, a fault tolerant serving architecture designed to bridge the gap between hardware unreliability and service availability. KevlarFlow leverages 1) decoupled model parallelism initialization, 2) dynamic traffic rerouting, and 3) background KV cache replication to maintain high throughput during partial failures. Our evaluation demonstrates that KevlarFlow reduces mean-time-to-recovery (MTTR) by 20x and, under failure conditions, improves average latency by 3.1x, 99th percentile (p99) latency by 2.8x, average time-to-first-token (TTFT) by 378.9x, and p99 TTFT by 574.6x with negligible runtime overhead in comparison to state-of-the-art LLM serving systems.", "AI": {"tldr": "KevlarFlow\u662f\u4e00\u4e2a\u7528\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u670d\u52a1\u7684\u5bb9\u9519\u67b6\u6784\uff0c\u901a\u8fc7\u89e3\u8026\u6a21\u578b\u5e76\u884c\u521d\u59cb\u5316\u3001\u52a8\u6001\u6d41\u91cf\u91cd\u8def\u7531\u548c\u540e\u53f0KV\u7f13\u5b58\u590d\u5236\uff0c\u5c06\u6062\u590d\u65f6\u95f4\u7f29\u77ed20\u500d\uff0c\u5728\u6545\u969c\u6761\u4ef6\u4e0b\u663e\u8457\u6539\u5584\u5ef6\u8fdf\u6307\u6807\u3002", "motivation": "\u5f53\u524dLLM\u670d\u52a1\u7cfb\u7edf\u5728\u8d85\u5927\u89c4\u6a21\u96c6\u7fa4\u4e2d\u9762\u4e34\u786c\u4ef6\u6545\u969c\u9891\u7e41\u89e6\u53d1\u8f6f\u4ef6\u6808\u670d\u52a1\u4e2d\u65ad\u7684\u95ee\u9898\uff0c\u73b0\u6709\u6062\u590d\u673a\u5236\u8fc7\u4e8e\u7f13\u6162\uff08\u9700\u8981\u957f\u8fbe10\u5206\u949f\u91cd\u65b0\u521d\u59cb\u5316\u8d44\u6e90\u548c\u52a0\u8f7d\u6a21\u578b\u6743\u91cd\uff09\uff0c\u65e0\u6cd5\u6ee1\u8db3\u670d\u52a1\u53ef\u7528\u6027\u9700\u6c42\u3002", "method": "1) \u89e3\u8026\u6a21\u578b\u5e76\u884c\u521d\u59cb\u5316\uff1a\u5206\u79bb\u6a21\u578b\u5e76\u884c\u7ec4\u4ef6\u7684\u521d\u59cb\u5316\u8fc7\u7a0b\uff1b2) \u52a8\u6001\u6d41\u91cf\u91cd\u8def\u7531\uff1a\u5728\u90e8\u5206\u6545\u969c\u65f6\u667a\u80fd\u91cd\u5b9a\u5411\u6d41\u91cf\uff1b3) \u540e\u53f0KV\u7f13\u5b58\u590d\u5236\uff1a\u5728\u540e\u53f0\u6301\u7eed\u590d\u5236\u952e\u503c\u7f13\u5b58\u4ee5\u652f\u6301\u5feb\u901f\u6062\u590d\u3002", "result": "KevlarFlow\u5c06\u5e73\u5747\u6062\u590d\u65f6\u95f4\uff08MTTR\uff09\u7f29\u77ed20\u500d\uff0c\u5728\u6545\u969c\u6761\u4ef6\u4e0b\uff1a\u5e73\u5747\u5ef6\u8fdf\u6539\u55843.1\u500d\uff0cp99\u5ef6\u8fdf\u6539\u55842.8\u500d\uff0c\u5e73\u5747\u9996\u8bcd\u65f6\u95f4\uff08TTFT\uff09\u6539\u5584378.9\u500d\uff0cp99 TTFT\u6539\u5584574.6\u500d\uff0c\u8fd0\u884c\u65f6\u5f00\u9500\u53ef\u5ffd\u7565\u3002", "conclusion": "KevlarFlow\u901a\u8fc7\u521b\u65b0\u7684\u5bb9\u9519\u67b6\u6784\u6709\u6548\u5f25\u5408\u4e86\u786c\u4ef6\u4e0d\u53ef\u9760\u6027\u4e0e\u670d\u52a1\u53ef\u7528\u6027\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u663e\u8457\u63d0\u5347\u4e86LLM\u670d\u52a1\u7cfb\u7edf\u7684\u97e7\u6027\u548c\u6027\u80fd\u8868\u73b0\u3002"}}
{"id": "2601.22487", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2601.22487", "abs": "https://arxiv.org/abs/2601.22487", "authors": ["Ali Jahanshahi", "Sara Rashidi Golrouye", "Osten Anderson", "Nanpeng Yu", "Daniel Wong"], "title": "Coordinating Power Grid Frequency Regulation Service with Data Center Load Flexibility", "comment": null, "summary": "AI/ML data center growth have led to higher energy consumption and carbon emissions. The shift to renewable energy and growing data center energy demands can destabilize the power grid. Power grids rely on frequency regulation reserves, typically fossil-fueled power plants, to stabilize and balance the supply and demand of electricity. This paper sheds light on the hidden carbon emissions of frequency regulation service. Our work explores how modern GPU data centers can coordinate with power grids to reduce the need for fossil-fueled frequency regulation reserves. We first introduce a novel metric, Exogenous Carbon, to quantify grid-side carbon emission reductions resulting from data center participation in regulation service. We additionally introduce EcoCenter, a framework to maximize the amount of frequency regulation provision that GPU data centers can provide, and thus, reduce the amount of frequency regulation reserves necessary. We demonstrate that data center participation in frequency regulation can result in Exogenous carbon savings that oftentimes outweigh Operational carbon emissions.", "AI": {"tldr": "GPU\u6570\u636e\u4e2d\u5fc3\u53c2\u4e0e\u7535\u7f51\u9891\u7387\u8c03\u8282\u670d\u52a1\u53ef\u51cf\u5c11\u5316\u77f3\u71c3\u6599\u5907\u7528\u5bb9\u91cf\u9700\u6c42\uff0c\u4ece\u800c\u964d\u4f4e\u7535\u7f51\u4fa7\u78b3\u6392\u653e\uff0c\u5176\"\u5916\u6e90\u6027\u78b3\u51cf\u6392\"\u53ef\u80fd\u8d85\u8fc7\u6570\u636e\u4e2d\u5fc3\u81ea\u8eab\u8fd0\u8425\u78b3\u6392\u653e\u3002", "motivation": "AI/ML\u6570\u636e\u4e2d\u5fc3\u80fd\u8017\u589e\u957f\u5bfc\u81f4\u78b3\u6392\u653e\u589e\u52a0\uff0c\u800c\u5411\u53ef\u518d\u751f\u80fd\u6e90\u8f6c\u578b\u548c\u80fd\u6e90\u9700\u6c42\u589e\u957f\u53ef\u80fd\u7834\u574f\u7535\u7f51\u7a33\u5b9a\u3002\u7535\u7f51\u4f9d\u8d56\u5316\u77f3\u71c3\u6599\u53d1\u7535\u5382\u8fdb\u884c\u9891\u7387\u8c03\u8282\uff0c\u8fd9\u4ea7\u751f\u9690\u6027\u78b3\u6392\u653e\u3002\u7814\u7a76\u63a2\u7d22\u6570\u636e\u4e2d\u5fc3\u5982\u4f55\u53c2\u4e0e\u9891\u7387\u8c03\u8282\u670d\u52a1\u6765\u51cf\u5c11\u5bf9\u5316\u77f3\u71c3\u6599\u5907\u7528\u5bb9\u91cf\u7684\u9700\u6c42\u3002", "method": "\u63d0\u51fa\"\u5916\u6e90\u6027\u78b3\"\u65b0\u6307\u6807\u6765\u91cf\u5316\u6570\u636e\u4e2d\u5fc3\u53c2\u4e0e\u8c03\u8282\u670d\u52a1\u5e26\u6765\u7684\u7535\u7f51\u4fa7\u78b3\u51cf\u6392\uff1b\u5f00\u53d1EcoCenter\u6846\u67b6\uff0c\u6700\u5927\u5316GPU\u6570\u636e\u4e2d\u5fc3\u80fd\u63d0\u4f9b\u7684\u9891\u7387\u8c03\u8282\u91cf\uff0c\u4ece\u800c\u51cf\u5c11\u6240\u9700\u5316\u77f3\u71c3\u6599\u5907\u7528\u5bb9\u91cf\u3002", "result": "\u6570\u636e\u4e2d\u5fc3\u53c2\u4e0e\u9891\u7387\u8c03\u8282\u670d\u52a1\u53ef\u4ea7\u751f\u663e\u8457\u7684\u5916\u6e90\u6027\u78b3\u51cf\u6392\uff0c\u8fd9\u4e9b\u51cf\u6392\u91cf\u5e38\u5e38\u8d85\u8fc7\u6570\u636e\u4e2d\u5fc3\u81ea\u8eab\u7684\u8fd0\u8425\u78b3\u6392\u653e\u3002", "conclusion": "GPU\u6570\u636e\u4e2d\u5fc3\u4e0e\u7535\u7f51\u534f\u8c03\u53c2\u4e0e\u9891\u7387\u8c03\u8282\u670d\u52a1\u662f\u51cf\u5c11\u7535\u7f51\u78b3\u6392\u653e\u7684\u6709\u6548\u9014\u5f84\uff0c\u6570\u636e\u4e2d\u5fc3\u7684\u5916\u6e90\u6027\u78b3\u51cf\u6392\u6f5c\u529b\u5de8\u5927\uff0c\u53ef\u80fd\u8d85\u8fc7\u5176\u81ea\u8eab\u8fd0\u8425\u6392\u653e\uff0c\u4e3a\u5b9e\u73b0\u78b3\u4e2d\u548c\u63d0\u4f9b\u65b0\u601d\u8def\u3002"}}
{"id": "2601.22585", "categories": ["cs.DC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.22585", "abs": "https://arxiv.org/abs/2601.22585", "authors": ["Heehoon Kim", "Jaehwan Lee", "Taejeoung Kim", "Jongwon Park", "Jinpyo Kim", "Pyongwon Suh", "Ryan H. Choi", "Sangwoo Lee", "Jaejin Lee"], "title": "HetCCL: Accelerating LLM Training with Heterogeneous GPUs", "comment": null, "summary": "The rapid growth of large language models is driving organizations to expand their GPU clusters, often with GPUs from multiple vendors. However, current deep learning frameworks lack support for collective communication across heterogeneous GPUs, leading to inefficiency and higher costs. We present HetCCL, a collective communication library that unifies vendor-specific backends and enables RDMA-based communication across GPUs without requiring driver modifications. HetCCL introduces two novel mechanisms that enable cross-vendor communication while leveraging optimized vendor libraries, NVIDIA NCCL and AMD RCCL. Evaluations on a multi-vendor GPU cluster show that HetCCL matches NCCL and RCCL performance in homogeneous setups while uniquely scaling in heterogeneous environments, enabling practical, high-performance training with both NVIDIA and AMD GPUs without changes to existing deep learning applications.", "AI": {"tldr": "HetCCL\u662f\u4e00\u4e2a\u5f02\u6784GPU\u96c6\u4f53\u901a\u4fe1\u5e93\uff0c\u652f\u6301\u8de8NVIDIA\u548cAMD GPU\u7684\u9ad8\u6027\u80fd\u901a\u4fe1\uff0c\u65e0\u9700\u4fee\u6539\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u5e94\u7528\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5feb\u901f\u53d1\u5c55\uff0c\u7ec4\u7ec7\u9700\u8981\u6269\u5c55\u591a\u5382\u5546GPU\u96c6\u7fa4\uff0c\u4f46\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\u7f3a\u4e4f\u5bf9\u5f02\u6784GPU\u96c6\u4f53\u901a\u4fe1\u7684\u652f\u6301\uff0c\u5bfc\u81f4\u6548\u7387\u4f4e\u4e0b\u548c\u6210\u672c\u589e\u52a0\u3002", "method": "HetCCL\u901a\u8fc7\u7edf\u4e00\u5382\u5546\u7279\u5b9a\u540e\u7aef\uff08NCCL\u548cRCCL\uff09\u5e76\u5f15\u5165\u4e24\u79cd\u65b0\u9896\u673a\u5236\uff0c\u5b9e\u73b0\u8de8\u5382\u5546RDMA\u901a\u4fe1\uff0c\u65e0\u9700\u9a71\u52a8\u7a0b\u5e8f\u4fee\u6539\uff0c\u540c\u65f6\u5229\u7528\u4f18\u5316\u7684\u5382\u5546\u5e93\u3002", "result": "\u5728\u591a\u5382\u5546GPU\u96c6\u7fa4\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\uff0cHetCCL\u5728\u540c\u7c7bGPU\u8bbe\u7f6e\u4e2d\u6027\u80fd\u4e0eNCCL\u548cRCCL\u76f8\u5f53\uff0c\u5728\u5f02\u6784\u73af\u5883\u4e2d\u80fd\u72ec\u7279\u6269\u5c55\uff0c\u5b9e\u73b0\u9ad8\u6027\u80fd\u8bad\u7ec3\u3002", "conclusion": "HetCCL\u4e3a\u5f02\u6784GPU\u96c6\u7fa4\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u9ad8\u6027\u80fd\u96c6\u4f53\u901a\u4fe1\u89e3\u51b3\u65b9\u6848\uff0c\u652f\u6301NVIDIA\u548cAMD GPU\u6df7\u5408\u8bad\u7ec3\uff0c\u65e0\u9700\u4fee\u6539\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u5e94\u7528\u3002"}}
{"id": "2601.22705", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2601.22705", "abs": "https://arxiv.org/abs/2601.22705", "authors": ["Qiaoling Chen", "Zhisheng Ye", "Tian Tang", "Peng Sun", "Boyu Tian", "Guoteng Wang", "Shenggui Li", "Yonggang Wen", "Zhenhua Han", "Tianwei Zhang"], "title": "CONCUR: High-Throughput Agentic Batch Inference of LLM via Congestion-Based Concurrency Control", "comment": null, "summary": "Batch inference for agentic workloads stresses the GPU key-value (KV) cache in a sustained and cumulative manner, often causing severe throughput degradation well before memory capacity is exhausted. We identify this phenomenon as middle-phase thrashing, a previously under-characterized pathology in which cache efficiency collapses as long-lived agents accumulate state over time.\n  We argue that mitigating this pathology requires moving beyond reactive, request-level cache management to proactive, agent-level admission control. Drawing inspiration from congestion control in distributed systems, we view the KV cache as a shared resource whose efficient utilization depends on feedback-driven regulation. Based on this insight, we present CONCUR, a lightweight control layer that regulates agent admission to bound aggregate cache pressure while preserving execution continuity. CONCUR adapts a cache-aware control algorithm to dynamically adjust the number of active agents using runtime cache signals.\n  Across large models and real-world agent workloads, CONCUR prevents middle-phase thrashing and improves batch inference throughput by up to 4.09x on Qwen3-32B and 1.9x on DeepSeek-V3, while remaining compatible with existing LLM serving systems.", "AI": {"tldr": "CONCUR\uff1a\u9488\u5bf9\u5927\u6a21\u578b\u6279\u91cf\u63a8\u7406\u4e2d\u4ee3\u7406\u5de5\u4f5c\u8d1f\u8f7d\u7684KV\u7f13\u5b58\u4e2d\u95f4\u9636\u6bb5\u98a0\u7c38\u95ee\u9898\uff0c\u63d0\u51fa\u57fa\u4e8e\u4ee3\u7406\u7ea7\u51c6\u5165\u63a7\u5236\u7684\u8f7b\u91cf\u7ea7\u63a7\u5236\u5c42\uff0c\u901a\u8fc7\u52a8\u6001\u8c03\u8282\u6d3b\u8dc3\u4ee3\u7406\u6570\u91cf\u6765\u63d0\u5347\u541e\u5410\u91cf\u3002", "motivation": "\u6279\u91cf\u63a8\u7406\u4e2d\u4ee3\u7406\u5de5\u4f5c\u8d1f\u8f7d\u4f1a\u5bfc\u81f4KV\u7f13\u5b58\u51fa\u73b0\u4e2d\u95f4\u9636\u6bb5\u98a0\u7c38\u73b0\u8c61\uff0c\u5373\u7f13\u5b58\u6548\u7387\u968f\u7740\u957f\u65f6\u95f4\u8fd0\u884c\u7684\u4ee3\u7406\u72b6\u6001\u7d2f\u79ef\u800c\u6025\u5267\u4e0b\u964d\uff0c\u4e25\u91cd\u5f71\u54cd\u541e\u5410\u91cf\uff0c\u800c\u73b0\u6709\u8bf7\u6c42\u7ea7\u7f13\u5b58\u7ba1\u7406\u65e0\u6cd5\u6709\u6548\u89e3\u51b3\u6b64\u95ee\u9898\u3002", "method": "\u501f\u9274\u5206\u5e03\u5f0f\u7cfb\u7edf\u4e2d\u7684\u62e5\u585e\u63a7\u5236\u601d\u60f3\uff0c\u5c06KV\u7f13\u5b58\u89c6\u4e3a\u5171\u4eab\u8d44\u6e90\uff0c\u8bbe\u8ba1CONCUR\u63a7\u5236\u5c42\u5b9e\u73b0\u4ee3\u7406\u7ea7\u51c6\u5165\u63a7\u5236\u3002\u91c7\u7528\u7f13\u5b58\u611f\u77e5\u7684\u63a7\u5236\u7b97\u6cd5\uff0c\u6839\u636e\u8fd0\u884c\u65f6\u7f13\u5b58\u4fe1\u53f7\u52a8\u6001\u8c03\u6574\u6d3b\u8dc3\u4ee3\u7406\u6570\u91cf\uff0c\u5728\u4fdd\u6301\u6267\u884c\u8fde\u7eed\u6027\u7684\u540c\u65f6\u9650\u5236\u805a\u5408\u7f13\u5b58\u538b\u529b\u3002", "result": "\u5728Qwen3-32B\u4e0a\u541e\u5410\u91cf\u63d0\u5347\u6700\u9ad8\u8fbe4.09\u500d\uff0c\u5728DeepSeek-V3\u4e0a\u63d0\u53471.9\u500d\uff0c\u6709\u6548\u9632\u6b62\u4e2d\u95f4\u9636\u6bb5\u98a0\u7c38\uff0c\u4e14\u4e0e\u73b0\u6709LLM\u670d\u52a1\u7cfb\u7edf\u517c\u5bb9\u3002", "conclusion": "KV\u7f13\u5b58\u7ba1\u7406\u9700\u8981\u4ece\u53cd\u5e94\u5f0f\u7684\u8bf7\u6c42\u7ea7\u63a7\u5236\u8f6c\u5411\u4e3b\u52a8\u7684\u4ee3\u7406\u7ea7\u51c6\u5165\u63a7\u5236\uff0cCONCUR\u901a\u8fc7\u8f7b\u91cf\u7ea7\u7684\u53cd\u9988\u9a71\u52a8\u8c03\u8282\u673a\u5236\uff0c\u663e\u8457\u63d0\u5347\u6279\u91cf\u63a8\u7406\u4e2d\u4ee3\u7406\u5de5\u4f5c\u8d1f\u8f7d\u7684\u541e\u5410\u6027\u80fd\u3002"}}
{"id": "2601.22175", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2601.22175", "abs": "https://arxiv.org/abs/2601.22175", "authors": ["Christophe B\u00e9chade"], "title": "An innovating approach to teaching applied to database design. Improvement of Action Learning in Lifelong Learning", "comment": null, "summary": "For now 10 years, the Action Learning has allowed employees of University of Angers, private and public Companies to be initiated with the design of database, on projects financed by professional structures. These innovating training periods are carried out within the framework of the University College of Further Education of the University of Angers. Database design is a process initially reserved to the professional data processing specialists, coming from French Level-2 technological courses (2-year degrees) or Engineer Schools (Master). The pedagogical model of technological courses has integrated for more than 20 years transverse semester projects, in order to give the students the opportunity to apply newly acquired knowledge, coordinated by teachers. Action Learning requires teachers to assume the role of supervisors for the project management. The objective of Action Learning is to transmit not only knowledge from teachers, but also the experience of consultants to trainees having no competence in data processing, but who have the knowledge of their business process. The present paper shows that Action Learning puts together the factors for success of French technological courses, the adaptability of pedagogy provided to the vocational training, and finally the competence of service provider, Keeping the best parts of those three complementary approaches makes it possible for this kind of formation to achieve teaching and professional, assessable and long lasting goals. Action Learning belongs to the French policy that aims to improve the volume and the quality of the contracts between Universities and companies.", "AI": {"tldr": "\u6602\u70ed\u5927\u5b66\u901a\u8fc7\u884c\u52a8\u5b66\u4e60\u6a21\u5f0f\uff0c\u8ba9\u5458\u5de5\u548c\u4f01\u4e1a\u4eba\u5458\u5728\u4e13\u4e1a\u9879\u76ee\u4e2d\u8fdb\u884c\u6570\u636e\u5e93\u8bbe\u8ba1\u57f9\u8bad\uff0c\u7ed3\u5408\u6280\u672f\u8bfe\u7a0b\u3001\u804c\u4e1a\u57f9\u8bad\u548c\u54a8\u8be2\u670d\u52a1\u4f18\u52bf\uff0c\u5b9e\u73b0\u6559\u5b66\u4e0e\u804c\u4e1a\u76ee\u6807", "motivation": "\u4f20\u7edf\u6570\u636e\u5e93\u8bbe\u8ba1\u901a\u5e38\u53ea\u9650\u4e8e\u4e13\u4e1a\u6570\u636e\u5904\u7406\u4eba\u5458\uff08\u5982\u6280\u672f\u5b66\u9662\u6216\u5de5\u7a0b\u5e08\u5b66\u6821\u6bd5\u4e1a\u751f\uff09\uff0c\u800c\u884c\u52a8\u5b66\u4e60\u65e8\u5728\u5411\u6ca1\u6709\u6570\u636e\u5904\u7406\u80fd\u529b\u4f46\u5177\u5907\u4e1a\u52a1\u6d41\u7a0b\u77e5\u8bc6\u7684\u5b66\u5458\u4f20\u6388\u77e5\u8bc6\u548c\u7ecf\u9a8c\uff0c\u4fc3\u8fdb\u5927\u5b66\u4e0e\u4f01\u4e1a\u7684\u5408\u4f5c", "method": "\u91c7\u7528\u884c\u52a8\u5b66\u4e60\u6a21\u5f0f\uff0c\u6559\u5e08\u62c5\u4efb\u9879\u76ee\u7ba1\u7406\u7684\u76d1\u7763\u8005\u89d2\u8272\uff0c\u5728\u4e13\u4e1a\u673a\u6784\u8d44\u52a9\u7684\u5b9e\u9645\u9879\u76ee\u4e2d\u57f9\u8bad\u5b66\u5458\u6570\u636e\u5e93\u8bbe\u8ba1\uff0c\u7ed3\u5408\u6cd5\u56fd\u6280\u672f\u8bfe\u7a0b\u7684\u6a2a\u5411\u5b66\u671f\u9879\u76ee\u7ecf\u9a8c", "result": "\u884c\u52a8\u5b66\u4e60\u6210\u529f\u6574\u5408\u4e86\u6cd5\u56fd\u6280\u672f\u8bfe\u7a0b\u7684\u6210\u529f\u56e0\u7d20\u3001\u804c\u4e1a\u57f9\u8bad\u7684\u9002\u5e94\u6027\u6559\u5b66\u6cd5\u4ee5\u53ca\u670d\u52a1\u63d0\u4f9b\u5546\u7684\u4e13\u4e1a\u80fd\u529b\uff0c\u5b9e\u73b0\u4e86\u53ef\u8bc4\u4f30\u4e14\u6301\u4e45\u7684\u6559\u5b66\u4e0e\u804c\u4e1a\u76ee\u6807", "conclusion": "\u884c\u52a8\u5b66\u4e60\u662f\u6cd5\u56fd\u4fc3\u8fdb\u5927\u5b66\u4e0e\u4f01\u4e1a\u5408\u4f5c\u653f\u7b56\u7684\u4e00\u90e8\u5206\uff0c\u901a\u8fc7\u7ed3\u5408\u4e09\u79cd\u4e92\u8865\u65b9\u6cd5\u7684\u4f18\u52bf\uff0c\u4e3a\u8fd9\u7c7b\u57f9\u8bad\u5b9e\u73b0\u4e86\u6559\u5b66\u4e0e\u804c\u4e1a\u7684\u53cc\u91cd\u76ee\u6807"}}
{"id": "2601.22196", "categories": ["cs.SE", "cs.CR"], "pdf": "https://arxiv.org/pdf/2601.22196", "abs": "https://arxiv.org/abs/2601.22196", "authors": ["Piotr Przymus", "Witold Weiner", "Krzysztof Rykaczewski", "Gunnar Kudrjavets"], "title": "Linux Kernel Recency Matters, CVE Severity Doesn't, and History Fades", "comment": null, "summary": "In 2024, the Linux kernel became its own Common Vulnerabilities and Exposures (CVE) Numbering Authority (CNA), formalizing how kernel vulnerabilities are identified and tracked. We analyze the anatomy and dynamics of kernel CVEs using metadata, associated commits, and patch latency to understand what drives patching. Results show that severity and Common Vulnerability Scoring System (CVSS) metrics have a negligible association with patch latency, whereas kernel recency is a reasonable predictor in survival models. Kernel developers fix newer kernels sooner, while older ones retain unresolved CVEs. Commits introducing vulnerabilities are typically broader and more complex than their fixes, though often only approximate reconstructions of development history. The Linux kernel remains a unique open-source project -- its CVE process is no exception.", "AI": {"tldr": "Linux\u5185\u6838\u6210\u4e3aCNA\u540e\uff0c\u7814\u7a76\u53d1\u73b0\u5185\u6838\u6f0f\u6d1e\u4fee\u590d\u5ef6\u8fdf\u4e0e\u4e25\u91cd\u6027\u8bc4\u5206\u5173\u7cfb\u4e0d\u5927\uff0c\u800c\u4e0e\u5185\u6838\u65b0\u65e7\u7a0b\u5ea6\u76f8\u5173\uff0c\u65b0\u5185\u6838\u4fee\u590d\u66f4\u5feb\uff0c\u65e7\u5185\u6838\u6f0f\u6d1e\u5e38\u672a\u89e3\u51b3\u3002", "motivation": "\u5206\u6790Linux\u5185\u6838\u6210\u4e3aCVE\u7f16\u53f7\u673a\u6784\uff08CNA\uff09\u540e\uff0c\u7814\u7a76\u5185\u6838\u6f0f\u6d1e\u7684\u89e3\u5256\u7ed3\u6784\u548c\u52a8\u6001\u7279\u5f81\uff0c\u7279\u522b\u662f\u4e86\u89e3\u9a71\u52a8\u6f0f\u6d1e\u4fee\u590d\u7684\u56e0\u7d20\uff0c\u4ee5\u7406\u89e3\u5185\u6838\u72ec\u7279\u7684\u5f00\u6e90\u9879\u76ee\u7279\u6027\u3002", "method": "\u4f7f\u7528\u5143\u6570\u636e\u3001\u76f8\u5173\u63d0\u4ea4\u548c\u8865\u4e01\u5ef6\u8fdf\u6765\u5206\u6790\u5185\u6838CVE\uff0c\u91c7\u7528\u751f\u5b58\u6a21\u578b\u7814\u7a76\u4fee\u590d\u65f6\u95f4\u9884\u6d4b\u56e0\u7d20\uff0c\u6bd4\u8f83\u5f15\u5165\u6f0f\u6d1e\u7684\u63d0\u4ea4\u4e0e\u4fee\u590d\u63d0\u4ea4\u7684\u590d\u6742\u6027\u3002", "result": "\u4e25\u91cd\u6027\u548cCVSS\u8bc4\u5206\u4e0e\u8865\u4e01\u5ef6\u8fdf\u5173\u8054\u5fae\u5f31\uff1b\u5185\u6838\u65b0\u65e7\u7a0b\u5ea6\u662f\u5408\u7406\u7684\u9884\u6d4b\u56e0\u5b50\uff0c\u65b0\u5185\u6838\u4fee\u590d\u66f4\u5feb\uff0c\u65e7\u5185\u6838\u4fdd\u7559\u672a\u89e3\u51b3\u7684CVE\uff1b\u5f15\u5165\u6f0f\u6d1e\u7684\u63d0\u4ea4\u901a\u5e38\u6bd4\u4fee\u590d\u66f4\u5e7f\u6cdb\u590d\u6742\u3002", "conclusion": "Linux\u5185\u6838\u7684CVE\u6d41\u7a0b\u5177\u6709\u72ec\u7279\u6027\uff0c\u4fee\u590d\u51b3\u7b56\u66f4\u591a\u57fa\u4e8e\u5185\u6838\u65b0\u65e7\u800c\u975e\u4f20\u7edf\u5b89\u5168\u6307\u6807\uff0c\u53cd\u6620\u4e86\u5185\u6838\u4f5c\u4e3a\u72ec\u7279\u5f00\u6e90\u9879\u76ee\u7684\u7279\u6027\u3002"}}
{"id": "2601.22760", "categories": ["cs.DC", "cs.LG", "cs.PF", "cs.SE"], "pdf": "https://arxiv.org/pdf/2601.22760", "abs": "https://arxiv.org/abs/2601.22760", "authors": ["Zhongzhen Wen", "Shudi Shao", "Zhong Li", "Yu Ge", "Tongtong Xu", "Yuanyi Lin", "Tian Zhang"], "title": "AscendCraft: Automatic Ascend NPU Kernel Generation via DSL-Guided Transcompilation", "comment": null, "summary": "The performance of deep learning models critically depends on efficient kernel implementations, yet developing high-performance kernels for specialized accelerators remains time-consuming and expertise-intensive. While recent work demonstrates that large language models (LLMs) can generate correct and performant GPU kernels, kernel generation for neural processing units (NPUs) remains largely underexplored due to domain-specific programming models, limited public examples, and sparse documentation. Consequently, directly generating AscendC kernels with LLMs yields extremely low correctness, highlighting a substantial gap between GPU and NPU kernel generation.\n  We present AscendCraft, a DSL-guided approach for automatic AscendC kernel generation. AscendCraft introduces a lightweight DSL that abstracts non-essential complexity while explicitly modeling Ascend-specific execution semantics. Kernels are first generated in the DSL using category-specific expert examples and then transcompiled into AscendC through structured, constraint-driven LLM lowering passes. Evaluated on MultiKernelBench across seven operator categories, AscendCraft achieves 98.1% compilation success and 90.4% functional correctness. Moreover, 46.2% of generated kernels match or exceed PyTorch eager execution performance, demonstrating that DSL-guided transcompilation can enable LLMs to generate both correct and competitive NPU kernels. Beyond benchmarks, AscendCraft further demonstrates its generality by successfully generating two correct kernels for newly proposed mHC architecture, achieving performance that substantially surpasses PyTorch eager execution.", "AI": {"tldr": "AscendCraft\uff1a\u4e00\u79cdDSL\u5f15\u5bfc\u7684\u81ea\u52a8AscendC\u5185\u6838\u751f\u6210\u65b9\u6cd5\uff0c\u901a\u8fc7\u8f7b\u91cf\u7ea7DSL\u62bd\u8c61\u590d\u6742\u6027\u548c\u663e\u5f0f\u5efa\u6a21Ascend\u6267\u884c\u8bed\u4e49\uff0c\u5b9e\u73b0\u9ad8\u7f16\u8bd1\u6210\u529f\u7387\u548c\u529f\u80fd\u6b63\u786e\u6027", "motivation": "\u4e3a\u4e13\u7528\u52a0\u901f\u5668\uff08\u7279\u522b\u662fNPU\uff09\u5f00\u53d1\u9ad8\u6027\u80fd\u5185\u6838\u8017\u65f6\u4e14\u9700\u8981\u4e13\u4e1a\u77e5\u8bc6\uff0c\u800c\u73b0\u6709LLM\u65b9\u6cd5\u5728GPU\u4e0a\u6709\u6548\u4f46\u5728NPU\u4e0a\u6548\u679c\u5dee\uff0c\u4e3b\u8981\u7531\u4e8e\u9886\u57df\u7279\u5b9a\u7f16\u7a0b\u6a21\u578b\u3001\u6709\u9650\u516c\u5f00\u793a\u4f8b\u548c\u7a00\u758f\u6587\u6863", "method": "\u5f15\u5165\u8f7b\u91cf\u7ea7DSL\u62bd\u8c61\u975e\u5fc5\u8981\u590d\u6742\u6027\u5e76\u663e\u5f0f\u5efa\u6a21Ascend\u6267\u884c\u8bed\u4e49\uff0c\u4f7f\u7528\u7c7b\u522b\u7279\u5b9a\u4e13\u5bb6\u793a\u4f8b\u5728DSL\u4e2d\u751f\u6210\u5185\u6838\uff0c\u7136\u540e\u901a\u8fc7\u7ed3\u6784\u5316\u3001\u7ea6\u675f\u9a71\u52a8\u7684LLM\u964d\u4f4e\u4f20\u9012\u5c06DSL\u8f6c\u7f16\u8bd1\u4e3aAscendC", "result": "\u5728MultiKernelBench\u7684\u4e03\u4e2a\u7b97\u5b50\u7c7b\u522b\u4e0a\uff0c\u8fbe\u523098.1%\u7684\u7f16\u8bd1\u6210\u529f\u7387\u548c90.4%\u7684\u529f\u80fd\u6b63\u786e\u6027\uff0c46.2%\u7684\u751f\u6210\u5185\u6838\u5339\u914d\u6216\u8d85\u8fc7PyTorch eager\u6267\u884c\u6027\u80fd\uff0c\u5e76\u80fd\u6210\u529f\u4e3a\u65b0\u63d0\u51fa\u7684mHC\u67b6\u6784\u751f\u6210\u6b63\u786e\u5185\u6838", "conclusion": "DSL\u5f15\u5bfc\u7684\u8f6c\u7f16\u8bd1\u65b9\u6cd5\u80fd\u4f7fLLM\u751f\u6210\u65e2\u6b63\u786e\u53c8\u5177\u6709\u7ade\u4e89\u529b\u7684NPU\u5185\u6838\uff0c\u586b\u8865\u4e86GPU\u548cNPU\u5185\u6838\u751f\u6210\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u4e3a\u4e13\u7528\u52a0\u901f\u5668\u7684\u9ad8\u6548\u5185\u6838\u5f00\u53d1\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848"}}
{"id": "2601.22178", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2601.22178", "abs": "https://arxiv.org/abs/2601.22178", "authors": ["Zhenqiang Ye", "Wensheng Gan", "Gengsen Huang", "Tianlong Gu", "Philip S. Yu"], "title": "Discovering High-utility Sequential Rules with Increasing Utility Ratio", "comment": "IEEE Transactions on Big Data", "summary": "Utility-driven mining is an essential task in data science, as it can provide deeper insight into the real world. High-utility sequential rule mining (HUSRM) aims at discovering sequential rules with high utility and high confidence. It can certainly provide reliable information for decision-making because it uses confidence as an evaluation metric, as well as some algorithms like HUSRM and US-Rule. However, in current rule-growth mining methods, the linkage between HUSRs and their generation remains ambiguous. Specifically, it is unclear whether the addition of new items affects the utility or confidence of the former rule, leading to an increase or decrease in their values. Therefore, in this paper, we formulate the problem of mining HUSRs with an increasing utility ratio. To address this, we introduce a novel algorithm called SRIU for discovering all HUSRs with an increasing utility ratio using two distinct expansion methods, including left-right expansion and right-left expansion. SRIU also utilizes the item pair estimated utility pruning strategy (IPEUP) to reduce the search space. Moreover, for the two expansion methods, two sets of upper bounds and corresponding pruning strategies are introduced. To enhance the efficiency of SRIU, several optimizations are incorporated. These include utilizing the Bitmap to reduce memory consumption and designing a compact utility table for the mining procedure. Finally, extensive experimental results from both real-world and synthetic datasets demonstrate the effectiveness of the proposed method. Moreover, to better assess the quality of the generated sequential rules, metrics such as confidence and conviction are employed, which further demonstrate that SRIU can improve the relevance of mining results.", "AI": {"tldr": "\u63d0\u51faSRIU\u7b97\u6cd5\u6316\u6398\u5177\u6709\u9012\u589e\u6548\u7528\u6bd4\u7684\u9ad8\u6548\u7528\u5e8f\u5217\u89c4\u5219\uff0c\u89e3\u51b3\u4f20\u7edf\u65b9\u6cd5\u4e2d\u89c4\u5219\u751f\u6210\u4e0e\u6548\u7528\u53d8\u5316\u5173\u7cfb\u4e0d\u660e\u786e\u7684\u95ee\u9898", "motivation": "\u5f53\u524d\u9ad8\u6548\u7528\u5e8f\u5217\u89c4\u5219\u6316\u6398\u65b9\u6cd5\u4e2d\uff0c\u89c4\u5219\u4e0e\u5176\u751f\u6210\u8fc7\u7a0b\u4e4b\u95f4\u7684\u5173\u8054\u4e0d\u660e\u786e\uff0c\u65e0\u6cd5\u786e\u5b9a\u65b0\u589e\u9879\u5bf9\u89c4\u5219\u6548\u7528\u6216\u7f6e\u4fe1\u5ea6\u7684\u5f71\u54cd\u65b9\u5411\uff0c\u8fd9\u9650\u5236\u4e86\u51b3\u7b56\u652f\u6301\u7684\u53ef\u9760\u6027", "method": "\u63d0\u51faSRIU\u7b97\u6cd5\uff0c\u91c7\u7528\u5de6\u53f3\u6269\u5c55\u548c\u53f3\u5de6\u6269\u5c55\u4e24\u79cd\u65b9\u6cd5\uff0c\u5f15\u5165\u9879\u5bf9\u4f30\u8ba1\u6548\u7528\u526a\u679d\u7b56\u7565(IPEUP)\u51cf\u5c11\u641c\u7d22\u7a7a\u95f4\uff0c\u4f7f\u7528Bitmap\u964d\u4f4e\u5185\u5b58\u6d88\u8017\uff0c\u8bbe\u8ba1\u7d27\u51d1\u6548\u7528\u8868\u4f18\u5316\u6316\u6398\u8fc7\u7a0b", "result": "\u5728\u771f\u5b9e\u548c\u5408\u6210\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660eSRIU\u65b9\u6cd5\u6709\u6548\uff0c\u4f7f\u7528\u7f6e\u4fe1\u5ea6\u548cconviction\u7b49\u6307\u6807\u8bc4\u4f30\u89c4\u5219\u8d28\u91cf\uff0c\u8bc1\u660eSRIU\u80fd\u63d0\u9ad8\u6316\u6398\u7ed3\u679c\u7684\u76f8\u5173\u6027", "conclusion": "SRIU\u7b97\u6cd5\u6210\u529f\u89e3\u51b3\u4e86\u9ad8\u6548\u7528\u5e8f\u5217\u89c4\u5219\u6316\u6398\u4e2d\u89c4\u5219\u751f\u6210\u4e0e\u6548\u7528\u53d8\u5316\u5173\u7cfb\u4e0d\u660e\u786e\u7684\u95ee\u9898\uff0c\u901a\u8fc7\u9012\u589e\u6548\u7528\u6bd4\u7684\u6982\u5ff5\u548c\u591a\u79cd\u4f18\u5316\u7b56\u7565\uff0c\u63d0\u9ad8\u4e86\u6316\u6398\u6548\u7387\u548c\u7ed3\u679c\u8d28\u91cf"}}
{"id": "2601.22208", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.22208", "abs": "https://arxiv.org/abs/2601.22208", "authors": ["Evelien Riddell", "James Riddell", "Gengyi Sun", "Micha\u0142 Antkiewicz", "Krzysztof Czarnecki"], "title": "Stalled, Biased, and Confused: Uncovering Reasoning Failures in LLMs for Cloud-Based Root Cause Analysis", "comment": "FORGE 2026", "summary": "Root cause analysis (RCA) is essential for diagnosing failures within complex software systems to ensure system reliability. The highly distributed and interdependent nature of modern cloud-based systems often complicates RCA efforts, particularly for multi-hop fault propagation, where symptoms appear far from their true causes. Recent advancements in Large Language Models (LLMs) present new opportunities to enhance automated RCA. However, their practical value for RCA depends on the fidelity of reasoning and decision-making. Existing work relies on historical incident corpora, operates directly on high-volume telemetry beyond current LLM capacity, or embeds reasoning inside complex multi-agent pipelines -- conditions that obscure whether failures arise from reasoning itself or from peripheral design choices.\n  We present a focused empirical evaluation that isolates an LLM's reasoning behavior. We design a controlled experimental framework that foregrounds the LLM by using a simplified experimental setting. We evaluate six LLMs under two agentic workflows (ReAct and Plan-and-Execute) and a non-agentic baseline on two real-world case studies (GAIA and OpenRCA). In total, we executed 48,000 simulated failure scenarios, totaling 228 days of execution time. We measure both root-cause accuracy and the quality of intermediate reasoning traces. We produce a labeled taxonomy of 16 common RCA reasoning failures and use an LLM-as-a-Judge for annotation. Our results clarify where current open-source LLMs succeed and fail in multi-hop RCA, quantify sensitivity to input data modalities, and identify reasoning failures that predict final correctness. Together, these contributions provide transparent and reproducible empirical results and a failure taxonomy to guide future work on reasoning-driven system diagnosis.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5bf9LLM\u5728\u6839\u56e0\u5206\u6790\u4e2d\u7684\u63a8\u7406\u80fd\u529b\u8fdb\u884c\u5b9e\u8bc1\u8bc4\u4f30\uff0c\u901a\u8fc7\u63a7\u5236\u5b9e\u9a8c\u6846\u67b6\u8bc4\u4f306\u4e2aLLM\u57282\u79cd\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\u4e0b\u7684\u8868\u73b0\uff0c\u6267\u884c48,000\u4e2a\u6545\u969c\u573a\u666f\uff0c\u8bc6\u522b16\u79cd\u5e38\u89c1\u63a8\u7406\u5931\u8d25\u6a21\u5f0f\u3002", "motivation": "\u73b0\u4ee3\u4e91\u7cfb\u7edf\u7684\u9ad8\u5ea6\u5206\u5e03\u5f0f\u7279\u6027\u4f7f\u591a\u8df3\u6545\u969c\u4f20\u64ad\u7684\u6839\u56e0\u5206\u6790\u53d8\u5f97\u590d\u6742\uff0cLLM\u4e3a\u81ea\u52a8\u5316RCA\u63d0\u4f9b\u4e86\u65b0\u673a\u4f1a\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u5386\u53f2\u4e8b\u4ef6\u8bed\u6599\u5e93\u6216\u590d\u6742\u591a\u667a\u80fd\u4f53\u7ba1\u9053\uff0c\u96be\u4ee5\u533a\u5206\u63a8\u7406\u5931\u8d25\u4e0e\u5916\u56f4\u8bbe\u8ba1\u95ee\u9898\u3002", "method": "\u8bbe\u8ba1\u63a7\u5236\u5b9e\u9a8c\u6846\u67b6\uff0c\u5728\u7b80\u5316\u5b9e\u9a8c\u73af\u5883\u4e2d\u8bc4\u4f306\u4e2aLLM\u5728\u4e24\u79cd\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\uff08ReAct\u548cPlan-and-Execute\uff09\u548c\u975e\u667a\u80fd\u4f53\u57fa\u7ebf\u4e0b\u7684\u8868\u73b0\uff0c\u4f7f\u7528\u4e24\u4e2a\u771f\u5b9e\u6848\u4f8b\u7814\u7a76\uff08GAIA\u548cOpenRCA\uff09\uff0c\u6267\u884c48,000\u4e2a\u6a21\u62df\u6545\u969c\u573a\u666f\uff0c\u901a\u8fc7LLM-as-a-Judge\u6807\u6ce816\u79cd\u5e38\u89c1\u63a8\u7406\u5931\u8d25\u5206\u7c7b\u3002", "result": "\u91cf\u5316\u4e86\u5f53\u524d\u5f00\u6e90LLM\u5728\u591a\u8df3RCA\u4e2d\u7684\u6210\u529f\u4e0e\u5931\u8d25\u60c5\u51b5\uff0c\u6d4b\u91cf\u4e86\u6839\u56e0\u51c6\u786e\u7387\u548c\u4e2d\u95f4\u63a8\u7406\u8f68\u8ff9\u8d28\u91cf\uff0c\u8bc6\u522b\u4e86\u5bf9\u8f93\u5165\u6570\u636e\u6a21\u6001\u7684\u654f\u611f\u6027\uff0c\u53d1\u73b0\u4e86\u80fd\u591f\u9884\u6d4b\u6700\u7ec8\u6b63\u786e\u6027\u7684\u63a8\u7406\u5931\u8d25\u6a21\u5f0f\u3002", "conclusion": "\u7814\u7a76\u63d0\u4f9b\u4e86\u900f\u660e\u53ef\u590d\u73b0\u7684\u5b9e\u8bc1\u7ed3\u679c\u548c\u5931\u8d25\u5206\u7c7b\u6cd5\uff0c\u4e3a\u57fa\u4e8e\u63a8\u7406\u7684\u7cfb\u7edf\u8bca\u65ad\u672a\u6765\u5de5\u4f5c\u63d0\u4f9b\u6307\u5bfc\uff0c\u660e\u786e\u4e86\u5f53\u524dLLM\u5728\u590d\u6742\u6839\u56e0\u5206\u6790\u4e2d\u7684\u80fd\u529b\u8fb9\u754c\u548c\u5c40\u9650\u6027\u3002"}}
{"id": "2601.22963", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2601.22963", "abs": "https://arxiv.org/abs/2601.22963", "authors": ["Kegan Dougal"], "title": "ERA: Epoch-Resolved Arbitration for Duelling Admins in Group Management CRDTs", "comment": "7 pages, 8 figures, submitted to the 13th Workshop on Principles and Practice of Consistency for Distributed Data", "summary": "Conflict-Free Replicated Data Types (CRDTs) are used in a range of fields for their coordination-free replication with strong eventual consistency. By prioritising availability over consistency under partition, nodes accumulate events in different orders, and rely on an associative, commutative and idempotent merge function to present a materialised view of the CRDT. Under some circumstances, the state of the materialised view over time can appear to ''roll back'' previously applied events. When the materialised view is used to manage group permissions such as ones found in instant messaging applications, this can lead to surprising behaviour. This can occur when there are multiple concurrent events, such as in the Duelling Admins problem where two equally permissioned admins concurrently revoke each other's permissions. Who wins? This article argues that a Byzantine admin can exploit concurrency to win the duel. As a result, an external arbiter is required to arbitrate an immutable happens-before relation between concurrent events. Arbitration occurs asynchronously in batches via optional ''epoch events'', preserving availability. This introduces a bounded total order within epochs, and the resulting ''finality'' improves on the level of consistency CRDTs can provide.", "AI": {"tldr": "CRDTs\u5728\u5e76\u53d1\u4e8b\u4ef6\u4e0b\u53ef\u80fd\u51fa\u73b0\u72b6\u6001\"\u56de\u6eda\"\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u6743\u9650\u7ba1\u7406\u573a\u666f\u4e2d\uff0c\u62dc\u5360\u5ead\u7ba1\u7406\u5458\u53ef\u5229\u7528\u5e76\u53d1\u8d62\u5f97\u6743\u9650\u4e89\u593a\uff0c\u9700\u8981\u5f15\u5165\u5f02\u6b65\u4ef2\u88c1\u673a\u5236\u6765\u5efa\u7acb\u4e8b\u4ef6\u987a\u5e8f", "motivation": "CRDTs\u5728\u5f3a\u6700\u7ec8\u4e00\u81f4\u6027\u4e0b\u4f18\u5148\u53ef\u7528\u6027\uff0c\u4f46\u5e76\u53d1\u4e8b\u4ef6\u53ef\u80fd\u5bfc\u81f4\u72b6\u6001\u56de\u6eda\uff0c\u5728\u5373\u65f6\u901a\u8baf\u7b49\u6743\u9650\u7ba1\u7406\u573a\u666f\u4e2d\u4ea7\u751f\u610f\u5916\u884c\u4e3a\uff0c\u5982\"\u51b3\u6597\u7ba1\u7406\u5458\"\u95ee\u9898\u4e2d\u62dc\u5360\u5ead\u7ba1\u7406\u5458\u53ef\u5229\u7528\u5e76\u53d1\u83b7\u80dc", "method": "\u5f15\u5165\u5916\u90e8\u4ef2\u88c1\u5668\u901a\u8fc7\u53ef\u9009\u7684\"\u7eaa\u5143\u4e8b\u4ef6\"\u5f02\u6b65\u6279\u91cf\u4ef2\u88c1\uff0c\u5efa\u7acb\u4e0d\u53ef\u53d8\u7684\u4e8b\u4ef6\u53d1\u751f\u524d\u5173\u7cfb\uff0c\u5728\u7eaa\u5143\u5185\u521b\u5efa\u6709\u754c\u5168\u5e8f\uff0c\u63d0\u4f9b\u6700\u7ec8\u6027\u4fdd\u8bc1", "result": "\u63d0\u51fa\u7684\u4ef2\u88c1\u673a\u5236\u5728\u4fdd\u6301\u53ef\u7528\u6027\u7684\u540c\u65f6\uff0c\u901a\u8fc7\u7eaa\u5143\u4e8b\u4ef6\u5f15\u5165\u6709\u754c\u5168\u5e8f\uff0c\u63d0\u9ad8\u4e86CRDTs\u7684\u4e00\u81f4\u6027\u7ea7\u522b\uff0c\u89e3\u51b3\u4e86\u5e76\u53d1\u4e8b\u4ef6\u5bfc\u81f4\u7684\u6743\u9650\u7ba1\u7406\u95ee\u9898", "conclusion": "CRDTs\u9700\u8981\u4ef2\u88c1\u673a\u5236\u6765\u5904\u7406\u5e76\u53d1\u4e8b\u4ef6\uff0c\u901a\u8fc7\u5f02\u6b65\u7eaa\u5143\u4e8b\u4ef6\u5efa\u7acb\u4e8b\u4ef6\u987a\u5e8f\uff0c\u5728\u4fdd\u6301\u53ef\u7528\u6027\u7684\u540c\u65f6\u63d0\u4f9b\u66f4\u597d\u7684\u6700\u7ec8\u4e00\u81f4\u6027\uff0c\u9632\u6b62\u62dc\u5360\u5ead\u7ba1\u7406\u5458\u5229\u7528\u5e76\u53d1\u83b7\u80dc"}}
{"id": "2601.22179", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2601.22179", "abs": "https://arxiv.org/abs/2601.22179", "authors": ["Chunkai Zhang", "Jiarui Deng", "Maohua Lyu", "Wensheng Gan", "Philip S. Yu"], "title": "High-utility Sequential Rule Mining Utilizing Segmentation Guided by Confidence", "comment": "IEEE TKDE", "summary": "Within the domain of data mining, one critical objective is the discovery of sequential rules with high utility. The goal is to discover sequential rules that exhibit both high utility and strong confidence, which are valuable in real-world applications. However, existing high-utility sequential rule mining algorithms suffer from redundant utility computations, as different rules may consist of the same sequence of items. When these items can form multiple distinct rules, additional utility calculations are required. To address this issue, this study proposes a sequential rule mining algorithm that utilizes segmentation guided by confidence (RSC), which employs confidence-guided segmentation to reduce redundant utility computation. It adopts a method that precomputes the confidence of segmented rules by leveraging the support of candidate subsequences in advance. Once the segmentation point is determined, all rules with different antecedents and consequents are generated simultaneously. RSC uses a utility-linked table to accelerate candidate sequence generation and introduces a stricter utility upper bound, called the reduced remaining utility of a sequence, to address sequences with duplicate items. Finally, the proposed RSC method was evaluated on multiple datasets, and the results demonstrate improvements over state-of-the-art approaches.", "AI": {"tldr": "\u63d0\u51faRSC\u7b97\u6cd5\uff0c\u901a\u8fc7\u7f6e\u4fe1\u5ea6\u5f15\u5bfc\u7684\u5206\u5272\u51cf\u5c11\u9ad8\u6548\u7528\u5e8f\u5217\u89c4\u5219\u6316\u6398\u4e2d\u7684\u5197\u4f59\u6548\u7528\u8ba1\u7b97", "motivation": "\u73b0\u6709\u9ad8\u6548\u7528\u5e8f\u5217\u89c4\u5219\u6316\u6398\u7b97\u6cd5\u5b58\u5728\u5197\u4f59\u6548\u7528\u8ba1\u7b97\u95ee\u9898\uff0c\u4e0d\u540c\u89c4\u5219\u53ef\u80fd\u5305\u542b\u76f8\u540c\u7684\u9879\u76ee\u5e8f\u5217\uff0c\u5f53\u8fd9\u4e9b\u9879\u76ee\u53ef\u4ee5\u5f62\u6210\u591a\u4e2a\u4e0d\u540c\u89c4\u5219\u65f6\u9700\u8981\u91cd\u590d\u8ba1\u7b97\u6548\u7528", "method": "\u91c7\u7528\u7f6e\u4fe1\u5ea6\u5f15\u5bfc\u7684\u5206\u5272\u7b56\u7565\uff0c\u9884\u5148\u8ba1\u7b97\u5206\u5272\u89c4\u5219\u7684\u7f6e\u4fe1\u5ea6\uff0c\u5229\u7528\u6548\u7528\u94fe\u63a5\u8868\u52a0\u901f\u5019\u9009\u5e8f\u5217\u751f\u6210\uff0c\u5f15\u5165\u66f4\u4e25\u683c\u7684\u6548\u7528\u4e0a\u754c\uff08\u5e8f\u5217\u7684\u51cf\u5c11\u5269\u4f59\u6548\u7528\uff09\u5904\u7406\u91cd\u590d\u9879\u76ee", "result": "\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30RSC\u65b9\u6cd5\uff0c\u7ed3\u679c\u663e\u793a\u76f8\u6bd4\u73b0\u6709\u6700\u4f18\u65b9\u6cd5\u6709\u6539\u8fdb", "conclusion": "RSC\u7b97\u6cd5\u901a\u8fc7\u51cf\u5c11\u5197\u4f59\u6548\u7528\u8ba1\u7b97\uff0c\u63d0\u9ad8\u4e86\u9ad8\u6548\u7528\u5e8f\u5217\u89c4\u5219\u6316\u6398\u7684\u6548\u7387"}}
{"id": "2601.22264", "categories": ["cs.SE", "cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.22264", "abs": "https://arxiv.org/abs/2601.22264", "authors": ["Henri A\u00efdasso", "Francis Bordeleau", "Ali Tizghadam"], "title": "Predicting Intermittent Job Failure Categories for Diagnosis Using Few-Shot Fine-Tuned Language Models", "comment": null, "summary": "In principle, Continuous Integration (CI) pipeline failures provide valuable feedback to developers on code-related errors. In practice, however, pipeline jobs often fail intermittently due to non-deterministic tests, network outages, infrastructure failures, resource exhaustion, and other reliability issues. These intermittent (flaky) job failures lead to substantial inefficiencies: wasted computational resources from repeated reruns and significant diagnosis time that distracts developers from core activities and often requires intervention from specialized teams. Prior work has proposed machine learning techniques to detect intermittent failures, but does not address the subsequent diagnosis challenge. To fill this gap, we introduce FlaXifyer, a few-shot learning approach for predicting intermittent job failure categories using pre-trained language models. FlaXifyer requires only job execution logs and achieves 84.3% Macro F1 and 92.0% Top-2 accuracy with just 12 labeled examples per category. We also propose LogSift, an interpretability technique that identifies influential log statements in under one second, reducing review effort by 74.4% while surfacing relevant failure information in 87% of cases. Evaluation on 2,458 job failures from TELUS demonstrates that FlaXifyer and LogSift enable effective automated triage, accelerate failure diagnosis, and pave the way towards the automated resolution of intermittent job failures.", "AI": {"tldr": "FlaXifyer\uff1a\u57fa\u4e8e\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u7684\u5c11\u6837\u672c\u5b66\u4e60\u65b9\u6cd5\uff0c\u7528\u4e8e\u9884\u6d4bCI\u6d41\u6c34\u7ebf\u4e2d\u95f4\u6b47\u6027\u4f5c\u4e1a\u5931\u8d25\u7c7b\u522b\uff0c\u4ec5\u9700\u4f5c\u4e1a\u6267\u884c\u65e5\u5fd7\u548c\u5c11\u91cf\u6807\u6ce8\u6570\u636e\uff0c\u540c\u65f6\u63d0\u51faLogSift\u53ef\u89e3\u91ca\u6027\u6280\u672f\u52a0\u901f\u6545\u969c\u8bca\u65ad\u3002", "motivation": "CI\u6d41\u6c34\u7ebf\u4e2d\u7684\u95f4\u6b47\u6027\uff08flaky\uff09\u4f5c\u4e1a\u5931\u8d25\u5bfc\u81f4\u5927\u91cf\u6548\u7387\u635f\u5931\uff1a\u91cd\u590d\u8fd0\u884c\u6d6a\u8d39\u8ba1\u7b97\u8d44\u6e90\uff0c\u8bca\u65ad\u65f6\u95f4\u5206\u6563\u5f00\u53d1\u8005\u7cbe\u529b\uff0c\u9700\u8981\u4e13\u4e1a\u56e2\u961f\u5e72\u9884\u3002\u73b0\u6709\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u4ec5\u68c0\u6d4b\u95f4\u6b47\u6027\u6545\u969c\uff0c\u672a\u89e3\u51b3\u540e\u7eed\u8bca\u65ad\u6311\u6218\u3002", "method": "\u63d0\u51faFlaXifyer\u5c11\u6837\u672c\u5b66\u4e60\u65b9\u6cd5\uff0c\u5229\u7528\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u57fa\u4e8e\u4f5c\u4e1a\u6267\u884c\u65e5\u5fd7\u9884\u6d4b\u95f4\u6b47\u6027\u4f5c\u4e1a\u5931\u8d25\u7c7b\u522b\uff1b\u540c\u65f6\u63d0\u51faLogSift\u53ef\u89e3\u91ca\u6027\u6280\u672f\uff0c\u5feb\u901f\u8bc6\u522b\u5173\u952e\u65e5\u5fd7\u8bed\u53e5\uff0c\u51cf\u5c11\u4eba\u5de5\u5ba1\u67e5\u5de5\u4f5c\u91cf\u3002", "result": "FlaXifyer\u4ec5\u9700\u6bcf\u7c7b\u522b12\u4e2a\u6807\u6ce8\u6837\u672c\uff0c\u8fbe\u523084.3%\u5b8f\u5e73\u5747F1\u5206\u6570\u548c92.0%Top-2\u51c6\u786e\u7387\uff1bLogSift\u57281\u79d2\u5185\u8bc6\u522b\u5173\u952e\u65e5\u5fd7\u8bed\u53e5\uff0c\u51cf\u5c1174.4%\u5ba1\u67e5\u5de5\u4f5c\u91cf\uff0c\u572887%\u60c5\u51b5\u4e0b\u80fd\u53d1\u73b0\u76f8\u5173\u6545\u969c\u4fe1\u606f\u3002", "conclusion": "FlaXifyer\u548cLogSift\u5b9e\u73b0\u4e86\u6709\u6548\u7684\u81ea\u52a8\u5316\u6545\u969c\u5206\u7c7b\uff0c\u52a0\u901f\u4e86\u6545\u969c\u8bca\u65ad\u8fc7\u7a0b\uff0c\u4e3a\u81ea\u52a8\u5316\u89e3\u51b3\u95f4\u6b47\u6027\u4f5c\u4e1a\u5931\u8d25\u95ee\u9898\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u5728TELUS\u76842,458\u4e2a\u4f5c\u4e1a\u5931\u8d25\u6848\u4f8b\u4e2d\u9a8c\u8bc1\u4e86\u6709\u6548\u6027\u3002"}}
{"id": "2601.22183", "categories": ["cs.DB", "cs.AI", "cs.DS"], "pdf": "https://arxiv.org/pdf/2601.22183", "abs": "https://arxiv.org/abs/2601.22183", "authors": ["Tenindra Abeywickrama", "Muhammad Aamir Cheema", "Sabine Storandt"], "title": "COL-Trees: Efficient Hierarchical Object Search in Road Networks", "comment": "Submitted to Artificial Intelligence (AIJ)", "summary": "Location-based services rely heavily on efficient methods that search for relevant points-of-interest (POIs) near a given location. A k Nearest Neighbor (kNN) query is one such example that finds the k closest POIs from an agent's location. While most existing techniques focus on retrieving nearby POIs for a single agent, these search heuristics do not translate to many other applications. For example, Aggregate k Nearest Neighbor (AkNN) queries require POIs that are close to multiple agents. k Farthest Neighbor (kFN) queries require POIs that are the antithesis of nearest. Such problems naturally benefit from a hierarchical approach, but existing methods rely on Euclidean-based heuristics, which have diminished effectiveness in graphs such as road networks. We propose a novel data structure, COL-Tree (Compacted Object-Landmark Tree), to address this gap by enabling efficient hierarchical graph traversal using a more accurate landmark-based heuristic. We then present query algorithms that utilize COL-Trees to efficiently answer AkNN, kFN, and other queries. In our experiments on real-world and synthetic datasets, we demonstrate that our techniques significantly outperform existing approaches, achieving up to 4 orders of magnitude improvement. Moreover, this comes at a small pre-processing overhead in both theory and practice.", "AI": {"tldr": "\u63d0\u51faCOL-Tree\u6570\u636e\u7ed3\u6784\uff0c\u4f7f\u7528\u5730\u6807\u542f\u53d1\u5f0f\u8fdb\u884c\u5c42\u6b21\u5316\u56fe\u904d\u5386\uff0c\u9ad8\u6548\u89e3\u51b3\u805a\u5408k\u8fd1\u90bb\u3001k\u8fdc\u90bb\u7b49\u67e5\u8be2\u95ee\u9898\uff0c\u6027\u80fd\u63d0\u5347\u8fbe4\u4e2a\u6570\u91cf\u7ea7\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u6b27\u51e0\u91cc\u5f97\u8ddd\u79bb\u7684\u542f\u53d1\u5f0f\u65b9\u6cd5\u5728\u9053\u8def\u7f51\u7edc\u7b49\u56fe\u7ed3\u6784\u4e2d\u6548\u679c\u6709\u9650\uff0c\u65e0\u6cd5\u6709\u6548\u5904\u7406\u805a\u5408k\u8fd1\u90bb\u3001k\u8fdc\u90bb\u7b49\u590d\u6742\u67e5\u8be2\u9700\u6c42\uff0c\u9700\u8981\u66f4\u7cbe\u786e\u7684\u56fe\u904d\u5386\u65b9\u6cd5\u3002", "method": "\u63d0\u51faCOL-Tree\uff08\u538b\u7f29\u5bf9\u8c61-\u5730\u6807\u6811\uff09\u6570\u636e\u7ed3\u6784\uff0c\u5229\u7528\u5730\u6807\u542f\u53d1\u5f0f\u8fdb\u884c\u5c42\u6b21\u5316\u56fe\u904d\u5386\uff0c\u5e76\u57fa\u4e8e\u6b64\u8bbe\u8ba1\u67e5\u8be2\u7b97\u6cd5\u5904\u7406\u805a\u5408k\u8fd1\u90bb\u3001k\u8fdc\u90bb\u7b49\u67e5\u8be2\u3002", "result": "\u5728\u771f\u5b9e\u4e16\u754c\u548c\u5408\u6210\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u6027\u80fd\u63d0\u5347\u9ad8\u8fbe4\u4e2a\u6570\u91cf\u7ea7\uff0c\u4e14\u9884\u5904\u7406\u5f00\u9500\u5728\u7406\u8bba\u548c\u5b9e\u8df5\u4e2d\u90fd\u5f88\u5c0f\u3002", "conclusion": "COL-Tree\u901a\u8fc7\u5730\u6807\u542f\u53d1\u5f0f\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u5c42\u6b21\u5316\u56fe\u904d\u5386\uff0c\u4e3a\u805a\u5408k\u8fd1\u90bb\u3001k\u8fdc\u90bb\u7b49\u590d\u6742\u67e5\u8be2\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5177\u6709\u663e\u8457\u6027\u80fd\u4f18\u52bf\u3002"}}
{"id": "2601.22414", "categories": ["cs.SE", "cs.CR", "cs.HC"], "pdf": "https://arxiv.org/pdf/2601.22414", "abs": "https://arxiv.org/abs/2601.22414", "authors": ["Ibrahim Khalilov", "Chaoran Chen", "Ziang Xiao", "Tianshi Li", "Toby Jia-Jun Li", "Yaxing Yao"], "title": "PriviSense: A Frida-Based Framework for Multi-Sensor Spoofing on Android", "comment": null, "summary": "Mobile apps increasingly rely on real-time sensor and system data to adapt their behavior to user context. While emulators and instrumented builds offer partial solutions, they often fail to support reproducible testing of context-sensitive app behavior on physical devices. We present PriviSense, a Frida-based, on-device toolkit for runtime spoofing of sensor and system signals on rooted Android devices. PriviSense can script and inject time-varying sensor streams (accelerometer, gyroscope, step counter) and system values (battery level, system time, device metadata) into unmodified apps, enabling reproducible on-device experiments without emulators or app rewrites. Our demo validates real-time spoofing on a rooted Android device across five representative sensor-visualization apps. By supporting scriptable and reversible manipulation of these values, PriviSense facilitates testing of app logic, uncovering of context-based behaviors, and privacy-focused analysis. To ensure ethical use, the code is shared upon request with verified researchers.\n  Tool Guide: How to Run PriviSense on Rooted Android https://bit.ly/privisense-guide Demonstration video: https://www.youtube.com/watch?v=4Qwnogcc3pw", "AI": {"tldr": "PriviSense\u662f\u4e00\u4e2a\u57fa\u4e8eFrida\u7684Android\u8bbe\u5907\u5de5\u5177\u5305\uff0c\u53ef\u5728\u5df2root\u7684\u8bbe\u5907\u4e0a\u8fd0\u884c\u65f6\u4f2a\u9020\u4f20\u611f\u5668\u548c\u7cfb\u7edf\u4fe1\u53f7\uff0c\u652f\u6301\u53ef\u91cd\u590d\u7684\u4e0a\u4e0b\u6587\u654f\u611f\u5e94\u7528\u6d4b\u8bd5\u3002", "motivation": "\u79fb\u52a8\u5e94\u7528\u8d8a\u6765\u8d8a\u4f9d\u8d56\u5b9e\u65f6\u4f20\u611f\u5668\u548c\u7cfb\u7edf\u6570\u636e\u6765\u9002\u5e94\u7528\u6237\u4e0a\u4e0b\u6587\uff0c\u4f46\u6a21\u62df\u5668\u548c\u63d2\u6869\u6784\u5efa\u901a\u5e38\u65e0\u6cd5\u5728\u7269\u7406\u8bbe\u5907\u4e0a\u652f\u6301\u53ef\u91cd\u590d\u7684\u4e0a\u4e0b\u6587\u654f\u611f\u5e94\u7528\u884c\u4e3a\u6d4b\u8bd5\u3002", "method": "\u57fa\u4e8eFrida\u5f00\u53d1\uff0c\u5728\u5df2root\u7684Android\u8bbe\u5907\u4e0a\u8fd0\u884c\u65f6\u4f2a\u9020\u4f20\u611f\u5668\u548c\u7cfb\u7edf\u4fe1\u53f7\uff0c\u53ef\u811a\u672c\u5316\u6ce8\u5165\u65f6\u53d8\u4f20\u611f\u5668\u6d41\uff08\u52a0\u901f\u5ea6\u8ba1\u3001\u9640\u87ba\u4eea\u3001\u6b65\u6570\u8ba1\u6570\u5668\uff09\u548c\u7cfb\u7edf\u503c\uff08\u7535\u6c60\u7535\u91cf\u3001\u7cfb\u7edf\u65f6\u95f4\u3001\u8bbe\u5907\u5143\u6570\u636e\uff09\u3002", "result": "\u5728\u5df2root\u7684Android\u8bbe\u5907\u4e0a\u5bf9\u4e94\u4e2a\u4ee3\u8868\u6027\u4f20\u611f\u5668\u53ef\u89c6\u5316\u5e94\u7528\u8fdb\u884c\u4e86\u5b9e\u65f6\u4f2a\u9020\u9a8c\u8bc1\uff0c\u652f\u6301\u811a\u672c\u5316\u548c\u53ef\u9006\u7684\u503c\u64cd\u4f5c\uff0c\u4fbf\u4e8e\u5e94\u7528\u903b\u8f91\u6d4b\u8bd5\u3001\u4e0a\u4e0b\u6587\u884c\u4e3a\u53d1\u73b0\u548c\u9690\u79c1\u5206\u6790\u3002", "conclusion": "PriviSense\u65e0\u9700\u6a21\u62df\u5668\u6216\u5e94\u7528\u91cd\u5199\u5373\u53ef\u5b9e\u73b0\u53ef\u91cd\u590d\u7684\u8bbe\u5907\u4e0a\u5b9e\u9a8c\uff0c\u4e3a\u6d4b\u8bd5\u5e94\u7528\u903b\u8f91\u3001\u53d1\u73b0\u57fa\u4e8e\u4e0a\u4e0b\u6587\u7684\u884c\u4e3a\u548c\u9690\u79c1\u5206\u6790\u63d0\u4f9b\u4e86\u5de5\u5177\u3002\u4e3a\u786e\u4fdd\u9053\u5fb7\u4f7f\u7528\uff0c\u4ee3\u7801\u4ec5\u4e0e\u9a8c\u8bc1\u8fc7\u7684\u7814\u7a76\u4eba\u5458\u5171\u4eab\u3002"}}
{"id": "2601.22590", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.22590", "abs": "https://arxiv.org/abs/2601.22590", "authors": ["Minxing Wang", "Yintong Huo"], "title": "Small is Beautiful: A Practical and Efficient Log Parsing Framework", "comment": "Accepted by FSE'26", "summary": "Log parsing is a fundamental step in log analysis, partitioning raw logs into constant templates and dynamic variables. While recent semantic-based parsers leveraging Large Language Models (LLMs) exhibit superior generalizability over traditional syntax-based methods, their effectiveness is heavily contingent on model scale. This dependency leads to significant performance collapse when employing smaller, more resource-efficient LLMs. Such degradation creates a major barrier to real-world adoption, where data privacy requirements and computational constraints necessitate the use of succinct models. To bridge this gap, we propose EFParser, an unsupervised LLM-based log parser designed to enhance the capabilities of smaller models through systematic architectural innovation. EFParser introduces a dual-cache system with an adaptive updating mechanism that distinguishes between novel patterns and variations of existing templates. This allows the parser to merge redundant templates and rectify prior errors, maintaining cache consistency. Furthermore, a dedicated correction module acts as a gatekeeper, validating and refining every LLM-generated template before caching to prevent error injection. Empirical evaluations on public large-scale datasets demonstrate that EFParser outperforms state-of-the-art baselines by an average of 12.5% across all metrics when running on smaller LLMs, even surpassing some baselines utilizing large-scale models. Despite its additional validation steps, EFParser maintains high computational efficiency, offering a robust and practical solution for real-world log analysis deployment.", "AI": {"tldr": "EFParser\u662f\u4e00\u4e2a\u57fa\u4e8eLLM\u7684\u65e0\u76d1\u7763\u65e5\u5fd7\u89e3\u6790\u5668\uff0c\u901a\u8fc7\u53cc\u7f13\u5b58\u7cfb\u7edf\u548c\u6821\u6b63\u6a21\u5757\u63d0\u5347\u5c0f\u6a21\u578b\u6027\u80fd\uff0c\u5728\u4fdd\u6301\u8ba1\u7b97\u6548\u7387\u7684\u540c\u65f6\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8bed\u4e49\u65e5\u5fd7\u89e3\u6790\u5668\u867d\u7136\u6cdb\u5316\u80fd\u529b\u5f3a\uff0c\u4f46\u4e25\u91cd\u4f9d\u8d56\u6a21\u578b\u89c4\u6a21\uff0c\u5bfc\u81f4\u4f7f\u7528\u5c0f\u6a21\u578b\u65f6\u6027\u80fd\u5927\u5e45\u4e0b\u964d\u3002\u8fd9\u5728\u6570\u636e\u9690\u79c1\u8981\u6c42\u548c\u8ba1\u7b97\u8d44\u6e90\u53d7\u9650\u7684\u5b9e\u9645\u90e8\u7f72\u573a\u666f\u4e2d\u6210\u4e3a\u4e3b\u8981\u969c\u788d\u3002", "method": "\u63d0\u51faEFParser\uff0c\u91c7\u7528\u53cc\u7f13\u5b58\u7cfb\u7edf\uff08\u81ea\u9002\u5e94\u66f4\u65b0\u673a\u5236\u533a\u5206\u65b0\u6a21\u677f\u548c\u73b0\u6709\u6a21\u677f\u53d8\u4f53\uff09\u548c\u4e13\u7528\u6821\u6b63\u6a21\u5757\uff08\u9a8c\u8bc1\u548c\u4f18\u5316LLM\u751f\u6210\u7684\u6a21\u677f\uff09\uff0c\u5728\u4fdd\u6301\u7f13\u5b58\u4e00\u81f4\u6027\u7684\u540c\u65f6\u9632\u6b62\u9519\u8bef\u6ce8\u5165\u3002", "result": "\u5728\u516c\u5f00\u5927\u89c4\u6a21\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cEFParser\u5728\u5c0f\u6a21\u578b\u4e0a\u8fd0\u884c\u65f6\uff0c\u5728\u6240\u6709\u6307\u6807\u4e0a\u5e73\u5747\u4f18\u4e8e\u6700\u5148\u8fdb\u57fa\u7ebf12.5%\uff0c\u751a\u81f3\u8d85\u8fc7\u67d0\u4e9b\u4f7f\u7528\u5927\u6a21\u578b\u7684\u57fa\u7ebf\u65b9\u6cd5\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u8ba1\u7b97\u6548\u7387\u3002", "conclusion": "EFParser\u901a\u8fc7\u7cfb\u7edf\u67b6\u6784\u521b\u65b0\uff0c\u6709\u6548\u63d0\u5347\u4e86\u5c0f\u6a21\u578b\u5728\u65e5\u5fd7\u89e3\u6790\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\uff0c\u4e3a\u5b9e\u9645\u90e8\u7f72\u63d0\u4f9b\u4e86\u9c81\u68d2\u4e14\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5f25\u5408\u4e86\u8bed\u4e49\u89e3\u6790\u5668\u6027\u80fd\u4e0e\u8d44\u6e90\u9700\u6c42\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002"}}
{"id": "2601.22597", "categories": ["cs.SE", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.22597", "abs": "https://arxiv.org/abs/2601.22597", "authors": ["Ryo Fujii", "Makoto Morishita", "Kazuki Yano", "Jun Suzuki"], "title": "TimeMachine-bench: A Benchmark for Evaluating Model Capabilities in Repository-Level Migration Tasks", "comment": "Accepted to EACL 2026 Main, camera-ready", "summary": "With the advancement of automated software engineering, research focus is increasingly shifting toward practical tasks reflecting the day-to-day work of software engineers. Among these tasks, software migration, a critical process of adapting code to evolving environments, has been largely overlooked. In this study, we introduce TimeMachine-bench, a benchmark designed to evaluate software migration in real-world Python projects. Our benchmark consists of GitHub repositories whose tests begin to fail in response to dependency updates. The construction process is fully automated, enabling live updates of the benchmark. Furthermore, we curated a human-verified subset to ensure problem solvability. We evaluated agent-based baselines built on top of 11 models, including both strong open-weight and state-of-the-art LLMs on this verified subset. Our results indicated that, while LLMs show some promise for migration tasks, they continue to face substantial reliability challenges, including spurious solutions that exploit low test coverage and unnecessary edits stemming from suboptimal tool-use strategies. Our dataset and implementation are available at https://github.com/tohoku-nlp/timemachine-bench.", "AI": {"tldr": "TimeMachine-bench\u662f\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30Python\u9879\u76ee\u8f6f\u4ef6\u8fc1\u79fb\u4efb\u52a1\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b\u56e0\u4f9d\u8d56\u66f4\u65b0\u5bfc\u81f4\u6d4b\u8bd5\u5931\u8d25\u7684GitHub\u4ed3\u5e93\uff0c\u5e76\u8bc4\u4f30\u4e8611\u4e2aLLM\u6a21\u578b\u5728\u8fc1\u79fb\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u3002", "motivation": "\u968f\u7740\u81ea\u52a8\u5316\u8f6f\u4ef6\u5de5\u7a0b\u7684\u53d1\u5c55\uff0c\u7814\u7a76\u91cd\u70b9\u6b63\u8f6c\u5411\u53cd\u6620\u8f6f\u4ef6\u5de5\u7a0b\u5e08\u65e5\u5e38\u5de5\u4f5c\u7684\u5b9e\u9645\u4efb\u52a1\u3002\u8f6f\u4ef6\u8fc1\u79fb\u4f5c\u4e3a\u9002\u5e94\u73af\u5883\u53d8\u5316\u7684\u5173\u952e\u8fc7\u7a0b\uff0c\u5728\u7814\u7a76\u4e2d\u88ab\u5ffd\u89c6\uff0c\u9700\u8981\u5efa\u7acb\u8bc4\u4f30\u57fa\u51c6\u3002", "method": "\u6784\u5efa\u4e86TimeMachine-bench\u57fa\u51c6\uff0c\u5305\u542b\u56e0\u4f9d\u8d56\u66f4\u65b0\u5bfc\u81f4\u6d4b\u8bd5\u5931\u8d25\u7684GitHub\u4ed3\u5e93\uff0c\u91c7\u7528\u5168\u81ea\u52a8\u5316\u6784\u5efa\u6d41\u7a0b\u652f\u6301\u5b9e\u65f6\u66f4\u65b0\uff0c\u5e76\u521b\u5efa\u4e86\u4eba\u5de5\u9a8c\u8bc1\u7684\u5b50\u96c6\u786e\u4fdd\u95ee\u9898\u53ef\u89e3\u6027\u3002\u5728\u9a8c\u8bc1\u5b50\u96c6\u4e0a\u8bc4\u4f30\u4e86\u57fa\u4e8e11\u4e2a\u6a21\u578b\uff08\u5305\u62ec\u5f00\u6e90\u548cSOTA LLM\uff09\u7684\u667a\u80fd\u4f53\u57fa\u7ebf\u3002", "result": "LLM\u5728\u8fc1\u79fb\u4efb\u52a1\u4e0a\u663e\u793a\u51fa\u4e00\u5b9a\u6f5c\u529b\uff0c\u4f46\u4ecd\u9762\u4e34\u91cd\u5927\u53ef\u9760\u6027\u6311\u6218\uff1a\u5305\u62ec\u5229\u7528\u4f4e\u6d4b\u8bd5\u8986\u76d6\u7387\u4ea7\u751f\u865a\u5047\u89e3\u51b3\u65b9\u6848\uff0c\u4ee5\u53ca\u7531\u4e8e\u5de5\u5177\u4f7f\u7528\u7b56\u7565\u4e0d\u4f73\u5bfc\u81f4\u7684\u4e0d\u5fc5\u8981\u7f16\u8f91\u3002", "conclusion": "TimeMachine-bench\u4e3a\u8f6f\u4ef6\u8fc1\u79fb\u4efb\u52a1\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u8bc4\u4f30\u57fa\u51c6\uff0c\u63ed\u793a\u4e86LLM\u5728\u8be5\u4efb\u52a1\u4e0a\u7684\u5f53\u524d\u5c40\u9650\u6027\u548c\u6539\u8fdb\u65b9\u5411\uff0c\u76f8\u5173\u6570\u636e\u96c6\u548c\u5b9e\u73b0\u5df2\u5f00\u6e90\u3002"}}
{"id": "2601.22627", "categories": ["cs.SE", "cs.HC"], "pdf": "https://arxiv.org/pdf/2601.22627", "abs": "https://arxiv.org/abs/2601.22627", "authors": ["Yuqing Xiao", "John Grundy", "Anuradha Madugalla", "Elizabeth Manias"], "title": "Elderly HealthMag: Systematic Building and Calibrating a Tool for Identifying and Evaluating Senior User Digital Health Software", "comment": null, "summary": "Digital health (DH) software is increasingly deployed to populations where many end users live with one or more health conditions. Yet, DH software development teams frequently operate using implicit, incorrect assumptions about these users, resulting in products that under-serve the specific requirements imposed by their age and health conditions. Consequently, while software may meet clinical objectives on paper, it often fails to be inclusive during actual user interaction. To address this, we propose \\textbf{\\textit{HealthMag}}, a tool inspired by GenderMag designed to help better elicit, model and evaluate requirements for digital health software. We developed HealthMag through systematic mapping and calibration following the InclusiveMag framework. Furthermore, we integrated this with a calibrated version of an existing AgeMag method to create a dual-lens approach: \\textbf{\\textit{Elderly HealthMag}}, designed to aid requirements, design and evaluation of mHealth software for senior end users. We demonstrate application and utility of Age HealthMag via cognitive walkthroughs in identifying inclusivity biases in current senior user-oriented digital health applications.", "AI": {"tldr": "\u63d0\u51faHealthMag\u5de5\u5177\uff0c\u7528\u4e8e\u6570\u5b57\u5065\u5eb7\u8f6f\u4ef6\u7684\u9700\u6c42\u5efa\u6a21\u548c\u8bc4\u4f30\uff0c\u7279\u522b\u5173\u6ce8\u8001\u5e74\u7528\u6237\u7684\u5305\u5bb9\u6027\u9700\u6c42", "motivation": "\u6570\u5b57\u5065\u5eb7\u8f6f\u4ef6\u5e38\u57fa\u4e8e\u5bf9\u7528\u6237\u5065\u5eb7\u72b6\u51b5\u7684\u9690\u542b\u9519\u8bef\u5047\u8bbe\u5f00\u53d1\uff0c\u5bfc\u81f4\u4ea7\u54c1\u65e0\u6cd5\u6ee1\u8db3\u7279\u5b9a\u5e74\u9f84\u548c\u5065\u5eb7\u72b6\u51b5\u7528\u6237\u7684\u5b9e\u9645\u9700\u6c42\uff0c\u7f3a\u4e4f\u5305\u5bb9\u6027", "method": "\u57fa\u4e8eInclusiveMag\u6846\u67b6\uff0c\u901a\u8fc7\u7cfb\u7edf\u6620\u5c04\u548c\u6821\u51c6\u5f00\u53d1HealthMag\u5de5\u5177\uff0c\u5e76\u4e0eAgeMag\u65b9\u6cd5\u6574\u5408\u5f62\u6210Elderly HealthMag\u53cc\u91cd\u65b9\u6cd5\uff0c\u901a\u8fc7\u8ba4\u77e5\u8d70\u67e5\u6f14\u793a\u5e94\u7528", "result": "\u5f00\u53d1\u4e86HealthMag\u548cElderly HealthMag\u5de5\u5177\uff0c\u80fd\u591f\u8bc6\u522b\u5f53\u524d\u9762\u5411\u8001\u5e74\u7528\u6237\u7684\u6570\u5b57\u5065\u5eb7\u5e94\u7528\u4e2d\u7684\u5305\u5bb9\u6027\u504f\u89c1", "conclusion": "\u63d0\u51fa\u7684\u5de5\u5177\u80fd\u5e2e\u52a9\u6570\u5b57\u5065\u5eb7\u8f6f\u4ef6\u5f00\u53d1\u56e2\u961f\u66f4\u597d\u5730\u83b7\u53d6\u3001\u5efa\u6a21\u548c\u8bc4\u4f30\u7528\u6237\u9700\u6c42\uff0c\u63d0\u9ad8\u8f6f\u4ef6\u5bf9\u7279\u5b9a\u5065\u5eb7\u72b6\u51b5\u548c\u5e74\u9f84\u7528\u6237\u7684\u5305\u5bb9\u6027"}}
{"id": "2601.22667", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.22667", "abs": "https://arxiv.org/abs/2601.22667", "authors": ["Chi Zhang", "Zehan Li", "Ziqian Zhong", "Haibing Ma", "Dan Xiao", "Chen Lin", "Ming Dong"], "title": "From Horizontal Layering to Vertical Integration: A Comparative Study of the AI-Driven Software Development Paradigm", "comment": null, "summary": "This paper examines the organizational implications of Generative AI adoption in software engineering through a multiple-case comparative study. We contrast two development environments: a traditional enterprise (brownfield) and an AI-native startup (greenfield). Our analysis reveals that transitioning from Horizontal Layering (functional specialization) to Vertical Integration (end-to-end ownership) yields 8-fold to 33-fold reductions in resource consumption. We attribute these gains to the emergence of Super Employees, AI-augmented engineers who span traditional role boundaries, and the elimination of inter-functional coordination overhead. Theoretically, we propose Human-AI Collaboration Efficacy as the primary optimization target for engineering organizations, supplanting individual productivity metrics. Our Total Factor Productivity analysis identifies an AI Distortion Effect that diminishes returns to labor scale while amplifying technological leverage. We conclude with managerial strategies for organizational redesign, including the reactivation of idle cognitive bandwidth in senior engineers and the suppression of blind scale expansion.", "AI": {"tldr": "\u751f\u6210\u5f0fAI\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u7684\u5e94\u7528\u5bfc\u81f4\u7ec4\u7ec7\u4ece\u6c34\u5e73\u5206\u5c42\u8f6c\u5411\u5782\u76f4\u6574\u5408\uff0c\u5e26\u67658-33\u500d\u7684\u8d44\u6e90\u6d88\u8017\u51cf\u5c11\uff0c\u4e3b\u8981\u5f97\u76ca\u4e8e\u8d85\u7ea7\u5458\u5de5\u7684\u51fa\u73b0\u548c\u8de8\u804c\u80fd\u534f\u8c03\u5f00\u9500\u7684\u6d88\u9664\u3002", "motivation": "\u7814\u7a76\u751f\u6210\u5f0fAI\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u7684\u7ec4\u7ec7\u5f71\u54cd\uff0c\u901a\u8fc7\u5bf9\u6bd4\u4f20\u7edf\u4f01\u4e1a\uff08\u68d5\u5730\uff09\u548cAI\u539f\u751f\u521d\u521b\u516c\u53f8\uff08\u7eff\u5730\uff09\u4e24\u79cd\u5f00\u53d1\u73af\u5883\uff0c\u63a2\u7d22AI\u5982\u4f55\u6539\u53d8\u5de5\u7a0b\u7ec4\u7ec7\u7ed3\u6784\u3002", "method": "\u91c7\u7528\u591a\u6848\u4f8b\u6bd4\u8f83\u7814\u7a76\uff0c\u5bf9\u6bd4\u5206\u6790\u4f20\u7edf\u4f01\u4e1a\u548cAI\u539f\u751f\u521d\u521b\u516c\u53f8\u7684\u5f00\u53d1\u73af\u5883\uff0c\u4f7f\u7528\u603b\u8981\u7d20\u751f\u4ea7\u7387\u5206\u6790\u6765\u8bc6\u522bAI\u626d\u66f2\u6548\u5e94\u3002", "result": "\u4ece\u6c34\u5e73\u5206\u5c42\u8f6c\u5411\u5782\u76f4\u6574\u5408\u5e26\u67658-33\u500d\u7684\u8d44\u6e90\u6d88\u8017\u51cf\u5c11\uff1b\u53d1\u73b0\u8d85\u7ea7\u5458\u5de5\u73b0\u8c61\uff08AI\u589e\u5f3a\u5de5\u7a0b\u5e08\u8de8\u8d8a\u4f20\u7edf\u89d2\u8272\u8fb9\u754c\uff09\uff1b\u8bc6\u522b\u51faAI\u626d\u66f2\u6548\u5e94\uff0c\u51cf\u5c11\u52b3\u52a8\u529b\u89c4\u6a21\u56de\u62a5\u540c\u65f6\u653e\u5927\u6280\u672f\u6760\u6746\u3002", "conclusion": "\u63d0\u51fa\u4eba\u673a\u534f\u4f5c\u6548\u80fd\u5e94\u6210\u4e3a\u5de5\u7a0b\u7ec4\u7ec7\u7684\u4e3b\u8981\u4f18\u5316\u76ee\u6807\uff0c\u53d6\u4ee3\u4e2a\u4eba\u751f\u4ea7\u529b\u6307\u6807\uff1b\u4e3a\u7ec4\u7ec7\u91cd\u65b0\u8bbe\u8ba1\u63d0\u4f9b\u7ba1\u7406\u7b56\u7565\uff0c\u5305\u62ec\u91cd\u65b0\u6fc0\u6d3b\u9ad8\u7ea7\u5de5\u7a0b\u5e08\u7684\u95f2\u7f6e\u8ba4\u77e5\u5e26\u5bbd\u548c\u6291\u5236\u76f2\u76ee\u89c4\u6a21\u6269\u5f20\u3002"}}
{"id": "2601.22676", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.22676", "abs": "https://arxiv.org/abs/2601.22676", "authors": ["Jinrui Sun", "Tong Jia", "Minghua He", "Ying Li"], "title": "VarParser: Unleashing the Neglected Power of Variables for LLM-based Log Parsing", "comment": "12 pages, 9 figures, Accepted in TheWebConf 2026", "summary": "Logs serve as a primary source of information for engineers to diagnose failures in large-scale online service systems. Log parsing, which extracts structured events from massive unstructured log data, is a critical first step for downstream tasks like anomaly detection and failure diagnosis. With advances in large language models (LLMs), leveraging their strong text understanding capabilities has proven effective for accurate log parsing. However, existing LLM-based log parsers all focus on the constant part of logs, ignoring the potential contribution of the variable part to log parsing. This constant-centric strategy brings four key problems. First, inefficient log grouping and sampling with only constant information. Second, a relatively large number of LLM invocations due to constant-based cache, leading to low log parsing accuracy and efficiency. Third, a relatively large number of consumed constant tokens in prompts leads to high LLM invocation costs. At last, these methods only retain placeholders in the results, losing the system visibility brought by variable information in logs.\n  Facing these problems, we propose a variable-centric log parsing strategy named VarParser. Through variable contribution sampling, variable-centric parsing cache, and adaptive variable-aware in-context learning, our approach can efficiently capture the variable parts of logs and leverage their contributions to parsing. By introducing variable units, we preserve rich variable information, enhancing the integrity of log parsing results. Extensive evaluations on large-scale datasets demonstrate that VarParser achieves higher accuracy compared to existing methods, significantly improving parsing efficiency while reducing the LLM invocation costs.", "AI": {"tldr": "VarParser\u63d0\u51fa\u4e86\u4e00\u79cd\u4ee5\u53d8\u91cf\u4e3a\u4e2d\u5fc3\u7684\u65e5\u5fd7\u89e3\u6790\u7b56\u7565\uff0c\u901a\u8fc7\u5229\u7528\u65e5\u5fd7\u4e2d\u7684\u53d8\u91cf\u90e8\u5206\u63d0\u5347\u89e3\u6790\u51c6\u786e\u6027\u548c\u6548\u7387\uff0c\u76f8\u6bd4\u73b0\u6709\u4ec5\u5173\u6ce8\u5e38\u91cf\u90e8\u5206\u7684\u65b9\u6cd5\u6709\u663e\u8457\u6539\u8fdb\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u65e5\u5fd7\u89e3\u6790\u5668\u90fd\u53ea\u5173\u6ce8\u65e5\u5fd7\u7684\u5e38\u91cf\u90e8\u5206\uff0c\u5ffd\u7565\u4e86\u53d8\u91cf\u90e8\u5206\u5bf9\u65e5\u5fd7\u89e3\u6790\u7684\u6f5c\u5728\u8d21\u732e\u3002\u8fd9\u79cd\u5e38\u91cf\u4e2d\u5fc3\u7b56\u7565\u5e26\u6765\u4e86\u56db\u4e2a\u5173\u952e\u95ee\u9898\uff1a1\uff09\u4ec5\u4f7f\u7528\u5e38\u91cf\u4fe1\u606f\u7684\u4f4e\u6548\u65e5\u5fd7\u5206\u7ec4\u548c\u91c7\u6837\uff1b2\uff09\u57fa\u4e8e\u5e38\u91cf\u7684\u7f13\u5b58\u5bfc\u81f4\u5927\u91cfLLM\u8c03\u7528\uff0c\u964d\u4f4e\u89e3\u6790\u51c6\u786e\u6027\u548c\u6548\u7387\uff1b3\uff09\u63d0\u793a\u4e2d\u6d88\u8017\u5927\u91cf\u5e38\u91cftoken\u5bfc\u81f4\u9ad8\u8c03\u7528\u6210\u672c\uff1b4\uff09\u7ed3\u679c\u4e2d\u53ea\u4fdd\u7559\u5360\u4f4d\u7b26\uff0c\u4e22\u5931\u4e86\u65e5\u5fd7\u4e2d\u53d8\u91cf\u4fe1\u606f\u5e26\u6765\u7684\u7cfb\u7edf\u53ef\u89c1\u6027\u3002", "method": "\u63d0\u51faVarParser\u53d8\u91cf\u4e2d\u5fc3\u65e5\u5fd7\u89e3\u6790\u7b56\u7565\uff0c\u5305\u542b\u4e09\u4e2a\u6838\u5fc3\u6280\u672f\uff1a1\uff09\u53d8\u91cf\u8d21\u732e\u91c7\u6837 - \u9ad8\u6548\u6355\u83b7\u65e5\u5fd7\u7684\u53d8\u91cf\u90e8\u5206\uff1b2\uff09\u53d8\u91cf\u4e2d\u5fc3\u89e3\u6790\u7f13\u5b58 - \u51cf\u5c11LLM\u8c03\u7528\u6b21\u6570\uff1b3\uff09\u81ea\u9002\u5e94\u53d8\u91cf\u611f\u77e5\u4e0a\u4e0b\u6587\u5b66\u4e60\u3002\u901a\u8fc7\u5f15\u5165\u53d8\u91cf\u5355\u5143\uff0c\u4fdd\u7559\u4e30\u5bcc\u7684\u53d8\u91cf\u4fe1\u606f\uff0c\u589e\u5f3a\u65e5\u5fd7\u89e3\u6790\u7ed3\u679c\u7684\u5b8c\u6574\u6027\u3002", "result": "\u5728\u5927\u89c4\u6a21\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u8bc4\u4f30\u8868\u660e\uff0cVarParser\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u51c6\u786e\u6027\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u89e3\u6790\u6548\u7387\uff0c\u540c\u65f6\u964d\u4f4e\u4e86LLM\u8c03\u7528\u6210\u672c\u3002", "conclusion": "VarParser\u901a\u8fc7\u5229\u7528\u65e5\u5fd7\u4e2d\u7684\u53d8\u91cf\u90e8\u5206\uff0c\u89e3\u51b3\u4e86\u73b0\u6709LLM-based\u65e5\u5fd7\u89e3\u6790\u5668\u7684\u5c40\u9650\u6027\uff0c\u5728\u51c6\u786e\u6027\u3001\u6548\u7387\u548c\u6210\u672c\u65b9\u9762\u90fd\u6709\u663e\u8457\u63d0\u5347\uff0c\u4e3a\u4e0b\u6e38\u4efb\u52a1\u5982\u5f02\u5e38\u68c0\u6d4b\u548c\u6545\u969c\u8bca\u65ad\u63d0\u4f9b\u4e86\u66f4\u5b8c\u6574\u7684\u65e5\u5fd7\u89e3\u6790\u7ed3\u679c\u3002"}}
{"id": "2601.22748", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.22748", "abs": "https://arxiv.org/abs/2601.22748", "authors": ["You Lu", "Jiyang Zhang", "Bihuan Chen", "Chaofeng Sha", "Dingji Wang", "Xin Peng"], "title": "AutoMerge: Search-Based Model Merging Framework for Effective Model Reuse", "comment": null, "summary": "Software reuse has long been recognized as a critical and widely studied topic in software engineering, offering substantial benefits in reducing development costs, improving software quality, and enhancing operational efficiency. This paradigm extends into deep learning through model reuse. Recently, model merging has emerged in the domain of large language models (LLMs) as a training-free approach that takes multiple task-specific models with the same architecture as source models and merges them without retraining, enhancing model reuse within LLMs. However, no prior work has systematically investigated whether such an approach can be effectively applied to other deep learning models with different architectures across domains. To bridge this gap, we present the first systematic study that evaluates five model merging techniques on three distinct model architectures across three domains: LLMs, image classification, and autonomous driving. Our findings reveal that directly applying existing model merging techniques leads to highly inconsistent results and falls notably short of their success within LLMs. Moreover, a single model merging technique often fails to handle the heterogeneous structural properties within a model, limiting its applicability to different model architectures across domains. Furthermore, the effectiveness of model merging techniques is highly sensitive to hyperparameter configurations, thereby constraining their potential for broader adoption. Inspired by these insights, we propose AutoMerge, a novel search-based model merging framework that first segments complex models into multiple heterogeneous blocks and then systematically explores the merging space to identify the merging technique and its hyperparameter configuration.", "AI": {"tldr": "\u8bba\u6587\u9996\u6b21\u7cfb\u7edf\u7814\u7a76\u4e86\u6a21\u578b\u5408\u5e76\u6280\u672f\u5728\u4e0d\u540c\u67b6\u6784\u548c\u9886\u57df\u7684\u9002\u7528\u6027\uff0c\u53d1\u73b0\u73b0\u6709\u65b9\u6cd5\u6548\u679c\u4e0d\u4e00\u81f4\u4e14\u5bf9\u8d85\u53c2\u6570\u654f\u611f\uff0c\u63d0\u51fa\u4e86AutoMerge\u6846\u67b6\u6765\u4f18\u5316\u5408\u5e76\u8fc7\u7a0b\u3002", "motivation": "\u8f6f\u4ef6\u590d\u7528\u662f\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u7684\u91cd\u8981\u8bdd\u9898\uff0c\u6a21\u578b\u5408\u5e76\u4f5c\u4e3a\u514d\u8bad\u7ec3\u65b9\u6cd5\u5728LLMs\u4e2d\u53d6\u5f97\u6210\u529f\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u5176\u4ed6\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u67b6\u6784\u548c\u9886\u57df\u7684\u7cfb\u7edf\u6027\u7814\u7a76\u3002", "method": "\u7cfb\u7edf\u8bc4\u4f30\u4e865\u79cd\u6a21\u578b\u5408\u5e76\u6280\u672f\u57283\u79cd\u4e0d\u540c\u67b6\u6784\uff08LLMs\u3001\u56fe\u50cf\u5206\u7c7b\u3001\u81ea\u52a8\u9a7e\u9a76\uff09\u4e0a\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u73b0\u6709\u65b9\u6cd5\u6548\u679c\u4e0d\u4f73\uff0c\u63d0\u51fa\u4e86AutoMerge\u6846\u67b6\uff1a\u5148\u5c06\u590d\u6742\u6a21\u578b\u5206\u5272\u4e3a\u5f02\u6784\u5757\uff0c\u7136\u540e\u7cfb\u7edf\u63a2\u7d22\u5408\u5e76\u7a7a\u95f4\u5bfb\u627e\u6700\u4f18\u5408\u5e76\u6280\u672f\u548c\u8d85\u53c2\u6570\u914d\u7f6e\u3002", "result": "\u73b0\u6709\u6a21\u578b\u5408\u5e76\u6280\u672f\u5728\u4e0d\u540c\u67b6\u6784\u548c\u9886\u57df\u6548\u679c\u9ad8\u5ea6\u4e0d\u4e00\u81f4\uff0c\u8fdc\u4e0d\u5982\u5728LLMs\u4e2d\u7684\u6210\u529f\uff1b\u5355\u4e2a\u5408\u5e76\u6280\u672f\u96be\u4ee5\u5904\u7406\u6a21\u578b\u5185\u7684\u5f02\u6784\u7ed3\u6784\u7279\u6027\uff1b\u5408\u5e76\u6548\u679c\u5bf9\u8d85\u53c2\u6570\u914d\u7f6e\u9ad8\u5ea6\u654f\u611f\u3002", "conclusion": "\u6a21\u578b\u5408\u5e76\u6280\u672f\u4e0d\u80fd\u76f4\u63a5\u8de8\u67b6\u6784\u548c\u9886\u57df\u5e94\u7528\uff0c\u9700\u8981\u66f4\u7cfb\u7edf\u7684\u65b9\u6cd5\u3002AutoMerge\u6846\u67b6\u901a\u8fc7\u5206\u5272\u548c\u641c\u7d22\u7b56\u7565\u80fd\u591f\u6709\u6548\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u63d0\u5347\u6a21\u578b\u5408\u5e76\u7684\u9002\u7528\u6027\u548c\u6548\u679c\u3002"}}
{"id": "2601.22773", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.22773", "abs": "https://arxiv.org/abs/2601.22773", "authors": ["Sung Une Lee", "Liming Zhu", "Md Shamsujjoha", "Liming Dong", "Qinghua Lu", "Jieshan Chen"], "title": "Constructing Safety Cases for AI Systems: A Reusable Template Framework", "comment": "41 pages, 8 figures, 8 tables", "summary": "Safety cases, structured arguments that a system is acceptably safe, are becoming central to the governance of AI systems. Yet, traditional safety-case practices from aviation or nuclear engineering rely on well-specified system boundaries, stable architectures, and known failure modes. Modern AI systems such as generative and agentic AI are the opposite. Their capabilities emerge unpredictably from low-level training objectives, their behaviour varies with prompts, and their risk profiles shift through fine-tuning, scaffolding, or deployment context. This study examines how safety cases are currently constructed for AI systems and why classical approaches fail to capture these dynamics. It then proposes a framework of reusable safety-case templates, each following a predefined structure of claims, arguments, and evidence tailored for AI systems. The framework introduces comprehensive taxonomies for AI-specific claim types (assertion-based, constrained-based, capability-based), argument types (demonstrative, comparative, causal/explanatory, risk-based, and normative), and evidence families (empirical, mechanistic, comparative, expert-driven, formal methods, operational/field data, and model-based). Each template is illustrated through end-to-end patterns addressing distinctive challenges such as evaluation without ground truth, dynamic model updates, and threshold-based risk decisions. The result is a systematic, composable, and reusable approach to constructing and maintaining safety cases that are credible, auditable, and adaptive to the evolving behaviour of generative and frontier AI systems.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u9488\u5bf9AI\u7cfb\u7edf\u7684\u53ef\u590d\u7528\u5b89\u5168\u6848\u4f8b\u6a21\u677f\u6846\u67b6\uff0c\u89e3\u51b3\u4f20\u7edf\u5b89\u5168\u6848\u4f8b\u65b9\u6cd5\u4e0d\u9002\u7528\u4e8e\u751f\u6210\u5f0f\u548c\u667a\u80fd\u4f53AI\u52a8\u6001\u7279\u6027\u7684\u95ee\u9898\u3002", "motivation": "\u4f20\u7edf\u5b89\u5168\u6848\u4f8b\u65b9\u6cd5\uff08\u6765\u81ea\u822a\u7a7a\u3001\u6838\u5de5\u7a0b\uff09\u4f9d\u8d56\u660e\u786e\u7684\u7cfb\u7edf\u8fb9\u754c\u3001\u7a33\u5b9a\u67b6\u6784\u548c\u5df2\u77e5\u6545\u969c\u6a21\u5f0f\uff0c\u800c\u73b0\u4ee3AI\u7cfb\u7edf\uff08\u751f\u6210\u5f0f\u3001\u667a\u80fd\u4f53AI\uff09\u5177\u6709\u80fd\u529b\u4e0d\u53ef\u9884\u6d4b\u3001\u884c\u4e3a\u968f\u63d0\u793a\u53d8\u5316\u3001\u98ce\u9669\u968f\u5fae\u8c03/\u90e8\u7f72\u73af\u5883\u52a8\u6001\u53d8\u5316\u7b49\u7279\u70b9\uff0c\u9700\u8981\u65b0\u7684\u5b89\u5168\u6848\u4f8b\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u53ef\u590d\u7528\u5b89\u5168\u6848\u4f8b\u6a21\u677f\u6846\u67b6\uff0c\u5305\u542bAI\u7279\u5b9a\u7684\u58f0\u660e\u5206\u7c7b\uff08\u57fa\u4e8e\u65ad\u8a00\u3001\u7ea6\u675f\u3001\u80fd\u529b\uff09\u3001\u8bba\u8bc1\u7c7b\u578b\uff08\u6f14\u793a\u6027\u3001\u6bd4\u8f83\u6027\u3001\u56e0\u679c/\u89e3\u91ca\u6027\u3001\u57fa\u4e8e\u98ce\u9669\u3001\u89c4\u8303\u6027\uff09\u548c\u8bc1\u636e\u5bb6\u65cf\uff08\u7ecf\u9a8c\u6027\u3001\u673a\u5236\u6027\u3001\u6bd4\u8f83\u6027\u3001\u4e13\u5bb6\u9a71\u52a8\u3001\u5f62\u5f0f\u5316\u65b9\u6cd5\u3001\u64cd\u4f5c/\u73b0\u573a\u6570\u636e\u3001\u57fa\u4e8e\u6a21\u578b\uff09\u3002\u6bcf\u4e2a\u6a21\u677f\u91c7\u7528\u9884\u5b9a\u4e49\u7ed3\u6784\uff08\u58f0\u660e\u3001\u8bba\u8bc1\u3001\u8bc1\u636e\uff09\uff0c\u9488\u5bf9\u7279\u5b9a\u6311\u6218\uff08\u5982\u65e0\u771f\u5b9e\u6807\u7b7e\u8bc4\u4f30\u3001\u52a8\u6001\u6a21\u578b\u66f4\u65b0\u3001\u57fa\u4e8e\u9608\u503c\u7684\u98ce\u9669\u51b3\u7b56\uff09\u63d0\u4f9b\u7aef\u5230\u7aef\u6a21\u5f0f\u3002", "result": "\u5efa\u7acb\u4e86\u4e00\u4e2a\u7cfb\u7edf\u5316\u3001\u53ef\u7ec4\u5408\u3001\u53ef\u590d\u7528\u7684\u5b89\u5168\u6848\u4f8b\u6784\u5efa\u548c\u7ef4\u62a4\u65b9\u6cd5\uff0c\u4f7f\u5b89\u5168\u6848\u4f8b\u5bf9\u751f\u6210\u5f0f\u548c\u524d\u6cbfAI\u7cfb\u7edf\u5177\u6709\u53ef\u4fe1\u6027\u3001\u53ef\u5ba1\u8ba1\u6027\u548c\u9002\u5e94\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3aAI\u7cfb\u7edf\u5b89\u5168\u6848\u4f8b\u63d0\u4f9b\u4e86\u7ed3\u6784\u5316\u65b9\u6cd5\uff0c\u80fd\u591f\u5e94\u5bf9AI\u7cfb\u7edf\u7684\u52a8\u6001\u7279\u6027\u548c\u65b0\u5174\u98ce\u9669\uff0c\u652f\u6301\u53ef\u4fe1\u3001\u53ef\u5ba1\u8ba1\u4e14\u9002\u5e94AI\u884c\u4e3a\u6f14\u5316\u7684\u5b89\u5168\u8bba\u8bc1\u3002"}}
{"id": "2601.22791", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.22791", "abs": "https://arxiv.org/abs/2601.22791", "authors": ["Sabinakhon Akbarova", "Felix Dobslaw", "Robert Feldt"], "title": "Understanding on the Edge: LLM-generated Boundary Test Explanations", "comment": "This is the author's accepted manuscript of a paper accepted for publication at AST 2026. The final version will appear in the ACM Digital Library", "summary": "Boundary value analysis and testing (BVT) is fundamental in software quality assurance because faults tend to cluster at input extremes, yet testers often struggle to understand and justify why certain input-output pairs represent meaningful behavioral boundaries. Large Language Models (LLMs) could help by producing natural-language rationales, but their value for BVT has not been empirically assessed. We therefore conducted an exploratory study on LLM-generated boundary explanations: in a survey, twenty-seven software professionals rated GPT-4.1 explanations for twenty boundary pairs on clarity, correctness, completeness and perceived usefulness, and six of them elaborated in follow-up interviews. Overall, 63.5% of all ratings were positive (4-5 on a five-point Likert scale) compared to 17% negative (1-2), indicating general agreement but also variability in perceptions. Participants favored explanations that followed a clear structure, cited authoritative sources, and adapted their depth to the reader's expertise; they also stressed the need for actionable examples to support debugging and documentation. From these insights, we distilled a seven-item requirement checklist that defines concrete design criteria for future LLM-based boundary explanation tools. The results suggest that, with further refinement, LLM-based tools can support testing workflows by making boundary explanations more actionable and trustworthy.", "AI": {"tldr": "\u7814\u7a76\u8bc4\u4f30\u4e86GPT-4.1\u751f\u6210\u7684\u8fb9\u754c\u503c\u5206\u6790\u89e3\u91ca\u7684\u8d28\u91cf\u548c\u5b9e\u7528\u6027\uff0c\u901a\u8fc727\u540d\u8f6f\u4ef6\u4e13\u4e1a\u4eba\u5458\u5bf920\u4e2a\u8fb9\u754c\u5bf9\u7684\u89e3\u91ca\u8fdb\u884c\u8bc4\u5206\uff0c\u53d1\u73b063.5%\u7684\u8bc4\u5206\u662f\u79ef\u6781\u7684\uff0c\u4f46\u53c2\u4e0e\u8005\u671f\u671b\u66f4\u7ed3\u6784\u5316\u3001\u6709\u6743\u5a01\u6765\u6e90\u652f\u6301\u4e14\u5305\u542b\u53ef\u64cd\u4f5c\u793a\u4f8b\u7684\u89e3\u91ca\u3002", "motivation": "\u8fb9\u754c\u503c\u5206\u6790\u5728\u8f6f\u4ef6\u8d28\u91cf\u4fdd\u8bc1\u4e2d\u5f88\u91cd\u8981\uff0c\u4f46\u6d4b\u8bd5\u4eba\u5458\u5e38\u5e38\u96be\u4ee5\u7406\u89e3\u548c\u8bc1\u660e\u67d0\u4e9b\u8f93\u5165-\u8f93\u51fa\u5bf9\u4e3a\u4f55\u4ee3\u8868\u6709\u610f\u4e49\u7684\u884c\u4e3a\u8fb9\u754c\u3002\u867d\u7136\u5927\u8bed\u8a00\u6a21\u578b\u53ef\u4ee5\u751f\u6210\u81ea\u7136\u8bed\u8a00\u89e3\u91ca\uff0c\u4f46\u5176\u5728\u8fb9\u754c\u503c\u5206\u6790\u4e2d\u7684\u4ef7\u503c\u5c1a\u672a\u7ecf\u8fc7\u5b9e\u8bc1\u8bc4\u4f30\u3002", "method": "\u8fdb\u884c\u63a2\u7d22\u6027\u7814\u7a76\uff1a\u8ba927\u540d\u8f6f\u4ef6\u4e13\u4e1a\u4eba\u5458\u5bf9GPT-4.1\u4e3a20\u4e2a\u8fb9\u754c\u5bf9\u751f\u6210\u7684\u89e3\u91ca\u8fdb\u884c\u8bc4\u5206\uff08\u6e05\u6670\u5ea6\u3001\u6b63\u786e\u6027\u3001\u5b8c\u6574\u6027\u548c\u611f\u77e5\u6709\u7528\u6027\uff09\uff0c\u5e76\u5bf9\u5176\u4e2d6\u4eba\u8fdb\u884c\u540e\u7eed\u8bbf\u8c08\u3002", "result": "63.5%\u7684\u8bc4\u5206\u662f\u79ef\u6781\u7684\uff085\u5206\u5236\u4e2d\u76844-5\u5206\uff09\uff0c17%\u662f\u6d88\u6781\u7684\uff081-2\u5206\uff09\u3002\u53c2\u4e0e\u8005\u504f\u597d\u7ed3\u6784\u6e05\u6670\u3001\u5f15\u7528\u6743\u5a01\u6765\u6e90\u3001\u6839\u636e\u8bfb\u8005\u4e13\u4e1a\u77e5\u8bc6\u8c03\u6574\u6df1\u5ea6\u7684\u89e3\u91ca\uff0c\u5e76\u5f3a\u8c03\u9700\u8981\u652f\u6301\u8c03\u8bd5\u548c\u6587\u6863\u7684\u53ef\u64cd\u4f5c\u793a\u4f8b\u3002", "conclusion": "\u7814\u7a76\u63d0\u70bc\u4e86\u4e00\u4e2a\u5305\u542b7\u9879\u8981\u6c42\u7684\u68c0\u67e5\u6e05\u5355\uff0c\u4e3a\u672a\u6765\u57fa\u4e8eLLM\u7684\u8fb9\u754c\u89e3\u91ca\u5de5\u5177\u5b9a\u4e49\u4e86\u5177\u4f53\u8bbe\u8ba1\u6807\u51c6\u3002\u7ed3\u679c\u8868\u660e\uff0c\u7ecf\u8fc7\u8fdb\u4e00\u6b65\u6539\u8fdb\uff0c\u57fa\u4e8eLLM\u7684\u5de5\u5177\u53ef\u4ee5\u901a\u8fc7\u4f7f\u8fb9\u754c\u89e3\u91ca\u66f4\u5177\u53ef\u64cd\u4f5c\u6027\u548c\u53ef\u4fe1\u5ea6\u6765\u652f\u6301\u6d4b\u8bd5\u5de5\u4f5c\u6d41\u7a0b\u3002"}}
{"id": "2601.22832", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.22832", "abs": "https://arxiv.org/abs/2601.22832", "authors": ["Matthew Becker", "Yifei Chen", "Nicholas Cochran", "Pouyan Ghasemi", "Abhishek Gulati", "Mark Harman", "Zachary Haluza", "Mehrdad Honarkhah", "Herve Robert", "Jiacheng Liu", "Weini Liu", "Sreeja Thummala", "Xiaoning Yang", "Rui Xin", "Sophie Zeng"], "title": "Just-in-Time Catching Test Generation at Meta", "comment": "Submitted to FSE 2026 industry track", "summary": "We report on Just-in-Time catching test generation at Meta, designed to prevent bugs in large scale backend systems of hundreds of millions of line of code. Unlike traditional hardening tests, which pass at generation time, catching tests are meant to fail, surfacing bugs before code lands. The primary challenge is to reduce development drag from false positive test failures. Analyzing 22,126 generated tests, we show code-change-aware methods improve candidate catch generation 4x over hardening tests and 20x over coincidentally failing tests. To address false positives, we use rule-based and LLM-based assessors. These assessors reduce human review load by 70%. Inferential statistical analysis showed that human-accepted code changes are assessed to have significantly more false positives, while human-rejected changes have significantly more true positives. We reported 41 candidate catches to engineers; 8 were confirmed to be true positives, 4 of which would have led to serious failures had they remained uncaught. Overall, our results show that Just-in-Time catching is scalable, industrially applicable, and that it prevents serious failures from reaching production.", "AI": {"tldr": "Meta\u5f00\u53d1\u4e86\u5373\u65f6\u6355\u83b7\u6d4b\u8bd5\u751f\u6210\u7cfb\u7edf\uff0c\u65e8\u5728\u9632\u6b62\u5927\u89c4\u6a21\u540e\u7aef\u7cfb\u7edf\u4e2d\u7684bug\uff0c\u901a\u8fc7\u751f\u6210\u9884\u671f\u4f1a\u5931\u8d25\u7684\u6d4b\u8bd5\u6765\u5728\u4ee3\u7801\u5408\u5e76\u524d\u53d1\u73b0\u95ee\u9898\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u5047\u9633\u6027\u5e76\u6210\u529f\u6355\u83b7\u4e86\u4e25\u91cdbug\u3002", "motivation": "\u4f20\u7edf\u5f3a\u5316\u6d4b\u8bd5\u5728\u751f\u6210\u65f6\u901a\u8fc7\uff0c\u65e0\u6cd5\u6709\u6548\u53d1\u73b0bug\u3002Meta\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u5728\u5927\u89c4\u6a21\u540e\u7aef\u7cfb\u7edf\uff08\u6570\u4ebf\u884c\u4ee3\u7801\uff09\u4e2d\u9884\u9632bug\uff0c\u7279\u522b\u662f\u8981\u5728\u4ee3\u7801\u5408\u5e76\u524d\u53d1\u73b0\u95ee\u9898\uff0c\u800c\u4e0d\u662f\u7b49\u5230\u751f\u4ea7\u73af\u5883\u3002", "method": "\u91c7\u7528\u5373\u65f6\u6355\u83b7\u6d4b\u8bd5\u751f\u6210\u65b9\u6cd5\uff0c\u751f\u6210\u9884\u671f\u4f1a\u5931\u8d25\u7684\u6d4b\u8bd5\uff08\u6355\u83b7\u6d4b\u8bd5\uff09\u3002\u4f7f\u7528\u4ee3\u7801\u53d8\u66f4\u611f\u77e5\u65b9\u6cd5\u6539\u8fdb\u5019\u9009\u6355\u83b7\u751f\u6210\uff0c\u7ed3\u5408\u57fa\u4e8e\u89c4\u5219\u548cLLM\u7684\u8bc4\u4f30\u5668\u6765\u51cf\u5c11\u5047\u9633\u6027\uff0c\u5e76\u901a\u8fc7\u7edf\u8ba1\u5206\u6790\u548c\u4eba\u5de5\u9a8c\u8bc1\u6765\u8bc4\u4f30\u6548\u679c\u3002", "result": "\u4ee3\u7801\u53d8\u66f4\u611f\u77e5\u65b9\u6cd5\u5c06\u5019\u9009\u6355\u83b7\u751f\u6210\u63d0\u9ad8\u4e864\u500d\uff08\u76f8\u6bd4\u5f3a\u5316\u6d4b\u8bd5\uff09\u548c20\u500d\uff08\u76f8\u6bd4\u5076\u7136\u5931\u8d25\u7684\u6d4b\u8bd5\uff09\u3002\u8bc4\u4f30\u5668\u51cf\u5c11\u4e8670%\u7684\u4eba\u5de5\u5ba1\u67e5\u5de5\u4f5c\u91cf\u3002\u5728\u62a5\u544a\u768441\u4e2a\u5019\u9009\u6355\u83b7\u4e2d\uff0c8\u4e2a\u88ab\u786e\u8ba4\u4e3a\u771f\u9633\u6027\uff0c\u5176\u4e2d4\u4e2a\u5982\u679c\u672a\u88ab\u6355\u83b7\u5c06\u5bfc\u81f4\u4e25\u91cd\u6545\u969c\u3002", "conclusion": "\u5373\u65f6\u6355\u83b7\u6d4b\u8bd5\u751f\u6210\u662f\u89c4\u6a21\u5316\u3001\u5de5\u4e1a\u53ef\u7528\u7684\u65b9\u6cd5\uff0c\u80fd\u6709\u6548\u9632\u6b62\u4e25\u91cd\u6545\u969c\u8fdb\u5165\u751f\u4ea7\u73af\u5883\uff0c\u901a\u8fc7\u63d0\u524d\u53d1\u73b0bug\u663e\u8457\u63d0\u9ad8\u4e86\u4ee3\u7801\u8d28\u91cf\u3002"}}
{"id": "2601.22859", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.22859", "abs": "https://arxiv.org/abs/2601.22859", "authors": ["Chuanzhe Guo", "Jingjing Wu", "Sijun He", "Yang Chen", "Zhaoqi Kuang", "Shilong Fan", "Bingjin Chen", "Siqi Bao", "Jing Liu", "Hua Wu", "Qingfu Zhu", "Wanxiang Che", "Haifeng Wang"], "title": "MEnvAgent: Scalable Polyglot Environment Construction for Verifiable Software Engineering", "comment": null, "summary": "The evolution of Large Language Model (LLM) agents for software engineering (SWE) is constrained by the scarcity of verifiable datasets, a bottleneck stemming from the complexity of constructing executable environments across diverse languages. To address this, we introduce MEnvAgent, a Multi-language framework for automated Environment construction that facilitates scalable generation of verifiable task instances. MEnvAgent employs a multi-agent Planning-Execution-Verification architecture to autonomously resolve construction failures and integrates a novel Environment Reuse Mechanism that reduces computational overhead by incrementally patching historical environments. Evaluations on MEnvBench, a new benchmark comprising 1,000 tasks across 10 languages, demonstrate that MEnvAgent outperforms baselines, improving Fail-to-Pass (F2P) rates by 8.6% while reducing time costs by 43%. Additionally, we demonstrate the utility of MEnvAgent by constructing MEnvData-SWE, the largest open-source polyglot dataset of realistic verifiable Docker environments to date, alongside solution trajectories that enable consistent performance gains on SWE tasks across a wide range of models. Our code, benchmark, and dataset are available at https://github.com/ernie-research/MEnvAgent.", "AI": {"tldr": "MEnvAgent\u662f\u4e00\u4e2a\u591a\u8bed\u8a00\u6846\u67b6\uff0c\u7528\u4e8e\u81ea\u52a8\u5316\u6784\u5efa\u53ef\u6267\u884c\u73af\u5883\uff0c\u89e3\u51b3LLM\u4ee3\u7406\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u7f3a\u4e4f\u53ef\u9a8c\u8bc1\u6570\u636e\u96c6\u7684\u95ee\u9898\u3002\u8be5\u6846\u67b6\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u67b6\u6784\u548c\u589e\u91cf\u73af\u5883\u590d\u7528\u673a\u5236\uff0c\u663e\u8457\u63d0\u5347\u4e86\u73af\u5883\u6784\u5efa\u7684\u6210\u529f\u7387\u548c\u6548\u7387\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u8f6f\u4ef6\u5de5\u7a0b\u9886\u57df\u7684\u5e94\u7528\u53d7\u5230\u53ef\u9a8c\u8bc1\u6570\u636e\u96c6\u7a00\u7f3a\u7684\u9650\u5236\uff0c\u4e3b\u8981\u539f\u56e0\u662f\u8de8\u591a\u79cd\u7f16\u7a0b\u8bed\u8a00\u6784\u5efa\u53ef\u6267\u884c\u73af\u5883\u7684\u590d\u6742\u6027\u3002\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u89c4\u6a21\u5316\u751f\u6210\u53ef\u9a8c\u8bc1\u7684\u4efb\u52a1\u5b9e\u4f8b\u3002", "method": "MEnvAgent\u91c7\u7528\u591a\u667a\u80fd\u4f53\u89c4\u5212-\u6267\u884c-\u9a8c\u8bc1\u67b6\u6784\uff0c\u81ea\u4e3b\u89e3\u51b3\u73af\u5883\u6784\u5efa\u5931\u8d25\u95ee\u9898\uff0c\u5e76\u96c6\u6210\u4e86\u521b\u65b0\u7684\u73af\u5883\u590d\u7528\u673a\u5236\uff0c\u901a\u8fc7\u589e\u91cf\u4fee\u8865\u5386\u53f2\u73af\u5883\u6765\u51cf\u5c11\u8ba1\u7b97\u5f00\u9500\u3002", "result": "\u5728\u5305\u542b10\u79cd\u8bed\u8a00\u30011000\u4e2a\u4efb\u52a1\u7684MEnvBench\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cMEnvAgent\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5c06\u5931\u8d25\u8f6c\u6210\u529f(F2P)\u7387\u63d0\u9ad8\u4e868.6%\uff0c\u540c\u65f6\u51cf\u5c11\u4e8643%\u7684\u65f6\u95f4\u6210\u672c\u3002\u8fd8\u6784\u5efa\u4e86\u76ee\u524d\u6700\u5927\u7684\u5f00\u6e90\u591a\u8bed\u8a00\u53ef\u9a8c\u8bc1Docker\u73af\u5883\u6570\u636e\u96c6MEnvData-SWE\u3002", "conclusion": "MEnvAgent\u4e3aLLM\u4ee3\u7406\u5728\u8f6f\u4ef6\u5de5\u7a0b\u9886\u57df\u7684\u53d1\u5c55\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u73af\u5883\u6784\u5efa\u89e3\u51b3\u65b9\u6848\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4efb\u52a1\u5b9e\u4f8b\u751f\u6210\u7684\u53ef\u9a8c\u8bc1\u6027\u548c\u6548\u7387\uff0c\u5e76\u4e3a\u8be5\u9886\u57df\u8d21\u732e\u4e86\u5b9d\u8d35\u7684\u6570\u636e\u8d44\u6e90\u3002"}}
{"id": "2601.22881", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.22881", "abs": "https://arxiv.org/abs/2601.22881", "authors": ["Ke Ping", "Hamza Bin Mazhar", "Yuqing Wang", "Ying Song", "Mika V. M\u00e4ntyl\u00e4"], "title": "AnoMod: A Dataset for Anomaly Detection and Root Cause Analysis in Microservice Systems", "comment": "Accepted at the 23rd International Conference on Mining Software Repositories (MSR 2026). Dataset paper", "summary": "Microservice systems (MSS) have become a predominant architectural style for cloud services. Yet the community still lacks high-quality, publicly available datasets for anomaly detection (AD) and root cause analysis (RCA) in MSS. Most benchmarks emphasize performance-related faults and provide only one or two monitoring modalities, limiting research on broader failure modes and cross-modal methods. To address these gaps, we introduce a new multimodal anomaly dataset built on two open-source microservice systems: SocialNetwork and TrainTicket. We design and inject four categories of anomalies (Ano): performance-level, service-level, database-level, and code-level, to emulate realistic anomaly modes. For each scenario, we collect five modalities (Mod): logs, metrics, distributed traces, API responses, and code coverage reports, offering a richer, end-to-end view of system state and inter-service interactions. We name our dataset, reflecting its unique properties, as AnoMod. This dataset enables (1) evaluation of cross-modal anomaly detection and fusion/ablation strategies, and (2) fine-grained RCA studies across service and code regions, supporting end-to-end troubleshooting pipelines that jointly consider detection and localization.", "AI": {"tldr": "\u63d0\u51fa\u4e86AnoMod\u6570\u636e\u96c6\uff0c\u4e00\u4e2a\u7528\u4e8e\u5fae\u670d\u52a1\u7cfb\u7edf\u5f02\u5e38\u68c0\u6d4b\u548c\u6839\u56e0\u5206\u6790\u7684\u591a\u6a21\u6001\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u5305\u542b\u56db\u79cd\u5f02\u5e38\u7c7b\u578b\u548c\u4e94\u79cd\u76d1\u63a7\u6a21\u6001\u3002", "motivation": "\u5f53\u524d\u5fae\u670d\u52a1\u7cfb\u7edf\u7f3a\u4e4f\u9ad8\u8d28\u91cf\u3001\u516c\u5f00\u53ef\u7528\u7684\u5f02\u5e38\u68c0\u6d4b\u548c\u6839\u56e0\u5206\u6790\u6570\u636e\u96c6\uff0c\u73b0\u6709\u57fa\u51c6\u4e3b\u8981\u5173\u6ce8\u6027\u80fd\u76f8\u5173\u6545\u969c\u4e14\u6a21\u6001\u5355\u4e00\uff0c\u9650\u5236\u4e86\u8de8\u6a21\u6001\u65b9\u6cd5\u548c\u66f4\u5e7f\u6cdb\u6545\u969c\u6a21\u5f0f\u7684\u7814\u7a76\u3002", "method": "\u57fa\u4e8e\u4e24\u4e2a\u5f00\u6e90\u5fae\u670d\u52a1\u7cfb\u7edf\uff08SocialNetwork\u548cTrainTicket\uff09\uff0c\u8bbe\u8ba1\u5e76\u6ce8\u5165\u4e86\u56db\u7c7b\u5f02\u5e38\uff08\u6027\u80fd\u7ea7\u3001\u670d\u52a1\u7ea7\u3001\u6570\u636e\u5e93\u7ea7\u3001\u4ee3\u7801\u7ea7\uff09\uff0c\u6536\u96c6\u4e86\u4e94\u79cd\u6a21\u6001\u6570\u636e\uff08\u65e5\u5fd7\u3001\u6307\u6807\u3001\u5206\u5e03\u5f0f\u8ffd\u8e2a\u3001API\u54cd\u5e94\u3001\u4ee3\u7801\u8986\u76d6\u7387\u62a5\u544a\uff09\u3002", "result": "\u521b\u5efa\u4e86AnoMod\u6570\u636e\u96c6\uff0c\u63d0\u4f9b\u4e86\u4e30\u5bcc\u7684\u7aef\u5230\u7aef\u7cfb\u7edf\u72b6\u6001\u89c6\u56fe\uff0c\u652f\u6301\u8de8\u6a21\u6001\u5f02\u5e38\u68c0\u6d4b\u3001\u878d\u5408/\u6d88\u878d\u7b56\u7565\u8bc4\u4f30\uff0c\u4ee5\u53ca\u8de8\u670d\u52a1\u548c\u4ee3\u7801\u533a\u57df\u7684\u7ec6\u7c92\u5ea6\u6839\u56e0\u5206\u6790\u3002", "conclusion": "AnoMod\u6570\u636e\u96c6\u586b\u8865\u4e86\u5fae\u670d\u52a1\u7cfb\u7edf\u5f02\u5e38\u68c0\u6d4b\u548c\u6839\u56e0\u5206\u6790\u7814\u7a76\u7684\u6570\u636e\u7a7a\u767d\uff0c\u652f\u6301\u8054\u5408\u8003\u8651\u68c0\u6d4b\u548c\u5b9a\u4f4d\u7684\u7aef\u5230\u7aef\u6545\u969c\u6392\u9664\u6d41\u7a0b\u7814\u7a76\u3002"}}
{"id": "2601.22919", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.22919", "abs": "https://arxiv.org/abs/2601.22919", "authors": ["Fabian Bally", "Michael Sch\u00f6tz", "Thomas Limbrunner"], "title": "A Serverless Edge-Native Data Processing Architecture for Autonomous Driving Training", "comment": "Source code is available at https://github.com/LASFAS/jblambda", "summary": "Data is both the key enabler and a major bottleneck for machine learning in autonomous driving. Effective model training requires not only large quantities of sensor data but also balanced coverage that includes rare yet safety-critical scenarios. Capturing such events demands extensive driving time and efficient selection. This paper introduces the Lambda framework, an edge-native platform that enables on-vehicle data filtering and processing through user-defined functions. The framework provides a serverless-inspired abstraction layer that separates application logic from low-level execution concerns such as scheduling, deployment, and isolation. By adapting Function-as-a-Service (FaaS) principles to resource-constrained automotive environments, it allows developers to implement modular, event-driven filtering algorithms while maintaining compatibility with ROS 2 and existing data recording pipelines. We evaluate the framework on an NVIDIA Jetson Orin Nano and compare it against native ROS 2 deployments. Results show competitive performance, reduced latency and jitter, and confirm that lambda-based abstractions can support real-time data processing in embedded autonomous driving systems. The source code is available at https://github.com/LASFAS/jblambda.", "AI": {"tldr": "Lambda\u6846\u67b6\u662f\u4e00\u4e2a\u8fb9\u7f18\u539f\u751f\u5e73\u53f0\uff0c\u901a\u8fc7\u7528\u6237\u5b9a\u4e49\u51fd\u6570\u5b9e\u73b0\u8f66\u8f7d\u6570\u636e\u8fc7\u6ee4\u548c\u5904\u7406\uff0c\u5c06FaaS\u539f\u5219\u9002\u914d\u5230\u8d44\u6e90\u53d7\u9650\u7684\u6c7d\u8f66\u73af\u5883\uff0c\u652f\u6301\u5b9e\u65f6\u6570\u636e\u5904\u7406\u3002", "motivation": "\u81ea\u52a8\u9a7e\u9a76\u673a\u5668\u5b66\u4e60\u9762\u4e34\u6570\u636e\u74f6\u9888\uff0c\u9700\u8981\u5927\u91cf\u4f20\u611f\u5668\u6570\u636e\u4e14\u9700\u8986\u76d6\u7f55\u89c1\u4f46\u5b89\u5168\u5173\u952e\u7684\u573a\u666f\uff0c\u4f20\u7edf\u65b9\u6cd5\u9700\u8981\u5927\u91cf\u9a7e\u9a76\u65f6\u95f4\u548c\u9ad8\u6548\u9009\u62e9\u673a\u5236\u3002", "method": "\u5f15\u5165Lambda\u6846\u67b6\uff0c\u63d0\u4f9b\u670d\u52a1\u5668\u65e0\u611f\u77e5\u62bd\u8c61\u5c42\uff0c\u5206\u79bb\u5e94\u7528\u903b\u8f91\u4e0e\u5e95\u5c42\u6267\u884c\u5173\u6ce8\u70b9\uff0c\u9002\u914dFaaS\u539f\u5219\u5230\u8d44\u6e90\u53d7\u9650\u6c7d\u8f66\u73af\u5883\uff0c\u652f\u6301\u6a21\u5757\u5316\u4e8b\u4ef6\u9a71\u52a8\u8fc7\u6ee4\u7b97\u6cd5\uff0c\u517c\u5bb9ROS 2\u548c\u73b0\u6709\u6570\u636e\u8bb0\u5f55\u7ba1\u9053\u3002", "result": "\u5728NVIDIA Jetson Orin Nano\u4e0a\u8bc4\u4f30\uff0c\u76f8\u6bd4\u539f\u751fROS 2\u90e8\u7f72\uff0c\u8868\u73b0\u51fa\u7ade\u4e89\u6027\u6027\u80fd\u3001\u964d\u4f4e\u7684\u5ef6\u8fdf\u548c\u6296\u52a8\uff0c\u8bc1\u5b9elambda\u62bd\u8c61\u80fd\u652f\u6301\u5d4c\u5165\u5f0f\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u7684\u5b9e\u65f6\u6570\u636e\u5904\u7406\u3002", "conclusion": "Lambda\u6846\u67b6\u6210\u529f\u5c06FaaS\u539f\u5219\u5e94\u7528\u4e8e\u8d44\u6e90\u53d7\u9650\u7684\u6c7d\u8f66\u73af\u5883\uff0c\u652f\u6301\u5b9e\u65f6\u6570\u636e\u8fc7\u6ee4\u548c\u5904\u7406\uff0c\u4e3a\u81ea\u52a8\u9a7e\u9a76\u6570\u636e\u91c7\u96c6\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.22952", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.22952", "abs": "https://arxiv.org/abs/2601.22952", "authors": ["Yunpeng Xiong", "Ting Zhang"], "title": "Sifting the Noise: A Comparative Study of LLM Agents in Vulnerability False Positive Filtering", "comment": null, "summary": "Static Application Security Testing (SAST) tools are essential for identifying software vulnerabilities, but they often produce a high volume of false positives (FPs), imposing a substantial manual triage burden on developers. Recent advances in Large Language Model (LLM) agents offer a promising direction by enabling iterative reasoning, tool use, and environment interaction to refine SAST alerts. However, the comparative effectiveness of different LLM-based agent architectures for FP filtering remains poorly understood. In this paper, we present a comparative study of three state-of-the-art LLM-based agent frameworks, i.e., Aider, OpenHands, and SWE-agent, for vulnerability FP filtering. We evaluate these frameworks using the vulnerabilities from the OWASP Benchmark and real-world open-source Java projects. The experimental results show that LLM-based agents can remove the majority of SAST noise, reducing an initial FP detection rate of over 92% on the OWASP Benchmark to as low as 6.3% in the best configuration. On real-world dataset, the best configuration of LLM-based agents can achieve an FP identification rate of up to 93.3% involving CodeQL alerts. However, the benefits of agents are strongly backbone- and CWE-dependent: agentic frameworks significantly outperform vanilla prompting for stronger models such as Claude Sonnet 4 and GPT-5, but yield limited or inconsistent gains for weaker backbones. Moreover, aggressive FP reduction can come at the cost of suppressing true vulnerabilities, highlighting important trade-offs. Finally, we observe large disparities in computational cost across agent frameworks. Overall, our study demonstrates that LLM-based agents are a powerful but non-uniform solution for SAST FP filtering, and that their practical deployment requires careful consideration of agent design, backbone model choice, vulnerability category, and operational cost.", "AI": {"tldr": "LLM\u667a\u80fd\u4f53\u53ef\u663e\u8457\u964d\u4f4eSAST\u5de5\u5177\u8bef\u62a5\u7387\uff0c\u4f46\u6548\u679c\u53d7\u6a21\u578b\u80fd\u529b\u3001\u6f0f\u6d1e\u7c7b\u578b\u548c\u67b6\u6784\u8bbe\u8ba1\u5f71\u54cd\uff0c\u5b58\u5728\u8ba1\u7b97\u6210\u672c\u4e0e\u6f0f\u62a5\u7684\u6743\u8861\u3002", "motivation": "SAST\u5de5\u5177\u4ea7\u751f\u5927\u91cf\u8bef\u62a5\u7ed9\u5f00\u53d1\u8005\u5e26\u6765\u6c89\u91cd\u8d1f\u62c5\uff0cLLM\u667a\u80fd\u4f53\u901a\u8fc7\u8fed\u4ee3\u63a8\u7406\u548c\u73af\u5883\u4ea4\u4e92\u6709\u671b\u4f18\u5316\u8bef\u62a5\u8fc7\u6ee4\uff0c\u4f46\u4e0d\u540c\u667a\u80fd\u4f53\u67b6\u6784\u7684\u6bd4\u8f83\u6548\u679c\u5c1a\u4e0d\u660e\u786e\u3002", "method": "\u6bd4\u8f83\u4e09\u79cd\u6700\u5148\u8fdb\u7684LLM\u667a\u80fd\u4f53\u6846\u67b6\uff08Aider\u3001OpenHands\u3001SWE-agent\uff09\u5728\u6f0f\u6d1e\u8bef\u62a5\u8fc7\u6ee4\u4e2d\u7684\u8868\u73b0\uff0c\u4f7f\u7528OWASP Benchmark\u548c\u771f\u5b9e\u5f00\u6e90Java\u9879\u76ee\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "LLM\u667a\u80fd\u4f53\u53ef\u5c06OWASP Benchmark\u7684\u8bef\u62a5\u7387\u4ece92%\u964d\u81f36.3%\uff0c\u5728\u771f\u5b9e\u9879\u76ee\u4e2dCodeQL\u8b66\u62a5\u7684\u8bef\u62a5\u8bc6\u522b\u7387\u53ef\u8fbe93.3%\u3002\u4f46\u6548\u679c\u5f3a\u70c8\u4f9d\u8d56\u9aa8\u5e72\u6a21\u578b\u548cCWE\u7c7b\u578b\uff0c\u5f3a\u6a21\u578b\uff08Claude Sonnet 4\u3001GPT-5\uff09\u4e0a\u667a\u80fd\u4f53\u663e\u8457\u4f18\u4e8e\u666e\u901a\u63d0\u793a\uff0c\u5f31\u6a21\u578b\u4e0a\u589e\u76ca\u6709\u9650\u6216\u4e0d\u4e00\u81f4\u3002\u6fc0\u8fdb\u7684\u8bef\u62a5\u51cf\u5c11\u53ef\u80fd\u6291\u5236\u771f\u5b9e\u6f0f\u6d1e\uff0c\u4e14\u4e0d\u540c\u6846\u67b6\u8ba1\u7b97\u6210\u672c\u5dee\u5f02\u5927\u3002", "conclusion": "LLM\u667a\u80fd\u4f53\u662fSAST\u8bef\u62a5\u8fc7\u6ee4\u7684\u5f3a\u5927\u4f46\u975e\u5747\u5300\u89e3\u51b3\u65b9\u6848\uff0c\u5b9e\u9645\u90e8\u7f72\u9700\u7efc\u5408\u8003\u8651\u667a\u80fd\u4f53\u8bbe\u8ba1\u3001\u9aa8\u5e72\u6a21\u578b\u9009\u62e9\u3001\u6f0f\u6d1e\u7c7b\u522b\u548c\u8fd0\u8425\u6210\u672c\u3002"}}
{"id": "2601.22956", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.22956", "abs": "https://arxiv.org/abs/2601.22956", "authors": ["Boyin Tan", "Haoning Deng", "Junyuan Zhang", "Junjielong Xu", "Pinjia He", "Youcheng Sun"], "title": "SWE-Manager: Selecting and Synthesizing Golden Proposals Before Coding", "comment": null, "summary": "Large language model (LLM) research in software engineering has largely focused on tasks such as code generation and bug repair. In practice, teams often draft multiple candidate proposals for fixing an issue and then deliberate on one golden proposal for implementation. This selection requires not only assessing the issue's scope, impact, and urgency, but also a clear understanding of each proposal's strengths and weaknesses. A good selection could make issue resolution more reliable while reducing regression and operational risk, whereas a poor choice can increase risk and even cause unpredictable failures.\n  We first conduct a manual study of real-world issues to characterize the rationales maintainers use when selecting among competing proposals. Motivated by these findings, we introduce SWE-Manager, a joint selection and synthesis approach that selects the best proposal and synthesizes a golden proposal. SWE-Manager is an 8B model trained via reinforcement learning (RL) to compare proposals, justify its choice, and synthesize a golden proposal for implementation. We view proposal selection as a reasoning task, mirroring how technical managers review competing proposals by weighing issue context and each proposal's solution without executing code or running tests. On the SWE-Lancer Manager benchmark, SWE-Manager achieves 53.21 selection accuracy and 57.75 earn rate, earning 152,750 dollars and outperforming strong baselines including GPT-5. To further evaluate the effectiveness of SWE-Manager in real-world issue resolution, we design the P2A framework, which simulates a real-world workflow where multiple proposals are drafted, reviewed, and a golden proposal is selected for implementation ...", "AI": {"tldr": "SWE-Manager\uff1a\u4e00\u4e2a8B\u53c2\u6570\u6a21\u578b\uff0c\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\uff0c\u7528\u4e8e\u5728\u591a\u4e2a\u4ee3\u7801\u4fee\u590d\u63d0\u6848\u4e2d\u9009\u62e9\u6700\u4f73\u65b9\u6848\u5e76\u5408\u6210\u6700\u7ec8\u5b9e\u65bd\u65b9\u6848\uff0c\u5728SWE-Lancer Manager\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u4e8eGPT-5\u7b49\u57fa\u7ebf\u6a21\u578b\u3002", "motivation": "\u5f53\u524dLLM\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u7684\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u4ee3\u7801\u751f\u6210\u548c\u9519\u8bef\u4fee\u590d\uff0c\u4f46\u5b9e\u9645\u5f00\u53d1\u4e2d\u56e2\u961f\u9700\u8981\u4ece\u591a\u4e2a\u5019\u9009\u65b9\u6848\u4e2d\u9009\u62e9\u6700\u4f73\u5b9e\u65bd\u65b9\u6848\u3002\u8fd9\u79cd\u9009\u62e9\u9700\u8981\u8003\u8651\u95ee\u9898\u7684\u8303\u56f4\u3001\u5f71\u54cd\u548c\u7d27\u8feb\u6027\uff0c\u4ee5\u53ca\u6bcf\u4e2a\u65b9\u6848\u7684\u4f18\u7f3a\u70b9\u3002\u597d\u7684\u9009\u62e9\u53ef\u4ee5\u63d0\u9ad8\u95ee\u9898\u89e3\u51b3\u7684\u53ef\u9760\u6027\uff0c\u964d\u4f4e\u56de\u5f52\u548c\u64cd\u4f5c\u98ce\u9669\u3002", "method": "1. \u9996\u5148\u5bf9\u771f\u5b9e\u4e16\u754c\u95ee\u9898\u8fdb\u884c\u4eba\u5de5\u7814\u7a76\uff0c\u5206\u6790\u7ef4\u62a4\u8005\u5728\u9009\u62e9\u7ade\u4e89\u63d0\u6848\u65f6\u7684\u51b3\u7b56\u4f9d\u636e\uff1b2. \u63d0\u51faSWE-Manager\uff0c\u8fd9\u662f\u4e00\u4e2a8B\u53c2\u6570\u7684\u6a21\u578b\uff0c\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\uff0c\u80fd\u591f\u6bd4\u8f83\u63d0\u6848\u3001\u8bc1\u660e\u9009\u62e9\u5408\u7406\u6027\u5e76\u5408\u6210\u6700\u7ec8\u5b9e\u65bd\u65b9\u6848\uff1b3. \u5c06\u63d0\u6848\u9009\u62e9\u89c6\u4e3a\u63a8\u7406\u4efb\u52a1\uff0c\u6a21\u62df\u6280\u672f\u7ecf\u7406\u5728\u4e0d\u6267\u884c\u4ee3\u7801\u6216\u8fd0\u884c\u6d4b\u8bd5\u7684\u60c5\u51b5\u4e0b\u8bc4\u4f30\u63d0\u6848\u7684\u8fc7\u7a0b\uff1b4. \u8bbe\u8ba1P2A\u6846\u67b6\u6a21\u62df\u771f\u5b9e\u5de5\u4f5c\u6d41\u7a0b\u3002", "result": "\u5728SWE-Lancer Manager\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cSWE-Manager\u8fbe\u523053.21%\u7684\u9009\u62e9\u51c6\u786e\u7387\u548c57.75%\u7684\u6536\u76ca\u7387\uff0c\u83b7\u5f97152,750\u7f8e\u5143\u6536\u76ca\uff0c\u8868\u73b0\u4f18\u4e8e\u5305\u62ecGPT-5\u5728\u5185\u7684\u5f3a\u57fa\u7ebf\u6a21\u578b\u3002", "conclusion": "SWE-Manager\u901a\u8fc7\u5c06\u63d0\u6848\u9009\u62e9\u5efa\u6a21\u4e3a\u63a8\u7406\u4efb\u52a1\uff0c\u6709\u6548\u6a21\u62df\u4e86\u6280\u672f\u7ecf\u7406\u7684\u51b3\u7b56\u8fc7\u7a0b\uff0c\u5728\u8f6f\u4ef6\u5de5\u7a0b\u95ee\u9898\u89e3\u51b3\u4e2d\u5c55\u73b0\u51fa\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u7684\u6027\u80fd\uff0c\u4e3a\u5b9e\u9645\u5f00\u53d1\u5de5\u4f5c\u6d41\u7a0b\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u81ea\u52a8\u5316\u5de5\u5177\u3002"}}
{"id": "2601.23009", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.23009", "abs": "https://arxiv.org/abs/2601.23009", "authors": ["Wei Chen", "Zhiyuan Peng", "Xin Yin", "Chao Ni", "Chenhao Ying", "Bang Xie", "Yuan Luo"], "title": "SolAgent: A Specialized Multi-Agent Framework for Solidity Code Generation", "comment": null, "summary": "Smart contracts are the backbone of the decentralized web, yet ensuring their functional correctness and security remains a critical challenge. While Large Language Models (LLMs) have shown promise in code generation, they often struggle with the rigorous requirements of smart contracts, frequently producing code that is buggy or vulnerable. To address this, we propose SolAgent, a novel tool-augmented multi-agent framework that mimics the workflow of human experts. SolAgent integrates a \\textbf{dual-loop refinement mechanism}: an inner loop using the \\textit{Forge} compiler to ensure functional correctness, and an outer loop leveraging the \\textit{Slither} static analyzer to eliminate security vulnerabilities. Additionally, the agent is equipped with file system capabilities to resolve complex project dependencies. Experiments on the SolEval+ Benchmark, a rigorous suite derived from high-quality real-world projects, demonstrate that SolAgent achieves a Pass@1 rate of up to \\textbf{64.39\\%}, significantly outperforming state-of-the-art LLMs ($\\sim$25\\%), AI IDEs (e.g., GitHub Copilot), and existing agent frameworks. Moreover, it reduces security vulnerabilities by up to \\textbf{39.77\\%} compared to human-written baselines. Finally, we demonstrate that the high-quality trajectories generated by SolAgent can be used to distill smaller, open-source models, democratizing access to secure smart contract generation. We release our data and code at https://github.com/openpaperz/SolAgent.", "AI": {"tldr": "SolAgent\u662f\u4e00\u4e2a\u57fa\u4e8e\u591a\u667a\u80fd\u4f53\u6846\u67b6\u7684\u5de5\u5177\u589e\u5f3a\u7cfb\u7edf\uff0c\u4e13\u95e8\u7528\u4e8e\u751f\u6210\u5b89\u5168\u53ef\u9760\u7684\u667a\u80fd\u5408\u7ea6\u4ee3\u7801\uff0c\u901a\u8fc7\u53cc\u5faa\u73af\u4f18\u5316\u673a\u5236\u663e\u8457\u63d0\u5347\u4ee3\u7801\u8d28\u91cf\u548c\u5b89\u5168\u6027\u3002", "motivation": "\u667a\u80fd\u5408\u7ea6\u662f\u53bb\u4e2d\u5fc3\u5316\u7f51\u7edc\u7684\u6838\u5fc3\uff0c\u4f46\u5176\u529f\u80fd\u6b63\u786e\u6027\u548c\u5b89\u5168\u6027\u4fdd\u969c\u4ecd\u662f\u5173\u952e\u6311\u6218\u3002\u73b0\u6709\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u751f\u6210\u667a\u80fd\u5408\u7ea6\u4ee3\u7801\u65f6\u7ecf\u5e38\u4ea7\u751f\u6709\u7f3a\u9677\u6216\u6613\u53d7\u653b\u51fb\u7684\u4ee3\u7801\uff0c\u65e0\u6cd5\u6ee1\u8db3\u4e25\u683c\u7684\u5b89\u5168\u8981\u6c42\u3002", "method": "\u63d0\u51faSolAgent\u6846\u67b6\uff0c\u91c7\u7528\u5de5\u5177\u589e\u5f3a\u7684\u591a\u667a\u80fd\u4f53\u67b6\u6784\uff0c\u6a21\u62df\u4eba\u7c7b\u4e13\u5bb6\u5de5\u4f5c\u6d41\u7a0b\u3002\u6838\u5fc3\u662f\u53cc\u5faa\u73af\u4f18\u5316\u673a\u5236\uff1a\u5185\u5faa\u73af\u4f7f\u7528Forge\u7f16\u8bd1\u5668\u786e\u4fdd\u529f\u80fd\u6b63\u786e\u6027\uff0c\u5916\u5faa\u73af\u5229\u7528Slither\u9759\u6001\u5206\u6790\u5668\u6d88\u9664\u5b89\u5168\u6f0f\u6d1e\u3002\u7cfb\u7edf\u8fd8\u5177\u5907\u6587\u4ef6\u7cfb\u7edf\u80fd\u529b\u4ee5\u89e3\u51b3\u590d\u6742\u9879\u76ee\u4f9d\u8d56\u3002", "result": "\u5728SolEval+\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cSolAgent\u8fbe\u523064.39%\u7684Pass@1\u7387\uff0c\u663e\u8457\u4f18\u4e8e\u6700\u5148\u8fdb\u7684LLM\uff08\u7ea625%\uff09\u3001AI IDE\uff08\u5982GitHub Copilot\uff09\u548c\u73b0\u6709\u667a\u80fd\u4f53\u6846\u67b6\u3002\u76f8\u6bd4\u4eba\u5de5\u7f16\u5199\u7684\u57fa\u7ebf\uff0c\u5b89\u5168\u6f0f\u6d1e\u51cf\u5c11\u8fbe39.77%\u3002", "conclusion": "SolAgent\u80fd\u6709\u6548\u751f\u6210\u9ad8\u8d28\u91cf\u3001\u5b89\u5168\u7684\u667a\u80fd\u5408\u7ea6\u4ee3\u7801\uff0c\u5176\u751f\u6210\u7684\u9ad8\u8d28\u91cf\u8f68\u8ff9\u53ef\u7528\u4e8e\u84b8\u998f\u66f4\u5c0f\u7684\u5f00\u6e90\u6a21\u578b\uff0c\u4fc3\u8fdb\u5b89\u5168\u667a\u80fd\u5408\u7ea6\u751f\u6210\u7684\u6c11\u4e3b\u5316\u3002"}}
{"id": "2601.23020", "categories": ["cs.SE", "cs.CR"], "pdf": "https://arxiv.org/pdf/2601.23020", "abs": "https://arxiv.org/abs/2601.23020", "authors": ["Stefan Schott", "Serena Elisa Ponta", "Wolfram Fischer", "Jonas Klauke", "Eric Bodden"], "title": "Uncovering Hidden Inclusions of Vulnerable Dependencies in Real-World Java Projects", "comment": null, "summary": "Open-source software (OSS) dependencies are a dominant component of modern software code bases. Using proven and well-tested OSS components lets developers reduce development time and cost while improving quality. However, heavy reliance on open-source software also introduces significant security risks, including the incorporation of known vulnerabilities into the codebase. To mitigate these risks, metadata-based dependency scanners, which are lightweight and fast, and code-centric scanners, which enable the detection of modified dependencies hidden from metadata-based approaches, have been developed. In this paper, we present Unshade, a hybrid approach towards dependency scanning in Java that combines the efficiency of metadata-based scanning with the ability to detect modified dependencies of code-centric approaches. Unshade first augments a Java project's software bill of materials (SBOM) by identifying modified and hidden dependencies via a bytecode-based fingerprinting mechanism. This augmented SBOM is then passed to a metadata-based vulnerability scanner to identify known vulnerabilities in both declared and newly revealed dependencies. Leveraging Unshade's high scalability, we conducted a large-scale study of the 1,808 most popular open-source Java Maven projects on GitHub. The results show that nearly 50% of these projects contain at least one modified, hidden dependency associated with a known vulnerability. On average, each affected project includes more than eight such hidden vulnerable dependencies, all missed by traditional metadata-based scanners. Overall, Unshade identified 7,712 unique CVEs in hidden dependencies that would remain undetected when relying on metadata-based scanning alone.", "AI": {"tldr": "Unshade\u662f\u4e00\u4e2a\u6df7\u5408\u4f9d\u8d56\u626b\u63cf\u5de5\u5177\uff0c\u7ed3\u5408\u5143\u6570\u636e\u626b\u63cf\u7684\u9ad8\u6548\u6027\u548c\u4ee3\u7801\u4e2d\u5fc3\u65b9\u6cd5\u7684\u68c0\u6d4b\u80fd\u529b\uff0c\u80fd\u53d1\u73b0Java\u9879\u76ee\u4e2d\u4fee\u6539\u548c\u9690\u85cf\u7684\u4f9d\u8d56\u6f0f\u6d1e\u3002", "motivation": "\u73b0\u4ee3\u8f6f\u4ef6\u4e25\u91cd\u4f9d\u8d56\u5f00\u6e90\u7ec4\u4ef6\uff0c\u8fd9\u867d\u7136\u63d0\u9ad8\u5f00\u53d1\u6548\u7387\u4f46\u5f15\u5165\u5b89\u5168\u98ce\u9669\u3002\u73b0\u6709\u626b\u63cf\u5668\u6709\u5c40\u9650\u6027\uff1a\u5143\u6570\u636e\u626b\u63cf\u5668\u8f7b\u91cf\u5feb\u901f\u4f46\u65e0\u6cd5\u68c0\u6d4b\u4fee\u6539\u7684\u4f9d\u8d56\uff1b\u4ee3\u7801\u4e2d\u5fc3\u626b\u63cf\u5668\u80fd\u68c0\u6d4b\u4fee\u6539\u4f9d\u8d56\u4f46\u6548\u7387\u8f83\u4f4e\u3002", "method": "Unshade\u91c7\u7528\u6df7\u5408\u65b9\u6cd5\uff1a\u9996\u5148\u901a\u8fc7\u57fa\u4e8e\u5b57\u8282\u7801\u7684\u6307\u7eb9\u8bc6\u522b\u673a\u5236\u8bc6\u522b\u4fee\u6539\u548c\u9690\u85cf\u7684\u4f9d\u8d56\uff0c\u589e\u5f3a\u9879\u76ee\u7684\u8f6f\u4ef6\u7269\u6599\u6e05\u5355(SBOM)\uff0c\u7136\u540e\u5c06\u589e\u5f3a\u7684SBOM\u4f20\u9012\u7ed9\u5143\u6570\u636e\u6f0f\u6d1e\u626b\u63cf\u5668\uff0c\u68c0\u6d4b\u58f0\u660e\u4f9d\u8d56\u548c\u65b0\u53d1\u73b0\u4f9d\u8d56\u4e2d\u7684\u5df2\u77e5\u6f0f\u6d1e\u3002", "result": "\u5bf9GitHub\u4e0a1,808\u4e2a\u6700\u6d41\u884c\u7684Java Maven\u9879\u76ee\u8fdb\u884c\u5927\u89c4\u6a21\u7814\u7a76\uff0c\u53d1\u73b0\u8fd150%\u7684\u9879\u76ee\u5305\u542b\u81f3\u5c11\u4e00\u4e2a\u4e0e\u5df2\u77e5\u6f0f\u6d1e\u76f8\u5173\u7684\u4fee\u6539\u3001\u9690\u85cf\u4f9d\u8d56\u3002\u5e73\u5747\u6bcf\u4e2a\u53d7\u5f71\u54cd\u9879\u76ee\u5305\u542b\u8d85\u8fc78\u4e2a\u8fd9\u6837\u7684\u9690\u85cf\u6f0f\u6d1e\u4f9d\u8d56\uff0c\u4f20\u7edf\u5143\u6570\u636e\u626b\u63cf\u5668\u4f1a\u5168\u90e8\u6f0f\u6389\u3002Unshade\u5171\u8bc6\u522b\u51fa7,712\u4e2a\u9690\u85cf\u4f9d\u8d56\u4e2d\u7684\u552f\u4e00CVE\u3002", "conclusion": "Unshade\u7ed3\u5408\u4e86\u4e24\u79cd\u626b\u63cf\u65b9\u6cd5\u7684\u4f18\u52bf\uff0c\u80fd\u6709\u6548\u68c0\u6d4b\u4f20\u7edf\u5143\u6570\u636e\u626b\u63cf\u5668\u65e0\u6cd5\u53d1\u73b0\u7684\u9690\u85cf\u4f9d\u8d56\u6f0f\u6d1e\uff0c\u663e\u8457\u63d0\u9ad8\u4e86Java\u9879\u76ee\u4f9d\u8d56\u5b89\u5168\u626b\u63cf\u7684\u8986\u76d6\u7387\u548c\u51c6\u786e\u6027\u3002"}}
{"id": "2601.23059", "categories": ["cs.SE", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.23059", "abs": "https://arxiv.org/abs/2601.23059", "authors": ["Antonio Vitale", "Emanuela Guglielmi", "Simone Scalabrino", "Rocco Oliveto"], "title": "On the Impact of Code Comments for Automated Bug-Fixing: An Empirical Study", "comment": "Accepted at the 34th IEEE/ACM International Conference on Program Comprehension (ICPC 2026)", "summary": "Large Language Models (LLMs) are increasingly relevant in Software Engineering research and practice, with Automated Bug Fixing (ABF) being one of their key applications. ABF involves transforming a buggy method into its fixed equivalent. A common preprocessing step in ABF involves removing comments from code prior to training. However, we hypothesize that comments may play a critical role in fixing certain types of bugs by providing valuable design and implementation insights. In this study, we investigate how the presence or absence of comments, both during training and at inference time, impacts the bug-fixing capabilities of LLMs. We conduct an empirical evaluation comparing two model families, each evaluated under all combinations of training and inference conditions (with and without comments), and thereby revisiting the common practice of removing comments during training. To address the limited availability of comments in state-of-the-art datasets, we use an LLM to automatically generate comments for methods lacking them. Our findings show that comments improve ABF accuracy by up to threefold when present in both phases, while training with comments does not degrade performance when instances lack them. Additionally, an interpretability analysis identifies that comments detailing method implementation are particularly effective in aiding LLMs to fix bugs accurately.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4ee3\u7801\u6ce8\u91ca\u5bf9LLM\u81ea\u52a8\u4fee\u590dbug\u80fd\u529b\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u8bad\u7ec3\u548c\u63a8\u7406\u9636\u6bb5\u90fd\u5305\u542b\u6ce8\u91ca\u53ef\u5c06\u4fee\u590d\u51c6\u786e\u7387\u63d0\u5347\u4e09\u500d\uff0c\u4e14\u5b9e\u73b0\u7ec6\u8282\u7c7b\u6ce8\u91ca\u6700\u6709\u6548\u3002", "motivation": "\u5f53\u524d\u81ea\u52a8bug\u4fee\u590d\u7814\u7a76\u4e2d\u666e\u904d\u5b58\u5728\u53bb\u9664\u4ee3\u7801\u6ce8\u91ca\u7684\u505a\u6cd5\uff0c\u4f46\u7814\u7a76\u8005\u5047\u8bbe\u6ce8\u91ca\u53ef\u80fd\u5305\u542b\u6709\u4ef7\u503c\u7684\u8bbe\u8ba1\u548c\u5b9e\u73b0\u4fe1\u606f\uff0c\u5bf9\u4fee\u590d\u67d0\u4e9b\u7c7b\u578bbug\u81f3\u5173\u91cd\u8981\u3002\u9700\u8981\u91cd\u65b0\u5ba1\u89c6\u53bb\u9664\u6ce8\u91ca\u8fd9\u4e00\u5e38\u89c1\u9884\u5904\u7406\u6b65\u9aa4\u3002", "method": "1) \u4f7f\u7528LLM\u4e3a\u7f3a\u4e4f\u6ce8\u91ca\u7684\u6570\u636e\u96c6\u81ea\u52a8\u751f\u6210\u6ce8\u91ca\uff1b2) \u6bd4\u8f83\u4e24\u4e2a\u6a21\u578b\u5bb6\u65cf\u5728\u8bad\u7ec3\u548c\u63a8\u7406\u9636\u6bb5\u6240\u6709\u7ec4\u5408\u6761\u4ef6\u4e0b\u7684\u8868\u73b0\uff08\u6709/\u65e0\u6ce8\u91ca\uff09\uff1b3) \u8fdb\u884c\u53ef\u89e3\u91ca\u6027\u5206\u6790\uff0c\u8bc6\u522b\u6700\u6709\u6548\u7684\u6ce8\u91ca\u7c7b\u578b\u3002", "result": "1) \u5f53\u6ce8\u91ca\u540c\u65f6\u5b58\u5728\u4e8e\u8bad\u7ec3\u548c\u63a8\u7406\u9636\u6bb5\u65f6\uff0c\u81ea\u52a8bug\u4fee\u590d\u51c6\u786e\u7387\u6700\u9ad8\u53ef\u63d0\u5347\u4e09\u500d\uff1b2) \u4f7f\u7528\u5e26\u6ce8\u91ca\u6570\u636e\u8bad\u7ec3\u4e0d\u4f1a\u964d\u4f4e\u65e0\u6ce8\u91ca\u5b9e\u4f8b\u7684\u6027\u80fd\uff1b3) \u63cf\u8ff0\u65b9\u6cd5\u5b9e\u73b0\u7ec6\u8282\u7684\u6ce8\u91ca\u5bf9\u5e2e\u52a9LLM\u51c6\u786e\u4fee\u590dbug\u7279\u522b\u6709\u6548\u3002", "conclusion": "\u4ee3\u7801\u6ce8\u91ca\u5bf9LLM\u7684\u81ea\u52a8bug\u4fee\u590d\u80fd\u529b\u6709\u663e\u8457\u79ef\u6781\u5f71\u54cd\uff0c\u7279\u522b\u662f\u5728\u8bad\u7ec3\u548c\u63a8\u7406\u9636\u6bb5\u90fd\u4fdd\u7559\u6ce8\u91ca\u65f6\u6548\u679c\u6700\u4f73\u3002\u7814\u7a76\u5efa\u8bae\u91cd\u65b0\u8003\u8651\u53bb\u9664\u6ce8\u91ca\u7684\u5e38\u89c1\u505a\u6cd5\uff0c\u5e76\u5f3a\u8c03\u5b9e\u73b0\u7ec6\u8282\u7c7b\u6ce8\u91ca\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2601.23139", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.23139", "abs": "https://arxiv.org/abs/2601.23139", "authors": ["Ruizhen Gu", "Jos\u00e9 Miguel Rojas", "Donghwan Shin"], "title": "Automated Testing of Prevalent 3D User Interactions in Virtual Reality Applications", "comment": "31 pages, 7 figures", "summary": "Virtual Reality (VR) technologies offer immersive user experiences across various domains, but present unique testing challenges compared to traditional software. Existing VR testing approaches enable scene navigation and interaction activation, but lack the ability to automatically synthesise realistic 3D user inputs (e.g, grab and trigger actions via hand-held controllers). Automated testing that generates and executes such input remains an unresolved challenge. Furthermore, existing metrics fail to robustly capture diverse interaction coverage. This paper addresses these gaps through four key contributions. First, we empirically identify four prevalent interaction types in nine open-source VR projects: fire, manipulate, socket, and custom. Second, we introduce the Interaction Flow Graph, a novel abstraction that systematically models 3D user interactions by identifying targets, actions, and conditions. Third, we construct XRBench3D, a benchmark comprising ten VR scenes that encompass 456 distinct user interactions for evaluating VR interaction testing. Finally, we present XRintTest, an automated testing approach that leverages this graph for dynamic scene exploration and interaction execution. Evaluation on XRBench3D shows that XRintTest achieves great effectiveness, reaching 93% coverage of fire, manipulate and socket interactions across all scenes, and performing 12x more effectively and 6x more efficiently than random exploration. Moreover, XRintTest can detect runtime exceptions and non-exception interaction issues, including subtle configuration defects. In addition, the Interaction Flow Graph can reveal potential interaction design smells that may compromise intended functionality and hinder testing performance for VR applications.", "AI": {"tldr": "\u63d0\u51faXRintTest\u81ea\u52a8\u5316\u6d4b\u8bd5\u6846\u67b6\uff0c\u89e3\u51b3VR\u5e94\u75283D\u7528\u6237\u4ea4\u4e92\u6d4b\u8bd5\u96be\u9898\uff0c\u901a\u8fc7\u4ea4\u4e92\u6d41\u56fe\u5efa\u6a21\u5b9e\u73b0\u9ad8\u6548\u4ea4\u4e92\u8986\u76d6", "motivation": "\u73b0\u6709VR\u6d4b\u8bd5\u65b9\u6cd5\u7f3a\u4e4f\u81ea\u52a8\u751f\u6210\u771f\u5b9e3D\u7528\u6237\u8f93\u5165\uff08\u5982\u624b\u67c4\u6293\u53d6\u548c\u89e6\u53d1\u52a8\u4f5c\uff09\u7684\u80fd\u529b\uff0c\u4e14\u73b0\u6709\u6307\u6807\u65e0\u6cd5\u7a33\u5065\u6355\u6349\u591a\u6837\u4ea4\u4e92\u8986\u76d6\uff0c\u81ea\u52a8\u5316\u6d4b\u8bd5\u751f\u6210\u548c\u6267\u884c\u4ecd\u662f\u672a\u89e3\u51b3\u7684\u6311\u6218", "method": "1) \u7ecf\u9a8c\u6027\u8bc6\u522b\u56db\u79cd\u5e38\u89c1VR\u4ea4\u4e92\u7c7b\u578b\uff1b2) \u63d0\u51fa\u4ea4\u4e92\u6d41\u56fe\u62bd\u8c61\u6a21\u578b\uff0c\u7cfb\u7edf\u5efa\u6a213D\u7528\u6237\u4ea4\u4e92\uff1b3) \u6784\u5efaXRBench3D\u57fa\u51c6\u6d4b\u8bd5\u96c6\uff1b4) \u5f00\u53d1XRintTest\u81ea\u52a8\u5316\u6d4b\u8bd5\u65b9\u6cd5\uff0c\u5229\u7528\u4ea4\u4e92\u6d41\u56fe\u8fdb\u884c\u52a8\u6001\u573a\u666f\u63a2\u7d22\u548c\u4ea4\u4e92\u6267\u884c", "result": "XRintTest\u5728XRBench3D\u4e0a\u8fbe\u523093%\u7684fire\u3001manipulate\u548csocket\u4ea4\u4e92\u8986\u76d6\u7387\uff0c\u6bd4\u968f\u673a\u63a2\u7d22\u6548\u679c\u9ad812\u500d\u3001\u6548\u7387\u9ad86\u500d\uff0c\u80fd\u68c0\u6d4b\u8fd0\u884c\u65f6\u5f02\u5e38\u548c\u975e\u5f02\u5e38\u4ea4\u4e92\u95ee\u9898\uff0c\u5305\u62ec\u7ec6\u5fae\u914d\u7f6e\u7f3a\u9677", "conclusion": "\u63d0\u51fa\u7684\u4ea4\u4e92\u6d41\u56fe\u548cXRintTest\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86VR\u5e94\u75283D\u4ea4\u4e92\u81ea\u52a8\u5316\u6d4b\u8bd5\u7684\u6311\u6218\uff0c\u4e0d\u4ec5\u80fd\u5b9e\u73b0\u9ad8\u8986\u76d6\u7387\u6d4b\u8bd5\uff0c\u8fd8\u80fd\u63ed\u793a\u53ef\u80fd\u5f71\u54cd\u529f\u80fd\u548c\u6d4b\u8bd5\u6027\u80fd\u7684\u4ea4\u4e92\u8bbe\u8ba1\u95ee\u9898"}}
{"id": "2601.23141", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.23141", "abs": "https://arxiv.org/abs/2601.23141", "authors": ["Mineth Weerasinghe", "Himindu Kularathne", "Methmini Madhushika", "Danuka Lakshan", "Nisansa de Silva", "Adeesha Wijayasiri", "Srinath Perera"], "title": "From Monolith to Microservices: A Comparative Evaluation of Decomposition Frameworks", "comment": "Accepted at WorldCist 2026. Preprint version. 12 pages, 1 table", "summary": "Software modernisation through the migration from monolithic architectures to microservices has become increasingly critical, yet identifying effective service boundaries remains a complex and unresolved challenge. Although numerous automated microservice decomposition frameworks have been proposed, their evaluation is often fragmented due to inconsistent benchmark systems, incompatible metrics, and limited reproducibility, thus hindering objective comparison. This work presents a unified comparative evaluation of state-of-the-art microservice decomposition approaches spanning static, dynamic, and hybrid techniques. Using a consistent metric computation pipeline, we assess the decomposition quality across widely used benchmark systems (JPetStore, AcmeAir, DayTrader, and Plants) using Structural Modularity (SM), Interface Number(IFN), Inter-partition Communication (ICP), Non-Extreme Distribution (NED), and related indicators. Our analysis combines results reported in prior studies with experimentally reproduced outputs from available replication packages. Findings indicate that the hierarchical clustering-based methods, particularly HDBScan, produce the most consistently balanced decompositions across benchmarks, achieving strong modularity while minimizing communication and interface overhead.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5bf9\u5fae\u670d\u52a1\u5206\u89e3\u65b9\u6cd5\u8fdb\u884c\u4e86\u7edf\u4e00\u8bc4\u4f30\uff0c\u53d1\u73b0\u57fa\u4e8e\u5c42\u6b21\u805a\u7c7b\u7684\u65b9\u6cd5\uff08\u7279\u522b\u662fHDBScan\uff09\u5728\u4e0d\u540c\u57fa\u51c6\u7cfb\u7edf\u4e2d\u4ea7\u751f\u6700\u4e00\u81f4\u7684\u5e73\u8861\u5206\u89e3\u7ed3\u679c\u3002", "motivation": "\u8f6f\u4ef6\u73b0\u4ee3\u5316\u8fc7\u7a0b\u4e2d\uff0c\u4ece\u5355\u4f53\u67b6\u6784\u8fc1\u79fb\u5230\u5fae\u670d\u52a1\u67b6\u6784\u65e5\u76ca\u91cd\u8981\uff0c\u4f46\u786e\u5b9a\u6709\u6548\u7684\u670d\u52a1\u8fb9\u754c\u4ecd\u7136\u662f\u4e00\u4e2a\u590d\u6742\u4e14\u672a\u89e3\u51b3\u7684\u6311\u6218\u3002\u73b0\u6709\u7684\u81ea\u52a8\u5316\u5fae\u670d\u52a1\u5206\u89e3\u6846\u67b6\u8bc4\u4f30\u5b58\u5728\u788e\u7247\u5316\u95ee\u9898\uff0c\u5305\u62ec\u57fa\u51c6\u7cfb\u7edf\u4e0d\u4e00\u81f4\u3001\u6307\u6807\u4e0d\u517c\u5bb9\u548c\u53ef\u590d\u73b0\u6027\u6709\u9650\uff0c\u963b\u788d\u4e86\u5ba2\u89c2\u6bd4\u8f83\u3002", "method": "\u91c7\u7528\u7edf\u4e00\u7684\u6bd4\u8f83\u8bc4\u4f30\u65b9\u6cd5\uff0c\u6db5\u76d6\u9759\u6001\u3001\u52a8\u6001\u548c\u6df7\u5408\u6280\u672f\u7684\u6700\u5148\u8fdb\u5fae\u670d\u52a1\u5206\u89e3\u65b9\u6cd5\u3002\u4f7f\u7528\u4e00\u81f4\u7684\u6307\u6807\u8ba1\u7b97\u7ba1\u9053\uff0c\u5728\u5e7f\u6cdb\u4f7f\u7528\u7684\u57fa\u51c6\u7cfb\u7edf\uff08JPetStore\u3001AcmeAir\u3001DayTrader\u3001Plants\uff09\u4e0a\u8bc4\u4f30\u5206\u89e3\u8d28\u91cf\uff0c\u4f7f\u7528\u7ed3\u6784\u6a21\u5757\u5316\u3001\u63a5\u53e3\u6570\u91cf\u3001\u5206\u533a\u95f4\u901a\u4fe1\u3001\u975e\u6781\u7aef\u5206\u5e03\u7b49\u76f8\u5173\u6307\u6807\u3002\u7ed3\u5408\u5148\u524d\u7814\u7a76\u62a5\u544a\u7684\u7ed3\u679c\u548c\u901a\u8fc7\u53ef\u7528\u590d\u5236\u5305\u5b9e\u9a8c\u590d\u73b0\u7684\u8f93\u51fa\u8fdb\u884c\u5206\u6790\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u57fa\u4e8e\u5c42\u6b21\u805a\u7c7b\u7684\u65b9\u6cd5\uff0c\u7279\u522b\u662fHDBScan\uff0c\u5728\u4e0d\u540c\u57fa\u51c6\u7cfb\u7edf\u4e2d\u4ea7\u751f\u6700\u4e00\u81f4\u7684\u5e73\u8861\u5206\u89e3\u7ed3\u679c\uff0c\u5728\u5b9e\u73b0\u5f3a\u6a21\u5757\u5316\u7684\u540c\u65f6\u6700\u5c0f\u5316\u901a\u4fe1\u548c\u63a5\u53e3\u5f00\u9500\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u5fae\u670d\u52a1\u5206\u89e3\u65b9\u6cd5\u7684\u8bc4\u4f30\u63d0\u4f9b\u4e86\u7edf\u4e00\u7684\u6846\u67b6\uff0c\u8bc1\u660e\u4e86\u5c42\u6b21\u805a\u7c7b\u65b9\u6cd5\uff08\u5c24\u5176\u662fHDBScan\uff09\u5728\u5fae\u670d\u52a1\u5206\u89e3\u4e2d\u7684\u4f18\u8d8a\u6027\u548c\u4e00\u81f4\u6027\uff0c\u4e3a\u8f6f\u4ef6\u73b0\u4ee3\u5316\u4e2d\u7684\u67b6\u6784\u8fc1\u79fb\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u6307\u5bfc\u3002"}}
{"id": "2601.23142", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.23142", "abs": "https://arxiv.org/abs/2601.23142", "authors": ["Mohamed Ouf", "Amr Mohamed", "Mariam Guizani"], "title": "Do Good, Stay Longer? Temporal Patterns and Predictors of Newcomer-to-Core Transitions in Conventional OSS and OSS4SG", "comment": null, "summary": "Open Source Software (OSS) sustainability relies on newcomers transitioning to core contributors, but this pipeline is broken, with most newcomers becoming inactive after initial contributions. Open Source Software for Social Good (OSS4SG) projects, which prioritize societal impact as their primary mission, may be associated with different newcomer-to-core transition outcomes than conventional OSS projects. We compared 375 projects (190 OSS4SG, 185 OSS), analyzing 92,721 contributors and 3.5 million commits. OSS4SG projects retain contributors at 2.2X higher rates and contributors have 19.6% higher probability of achieving core status. Early broad project exploration predicts core achievement (22.2% importance); conventional OSS concentrates on one dominant pathway (61.62% of transitions) while OSS4SG provides multiple pathways. Contrary to intuition, contributors who invest time learning the project before intensifying their contributions (Late Spike pattern) achieve core status 2.4-2.9X faster (21 weeks) than those who contribute intensively from day one (Early Spike pattern, 51-60 weeks). OSS4SG supports two effective temporal patterns while only Late Spike achieves fastest time-to-core in conventional OSS. Our findings suggest that finding a project aligned with personal values and taking time to understand the codebase before major contributions are key strategies for achieving core status. Our findings show that project mission is associated with measurably different environments for newcomer-to-core transitions and provide evidence-based guidance for newcomers and maintainers.", "AI": {"tldr": "OSS4SG\u9879\u76ee\u76f8\u6bd4\u4f20\u7edfOSS\u9879\u76ee\uff0c\u65b0\u4eba\u8f6c\u4e3a\u6838\u5fc3\u8d21\u732e\u8005\u7684\u4fdd\u7559\u7387\u66f4\u9ad8\uff082.2\u500d\uff09\uff0c\u6838\u5fc3\u5730\u4f4d\u8fbe\u6210\u6982\u7387\u66f4\u9ad8\uff0819.6%\uff09\uff0c\u4e14\u63d0\u4f9b\u591a\u79cd\u6210\u957f\u8def\u5f84\u800c\u975e\u5355\u4e00\u4e3b\u5bfc\u8def\u5f84", "motivation": "\u5f00\u6e90\u8f6f\u4ef6\u53ef\u6301\u7eed\u6027\u4f9d\u8d56\u65b0\u4eba\u8f6c\u4e3a\u6838\u5fc3\u8d21\u732e\u8005\uff0c\u4f46\u8fd9\u4e00\u7ba1\u9053\u5b58\u5728\u65ad\u88c2\u95ee\u9898\u3002\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u4ee5\u793e\u4f1a\u5f71\u54cd\u4e3a\u4f7f\u547d\u7684OSS4SG\u9879\u76ee\u662f\u5426\u4e0e\u4f20\u7edfOSS\u9879\u76ee\u5728\u65b0\u4eba\u8f6c\u6838\u5fc3\u65b9\u9762\u5b58\u5728\u5dee\u5f02", "method": "\u6bd4\u8f83375\u4e2a\u9879\u76ee\uff08190\u4e2aOSS4SG\uff0c185\u4e2a\u4f20\u7edfOSS\uff09\uff0c\u5206\u679092,721\u540d\u8d21\u732e\u8005\u548c350\u4e07\u6b21\u63d0\u4ea4\uff0c\u7814\u7a76\u8d21\u732e\u8005\u4fdd\u7559\u7387\u3001\u6838\u5fc3\u5730\u4f4d\u8fbe\u6210\u6982\u7387\u3001\u6210\u957f\u8def\u5f84\u6a21\u5f0f\u548c\u65f6\u95f4\u6a21\u5f0f", "result": "OSS4SG\u9879\u76ee\u4fdd\u7559\u7387\u662f\u4f20\u7edf\u9879\u76ee\u76842.2\u500d\uff0c\u6838\u5fc3\u5730\u4f4d\u8fbe\u6210\u6982\u7387\u9ad819.6%\u3002\u65e9\u671f\u5e7f\u6cdb\u63a2\u7d22\u9879\u76ee\u80fd\u9884\u6d4b\u6838\u5fc3\u5730\u4f4d\u8fbe\u6210\uff0822.2%\u91cd\u8981\u6027\uff09\u3002\u4f20\u7edfOSS\u4e3b\u8981\u4f9d\u8d56\u5355\u4e00\u4e3b\u5bfc\u8def\u5f84\uff0861.62%\uff09\uff0c\u800cOSS4SG\u63d0\u4f9b\u591a\u79cd\u8def\u5f84\u3002Late Spike\u6a21\u5f0f\uff08\u5148\u5b66\u4e60\u518d\u96c6\u4e2d\u8d21\u732e\uff09\u6bd4Early Spike\u6a21\u5f0f\uff08\u4ece\u4e00\u5f00\u59cb\u5c31\u9ad8\u5f3a\u5ea6\u8d21\u732e\uff09\u8fbe\u6210\u6838\u5fc3\u5730\u4f4d\u5feb2.4-2.9\u500d", "conclusion": "\u9879\u76ee\u4f7f\u547d\u4e0e\u65b0\u4eba\u8f6c\u6838\u5fc3\u73af\u5883\u663e\u8457\u76f8\u5173\u3002\u5173\u952e\u7b56\u7565\u5305\u62ec\uff1a\u9009\u62e9\u4e0e\u4e2a\u4eba\u4ef7\u503c\u89c2\u4e00\u81f4\u7684\u9879\u76ee\uff0c\u5728\u4e3b\u8981\u8d21\u732e\u524d\u82b1\u65f6\u95f4\u7406\u89e3\u4ee3\u7801\u5e93\u3002OSS4SG\u652f\u6301\u4e24\u79cd\u6709\u6548\u65f6\u95f4\u6a21\u5f0f\uff0c\u800c\u4f20\u7edfOSS\u53ea\u6709Late Spike\u6a21\u5f0f\u80fd\u6700\u5feb\u8fbe\u6210\u6838\u5fc3\u5730\u4f4d"}}
{"id": "2601.23254", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.23254", "abs": "https://arxiv.org/abs/2601.23254", "authors": ["Baoyi Wang", "Xingliang Wang", "Guochang Li", "Chen Zhi", "Junxiao Han", "Xinkui Zhao", "Nan Wang", "Shuiguang Deng", "Jianwei Yin"], "title": "GrepRAG: An Empirical Study and Optimization of Grep-Like Retrieval for Code Completion", "comment": "Under Review", "summary": "Repository-level code completion remains challenging for large language models (LLMs) due to cross-file dependencies and limited context windows. Prior work addresses this challenge using Retrieval-Augmented Generation (RAG) frameworks based on semantic indexing or structure-aware graph analysis, but these approaches incur substantial computational overhead for index construction and maintenance. Motivated by common developer workflows that rely on lightweight search utilities (e.g., ripgrep), we revisit a fundamental yet underexplored question: how far can simple, index-free lexical retrieval support repository-level code completion before more complex retrieval mechanisms become necessary? To answer this question, we systematically investigate lightweight, index-free, intent-aware lexical retrieval through extensive empirical analysis. We first introduce Naive GrepRAG, a baseline framework in which LLMs autonomously generate ripgrep commands to retrieve relevant context. Despite its simplicity, Naive GrepRAG achieves performance comparable to sophisticated graph-based baselines. Further analysis shows that its effectiveness stems from retrieving lexically precise code fragments that are spatially closer to the completion site. We also identify key limitations of lexical retrieval, including sensitivity to noisy matches from high-frequency ambiguous keywords and context fragmentation caused by rigid truncation boundaries. To address these issues, we propose GrepRAG, which augments lexical retrieval with a lightweight post-processing pipeline featuring identifier-weighted re-ranking and structure-aware deduplication. Extensive evaluation on CrossCodeEval and RepoEval-Updated demonstrates that GrepRAG consistently outperforms state-of-the-art (SOTA) methods, achieving 7.04-15.58 percent relative improvement in code exact match (EM) over the best baseline on CrossCodeEval.", "AI": {"tldr": "GrepRAG\uff1a\u4e00\u79cd\u57fa\u4e8e\u8f7b\u91cf\u7ea7\u8bcd\u6cd5\u68c0\u7d22\u7684\u4ed3\u5e93\u7ea7\u4ee3\u7801\u8865\u5168\u6846\u67b6\uff0c\u901a\u8fc7ripgrep\u547d\u4ee4\u68c0\u7d22\u76f8\u5173\u4ee3\u7801\u7247\u6bb5\uff0c\u914d\u5408\u540e\u5904\u7406\u7ba1\u9053\uff0c\u5728\u65e0\u9700\u590d\u6742\u7d22\u5f15\u7684\u60c5\u51b5\u4e0b\u8d85\u8d8a\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u8bed\u4e49\u7d22\u5f15\u6216\u56fe\u5206\u6790\u7684RAG\u65b9\u6cd5\u8ba1\u7b97\u5f00\u9500\u5927\uff0c\u800c\u5f00\u53d1\u8005\u5e38\u7528\u8f7b\u91cf\u7ea7\u641c\u7d22\u5de5\u5177\uff08\u5982ripgrep\uff09\u3002\u7814\u7a76\u63a2\u7d22\u7b80\u5355\u8bcd\u6cd5\u68c0\u7d22\u5728\u4ed3\u5e93\u7ea7\u4ee3\u7801\u8865\u5168\u4e2d\u7684\u6f5c\u529b\uff0c\u4ee5\u53ca\u4f55\u65f6\u9700\u8981\u66f4\u590d\u6742\u7684\u68c0\u7d22\u673a\u5236\u3002", "method": "1. \u63d0\u51faNaive GrepRAG\u57fa\u7ebf\u6846\u67b6\uff1aLLM\u81ea\u4e3b\u751f\u6210ripgrep\u547d\u4ee4\u68c0\u7d22\u76f8\u5173\u4e0a\u4e0b\u6587\uff1b2. \u5206\u6790\u8bcd\u6cd5\u68c0\u7d22\u7684\u5c40\u9650\u6027\uff1a\u5bf9\u9ad8\u9891\u6a21\u7cca\u5173\u952e\u8bcd\u654f\u611f\u3001\u4e0a\u4e0b\u6587\u788e\u7247\u5316\uff1b3. \u63d0\u51fa\u6539\u8fdb\u7248GrepRAG\uff1a\u589e\u52a0\u6807\u8bc6\u7b26\u52a0\u6743\u91cd\u6392\u548c\u7ed3\u6784\u611f\u77e5\u53bb\u91cd\u7684\u540e\u5904\u7406\u7ba1\u9053\u3002", "result": "Naive GrepRAG\u6027\u80fd\u4e0e\u590d\u6742\u56fe\u57fa\u7ebf\u76f8\u5f53\uff1bGrepRAG\u5728CrossCodeEval\u548cRepoEval-Updated\u4e0a\u6301\u7eed\u8d85\u8d8aSOTA\u65b9\u6cd5\uff0c\u5728CrossCodeEval\u4e0a\u4ee3\u7801\u7cbe\u786e\u5339\u914d\u76f8\u5bf9\u63d0\u53477.04-15.58%\u3002", "conclusion": "\u7b80\u5355\u8bcd\u6cd5\u68c0\u7d22\u5728\u4ed3\u5e93\u7ea7\u4ee3\u7801\u8865\u5168\u4e2d\u5177\u6709\u663e\u8457\u6f5c\u529b\uff0cGrepRAG\u901a\u8fc7\u8f7b\u91cf\u7ea7\u540e\u5904\u7406\u89e3\u51b3\u8bcd\u6cd5\u68c0\u7d22\u7684\u5c40\u9650\u6027\uff0c\u5728\u65e0\u9700\u590d\u6742\u7d22\u5f15\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u6700\u4f73\u6027\u80fd\uff0c\u4e3a\u5b9e\u9645\u90e8\u7f72\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.23257", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.23257", "abs": "https://arxiv.org/abs/2601.23257", "authors": ["Chenglin Li", "Yisen Xu", "Zehao Wang", "Shin Hwei Tan", "Tse-Hsun", "Chen"], "title": "Outcome-Conditioned Reasoning Distillation for Resolving Software Issues", "comment": "17 pages, 3 figures, 5 tables", "summary": "Software issue resolution in large repositories is a long-range decision process: choices made during localization shape the space of viable edits, and missteps can compound into incorrect patches. Despite this, many LLM-based repair pipelines still operate in a reset-and-solve manner, producing fresh reasoning for every new issue instead of carrying forward what worked in past fixes. This is wasteful because repositories routinely contain earlier issues with overlapping structure, failure modes, or constraints, where prior repair experience could provide useful guidance. Existing approaches typically harvest this signal through forward-time trial procedures, such as repeated refinement or search, incurring high inference cost while still risking divergence from the eventual correct patch. We present an Outcome-Conditioned Reasoning Distillation(O-CRD) framework that uses resolved in-repository issues with verified patches as supervision. Starting from a historical fix, the method reconstructs a stage-wise repair trace backward from the verified outcome, then reuses the distilled guidance at inference time to steer file/function localization and patch synthesis, without fine-tuning or online search. On SWE-Bench Lite, this approach increases Pass@1 by 10.4% with GPT-4o, 8.6% with DeepSeek-V3, and 10.3% with GPT-5, indicating that outcome-conditioned reuse of verified repairs can replace costly forward exploration for software issue resolution.", "AI": {"tldr": "\u63d0\u51faO-CRD\u6846\u67b6\uff0c\u901a\u8fc7\u4ece\u5df2\u9a8c\u8bc1\u7684\u5386\u53f2\u4fee\u590d\u4e2d\u53cd\u5411\u91cd\u6784\u4fee\u590d\u8f68\u8ff9\uff0c\u5728\u63a8\u7406\u65f6\u590d\u7528\u8fd9\u4e9b\u6307\u5bfc\u6765\u5f15\u5bfc\u8f6f\u4ef6\u95ee\u9898\u5b9a\u4f4d\u548c\u8865\u4e01\u5408\u6210\uff0c\u65e0\u9700\u5fae\u8c03\u6216\u5728\u7ebf\u641c\u7d22\uff0c\u663e\u8457\u63d0\u5347\u4fee\u590d\u6210\u529f\u7387\u3002", "motivation": "\u73b0\u6709LLM\u4fee\u590d\u7ba1\u9053\u901a\u5e38\u4ee5\u91cd\u7f6e\u548c\u89e3\u51b3\u7684\u65b9\u5f0f\u8fd0\u4f5c\uff0c\u6bcf\u6b21\u9047\u5230\u65b0\u95ee\u9898\u90fd\u91cd\u65b0\u63a8\u7406\uff0c\u6d6a\u8d39\u4e86\u4ed3\u5e93\u4e2d\u5df2\u6709\u7684\u76f8\u4f3c\u95ee\u9898\u4fee\u590d\u7ecf\u9a8c\u3002\u73b0\u6709\u65b9\u6cd5\u901a\u8fc7\u524d\u5411\u65f6\u95f4\u8bd5\u9a8c\u8fc7\u7a0b\uff08\u5982\u91cd\u590d\u7cbe\u70bc\u6216\u641c\u7d22\uff09\u6765\u5229\u7528\u8fd9\u4e9b\u4fe1\u53f7\uff0c\u6210\u672c\u9ad8\u4e14\u53ef\u80fd\u504f\u79bb\u6b63\u786e\u8865\u4e01\u3002", "method": "O-CRD\u6846\u67b6\u4f7f\u7528\u5df2\u89e3\u51b3\u7684\u4ed3\u5e93\u95ee\u9898\u53ca\u5176\u5df2\u9a8c\u8bc1\u8865\u4e01\u4f5c\u4e3a\u76d1\u7763\u3002\u4ece\u5386\u53f2\u4fee\u590d\u5f00\u59cb\uff0c\u8be5\u65b9\u6cd5\u4ece\u5df2\u9a8c\u8bc1\u7ed3\u679c\u5411\u540e\u91cd\u6784\u9636\u6bb5\u5f0f\u4fee\u590d\u8f68\u8ff9\uff0c\u7136\u540e\u5728\u63a8\u7406\u65f6\u590d\u7528\u8fd9\u4e9b\u84b8\u998f\u7684\u6307\u5bfc\u6765\u5f15\u5bfc\u6587\u4ef6/\u51fd\u6570\u5b9a\u4f4d\u548c\u8865\u4e01\u5408\u6210\uff0c\u65e0\u9700\u5fae\u8c03\u6216\u5728\u7ebf\u641c\u7d22\u3002", "result": "\u5728SWE-Bench Lite\u4e0a\uff0c\u8be5\u65b9\u6cd5\u5c06Pass@1\u63d0\u5347\u4e8610.4%\uff08GPT-4o\uff09\u30018.6%\uff08DeepSeek-V3\uff09\u548c10.3%\uff08GPT-5\uff09\uff0c\u8868\u660e\u7ed3\u679c\u5bfc\u5411\u7684\u5df2\u9a8c\u8bc1\u4fee\u590d\u590d\u7528\u53ef\u4ee5\u66ff\u4ee3\u6602\u8d35\u7684\u524d\u5411\u63a2\u7d22\u3002", "conclusion": "\u901a\u8fc7\u4ece\u5386\u53f2\u4fee\u590d\u4e2d\u53cd\u5411\u91cd\u6784\u4fee\u590d\u8f68\u8ff9\u5e76\u590d\u7528\u6307\u5bfc\uff0cO-CRD\u6846\u67b6\u80fd\u591f\u6709\u6548\u5229\u7528\u4ed3\u5e93\u4e2d\u7684\u4fee\u590d\u7ecf\u9a8c\uff0c\u663e\u8457\u63d0\u5347\u8f6f\u4ef6\u95ee\u9898\u89e3\u51b3\u7684\u6210\u529f\u7387\uff0c\u540c\u65f6\u907f\u514d\u6602\u8d35\u7684\u5728\u7ebf\u641c\u7d22\u6210\u672c\u3002"}}
