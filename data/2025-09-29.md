<div id=toc></div>

# Table of Contents

- [cs.SE](#cs.SE) [Total: 16]
- [cs.DB](#cs.DB) [Total: 4]
- [cs.DC](#cs.DC) [Total: 5]


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [1] [Extracting Conceptual Knowledge to Locate Software Issues](https://arxiv.org/abs/2509.21427)
*Ying Wang,Wenjun Mao,Chong Wang,Zhenhao Zhou,Yicheng Zhou,Wenyun Zhao,Yiling Lou,Xin Peng*

Main category: cs.SE

TL;DR: RepoLens通过提取和利用代码仓库的概念知识来解决大规模仓库中的问题定位挑战，通过将细粒度功能分解并重新组合为高层次关注点来指导LLMs，显著提升了现有工具的定位性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有LLM方法在大规模代码仓库中面临的问题：关注点混合（相关逻辑被埋没在大函数中）和关注点分散（相关逻辑分散在不同文件中），这些问题影响了问题定位的准确性。

Method: RepoLens采用两阶段方法：离线阶段提取和丰富概念知识构建仓库级知识库；在线阶段检索问题相关术语，按相关性聚类和排序关注点，并通过最小侵入式提示增强集成到定位工作流中。

Result: 在SWE-Lancer-Loc基准测试的216个任务上，RepoLens显著提升了三种最先进工具的性能，在文件和函数级定位中平均提升超过22%的Hit@k和46%的Recall@k，在不同模型上Hit@1和Recall@10分别提升高达504%和376%。

Conclusion: RepoLens通过构建语义连贯的功能集群来指导LLMs，有效解决了大规模代码仓库中的问题定位挑战，消融研究和人工评估证实了所构建关注点的有效性和可靠性。

Abstract: Issue localization, which identifies faulty code elements such as files or
functions, is critical for effective bug fixing. While recent LLM-based and
LLM-agent-based approaches improve accuracy, they struggle in large-scale
repositories due to concern mixing, where relevant logic is buried in large
functions, and concern scattering, where related logic is dispersed across
files.
  To address these challenges, we propose RepoLens, a novel approach that
abstracts and leverages conceptual knowledge from code repositories. RepoLens
decomposes fine-grained functionalities and recomposes them into high-level
concerns, semantically coherent clusters of functionalities that guide LLMs. It
operates in two stages: an offline stage that extracts and enriches conceptual
knowledge into a repository-wide knowledge base, and an online stage that
retrieves issue-specific terms, clusters and ranks concerns by relevance, and
integrates them into localization workflows via minimally intrusive prompt
enhancements. We evaluate RepoLens on SWE-Lancer-Loc, a benchmark of 216 tasks
derived from SWE-Lancer. RepoLens consistently improves three state-of-the-art
tools, namely AgentLess, OpenHands, and mini-SWE-agent, achieving average gains
of over 22% in Hit@k and 46% in Recall@k for file- and function-level
localization. It generalizes across models (GPT-4o, GPT-4o-mini, GPT-4.1) with
Hit@1 and Recall@10 gains up to 504% and 376%, respectively. Ablation studies
and manual evaluation confirm the effectiveness and reliability of the
constructed concerns.

</details>


### [2] [Lost in Transition: The Struggle of Women Returning to Software Engineering Research after Career Breaks](https://arxiv.org/abs/2509.21533)
*Shalini Chakraborty,Sebastian Baltes*

Main category: cs.SE

TL;DR: 研究女性软件工程师在职业中断后重返学术界面临的挑战，比较学术与产业环境的差异，分析不同国家的政策支持，并提出改进建议。


<details>
  <summary>Details</summary>
Motivation: IT行业为女性重返职场提供了多种支持途径，但学术界缺乏相应的机会和激励措施。职业中断（如生育、移民、缺乏灵活工作选择）严重影响女性职业发展，而学术机构的性别多样性政策往往不完善且未被充分重视。

Method: 开展多元文化研究项目，在多个国家和大学进行调查，收集女性重返学术或研究岗位面临的挑战数据，进行机构视角分析，比较不同国家的现有政策和机会。

Result: 研究发现女性在重返学术界时面临比产业界更大的障碍，学术机构的支持政策存在显著差异且普遍不足，需要改进透明招聘实践。

Conclusion: 需要为女性重返学术界提供更好的支持机制，包括改进政策、增加灵活工作选择、建立透明招聘流程，以促进学术界的性别多样性。

Abstract: The IT industry provides supportive pathways such as returnship programs,
coding boot camps, and buddy systems for women re-entering their job after a
career break. Academia, however, offers limited opportunities to motivate women
to return. We propose a diverse multicultural research project investigating
the challenges faced by women with software engineering (SE) backgrounds
re-entering academia or related research roles after a career break. Career
disruptions due to pregnancy, immigration status, or lack of flexible work
options can significantly impact women's career progress, creating barriers for
returning as lecturers, professors, or senior researchers. Although many
companies promote gender diversity policies, such measures are less prominent
and often under-recognized within academic institutions. Our goal is to explore
the specific challenges women encounter when re-entering academic roles
compared to industry roles; to understand the institutional perspective,
including a comparative analysis of existing policies and opportunities in
different countries for women to return to the field; and finally, to provide
recommendations that support transparent hiring practices. The research project
will be carried out in multiple universities and in multiple countries to
capture the diverse challenges and policies that vary by location.

</details>


### [3] [No More Manual Guides: Automatic and Scalable Generation of High-Quality Excel Tutorials](https://arxiv.org/abs/2509.21816)
*Yuhang Xie,Jian Mu,Xiaojun Ma,Chaoyun Zhang,Lu Wang,Mengyu Zhou,Mugeng Liu,Si Qin,Qingwei Lin,Saravan Rajmohan,Shi Han,Dongmei Zhang*

Main category: cs.SE

TL;DR: 提出了首个从自然语言任务描述自动生成Excel教程的框架，通过执行代理在Excel中规划执行解决方案并收集中间产物，自动生成结构化文档和视频演示，显著提升任务执行成功率并大幅降低人工成本。


<details>
  <summary>Details</summary>
Motivation: Excel功能复杂但用户需求旺盛，现有教程依赖专家手动编写且更新成本高，需要实现完全自动化的教程生成来满足持续需求。

Method: 框架首先实例化任务，然后通过执行代理在Excel中规划执行解决方案，收集中间产物，最后将这些产物转换为结构化Excel文档和视频演示。

Result: 在1,559个真实场景任务上的实验表明，框架将任务执行成功率提升8.5%，生成的教程可读性和教学效果接近或超过专家编写材料，自动化流程将时间成本降至专家编写的1/20。

Conclusion: 该框架首次实现了可扩展的高质量Excel教程自动生成，消除了人工劳动，为大规模教程生成提供了实用解决方案。

Abstract: Excel is one of the most widely used productivity tools across domains,
offering rich functionality but also overwhelming users with its complexity.
This creates a persistent demand for tutorials to support effective usage.
However, existing tutorials are manually authored by experts, require frequent
updates after each software release, and incur substantial labor costs. Prior
work has not achieved fully automated tutorial generation, since existing
methods still depend on handcrafted operation sequences or example materials.
In this paper, we present the first framework for automatically generating
Excel tutorials directly from natural language task descriptions. Our framework
first instantiates the task. Then a central component of this framework,
Execution Agent, plans and executes the solution in Excel, and collects the
intermediate artifacts required for tutorial construction. These artifacts are
then transformed into both structured Excel documents and video demonstrations.
To build a comprehensive tutorial corpus, we collected 1,559 task descriptions
from real-world scenarios. In addition, we designed a systematic evaluation
framework that integrates assessments from both large language models (LLMs)
and human reviewers. Experimental results show that our framework improves task
execution success rates by 8.5% over state-of-the-art baselines. Moreover, the
generated tutorials demonstrate superior readability and instructional
effectiveness, often approaching or surpassing expert-authored materials.
Importantly, the automated pipeline eliminates manual labor and reduces time
costs to 1/20 of expert authoring, making scalable and high-quality tutorial
generation practical for the first time.

</details>


### [4] [Software Engineering Data Analytics: A Framework Based on a Multi-Layered Abstraction Mechanism](https://arxiv.org/abs/2509.21881)
*Chaman Wijesiriwardana,Prasad Wimalaratne*

Main category: cs.SE

TL;DR: 提出了一个用于软件分析领域的特定领域框架，支持异构软件存储库的查询、建模和集成，采用多层抽象机制和领域特定操作符。


<details>
  <summary>Details</summary>
Motivation: 为了解决异构软件存储库数据难以统一查询、建模和集成的问题，提高软件分析的效率和准确性。

Method: 设计了一个基于多层抽象机制的领域特定框架，包含领域特定操作符，并通过案例研究验证方法可行性。

Result: 通过案例研究展示了该方法的潜力，能够有效处理异构软件存储库的集成和分析。

Conclusion: 该领域特定框架为软件分析提供了一种有效的解决方案，能够简化异构数据源的集成和分析过程。

Abstract: This paper presents a concept of a domain-specific framework for software
analytics by enabling querying, modeling, and integration of heterogeneous
software repositories. The framework adheres to a multi-layered abstraction
mechanism that consists of domain-specific operators. We showcased the
potential of this approach by employing a case study.

</details>


### [5] [AgentPack: A Dataset of Code Changes, Co-Authored by Agents and Humans](https://arxiv.org/abs/2509.21891)
*Yangtian Zi,Zixuan Wu,Aleksander Boruch-Gruszecki,Jonathan Bell,Arjun Guha*

Main category: cs.SE

TL;DR: AgentPack是一个包含130万代码编辑的数据集，这些编辑由Claude Code、OpenAI Codex和Cursor Agent等AI代理与人类共同完成。相比传统的人类提交数据，这些AI辅助的代码编辑更专注、目标更清晰，提交消息更详细。基于AgentPack微调的模型在代码编辑任务上表现优于使用传统人类提交数据训练的模型。


<details>
  <summary>Details</summary>
Motivation: 传统基于提交和拉取请求的代码编辑数据存在噪声问题：提交消息简洁、人类提交混杂多个无关编辑、许多提交来自简单的基于规则的机器人。AI软件工程代理的出现改变了这一局面，它们与人类共同编写的代码变更更加专注，提交消息更详细地阐述意图和原理。

Method: 构建AgentPack语料库，包含130万代码编辑，来自Claude Code、OpenAI Codex和Cursor Agent在公共GitHub项目中的协作编辑。描述了识别和整理流程，量化了这些代理的采用趋势，并分析了编辑的结构特性。

Result: 基于AgentPack微调的模型在代码编辑任务上表现优于使用传统人类提交数据训练的模型，展示了使用软件工程代理的公共数据训练未来代码编辑模型的潜力。

Conclusion: 软件工程代理生成的公共数据为训练代码编辑模型提供了更高质量的训练数据，基于这些数据训练的模型性能优于传统方法，代表了代码编辑模型训练的新方向。

Abstract: Fine-tuning large language models for code editing has typically relied on
mining commits and pull requests. The working hypothesis has been that commit
messages describe human intent in natural language, and patches to code
describe the changes that implement that intent. However, much of the
previously collected data is noisy: commit messages are terse, human-written
commits commingle several unrelated edits, and many commits come from simple,
rule-based bots.
  The recent adoption of software engineering agents changes this landscape.
Code changes co-authored by humans and agents tend to be more narrowly scoped
and focused on clearer goals. Their commit messages, generated by LLMs,
articulate intent and rationale in much greater detail. Moreover, when these
changes land in public repositories, they are implicitly filtered by humans:
maintainers discard low-quality commits to their projects.
  We present AgentPack, a corpus of 1.3M code edits co-authored by Claude Code,
OpenAI Codex, and Cursor Agent across public GitHub projects up to mid-August
2025. We describe the identification and curation pipeline, quantify adoption
trends of these agents, and analyze the structural properties of the edits.
Finally, we show that models fine-tuned on AgentPack can outperform models
trained on prior human-only commit corpora, highlighting the potential of using
public data from software engineering agents to train future code-editing
models.

</details>


### [6] [Unveiling Many Faces of Surrogate Models for Configuration Tuning: A Fitness Landscape Analysis Perspective](https://arxiv.org/abs/2509.21945)
*Pengzhou Chen,Hongyuan Liang,Tao Chen*

Main category: cs.SE

TL;DR: 本文首次系统性地探索了配置调优中代理模型的多种角色，提出了基于适应度景观分析的新视角，开发了Model4Tune工具来自动预测最佳模型-调优器组合。


<details>
  <summary>Details</summary>
Motivation: 传统观点认为需要更准确的代理模型来加速系统配置调优，但先前研究发现准确性可能具有欺骗性，这引发了关于代理模型在配置调优中真正作用的疑问。

Method: 通过适应度景观分析的新视角，提出了评估模型有用性的替代理论，并进行了涉及27,000个案例的广泛实证研究，开发了Model4Tune自动化预测工具。

Result: Model4Tune在79%-82%的情况下显著优于随机猜测，能够在不进行昂贵调优器分析的情况下预测最佳模型-调优器组合。

Conclusion: 研究不仅揭示了未来可能的研究方向，还提供了实用的解决方案，帮助从业者评估配置调优中最有用的模型。

Abstract: To efficiently tune configuration for better system performance (e.g.,
latency), many tuners have leveraged a surrogate model to expedite the process
instead of solely relying on the profoundly expensive system measurement. As
such, it is naturally believed that we need more accurate models. However, the
fact of accuracy can lie-a somewhat surprising finding from prior work-has left
us many unanswered questions regarding what role the surrogate model plays in
configuration tuning. This paper provides the very first systematic exploration
and discussion, together with a resolution proposal, to disclose the many faces
of surrogate models for configuration tuning, through the novel perspective of
fitness landscape analysis. We present a theory as an alternative to accuracy
for assessing the model usefulness in tuning, based on which we conduct an
extensive empirical study involving up to 27,000 cases. Drawing on the above,
we propose Model4Tune, an automated predictive tool that estimates which
model-tuner pairs are the best for an unforeseen system without expensive tuner
profiling. Our results suggest that Moldel4Tune, as one of the first of its
kind, performs significantly better than random guessing in 79%-82% of the
cases. Our results not only shed light on the possible future research
directions but also offer a practical resolution that can assist practitioners
in evaluating the most useful model for configuration tuning.

</details>


### [7] [SecureAgentBench: Benchmarking Secure Code Generation under Realistic Vulnerability Scenarios](https://arxiv.org/abs/2509.22097)
*Junkai Chen,Huihui Huang,Yunbo Lyu,Junwen An,Jieke Shi,Chengran Yang,Ting Zhang,Haoye Tian,Yikun Li,Zhenhao Li,Xin Zhou,Xing Hu,David Lo*

Main category: cs.SE

TL;DR: SecureAgentBench是一个包含105个编码任务的基准测试，用于严格评估代码代理在安全代码生成方面的能力。评估结果显示当前代理在生成安全代码方面表现不佳，最佳性能的代理仅能生成15.2%正确且安全的解决方案。


<details>
  <summary>Details</summary>
Motivation: 现有的基准测试在评估代码代理生成代码的安全性方面存在不足，往往忽略了漏洞引入的真实上下文，或采用狭窄的评估协议无法捕捉功能正确性或新引入的漏洞。

Method: 构建包含105个编码任务的SecureAgentBench基准，每个任务包括：(i)需要在大仓库中进行多文件编辑的现实任务设置；(ii)基于真实开源漏洞的上下文；(iii)结合功能测试、漏洞检查和新漏洞检测的综合评估。评估了三个代表性代理和三个最先进的LLM。

Result: 当前代理难以生成安全代码，最佳性能的SWE-agent配合DeepSeek-V3.1仅能生成15.2%正确且安全的解决方案；一些代理生成功能正确的代码但仍引入漏洞；添加明确的安全指令对改善安全编码没有显著帮助。

Conclusion: SecureAgentBench为安全代码生成提供了一个严格的基准测试，是迈向更可靠LLM软件开发的步骤，表明需要进一步研究来提高代码代理的安全性。

Abstract: Large language model (LLM) powered code agents are rapidly transforming
software engineering by automating tasks such as testing, debugging, and
repairing, yet the security risks of their generated code have become a
critical concern. Existing benchmarks have offered valuable insights but remain
insufficient: they often overlook the genuine context in which vulnerabilities
were introduced or adopt narrow evaluation protocols that fail to capture
either functional correctness or newly introduced vulnerabilities. We therefore
introduce SecureAgentBench, a benchmark of 105 coding tasks designed to
rigorously evaluate code agents' capabilities in secure code generation. Each
task includes (i) realistic task settings that require multi-file edits in
large repositories, (ii) aligned contexts based on real-world open-source
vulnerabilities with precisely identified introduction points, and (iii)
comprehensive evaluation that combines functionality testing, vulnerability
checking through proof-of-concept exploits, and detection of newly introduced
vulnerabilities using static analysis. We evaluate three representative agents
(SWE-agent, OpenHands, and Aider) with three state-of-the-art LLMs (Claude 3.7
Sonnet, GPT-4.1, and DeepSeek-V3.1). Results show that (i) current agents
struggle to produce secure code, as even the best-performing one, SWE-agent
supported by DeepSeek-V3.1, achieves merely 15.2% correct-and-secure solutions,
(ii) some agents produce functionally correct code but still introduce
vulnerabilities, including new ones not previously recorded, and (iii) adding
explicit security instructions for agents does not significantly improve secure
coding, underscoring the need for further research. These findings establish
SecureAgentBench as a rigorous benchmark for secure code generation and a step
toward more reliable software development with LLMs.

</details>


### [8] [SK2Decompile: LLM-based Two-Phase Binary Decompilation from Skeleton to Skin](https://arxiv.org/abs/2509.22114)
*Hanzhuo Tan,Weihao Li,Xiaolong Tian,Siyi Wang,Jiaming Liu,Jing Li,Yuqun Zhang*

Main category: cs.SE

TL;DR: SK2Decompile是一个新颖的两阶段反编译方法，通过从程序骨架（语义结构）到皮肤（标识符）的分解，显著提升了二进制代码反编译的正确性和可读性。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的反编译器在有效呈现程序源代码结构及其原始标识符方面存在局限，需要改进以更好地恢复程序语义。

Method: 采用两阶段方法：第一阶段使用结构恢复模型将二进制代码转换为中间表示（IR），保留控制流和数据结构但混淆标识符；第二阶段使用标识符命名模型生成有意义的标识符。两个阶段都应用强化学习来优化模型输出。

Result: 在HumanEval数据集上比GPT-5-mini平均重执行率提升21.6%，在GitHub2025基准测试中比Idioms平均R2I改进29.4%。

Conclusion: SK2Decompile通过分离结构恢复和标识符命名两个阶段，独立推进反编译的正确性和可读性，显著优于现有最先进方法。

Abstract: Large Language Models (LLMs) have emerged as a promising approach for binary
decompilation. However, the existing LLM-based decompilers still are somewhat
limited in effectively presenting a program's source-level structure with its
original identifiers. To mitigate this, we introduce SK2Decompile, a novel
two-phase approach to decompile from the skeleton (semantic structure) to the
skin (identifier) of programs. Specifically, we first apply a Structure
Recovery model to translate a program's binary code to an Intermediate
Representation (IR) as deriving the program's "skeleton", i.e., preserving
control flow and data structures while obfuscating all identifiers with generic
placeholders. We also apply reinforcement learning to reward the model for
producing program structures that adhere to the syntactic and semantic rules
expected by compilers. Second, we apply an Identifier Naming model to produce
meaningful identifiers which reflect actual program semantics as deriving the
program's "skin". We train the Identifier Naming model with a separate
reinforcement learning objective that rewards the semantic similarity between
its predictions and the reference code. Such a two-phase decompilation process
facilitates advancing the correctness and readability of decompilation
independently. Our evaluations indicate that SK2Decompile, significantly
outperforms the SOTA baselines, achieving 21.6% average re-executability rate
gain over GPT-5-mini on the HumanEval dataset and 29.4% average R2I improvement
over Idioms on the GitHub2025 benchmark.

</details>


### [9] [Leveraging LLM Agents for Automated Video Game Testing](https://arxiv.org/abs/2509.22170)
*Chengjia Wang,Lanling Tang,Ming Yuan,Jiongchi Yu,Xiaofei Xie,Jiajun Bu*

Main category: cs.SE

TL;DR: TITAN是一个基于大语言模型的智能MMORPG测试框架，通过状态感知、动作优化、长程推理和LLM检测器四个核心组件，显著提升了任务完成率和bug检测性能。


<details>
  <summary>Details</summary>
Motivation: 传统自动化游戏测试方法在MMORPG这类复杂开放环境中难以实现高状态覆盖和效率，现有LLM方法对复杂游戏状态-动作空间和长复杂任务的理解能力有限。

Method: TITAN框架包含四个关键组件：高维游戏状态感知与抽象、主动优化和优先处理可用动作、具有动作轨迹记忆和反思自校正的长程推理、基于LLM的检测器来识别潜在功能和逻辑bug。

Result: 在两个大型商业MMORPG上的实验显示，TITAN实现了95%的任务完成率，bug检测性能优于现有方法，发现了四个先前未知的bug，并已在八个真实游戏QA流水线中部署。

Conclusion: TITAN证明了LLM驱动智能测试系统的有效性，为推进智能通用测试系统提供了新方向，具有重要的实际应用价值。

Abstract: Testing MMORPGs (Massively Multiplayer Online Role-Playing Games) is a
critical yet labor-intensive task in game development due to their complexity
and frequent updating nature. Traditional automated game testing approaches
struggle to achieve high state coverage and efficiency in these rich,
open-ended environments, while existing LLM-based game-playing approaches are
limited to shallow reasoning ability in understanding complex game state-action
spaces and long-complex tasks. To address these challenges, we propose TITAN,
an effective LLM-driven agent framework for intelligent MMORPG testing. TITAN
incorporates four key components to: (1) perceive and abstract high-dimensional
game states, (2) proactively optimize and prioritize available actions, (3)
enable long-horizon reasoning with action trace memory and reflective
self-correction, and (4) employ LLM-based oracles to detect potential
functional and logic bugs with diagnostic reports.
  We implement the prototype of TITAN and evaluate it on two large-scale
commercial MMORPGs spanning both PC and mobile platforms. In our experiments,
TITAN achieves significantly higher task completion rates (95%) and bug
detection performance compared to existing automated game testing approaches.
An ablation study further demonstrates that each core component of TITAN
contributes substantially to its overall performance. Notably, TITAN detects
four previously unknown bugs that prior testing approaches fail to identify. We
provide an in-depth discussion of these results, which offer guidance for new
avenues of advancing intelligent, general-purpose testing systems. Moreover,
TITAN has been deployed in eight real-world game QA pipelines, underscoring its
practical impact as an LLM-driven game testing framework.

</details>


### [10] [Library Hallucinations in LLMs: Risk Analysis Grounded in Developer Queries](https://arxiv.org/abs/2509.22202)
*Lukas Twist,Jie M. Zhang,Mark Harman,Helen Yannakoudakis*

Main category: cs.SE

TL;DR: 本文首次系统研究了用户提示变化对LLM生成代码中库幻觉的影响，发现即使单个字符拼写错误也会导致高达26%的幻觉率，虚假库名被接受率高达99%，揭示了LLM对自然提示变化的脆弱性。


<details>
  <summary>Details</summary>
Motivation: LLM在生成代码时经常产生库幻觉，这些幻觉不仅仅是良性错误，还可能误导开发者、破坏构建过程并暴露系统于供应链威胁。尽管风险意识增强，但现实世界提示变化如何影响幻觉率尚不清楚。

Method: 评估了6种不同的LLM，研究两种幻觉类型：库名幻觉（无效导入）和库成员幻觉（有效库中的无效调用）。分析了从开发者论坛提取的现实用户语言以及不同程度的用户错误（单字符/多字符拼写错误和完全虚假名称/成员）对幻觉率的影响。

Result: 发现系统性漏洞：库名中的单字符拼写错误在高达26%的任务中触发幻觉，虚假库名在高达99%的任务中被接受，时间相关提示在高达84%的任务中导致幻觉。提示工程显示出缓解幻觉的潜力，但仍不一致且依赖特定LLM。

Conclusion: 结果强调了LLM对自然提示变化的脆弱性，并凸显了迫切需要针对库相关幻觉及其潜在利用的安全保障措施。

Abstract: Large language models (LLMs) are increasingly used to generate code, yet they
continue to hallucinate, often inventing non-existent libraries. Such library
hallucinations are not just benign errors: they can mislead developers, break
builds, and expose systems to supply chain threats such as slopsquatting.
Despite increasing awareness of these risks, little is known about how
real-world prompt variations affect hallucination rates. Therefore, we present
the first systematic study of how user-level prompt variations impact library
hallucinations in LLM-generated code. We evaluate six diverse LLMs across two
hallucination types: library name hallucinations (invalid imports) and library
member hallucinations (invalid calls from valid libraries). We investigate how
realistic user language extracted from developer forums and how user errors of
varying degrees (one- or multi-character misspellings and completely fake
names/members) affect LLM hallucination rates. Our findings reveal systemic
vulnerabilities: one-character misspellings in library names trigger
hallucinations in up to 26% of tasks, fake library names are accepted in up to
99% of tasks, and time-related prompts lead to hallucinations in up to 84% of
tasks. Prompt engineering shows promise for mitigating hallucinations, but
remains inconsistent and LLM-dependent. Our results underscore the fragility of
LLMs to natural prompt variation and highlight the urgent need for safeguards
against library-related hallucinations and their potential exploitation.

</details>


### [11] [Green Prompt Engineering: Investigating the Energy Impact of Prompt Design in Software Engineering](https://arxiv.org/abs/2509.22320)
*Vincenzo De Martino,Mohammad Amin Zadenoori,Xavier Franch,Alessio Ferrari*

Main category: cs.SE

TL;DR: 本文提出绿色提示工程，研究提示语言复杂度对能耗和性能的影响，发现更简单的提示可以降低能耗且性能损失较小。


<details>
  <summary>Details</summary>
Motivation: 语言模型在软件工程中应用日益广泛，但其推理过程带来环境问题。现有研究关注硬件选择和提示长度，但忽略了语言复杂度作为可持续性因素的重要性。

Method: 使用开源小语言模型进行需求分类的实证研究，通过改变提示的可读性来评估其对能耗和性能的影响。

Result: 研究发现提示的可读性影响环境可持续性和性能，揭示了二者之间的权衡关系。更简单的提示可以降低能耗成本，且F1分数损失不大。

Conclusion: 对实践者而言，使用更简单的提示可以在不显著损失性能的情况下降低能耗；对研究者而言，这为在绿色AI议程下制定可持续提示设计指南和研究开辟了新路径。

Abstract: Language Models are increasingly applied in software engineering, yet their
inference raises growing environmental concerns. Prior work has examined
hardware choices and prompt length, but little attention has been paid to
linguistic complexity as a sustainability factor. This paper introduces Green
Prompt Engineering, framing linguistic complexity as a design dimension that
can influence energy consumption and performance. We conduct an empirical study
on requirement classification using open-source Small Language Models, varying
the readability of prompts. Our results reveal that readability affects
environmental sustainability and performance, exposing trade-offs between them.
For practitioners, simpler prompts can reduce energy costs without a
significant F1-score loss; for researchers, it opens a path toward guidelines
and studies on sustainable prompt design within the Green AI agenda.

</details>


### [12] [GPU-Accelerated Loopy Belief Propagation for Program Analysis](https://arxiv.org/abs/2509.22337)
*Haoyu Feng,Xin Zhang*

Main category: cs.SE

TL;DR: 本文提出了一个GPU加速的LBP算法用于程序分析，支持灵活更新策略，在8个真实Java程序的数据竞争分析中实现了2.14倍和5.56倍的加速。


<details>
  <summary>Details</summary>
Motivation: LBP在大型程序分析中面临计算挑战，现有GPU方法缺乏灵活更新策略支持且未整合逻辑约束，导致性能不佳。

Method: 提出统一表示法支持任意用户定义更新策略，进行依赖分析；基于Horn子句局部结构分组消息以减少warp发散，优化GPU资源利用。

Result: 在8个真实Java程序的数据竞争分析中，相比最先进串行方法平均加速2.14倍，相比最先进GPU方法平均加速5.56倍，同时保持高精度。

Conclusion: GPU加速LBP算法能有效提升程序分析性能，支持灵活更新策略并优化GPU资源利用。

Abstract: Loopy Belief Propagation (LBP) is a widely used approximate inference
algorithm in probabilistic graphical models, with applications in computer
vision, error correction codes, protein folding, program analysis, etc.
However, LBP faces significant computational challenges when applied to
large-scale program analysis. While GPU (Graphics Processing Unit) parallel
computing provides a promising solution, existing approaches lack support for
flexible update strategies and have yet to integrate logical constraints with
GPU acceleration, leading to suboptimal practical performance.
  This paper presents a GPU-accelerated LBP algorithm for program analysis. To
support the diverse update strategies required by users, we propose a unified
representation for specifying arbitrary user-defined update strategies, along
with a dependency analysis algorithm. Furthermore, building on previous work
that leverages the local structure of Horn clauses to simplify message passing,
we group messages to minimize warp divergence and better utilize GPU resources.
Experimental results on datarace analysis over eight real-world Java programs
show that our approach achieves an average speedup of $2.14\times$ over the
state-of-the-art sequential approach and $5.56\times$ over the state-of-the-art
GPU-based approach, while maintaining high accuracy.

</details>


### [13] [A Multi-Modality Evaluation of the Reality Gap in Autonomous Driving Systems](https://arxiv.org/abs/2509.22379)
*Stefano Carlo Lambertenghi,Mirena Flores Valdez,Andrea Stocco*

Main category: cs.SE

TL;DR: 本文通过实证研究比较了四种自动驾驶系统测试模式（SiL、ViL、MR和真实世界测试），评估了它们在执行、感知和行为保真度三个维度上的现实差距，发现MR测试能提高感知真实性而不影响安全性。


<details>
  <summary>Details</summary>
Motivation: 仿真测试与真实世界行为之间存在现实差距，这挑战了测试结果在部署系统中的可转移性。需要系统评估不同测试模式的有效性。

Method: 使用配备真实传感器的小型物理车辆及其数字孪生，在室内驾驶场景中实现四种测试设置，评估两种ADS架构（模块化和端到端）。

Result: SiL和ViL设置简化了真实世界动态和感知的关键方面，而MR测试提高了感知真实性且不影响安全或控制。识别了故障在不同测试模式间不转移的条件。

Conclusion: 研究结果为每种测试模式的优缺点提供了实用见解，并为实现更稳健和可转移的自动驾驶系统验证指明了方向。

Abstract: Simulation-based testing is a cornerstone of Autonomous Driving System (ADS)
development, offering safe and scalable evaluation across diverse driving
scenarios. However, discrepancies between simulated and real-world behavior,
known as the reality gap, challenge the transferability of test results to
deployed systems. In this paper, we present a comprehensive empirical study
comparing four representative testing modalities: Software-in-the-Loop (SiL),
Vehicle-in-the-Loop (ViL), Mixed-Reality (MR), and full real-world testing.
Using a small-scale physical vehicle equipped with real sensors (camera and
LiDAR) and its digital twin, we implement each setup and evaluate two ADS
architectures (modular and end-to-end) across diverse indoor driving scenarios
involving real obstacles, road topologies, and indoor environments. We
systematically assess the impact of each testing modality along three
dimensions of the reality gap: actuation, perception, and behavioral fidelity.
Our results show that while SiL and ViL setups simplify critical aspects of
real-world dynamics and sensing, MR testing improves perceptual realism without
compromising safety or control. Importantly, we identify the conditions under
which failures do not transfer across testing modalities and isolate the
underlying dimensions of the gap responsible for these discrepancies. Our
findings offer actionable insights into the respective strengths and
limitations of each modality and outline a path toward more robust and
transferable validation of autonomous driving systems.

</details>


### [14] [Context-Specific Instruction: A Longitudinal Study on Debugging Skill Acquisition and Retention for Novice Programmers](https://arxiv.org/abs/2509.22420)
*Ziyi Zhang,Devjeet Roy,Venera Arnaoudova*

Main category: cs.SE

TL;DR: 本研究比较了四种调试指导方法的效果，发现结合具体步骤和问题特定细节的上下文特定指导(G4)在正确率和效率上显著优于其他方法，能更快地培养新手的bug定位技能。


<details>
  <summary>Details</summary>
Motivation: 新手在bug定位时缺乏系统方法，现有研究测试了抽象指导原则和通用具体步骤，但上下文特定指导的影响尚不明确。

Method: 进行了为期八周的纵向研究，44名本科生分为四组：无指导(G1)、抽象指导原则(G2)、具体步骤(G3)、上下文特定指导(G4)。每组完成5个会话，每个会话包含2-3个调试任务。

Result: G4组在第一个会话后达到80%正确率(其他组20-44%)，三周后仍保持80%正确率，完成时间稳定在13-15分钟，而其他组需要2-3个会话才能稳定在22-27分钟。

Conclusion: 上下文特定指导比抽象指导原则或上下文无关步骤能更快获得技能并保持更强记忆，将上下文示例与抽象原则结合可以弥合bug定位教育中的理论与实践差距。

Abstract: Bug localization is a critical skill, yet novices often lack systematic
approaches. Prior work tested abstract guidelines and general concrete steps;
the impact of context-specific instruction is unclear. We ran an eight-week
longitudinal study with four conditions: no instruction (G1), abstract
guidelines (G2), concrete steps (G3), and our context-specific instruction that
pairs concrete bug-localization steps with problem-specific details (G4).
Forty-four undergraduates participated; 41 completed all five sessions (S1-S5).
Each session included 2-3 debugging tasks to identify the minimal code element
containing a seeded logical fault. We measured correctness (binary), time to
completion, self-perceived scores (stress, difficulty, satisfaction, and
strategy adherence). G4 achieved higher correctness and shorter time to
completion: it reached 80% correctness after one session (vs. 20-44% for other
groups) and maintained 80% after three weeks, outperforming all groups (p <
0.05); its time to completion stabilized at 13-15 minutes in S1, whereas other
groups took 2-3 sessions to stabilize at 22-27 minutes. Qualitative responses
showed lower stress and higher satisfaction in G4, with participants
internalizing strategies via contextual examples. We conclude that
context-specific instruction yields faster skill acquisition and stronger
retention than abstract guidelines or context-agnostic steps. Even 1-2 sessions
produced significant gains, while extended practice optimized and stabilized
performance. Integrating contextual examples with abstract principles may
bridge theory-practice gaps in bug-localization education and provide a more
equitable path for novices.

</details>


### [15] [TreeMind: Automatically Reproducing Android Bug Reports via LLM-empowered Monte Carlo Tree Search](https://arxiv.org/abs/2509.22431)
*Zhengyu Chen,Zhaoyi Meng,Wenxiang Zhao,Wansen Wang,Haoyang Zhao,Jiahao Zhan,Jie Cui,Hong Zhong*

Main category: cs.SE

TL;DR: TreeMind结合LLM和蒙特卡洛树搜索(MCTS)实现自动化Android应用崩溃复现，通过战略性的UI探索解决现有方法在推理缺失步骤和重建用户操作序列方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有基于强化学习或LLM的方法在复现不完整bug报告时存在局限，难以推断未观察步骤和重建用户操作序列，主要因为缺乏目标导向的推理和规划能力。

Method: 将复现任务建模为目标驱动的搜索问题，使用MCTS作为核心规划机制，引入两个LLM引导的智能体：Expander生成有前景的操作，Simulator估计操作成功概率，结合多模态UI输入和高级提示技术进行反馈感知导航。

Result: 在包含93个真实Android bug报告的数据集上评估，TreeMind在复现成功率上显著优于四个最先进的基线方法。

Conclusion: 将LLM推理与基于MCTS的规划相结合是自动化bug复现的一个有前景的方向。

Abstract: Automatically reproducing Android app crashes from textual bug reports is
challenging, particularly when the reports are incomplete and the modern UI
exhibits high combinatorial complexity. Existing approaches based on
reinforcement learning or large language models (LLMs) exhibit limitations in
such scenarios. They struggle to infer unobserved steps and reconstruct the
underlying user action sequences to navigate the vast UI interaction space,
primarily due to limited goal-directed reasoning and planning. We present
TreeMind, a novel technique that integrates LLMs with a customized Monte Carlo
Tree Search (MCTS) algorithm to achieve strategic UI exploration in bug
reproduction. To the best of our knowledge, this is the first work to combine
external decision-making with LLM semantic reasoning for reliable bug
reproduction. We formulate the reproduction task as a target-driven search
problem, leveraging MCTS as the core planning mechanism to iteratively refine
action sequences. To enhance MCTS with semantic reasoning, we introduce two
LLM-guided agents with distinct roles: Expander generates top-k promising
actions based on the current UI state and exploration history, while Simulator
estimates the likelihood that each action leads toward successful reproduction.
By incorporating multi-modal UI inputs and advanced prompting techniques,
TreeMind conducts feedback-aware navigation that identifies missing but
essential user actions and incrementally reconstructs the reproduction paths.
We evaluate TreeMind on a dataset of 93 real-world Android bug reports from
three widely-used benchmarks. Experimental results show that it significantly
outperforms four state-of-the-art baselines in reproduction success rate. A
real-world case study indicates that integrating LLM reasoning with MCTS-based
planning is a compelling direction for automated bug reproduction.

</details>


### [16] [Boosting Pointer Analysis With Large Language Model-Enhanced Allocation Function Detection](https://arxiv.org/abs/2509.22530)
*Baijun Cheng,Kailong Wang,Ling Shi,Haoyu Wang,Peng Di,Yao Guo,Ding Li,Xiangqun Chen*

Main category: cs.SE

TL;DR: AFD是一种增强指针分析的新技术，通过自动识别和建模自定义分配函数来提高分析精度，在15个真实C项目中识别了600多个自定义分配函数，显著提升了堆对象建模和别名分析精度。


<details>
  <summary>Details</summary>
Motivation: 现有指针分析方法在很大程度上忽视了自定义分配函数，导致粗粒度的别名分析和降低的分析精度，特别是在C/C++程序中用户自定义分配函数普遍存在的情况下。

Method: AFD采用混合方法：使用值流分析检测简单包装器，并利用大型语言模型推理具有副作用的更复杂分配模式，实现精确的堆对象建模。

Result: 在15个真实C项目中识别了600多个自定义分配函数，集成AFD后堆对象建模增加26倍，别名集大小减少39%，运行时开销仅为1.4倍，还发现了17个之前未检测到的内存错误。

Conclusion: 精确建模自定义分配函数为提高大型软件系统中指针分析的精度提供了可扩展且实用的途径。

Abstract: Pointer analysis is foundational for many static analysis tasks, yet its
effectiveness is often hindered by imprecise modeling of heap allocations,
particularly in C/C++ programs where user-defined allocation functions (AFs)
are pervasive. Existing approaches largely overlook these custom allocators,
leading to coarse aliasing and reduced analysis precision. In this paper, we
present AFD, a novel technique that enhances pointer analysis by automatically
identifying and modeling custom allocation functions. AFD employs a hybrid
approach: it uses value-flow analysis to detect straightforward wrappers and
leverages Large Language Models (LLMs) to reason about more complex allocation
patterns with side effects. This targeted enhancement enables precise modeling
of heap objects at each call site, achieving context-sensitivity-like benefits
without the associated overhead. We evaluate AFD on 15 real-world C projects,
identifying over 600 custom AFs. Integrating AFD into a baseline pointer
analysis yields a 26x increase in modeled heap objects and a 39% reduction in
alias set sizes, with only 1.4x runtime overhead. Furthermore, our enhanced
analysis improves indirect call resolution and uncovers 17 previously
undetected memory bugs. These results demonstrate that precise modeling of
custom allocation functions offers a scalable and practical path to improving
pointer analysis in large software systems.

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [17] [QueryGym: Step-by-Step Interaction with Relational Databases](https://arxiv.org/abs/2509.21674)
*Haritha Ananthakrishanan,Harsha Kokel,Kelsey Sikes,Debarun Bhattacharjya,Michael Katz,Shirin Sohrabi,Kavitha Srinivas*

Main category: cs.DB

TL;DR: QueryGym是一个用于构建、测试和评估基于LLM的查询规划代理的交互式环境，通过显式的关系代数操作序列确保引擎无关评估和透明化逐步规划。


<details>
  <summary>Details</summary>
Motivation: 现有框架通常将代理绑定到特定查询语言方言或隐藏其推理过程，缺乏透明度和通用性评估。

Method: 作为Gymnasium接口实现，提供模式细节、中间结果和执行反馈等观察，接收数据库探索和关系代数操作作为动作。

Result: 展示了与当代LLM查询数据库的对比，证明了环境的实用性。

Conclusion: QueryGym为查询生成中的错误修复、透明度和强化学习研究提供了实用的测试平台。

Abstract: We introduce QueryGym, an interactive environment for building, testing, and
evaluating LLM-based query planning agents. Existing frameworks often tie
agents to specific query language dialects or obscure their reasoning; QueryGym
instead requires agents to construct explicit sequences of relational algebra
operations, ensuring engine-agnostic evaluation and transparent step-by-step
planning. The environment is implemented as a Gymnasium interface that supplies
observations -- including schema details, intermediate results, and execution
feedback -- and receives actions that represent database exploration (e.g.,
previewing tables, sampling column values, retrieving unique values) as well as
relational algebra operations (e.g., filter, project, join). We detail the
motivation and the design of the environment. In the demo, we showcase the
utility of the environment by contrasting it with contemporary LLMs that query
databases. QueryGym serves as a practical testbed for research in error
remediation, transparency, and reinforcement learning for query generation. For
the associated demo, see https://ibm.biz/QueryGym.

</details>


### [18] [Unbiased Binning: Fairness-aware Attribute Representation](https://arxiv.org/abs/2509.21785)
*Abolfazl Asudeh,Zeinab,Asoodeh,Bita Asoodeh,Omid Asudeh*

Main category: cs.DB

TL;DR: 本文提出了无偏分箱问题，旨在寻找最接近等大小分箱且满足组间公平性的离散化方法，并开发了高效的动态规划算法。当无偏分箱不可行时，进一步引入ε-偏分箱问题，提出了基于局部搜索的可扩展算法。


<details>
  <summary>Details</summary>
Motivation: 特征离散化是数据共享的常见步骤，但会导致数据偏差并放大下游任务的不公平性。需要找到既能保持数据效用又能确保组间公平的离散化方法。

Method: 1. 定义边界候选集，证明无偏分箱必须从此集合中选择边界；2. 开发基于边界候选集的动态规划算法；3. 对于ε-偏分箱问题，提出动态规划解法和基于局部搜索的可扩展算法，其中包含分治算法作为关键组件。

Result: 证明了无偏分箱边界必须来自预定义的候选集；开发了多项式时间的动态规划算法；针对大规模设置提出了基于局部搜索的实用可扩展算法，分治算法能在近线性时间内找到近似最优解。

Conclusion: 本文系统解决了特征离散化中的公平性问题，提供了从理论证明到实际算法的完整解决方案，能够在保持数据效用的同时确保组间公平，特别适用于大规模数据集。

Abstract: Discretizing raw features into bucketized attribute representations is a
popular step before sharing a dataset. It is, however, evident that this step
can cause significant bias in data and amplify unfairness in downstream tasks.
  In this paper, we address this issue by introducing the unbiased binning
problem that, given an attribute to bucketize, finds its closest discretization
to equal-size binning that satisfies group parity across different buckets.
Defining a small set of boundary candidates, we prove that unbiased binning
must select its boundaries from this set. We then develop an efficient dynamic
programming algorithm on top of the boundary candidates to solve the unbiased
binning problem.
  Finding an unbiased binning may sometimes result in a high price of fairness,
or it may not even exist, especially when group values follow different
distributions. Considering that a small bias in the group ratios may be
tolerable in such settings, we introduce the epsilon-biased binning problem
that bounds the group disparities across buckets to a small value epsilon. We
first develop a dynamic programming solution, DP, that finds the optimal
binning in quadratic time. The DP algorithm, while polynomial, does not scale
to very large settings. Therefore, we propose a practically scalable algorithm,
based on local search (LS), for epsilon-biased binning. The key component of
the LS algorithm is a divide-and-conquer (D&C) algorithm that finds a
near-optimal solution for the problem in near-linear time. We prove that D&C
finds a valid solution for the problem unless none exists. The LS algorithm
then initiates a local search, using the D&C solution as the upper bound, to
find the optimal solution.

</details>


### [19] [The system of processing and analysis of customer tracking data for customer journey research on the base of RFID technology](https://arxiv.org/abs/2509.22162)
*Marina Kholod*

Main category: cs.DB

TL;DR: 该研究开发了一个基于RFID技术的追踪数据处理分析系统，用于研究零售业客户旅程，通过ETL方法整合RFID和POS数据，建立结构化数据仓库，并采用平衡计分卡评估RFID实施的商业效益。


<details>
  <summary>Details</summary>
Motivation: 研究RFID技术在零售业的应用，超越传统物流功能，实现精确库存管理、防损和客户体验提升，通过整合追踪和交易数据来深入了解客户行为模式。

Method: 采用ETL（提取、转换、加载）方法处理原始RFID和POS数据，构建结构化分析数据仓库，设计逻辑数据库模型结合销售指标与客户移动行为模式。

Result: 提出了完整的RFID数据处理架构和逻辑数据库模型，能够将财务销售指标与客户行为模式进行综合分析。

Conclusion: RFID追踪数据与交易数据的整合为零售业向精确、数据驱动的科学转型奠定了基础，提供了对实体产品流和消费者行为前所未有的可视性。

Abstract: The article focuses on researching a system for processing and analyzing
tracking data based on RFID technology to study the customer journey in retail.
It examines the evolution of RFID technology, its key operating principles, and
modern applications in retail that extend beyond logistics to include precise
inventory management, loss prevention, and customer experience improvement.
Particular attention is paid to the architecture for data collection,
processing, and integration, specifically the ETL (extract, transform, load)
methodology for transforming raw RFID and POS data into a structured analytical
data warehouse. A detailed logical database model is proposed, designed for
comprehensive analysis that combines financial sales metrics with behavioral
patterns of customer movement. The article also analyzes the expected business
benefits of RFID implementation through the lens of the Balanced Scorecard
(BSC), which evaluates financial performance, customer satisfaction, and
internal process optimization. It is concluded that the integration of tracking
and transactional data creates a foundation for transforming retail into a
precise, data-driven science, providing unprecedented visibility into physical
product flows and consumer behavior.

</details>


### [20] [I-ETL: an interoperability-aware health (meta) data pipeline to enable federated analyses](https://arxiv.org/abs/2509.22351)
*Nelly Barret,Anna Bernasconi,Boris Bikbov,Pietro Pinoli*

Main category: cs.DB

TL;DR: I-ETL是一个用于整合高度异构医疗数据集的框架，通过两个可扩展的概念模型和ETL管道确保互操作性，支持联邦学习环境下的医疗数据协作。


<details>
  <summary>Details</summary>
Motivation: 临床医生需要共享和分析复杂疾病数据，但医疗机构的异构数据格式和隐私要求阻碍了合作。需要一种能在保护隐私的同时整合不同来源医疗数据的方法。

Method: 设计两个通用可扩展的概念模型来建模数据和元数据，并提出一个确保互操作性的ETL（提取-转换-加载）管道。

Result: 在开源数据集上的实验表明，I-ETL能够以统一方式表示各种健康数据集，并确保不同中心之间的协作可能性。

Conclusion: I-ETL框架成功解决了医疗数据异构性问题，将互操作性作为集成管道的首要考虑因素，为联邦学习环境下的医疗数据协作提供了可行方案。

Abstract: Clinicians are interested in better understanding complex diseases, such as
cancer or rare diseases, so they need to produce and exchange data to mutualize
sources and join forces. To do so and ensure privacy, a natural way consists in
using a decentralized architecture and Federated Learning algorithms. This
ensures that data stays in the organization in which it has been collected, but
requires data to be collected in similar settings and similar models. In
practice, this is often not the case because healthcare institutions work
individually with different representations and raw data; they do not have
means to normalize their data, and even less to do so across centers. For
instance, clinicians have at hand phenotypic, clinical, imaging and genomic
data (each individually collected) and want to better understand some diseases
by analyzing them together. This example highlights the needs and challenges
for a cooperative use of this wealth of information. We designed and
implemented a framework, named I-ETL, for integrating highly heterogeneous
healthcare datasets of hospitals in interoperable databases. Our proposal is
twofold: (i) we devise two general and extensible conceptual models for
modeling both data and metadata and (ii) we propose an Extract-Transform-Load
(ETL) pipeline ensuring and assessing interoperability from the start. By
conducting experiments on open-source datasets, we show that I-ETL succeeds in
representing various health datasets in a unified way thanks to our two general
conceptual models. Next, we demonstrate the importance of blending
interoperability as a first-class citizen in integration pipelines, ensuring
possible collaboration between different centers.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [21] [Redesigning GROMACS Halo Exchange: Improving Strong Scaling with GPU-initiated NVSHMEM](https://arxiv.org/abs/2509.21527)
*Mahesh Doijade,Andrey Alekseenko,Ania Brown,Alan Gray,Szilárd Páll*

Main category: cs.DC

TL;DR: 本文提出了一种基于NVSHMEM的GPU内核启动的GROMACS域分解halo交换算法重设计，通过GPU内核融合数据打包和通信，利用硬件延迟隐藏实现细粒度重叠，显著提升了分子动力学模拟的强扩展性能。


<details>
  <summary>Details</summary>
Motivation: GROMACS分子动力学模拟在异构超级计算机上存在强扩展挑战，MPI的CPU中心特性在GPU驻留应用的关键路径上引入额外延迟，阻碍了GPU利用率和可扩展性。

Method: 采用NVSHMEM的GPU内核启动重新设计GROMACS域分解halo交换算法，通过高度优化的GPU内核融合数据打包和通信，利用异步复制引擎在NVLink上优化延迟和带宽。

Result: 在NVLink上实现了高达1.5倍（节点内）和2倍（多节点）的GROMACS强扩展性能提升，在NVLink+InfiniBand多节点环境下提升达1.3倍。

Conclusion: GPU启动通信对于强扩展各种延迟敏感应用具有深远益处，证明了GPU驻留通信设计的重要性。

Abstract: Improving time-to-solution in molecular dynamics simulations often requires
strong scaling due to fixed-sized problems. GROMACS is highly
latency-sensitive, with peak iteration rates in the sub-millisecond, making
scalability on heterogeneous supercomputers challenging. MPI's CPU-centric
nature introduces additional latencies on GPU-resident applications' critical
path, hindering GPU utilization and scalability. To address these limitations,
we present an NVSHMEM-based GPU kernel-initiated redesign of the GROMACS domain
decomposition halo-exchange algorithm. Highly tuned GPU kernels fuse data
packing and communication, leveraging hardware latency-hiding for fine-grained
overlap. We employ kernel fusion across overlapped data forwarding
communication phases and utilize the asynchronous copy engine over NVLink to
optimize latency and bandwidth. Our GPU-resident formulation greatly increases
communication-computation overlap, improving GROMACS strong scaling performance
across NVLink by up to 1.5x (intra-node) and 2x (multi-node), and up to 1.3x
multi-node over NVLink+InfiniBand. This demonstrates the profound benefits of
GPU-initiated communication for strong-scaling a broad range of
latency-sensitive applications.

</details>


### [22] [Zeppelin: Balancing Variable-length Workloads in Data Parallel Large Model Training](https://arxiv.org/abs/2509.21841)
*Chang Chen,Tiancheng Chen,Jiangfei Duan,Qianchao Zhu,Zerui Wang,Qinghao Hu,Peng Sun,Xiuhong Li,Chao Yang,Torsten Hoefler*

Main category: cs.DC

TL;DR: Zeppelin是一个解决大语言模型训练中序列长度变化导致的负载不平衡问题的系统，通过分层序列分区、路由层和重映射层技术，相比现有方法实现了2.80倍的平均加速。


<details>
  <summary>Details</summary>
Motivation: 训练大语言模型时，序列长度变化和增加会带来严重的负载不平衡问题，现有方法忽略了计算和通信成本随序列长度的变化，导致性能不佳。

Method: 1. 分层序列分区方法减少通信开销并平衡计算；2. 路由层协调节点间传输以充分利用NIC带宽；3. 重映射层在注意力和线性模块间转换序列布局。

Result: 在各种配置下的综合评估显示，Zeppelin相比最先进方法实现了平均2.80倍的加速。

Conclusion: Zeppelin通过解决序列长度变化带来的三个关键挑战，显著提升了大规模数据并行训练的性能。

Abstract: Training large language models (LLMs) with increasingly long and varying
sequence lengths introduces severe load imbalance challenges in large-scale
data-parallel training. Recent frameworks attempt to mitigate these issues
through data reorganization or hybrid parallel strategies. However, they often
overlook how computational and communication costs scale with sequence length,
resulting in suboptimal performance. We identify three critical challenges: (1)
varying computation-to-communication ratios across sequences of different
lengths in distributed attention, (2) mismatch between static NIC-GPU affinity
and dynamic parallel workloads, and (3) distinct optimal partitioning
strategies required for quadratic attention versus linear components. To
address these challenges, we present Zeppelin, a novel training system that
integrates three key techniques: (1) a hierarchical sequence partitioning
method for the attention module that reduces communication overhead and
balances computation, supported by an efficient attention engine that applies
divergent parallel strategies; (2) a routing layer that orchestrates inter-node
transfers to fully utilize NIC bandwidth; and (3) a remapping layer that
transforms sequence layouts between attention and linear modules, ensuring high
computational efficiency across both. Comprehensive evaluations across diverse
configurations show that Zeppelin delivers an average 2.80x speedup over
state-of-the-art methods.

</details>


### [23] [Code once, Run Green: Automated Green Code Translation in Serverless Computing](https://arxiv.org/abs/2509.22068)
*Sebastian Werner,Mathis Kähler,Alireza Hakamian*

Main category: cs.DC

TL;DR: 本文探讨了利用无服务器计算平台和大型语言模型自动减少能源债务的潜力，通过将无服务器函数转换为更节能的编程语言，最高可减少70%的调用能耗。


<details>
  <summary>Details</summary>
Motivation: 计算基础设施的快速数字化和AI模型等新兴技术的使用显著增加了碳排放。现有的缓解策略依赖于利益相关者干预，在遗留系统中难以实施，导致过去的架构决策持续产生额外能源消耗，即能源债务。

Method: 设计并实现了ReFaaS系统，集成到Fission无服务器框架中，利用大型语言模型将无服务器函数转换为更节能的编程语言，同时保持功能正确性。

Result: 初步结果显示，转换后的函数可减少高达70%的调用能耗，根据使用的LLM不同，大约在3,000到5,000次调用后实现净能源节约。

Conclusion: 虽然该方法面临挑战（并非所有函数都适合转换，某些函数的摊销门槛较高），但确定了四个关键研究挑战，解决这些挑战可能解锁无服务器计算中长期、自动化的能源债务缓解。

Abstract: The rapid digitization and the increasing use of emerging technologies such
as AI models have significantly contributed to the emissions of computing
infrastructure. Efforts to mitigate this impact typically focus on the
infrastructure level such as powering data centers with renewable energy, or
through the specific design of energy-efficient software. However, both
strategies rely on stakeholder intervention, making their adoption in legacy
and already-deployed systems unlikely. As a result, past architectural and
implementation decisions continue to incur additional energy usage - a
phenomenon we refer to as energy debt.
  Hence, in this paper, we investigate the potential of serverless computing
platforms to automatically reduce energy debt by leveraging the unique access
to function source code. Specifically, we explore whether large language models
(LLMs) can translate serverless functions into more energy-efficient
programming languages while preserving functional correctness. To this end, we
design and implement ReFaaS and integrate it into the Fission serverless
framework. We evaluate multiple LLMs on their ability to perform such code
translations and analyze their impact on energy consumption.
  Our preliminary results indicate that translated functions can reduce
invocation energy by up to 70%, achieving net energy savings after
approximately 3,000 to 5,000 invocations, depending on the LLM used.
Nonetheless, the approach faces several challenges: not all functions are
suitable for translation, and for some, the amortization threshold is
significantly higher or unreachable. Despite these limitations, we identify
four key research challenges whose resolution could unlock long-term, automated
mitigation of energy debt in serverless computing.

</details>


### [24] [The AI_INFN Platform: Artificial Intelligence Development in the Cloud](https://arxiv.org/abs/2509.22117)
*Lucio Anderlini,Giulio Bianchini,Diego Ciangottini,Stefano Dal Pra,Diego Michelotto,Rosa Petrini,Daniele Spiga*

Main category: cs.DC

TL;DR: INFN AI项目通过Kubernetes平台为机器学习工作流提供GPU加速资源管理，支持在异构分布式计算环境中部署和扩展AI应用，包括WLCG网格和超级计算机。


<details>
  <summary>Details</summary>
Motivation: 机器学习在科学软件中的广泛应用对计算基础设施提出了新挑战，特别是在硬件加速器的配置和编排方面。AI_INFN项目旨在促进INFN内部机器学习技术的采用。

Method: 利用云原生解决方案在INFN Cloud中构建Kubernetes平台，通过Virtual Kubelet和InterLink API实现工作流在不同资源提供商间的管理和扩展。

Result: 平台能够管理跨不同资源提供商的工作流，包括WLCG站点和CINECA Leonardo超级计算机，为需要专用基础设施的工作负载提供了模型。

Conclusion: 该平台为机器学习工作流提供了有效的GPU资源管理和扩展解决方案，支持在异构分布式环境中部署AI应用。

Abstract: Machine Learning (ML) is driving a revolution in the way scientists design,
develop, and deploy data-intensive software. However, the adoption of ML
presents new challenges for the computing infrastructure, particularly in terms
of provisioning and orchestrating access to hardware accelerators for
development, testing, and production. The INFN-funded project AI_INFN
(Artificial Intelligence at INFN) aims at fostering the adoption of ML
techniques within INFN use cases by providing support on multiple aspects,
including the provisioning of AI-tailored computing resources. It leverages
cloud-native solutions in the context of INFN Cloud, to share hardware
accelerators as effectively as possible, ensuring the diversity of the
Institute's research activities is not compromised. In this contribution, we
provide an update on the commissioning of a Kubernetes platform designed to
ease the development of GPU-powered data analysis workflows and their
scalability on heterogeneous distributed computing resources, also using the
offloading mechanism with Virtual Kubelet and InterLink API. This setup can
manage workflows across different resource providers, including sites of the
Worldwide LHC Computing Grid and supercomputers such as CINECA Leonardo,
providing a model for use cases requiring dedicated infrastructures for
different parts of the workload. Initial test results, emerging case studies,
and integration scenarios will be presented with functional tests and
benchmarks.

</details>


### [25] [Orientation does not help with 3-coloring a grid in online-LOCAL](https://arxiv.org/abs/2509.22233)
*Thomas Boudier,Filippo Casagrande,Avinandan Das,Massimo Equi,Henrik Lievonen,Augusto Modanese,Ronja Stimpert*

Main category: cs.DC

TL;DR: 本文证明了在确定性在线-LOCAL和随机化在线-LOCAL模型中，即使算法明确获得网格的全局一致方向信息，3-着色网格图仍然需要Ω(log n)的局部性。


<details>
  <summary>Details</summary>
Motivation: 先前的研究表明3-着色二分图在在线-LOCAL模型中需要全局内存优势，但证明都依赖于算法无法访问网格方向的假设。本文旨在消除这一限制。

Method: 通过改进证明技术，展示了即使算法明确获得网格的全局一致方向信息，3-着色网格图的局部性下界仍然成立。

Result: 成功证明了在确定性在线-LOCAL和随机化在线-LOCAL模型中，3-着色网格图需要Ω(log n)的局部性，且这一结果不依赖于方向信息的假设。

Conclusion: 网格图的3-着色问题在在线-LOCAL模型中确实需要较高的局部性，这一性质不受算法是否获得网格方向信息的影响。

Abstract: The online-LOCAL and SLOCAL models are extensions of the LOCAL model where
nodes are processed in a sequential but potentially adversarial order. So far,
the only problem we know of where the global memory of the online-LOCAL model
has an advantage over SLOCAL is 3-coloring bipartite graphs. Recently, Chang et
al. [PODC 2024] showed that even in grids, 3-coloring requires $\Omega(\log n)$
locality in deterministic online-LOCAL. This result was subsequently extended
by Akbari et al. [STOC 2025] to also hold in randomized online-LOCAL. However,
both proofs heavily rely on the assumption that the algorithm does not have
access to the orientation of the underlying grid. In this paper, we show how to
lift this requirement and obtain the same lower bound (against either model)
even when the algorithm is explicitly given a globally consistent orientation
of the grid.

</details>
